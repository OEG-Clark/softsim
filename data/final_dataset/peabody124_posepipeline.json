{"home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.make_entry": [[28, 39], ["os.path.split", "datetime.datetime.datetime.strptime", "d.update"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update"], ["@", "staticmethod", "\n", "def", "make_entry", "(", "filepath", ",", "session_id", "=", "None", ")", ":", "\n", "        ", "from", "datetime", "import", "datetime", "\n", "import", "os", "\n", "\n", "_", ",", "fn", "=", "os", ".", "path", ".", "split", "(", "filepath", ")", "\n", "date", "=", "datetime", ".", "strptime", "(", "fn", "[", ":", "16", "]", ",", "'%Y%m%d-%H%M%SZ'", ")", "\n", "d", "=", "{", "'filename'", ":", "fn", ",", "'video'", ":", "filepath", ",", "'start_time'", ":", "date", "}", "\n", "if", "session_id", "is", "not", "None", ":", "\n", "            ", "d", ".", "update", "(", "{", "'session_id'", ":", "session_id", "}", ")", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader": [[40, 78], ["tempfile.mkstemp", "subprocess.run", "cv2.VideoCapture", "int", "range", "cv2.VideoCapture.get", "tempfile.mkstemp", "print", "subprocess.run", "cv2.VideoCapture.read", "cv2.VideoCapture.set", "cv2.VideoCapture.release", "cv2.VideoCapture.release", "pipeline.Video.get_robust_reader.compress"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.video_format.compress"], ["", "@", "staticmethod", "\n", "def", "get_robust_reader", "(", "key", ",", "return_cap", "=", "True", ")", ":", "\n", "        ", "import", "subprocess", "\n", "import", "tempfile", "\n", "\n", "# fetch video and place in temp directory", "\n", "video", "=", "(", "Video", "&", "key", ")", ".", "fetch1", "(", "'video'", ")", "\n", "_", ",", "outfile", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "subprocess", ".", "run", "(", "[", "'mv'", ",", "video", ",", "outfile", "]", ")", "\n", "video", "=", "outfile", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "\n", "# check all the frames are readable", "\n", "expected_frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "completed", "=", "True", "\n", "\n", "def", "compress", "(", "video", ")", ":", "\n", "            ", "_", ",", "outfile", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "print", "(", "f'Unable to read all the fails. Transcoding {video} to {outfile}'", ")", "\n", "subprocess", ".", "run", "(", "[", "'ffmpeg'", ",", "'-y'", ",", "'-i'", ",", "video", ",", "'-c:v'", ",", "'libx264'", ",", "'-b:v'", ",", "'1M'", ",", "outfile", "]", ")", "\n", "return", "outfile", "\n", "\n", "", "for", "i", "in", "range", "(", "expected_frames", ")", ":", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "                ", "cap", ".", "release", "(", ")", "\n", "\n", "video", "=", "compress", "(", "video", ")", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "break", "\n", "\n", "", "", "if", "return_cap", ":", "\n", "            ", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ",", "0", ")", "\n", "return", "cap", "\n", "", "else", ":", "\n", "            ", "cap", ".", "release", "(", ")", "\n", "return", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.VideoInfo.make": [[93, 107], ["cv2.VideoCapture", "cv2.VideoCapture.get", "int", "int", "int", "pipeline.VideoInfo.insert1", "os.remove", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "datetime.datetime.timedelta().total_seconds", "datetime.datetime.timedelta", "range", "range", "datetime.datetime.timedelta"], "methods", ["None"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "video", ",", "start_time", "=", "(", "Video", "&", "key", ")", ".", "fetch1", "(", "'video'", ",", "'start_time'", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "key", "[", "'fps'", "]", "=", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "key", "[", "'num_frames'", "]", "=", "frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "key", "[", "'width'", "]", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "key", "[", "'height'", "]", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "key", "[", "'timestamps'", "]", "=", "[", "start_time", "+", "timedelta", "(", "0", ",", "i", "/", "fps", ")", "for", "i", "in", "range", "(", "frames", ")", "]", "\n", "key", "[", "'delta_time'", "]", "=", "[", "timedelta", "(", "0", ",", "i", "/", "fps", ")", ".", "total_seconds", "(", ")", "for", "i", "in", "range", "(", "frames", ")", "]", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.VideoInfo.fetch_timestamps": [[108, 113], ["pipeline.VideoInfo.fetch1", "numpy.array", "len"], "methods", ["None"], ["", "def", "fetch_timestamps", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ")", "==", "1", ",", "\"Restrict to single entity\"", "\n", "timestamps", "=", "self", ".", "fetch1", "(", "'timestamps'", ")", "\n", "timestamps", "=", "np", ".", "array", "(", "[", "(", "t", "-", "timestamps", "[", "0", "]", ")", ".", "total_seconds", "(", ")", "for", "t", "in", "timestamps", "]", ")", "\n", "return", "timestamps", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.BottomUpPeople.make": [[142, 153], ["pipeline.BottomUpPeople.insert1", "Exception", "mmpose_bottom_up", "Exception"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmpose.mmpose_bottom_up"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "if", "key", "[", "'bottom_up_method_name'", "]", "==", "'OpenPose'", ":", "\n", "            ", "raise", "Exception", "(", "'OpenPose wrapper not implemented yet'", ")", "\n", "", "elif", "key", "[", "'bottom_up_method_name'", "]", "==", "'MMPose'", ":", "\n", "            ", "from", ".", "wrappers", ".", "mmpose", "import", "mmpose_bottom_up", "\n", "key", "[", "'keypoints'", "]", "=", "mmpose_bottom_up", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Method not implemented\"", ")", "\n", "\n", "", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.OpenPose.make": [[167, 185], ["pipeline.Video.get_robust_reader", "pipeline.OpenPose.insert1", "os.remove", "env.add_path", "openpose_parse_video", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.openpose_parse_video"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "return_cap", "=", "False", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'OPENPOSE_PATH'", "]", ",", "'build/python'", ")", ")", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "openpose", "import", "openpose_parse_video", "\n", "res", "=", "openpose_parse_video", "(", "video", ")", "\n", "\n", "", "key", "[", "'keypoints'", "]", "=", "[", "r", "[", "'keypoints'", "]", "for", "r", "in", "res", "]", "\n", "key", "[", "'pose_ids'", "]", "=", "[", "r", "[", "'pose_ids'", "]", "for", "r", "in", "res", "]", "\n", "key", "[", "'pose_scores'", "]", "=", "[", "r", "[", "'pose_scores'", "]", "for", "r", "in", "res", "]", "\n", "key", "[", "'hand_keypoints'", "]", "=", "[", "r", "[", "'hand_keypoints'", "]", "for", "r", "in", "res", "]", "\n", "key", "[", "'face_keypoints'", "]", "=", "[", "r", "[", "'face_keypoints'", "]", "for", "r", "in", "res", "]", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "# remove the downloaded video to avoid clutter", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.BlurredVideo.make": [[196, 229], ["pipeline.Video.get_robust_reader", "tempfile.mkstemp", "video_overlay", "pipeline.BlurredVideo.insert1", "os.remove", "os.remove", "image.copy.copy.copy", "numpy.linalg.norm", "numpy.clip", "range", "cv2.circle", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", "\n", "\n", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "return_cap", "=", "False", ")", "\n", "keypoints", "=", "(", "OpenPose", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "def", "overlay_callback", "(", "image", ",", "idx", ")", ":", "\n", "            ", "image", "=", "image", ".", "copy", "(", ")", "\n", "if", "keypoints", "[", "idx", "]", "is", "None", ":", "\n", "                ", "return", "image", "\n", "\n", "", "found_noses", "=", "keypoints", "[", "idx", "]", "[", ":", ",", "0", ",", "-", "1", "]", ">", "0.1", "\n", "nose_positions", "=", "keypoints", "[", "idx", "]", "[", "found_noses", ",", "0", ",", ":", "2", "]", "\n", "neck_positions", "=", "keypoints", "[", "idx", "]", "[", "found_noses", ",", "1", ",", ":", "2", "]", "\n", "\n", "radius", "=", "np", ".", "linalg", ".", "norm", "(", "neck_positions", "-", "nose_positions", ",", "axis", "=", "1", ")", "\n", "radius", "=", "np", ".", "clip", "(", "radius", ",", "10", ",", "250", ")", "\n", "\n", "for", "i", "in", "range", "(", "nose_positions", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "center", "=", "(", "int", "(", "nose_positions", "[", "i", ",", "0", "]", ")", ",", "int", "(", "nose_positions", "[", "i", ",", "1", "]", ")", ")", "\n", "cv2", ".", "circle", "(", "image", ",", "center", ",", "int", "(", "radius", "[", "i", "]", ")", ",", "(", "255", ",", "255", ",", "255", ")", ",", "-", "1", ")", "\n", "\n", "", "return", "image", "\n", "\n", "", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "overlay_callback", ",", "downsample", "=", "1", ")", "\n", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.TrackingBbox.make": [[265, 316], ["pipeline.Video.get_robust_reader", "numpy.unique", "len", "pipeline.TrackingBbox.insert1", "os.path.exists", "tracking_bounding_boxes", "os.remove", "mmtrack_bounding_boxes", "mmtrack_bounding_boxes", "mmtrack_bounding_boxes", "fairmot_bounding_boxes", "transtrack_bounding_boxes", "trades_bounding_boxes", "os.remove", "Exception"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.parser.tracking_bounding_boxes", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmtrack.mmtrack_bounding_boxes", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmtrack.mmtrack_bounding_boxes", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmtrack.mmtrack_bounding_boxes", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.fairmot.fairmot_bounding_boxes", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.transtrack.transtrack_bounding_boxes", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.trades.trades_bounding_boxes"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "return_cap", "=", "False", ")", "\n", "\n", "if", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "==", "'DeepSortYOLOv4'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "deep_sort_yolov4", ".", "parser", "import", "tracking_bounding_boxes", "\n", "tracks", "=", "tracking_bounding_boxes", "(", "video", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "elif", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "in", "'MMTrack_tracktor'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "mmtrack", "import", "mmtrack_bounding_boxes", "\n", "tracks", "=", "mmtrack_bounding_boxes", "(", "video", ",", "'tracktor'", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "elif", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "==", "'MMTrack_deepsort'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "mmtrack", "import", "mmtrack_bounding_boxes", "\n", "tracks", "=", "mmtrack_bounding_boxes", "(", "video", ",", "'deepsort'", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "elif", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "==", "'MMTrack_bytetrack'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "mmtrack", "import", "mmtrack_bounding_boxes", "\n", "tracks", "=", "mmtrack_bounding_boxes", "(", "video", ",", "'bytetrack'", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "elif", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "==", "'FairMOT'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "fairmot", "import", "fairmot_bounding_boxes", "\n", "tracks", "=", "fairmot_bounding_boxes", "(", "video", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "elif", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "==", "'TransTrack'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "transtrack", "import", "transtrack_bounding_boxes", "\n", "tracks", "=", "transtrack_bounding_boxes", "(", "video", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "elif", "(", "TrackingBboxMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'tracking_method_name'", ")", "==", "'TraDeS'", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "trades", "import", "trades_bounding_boxes", "\n", "tracks", "=", "trades_bounding_boxes", "(", "video", ")", "\n", "key", "[", "'tracks'", "]", "=", "tracks", "\n", "\n", "", "else", ":", "\n", "            ", "os", ".", "remove", "(", "video", ")", "\n", "raise", "Exception", "(", "f\"Unsupported tracking method: {key['tracking_method']}\"", ")", "\n", "\n", "", "track_ids", "=", "np", ".", "unique", "(", "[", "t", "[", "'track_id'", "]", "for", "track", "in", "tracks", "for", "t", "in", "track", "]", ")", "\n", "key", "[", "'num_tracks'", "]", "=", "len", "(", "track_ids", ")", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "# remove the downloaded video to avoid clutter", "\n", "if", "os", ".", "path", ".", "exists", "(", "video", ")", ":", "\n", "            ", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.TrackingBboxVideo.make": [[327, 371], ["len", "matplotlib.cm.get_cmap", "tempfile.mkstemp", "video_overlay", "pipeline.TrackingBboxVideo.insert1", "os.remove", "os.remove", "numpy.unique", "image.copy.copy.copy", "matplotlib.cm.get_cmap.", "int", "cv2.rectangle", "cv2.rectangle", "str", "int", "int", "cv2.putText", "cv2.putText", "int", "int", "int", "cv2.getTextSize", "numpy.max", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "import", "matplotlib", "\n", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", "\n", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "tracks", "=", "(", "TrackingBbox", "&", "key", ")", ".", "fetch1", "(", "'tracks'", ")", "\n", "\n", "N", "=", "len", "(", "np", ".", "unique", "(", "[", "t", "[", "'track_id'", "]", "for", "track", "in", "tracks", "for", "t", "in", "track", "]", ")", ")", "\n", "colors", "=", "matplotlib", ".", "cm", ".", "get_cmap", "(", "'hsv'", ",", "lut", "=", "N", ")", "\n", "\n", "def", "overlay_callback", "(", "image", ",", "idx", ")", ":", "\n", "            ", "image", "=", "image", ".", "copy", "(", ")", "\n", "\n", "for", "track", "in", "tracks", "[", "idx", "]", ":", "\n", "                ", "c", "=", "colors", "(", "track", "[", "'track_id'", "]", ")", "\n", "c", "=", "(", "int", "(", "c", "[", "0", "]", "*", "255.0", ")", ",", "int", "(", "c", "[", "1", "]", "*", "255.0", ")", ",", "int", "(", "c", "[", "2", "]", "*", "255.0", ")", ")", "\n", "\n", "small", "=", "int", "(", "5e-3", "*", "np", ".", "max", "(", "image", ".", "shape", ")", ")", "\n", "large", "=", "2", "*", "small", "\n", "\n", "bbox", "=", "track", "[", "'tlbr'", "]", "\n", "cv2", ".", "rectangle", "(", "image", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "(", "255", ",", "255", ",", "255", ")", ",", "large", ")", "\n", "cv2", ".", "rectangle", "(", "image", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "c", ",", "small", ")", "\n", "\n", "label", "=", "str", "(", "track", "[", "'track_id'", "]", ")", "\n", "textsize", "=", "cv2", ".", "getTextSize", "(", "label", ",", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "int", "(", "5.0e-3", "*", "image", ".", "shape", "[", "0", "]", ")", ",", "4", ")", "[", "0", "]", "\n", "x", "=", "int", "(", "(", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ")", "/", "2", "-", "textsize", "[", "0", "]", "/", "2", ")", "\n", "y", "=", "int", "(", "(", "bbox", "[", "3", "]", "+", "bbox", "[", "1", "]", ")", "/", "2", "+", "textsize", "[", "1", "]", "/", "2", ")", "\n", "cv2", ".", "putText", "(", "image", ",", "label", ",", "(", "x", ",", "y", ")", ",", "0", ",", "5.0e-3", "*", "image", ".", "shape", "[", "0", "]", ",", "(", "255", ",", "255", ",", "255", ")", ",", "thickness", "=", "large", ")", "\n", "cv2", ".", "putText", "(", "image", ",", "label", ",", "(", "x", ",", "y", ")", ",", "0", ",", "5.0e-3", "*", "image", ".", "shape", "[", "0", "]", ",", "c", ",", "thickness", "=", "small", ")", "\n", "\n", "", "return", "image", "\n", "\n", "", "_", ",", "fname", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "fname", ",", "overlay_callback", ",", "downsample", "=", "1", ")", "\n", "\n", "key", "[", "'output_video'", "]", "=", "fname", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "# remove the downloaded video to avoid clutter", "\n", "os", ".", "remove", "(", "video", ")", "\n", "os", ".", "remove", "(", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.make": [[392, 425], ["pipeline.PersonBbox.make.extract_person_track"], "methods", ["None"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "tracks", "=", "(", "TrackingBbox", "&", "key", ")", ".", "fetch1", "(", "'tracks'", ")", "\n", "keep_tracks", "=", "(", "PersonBboxValid", "&", "key", ")", ".", "fetch1", "(", "'keep_tracks'", ")", "\n", "\n", "def", "extract_person_track", "(", "tracks", ")", ":", "\n", "\n", "            ", "def", "process_timestamp", "(", "track_timestep", ")", ":", "\n", "                ", "valid", "=", "[", "t", "for", "t", "in", "track_timestep", "if", "t", "[", "'track_id'", "]", "in", "keep_tracks", "]", "\n", "if", "len", "(", "valid", ")", "==", "1", ":", "\n", "                    ", "return", "{", "'present'", ":", "True", ",", "'bbox'", ":", "valid", "[", "0", "]", "[", "'tlhw'", "]", "}", "\n", "", "else", ":", "\n", "                    ", "return", "{", "'present'", ":", "False", ",", "'bbox'", ":", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "}", "\n", "\n", "", "", "return", "[", "process_timestamp", "(", "t", ")", "for", "t", "in", "tracks", "]", "\n", "\n", "", "LD", "=", "main_track", "=", "extract_person_track", "(", "tracks", ")", "\n", "dict_lists", "=", "{", "k", ":", "[", "dic", "[", "k", "]", "for", "dic", "in", "LD", "]", "for", "k", "in", "LD", "[", "0", "]", "}", "\n", "\n", "present", "=", "np", ".", "array", "(", "dict_lists", "[", "'present'", "]", ")", "\n", "bbox", "=", "np", ".", "array", "(", "dict_lists", "[", "'bbox'", "]", ")", "\n", "\n", "# smooth any brief missing frames", "\n", "df", "=", "pd", ".", "DataFrame", "(", "bbox", ")", "\n", "df", ".", "iloc", "[", "~", "present", "]", "=", "np", ".", "nan", "\n", "df", "=", "df", ".", "fillna", "(", "method", "=", "'bfill'", ",", "axis", "=", "0", ",", "limit", "=", "2", ")", "\n", "df", "=", "df", ".", "fillna", "(", "method", "=", "'ffill'", ",", "axis", "=", "0", ",", "limit", "=", "2", ")", "\n", "\n", "# get smoothed version", "\n", "key", "[", "'present'", "]", "=", "~", "df", ".", "isna", "(", ")", ".", "any", "(", "axis", "=", "1", ")", ".", "values", "\n", "key", "[", "'bbox'", "]", "=", "df", ".", "values", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.get_overlay_fn": [[426, 441], ["bboxes[].copy", "numpy.any", "cv2.rectangle", "numpy.isnan", "int", "int", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_overlay_fn", "(", "key", ")", ":", "\n", "\n", "        ", "bboxes", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ")", "\n", "\n", "def", "overlay_fn", "(", "image", ",", "idx", ",", "width", "=", "6", ",", "color", "=", "(", "255", ",", "255", ",", "255", ")", ")", ":", "\n", "            ", "bbox", "=", "bboxes", "[", "idx", "]", ".", "copy", "(", ")", "\n", "bbox", "[", "2", ":", "]", "=", "bbox", "[", ":", "2", "]", "+", "bbox", "[", "2", ":", "]", "\n", "if", "np", ".", "any", "(", "np", ".", "isnan", "(", "bbox", ")", ")", ":", "\n", "                ", "return", "image", "\n", "\n", "", "cv2", ".", "rectangle", "(", "image", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "color", ",", "width", ")", "\n", "return", "image", "\n", "\n", "", "return", "overlay_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.key_source": [[442, 445], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "key_source", "(", "self", ")", ":", "\n", "        ", "return", "PersonBboxValid", "&", "'video_subject_id >= 0'", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.DetectedFrames.make": [[461, 501], ["pipeline.DetectedFrames.make.extract_person_stats"], "methods", ["None"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "if", "(", "PersonBboxValid", "&", "key", ")", ".", "fetch1", "(", "'video_subject_id'", ")", "<", "0", ":", "\n", "            ", "key", "[", "'frames_detected'", "]", "=", "0", "\n", "key", "[", "'frames_missed'", "]", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'num_frames'", ")", "\n", "\n", "# compute statistics", "\n", "", "tracks", "=", "(", "TrackingBbox", "&", "key", ")", ".", "fetch1", "(", "'tracks'", ")", "\n", "keep_tracks", "=", "(", "PersonBboxValid", "&", "key", ")", ".", "fetch1", "(", "'keep_tracks'", ")", "\n", "\n", "def", "extract_person_stats", "(", "tracks", ")", ":", "\n", "\n", "            ", "def", "process_timestamp", "(", "track_timestep", ")", ":", "\n", "                ", "valid", "=", "[", "t", "for", "t", "in", "track_timestep", "if", "t", "[", "'track_id'", "]", "in", "keep_tracks", "]", "\n", "total_tracks", "=", "len", "(", "track_timestep", ")", "\n", "if", "len", "(", "valid", ")", "==", "1", ":", "\n", "                    ", "if", "'confidence'", "in", "valid", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "                        ", "return", "{", "'present'", ":", "True", ",", "'confidence'", ":", "valid", "[", "0", "]", "[", "'confidence'", "]", ",", "'others'", ":", "total_tracks", "-", "1", "}", "\n", "", "else", ":", "\n", "                        ", "return", "{", "'present'", ":", "True", ",", "'confidence'", ":", "1.0", ",", "'others'", ":", "total_tracks", "-", "1", "}", "\n", "", "", "else", ":", "\n", "                    ", "return", "{", "'present'", ":", "False", ",", "'confidence'", ":", "0", ",", "'others'", ":", "total_tracks", "}", "\n", "\n", "", "", "return", "[", "process_timestamp", "(", "t", ")", "for", "t", "in", "tracks", "]", "\n", "\n", "", "stats", "=", "extract_person_stats", "(", "tracks", ")", "\n", "present", "=", "np", ".", "array", "(", "[", "x", "[", "'present'", "]", "for", "x", "in", "stats", "]", ")", "\n", "\n", "key", "[", "'frames_detected'", "]", "=", "np", ".", "sum", "(", "present", ")", "\n", "key", "[", "'frames_missed'", "]", "=", "np", ".", "sum", "(", "~", "present", ")", "\n", "key", "[", "'fraction_found'", "]", "=", "key", "[", "'frames_detected'", "]", "/", "(", "key", "[", "'frames_missed'", "]", "+", "key", "[", "'frames_detected'", "]", ")", "\n", "\n", "if", "key", "[", "'frames_detected'", "]", ">", "0", ":", "\n", "            ", "key", "[", "'median_confidence'", "]", "=", "np", ".", "median", "(", "[", "x", "[", "'confidence'", "]", "for", "x", "in", "stats", "if", "x", "[", "'present'", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "key", "[", "'median_confidence'", "]", "=", "0.0", "\n", "", "key", "[", "'mean_other_people'", "]", "=", "np", ".", "nanmean", "(", "[", "x", "[", "'others'", "]", "for", "x", "in", "stats", "]", ")", "\n", "key", "[", "'frame_data'", "]", "=", "stats", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.DetectedFrames.key_source": [[502, 505], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "key_source", "(", "self", ")", ":", "\n", "        ", "return", "PersonBboxValid", "&", "'video_subject_id >= 0'", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.BestDetectedFrames.make": [[512, 519], ["numpy.argmax", "res.pop", "pipeline.BestDetectedFrames.insert1"], "methods", ["None"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "        ", "detected_frames", "=", "(", "DetectedFrames", "&", "key", ")", ".", "fetch", "(", "'fraction_found'", ",", "'KEY'", ",", "as_dict", "=", "True", ")", "\n", "\n", "best", "=", "np", ".", "argmax", "(", "[", "d", "[", "'fraction_found'", "]", "for", "d", "in", "detected_frames", "]", ")", "\n", "res", "=", "detected_frames", "[", "best", "]", "\n", "res", ".", "pop", "(", "'fraction_found'", ")", "\n", "self", ".", "insert1", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.BestDetectedFrames.key_source": [[520, 523], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "key_source", "(", "self", ")", ":", "\n", "        ", "return", "Video", "&", "DetectedFrames", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.OpenPosePerson.make": [[535, 560], ["list", "numpy.array", "numpy.array", "zip", "numpy.asarray", "pipeline.OpenPosePerson.insert1", "utils.keypoint_matching.match_keypoints_to_bbox", "zip", "range", "key[].append", "key[].append", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.match_keypoints_to_bbox"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "# fetch data", "\n", "        ", "keypoints", ",", "hand_keypoints", "=", "(", "OpenPose", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ",", "'hand_keypoints'", ")", "\n", "bbox", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ")", "\n", "\n", "res", "=", "[", "match_keypoints_to_bbox", "(", "bbox", "[", "idx", "]", ",", "keypoints", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "bbox", ".", "shape", "[", "0", "]", ")", "]", "\n", "keypoints", ",", "openpose_ids", "=", "list", "(", "zip", "(", "*", "res", ")", ")", "\n", "\n", "keypoints", "=", "np", ".", "array", "(", "keypoints", ")", "\n", "openpose_ids", "=", "np", ".", "array", "(", "openpose_ids", ")", "\n", "\n", "key", "[", "'keypoints'", "]", "=", "keypoints", "\n", "key", "[", "'openpose_ids'", "]", "=", "openpose_ids", "\n", "\n", "key", "[", "'hand_keypoints'", "]", "=", "[", "]", "\n", "\n", "for", "openpose_id", ",", "hand_keypoint", "in", "zip", "(", "openpose_ids", ",", "hand_keypoints", ")", ":", "\n", "            ", "if", "openpose_id", "is", "None", ":", "\n", "                ", "key", "[", "'hand_keypoints'", "]", ".", "append", "(", "np", ".", "zeros", "(", "(", "2", ",", "21", ",", "3", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "key", "[", "'hand_keypoints'", "]", ".", "append", "(", "[", "hand_keypoint", "[", "0", "]", "[", "openpose_id", "]", ",", "hand_keypoint", "[", "1", "]", "[", "openpose_id", "]", "]", ")", "\n", "", "", "key", "[", "'hand_keypoints'", "]", "=", "np", ".", "asarray", "(", "key", "[", "'hand_keypoints'", "]", ")", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.OpenPosePersonVideo.make": [[571, 598], ["tempfile.mkstemp", "tempfile.mkstemp", "video_overlay", "pipeline.OpenPosePersonVideo.insert1", "os.remove", "os.remove", "draw_keypoints", "draw_keypoints", "draw_keypoints"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", ",", "draw_keypoints", "\n", "\n", "# fetch data", "\n", "keypoints", ",", "hand_keypoints", "=", "(", "OpenPosePerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ",", "'hand_keypoints'", ")", "\n", "video_filename", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "\n", "_", ",", "fname", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "keypoints", "=", "(", "OpenPosePerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "def", "overlay", "(", "image", ",", "idx", ")", ":", "\n", "            ", "image", "=", "draw_keypoints", "(", "image", ",", "keypoints", "[", "idx", "]", ")", "\n", "image", "=", "draw_keypoints", "(", "image", ",", "hand_keypoints", "[", "idx", ",", "0", "]", ",", "threshold", "=", "0.02", ")", "\n", "image", "=", "draw_keypoints", "(", "image", ",", "hand_keypoints", "[", "idx", ",", "1", "]", ",", "threshold", "=", "0.02", ")", "\n", "return", "image", "\n", "\n", "", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "overlay", ",", "downsample", "=", "4", ")", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.TopDownPerson.make": [[628, 640], ["pipeline.TopDownPerson.insert1", "mmpose_top_down_person", "mmpose_whole_body", "Exception"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmpose.mmpose_top_down_person", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmpose.mmpose_whole_body"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "if", "(", "TopDownMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'top_down_method_name'", ")", "==", "'MMPose'", ":", "\n", "            ", "from", ".", "wrappers", ".", "mmpose", "import", "mmpose_top_down_person", "\n", "key", "[", "'keypoints'", "]", "=", "mmpose_top_down_person", "(", "key", ")", "\n", "", "elif", "(", "TopDownMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'top_down_method_name'", ")", "==", "'MMPoseWholebody'", ":", "\n", "            ", "from", ".", "wrappers", ".", "mmpose", "import", "mmpose_whole_body", "\n", "key", "[", "'keypoints'", "]", "=", "mmpose_whole_body", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Method not implemented\"", ")", "\n", "\n", "", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.TopDownPerson.joint_names": [[641, 646], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "joint_names", "(", ")", ":", "\n", "        ", "return", "[", "\"Nose\"", ",", "\"Left Eye\"", ",", "\"Right Eye\"", ",", "\"Left Ear\"", ",", "\"Right Ear\"", ",", "\"Left Shoulder\"", ",", "\"Right Shoulder\"", ",", "\n", "\"Left Elbow\"", ",", "\"Right Elbow\"", ",", "\"Left Wrist\"", ",", "\"Right Wrist\"", ",", "\"Left Hip\"", ",", "\"Right Hip\"", ",", "\"Left Knee\"", ",", "\n", "\"Right Knee\"", ",", "\"Left Ankle\"", ",", "\"Right Ankle\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.SkeletonAction.make": [[664, 670], ["mmaction_skeleton_action_person", "pipeline.SkeletonAction.insert1"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmaction.mmaction_skeleton_action_person"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "wrappers", ".", "mmaction", "import", "mmaction_skeleton_action_person", "\n", "key", "=", "mmaction_skeleton_action_person", "(", "key", ",", "stride", "=", "1", ")", "\n", "key", "[", "'method'", "]", "=", "'mmaction_skeleton'", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.SkeletonActionVideo.make": [[680, 724], ["pipeline.PersonBbox.get_overlay_fn", "tempfile.mkstemp", "video_overlay", "pipeline.SkeletonActionVideo.insert1", "os.remove", "os.remove", "draw_keypoints", "pipeline.PersonBbox.get_overlay_fn", "numpy.any", "enumerate", "numpy.isnan", "min", "cv2.putText", "cv2.getTextSize", "int", "int", "len", "action.capitalize"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.get_overlay_fn", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints", "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.get_overlay_fn"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "        ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", ",", "draw_keypoints", "\n", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "bbox_fn", "=", "PersonBbox", ".", "get_overlay_fn", "(", "key", ")", "\n", "bbox", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ")", "\n", "\n", "top5_actions", ",", "stride", "=", "(", "SkeletonAction", "&", "key", ")", ".", "fetch1", "(", "'top5'", ",", "'stride'", ")", "\n", "\n", "def", "overlay_fn", "(", "image", ",", "idx", ")", ":", "\n", "            ", "image", "=", "draw_keypoints", "(", "image", ",", "keypoints", "[", "idx", "]", ",", "radius", "=", "20", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ")", "\n", "image", "=", "bbox_fn", "(", "image", ",", "idx", ",", "width", "=", "14", ",", "color", "=", "(", "0", ",", "0", ",", "255", ")", ")", "\n", "\n", "if", "np", ".", "any", "(", "np", ".", "isnan", "(", "bbox", "[", "idx", "]", ")", ")", ":", "\n", "                ", "return", "image", "\n", "\n", "", "top5", "=", "top5_actions", "[", "min", "(", "len", "(", "top5_actions", ")", "-", "1", ",", "idx", "//", "stride", ")", "]", "\n", "\n", "top_left", "=", "bbox", "[", "idx", ",", ":", "2", "]", "\n", "for", "i", ",", "(", "action", ",", "score", ")", "in", "enumerate", "(", "top5", ")", ":", "\n", "                ", "if", "score", ">", "0.1", ":", "\n", "                    ", "label", "=", "f'{action.capitalize()}: {score:0.3}'", "\n", "\n", "fontsize", "=", "1.0e-3", "*", "image", ".", "shape", "[", "0", "]", "\n", "textsize", "=", "cv2", ".", "getTextSize", "(", "label", ",", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "fontsize", ",", "4", ")", "[", "0", "]", "\n", "\n", "coord", "=", "(", "int", "(", "top_left", "[", "0", "]", "+", "5", ")", ",", "int", "(", "top_left", "[", "1", "]", "+", "(", "10", "+", "textsize", "[", "1", "]", ")", "*", "(", "1", "+", "i", ")", ")", ")", "\n", "cv2", ".", "putText", "(", "image", ",", "label", ",", "coord", ",", "0", ",", "fontsize", ",", "(", "255", ",", "255", ",", "255", ")", ",", "thickness", "=", "4", ")", "\n", "\n", "", "", "return", "image", "\n", "\n", "", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "overlay_fn", ",", "downsample", "=", "1", ")", "\n", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n", "return", "out_file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.LiftingPerson.make": [[758, 777], ["key.update", "pipeline.LiftingPerson.insert1", "process_rie", "process_gastnet", "process_videopose3d", "process_poseaug", "Exception"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.rie_lifting.process_rie", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.gastnet_lifting.process_gastnet", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.videopose3d.process_videopose3d", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.poseaug.process_poseaug"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "if", "(", "LiftingMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'lifting_method_name'", ")", "==", "'RIE'", ":", "\n", "            ", "from", ".", "wrappers", ".", "rie_lifting", "import", "process_rie", "\n", "results", "=", "process_rie", "(", "key", ")", "\n", "", "elif", "(", "LiftingMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'lifting_method_name'", ")", "==", "'GastNet'", ":", "\n", "            ", "from", ".", "wrappers", ".", "gastnet_lifting", "import", "process_gastnet", "\n", "results", "=", "process_gastnet", "(", "key", ")", "\n", "", "elif", "(", "LiftingMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'lifting_method_name'", ")", "==", "'VideoPose3D'", ":", "\n", "            ", "from", ".", "wrappers", ".", "videopose3d", "import", "process_videopose3d", "\n", "results", "=", "process_videopose3d", "(", "key", ")", "\n", "", "elif", "(", "LiftingMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'lifting_method_name'", ")", "==", "'PoseAug'", ":", "\n", "            ", "from", ".", "wrappers", ".", "poseaug", "import", "process_poseaug", "\n", "results", "=", "process_poseaug", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"Method not implemented {key}\"", ")", "\n", "\n", "", "key", ".", "update", "(", "results", ")", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.LiftingPerson.joint_names": [[778, 782], ["None"], "methods", ["None"], ["", "def", "joint_names", "(", ")", ":", "\n", "        ", "\"\"\" Lifting layers use Human3.6 ordering \"\"\"", "\n", "return", "[", "'Hip (root)'", ",", "'Right hip'", ",", "'Right knee'", ",", "'Right foot'", ",", "'Left hip'", ",", "'Left knee'", ",", "'Left foot'", ",", "'Spine'", ",", "'Thorax'", ",", "\n", "'Nose'", ",", "'Head'", ",", "'Left shoulder'", ",", "'Left elbow'", ",", "'Left wrist'", ",", "'Right shoulder'", ",", "'Right elbow'", ",", "'Right wrist'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.LiftingPersonVideo.make": [[793, 836], ["tempfile.mkstemp", "pipeline.LiftingPersonVideo.insert1", "os.remove", "os.remove", "env.add_path", "Skeleton", "adj_mx_from_skeleton", "numpy.array", "h36m_coco_format", "revise_kpts", "re_kpts.transpose.transpose.transpose", "numpy.amin", "render_animation", "numpy.array"], "methods", ["None"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "keypoints_3d", "=", "(", "LiftingPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints_3d'", ")", ".", "copy", "(", ")", "\n", "blurred_video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "width", ",", "height", ",", "fps", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'width'", ",", "'height'", ",", "'fps'", ")", "\n", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"GAST_PATH\"", "]", ")", ":", "\n", "\n", "            ", "from", "common", ".", "graph_utils", "import", "adj_mx_from_skeleton", "\n", "from", "common", ".", "skeleton", "import", "Skeleton", "\n", "from", "tools", ".", "inference", "import", "gen_pose", "\n", "from", "tools", ".", "preprocess", "import", "h36m_coco_format", ",", "revise_kpts", "\n", "\n", "from", "tools", ".", "vis_h36m", "import", "render_animation", "\n", "\n", "skeleton", "=", "Skeleton", "(", "parents", "=", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "0", ",", "4", ",", "5", ",", "0", ",", "7", ",", "8", ",", "9", ",", "8", ",", "11", ",", "12", ",", "8", ",", "14", ",", "15", "]", ",", "\n", "joints_left", "=", "[", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "22", ",", "23", "]", ",", "\n", "joints_right", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "24", ",", "25", ",", "26", ",", "27", ",", "28", ",", "29", ",", "30", ",", "31", "]", ")", "\n", "adj", "=", "adj_mx_from_skeleton", "(", "skeleton", ")", "\n", "\n", "joints_left", ",", "joints_right", "=", "[", "4", ",", "5", ",", "6", ",", "11", ",", "12", ",", "13", "]", ",", "[", "1", ",", "2", ",", "3", ",", "14", ",", "15", ",", "16", "]", "\n", "kps_left", ",", "kps_right", "=", "[", "4", ",", "5", ",", "6", ",", "11", ",", "12", ",", "13", "]", ",", "[", "1", ",", "2", ",", "3", ",", "14", ",", "15", ",", "16", "]", "\n", "rot", "=", "np", ".", "array", "(", "[", "0.14070565", ",", "-", "0.15007018", ",", "-", "0.7552408", ",", "0.62232804", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "keypoints_metadata", "=", "{", "'keypoints_symmetry'", ":", "(", "joints_left", ",", "joints_right", ")", ",", "'layout_name'", ":", "'Human3.6M'", ",", "'num_joints'", ":", "17", "}", "\n", "\n", "keypoints_reformat", ",", "keypoints_score", "=", "keypoints", "[", "None", ",", "...", ",", ":", "2", "]", ",", "keypoints", "[", "None", ",", "...", ",", "2", "]", "\n", "keypoints", ",", "scores", ",", "valid_frames", "=", "h36m_coco_format", "(", "keypoints_reformat", ",", "keypoints_score", ")", "\n", "re_kpts", "=", "revise_kpts", "(", "keypoints", ",", "scores", ",", "valid_frames", ")", "\n", "re_kpts", "=", "re_kpts", ".", "transpose", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "keypoints_3d", "[", ":", ",", ":", ",", "2", "]", "-=", "np", ".", "amin", "(", "keypoints_3d", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "anim_output", "=", "{", "'Reconstruction 1'", ":", "keypoints_3d", "}", "\n", "\n", "render_animation", "(", "re_kpts", ",", "keypoints_metadata", ",", "anim_output", ",", "skeleton", ",", "fps", ",", "30000", ",", "np", ".", "array", "(", "70.", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "out_file_name", ",", "input_video_path", "=", "blurred_video", ",", "viewport", "=", "(", "width", ",", "height", ")", ",", "com_reconstrcution", "=", "False", ")", "\n", "\n", "", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "blurred_video", ")", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.SMPLPerson.make": [[878, 929], ["pipeline.SMPLPerson.insert1", "process_vibe", "process_pixie.keys", "process_pixie.pop", "process_meva", "process_prohmr", "process_prohmr_mmpose", "process_expose", "process_pare", "process_pixie", "Exception"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.vibe.process_vibe", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.meva.process_meva", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.process_prohmr", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.process_prohmr_mmpose", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.process_expose", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pare.process_pare", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.process_pixie"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "smpl_method_name", "=", "(", "SMPLMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'smpl_method_name'", ")", "\n", "if", "smpl_method_name", "==", "'VIBE'", ":", "\n", "\n", "            ", "from", ".", "wrappers", ".", "vibe", "import", "process_vibe", "\n", "res", "=", "process_vibe", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL'", "\n", "\n", "", "elif", "smpl_method_name", "==", "'MEVA'", ":", "\n", "\n", "            ", "from", ".", "wrappers", ".", "meva", "import", "process_meva", "\n", "res", "=", "process_meva", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL'", "\n", "\n", "", "elif", "smpl_method_name", "==", "'ProHMR'", ":", "\n", "\n", "            ", "from", ".", "wrappers", ".", "prohmr", "import", "process_prohmr", "\n", "res", "=", "process_prohmr", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL'", "\n", "\n", "", "elif", "smpl_method_name", "==", "'ProHMR_MMPose'", ":", "\n", "            ", "from", ".", "wrappers", ".", "prohmr", "import", "process_prohmr_mmpose", "\n", "res", "=", "process_prohmr_mmpose", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL'", "\n", "\n", "", "elif", "smpl_method_name", "==", "'Expose'", ":", "\n", "\n", "            ", "from", ".", "wrappers", ".", "expose", "import", "process_expose", "\n", "res", "=", "process_expose", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL-X'", "\n", "\n", "", "elif", "smpl_method_name", "==", "'PARE'", ":", "\n", "\n", "            ", "from", ".", "wrappers", ".", "pare", "import", "process_pare", "\n", "res", "=", "process_pare", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL'", "\n", "\n", "", "elif", "smpl_method_name", "==", "'PIXIE'", ":", "\n", "\n", "            ", "from", ".", "wrappers", ".", "pixie", "import", "process_pixie", "\n", "res", "=", "process_pixie", "(", "key", ")", "\n", "res", "[", "'model_type'", "]", "=", "'SMPL-X'", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"Method {smpl_method_name} not implemented\"", ")", "\n", "\n", "", "if", "'verts'", "in", "res", ".", "keys", "(", ")", ":", "\n", "            ", "res", ".", "pop", "(", "'verts'", ")", "\n", "\n", "", "self", ".", "insert1", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.SMPLPerson.joint_names": [[930, 944], ["model.upper", "model.upper", "model.upper", "env.add_path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "joint_names", "(", "model", "=", "'smpl'", ")", ":", "\n", "        ", "if", "model", ".", "upper", "(", ")", "==", "'SMPL'", ":", "\n", "            ", "from", ".", "utils", ".", "smpl", "import", "JOINT_NAMES_49", "\n", "return", "JOINT_NAMES_49", "\n", "", "elif", "model", ".", "upper", "(", ")", "in", "[", "'SMPLX'", ",", "'SMPL-X'", "]", ":", "\n", "            ", "from", "smplx", ".", "joint_names", "import", "JOINT_NAMES", "\n", "return", "JOINT_NAMES", "\n", "", "elif", "model", ".", "upper", "(", ")", "==", "'PIXIE'", ":", "\n", "# frustratingly, Pixie does not use the default keypoint ordering", "\n", "# TODO: can likely remove the cfg.model.extra_joint_path setting and get defaults", "\n", "            ", "with", "add_path", "(", "os", ".", "environ", "[", "'PIXIE_PATH'", "]", ")", ":", "\n", "                ", "from", "pixielib", ".", "models", ".", "SMPLX", "import", "SMPLX_names", "as", "pixie_joint_names", "\n", "", "return", "pixie_joint_names", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.SMPLPerson.smpl_joint_names": [[946, 962], ["Exception"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "smpl_joint_names", "(", "model", "=", "'smpl'", ")", ":", "\n", "        ", "from", "smplx", ".", "joint_names", "import", "JOINT_NAMES", "\n", "\n", "if", "model", "==", "'smpl'", ":", "\n", "            ", "return", "JOINT_NAMES", "[", ":", "19", "]", "\n", "", "elif", "model", "==", "'smplx'", ":", "\n", "# in smplx models the pelvis orientation is in a different field (global orientation)", "\n", "# as are the wrists", "\n", "            ", "return", "JOINT_NAMES", "[", "1", ":", "21", "]", "\n", "", "elif", "model", "==", "'PIXIE'", ":", "\n", "# in addition to the dropped fields for smplx, Pixie also splits out the head and neck", "\n", "# into additional fields", "\n", "            ", "return", "[", "j", "for", "j", "in", "JOINT_NAMES", "[", ":", "20", "]", "if", "j", "not", "in", "[", "'pelvis'", ",", "'head'", ",", "'neck'", "]", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown model type'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.SMPLPersonVideo.make": [[974, 1004], ["tempfile.mkstemp", "video_overlay", "pipeline.SMPLPersonVideo.insert1", "os.close", "os.remove", "get_prohmr_smpl_callback", "get_expose_callback", "get_pixie_callback", "get_smpl_callback"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.get_prohmr_smpl_callback", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.get_expose_callback", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.get_pixie_callback", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.get_smpl_callback"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", "\n", "\n", "poses", ",", "betas", ",", "cams", "=", "(", "SMPLPerson", "&", "key", ")", ".", "fetch1", "(", "'poses'", ",", "'betas'", ",", "'cams'", ")", "\n", "\n", "smpl_method_name", "=", "(", "SMPLMethodLookup", "&", "key", ")", ".", "fetch1", "(", "'smpl_method_name'", ")", "\n", "if", "smpl_method_name", "==", "'ProHMR'", "or", "smpl_method_name", "==", "'ProHMR_MMPose'", ":", "\n", "            ", "from", ".", "wrappers", ".", "prohmr", "import", "get_prohmr_smpl_callback", "\n", "callback", "=", "get_prohmr_smpl_callback", "(", "key", ",", "poses", ",", "betas", ",", "cams", ")", "\n", "", "elif", "smpl_method_name", "==", "'Expose'", ":", "\n", "            ", "from", ".", "wrappers", ".", "expose", "import", "get_expose_callback", "\n", "callback", "=", "get_expose_callback", "(", "key", ")", "\n", "", "elif", "smpl_method_name", "==", "'PIXIE'", ":", "\n", "            ", "from", ".", "wrappers", ".", "pixie", "import", "get_pixie_callback", "\n", "callback", "=", "get_pixie_callback", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "get_smpl_callback", "\n", "callback", "=", "get_smpl_callback", "(", "key", ",", "poses", ",", "betas", ",", "cams", ")", "\n", "\n", "", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "\n", "fd", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "callback", ",", "downsample", "=", "1", ")", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "close", "(", "fd", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.CenterHMR.make": [[1015, 1033], ["pipeline.CenterHMR.insert1", "os.remove", "env.add_path", "pipeline.Video.get_robust_reader", "centerhmr_parse_video", "os.path.join", "os.path.join", "r.items"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.centerhmr.centerhmr_parse_video"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "with", "add_path", "(", "[", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'CENTERHMR_PATH'", "]", ",", "'src'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'CENTERHMR_PATH'", "]", ",", "'src/core'", ")", "]", ")", ":", "\n", "            ", "from", "pose_pipeline", ".", "wrappers", ".", "centerhmr", "import", "centerhmr_parse_video", "\n", "\n", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "return_cap", "=", "False", ")", "\n", "res", "=", "centerhmr_parse_video", "(", "video", ",", "os", ".", "environ", "[", "'CENTERHMR_PATH'", "]", ")", "\n", "\n", "# don't store verticies or images", "\n", "", "keys_to_keep", "=", "[", "'params'", ",", "'pj2d'", ",", "'j3d'", ",", "'j3d_smpl24'", ",", "'j3d_spin24'", ",", "'j3d_op25'", "]", "\n", "res", "=", "[", "{", "k", ":", "v", "for", "k", ",", "v", "in", "r", ".", "items", "(", ")", "if", "k", "in", "keys_to_keep", "}", "for", "r", "in", "res", "]", "\n", "key", "[", "'results'", "]", "=", "res", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "# not saving the video in database, just to reduce space requirements", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.CenterHMRPerson.make": [[1050, 1090], ["list", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "pipeline.CenterHMRPerson.insert1", "list", "utils.keypoint_matching.match_keypoints_to_bbox", "zip", "numpy.array", "numpy.max", "numpy.zeros", "pipeline.CenterHMRPerson.make.convert_keypoints_to_image"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.match_keypoints_to_bbox"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "width", ",", "height", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'width'", ",", "'height'", ")", "\n", "\n", "def", "convert_keypoints_to_image", "(", "keypoints", ",", "imsize", "=", "[", "width", ",", "height", "]", ")", ":", "\n", "            ", "mp", "=", "np", ".", "array", "(", "imsize", ")", "*", "0.5", "\n", "scale", "=", "np", ".", "max", "(", "np", ".", "array", "(", "imsize", ")", ")", "*", "0.5", "\n", "\n", "keypoints_image", "=", "keypoints", "*", "scale", "+", "mp", "\n", "return", "list", "(", "keypoints_image", ")", "\n", "\n", "# fetch data", "\n", "", "hmr_results", "=", "(", "CenterHMR", "&", "key", ")", ".", "fetch1", "(", "'results'", ")", "\n", "bbox", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ")", "\n", "\n", "# get the 2D keypoints. note these are scaled from (-0.5, 0.5) assuming a", "\n", "# square image (hence convert_keypoints_to_image)", "\n", "pj2d", "=", "[", "r", "[", "'pj2d'", "]", "if", "'pj2d'", "in", "r", ".", "keys", "(", ")", "else", "np", ".", "zeros", "(", "(", "0", ",", "25", ",", "2", ")", ")", "for", "r", "in", "hmr_results", "]", "\n", "all_matches", "=", "[", "match_keypoints_to_bbox", "(", "bbox", "[", "idx", "]", ",", "convert_keypoints_to_image", "(", "pj2d", "[", "idx", "]", ")", ",", "visible", "=", "False", ")", "\n", "for", "idx", "in", "range", "(", "bbox", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "keypoints", ",", "centerhmr_ids", "=", "list", "(", "zip", "(", "*", "all_matches", ")", ")", "\n", "\n", "key", "[", "'poses'", "]", "=", "np", ".", "asarray", "(", "[", "res", "[", "'params'", "]", "[", "'body_pose'", "]", "[", "id", "]", "\n", "if", "id", "is", "not", "None", "else", "np", ".", "array", "(", "[", "np", ".", "nan", "]", "*", "69", ")", "*", "np", ".", "nan", "\n", "for", "res", ",", "id", "in", "zip", "(", "hmr_results", ",", "centerhmr_ids", ")", "]", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "asarray", "(", "[", "res", "[", "'params'", "]", "[", "'betas'", "]", "[", "id", "]", "\n", "if", "id", "is", "not", "None", "else", "np", ".", "array", "(", "[", "np", ".", "nan", "]", "*", "10", ")", "*", "np", ".", "nan", "\n", "for", "res", ",", "id", "in", "zip", "(", "hmr_results", ",", "centerhmr_ids", ")", "]", ")", "\n", "key", "[", "'cams'", "]", "=", "np", ".", "asarray", "(", "[", "res", "[", "'params'", "]", "[", "'cam'", "]", "[", "id", "]", "\n", "if", "id", "is", "not", "None", "else", "np", ".", "array", "(", "[", "np", ".", "nan", "]", "*", "3", ")", "*", "np", ".", "nan", "\n", "for", "res", ",", "id", "in", "zip", "(", "hmr_results", ",", "centerhmr_ids", ")", "]", ")", "\n", "key", "[", "'global_orients'", "]", "=", "np", ".", "asarray", "(", "[", "res", "[", "'params'", "]", "[", "'global_orient'", "]", "[", "id", "]", "\n", "if", "id", "is", "not", "None", "else", "np", ".", "array", "(", "[", "np", ".", "nan", "]", "*", "3", ")", "*", "np", ".", "nan", "\n", "for", "res", ",", "id", "in", "zip", "(", "hmr_results", ",", "centerhmr_ids", ")", "]", ")", "\n", "\n", "key", "[", "'keypoints'", "]", "=", "np", ".", "asarray", "(", "keypoints", ")", "\n", "key", "[", "'centerhmr_ids'", "]", "=", "np", ".", "asarray", "(", "centerhmr_ids", ")", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.CenterHMRPerson.joint_names": [[1091, 1095], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "joint_names", "(", ")", ":", "\n", "        ", "from", "smplx", ".", "joint_names", "import", "JOINT_NAMES", "\n", "return", "JOINT_NAMES", "[", ":", "23", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.CenterHMRPersonVideo.make": [[1106, 1154], ["tempfile.mkstemp", "SMPL", "tempfile.mkstemp", "video_overlay", "pipeline.CenterHMRPersonVideo.insert1", "os.remove", "os.remove", "numpy.concatenate", "numpy.any", "overlay.renderer", "numpy.isnan", "PyrendererRenderer", "SMPL.get_faces", "SMPL.", "numpy.concatenate.astype", "body_beta.astype"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_estimation", ".", "util", ".", "pyrender_renderer", "import", "PyrendererRenderer", "\n", "from", "pose_estimation", ".", "body_models", ".", "smpl", "import", "SMPL", "\n", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", "\n", "\n", "# fetch data", "\n", "pose_data", "=", "(", "CenterHMRPerson", "&", "key", ")", ".", "fetch1", "(", ")", "\n", "video_filename", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "\n", "_", ",", "fname", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "\n", "smpl", "=", "SMPL", "(", ")", "\n", "\n", "def", "overlay", "(", "image", ",", "idx", ")", ":", "\n", "            ", "body_pose", "=", "np", ".", "concatenate", "(", "[", "pose_data", "[", "'global_orients'", "]", "[", "idx", "]", ",", "pose_data", "[", "'poses'", "]", "[", "idx", "]", "]", ")", "\n", "body_beta", "=", "pose_data", "[", "'betas'", "]", "[", "idx", "]", "\n", "\n", "if", "np", ".", "any", "(", "np", ".", "isnan", "(", "body_pose", ")", ")", ":", "\n", "                ", "return", "image", "\n", "\n", "", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "if", "overlay", ".", "renderer", "is", "None", ":", "\n", "                ", "overlay", ".", "renderer", "=", "PyrendererRenderer", "(", "smpl", ".", "get_faces", "(", ")", ",", "(", "h", ",", "w", ")", ")", "\n", "\n", "", "verts", "=", "smpl", "(", "body_pose", ".", "astype", "(", "np", ".", "float32", ")", "[", "None", ",", "...", "]", ",", "body_beta", ".", "astype", "(", "np", ".", "float32", ")", "[", "None", ",", "...", "]", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "cam", "=", "[", "pose_data", "[", "'cams'", "]", "[", "idx", "]", "[", "0", "]", ",", "*", "pose_data", "[", "'cams'", "]", "[", "idx", "]", "[", ":", "3", "]", "]", "\n", "if", "h", ">", "w", ":", "\n", "                ", "cam", "[", "0", "]", "=", "1.1", "**", "cam", "[", "0", "]", "*", "(", "h", "/", "w", ")", "\n", "cam", "[", "1", "]", "=", "(", "1.1", "**", "cam", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "cam", "[", "0", "]", "=", "1.1", "**", "cam", "[", "0", "]", "\n", "cam", "[", "1", "]", "=", "(", "1.1", "**", "cam", "[", "1", "]", ")", "*", "(", "w", "/", "h", ")", "\n", "\n", "", "return", "overlay", ".", "renderer", "(", "verts", ",", "cam", ",", "img", "=", "image", ")", "\n", "", "overlay", ".", "renderer", "=", "None", "\n", "\n", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "overlay", ",", "downsample", "=", "4", ")", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.HumorPerson.make": [[1173, 1180], ["process_humor", "pipeline.HumorPerson.insert1"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.process_humor"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "wrappers", ".", "humor", "import", "process_humor", "\n", "\n", "res", "=", "process_humor", "(", "key", ")", "\n", "\n", "self", ".", "insert1", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.HumorPersonVideo.make": [[1190, 1198], ["render_humor", "pipeline.HumorPersonVideo.insert1"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.render_humor"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "wrappers", ".", "humor", "import", "render_humor", "\n", "\n", "video", "=", "render_humor", "(", "key", ")", "\n", "key", "[", "'output_video'", "]", "=", "video", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.TopDownPersonVideo.make": [[1209, 1232], ["pipeline.PersonBbox.get_overlay_fn", "tempfile.mkstemp", "video_overlay", "pipeline.TopDownPersonVideo.insert1", "os.remove", "os.remove", "draw_keypoints", "pipeline.PersonBbox.get_overlay_fn"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.get_overlay_fn", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints", "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.get_overlay_fn"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", ",", "draw_keypoints", "\n", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "bbox_fn", "=", "PersonBbox", ".", "get_overlay_fn", "(", "key", ")", "\n", "\n", "def", "overlay_fn", "(", "image", ",", "idx", ")", ":", "\n", "            ", "image", "=", "draw_keypoints", "(", "image", ",", "keypoints", "[", "idx", "]", ")", "\n", "image", "=", "bbox_fn", "(", "image", ",", "idx", ")", "\n", "return", "image", "\n", "\n", "", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "overlay_fn", ",", "downsample", "=", "1", ")", "\n", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.TopDownPersonVideo.joint_names": [[1233, 1237], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "joint_names", "(", ")", ":", "\n", "        ", "\"\"\" PoseFormer follows the output format of Video3D and uses Human3.6 ordering \"\"\"", "\n", "return", "[", "'Hip (root)'", ",", "'Right hip'", ",", "'Right knee'", ",", "'Right foot'", ",", "'Left hip'", ",", "'Left knee'", ",", "'Left foot'", ",", "'Spine'", ",", "'Thorax'", ",", "'Nose'", ",", "'Head'", ",", "'Left shoulder'", ",", "'Left elbow'", ",", "'Left wrist'", ",", "'Right shoulder'", ",", "'Right elbow'", ",", "'Right wrist'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.env.add_path.__init__": [[6, 11], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "path", ",", "list", ")", ":", "\n", "            ", "self", ".", "path", "=", "[", "path", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "path", "=", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.env.add_path.__enter__": [[12, 15], ["sys.path.insert"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "path", ":", "\n", "            ", "sys", ".", "path", ".", "insert", "(", "0", ",", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.env.add_path.__exit__": [[16, 22], ["sys.path.remove"], "methods", ["None"], ["", "", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "for", "p", "in", "self", ".", "path", ":", "\n", "                ", "sys", ".", "path", ".", "remove", "(", "p", ")", "\n", "", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.env.set_environmental_variables": [[23, 50], ["platform.version"], "function", ["None"], ["", "", "", "def", "set_environmental_variables", "(", ")", ":", "\n", "# TODO: should create a cfg file or use a path relative to module for this instead", "\n", "# of hardcoding for my local setup", "\n", "    ", "os", ".", "environ", "[", "'OPENPOSE_PATH'", "]", "=", "'/home/jcotton/projects/pose/openpose'", "\n", "os", ".", "environ", "[", "'OPENPOSE_PYTHON_PATH'", "]", "=", "'/home/jcotton/projects/pose/openpose/build/python'", "\n", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", "=", "'/home/jcotton/projects/pose/expose'", "\n", "os", ".", "environ", "[", "'CENTERHMR_PATH'", "]", "=", "'/home/jcotton/projects/pose/CenterHMR'", "\n", "os", ".", "environ", "[", "\"GAST_PATH\"", "]", "=", "'/home/jcotton/projects/pose/GAST-Net-3DPoseEstimation'", "\n", "os", ".", "environ", "[", "\"POSEFORMER_PATH\"", "]", "=", "'/home/jcotton/projects/pose/PoseFormer'", "\n", "os", ".", "environ", "[", "\"VIBE_PATH\"", "]", "=", "'/home/jcotton/projects/pose/VIBE'", "\n", "os", ".", "environ", "[", "\"MEVA_PATH\"", "]", "=", "'/home/jcotton/projects/pose/MEVA'", "\n", "os", ".", "environ", "[", "\"PARE_PATH\"", "]", "=", "'/home/jcotton/projects/pose/PARE'", "\n", "os", ".", "environ", "[", "\"PIXIE_PATH\"", "]", "=", "'/home/jcotton/projects/pose/PIXIE'", "\n", "os", ".", "environ", "[", "\"HUMOR_PATH\"", "]", "=", "'/home/jcotton/projects/pose/humor/humor'", "\n", "os", ".", "environ", "[", "\"FAIRMOT_PATH\"", "]", "=", "'/home/jcotton/projects/pose/FairMOT/src/lib'", "\n", "os", ".", "environ", "[", "\"DCNv2_PATH\"", "]", "=", "'/home/jcotton/projects/pose/DCNv2/DCN'", "\n", "os", ".", "environ", "[", "\"TRANSTRACK_PATH\"", "]", "=", "'/home/jcotton/projects/pose/TransTrack'", "\n", "os", ".", "environ", "[", "\"PROHMR_PATH\"", "]", "=", "'/home/jcotton/projects/pose/ProHMR'", "\n", "os", ".", "environ", "[", "\"TRADES_PATH\"", "]", "=", "'/home/jcotton/projects/pose/TraDeS/src/lib'", "\n", "os", ".", "environ", "[", "\"RIE_PATH\"", "]", "=", "'/home/jcotton/projects/pose/Pose3D-RIE'", "\n", "os", ".", "environ", "[", "\"VIDEOPOSE3D_PATH\"", "]", "=", "'/home/jcotton/projects/pose/VideoPose3D'", "\n", "os", ".", "environ", "[", "\"POSEAUG_PATH\"", "]", "=", "'/home/jcotton/projects/pose/PoseAug'", "\n", "\n", "import", "platform", "\n", "if", "'Ubuntu'", "in", "platform", ".", "version", "(", ")", ":", "\n", "# In Ubuntu, using osmesa mode for rendering", "\n", "        ", "os", ".", "environ", "[", "'PYOPENGL_PLATFORM'", "]", "=", "'egl'", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.transform_preds": [[20, 25], ["None"], "function", ["None"], ["def", "transform_preds", "(", "coords", ",", "bbox", ",", "hm_size", ")", ":", "\n", "    ", "\"\"\" Transform predictions that are (0, 1) on the heatmap coordinates \n        from a bounding box into src image coordinates \"\"\"", "\n", "\n", "return", "bbox", "[", ":", "2", "]", "+", "coords", "/", "hm_size", "*", "bbox", "[", "2", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.get_max_preds": [[27, 56], ["isinstance", "batch_heatmaps.reshape", "numpy.argmax", "numpy.amax", "maxvals.reshape.reshape", "idx.reshape.reshape", "numpy.tile().astype", "numpy.floor", "numpy.tile", "pred_mask.astype.astype", "numpy.greater", "numpy.tile"], "function", ["None"], ["", "def", "get_max_preds", "(", "batch_heatmaps", ")", ":", "\n", "    ", "'''\n    get predictions from score maps\n    heatmaps: numpy.ndarray([batch_size, num_joints, height, width])\n    '''", "\n", "assert", "isinstance", "(", "batch_heatmaps", ",", "np", ".", "ndarray", ")", ",", "'batch_heatmaps should be numpy.ndarray'", "\n", "assert", "batch_heatmaps", ".", "ndim", "==", "4", ",", "'batch_images should be 4-ndim'", "\n", "\n", "batch_size", "=", "batch_heatmaps", ".", "shape", "[", "0", "]", "\n", "num_joints", "=", "batch_heatmaps", ".", "shape", "[", "1", "]", "\n", "width", "=", "batch_heatmaps", ".", "shape", "[", "3", "]", "\n", "heatmaps_reshaped", "=", "batch_heatmaps", ".", "reshape", "(", "(", "batch_size", ",", "num_joints", ",", "-", "1", ")", ")", "\n", "idx", "=", "np", ".", "argmax", "(", "heatmaps_reshaped", ",", "2", ")", "\n", "maxvals", "=", "np", ".", "amax", "(", "heatmaps_reshaped", ",", "2", ")", "\n", "\n", "maxvals", "=", "maxvals", ".", "reshape", "(", "(", "batch_size", ",", "num_joints", ",", "1", ")", ")", "\n", "idx", "=", "idx", ".", "reshape", "(", "(", "batch_size", ",", "num_joints", ",", "1", ")", ")", "\n", "\n", "preds", "=", "np", ".", "tile", "(", "idx", ",", "(", "1", ",", "1", ",", "2", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "preds", "[", ":", ",", ":", ",", "0", "]", "=", "(", "preds", "[", ":", ",", ":", ",", "0", "]", ")", "%", "width", "\n", "preds", "[", ":", ",", ":", ",", "1", "]", "=", "np", ".", "floor", "(", "(", "preds", "[", ":", ",", ":", ",", "1", "]", ")", "/", "width", ")", "\n", "\n", "pred_mask", "=", "np", ".", "tile", "(", "np", ".", "greater", "(", "maxvals", ",", "0.0", ")", ",", "(", "1", ",", "1", ",", "2", ")", ")", "\n", "pred_mask", "=", "pred_mask", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "preds", "*=", "pred_mask", "\n", "return", "preds", ",", "maxvals", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.taylor": [[58, 78], ["int", "int", "numpy.matrix", "numpy.matrix", "numpy.squeeze", "numpy.array"], "function", ["None"], ["", "def", "taylor", "(", "hm", ",", "coord", ")", ":", "\n", "    ", "heatmap_height", "=", "hm", ".", "shape", "[", "0", "]", "\n", "heatmap_width", "=", "hm", ".", "shape", "[", "1", "]", "\n", "px", "=", "int", "(", "coord", "[", "0", "]", ")", "\n", "py", "=", "int", "(", "coord", "[", "1", "]", ")", "\n", "if", "1", "<", "px", "<", "heatmap_width", "-", "2", "and", "1", "<", "py", "<", "heatmap_height", "-", "2", ":", "\n", "        ", "dx", "=", "0.5", "*", "(", "hm", "[", "py", "]", "[", "px", "+", "1", "]", "-", "hm", "[", "py", "]", "[", "px", "-", "1", "]", ")", "\n", "dy", "=", "0.5", "*", "(", "hm", "[", "py", "+", "1", "]", "[", "px", "]", "-", "hm", "[", "py", "-", "1", "]", "[", "px", "]", ")", "\n", "dxx", "=", "0.25", "*", "(", "hm", "[", "py", "]", "[", "px", "+", "2", "]", "-", "2", "*", "hm", "[", "py", "]", "[", "px", "]", "+", "hm", "[", "py", "]", "[", "px", "-", "2", "]", ")", "\n", "dxy", "=", "0.25", "*", "(", "hm", "[", "py", "+", "1", "]", "[", "px", "+", "1", "]", "-", "hm", "[", "py", "-", "1", "]", "[", "px", "+", "1", "]", "-", "hm", "[", "py", "+", "1", "]", "[", "px", "-", "1", "]", "+", "hm", "[", "py", "-", "1", "]", "[", "px", "-", "1", "]", ")", "\n", "dyy", "=", "0.25", "*", "(", "hm", "[", "py", "+", "2", "*", "1", "]", "[", "px", "]", "-", "2", "*", "hm", "[", "py", "]", "[", "px", "]", "+", "hm", "[", "py", "-", "2", "*", "1", "]", "[", "px", "]", ")", "\n", "derivative", "=", "np", ".", "matrix", "(", "[", "[", "dx", "]", ",", "[", "dy", "]", "]", ")", "\n", "hessian", "=", "np", ".", "matrix", "(", "[", "[", "dxx", ",", "dxy", "]", ",", "[", "dxy", ",", "dyy", "]", "]", ")", "\n", "if", "dxx", "*", "dyy", "-", "dxy", "**", "2", "!=", "0", ":", "\n", "            ", "hessianinv", "=", "hessian", ".", "I", "\n", "offset", "=", "-", "hessianinv", "*", "derivative", "\n", "offset", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "offset", ".", "T", ")", ",", "axis", "=", "0", ")", "\n", "coord", "+=", "offset", "\n", "", "", "return", "coord", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.gaussian_blur": [[80, 95], ["range", "range", "numpy.max", "numpy.zeros", "hm[].copy", "cv2.GaussianBlur", "dr[].copy", "numpy.max"], "function", ["None"], ["", "def", "gaussian_blur", "(", "hm", ",", "kernel", ")", ":", "\n", "    ", "border", "=", "(", "kernel", "-", "1", ")", "//", "2", "\n", "batch_size", "=", "hm", ".", "shape", "[", "0", "]", "\n", "num_joints", "=", "hm", ".", "shape", "[", "1", "]", "\n", "height", "=", "hm", ".", "shape", "[", "2", "]", "\n", "width", "=", "hm", ".", "shape", "[", "3", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "num_joints", ")", ":", "\n", "            ", "origin_max", "=", "np", ".", "max", "(", "hm", "[", "i", ",", "j", "]", ")", "\n", "dr", "=", "np", ".", "zeros", "(", "(", "height", "+", "2", "*", "border", ",", "width", "+", "2", "*", "border", ")", ")", "\n", "dr", "[", "border", ":", "-", "border", ",", "border", ":", "-", "border", "]", "=", "hm", "[", "i", ",", "j", "]", ".", "copy", "(", ")", "\n", "dr", "=", "cv2", ".", "GaussianBlur", "(", "dr", ",", "(", "kernel", ",", "kernel", ")", ",", "0", ")", "\n", "hm", "[", "i", ",", "j", "]", "=", "dr", "[", "border", ":", "-", "border", ",", "border", ":", "-", "border", "]", ".", "copy", "(", ")", "\n", "hm", "[", "i", ",", "j", "]", "*=", "origin_max", "/", "np", ".", "max", "(", "hm", "[", "i", ",", "j", "]", ")", "\n", "", "", "return", "hm", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.get_final_preds": [[97, 119], ["inference.get_max_preds", "inference.gaussian_blur", "numpy.maximum", "numpy.log", "range", "coords.copy", "range", "range", "inference.transform_preds", "inference.taylor"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.get_max_preds", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.gaussian_blur", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.transform_preds", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.inference.taylor"], ["", "def", "get_final_preds", "(", "config", ",", "hm", ",", "bbox", ")", ":", "\n", "    ", "coords", ",", "maxvals", "=", "get_max_preds", "(", "hm", ")", "\n", "heatmap_height", "=", "hm", ".", "shape", "[", "2", "]", "\n", "heatmap_width", "=", "hm", ".", "shape", "[", "3", "]", "\n", "\n", "# post-processing", "\n", "hm", "=", "gaussian_blur", "(", "hm", ",", "config", ".", "TEST", ".", "BLUR_KERNEL", ")", "\n", "hm", "=", "np", ".", "maximum", "(", "hm", ",", "1e-10", ")", "\n", "hm", "=", "np", ".", "log", "(", "hm", ")", "\n", "for", "n", "in", "range", "(", "coords", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "p", "in", "range", "(", "coords", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "coords", "[", "n", ",", "p", "]", "=", "taylor", "(", "hm", "[", "n", "]", "[", "p", "]", ",", "coords", "[", "n", "]", "[", "p", "]", ")", "\n", "\n", "", "", "preds", "=", "coords", ".", "copy", "(", ")", "\n", "\n", "# Transform back", "\n", "for", "i", "in", "range", "(", "coords", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "preds", "[", "i", "]", "=", "transform_preds", "(", "\n", "coords", "[", "i", "]", ",", "bbox", "[", "i", "]", ",", "[", "heatmap_width", ",", "heatmap_height", "]", "\n", ")", "\n", "\n", "", "return", "preds", ",", "maxvals", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.FaceBlur.__init__": [[13, 18], ["os.path.join", "os.path.join", "os.path.join", "cv2.dnn.readNetFromCaffe", "os.path.split"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "base_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "__file__", ")", "[", "0", "]", ",", "'./weights'", ")", "\n", "prototxt_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "'deploy.prototxt'", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "base_path", ",", "'res10_300x300_ssd_iter_140000_fp16.caffemodel'", ")", "\n", "self", ".", "model", "=", "cv2", ".", "dnn", ".", "readNetFromCaffe", "(", "prototxt_path", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.FaceBlur.detect_faces": [[19, 24], ["cv2.dnn.blobFromImage", "visualization.FaceBlur.model.setInput", "numpy.squeeze", "visualization.FaceBlur.model.forward"], "methods", ["None"], ["", "def", "detect_faces", "(", "self", ",", "image", ")", ":", "\n", "        ", "blob", "=", "cv2", ".", "dnn", ".", "blobFromImage", "(", "image", ",", "1.0", ",", "(", "300", ",", "300", ")", ",", "(", "104.0", ",", "177.0", ",", "123.0", ")", ")", "\n", "self", ".", "model", ".", "setInput", "(", "blob", ")", "\n", "output", "=", "np", ".", "squeeze", "(", "self", ".", "model", ".", "forward", "(", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.FaceBlur.blur_faces": [[25, 52], ["visualization.FaceBlur.detect_faces", "range", "box.astype", "cv2.GaussianBlur", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.FaceBlur.detect_faces"], ["", "def", "blur_faces", "(", "self", ",", "image", ")", ":", "\n", "        ", "faces", "=", "self", ".", "detect_faces", "(", "image", ")", "\n", "\n", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "kernel_width", "=", "(", "w", "//", "7", ")", "|", "1", "\n", "kernel_height", "=", "(", "h", "//", "7", ")", "|", "1", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "faces", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "confidence", "=", "faces", "[", "i", ",", "2", "]", "\n", "# get the confidence", "\n", "# if confidence is above 40%, then blur the bounding box (face)", "\n", "if", "confidence", ">", "0.1", ":", "\n", "# get the surrounding box cordinates and upscale them to original image", "\n", "                ", "box", "=", "faces", "[", "i", ",", "3", ":", "7", "]", "*", "np", ".", "array", "(", "[", "w", ",", "h", ",", "w", ",", "h", "]", ")", "\n", "# convert to integers", "\n", "start_x", ",", "start_y", ",", "end_x", ",", "end_y", "=", "box", ".", "astype", "(", "int", ")", "\n", "\n", "#print(start_x, start_y, end_x, end_y)", "\n", "# get the face image", "\n", "face", "=", "image", "[", "start_y", ":", "end_y", ",", "start_x", ":", "end_x", "]", "\n", "# apply gaussian blur to this face", "\n", "face", "=", "cv2", ".", "GaussianBlur", "(", "face", ",", "(", "kernel_width", ",", "kernel_height", ")", ",", "0", ")", "\n", "# put the blurred face into the original image", "\n", "image", "[", "start_y", ":", "end_y", ",", "start_x", ":", "end_x", "]", "=", "face", "\n", "\n", "", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.FaceBlur.__call__": [[53, 55], ["visualization.FaceBlur.blur_faces"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.FaceBlur.blur_faces"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "        ", "return", "self", ".", "blur_faces", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay": [[57, 109], ["cv2.VideoCapture", "int", "int", "int", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "tqdm.tqdm", "cv2.VideoWriter.release", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "int", "int", "visualization.FaceBlur", "range", "cv2.VideoCapture.read", "cv2.cvtColor", "callback", "cv2.cvtColor", "cv2.resize", "cv2.VideoWriter.write", "tempfile.mkstemp", "subprocess.run", "subprocess.run", "FaceBlur."], "function", ["None"], ["", "", "def", "video_overlay", "(", "video", ",", "output_name", ",", "callback", ",", "downsample", "=", "4", ",", "codec", "=", "'MP4V'", ",", "blur_faces", "=", "False", ",", "\n", "compress", "=", "True", ",", "bitrate", "=", "'5M'", ")", ":", "\n", "    ", "\"\"\" Process a video and create overlay image\n\n        Args:\n            video (str): filename for source\n            output_name (str): output filename\n            callback (fn(im, idx) -> im): method to overlay frame\n    \"\"\"", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "\n", "# get info", "\n", "total_frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "h", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "w", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "\n", "# configure output", "\n", "output_size", "=", "(", "int", "(", "w", "/", "downsample", ")", ",", "int", "(", "h", "/", "downsample", ")", ")", "\n", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "codec", ")", "\n", "out", "=", "cv2", ".", "VideoWriter", "(", "output_name", ",", "fourcc", ",", "fps", ",", "output_size", ")", "\n", "\n", "if", "blur_faces", ":", "\n", "        ", "blur", "=", "FaceBlur", "(", ")", "\n", "\n", "", "for", "idx", "in", "tqdm", "(", "range", "(", "total_frames", ")", ")", ":", "\n", "\n", "        ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "            ", "break", "\n", "\n", "# process image in RGB format", "\n", "", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "out_frame", "=", "callback", "(", "frame", ",", "idx", ")", "\n", "\n", "if", "blur_faces", ":", "\n", "            ", "out_frame", "=", "blur", "(", "out_frame", ")", "\n", "\n", "# move back to BGR format and write to movie", "\n", "", "out_frame", "=", "cv2", ".", "cvtColor", "(", "out_frame", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "out_frame", "=", "cv2", ".", "resize", "(", "out_frame", ",", "output_size", ")", "\n", "out", ".", "write", "(", "out_frame", ")", "\n", "\n", "", "out", ".", "release", "(", ")", "\n", "cap", ".", "release", "(", ")", "\n", "\n", "if", "compress", ":", "\n", "        ", "_", ",", "temp", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "subprocess", ".", "run", "(", "[", "'ffmpeg'", ",", "'-y'", ",", "'-i'", ",", "output_name", ",", "'-c:v'", ",", "'libx264'", ",", "'-b:v'", ",", "bitrate", ",", "temp", "]", ")", "\n", "subprocess", ".", "run", "(", "[", "'mv'", ",", "temp", ",", "output_name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints": [[111, 121], ["image.copy.copy", "range", "cv2.circle", "cv2.circle", "int", "int", "int", "int"], "function", ["None"], ["", "", "def", "draw_keypoints", "(", "image", ",", "keypoints", ",", "radius", "=", "10", ",", "threshold", "=", "0.2", ",", "color", "=", "(", "255", ",", "255", ",", "255", ")", ")", ":", "\n", "    ", "\"\"\" Draw the keypoints on an image\n    \"\"\"", "\n", "image", "=", "image", ".", "copy", "(", ")", "\n", "for", "i", "in", "range", "(", "keypoints", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "keypoints", "[", "i", ",", "-", "1", "]", ">", "threshold", ":", "\n", "            ", "cv2", ".", "circle", "(", "image", ",", "(", "int", "(", "keypoints", "[", "i", ",", "0", "]", ")", ",", "int", "(", "keypoints", "[", "i", ",", "1", "]", ")", ")", ",", "radius", ",", "(", "0", ",", "0", ",", "0", ")", ",", "-", "1", ")", "\n", "if", "radius", ">", "2", ":", "\n", "                ", "cv2", ".", "circle", "(", "image", ",", "(", "int", "(", "keypoints", "[", "i", ",", "0", "]", ")", ",", "int", "(", "keypoints", "[", "i", ",", "1", "]", ")", ")", ",", "radius", "-", "2", ",", "color", ",", "-", "1", ")", "\n", "", "", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.get_smpl_callback": [[123, 145], ["SMPL", "PyrendererRenderer", "[].numpy", "numpy.where", "SMPL.get_faces", "numpy.where", "len", "PyrendererRenderer.", "visualization.draw_keypoints", "SMPL."], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints"], ["", "def", "get_smpl_callback", "(", "key", ",", "poses", ",", "betas", ",", "cams", ")", ":", "\n", "    ", "from", "pose_estimation", ".", "body_models", ".", "smpl", "import", "SMPL", "\n", "from", "pose_estimation", ".", "util", ".", "pyrender_renderer", "import", "PyrendererRenderer", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "valid_idx", "=", "np", ".", "where", "(", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'present'", ")", ")", "[", "0", "]", "\n", "\n", "smpl", "=", "SMPL", "(", ")", "\n", "renderer", "=", "PyrendererRenderer", "(", "smpl", ".", "get_faces", "(", ")", ",", "img_size", "=", "(", "height", ",", "width", ")", ")", "\n", "verts", "=", "smpl", "(", "poses", ",", "betas", ")", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "joints2d", "=", "(", "SMPLPerson", "&", "key", ")", ".", "fetch1", "(", "'joints2d'", ")", "\n", "\n", "def", "overlay", "(", "frame", ",", "idx", ",", "renderer", "=", "renderer", ",", "verts", "=", "verts", ",", "cams", "=", "cams", ",", "joints2d", "=", "joints2d", ")", ":", "\n", "\n", "        ", "smpl_idx", "=", "np", ".", "where", "(", "valid_idx", "==", "idx", ")", "[", "0", "]", "\n", "if", "len", "(", "smpl_idx", ")", "==", "1", ":", "\n", "            ", "frame", "=", "renderer", "(", "verts", "[", "smpl_idx", "[", "0", "]", "]", ",", "cams", "[", "smpl_idx", "[", "0", "]", "]", ",", "frame", ")", "\n", "frame", "=", "draw_keypoints", "(", "frame", ",", "joints2d", "[", "smpl_idx", "[", "0", "]", "]", ",", "radius", "=", "4", ")", "\n", "", "return", "frame", "\n", "\n", "", "return", "overlay", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.fix_bb_aspect_ratio": [[7, 30], ["numpy.concatenate", "numpy.array", "numpy.array"], "function", ["None"], ["def", "fix_bb_aspect_ratio", "(", "bbox", ",", "dilate", "=", "1.2", ",", "ratio", "=", "1.0", ")", ":", "\n", "    ", "\"\"\" Inflates a bounding box with the desired aspect ratio \n    \n        Args:\n            bbox (4,) : bounding box in TLHW format\n            dilate (float): fraction amount to increase for crop\n            ratio (float): desired ratio (width / height)\n        \n        Returns:\n            bbox (4,) : corrected bounding box\n    \"\"\"", "\n", "\n", "center", "=", "bbox", "[", ":", "2", "]", "+", "bbox", "[", "2", ":", "]", "/", "2.0", "\n", "hw", "=", "bbox", "[", "2", ":", "]", "\n", "\n", "if", "hw", "[", "0", "]", "/", "hw", "[", "1", "]", "<", "ratio", ":", "\n", "# if bbox width/height is greater than desired ratio, increase height to match", "\n", "        ", "hw", "=", "np", ".", "array", "(", "[", "hw", "[", "1", "]", "*", "ratio", ",", "hw", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "        ", "hw", "=", "np", ".", "array", "(", "[", "hw", "[", "0", "]", ",", "hw", "[", "0", "]", "/", "ratio", "]", ")", "\n", "", "hw", "=", "hw", "*", "dilate", "\n", "\n", "return", "np", ".", "concatenate", "(", "[", "center", "-", "hw", "/", "2", ",", "hw", "]", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.crop_image_bbox": [[32, 54], ["bounding_box.fix_bb_aspect_ratio", "numpy.asarray", "numpy.array", "cv2.getAffineTransform", "cv2.warpAffine", "numpy.float32", "numpy.float32"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.fix_bb_aspect_ratio"], ["", "def", "crop_image_bbox", "(", "image", ",", "bbox", ",", "target_size", "=", "(", "288", ",", "384", ")", ",", "dilate", "=", "1.2", ")", ":", "\n", "    ", "\"\"\" Extract the image defined by bounding box with desired aspect ratio\n    \n        Args:\n            image (np.array): uses HWC format\n            bbox (4,): bounding box, will contain at least this area\n            target_size (optional): image size to produce\n            dilate: additional dilation on the bounding box\n            \n        Returns:\n            cropped image\n    \"\"\"", "\n", "\n", "bbox", "=", "fix_bb_aspect_ratio", "(", "bbox", ",", "ratio", "=", "target_size", "[", "0", "]", "/", "target_size", "[", "1", "]", ",", "dilate", "=", "dilate", ")", "\n", "\n", "# three points on corner of bounding box", "\n", "src", "=", "np", ".", "asarray", "(", "[", "[", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", "]", ",", "[", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ",", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", "]", ",", "[", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", "]", "]", ")", "\n", "dst", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "[", "target_size", "[", "0", "]", ",", "target_size", "[", "1", "]", "]", ",", "[", "0", ",", "target_size", "[", "1", "]", "]", "]", ")", "\n", "trans", "=", "cv2", ".", "getAffineTransform", "(", "np", ".", "float32", "(", "src", ")", ",", "np", ".", "float32", "(", "dst", ")", ")", "\n", "image", "=", "cv2", ".", "warpAffine", "(", "image", ",", "trans", ",", "target_size", ",", "flags", "=", "cv2", ".", "INTER_LINEAR", ")", "\n", "\n", "return", "image", ",", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_cam_to_orig_img": [[56, 80], ["numpy.stack"], "function", ["None"], ["", "def", "convert_crop_cam_to_orig_img", "(", "cam", ",", "bbox", ",", "img_width", ",", "img_height", ")", ":", "\n", "    ", "'''\n    Convert predicted camera from cropped image coordinates\n    to original image coordinates\n    :param cam (ndarray, shape=(3,)): weak perspective camera in cropped img coordinates\n    :param bbox (ndarray, shape=(4,)): bbox coordinates (TLHW)\n    :param img_width (int): original image width\n    :param img_height (int): original image height\n    :return:\n\n    Adopted from https://github.com/mkocabas/VIBE/blob/master/lib/utils/demo_utils.py\n    '''", "\n", "\n", "cy", "=", "bbox", "[", ":", ",", "1", "]", "+", "bbox", "[", ":", ",", "3", "]", "/", "2", "\n", "cx", "=", "bbox", "[", ":", ",", "0", "]", "+", "bbox", "[", ":", ",", "2", "]", "/", "2", "\n", "h", "=", "bbox", "[", ":", ",", "2", "]", "\n", "\n", "hw", ",", "hh", "=", "img_width", "/", "2.", ",", "img_height", "/", "2.", "\n", "sx", "=", "cam", "[", ":", ",", "0", "]", "*", "(", "1.", "/", "(", "img_width", "/", "h", ")", ")", "\n", "sy", "=", "cam", "[", ":", ",", "0", "]", "*", "(", "1.", "/", "(", "img_height", "/", "h", ")", ")", "\n", "tx", "=", "(", "(", "cx", "-", "hw", ")", "/", "hw", "/", "sx", ")", "+", "cam", "[", ":", ",", "1", "]", "\n", "ty", "=", "(", "(", "cy", "-", "hh", ")", "/", "hh", "/", "sy", ")", "+", "cam", "[", ":", ",", "2", "]", "\n", "orig_cam", "=", "np", ".", "stack", "(", "[", "sx", ",", "sy", ",", "tx", ",", "ty", "]", ")", ".", "T", "\n", "return", "orig_cam", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_coords_to_orig_img": [[82, 99], ["None"], "function", ["None"], ["", "def", "convert_crop_coords_to_orig_img", "(", "bbox", ",", "keypoints", ",", "crop_size", ")", ":", "\n", "# Adopted from https://github.com/mkocabas/VIBE/blob/master/lib/utils/demo_utils.py", "\n", "\n", "    ", "cy", "=", "bbox", "[", ":", ",", "1", "]", "+", "bbox", "[", ":", ",", "3", "]", "/", "2", "\n", "cx", "=", "bbox", "[", ":", ",", "0", "]", "+", "bbox", "[", ":", ",", "2", "]", "/", "2", "\n", "h", "=", "bbox", "[", ":", ",", "2", "]", "\n", "\n", "# unnormalize to crop coords", "\n", "keypoints", "=", "0.5", "*", "crop_size", "*", "(", "keypoints", "+", "1.0", ")", "\n", "\n", "# rescale to orig img crop", "\n", "keypoints", "*=", "h", "[", "...", ",", "None", ",", "None", "]", "/", "crop_size", "\n", "\n", "# transform into original image coords", "\n", "keypoints", "[", ":", ",", ":", ",", "0", "]", "=", "(", "cx", "-", "h", "/", "2", ")", "[", "...", ",", "None", "]", "+", "keypoints", "[", ":", ",", ":", ",", "0", "]", "\n", "keypoints", "[", ":", ",", ":", ",", "1", "]", "=", "(", "cy", "-", "h", "/", "2", ")", "[", "...", ",", "None", "]", "+", "keypoints", "[", ":", ",", ":", ",", "1", "]", "\n", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.get_person_dataloader": [[101, 188], ["cv2.VideoCapture", "transforms.Normalize", "transforms.Compose", "enumerate", "Inference", "DataLoader", "zip", "cv2.VideoCapture.read", "cv2.cvtColor", "bounding_box.crop_image_bbox", "transforms.Compose.", "frames.append", "bboxes.append", "frame_ids.append", "numpy.stack", "transforms.ToTensor", "print", "get_default_transform"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.crop_image_bbox"], ["", "def", "get_person_dataloader", "(", "key", ",", "batch_size", "=", "32", ",", "num_workers", "=", "16", ",", "crop_size", "=", "224", ",", "scale", "=", "1.0", ")", ":", "\n", "\n", "    ", "from", "torch", ".", "utils", ".", "data", "import", "Dataset", "\n", "from", "torch", ".", "utils", ".", "data", "import", "DataLoader", "\n", "import", "torchvision", ".", "transforms", "as", "transforms", "\n", "\n", "video", ",", "bboxes_dj", ",", "present_dj", "=", "(", "Video", "*", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'video'", ",", "'bbox'", ",", "'present'", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "\n", "frames", "=", "[", "]", "\n", "bboxes", "=", "[", "]", "\n", "frame_ids", "=", "[", "]", "\n", "for", "idx", ",", "(", "bbox", ",", "present", ")", "in", "enumerate", "(", "zip", "(", "bboxes_dj", ",", "present_dj", ")", ")", ":", "\n", "\n", "# handle the case where person is not tracked in frame", "\n", "        ", "if", "not", "present", ":", "\n", "            ", "print", "(", "'Skip missing frame'", ")", "\n", "continue", "\n", "\n", "# should match the length of identified person tracks", "\n", "", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "assert", "ret", "and", "frame", "is", "not", "None", "\n", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "norm_img", ",", "bbox", "=", "crop_image_bbox", "(", "img", ",", "bbox", ",", "target_size", "=", "(", "crop_size", ",", "crop_size", ")", ",", "dilate", "=", "scale", ")", "\n", "norm_img", "=", "transform", "(", "norm_img", ")", "\n", "\n", "#print(norm_img.shape)", "\n", "#break", "\n", "frames", ".", "append", "(", "norm_img", ")", "\n", "bboxes", ".", "append", "(", "bbox", ")", "\n", "frame_ids", ".", "append", "(", "idx", ")", "\n", "\n", "", "class", "Inference", "(", "Dataset", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "frames", ",", "bboxes", "=", "None", ",", "joints2d", "=", "None", ")", ":", "\n", "\n", "            ", "self", ".", "frames", "=", "frames", "\n", "self", ".", "bboxes", "=", "bboxes", "\n", "self", ".", "joints2d", "=", "joints2d", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "frames", "=", "frames", "\n", "self", ".", "has_keypoints", "=", "True", "if", "joints2d", "is", "not", "None", "else", "False", "\n", "\n", "def", "get_default_transform", "(", ")", ":", "\n", "\n", "                ", "return", "transform", "\n", "\n", "", "self", ".", "transform", "=", "get_default_transform", "(", ")", "\n", "self", ".", "norm_joints2d", "=", "np", ".", "zeros_like", "(", "self", ".", "joints2d", ")", "\n", "\n", "if", "self", ".", "has_keypoints", ":", "\n", "                ", "bboxes", ",", "time_pt1", ",", "time_pt2", "=", "get_all_bbox_params", "(", "joints2d", ",", "vis_thresh", "=", "0.3", ")", "\n", "bboxes", "[", ":", ",", "2", ":", "]", "=", "150.", "/", "bboxes", "[", ":", ",", "2", ":", "]", "\n", "self", ".", "bboxes", "=", "np", ".", "stack", "(", "[", "bboxes", "[", ":", ",", "0", "]", ",", "bboxes", "[", ":", ",", "1", "]", ",", "bboxes", "[", ":", ",", "2", "]", ",", "bboxes", "[", ":", ",", "2", "]", "]", ")", ".", "T", "\n", "\n", "self", ".", "image_file_names", "=", "self", ".", "image_file_names", "[", "time_pt1", ":", "time_pt2", "]", "\n", "self", ".", "joints2d", "=", "joints2d", "[", "time_pt1", ":", "time_pt2", "]", "\n", "self", ".", "frames", "=", "frames", "[", "time_pt1", ":", "time_pt2", "]", "\n", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "            ", "return", "len", "(", "self", ".", "frames", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "            ", "img", "=", "self", ".", "frames", "[", "idx", "]", "\n", "j2d", "=", "self", ".", "joints2d", "[", "idx", "]", "if", "self", ".", "has_keypoints", "else", "None", "\n", "\n", "if", "self", ".", "has_keypoints", ":", "\n", "                ", "return", "img", ",", "kp_2d", "\n", "", "else", ":", "\n", "                ", "return", "img", "\n", "\n", "", "", "", "dataset", "=", "Inference", "(", "frames", ",", "bboxes", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ")", "\n", "\n", "return", "frame_ids", ",", "dataloader", ",", "np", ".", "stack", "(", "bboxes", ",", "axis", "=", "0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.jupyter.play": [[4, 8], ["video.fetch1.fetch1", "IPython.display.display", "IPython.display.Video"], "function", ["None"], ["def", "play", "(", "video", ",", "width", "=", "640", ")", ":", "\n", "    ", "video_kwargs", "=", "{", "'width'", ":", "width", ",", "'html_attributes'", ":", "\"controls autoplay loop\"", "}", "\n", "video", "=", "video", ".", "fetch1", "(", "'output_video'", ")", "\n", "display", "(", "Video", "(", "video", ",", "**", "video_kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.jupyter.play_grid": [[10, 26], ["IPython.display.display", "isinstance", "IPython.display.HTML", "IPython.display.Video()._repr_html_", "IPython.display.Video", "v.fetch1", "str"], "function", ["None"], ["", "def", "play_grid", "(", "videos", ",", "height", "=", "200", ")", ":", "\n", "# nicely handle a single row", "\n", "    ", "if", "not", "isinstance", "(", "videos", "[", "0", "]", ",", "list", ")", ":", "\n", "        ", "videos", "=", "[", "videos", "]", "\n", "\n", "", "video_kwargs", "=", "{", "'height'", ":", "height", ",", "'html_attributes'", ":", "\"controls autoplay loop\"", "}", "\n", "\n", "# get the videos and their HTML embedding", "\n", "videos", "=", "[", "[", "Video", "(", "v", ".", "fetch1", "(", "'output_video'", ")", ",", "**", "video_kwargs", ")", ".", "_repr_html_", "(", ")", "if", "v", "is", "not", "None", "else", "\"\"", "\n", "for", "v", "in", "vrow", "]", "for", "vrow", "in", "videos", "]", "\n", "\n", "\n", "# build a row up", "\n", "display", "(", "HTML", "(", "'<table><tr>{}</tr></table>'", ".", "format", "(", "\n", "'</tr><tr>'", ".", "join", "(", "\n", "'<td>{}</td>'", ".", "format", "(", "'</td><td>'", ".", "join", "(", "str", "(", "_", ")", "for", "_", "in", "row", ")", ")", "for", "row", "in", "videos", ")", "\n", ")", ")", ")", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.video_format.compress": [[7, 13], ["tempfile.mkstemp", "subprocess.run"], "function", ["None"], ["def", "compress", "(", "fn", ")", ":", "\n", "    ", "import", "subprocess", "\n", "\n", "_", ",", "temp", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "subprocess", ".", "run", "(", "[", "'ffmpeg'", ",", "'-y'", ",", "'-i'", ",", "fn", ",", "'-c:v'", ",", "'libx264'", ",", "'-b:v'", ",", "'5M'", ",", "temp", "]", ")", "\n", "return", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.video_format.insert_local_video": [[15, 25], ["os.path.exists", "print", "pose_pipeline.pipeline.Video().insert1", "pose_pipeline.pipeline.Video"], "function", ["None"], ["", "def", "insert_local_video", "(", "filename", ",", "video_start_time", ",", "local_path", ",", "video_project", "=", "\"TESTING\"", ",", "skip_duplicates", "=", "False", ")", ":", "\n", "    ", "\"\"\" Insert local video into the Pose Pipeline \"\"\"", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "local_path", ")", "\n", "\n", "vid_struct", "=", "{", "'video_project'", ":", "video_project", ",", "'filename'", ":", "filename", ",", "\n", "'start_time'", ":", "video_start_time", ",", "'video'", ":", "local_path", "}", "\n", "\n", "print", "(", "vid_struct", ")", "\n", "Video", "(", ")", ".", "insert1", "(", "vid_struct", ",", "skip_duplicates", "=", "skip_duplicates", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.keypoints_to_bbox": [[5, 18], ["numpy.min", "numpy.min", "numpy.max", "numpy.max"], "function", ["None"], ["def", "keypoints_to_bbox", "(", "keypoints", ",", "thresh", "=", "0.1", ",", "min_keypoints", "=", "5", ")", ":", "\n", "\n", "    ", "if", "keypoints", ".", "shape", "[", "-", "1", "]", "==", "3", ":", "\n", "        ", "valid", "=", "keypoints", "[", ":", ",", "-", "1", "]", ">", "thresh", "\n", "keypoints", "=", "keypoints", "[", "valid", ",", ":", "-", "1", "]", "\n", "\n", "", "if", "keypoints", ".", "shape", "[", "0", "]", "<", "min_keypoints", ":", "\n", "        ", "return", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "\n", "\n", "", "bbox", "=", "[", "np", ".", "min", "(", "keypoints", "[", ":", ",", "0", "]", ")", ",", "np", ".", "min", "(", "keypoints", "[", ":", ",", "1", "]", ")", ",", "np", ".", "max", "(", "keypoints", "[", ":", ",", "0", "]", ")", ",", "np", ".", "max", "(", "keypoints", "[", ":", ",", "1", "]", ")", "]", "\n", "bbox", "=", "bbox", "[", ":", "2", "]", "+", "[", "bbox", "[", "2", "]", "-", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "-", "bbox", "[", "1", "]", "]", "\n", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.compute_iou": [[20, 47], ["max", "numpy.ones().astype", "numpy.all", "numpy.all", "numpy.prod().astype", "numpy.greater", "numpy.greater", "numpy.ones", "numpy.prod", "numpy.prod", "numpy.prod", "numpy.minimum", "numpy.maximum"], "function", ["None"], ["", "def", "compute_iou", "(", "box1", ":", "np", ".", "ndarray", ",", "box2", ":", "np", ".", "ndarray", ",", "tlhw", "=", "True", ",", "epsilon", "=", "1e-8", ")", ":", "\n", "    ", "\"\"\"\n    calculate intersection over union cover percent\n    \n        :param box1: box1 with shape (N,4)\n        :param box2: box2 with shape (N,4)\n        :tlhw: bool if format is tlhw and need to be converted to tlbr\n        :return: IoU ratio if intersect, else 0\n    \"\"\"", "\n", "point_num", "=", "max", "(", "box1", ".", "shape", "[", "0", "]", ",", "box2", ".", "shape", "[", "0", "]", ")", "\n", "b1p1", ",", "b1p2", ",", "b2p1", ",", "b2p2", "=", "box1", "[", ":", ",", ":", "2", "]", ",", "box1", "[", ":", ",", "2", ":", "]", ",", "box2", "[", ":", ",", ":", "2", "]", ",", "box2", "[", ":", ",", "2", ":", "]", "\n", "\n", "if", "tlhw", ":", "\n", "        ", "b1p2", "=", "b1p1", "+", "b1p2", "\n", "b2p2", "=", "b2p1", "+", "b2p2", "\n", "\n", "# mask that eliminates non-intersecting matrices", "\n", "", "base_mat", "=", "np", ".", "ones", "(", "shape", "=", "(", "point_num", ",", ")", ")", ".", "astype", "(", "float", ")", "\n", "base_mat", "*=", "np", ".", "all", "(", "np", ".", "greater", "(", "b1p2", "-", "b2p1", ",", "0", ")", ",", "axis", "=", "1", ")", "\n", "base_mat", "*=", "np", ".", "all", "(", "np", ".", "greater", "(", "b2p2", "-", "b1p1", ",", "0", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# epsilon handles case where a bbox has zero size (so let's make that have a IoU=0)", "\n", "intersect_area", "=", "np", ".", "prod", "(", "np", ".", "minimum", "(", "b2p2", ",", "b1p2", ")", "-", "np", ".", "maximum", "(", "b1p1", ",", "b2p1", ")", ",", "axis", "=", "1", ")", ".", "astype", "(", "float", ")", "\n", "union_area", "=", "np", ".", "prod", "(", "b1p2", "-", "b1p1", ",", "axis", "=", "1", ")", "+", "np", ".", "prod", "(", "b2p2", "-", "b2p1", ",", "axis", "=", "1", ")", "-", "intersect_area", "+", "epsilon", "\n", "intersect_ratio", "=", "intersect_area", "/", "union_area", "\n", "\n", "return", "base_mat", "*", "intersect_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.match_keypoints_to_bbox": [[49, 70], ["numpy.reshape", "numpy.array", "keypoint_matching.compute_iou", "numpy.argmax", "numpy.zeros", "numpy.zeros", "len", "keypoint_matching.keypoints_to_bbox"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.compute_iou", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.keypoint_matching.keypoints_to_bbox"], ["", "def", "match_keypoints_to_bbox", "(", "bbox", ":", "np", ".", "ndarray", ",", "keypoints_list", ":", "list", ",", "thresh", "=", "0.25", ",", "num_keypoints", "=", "25", ",", "visible", "=", "True", ")", ":", "\n", "    ", "\"\"\" Finds the best keypoints with an acceptable IoU, if present \"\"\"", "\n", "\n", "if", "visible", ":", "\n", "        ", "empty_keypoints", "=", "np", ".", "zeros", "(", "(", "num_keypoints", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "        ", "empty_keypoints", "=", "np", ".", "zeros", "(", "(", "num_keypoints", ",", "2", ")", ")", "\n", "\n", "", "if", "keypoints_list", "is", "None", "or", "len", "(", "keypoints_list", ")", "==", "0", ":", "\n", "        ", "return", "empty_keypoints", ",", "None", "\n", "\n", "", "bbox", "=", "np", ".", "reshape", "(", "bbox", ",", "(", "1", ",", "4", ")", ")", "\n", "kp_bbox", "=", "np", ".", "array", "(", "[", "keypoints_to_bbox", "(", "k", ")", "for", "k", "in", "keypoints_list", "]", ")", "\n", "\n", "iou", "=", "compute_iou", "(", "bbox", ",", "kp_bbox", ")", "\n", "idx", "=", "np", ".", "argmax", "(", "iou", ")", "\n", "\n", "if", "iou", "[", "idx", "]", ">", "thresh", ":", "\n", "        ", "return", "keypoints_list", "[", "idx", "]", ",", "idx", "\n", "\n", "", "return", "empty_keypoints", ",", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.poseaug.get_keypoints": [[10, 48], ["numpy.array", "max", "poseaug.get_keypoints.normalize_screen_coordinates"], "function", ["None"], ["def", "get_keypoints", "(", "key", ",", "normalize", "=", "True", ",", "transform_coco", "=", "True", ")", ":", "\n", "\n", "    ", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "N", "=", "keypoints", ".", "shape", "[", "0", "]", "\n", "\n", "def", "normalize_screen_coordinates", "(", "X", ",", "w", ",", "h", ")", ":", "\n", "        ", "assert", "X", ".", "shape", "[", "-", "1", "]", "==", "2", "\n", "\n", "# Normalize so that [0, w] is mapped to [-1, 1], while preserving the aspect ratio", "\n", "if", "w", ">", "h", ":", "\n", "            ", "return", "X", "/", "w", "*", "2", "-", "[", "1", ",", "h", "/", "w", "]", "\n", "", "else", ":", "\n", "            ", "return", "X", "/", "h", "*", "2", "-", "[", "w", "/", "h", ",", "1", "]", "\n", "\n", "", "", "if", "normalize", ":", "\n", "        ", "max_dim", "=", "max", "(", "height", ",", "width", ")", "\n", "keypoints_score", "=", "keypoints", "[", "None", ",", "...", ",", "2", "]", "\n", "keypoints", "=", "normalize_screen_coordinates", "(", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", ",", "width", ",", "height", ")", "\n", "", "else", ":", "\n", "        ", "keypoints_score", "=", "keypoints", "[", "None", ",", "...", ",", "2", "]", "\n", "keypoints", "=", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", "\n", "\n", "", "if", "transform_coco", ":", "\n", "        ", "with", "add_path", "(", "os", ".", "environ", "[", "\"GAST_PATH\"", "]", ")", ":", "\n", "            ", "from", "tools", ".", "preprocess", "import", "h36m_coco_format", ",", "revise_kpts", "\n", "keypoints", "=", "keypoints", "[", "None", ",", "...", "]", "\n", "keypoints_reformat", ",", "scores", ",", "valid_frames", "=", "h36m_coco_format", "(", "keypoints", ",", "keypoints_score", ")", "\n", "keypoints_reformat", "=", "revise_kpts", "(", "keypoints_reformat", ",", "scores", ",", "valid_frames", ")", "[", "0", "]", "\n", "\n", "valid_frames", "=", "np", ".", "array", "(", "valid_frames", "[", "0", "]", ")", "\n", "keypoints", "=", "keypoints_reformat", "[", "valid_frames", "]", "\n", "\n", "", "", "idx_keep", "=", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "keypoints", ".", "shape", "[", "1", "]", ")", "if", "LiftingPerson", ".", "joint_names", "(", ")", "[", "i", "]", "!=", "'Nose'", "]", ")", "\n", "keypoints", "=", "keypoints", "[", ":", ",", "idx_keep", "]", "\n", "\n", "return", "keypoints", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.poseaug.process_poseaug": [[50, 72], ["os.path.join", "pose_pipeline.env.add_path", "WrapSTGCN", "torch.load", "WrapSTGCN.load_state_dict", "WrapSTGCN.cuda", "WrapSTGCN.eval", "poseaug.get_keypoints", "torch.from_numpy().cuda().float", "WrapSTGCN.cpu().detach().numpy", "list", "range", "torch.from_numpy().cuda", "WrapSTGCN.cpu().detach", "torch.from_numpy", "WrapSTGCN.cpu", "WrapSTGCN."], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.poseaug.get_keypoints", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "process_poseaug", "(", "key", ")", ":", "\n", "\n", "    ", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'poseaug/ckpt_best_dhp_p1.pth.tar'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"POSEAUG_PATH\"", "]", ")", ":", "\n", "\n", "        ", "import", "torch", "\n", "from", "models_baseline", ".", "models_st_gcn", ".", "st_gcn_single_frame_test", "import", "WrapSTGCN", "\n", "\n", "model_pos", "=", "WrapSTGCN", "(", "p_dropout", "=", "0.0", ")", "\n", "tmp_ckpt", "=", "torch", ".", "load", "(", "checkpoint", ")", "\n", "model_pos", ".", "load_state_dict", "(", "tmp_ckpt", "[", "'model_pos'", "]", ")", "\n", "model_pos", ".", "cuda", "(", ")", "\n", "model_pos", ".", "eval", "(", ")", "\n", "\n", "keypoints", "=", "get_keypoints", "(", "key", ")", "\n", "keypoints", "=", "torch", ".", "from_numpy", "(", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "\n", "keypoints_3d", "=", "model_pos", "(", "keypoints", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "keypoints_valid", "=", "list", "(", "range", "(", "keypoints_3d", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "return", "{", "'keypoints_3d'", ":", "keypoints_3d", ",", "'keypoints_valid'", ":", "keypoints_valid", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.TopDownPose_Humor_Dataset.__init__": [[16, 64], ["torch.utils.data.Dataset.__init__", "print", "numpy.array", "math.ceil", "range", "numpy.array", "seq_intervals.append", "humor.TopDownPose_Humor_Dataset.starts.append", "humor.TopDownPose_Humor_Dataset.ends.append"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.__init__"], ["    ", "def", "__init__", "(", "self", ",", "key", ",", "cam_mat", "=", "None", ",", "seq_len", "=", "60", ",", "overlap_len", "=", "10", ")", ":", "\n", "        ", "super", "(", "TopDownPose_Humor_Dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "key", "=", "key", "\n", "\n", "\n", "self", ".", "keypoints", "=", "(", "OpenPosePerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", ".", "copy", "(", ")", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "T", "=", "self", ".", "keypoints", ".", "shape", "[", "0", "]", "\n", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "overlap_len", "=", "overlap_len", "\n", "\n", "seq_intervals", "=", "[", "]", "\n", "self", ".", "starts", "=", "[", "]", "\n", "self", ".", "ends", "=", "[", "]", "\n", "if", "self", ".", "seq_len", "is", "not", "None", "and", "self", ".", "overlap_len", "is", "not", "None", ":", "\n", "            ", "num_seqs", "=", "math", ".", "ceil", "(", "(", "T", "-", "self", ".", "overlap_len", ")", "/", "(", "self", ".", "seq_len", "-", "self", ".", "overlap_len", ")", ")", "\n", "r", "=", "self", ".", "seq_len", "*", "num_seqs", "-", "self", ".", "overlap_len", "*", "(", "num_seqs", "-", "1", ")", "-", "T", "# number of extra frames we cover", "\n", "extra_o", "=", "r", "//", "(", "num_seqs", "-", "1", ")", "# we increase the overlap to avoid these as much as possible", "\n", "self", ".", "overlap_len", "=", "self", ".", "overlap_len", "+", "extra_o", "\n", "\n", "new_cov", "=", "self", ".", "seq_len", "*", "num_seqs", "-", "self", ".", "overlap_len", "*", "(", "num_seqs", "-", "1", ")", "# now compute how many frames are still left to account for", "\n", "r", "=", "new_cov", "-", "T", "\n", "\n", "# create intervals", "\n", "cur_s", "=", "0", "\n", "cur_e", "=", "cur_s", "+", "self", ".", "seq_len", "\n", "for", "int_idx", "in", "range", "(", "num_seqs", ")", ":", "\n", "                ", "seq_intervals", ".", "append", "(", "(", "cur_s", ",", "cur_e", ")", ")", "\n", "self", ".", "starts", ".", "append", "(", "cur_s", ")", "\n", "self", ".", "ends", ".", "append", "(", "cur_e", ")", "\n", "cur_overlap", "=", "self", ".", "overlap_len", "\n", "if", "int_idx", "<", "r", ":", "\n", "                    ", "cur_overlap", "+=", "1", "# update to account for final remainder", "\n", "", "cur_s", "+=", "(", "self", ".", "seq_len", "-", "cur_overlap", ")", "\n", "cur_e", "=", "cur_s", "+", "self", ".", "seq_len", "\n", "", "", "print", "(", "seq_intervals", ")", "\n", "\n", "self", ".", "DEFAULT_GROUND", "=", "np", ".", "array", "(", "[", "0.0", ",", "-", "1.0", ",", "0.0", ",", "-", "0.5", "]", ")", "\n", "\n", "if", "cam_mat", "is", "None", ":", "\n", "            ", "DEFAULT_FOCAL_LEN", "=", "(", "1060.531764702488", ",", "1060.3856705041237", ")", "\n", "self", ".", "cam_mat", "=", "np", ".", "array", "(", "[", "[", "DEFAULT_FOCAL_LEN", "[", "0", "]", ",", "0.0", ",", "width", "/", "2.", "]", ",", "\n", "[", "0.0", ",", "DEFAULT_FOCAL_LEN", "[", "1", "]", ",", "height", "/", "2.", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cam_mat", "=", "cam_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.TopDownPose_Humor_Dataset.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "starts", ")", "#1 # len(self.keypoints)", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.TopDownPose_Humor_Dataset.__getitem__": [[68, 79], ["dict", "dict", "torch.Tensor", "torch.Tensor().to", "torch.Tensor", "list"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "obs_data", "=", "dict", "(", ")", "\n", "gt_data", "=", "dict", "(", ")", "\n", "\n", "obs_data", "[", "'joints2d'", "]", "=", "torch", ".", "Tensor", "(", "self", ".", "keypoints", "[", "self", ".", "starts", "[", "idx", "]", ":", "self", ".", "ends", "[", "idx", "]", "]", ")", "\n", "obs_data", "[", "'seq_interval'", "]", "=", "torch", ".", "Tensor", "(", "list", "(", "[", "self", ".", "starts", "[", "idx", "]", ",", "self", ".", "ends", "[", "idx", "]", "]", ")", ")", ".", "to", "(", "torch", ".", "int", ")", "\n", "obs_data", "[", "'floor_plane'", "]", "=", "self", ".", "DEFAULT_GROUND", "\n", "\n", "gt_data", "[", "'cam_matx'", "]", "=", "self", ".", "cam_mat", "\n", "\n", "return", "obs_data", ",", "gt_data", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.process_humor": [[81, 291], ["humor.TopDownPose_Humor_Dataset", "torch.utils.data.DataLoader", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "humor.process_humor.stitch_results"], "function", ["None"], ["", "", "def", "process_humor", "(", "key", ",", "return_raw", "=", "False", ")", ":", "\n", "\n", "    ", "keypoints", "=", "(", "OpenPosePerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", ".", "copy", "(", ")", "\n", "fps", ",", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'fps'", ",", "'height'", ",", "'width'", ")", "\n", "\n", "dataset", "=", "TopDownPose_Humor_Dataset", "(", "key", ")", "\n", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "100", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "False", ",", "\n", "worker_init_fn", "=", "lambda", "_", ":", "np", ".", "random", ".", "seed", "(", ")", ")", "\n", "\n", "device", "=", "'cuda'", "\n", "NSTAGES", "=", "3", "\n", "\n", "vposer_location", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'humor/body_models/vposer_v1_0'", ")", "\n", "motion_prior_weights", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'humor/checkpoints/humor/best_model.pth'", ")", "\n", "gmm_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'humor/checkpoints/init_state_prior_gmm/prior_gmm.npz'", ")", "\n", "body_model_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'humor/body_models/smplh/neutral/model.npz'", ")", "\n", "\n", "T", "=", "keypoints", ".", "shape", "[", "0", "]", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'HUMOR_PATH'", "]", ")", ":", "\n", "        ", "from", "fitting", ".", "fitting_utils", "import", "load_vposer", "\n", "from", "models", ".", "humor_model", "import", "HumorModel", "\n", "from", "body_model", ".", "body_model", "import", "BodyModel", "\n", "from", "utils", ".", "torch", "import", "load_state", "\n", "from", "fitting", ".", "motion_optimizer", "import", "MotionOptimizer", "\n", "from", "utils", ".", "logging", "import", "Logger", "\n", "\n", "Logger", ".", "log", "=", "lambda", "x", ":", "None", "\n", "\n", "# weights for optimization loss terms. taken from `fit_rgb_demo_no_split.cfg`", "\n", "loss_weights", "=", "{", "\n", "'joints2d'", ":", "[", "0.001", ",", "0.001", ",", "0.001", "]", ",", "\n", "'joints3d'", ":", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "'joints3d_rollout'", ":", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "'verts3d'", ":", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "'points3d'", ":", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "'pose_prior'", ":", "[", "0.04", ",", "0.04", ",", "0.0", "]", ",", "\n", "'shape_prior'", ":", "[", "0.05", ",", "0.05", ",", "0.05", "]", ",", "\n", "'motion_prior'", ":", "[", "0.0", ",", "0.0", ",", "0.075", "]", ",", "\n", "'init_motion_prior'", ":", "[", "0.0", ",", "0.0", ",", "0.075", "]", ",", "\n", "'joint_consistency'", ":", "[", "0.0", ",", "0.0", ",", "100.0", "]", ",", "\n", "'bone_length'", ":", "[", "0.0", ",", "0.0", ",", "2000.0", "]", ",", "\n", "'joints3d_smooth'", ":", "[", "100.0", ",", "100.0", ",", "0.0", "]", ",", "\n", "'contact_vel'", ":", "[", "0.0", ",", "0.0", ",", "100.0", "]", ",", "\n", "'contact_height'", ":", "[", "0.0", ",", "0.0", ",", "10.0", "]", ",", "\n", "'floor_reg'", ":", "[", "0.0", ",", "0.0", ",", "0.167", "]", ",", "\n", "'rgb_overlap_consist'", ":", "[", "200.0", ",", "200.0", ",", "200.0", "]", "\n", "}", "\n", "\n", "max_loss_weights", "=", "{", "k", ":", "max", "(", "v", ")", "for", "k", ",", "v", "in", "loss_weights", ".", "items", "(", ")", "}", "\n", "all_stage_loss_weights", "=", "[", "]", "\n", "for", "sidx", "in", "range", "(", "NSTAGES", ")", ":", "\n", "            ", "stage_loss_weights", "=", "{", "k", ":", "v", "[", "sidx", "]", "for", "k", ",", "v", "in", "loss_weights", ".", "items", "(", ")", "}", "\n", "all_stage_loss_weights", ".", "append", "(", "stage_loss_weights", ")", "\n", "\n", "", "use_joints2d", "=", "max_loss_weights", "[", "'joints2d'", "]", ">", "0.0", "\n", "use_overlap_loss", "=", "max_loss_weights", "[", "'rgb_overlap_consist'", "]", ">", "0.0", "\n", "\n", "# load vpose body prior", "\n", "pose_prior", ",", "_", "=", "load_vposer", "(", "vposer_location", ")", "\n", "pose_prior", "=", "pose_prior", ".", "to", "(", "device", ")", "\n", "pose_prior", ".", "eval", "(", ")", "\n", "\n", "# load Humor motion prior", "\n", "motion_prior", "=", "HumorModel", "(", "in_rot_rep", "=", "'mat'", ",", "\n", "out_rot_rep", "=", "'aa'", ",", "\n", "latent_size", "=", "48", ",", "\n", "model_data_config", "=", "'smpl+joints+contacts'", ",", "\n", "steps_in", "=", "1", ")", "\n", "motion_prior", ".", "to", "(", "device", ")", "\n", "load_state", "(", "motion_prior_weights", ",", "motion_prior", ",", "map_location", "=", "device", ")", "\n", "motion_prior", ".", "eval", "(", ")", "\n", "\n", "# load initial motion distribution", "\n", "gmm_res", "=", "np", ".", "load", "(", "gmm_path", ")", "\n", "init_motion_prior", "=", "{", "'gmm'", ":", "(", "torch", ".", "Tensor", "(", "gmm_res", "[", "'weights'", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "torch", ".", "Tensor", "(", "gmm_res", "[", "'means'", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "torch", ".", "Tensor", "(", "gmm_res", "[", "'covariances'", "]", ")", ".", "to", "(", "device", ")", ")", "}", "\n", "\n", "results", "=", "{", "'trans'", ":", "[", "]", ",", "'root_orient'", ":", "[", "]", ",", "'pose_body'", ":", "[", "]", ",", "'betas'", ":", "[", "]", ",", "'latent_pose'", ":", "[", "]", ",", "\n", "'latent_motion'", ":", "[", "]", ",", "'floor_plane'", ":", "[", "]", ",", "'contacts'", ":", "[", "]", ",", "'vertices'", ":", "[", "]", ",", "'seq_interval'", ":", "[", "]", "}", "\n", "\n", "prev_batch_overlap_res_dict", "=", "None", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "observed_data", ",", "gt_data", "=", "data", "\n", "observed_data", "=", "{", "k", ":", "v", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "observed_data", ".", "items", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "}", "\n", "for", "k", ",", "v", "in", "gt_data", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "gt_data", "[", "k", "]", "=", "v", ".", "to", "(", "device", ")", "\n", "\n", "# pass in the last batch index from previous batch is using overlap consistency", "\n", "", "", "if", "use_overlap_loss", "and", "prev_batch_overlap_res_dict", "is", "not", "None", ":", "\n", "                ", "observed_data", "[", "'prev_batch_overlap_res'", "]", "=", "prev_batch_overlap_res_dict", "\n", "\n", "", "cur_batch_size", "=", "observed_data", "[", "list", "(", "observed_data", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "size", "(", "0", ")", "\n", "T", "=", "observed_data", "[", "list", "(", "observed_data", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ".", "size", "(", "1", ")", "\n", "print", "(", "f'Cur batch size: {cur_batch_size} and T {T}'", ")", "\n", "\n", "cam_mat", "=", "gt_data", "[", "'cam_matx'", "]", ".", "to", "(", "device", ")", "\n", "\n", "# load body model", "\n", "num_betas", "=", "16", "\n", "body_model", "=", "BodyModel", "(", "bm_path", "=", "body_model_path", ",", "num_betas", "=", "num_betas", ",", "\n", "batch_size", "=", "T", "*", "cur_batch_size", ",", "use_vtx_selector", "=", "use_joints2d", ")", ".", "to", "(", "device", ")", "\n", "\n", "# load optimizer", "\n", "robust_loss", "=", "'bisquare'", "\n", "robust_tuning_const", "=", "4.6851", "\n", "joint2d_sigma", "=", "100", "\n", "\n", "im_dim", "=", "(", "width", ",", "height", ")", "\n", "\n", "optimizer", "=", "MotionOptimizer", "(", "device", ",", "\n", "body_model", ",", "\n", "num_betas", ",", "\n", "cur_batch_size", ",", "\n", "T", ",", "\n", "[", "k", "for", "k", "in", "observed_data", ".", "keys", "(", ")", "]", ",", "\n", "all_stage_loss_weights", ",", "\n", "pose_prior", ",", "\n", "motion_prior", ",", "\n", "init_motion_prior", ",", "\n", "use_joints2d", ",", "\n", "cam_mat", ",", "\n", "robust_loss", ",", "\n", "robust_tuning_const", ",", "\n", "joint2d_sigma", ",", "\n", "stage3_tune_init_state", "=", "True", ",", "\n", "stage3_tune_init_num_frames", "=", "15", ",", "\n", "stage3_tune_init_freeze_start", "=", "30", ",", "\n", "stage3_tune_init_freeze_end", "=", "55", ",", "\n", "stage3_contact_refine_only", "=", "True", ",", "\n", "use_chamfer", "=", "(", "'points3d'", "in", "observed_data", ")", ",", "\n", "im_dim", "=", "im_dim", ")", "\n", "\n", "optim_result", ",", "per_stage_results", "=", "optimizer", ".", "run", "(", "observed_data", ",", "\n", "data_fps", "=", "fps", ",", "\n", "lr", "=", "1.0", ",", "\n", "num_iter", "=", "[", "30", ",", "80", ",", "70", "]", ",", "# 30, 90, 100", "\n", "lbfgs_max_iter", "=", "50", ",", "\n", "stages_res_out", "=", "None", ",", "\n", "fit_gender", "=", "'neutral'", ")", "\n", "\n", "# cache results for consistency loss between sequential batches", "\n", "if", "use_overlap_loss", ":", "\n", "                ", "prev_batch_overlap_res_dict", "=", "dict", "(", ")", "\n", "prev_batch_overlap_res_dict", "[", "'verts3d'", "]", "=", "per_stage_results", "[", "'stage3'", "]", "[", "'verts3d'", "]", "[", "-", "1", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "prev_batch_overlap_res_dict", "[", "'betas'", "]", "=", "optim_result", "[", "'betas'", "]", "[", "-", "1", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "prev_batch_overlap_res_dict", "[", "'floor_plane'", "]", "=", "optim_result", "[", "'floor_plane'", "]", "[", "-", "1", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "prev_batch_overlap_res_dict", "[", "'seq_interval'", "]", "=", "observed_data", "[", "'seq_interval'", "]", "[", "-", "1", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "", "for", "k", "in", "optim_result", ".", "keys", "(", ")", ":", "\n", "                ", "results", "[", "k", "]", ".", "append", "(", "optim_result", "[", "k", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "results", "[", "'vertices'", "]", ".", "append", "(", "per_stage_results", "[", "'stage3'", "]", "[", "'points3d'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'seq_interval'", "]", ".", "append", "(", "observed_data", "[", "'seq_interval'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "faces", "=", "body_model", ".", "bm", ".", "faces", "\n", "\n", "if", "i", "<", "(", "len", "(", "data_loader", ")", "-", "1", ")", ":", "\n", "                ", "del", "optimizer", "\n", "", "del", "body_model", "\n", "del", "observed_data", "\n", "del", "gt_data", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "", "def", "stitch_results", "(", "results", ")", ":", "\n", "        ", "seq_interval", "=", "results", ".", "pop", "(", "'seq_interval'", ")", "\n", "\n", "stitched_results", "=", "{", "k", ":", "[", "]", "for", "k", "in", "results", ".", "keys", "(", ")", "}", "\n", "\n", "last_end", "=", "None", "\n", "\n", "for", "batch_num", ",", "batch_seq", "in", "enumerate", "(", "seq_interval", ")", ":", "\n", "\n", "            ", "for", "i", ",", "interval", "in", "enumerate", "(", "batch_seq", ")", ":", "\n", "                ", "if", "last_end", "is", "None", ":", "\n", "                    ", "for", "k", "in", "results", ".", "keys", "(", ")", ":", "\n", "                        ", "stitched_results", "[", "k", "]", ".", "append", "(", "results", "[", "k", "]", "[", "batch_num", "]", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "discard", "=", "last_end", "-", "interval", "[", "0", "]", "\n", "for", "k", "in", "results", ".", "keys", "(", ")", ":", "\n", "                        ", "if", "k", "not", "in", "[", "'betas'", ",", "'floor_plane'", "]", ":", "\n", "                            ", "stitched_results", "[", "k", "]", ".", "append", "(", "results", "[", "k", "]", "[", "batch_num", "]", "[", "i", ",", "discard", ":", "]", ")", "\n", "", "else", ":", "\n", "                            ", "stitched_results", "[", "k", "]", ".", "append", "(", "results", "[", "k", "]", "[", "batch_num", "]", "[", "i", "]", ")", "\n", "\n", "", "", "", "last_end", "=", "interval", "[", "-", "1", "]", "\n", "\n", "", "", "for", "k", "in", "stitched_results", ".", "keys", "(", ")", ":", "\n", "            ", "if", "k", "not", "in", "[", "'betas'", ",", "'floor_plane'", "]", ":", "\n", "                ", "stitched_results", "[", "k", "]", "=", "np", ".", "concatenate", "(", "stitched_results", "[", "k", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "return", "stitched_results", "\n", "\n", "", "stiched_results", "=", "stitch_results", "(", "results", ")", "\n", "\n", "key", ".", "update", "(", "stiched_results", ")", "\n", "key", "[", "'faces'", "]", "=", "faces", "\n", "\n", "if", "return_raw", ":", "\n", "        ", "return", "key", ",", "results", "\n", "", "else", ":", "\n", "        ", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.humor.render_humor": [[293, 372], ["tempfile.mkdtemp", "print", "numpy.tile", "numpy.mean", "numpy.array", "numpy.array", "os.path.join", "numpy.mean", "numpy.array", "cv2.VideoCapture", "cv2.VideoCapture.release", "os.remove", "float", "float", "pose_pipeline.env.add_path", "BodyModel", "BodyModel.", "viz_smpl_seq", "os.path.join", "create_video", "numpy.array", "cv2.VideoCapture.read", "cv2.cvtColor", "imgs.append", "numpy.array", "os.path.join", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "", "def", "render_humor", "(", "key", ",", "show_bg", "=", "True", ")", ":", "\n", "    ", "import", "tempfile", "\n", "\n", "out_path", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "print", "(", "f'Rendering to {out_path}'", ")", "\n", "\n", "width", ",", "height", ",", "fps", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'width'", ",", "'height'", ",", "'fps'", ")", "\n", "pose_body", ",", "root_orient", ",", "trans", ",", "beta", ",", "contacts", ",", "floor_plane", "=", "(", "HumorPerson", "&", "key", ")", ".", "fetch1", "(", "'pose_body'", ",", "'root_orient'", ",", "'trans'", ",", "'betas'", ",", "'contacts'", ",", "'floor_plane'", ")", "\n", "betas", "=", "np", ".", "tile", "(", "np", ".", "mean", "(", "np", ".", "array", "(", "beta", ")", ",", "axis", "=", "0", ")", ",", "[", "pose_body", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "floor_plane", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "floor_plane", ")", ",", "axis", "=", "0", ")", "\n", "\n", "if", "show_bg", ":", "\n", "        ", "import", "cv2", "\n", "\n", "imgs", "=", "[", "]", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "", "img", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "imgs", ".", "append", "(", "img", ")", "\n", "", "cap", ".", "release", "(", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n", "img_arr", "=", "np", ".", "array", "(", "imgs", ")", "/", "256.0", "\n", "", "else", ":", "\n", "        ", "img_arr", "=", "None", "\n", "\n", "", "DEFAULT_GROUND", "=", "np", ".", "array", "(", "[", "0.0", ",", "-", "1.0", ",", "0.0", ",", "-", "0.5", "]", ")", "\n", "DEFAULT_FOCAL_LEN", "=", "(", "1060.531764702488", ",", "1060.3856705041237", ")", "\n", "cam_mat", "=", "np", ".", "array", "(", "[", "[", "DEFAULT_FOCAL_LEN", "[", "0", "]", ",", "0.0", ",", "width", "/", "2.", "]", ",", "\n", "[", "0.0", ",", "DEFAULT_FOCAL_LEN", "[", "1", "]", ",", "height", "/", "2.", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "\n", "# get camera intrinsics", "\n", "cam_fx", "=", "cam_mat", "[", "0", ",", "0", "]", "\n", "cam_fy", "=", "cam_mat", "[", "1", ",", "1", "]", "\n", "cam_cx", "=", "cam_mat", "[", "0", ",", "2", "]", "\n", "cam_cy", "=", "cam_mat", "[", "1", ",", "2", "]", "\n", "cam_intrins", "=", "(", "cam_fx", ",", "cam_fy", ",", "cam_cx", ",", "cam_cy", ")", "\n", "\n", "x_frac", "=", "float", "(", "width", ")", "/", "width", "\n", "y_frac", "=", "float", "(", "height", ")", "/", "height", "# if downsampling can use these", "\n", "cam_intrins_down", "=", "(", "cam_fx", "*", "x_frac", ",", "cam_fy", "*", "y_frac", ",", "cam_cx", "*", "x_frac", ",", "cam_cy", "*", "y_frac", ")", "\n", "\n", "body_model_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'humor/body_models/smplh/neutral/model.npz'", ")", "\n", "\n", "os", ".", "environ", "[", "'PYOPENGL_PLATFORM'", "]", "=", "'egl'", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'HUMOR_PATH'", "]", ")", ":", "\n", "        ", "from", "body_model", ".", "body_model", "import", "BodyModel", "\n", "from", "viz", ".", "utils", "import", "viz_smpl_seq", "\n", "from", "viz", ".", "utils", "import", "create_video", "\n", "\n", "num_betas", "=", "16", "\n", "T", "=", "pose_body", ".", "shape", "[", "0", "]", "\n", "body_model", "=", "BodyModel", "(", "bm_path", "=", "body_model_path", ",", "num_betas", "=", "num_betas", ",", "batch_size", "=", "T", ",", "use_vtx_selector", "=", "True", ")", "\n", "\n", "viz", "=", "body_model", "(", "root_orient", "=", "torch", ".", "Tensor", "(", "root_orient", ")", ",", "pose_body", "=", "torch", ".", "Tensor", "(", "pose_body", ")", ",", "betas", "=", "torch", ".", "Tensor", "(", "betas", ")", ",", "trans", "=", "torch", ".", "Tensor", "(", "trans", ")", ")", "\n", "\n", "if", "show_bg", ":", "\n", "            ", "BODY_ALPHA", "=", "0.8", "\n", "", "else", ":", "\n", "            ", "BODY_ALPHA", "=", "0.5", "\n", "", "SKELETON_ALPHA", "=", "1.0", "\n", "\n", "viz_smpl_seq", "(", "viz", ",", "use_offscreen", "=", "True", ",", "camera_intrinsics", "=", "cam_intrins_down", ",", "contacts", "=", "contacts", ",", "imw", "=", "width", ",", "imh", "=", "height", ",", "fps", "=", "fps", ",", "\n", "body_alpha", "=", "BODY_ALPHA", ",", "render_joints", "=", "True", ",", "render_skeleton", "=", "SKELETON_ALPHA", ",", "render_ground", "=", "False", ",", "ground_plane", "=", "floor_plane", ",", "\n", "img_seq", "=", "img_arr", ",", "out_path", "=", "out_path", ")", "\n", "\n", "out_vid", "=", "os", ".", "path", ".", "join", "(", "out_path", ",", "key", "[", "'filename'", "]", "+", "\"_humor.mp4\"", ")", "\n", "create_video", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "'frame_%08d.png'", ")", ",", "out_vid", ",", "fps", ")", "\n", "\n", "", "return", "out_vid", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.vibe.process_vibe": [[10, 71], ["os.path.join", "os.path.join", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "pose_pipeline.utils.bounding_box.convert_crop_cam_to_orig_img", "pose_pipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "pose_pipeline.env.add_path", "pose_pipeline.utils.bounding_box.get_person_dataloader", "VIBE_Demo().to", "torch.load", "VIBE_Demo().to.load_state_dict", "VIBE_Demo().to.eval", "torch.no_grad", "VIBE_Demo", "batch.to.unsqueeze", "batch.to.to", "pred_cam.append", "pred_verts.append", "pred_pose.append", "pred_betas.append", "pred_joints3d.append", "smpl_joints2d.append", "norm_joints2d.append", "VIBE_Demo().to.", "[].reshape().cpu().detach().numpy", "output[].reshape().cpu().detach().numpy", "[].reshape().cpu().detach().numpy", "[].reshape().cpu().detach().numpy", "output[].reshape().cpu().detach().numpy", "output[].reshape().cpu().detach().numpy", "nj2d.numpy().reshape", "[].reshape().cpu().detach", "output[].reshape().cpu().detach", "[].reshape().cpu().detach", "[].reshape().cpu().detach", "output[].reshape().cpu().detach", "output[].reshape().cpu().detach", "nj2d.numpy", "[].reshape().cpu", "output[].reshape().cpu", "[].reshape().cpu", "[].reshape().cpu", "output[].reshape().cpu", "output[].reshape().cpu", "[].reshape", "output[].reshape", "[].reshape", "[].reshape", "output[].reshape", "output[].reshape"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_cam_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.get_person_dataloader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["def", "process_vibe", "(", "key", ")", ":", "\n", "\n", "    ", "crop_size", "=", "224", "\n", "\n", "spin_checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'vibe/spin_model_checkpoint.pth.tar'", ")", "\n", "vibe_checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'vibe/vibe_model_w_3dpw.pth.tar'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'VIBE_PATH'", "]", ")", ":", "\n", "        ", "frame_ids", ",", "dataloader", ",", "bbox", "=", "get_person_dataloader", "(", "key", ",", "crop_size", "=", "crop_size", ")", "\n", "\n", "from", "lib", ".", "models", ".", "vibe", "import", "VIBE_Demo", "\n", "\n", "device", "=", "'cuda'", "\n", "has_keypoints", "=", "False", "\n", "model", "=", "VIBE_Demo", "(", "\n", "seqlen", "=", "16", ",", "\n", "n_layers", "=", "2", ",", "\n", "hidden_size", "=", "1024", ",", "\n", "add_linear", "=", "True", ",", "\n", "use_residual", "=", "True", ",", "\n", "pretrained", "=", "spin_checkpoint", "\n", ")", ".", "to", "(", "'cuda'", ")", "\n", "\n", "ckpt", "=", "torch", ".", "load", "(", "vibe_checkpoint", ")", "\n", "ckpt", "=", "ckpt", "[", "'gen_state_dict'", "]", "\n", "model", ".", "load_state_dict", "(", "ckpt", ",", "strict", "=", "False", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_cam", ",", "pred_verts", ",", "pred_pose", ",", "pred_betas", ",", "pred_joints3d", ",", "smpl_joints2d", ",", "norm_joints2d", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "                ", "if", "has_keypoints", ":", "\n", "                    ", "batch", ",", "nj2d", "=", "batch", "\n", "norm_joints2d", ".", "append", "(", "nj2d", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "21", ",", "3", ")", ")", "\n", "\n", "", "batch", "=", "batch", ".", "unsqueeze", "(", "0", ")", "\n", "batch", "=", "batch", ".", "to", "(", "device", ")", "\n", "\n", "batch_size", ",", "seqlen", "=", "batch", ".", "shape", "[", ":", "2", "]", "\n", "output", "=", "model", "(", "batch", ")", "[", "-", "1", "]", "\n", "\n", "pred_cam", ".", "append", "(", "output", "[", "'theta'", "]", "[", ":", ",", ":", ",", ":", "3", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_verts", ".", "append", "(", "output", "[", "'verts'", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ",", "3", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_pose", ".", "append", "(", "output", "[", "'theta'", "]", "[", ":", ",", ":", ",", "3", ":", "75", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_betas", ".", "append", "(", "output", "[", "'theta'", "]", "[", ":", ",", ":", ",", "75", ":", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_joints3d", ".", "append", "(", "output", "[", "'kp_3d'", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ",", "3", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "smpl_joints2d", ".", "append", "(", "output", "[", "'kp_2d'", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "key", "[", "'cams'", "]", "=", "np", ".", "concatenate", "(", "pred_cam", ",", "axis", "=", "0", ")", "\n", "key", "[", "'verts'", "]", "=", "np", ".", "concatenate", "(", "pred_verts", ",", "axis", "=", "0", ")", "\n", "key", "[", "'poses'", "]", "=", "np", ".", "concatenate", "(", "pred_pose", ",", "axis", "=", "0", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "concatenate", "(", "pred_betas", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints3d'", "]", "=", "np", ".", "concatenate", "(", "pred_joints3d", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints2d'", "]", "=", "np", ".", "concatenate", "(", "smpl_joints2d", ",", "axis", "=", "0", ")", "\n", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "key", "[", "'cams'", "]", "=", "convert_crop_cam_to_orig_img", "(", "key", "[", "'cams'", "]", ",", "bbox", ",", "width", ",", "height", ")", "\n", "key", "[", "'joints2d'", "]", "=", "convert_crop_coords_to_orig_img", "(", "bbox", ",", "key", "[", "'joints2d'", "]", ",", "crop_size", ")", "\n", "\n", "return", "key", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.fairmot.fairmot_bounding_boxes": [[61, 135], ["os.path.join", "dataclasses.dataclass", "params.items", "cv2.VideoCapture", "int", "int", "int", "cv2.VideoCapture.release", "dataclasses.dataclass.__setattr__", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "pose_pipeline.env.add_path", "logger.setLevel", "datasets.LoadVideo", "int", "int", "JDETracker", "tqdm.tqdm", "datasets.LoadVideo.cap.get", "datasets.LoadVideo.cap.get", "enumerate", "torch.from_numpy().cuda().unsqueeze", "JDETracker.update", "tracks.append", "torch.from_numpy().cuda", "frame_result.append", "torch.from_numpy", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update"], ["def", "fairmot_bounding_boxes", "(", "file_path", ")", ":", "\n", "    ", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "model_config", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'fairmot/fairmot_dla34.pth'", ")", "\n", "\n", "opt", "=", "dataclass", "(", ")", "\n", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "opt", ".", "__setattr__", "(", "k", ",", "v", ")", "\n", "", "opt", ".", "load_model", "=", "model_config", "\n", "\n", "tracks", "=", "[", "]", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "file_path", ")", "\n", "width", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "height", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "cap", ".", "release", "(", ")", "\n", "\n", "if", "height", ">", "width", ":", "\n", "        ", "opt", ".", "img_size", "=", "(", "608", ",", "1088", ")", "\n", "\n", "", "with", "add_path", "(", "[", "os", ".", "environ", "[", "'FAIRMOT_PATH'", "]", ",", "os", ".", "environ", "[", "'DCNv2_PATH'", "]", "]", ")", ":", "\n", "        ", "import", "datasets", ".", "dataset", ".", "jde", "as", "datasets", "\n", "from", "tracking_utils", ".", "log", "import", "logger", "\n", "from", "tracker", ".", "multitracker", "import", "JDETracker", "\n", "from", "tracker", ".", "basetrack", "import", "BaseTrack", "\n", "\n", "# suppress logging output", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "# set up the data loader", "\n", "dataloader", "=", "datasets", ".", "LoadVideo", "(", "file_path", ",", "opt", ".", "img_size", ")", "\n", "fps", "=", "dataloader", ".", "frame_rate", "\n", "\n", "width", "=", "int", "(", "dataloader", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "height", "=", "int", "(", "dataloader", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "\n", "# account for the image rescaling the dataloader performs", "\n", "xscale", "=", "width", "/", "dataloader", ".", "w", "\n", "yscale", "=", "height", "/", "dataloader", ".", "h", "\n", "\n", "# prevents prior runs increasing track id", "\n", "BaseTrack", ".", "_count", "=", "0", "\n", "\n", "# and get the tracker", "\n", "tracker", "=", "JDETracker", "(", "opt", ",", "fps", ")", "\n", "\n", "for", "frame_id", ",", "(", "path", ",", "img", ",", "img0", ")", "in", "tqdm", "(", "enumerate", "(", "dataloader", ")", ")", ":", "\n", "\n", "            ", "blob", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "cuda", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "online_targets", "=", "tracker", ".", "update", "(", "blob", ",", "img0", ")", "\n", "\n", "frame_result", "=", "[", "]", "\n", "\n", "for", "t", "in", "online_targets", ":", "\n", "                ", "tlwh", "=", "t", ".", "tlwh", "\n", "vertical", "=", "tlwh", "[", "2", "]", "/", "tlwh", "[", "3", "]", ">", "1.6", "\n", "\n", "if", "True", ":", "#tlwh[2] * tlwh[3] > opt.min_box_area: # and not vertical:", "\n", "                    ", "x1", ",", "y1", ",", "w", ",", "h", "=", "tlwh", "\n", "\n", "# Note: this is using the name \"TLHW\" consistent with the other algorithms in the", "\n", "# pose_pipeline, but is actually ordered X, Y, W, H.", "\n", "frame_result", ".", "append", "(", "{", "'track_id'", ":", "t", ".", "track_id", ",", "\n", "'tlbr'", ":", "np", ".", "array", "(", "[", "x1", "*", "xscale", ",", "y1", "*", "yscale", ",", "(", "x1", "+", "w", ")", "*", "xscale", ",", "(", "y1", "+", "h", ")", "*", "yscale", "]", ")", ",", "\n", "'tlhw'", ":", "np", ".", "array", "(", "[", "x1", "*", "xscale", ",", "y1", "*", "yscale", ",", "w", "*", "xscale", ",", "h", "*", "yscale", "]", ")", ",", "\n", "'confidence'", ":", "t", ".", "score", "\n", "}", ")", "\n", "\n", "", "", "tracks", ".", "append", "(", "frame_result", ")", "\n", "\n", "", "del", "tracker", "\n", "\n", "return", "tracks", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.PixiePosePipeDataset.__init__": [[18, 47], ["cv2.VideoCapture", "cv2.VideoCapture.release", "os.remove", "numpy.where", "pose_pipeline.Video.get_robust_reader", "cv2.VideoCapture.read", "pixie.PixiePosePipeDataset.frames.append", "cv2.cvtColor"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader"], ["    ", "def", "__init__", "(", "self", ",", "key", ",", "blurred", "=", "False", ",", "iscrop", "=", "True", ",", "crop_size", "=", "224", ",", "hd_size", "=", "1024", ",", "scale", "=", "1.1", ",", "body_detector", "=", "'rcnn'", ",", "device", "=", "'cpu'", ")", ":", "\n", "\n", "        ", "self", ".", "key", "=", "key", "\n", "\n", "self", ".", "bbox", ",", "self", ".", "present", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ",", "'present'", ")", "\n", "\n", "self", ".", "frames", "=", "[", "]", "\n", "self", ".", "frame_ids", "=", "np", ".", "where", "(", "self", ".", "present", ")", "[", "0", "]", "\n", "\n", "if", "blurred", ":", "\n", "            ", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "", "else", ":", "\n", "            ", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "False", ")", "\n", "\n", "", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "while", "True", ":", "\n", "# should match the length of identified person tracks", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "", "self", ".", "frames", ".", "append", "(", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", ")", "\n", "", "cap", ".", "release", "(", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "hd_size", "=", "hd_size", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "iscrop", "=", "iscrop", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.PixiePosePipeDataset.__len__": [[48, 50], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "frame_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.PixiePosePipeDataset.__getitem__": [[51, 89], ["numpy.array", "skimage.transform.estimate_transform", "skimage.transform.warp", "dst_image.transpose.transpose.transpose", "numpy.array", "skimage.transform.estimate_transform", "skimage.transform.warp", "hd_image.transpose.transpose.transpose", "torch.tensor", "max", "numpy.array", "int", "numpy.array", "numpy.array", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "image.transpose", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "image.transpose"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "frame_id", "=", "self", ".", "frame_ids", "[", "index", "]", "\n", "image", "=", "self", ".", "frames", "[", "frame_id", "]", "\n", "bbox", "=", "self", ".", "bbox", "[", "frame_id", "]", "\n", "h", ",", "w", ",", "_", "=", "image", ".", "shape", "\n", "\n", "image_tensor", "=", "torch", ".", "tensor", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "[", "None", ",", "...", "]", "\n", "if", "self", ".", "iscrop", ":", "\n", "            ", "left", "=", "bbox", "[", "0", "]", ";", "right", "=", "left", "+", "bbox", "[", "2", "]", ";", "top", "=", "bbox", "[", "1", "]", ";", "bottom", "=", "top", "+", "bbox", "[", "3", "]", "\n", "old_size", "=", "max", "(", "right", "-", "left", ",", "bottom", "-", "top", ")", "\n", "center", "=", "np", ".", "array", "(", "[", "right", "-", "(", "right", "-", "left", ")", "/", "2.0", ",", "bottom", "-", "(", "bottom", "-", "top", ")", "/", "2.0", "]", ")", "\n", "size", "=", "int", "(", "old_size", "*", "self", ".", "scale", ")", "\n", "src_pts", "=", "np", ".", "array", "(", "[", "[", "center", "[", "0", "]", "-", "size", "/", "2", ",", "center", "[", "1", "]", "-", "size", "/", "2", "]", ",", "[", "center", "[", "0", "]", "-", "size", "/", "2", ",", "center", "[", "1", "]", "+", "size", "/", "2", "]", ",", "[", "center", "[", "0", "]", "+", "size", "/", "2", ",", "center", "[", "1", "]", "-", "size", "/", "2", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "src_pts", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "h", "-", "1", "]", ",", "[", "w", "-", "1", ",", "0", "]", "]", ")", "\n", "left", "=", "0", ";", "right", "=", "w", "-", "1", ";", "top", "=", "0", ";", "bottom", "=", "h", "-", "1", "\n", "bbox", "=", "[", "left", ",", "top", ",", "right", ",", "bottom", "]", "\n", "\n", "# crop image", "\n", "", "DST_PTS", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "self", ".", "crop_size", "-", "1", "]", ",", "[", "self", ".", "crop_size", "-", "1", ",", "0", "]", "]", ")", "\n", "tform", "=", "estimate_transform", "(", "'similarity'", ",", "src_pts", ",", "DST_PTS", ")", "\n", "dst_image", "=", "warp", "(", "image", ",", "tform", ".", "inverse", ",", "output_shape", "=", "(", "self", ".", "crop_size", ",", "self", ".", "crop_size", ")", ")", "\n", "dst_image", "=", "dst_image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "# hd image", "\n", "DST_PTS", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "self", ".", "hd_size", "-", "1", "]", ",", "[", "self", ".", "hd_size", "-", "1", ",", "0", "]", "]", ")", "\n", "tform_hd", "=", "estimate_transform", "(", "'similarity'", ",", "src_pts", ",", "DST_PTS", ")", "\n", "hd_image", "=", "warp", "(", "image", ",", "tform_hd", ".", "inverse", ",", "output_shape", "=", "(", "self", ".", "hd_size", ",", "self", ".", "hd_size", ")", ")", "\n", "hd_image", "=", "hd_image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "# crop image", "\n", "return", "{", "'image'", ":", "torch", ".", "tensor", "(", "dst_image", ")", ".", "float", "(", ")", ",", "\n", "#'name': imagename,", "\n", "#'imagepath': imagepath,", "\n", "'image_hd'", ":", "torch", ".", "tensor", "(", "hd_image", ")", ".", "float", "(", ")", ",", "\n", "'tform'", ":", "torch", ".", "tensor", "(", "tform", ".", "params", ")", ".", "float", "(", ")", ",", "\n", "'original_image'", ":", "torch", ".", "tensor", "(", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ".", "float", "(", ")", ",", "\n", "'bbox'", ":", "bbox", ",", "\n", "'size'", ":", "size", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.process_pixie": [[92, 146], ["pixie.PixiePosePipeDataset", "torch.utils.data.DataLoader", "smplx[].cpu().detach().numpy", "smplx[].cpu().detach().numpy", "smplx[].cpu().detach().numpy", "pose_pipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "pose_pipeline.env.add_path", "PIXIE", "body.keys", "PIXIE.decode", "torch.no_grad", "tqdm.tqdm", "numpy.concatenate", "smplx[].cpu().detach", "smplx[].cpu().detach", "smplx[].cpu().detach", "util.move_dict_to_device", "PIXIE.encode", "body.items", "torch.tensor().to", "results[].append", "results.items", "smplx[].cpu", "smplx[].cpu", "smplx[].cpu", "v.detach().cpu().numpy", "torch.tensor", "v.detach().cpu", "v.detach"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "", "def", "process_pixie", "(", "key", ")", ":", "\n", "\n", "    ", "crop_size", "=", "224", "\n", "\n", "dataset", "=", "PixiePosePipeDataset", "(", "key", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "32", ",", "num_workers", "=", "4", ")", "\n", "bbox", ",", "present", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ",", "'present'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'PIXIE_PATH'", "]", ")", ":", "\n", "\n", "        ", "from", "pixielib", ".", "pixie", "import", "PIXIE", "\n", "from", "pixielib", ".", "utils", "import", "util", "\n", "from", "pixielib", ".", "utils", ".", "config", "import", "cfg", "as", "pixie_cfg", "\n", "\n", "device", "=", "'cuda'", "\n", "\n", "pixie_cfg", ".", "model", ".", "use_tex", "=", "False", "\n", "pixie", "=", "PIXIE", "(", "config", "=", "pixie_cfg", ",", "device", "=", "device", ")", "\n", "\n", "results", "=", "{", "'body_cam'", ":", "[", "]", ",", "'global_pose'", ":", "[", "]", ",", "'partbody_pose'", ":", "[", "]", ",", "\n", "'neck_pose'", ":", "[", "]", ",", "'shape'", ":", "[", "]", ",", "'exp'", ":", "[", "]", ",", "'head_pose'", ":", "[", "]", ",", "\n", "'jaw_pose'", ":", "[", "]", ",", "'left_hand_pose'", ":", "[", "]", ",", "'left_wrist_pose'", ":", "[", "]", ",", "\n", "'right_wrist_pose'", ":", "[", "]", ",", "'right_hand_pose'", ":", "[", "]", ",", "'tex'", ":", "[", "]", ",", "\n", "'light'", ":", "[", "]", "}", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "for", "batch", "in", "tqdm", "(", "dataloader", ")", ":", "\n", "\n", "                ", "util", ".", "move_dict_to_device", "(", "batch", ",", "device", ")", "\n", "\n", "param_dict", "=", "pixie", ".", "encode", "(", "{", "'body'", ":", "batch", "}", ")", "\n", "\n", "body", "=", "param_dict", "[", "'body'", "]", "\n", "for", "k", ",", "v", "in", "body", ".", "items", "(", ")", ":", "\n", "                    ", "results", "[", "k", "]", ".", "append", "(", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "for", "k", "in", "body", ".", "keys", "(", ")", ":", "\n", "            ", "results", "[", "k", "]", "=", "np", ".", "concatenate", "(", "results", "[", "k", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "smplx", "=", "pixie", ".", "decode", "(", "{", "k", ":", "torch", ".", "tensor", "(", "v", ")", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", "}", ",", "param_type", "=", "'body'", ")", "\n", "\n", "", "key", "[", "'cams'", "]", "=", "results", "[", "'body_cam'", "]", "\n", "key", "[", "'verts'", "]", "=", "smplx", "[", "'vertices'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "key", "[", "'poses'", "]", "=", "results", "\n", "key", "[", "'betas'", "]", "=", "results", "[", "'shape'", "]", "\n", "key", "[", "'joints3d'", "]", "=", "smplx", "[", "'smplx_kpt3d'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "key", "[", "'joints2d'", "]", "=", "smplx", "[", "'smplx_kpt'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "#height, width = (VideoInfo & key).fetch1('height', 'width')", "\n", "#key['cams'] = convert_crop_cam_to_orig_img(key['cams'], bbox, width, height)", "\n", "key", "[", "'joints2d'", "]", "=", "convert_crop_coords_to_orig_img", "(", "bbox", "[", "present", "]", ",", "key", "[", "'joints2d'", "]", ",", "crop_size", ")", "\n", "\n", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pixie.get_pixie_callback": [[147, 199], ["pixie.PixiePosePipeDataset", "pose_pipeline.env.add_path", "PIXIE", "Visualizer", "sample[].unsqueeze().to", "PIXIE.decode", "torch.inverse().transpose().to", "Visualizer.recover_position", "Visualizer.render_results", "np.clip().astype.transpose", "numpy.clip().astype", "numpy.where", "len", "torch.tensor().to", "sample[].to", "visdict[].detach().cpu().numpy", "results.items", "sample[].unsqueeze", "torch.inverse().transpose", "numpy.clip", "torch.tensor", "visdict[].detach().cpu", "torch.inverse", "visdict[].detach"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "get_pixie_callback", "(", "key", ")", ":", "\n", "\n", "    ", "results", "=", "(", "SMPLPerson", "&", "key", ")", ".", "fetch1", "(", "'poses'", ")", "\n", "dataset", "=", "PixiePosePipeDataset", "(", "key", ",", "blurred", "=", "True", ")", "\n", "frame_ids", "=", "dataset", ".", "frame_ids", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'PIXIE_PATH'", "]", ")", ":", "\n", "\n", "        ", "from", "pixielib", ".", "pixie", "import", "PIXIE", "\n", "from", "pixielib", ".", "visualizer", "import", "Visualizer", "\n", "from", "pixielib", ".", "utils", "import", "util", "\n", "from", "pixielib", ".", "utils", ".", "config", "import", "cfg", "as", "pixie_cfg", "\n", "\n", "device", "=", "'cuda'", "\n", "\n", "pixie_cfg", ".", "model", ".", "use_tex", "=", "False", "\n", "pixie", "=", "PIXIE", "(", "config", "=", "pixie_cfg", ",", "device", "=", "device", ")", "\n", "\n", "visualizer", "=", "Visualizer", "(", "render_size", "=", "224", ",", "config", "=", "pixie_cfg", ",", "device", "=", "device", ",", "rasterizer_type", "=", "'standard'", ")", "\n", "\n", "def", "overlay", "(", "image", ",", "idx", ")", ":", "\n", "\n", "            ", "idx", "=", "np", ".", "where", "(", "frame_ids", "==", "idx", ")", "[", "0", "]", "\n", "if", "len", "(", "idx", ")", "==", "1", ":", "\n", "                ", "idx", "=", "idx", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "return", "image", "\n", "\n", "", "poses", "=", "{", "k", ":", "torch", ".", "tensor", "(", "v", "[", "None", ",", "idx", "]", ")", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", "}", "\n", "sample", "=", "dataset", "[", "idx", "]", "\n", "sample", "[", "'image'", "]", "=", "sample", "[", "'image'", "]", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "\n", "\n", "opdict", "=", "pixie", ".", "decode", "(", "poses", ",", "param_type", "=", "'body'", ")", "# pass through SMPLX", "\n", "\n", "tform", "=", "sample", "[", "'tform'", "]", "[", "None", ",", "...", "]", "\n", "tform", "=", "torch", ".", "inverse", "(", "tform", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "to", "(", "device", ")", "\n", "original_image", "=", "sample", "[", "'original_image'", "]", "[", "None", ",", "...", "]", "/", "256.0", "\n", "\n", "# should be the same as the passed in image.", "\n", "# TODO: need to handled frames with missed bounding boxes", "\n", "visualizer", ".", "recover_position", "(", "opdict", ",", "sample", ",", "tform", ",", "original_image", ")", "\n", "\n", "visdict", "=", "visualizer", ".", "render_results", "(", "opdict", ",", "sample", "[", "'image_hd'", "]", ".", "to", "(", "device", ")", ",", "overlay", "=", "True", ")", "#, use_deca=True, moderator_weight=param_dict['moderator_weight'])", "\n", "\n", "# color_shape_images", "\n", "image_out", "=", "visdict", "[", "'shape_images'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "image_out", "=", "image_out", ".", "transpose", "(", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "image_out", "=", "np", ".", "clip", "(", "image_out", "*", "255", ",", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "return", "image_out", "\n", "\n", "", "", "return", "overlay", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.meva.process_meva": [[10, 75], ["os.path.join", "os.path.join", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "pose_pipeline.utils.bounding_box.convert_crop_cam_to_orig_img", "pose_pipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "pose_pipeline.env.add_path", "pose_pipeline.utils.bounding_box.get_person_dataloader", "update_cfg", "MEVA_demo().to", "torch.load", "MEVA_demo().to.load_state_dict", "MEVA_demo().to.eval", "torch.no_grad", "MEVA_demo", "batch.unsqueeze", "batch_image.to.to", "pred_cam.append", "pred_verts.append", "pred_pose.append", "pred_betas.append", "pred_joints3d.append", "norm_joints2d.append", "MEVA_demo().to.", "[].reshape().cpu().detach().numpy", "output[].reshape().cpu().detach().numpy", "[].reshape().cpu().detach().numpy", "[].reshape().cpu().detach().numpy", "output[].reshape().cpu().detach().numpy", "output[].reshape().cpu().detach().numpy", "[].reshape().cpu().detach", "output[].reshape().cpu().detach", "[].reshape().cpu().detach", "[].reshape().cpu().detach", "output[].reshape().cpu().detach", "output[].reshape().cpu().detach", "[].reshape().cpu", "output[].reshape().cpu", "[].reshape().cpu", "[].reshape().cpu", "output[].reshape().cpu", "output[].reshape().cpu", "[].reshape", "output[].reshape", "[].reshape", "[].reshape", "output[].reshape", "output[].reshape"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_cam_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.get_person_dataloader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["def", "process_meva", "(", "key", ")", ":", "\n", "\n", "    ", "crop_size", "=", "224", "\n", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "from", "pose_pipeline", ".", "utils", ".", "bounding_box", "import", "get_person_dataloader", "\n", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'meva/train_meva_2.yml'", ")", "\n", "pretrained_model", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'meva/model_best.pth.tar'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'MEVA_PATH'", "]", ")", ":", "\n", "        ", "frame_ids", ",", "dataloader", ",", "bbox", "=", "get_person_dataloader", "(", "key", ",", "crop_size", "=", "crop_size", ")", "\n", "\n", "from", "meva", ".", "lib", ".", "meva_model", "import", "MEVA", ",", "MEVA_demo", "\n", "from", "meva", ".", "utils", ".", "video_config", "import", "update_cfg", "\n", "\n", "device", "=", "'cuda'", "\n", "\n", "cfg", "=", "update_cfg", "(", "config_file", ")", "\n", "model", "=", "MEVA_demo", "(", "\n", "n_layers", "=", "cfg", ".", "MODEL", ".", "TGRU", ".", "NUM_LAYERS", ",", "\n", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "\n", "seqlen", "=", "cfg", ".", "DATASET", ".", "SEQLEN", ",", "\n", "hidden_size", "=", "cfg", ".", "MODEL", ".", "TGRU", ".", "HIDDEN_SIZE", ",", "\n", "add_linear", "=", "cfg", ".", "MODEL", ".", "TGRU", ".", "ADD_LINEAR", ",", "\n", "bidirectional", "=", "cfg", ".", "MODEL", ".", "TGRU", ".", "BIDIRECTIONAL", ",", "\n", "use_residual", "=", "cfg", ".", "MODEL", ".", "TGRU", ".", "RESIDUAL", ",", "\n", "cfg", "=", "cfg", ".", "VAE_CFG", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "ckpt", "=", "torch", ".", "load", "(", "pretrained_model", ")", "\n", "ckpt", "=", "ckpt", "[", "'gen_state_dict'", "]", "\n", "model", ".", "load_state_dict", "(", "ckpt", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_cam", ",", "pred_verts", ",", "pred_pose", ",", "pred_betas", ",", "pred_joints3d", ",", "norm_joints2d", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "\n", "                ", "batch_image", "=", "batch", ".", "unsqueeze", "(", "0", ")", "\n", "batch_image", "=", "batch_image", ".", "to", "(", "device", ")", "\n", "\n", "batch_size", ",", "seqlen", "=", "batch_image", ".", "shape", "[", ":", "2", "]", "\n", "output", "=", "model", "(", "batch_image", ")", "[", "-", "1", "]", "\n", "\n", "pred_cam", ".", "append", "(", "output", "[", "'theta'", "]", "[", ":", ",", ":", ",", ":", "3", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_verts", ".", "append", "(", "output", "[", "'verts'", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ",", "3", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_pose", ".", "append", "(", "output", "[", "'theta'", "]", "[", ":", ",", ":", ",", "3", ":", "75", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_betas", ".", "append", "(", "output", "[", "'theta'", "]", "[", ":", ",", ":", ",", "75", ":", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_joints3d", ".", "append", "(", "output", "[", "'kp_3d'", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ",", "3", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "norm_joints2d", ".", "append", "(", "output", "[", "'kp_2d'", "]", ".", "reshape", "(", "batch_size", "*", "seqlen", ",", "-", "1", ",", "2", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "key", "[", "'cams'", "]", "=", "np", ".", "concatenate", "(", "pred_cam", ",", "axis", "=", "0", ")", "\n", "key", "[", "'verts'", "]", "=", "np", ".", "concatenate", "(", "pred_verts", ",", "axis", "=", "0", ")", "\n", "key", "[", "'poses'", "]", "=", "np", ".", "concatenate", "(", "pred_pose", ",", "axis", "=", "0", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "concatenate", "(", "pred_betas", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints3d'", "]", "=", "np", ".", "concatenate", "(", "pred_joints3d", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints2d'", "]", "=", "np", ".", "concatenate", "(", "norm_joints2d", ",", "axis", "=", "0", ")", "\n", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "key", "[", "'cams'", "]", "=", "convert_crop_cam_to_orig_img", "(", "key", "[", "'cams'", "]", ",", "bbox", ",", "width", ",", "height", ")", "\n", "key", "[", "'joints2d'", "]", "=", "convert_crop_coords_to_orig_img", "(", "bbox", ",", "key", "[", "'joints2d'", "]", ",", "crop_size", ")", "\n", "\n", "return", "key", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.pare.process_pare": [[12, 115], ["os.path.join", "os.path.join", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "pose_pipeline.utils.bounding_box.convert_crop_cam_to_orig_img", "pose_pipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "pose_pipeline.env.add_path", "update_hparams", "PARE().to", "ckpt.keys", "collections.OrderedDict", "PARE().to.load_state_dict", "PARE().to.eval", "pose_pipeline.utils.bounding_box.get_person_dataloader", "torch.load", "pk.startswith", "torch.no_grad", "tqdm.tqdm", "PARE", "numpy.array().reshape", "batch.to.to", "PARE().to.", "pred_cam.append", "pred_verts.append", "pred_pose.append", "pred_betas.append", "pred_joints3d.append", "smpl_joints2d.append", "output[].cpu().detach().numpy", "output[].cpu().detach().numpy", "to_rotvec", "output[].cpu().detach().numpy", "output[].cpu().detach().numpy", "output[].cpu().detach().numpy", "pk.replace", "numpy.array", "output[].cpu().detach().numpy", "list", "output[].cpu().detach", "output[].cpu().detach", "output[].cpu().detach", "output[].cpu().detach", "output[].cpu().detach", "map", "output[].cpu().detach", "output[].cpu", "output[].cpu", "output[].cpu", "output[].cpu", "output[].cpu", "R.from_matrix().as_rotvec", "output[].cpu", "R.from_matrix"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_cam_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.get_person_dataloader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["def", "process_pare", "(", "key", ")", ":", "\n", "\n", "    ", "crop_size", "=", "224", "\n", "\n", "pare_config", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'pare/pare_w_3dpw_config.yaml'", ")", "\n", "pare_checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'pare/pare_w_3dpw_checkpoint.ckpt'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'PARE_PATH'", "]", ")", ":", "\n", "\n", "        ", "from", "pare", ".", "core", ".", "config", "import", "get_hparams_defaults", ",", "update_hparams", ",", "update_hparams_from_dict", "\n", "from", "pare", ".", "models", "import", "PARE", "\n", "\n", "model_cfg", "=", "update_hparams", "(", "pare_config", ")", "\n", "\n", "device", "=", "'cuda'", "\n", "model", "=", "PARE", "(", "\n", "backbone", "=", "model_cfg", ".", "PARE", ".", "BACKBONE", ",", "\n", "num_joints", "=", "model_cfg", ".", "PARE", ".", "NUM_JOINTS", ",", "\n", "softmax_temp", "=", "model_cfg", ".", "PARE", ".", "SOFTMAX_TEMP", ",", "\n", "num_features_smpl", "=", "model_cfg", ".", "PARE", ".", "NUM_FEATURES_SMPL", ",", "\n", "focal_length", "=", "model_cfg", ".", "DATASET", ".", "FOCAL_LENGTH", ",", "\n", "img_res", "=", "model_cfg", ".", "DATASET", ".", "IMG_RES", ",", "\n", "pretrained", "=", "model_cfg", ".", "TRAINING", ".", "PRETRAINED", ",", "\n", "iterative_regression", "=", "model_cfg", ".", "PARE", ".", "ITERATIVE_REGRESSION", ",", "\n", "num_iterations", "=", "model_cfg", ".", "PARE", ".", "NUM_ITERATIONS", ",", "\n", "iter_residual", "=", "model_cfg", ".", "PARE", ".", "ITER_RESIDUAL", ",", "\n", "shape_input_type", "=", "model_cfg", ".", "PARE", ".", "SHAPE_INPUT_TYPE", ",", "\n", "pose_input_type", "=", "model_cfg", ".", "PARE", ".", "POSE_INPUT_TYPE", ",", "\n", "pose_mlp_num_layers", "=", "model_cfg", ".", "PARE", ".", "POSE_MLP_NUM_LAYERS", ",", "\n", "shape_mlp_num_layers", "=", "model_cfg", ".", "PARE", ".", "SHAPE_MLP_NUM_LAYERS", ",", "\n", "pose_mlp_hidden_size", "=", "model_cfg", ".", "PARE", ".", "POSE_MLP_HIDDEN_SIZE", ",", "\n", "shape_mlp_hidden_size", "=", "model_cfg", ".", "PARE", ".", "SHAPE_MLP_HIDDEN_SIZE", ",", "\n", "use_keypoint_features_for_smpl_regression", "=", "model_cfg", ".", "PARE", ".", "USE_KEYPOINT_FEATURES_FOR_SMPL_REGRESSION", ",", "\n", "use_heatmaps", "=", "model_cfg", ".", "DATASET", ".", "USE_HEATMAPS", ",", "\n", "use_keypoint_attention", "=", "model_cfg", ".", "PARE", ".", "USE_KEYPOINT_ATTENTION", ",", "\n", "use_postconv_keypoint_attention", "=", "model_cfg", ".", "PARE", ".", "USE_POSTCONV_KEYPOINT_ATTENTION", ",", "\n", "use_scale_keypoint_attention", "=", "model_cfg", ".", "PARE", ".", "USE_SCALE_KEYPOINT_ATTENTION", ",", "\n", "keypoint_attention_act", "=", "model_cfg", ".", "PARE", ".", "KEYPOINT_ATTENTION_ACT", ",", "\n", "use_final_nonlocal", "=", "model_cfg", ".", "PARE", ".", "USE_FINAL_NONLOCAL", ",", "\n", "use_branch_nonlocal", "=", "model_cfg", ".", "PARE", ".", "USE_BRANCH_NONLOCAL", ",", "\n", "use_hmr_regression", "=", "model_cfg", ".", "PARE", ".", "USE_HMR_REGRESSION", ",", "\n", "use_coattention", "=", "model_cfg", ".", "PARE", ".", "USE_COATTENTION", ",", "\n", "num_coattention_iter", "=", "model_cfg", ".", "PARE", ".", "NUM_COATTENTION_ITER", ",", "\n", "coattention_conv", "=", "model_cfg", ".", "PARE", ".", "COATTENTION_CONV", ",", "\n", "use_upsampling", "=", "model_cfg", ".", "PARE", ".", "USE_UPSAMPLING", ",", "\n", "deconv_conv_kernel_size", "=", "model_cfg", ".", "PARE", ".", "DECONV_CONV_KERNEL_SIZE", ",", "\n", "use_soft_attention", "=", "model_cfg", ".", "PARE", ".", "USE_SOFT_ATTENTION", ",", "\n", "num_branch_iteration", "=", "model_cfg", ".", "PARE", ".", "NUM_BRANCH_ITERATION", ",", "\n", "branch_deeper", "=", "model_cfg", ".", "PARE", ".", "BRANCH_DEEPER", ",", "\n", "num_deconv_layers", "=", "model_cfg", ".", "PARE", ".", "NUM_DECONV_LAYERS", ",", "\n", "num_deconv_filters", "=", "model_cfg", ".", "PARE", ".", "NUM_DECONV_FILTERS", ",", "\n", "use_resnet_conv_hrnet", "=", "model_cfg", ".", "PARE", ".", "USE_RESNET_CONV_HRNET", ",", "\n", "use_position_encodings", "=", "model_cfg", ".", "PARE", ".", "USE_POS_ENC", ",", "\n", "use_mean_camshape", "=", "model_cfg", ".", "PARE", ".", "USE_MEAN_CAMSHAPE", ",", "\n", "use_mean_pose", "=", "model_cfg", ".", "PARE", ".", "USE_MEAN_POSE", ",", "\n", "init_xavier", "=", "model_cfg", ".", "PARE", ".", "INIT_XAVIER", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "ckpt", "=", "torch", ".", "load", "(", "pare_checkpoint", ")", "[", "'state_dict'", "]", "\n", "pretrained_keys", "=", "ckpt", ".", "keys", "(", ")", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "pk", "in", "pretrained_keys", ":", "\n", "            ", "if", "pk", ".", "startswith", "(", "'model.'", ")", ":", "\n", "                ", "new_state_dict", "[", "pk", ".", "replace", "(", "'model.'", ",", "''", ")", "]", "=", "ckpt", "[", "pk", "]", "\n", "", "else", ":", "\n", "                ", "new_state_dict", "[", "pk", "]", "=", "ckpt", "[", "pk", "]", "\n", "", "", "model", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", "=", "False", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "frame_ids", ",", "dataloader", ",", "bbox", "=", "get_person_dataloader", "(", "key", ",", "crop_size", "=", "crop_size", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_cam", ",", "pred_verts", ",", "pred_pose", ",", "pred_betas", ",", "pred_joints3d", ",", "smpl_joints2d", ",", "norm_joints2d", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "from", "scipy", ".", "spatial", ".", "transform", "import", "Rotation", "as", "R", "\n", "to_rotvec", "=", "lambda", "x", ":", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "y", ":", "R", ".", "from_matrix", "(", "y", ")", ".", "as_rotvec", "(", ")", ",", "x", ")", ")", ")", ".", "reshape", "(", "-", "1", ",", "72", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ")", ":", "\n", "\n", "                ", "batch", "=", "batch", ".", "to", "(", "device", ")", "\n", "\n", "batch_size", ",", "seqlen", "=", "batch", ".", "shape", "[", ":", "2", "]", "\n", "output", "=", "model", "(", "batch", ")", "\n", "\n", "pred_cam", ".", "append", "(", "output", "[", "'pred_cam'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_verts", ".", "append", "(", "output", "[", "'smpl_vertices'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_pose", ".", "append", "(", "to_rotvec", "(", "output", "[", "'pred_pose'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "pred_betas", ".", "append", "(", "output", "[", "'pred_shape'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_joints3d", ".", "append", "(", "output", "[", "'smpl_joints3d'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "smpl_joints2d", ".", "append", "(", "output", "[", "'smpl_joints2d'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "key", "[", "'cams'", "]", "=", "np", ".", "concatenate", "(", "pred_cam", ",", "axis", "=", "0", ")", "\n", "key", "[", "'verts'", "]", "=", "np", ".", "concatenate", "(", "pred_verts", ",", "axis", "=", "0", ")", "\n", "key", "[", "'poses'", "]", "=", "np", ".", "concatenate", "(", "pred_pose", ",", "axis", "=", "0", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "concatenate", "(", "pred_betas", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints3d'", "]", "=", "np", ".", "concatenate", "(", "pred_joints3d", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints2d'", "]", "=", "np", ".", "concatenate", "(", "smpl_joints2d", ",", "axis", "=", "0", ")", "\n", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "key", "[", "'cams'", "]", "=", "convert_crop_cam_to_orig_img", "(", "key", "[", "'cams'", "]", ",", "bbox", ",", "width", ",", "height", ")", "\n", "key", "[", "'joints2d'", "]", "=", "convert_crop_coords_to_orig_img", "(", "bbox", ",", "key", "[", "'joints2d'", "]", ",", "crop_size", ")", "\n", "\n", "return", "key", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.transtrack.transtrack_bounding_boxes": [[43, 123], ["os.path.join", "dataclasses.dataclass", "params.items", "cv2.VideoCapture", "int", "int", "int", "torch.tensor().to", "dataclasses.dataclass.__setattr__", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "pose_pipeline.env.add_path", "build_tracktrain_model", "model.eval", "torch.load", "model.load_state_dict", "model.to", "transforms.Compose", "Tracker", "Tracker.reset_all", "tqdm.tqdm", "torch.tensor", "range", "cv2.VideoCapture.read", "cv2.cvtColor", "[].to", "model", "tracks.append", "transforms.ToTensor", "transforms.Normalize", "print", "Tracker.init_track", "Tracker.step", "numpy.array", "numpy.array", "transtrack.transtrack_bounding_boxes.parse_result"], "function", ["None"], ["def", "transtrack_bounding_boxes", "(", "file_path", ")", ":", "\n", "\n", "    ", "import", "torch", "\n", "from", "torchvision", "import", "transforms", "\n", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'transtrack/671mot17_crowdhuman_mot17.pth'", ")", "\n", "\n", "opt", "=", "dataclass", "(", ")", "\n", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "opt", ".", "__setattr__", "(", "k", ",", "v", ")", "\n", "\n", "", "cap", "=", "cv2", ".", "VideoCapture", "(", "file_path", ")", "\n", "\n", "width", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "height", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n", "img_size", "=", "torch", ".", "tensor", "(", "[", "[", "height", ",", "width", "]", "]", ")", ".", "to", "(", "'cuda'", ")", "\n", "\n", "tracks", "=", "[", "]", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"TRANSTRACK_PATH\"", "]", ")", ":", "\n", "\n", "        ", "from", "models", "import", "Tracker", "\n", "from", "models", "import", "build_tracktrain_model", "\n", "\n", "# load model", "\n", "model", ",", "criterion", ",", "postprocessors", "=", "build_tracktrain_model", "(", "opt", ")", "\n", "model", ".", "eval", "(", ")", ";", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "model", ".", "to", "(", "'cuda'", ")", ";", "\n", "\n", "# transform to preprocess images", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "# set up tracker", "\n", "tracker", "=", "Tracker", "(", "params", "[", "'track_thresh'", "]", ")", "\n", "tracker", ".", "reset_all", "(", ")", "\n", "\n", "tracks", "=", "[", "]", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "frames", ")", ")", ":", "\n", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "                ", "print", "(", "'Failed to read a frame'", ")", "\n", "break", "\n", "\n", "", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "frame", "=", "transform", "(", "frame", ")", "[", "None", ",", "...", "]", ".", "to", "(", "'cuda'", ")", "\n", "\n", "outputs", "=", "model", "(", "frame", ")", "\n", "results", "=", "postprocessors", "[", "'bbox'", "]", "(", "outputs", "[", "0", "]", ",", "img_size", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "res_track", "=", "tracker", ".", "init_track", "(", "results", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "res_track", "=", "tracker", ".", "step", "(", "results", "[", "0", "]", ")", "\n", "\n", "", "del", "frame", "\n", "del", "outputs", "\n", "\n", "tracks", ".", "append", "(", "res_track", ")", "\n", "\n", "", "del", "tracker", "\n", "del", "model", "\n", "\n", "def", "parse_result", "(", "x", ")", ":", "\n", "            ", "return", "{", "'track_id'", ":", "x", "[", "'tracking_id'", "]", ",", "\n", "'tlbr'", ":", "np", ".", "array", "(", "x", "[", "'bbox'", "]", ")", ",", "\n", "'tlhw'", ":", "np", ".", "array", "(", "[", "*", "x", "[", "'bbox'", "]", "[", ":", "2", "]", ",", "x", "[", "'bbox'", "]", "[", "2", "]", "-", "x", "[", "'bbox'", "]", "[", "0", "]", ",", "x", "[", "'bbox'", "]", "[", "3", "]", "-", "x", "[", "'bbox'", "]", "[", "1", "]", "]", ")", ",", "\n", "'confidence'", ":", "x", "[", "'score'", "]", "}", "\n", "\n", "", "return", "[", "[", "parse_result", "(", "x", ")", "for", "x", "in", "frame", "]", "for", "frame", "in", "tracks", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.OpenposeParser.__init__": [[39, 101], ["op.WrapperPython", "openpose.OpenposeParser.opWrapper.configure", "openpose.OpenposeParser.opWrapper.start", "os.path.join", "op.Rectangle", "op.Rectangle", "op.Rectangle", "op.Rectangle", "op.Rectangle", "op.Rectangle", "op.Rectangle", "op.Rectangle", "op.Rectangle", "os.path.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "openpose_model_path", "=", "None", ",", "\n", "max_people", "=", "3", ",", "render", "=", "True", ",", "\n", "results_path", "=", "None", ",", "hand", "=", "False", ",", "face", "=", "False", ")", ":", "\n", "\n", "        ", "from", "openpose", "import", "pyopenpose", "as", "op", "\n", "if", "openpose_model_path", "is", "None", ":", "\n", "            ", "openpose_model_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "op", ".", "__file__", ")", "[", "0", "]", ",", "'../../../models'", ")", "\n", "\n", "", "self", ".", "faceRectangles", "=", "[", "\n", "op", ".", "Rectangle", "(", "330.119385", ",", "277.532715", ",", "48.717274", ",", "48.717274", ")", ",", "\n", "op", ".", "Rectangle", "(", "24.036991", ",", "267.918793", ",", "65.175171", ",", "65.175171", ")", ",", "\n", "op", ".", "Rectangle", "(", "151.803436", ",", "32.477852", ",", "108.295761", ",", "108.295761", ")", ",", "\n", "]", "\n", "\n", "self", ".", "handRectangles", "=", "[", "\n", "# Left/Right hands person 0", "\n", "[", "\n", "op", ".", "Rectangle", "(", "320.035889", ",", "377.675049", ",", "69.300949", ",", "69.300949", ")", ",", "\n", "op", ".", "Rectangle", "(", "0.", ",", "0.", ",", "0.", ",", "0.", ")", ",", "\n", "]", ",", "\n", "# Left/Right hands person 1", "\n", "[", "\n", "op", ".", "Rectangle", "(", "80.155792", ",", "407.673492", ",", "80.812706", ",", "80.812706", ")", ",", "\n", "op", ".", "Rectangle", "(", "46.449715", ",", "404.559753", ",", "98.898178", ",", "98.898178", ")", ",", "\n", "]", ",", "\n", "# Left/Right hands person 2", "\n", "[", "\n", "op", ".", "Rectangle", "(", "185.692673", ",", "303.112244", ",", "157.587555", ",", "157.587555", ")", ",", "\n", "op", ".", "Rectangle", "(", "88.984360", ",", "268.866547", ",", "117.818230", ",", "117.818230", ")", ",", "\n", "]", "\n", "]", "\n", "params", "=", "{", "'model_folder'", ":", "openpose_model_path", ",", "\n", "'number_people_max'", ":", "max_people", "}", "\n", "\n", "params", "[", "\"body\"", "]", "=", "1", "\n", "\n", "self", ".", "face", "=", "face", "\n", "self", ".", "hand", "=", "hand", "\n", "self", ".", "render", "=", "render", "\n", "\n", "if", "self", ".", "face", ":", "\n", "            ", "params", "[", "\"face\"", "]", "=", "True", "\n", "params", "[", "\"face_detector\"", "]", "=", "0", "\n", "\n", "", "if", "self", ".", "hand", ":", "\n", "            ", "params", "[", "\"hand\"", "]", "=", "True", "\n", "params", "[", "\"hand_detector\"", "]", "=", "0", "\n", "\n", "", "if", "results_path", "is", "not", "None", ":", "\n", "            ", "params", "[", "'write_json'", "]", "=", "results_path", "\n", "", "else", ":", "\n", "            ", "params", "[", "'write_json'", "]", "=", "'/tmp/openpose'", "\n", "\n", "", "if", "not", "render", ":", "\n", "            ", "params", "[", "'render_pose'", "]", "=", "0", "\n", "\n", "\n", "", "params", "[", "'model_pose'", "]", "=", "'BODY_25'", "\n", "\n", "self", ".", "opWrapper", "=", "op", ".", "WrapperPython", "(", ")", "\n", "self", ".", "opWrapper", ".", "configure", "(", "params", ")", "\n", "self", ".", "opWrapper", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.OpenposeParser.process_frame": [[102, 120], ["op.Datum", "openpose.OpenposeParser.opWrapper.emplaceAndPop", "op.VectorDatum"], "methods", ["None"], ["", "def", "process_frame", "(", "self", ",", "im", ")", ":", "\n", "        ", "from", "openpose", "import", "pyopenpose", "as", "op", "\n", "\n", "datum", "=", "op", ".", "Datum", "(", ")", "\n", "datum", ".", "cvInputData", "=", "im", "\n", "datum", ".", "faceRectangles", "=", "self", ".", "faceRectangles", "\n", "datum", ".", "handRectangles", "=", "self", ".", "handRectangles", "\n", "self", ".", "opWrapper", ".", "emplaceAndPop", "(", "op", ".", "VectorDatum", "(", "[", "datum", "]", ")", ")", "\n", "\n", "results", "=", "{", "'im'", ":", "datum", ".", "cvOutputData", "if", "self", ".", "render", "else", "None", ",", "\n", "'keypoints'", ":", "datum", ".", "poseKeypoints", ",", "\n", "'hand_keypoints'", ":", "datum", ".", "handKeypoints", "if", "self", ".", "hand", "else", "None", ",", "\n", "'face_keypoints'", ":", "datum", ".", "faceKeypoints", "if", "self", ".", "face", "else", "None", "}", "\n", "\n", "results", "[", "'pose_ids'", "]", "=", "datum", ".", "poseIds", ";", "\n", "results", "[", "'pose_scores'", "]", "=", "datum", ".", "poseScores", ";", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.OpenposeParser.stop": [[121, 124], ["openpose.OpenposeParser.opWrapper.stop"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.OpenposeParser.stop"], ["", "def", "stop", "(", "self", ")", ":", "\n", "        ", "self", ".", "opWrapper", ".", "stop", "(", ")", "\n", "del", "self", ".", "opWrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.openpose_parse_video": [[126, 152], ["openpose.OpenposeParser", "cv2.VideoCapture", "int", "tqdm.tqdm", "openpose.OpenposeParser.stop", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "range", "cv2.VideoCapture.read", "cv2.cvtColor", "openpose.OpenposeParser.process_frame", "op.process_frame.pop", "results.append"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.OpenposeParser.stop", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.openpose.OpenposeParser.process_frame"], ["", "", "def", "openpose_parse_video", "(", "video_file", ")", ":", "\n", "\n", "    ", "op", "=", "OpenposeParser", "(", "render", "=", "False", ",", "face", "=", "False", ",", "hand", "=", "True", ")", "\n", "results", "=", "[", "]", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_file", ")", "\n", "total_frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n", "for", "_", "in", "tqdm", "(", "range", "(", "total_frames", ")", ")", ":", "\n", "        ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "            ", "break", "\n", "\n", "", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "res", "=", "op", ".", "process_frame", "(", "frame", ")", "\n", "res", ".", "pop", "(", "'im'", ")", "\n", "results", ".", "append", "(", "res", ")", "\n", "\n", "", "op", ".", "stop", "(", ")", "\n", "del", "op", "\n", "\n", "cap", ".", "release", "(", ")", "\n", "\n", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.rie_lifting.process_rie": [[20, 95], ["numpy.arange", "pose_pipeline.env.add_path", "Skeleton", "rie_lifting.RIEArgs", "RIEModel", "os.path.join", "torch.load", "pretrain_dict.items", "RIEModel.state_dict", "model_pos.state_dict.update", "RIEModel.load_state_dict", "RIEModel.receptive_field", "Evaluate_Generator", "numpy.zeros", "pose_pipeline.env.add_path", "h36m_coco_format", "numpy.array", "int", "Skeleton.num_joints", "torch.no_grad", "RIEModel.eval", "torch.no_grad", "tqdm.tqdm", "numpy.concatenate", "revise_kpts", "RIEArgs.architecture.split", "pretrain_dict.items", "enumerate", "Evaluate_Generator.next_epoch", "torch.from_numpy().contiguous", "RIEModel.", "results.append", "np.array.tolist", "numpy.arange", "model_pos.state_dict.keys", "state_dict.items", "torch.from_numpy", "model_pos.detach().cpu().numpy", "torch.from_numpy().contiguous.astype", "model_pos.detach().cpu", "model_pos.detach"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "process_rie", "(", "key", ",", "batch_size", "=", "32", ",", "transform_coco", "=", "False", ")", ":", "\n", "\n", "    ", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "N", "=", "keypoints", ".", "shape", "[", "0", "]", "\n", "\n", "if", "transform_coco", ":", "\n", "        ", "with", "add_path", "(", "os", ".", "environ", "[", "\"GAST_PATH\"", "]", ")", ":", "\n", "            ", "from", "tools", ".", "preprocess", "import", "h36m_coco_format", ",", "revise_kpts", "\n", "keypoints_reformat", ",", "keypoints_score", "=", "keypoints", "[", "None", ",", "...", ",", ":", "2", "]", ",", "keypoints", "[", "None", ",", "...", ",", "2", "]", "\n", "keypoints_reformat", ",", "scores", ",", "valid_frames", "=", "h36m_coco_format", "(", "keypoints_reformat", ",", "keypoints_score", ")", "\n", "keypoints_reformat", "=", "revise_kpts", "(", "keypoints_reformat", ",", "scores", ",", "valid_frames", ")", "[", "0", "]", "\n", "\n", "valid_frames", "=", "np", ".", "array", "(", "valid_frames", "[", "0", "]", ")", "\n", "keypoints", "=", "keypoints_reformat", "[", "valid_frames", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "valid_frames", "=", "np", ".", "arange", "(", "keypoints", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "with", "add_path", "(", "os", ".", "environ", "[", "\"RIE_PATH\"", "]", ")", ":", "\n", "\n", "        ", "import", "torch", "\n", "from", "common", ".", "generators", "import", "Evaluate_Generator", "\n", "from", "common", ".", "skeleton", "import", "Skeleton", "\n", "from", "common", ".", "model", "import", "RIEModel", "\n", "\n", "skeleton", "=", "Skeleton", "(", "parents", "=", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "0", ",", "6", ",", "7", ",", "8", ",", "9", ",", "0", ",", "11", ",", "12", ",", "13", ",", "14", ",", "12", ",", "\n", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "19", ",", "22", ",", "12", ",", "24", ",", "25", ",", "26", ",", "27", ",", "28", ",", "27", ",", "30", "]", ",", "\n", "joints_left", "=", "[", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "22", ",", "23", "]", ",", "\n", "joints_right", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "24", ",", "25", ",", "26", ",", "27", ",", "28", ",", "29", ",", "30", ",", "31", "]", ")", "\n", "\n", "args", "=", "RIEArgs", "(", ")", "\n", "\n", "filter_widths", "=", "[", "int", "(", "x", ")", "for", "x", "in", "args", ".", "architecture", ".", "split", "(", "','", ")", "]", "\n", "\n", "model_pos", "=", "RIEModel", "(", "17", ",", "2", ",", "skeleton", ".", "num_joints", "(", ")", ",", "\n", "filter_widths", "=", "filter_widths", ",", "causal", "=", "args", ".", "causal", ",", "dropout", "=", "args", ".", "dropout", ",", "channels", "=", "args", ".", "channels", ",", "\n", "latten_features", "=", "args", ".", "latent_features_dim", ",", "dense", "=", "args", ".", "dense", ",", "is_train", "=", "False", ",", "Optimize1f", "=", "True", ",", "\n", "stage", "=", "args", ".", "stage", ")", "\n", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'rie/cpn_pretrained.bin'", ")", "\n", "checkpoint_p", "=", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "pretrain_dict", "=", "checkpoint_p", "[", "'model_pos'", "]", "\n", "temp", "=", "pretrain_dict", ".", "items", "(", ")", "\n", "model_dict", "=", "model_pos", ".", "state_dict", "(", ")", "\n", "state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pretrain_dict", ".", "items", "(", ")", "if", "k", "in", "model_dict", ".", "keys", "(", ")", "}", "\n", "state_dict", "=", "{", "k", ":", "v", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "state_dict", ".", "items", "(", ")", ")", "if", "i", "<", "317", "}", "\n", "\n", "model_dict", ".", "update", "(", "state_dict", ")", "\n", "model_pos", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model_pos", ".", "eval", "(", ")", "\n", "\n", "", "receptive_field", "=", "model_pos", ".", "receptive_field", "(", ")", "\n", "pad", "=", "(", "receptive_field", "-", "1", ")", "//", "2", "# Padding on each side", "\n", "causal_shift", "=", "pad", "if", "args", ".", "causal", "else", "0", "\n", "\n", "gen", "=", "Evaluate_Generator", "(", "batch_size", "=", "batch_size", ",", "cameras", "=", "None", ",", "poses_3d", "=", "None", ",", "poses_2d", "=", "[", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", "]", ",", "chunk_length", "=", "1", ",", "shuffle", "=", "False", ",", "pad", "=", "pad", ",", "causal_shift", "=", "causal_shift", ")", "\n", "\n", "results", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "sample", "in", "tqdm", "(", "gen", ".", "next_epoch", "(", ")", ")", ":", "\n", "                ", "sample", "=", "sample", "[", "2", "]", "\n", "sample", "=", "torch", ".", "from_numpy", "(", "sample", ".", "astype", "(", "'float32'", ")", ")", ".", "contiguous", "(", ")", "\n", "out", "=", "model_pos", "(", "sample", ")", "\n", "\n", "results", ".", "append", "(", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", ",", "0", ",", "...", "]", ")", "\n", "", "", "results", "=", "np", ".", "concatenate", "(", "results", ",", "axis", "=", "0", ")", "/", "1000.0", "\n", "\n", "keypoints_3d", "=", "np", ".", "zeros", "(", "(", "N", ",", "17", ",", "3", ")", ")", "\n", "keypoints_3d", "[", "valid_frames", "]", "=", "results", "\n", "keypoints_valid", "=", "[", "i", "in", "valid_frames", ".", "tolist", "(", ")", "for", "i", "in", "np", ".", "arange", "(", "keypoints", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "return", "{", "'keypoints_3d'", ":", "keypoints_3d", ",", "'keypoints_valid'", ":", "keypoints_valid", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.centerhmr.centerhmr_parse_video": [[13, 104], ["Parser", "Parser.process_video", "os.path.join", "os.path.join", "super().__init__", "centerhmr..set_up_smplx", "centerhmr.._build_model", "centerhmr..generator.eval", "Visualizer", "PIL.Image.fromarray", "tuple", "torchvision.transforms.Compose", "torch.from_numpy().unsqueeze().contiguous().float", "centerhmr..net_forward", "centerhmr..update", "cv2.VideoCapture", "int", "cv2.VideoCapture.get", "tqdm.tqdm", "image.cuda.cuda", "cv2.VideoCapture.get", "range", "cv2.VideoCapture.read", "outputs_cpu.pop", "centerhmr_parser.process_video.append", "cv2.VideoWriter.release", "torchvision.transforms.Resize", "torchvision.transforms.Pad", "torch.from_numpy().unsqueeze().contiguous", "torch.no_grad", "centerhmr..single_image_forward", "isinstance", "cpu"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.__init__", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["def", "centerhmr_parse_video", "(", "video_path", ",", "centerhmr_python_path", ",", "output_video_path", "=", "None", ")", ":", "\n", "\n", "    ", "old_args", "=", "sys", ".", "argv", "\n", "\n", "# CenterHMR uses a pretty awkward interface", "\n", "sys", ".", "argv", "=", "[", "'centerhmr_parse_video.py'", ",", "'--gpu=0'", ",", "\n", "'--gmodel-path='", "+", "os", ".", "path", ".", "join", "(", "centerhmr_python_path", ",", "'trained_models/pw3d_81.8_58.6.pkl'", ")", ",", "\n", "'--configs_yml='", "+", "os", ".", "path", ".", "join", "(", "centerhmr_python_path", ",", "'src/configs/basic_test_video.yml'", ")", "]", "\n", "\n", "from", "base", "import", "Base", ",", "Visualizer", "\n", "\n", "class", "Parser", "(", "Base", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", "Parser", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "set_up_smplx", "(", ")", "\n", "self", ".", "_build_model", "(", ")", "\n", "self", ".", "generator", ".", "eval", "(", ")", "\n", "self", ".", "vis_size", "=", "[", "1024", ",", "1024", ",", "3", "]", "#[1920,1080]", "\n", "self", ".", "visualizer", "=", "Visualizer", "(", "model_type", "=", "self", ".", "model_type", ",", "resolution", "=", "self", ".", "vis_size", ",", "input_size", "=", "self", ".", "input_size", ",", "with_renderer", "=", "True", ")", "\n", "\n", "", "def", "single_image_forward", "(", "self", ",", "image", ")", ":", "\n", "            ", "image_size", "=", "image", ".", "shape", "[", ":", "2", "]", "[", ":", ":", "-", "1", "]", "\n", "image_org", "=", "Image", ".", "fromarray", "(", "image", ")", "\n", "\n", "resized_image_size", "=", "(", "float", "(", "self", ".", "input_size", ")", "/", "max", "(", "image_size", ")", "*", "np", ".", "array", "(", "image_size", ")", "//", "2", "*", "2", ")", ".", "astype", "(", "int", ")", "[", ":", ":", "-", "1", "]", "\n", "padding", "=", "tuple", "(", "(", "self", ".", "input_size", "-", "resized_image_size", ")", "[", ":", ":", "-", "1", "]", "//", "2", ")", "\n", "transform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "\n", "torchvision", ".", "transforms", ".", "Resize", "(", "[", "*", "resized_image_size", "]", ",", "interpolation", "=", "3", ")", ",", "\n", "torchvision", ".", "transforms", ".", "Pad", "(", "padding", ",", "fill", "=", "0", ",", "padding_mode", "=", "'constant'", ")", ",", "\n", "]", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "transform", "(", "image_org", ")", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "contiguous", "(", ")", ".", "float", "(", ")", "\n", "if", "'-1'", "not", "in", "self", ".", "gpu", ":", "\n", "                ", "image", "=", "image", ".", "cuda", "(", ")", "\n", "", "outputs", ",", "centermaps", ",", "heatmap_AEs", ",", "_", ",", "reorganize_idx", "=", "self", ".", "net_forward", "(", "None", ",", "self", ".", "generator", ",", "image", ",", "mode", "=", "'test'", ")", "\n", "outputs", ".", "update", "(", "{", "'input_image'", ":", "image", ",", "'reorganize_idx'", ":", "reorganize_idx", "}", ")", "\n", "return", "outputs", "\n", "\n", "", "def", "process_video", "(", "self", ",", "video_file_path", "=", "None", ",", "output_file_name", "=", "None", ")", ":", "\n", "\n", "            ", "cap", "=", "cv2", ".", "VideoCapture", "(", "video_file_path", ")", "\n", "video_length", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "results", "=", "[", "]", "\n", "writer", "=", "None", "\n", "\n", "for", "frame_id", "in", "tqdm", "(", "range", "(", "video_length", ")", ")", ":", "\n", "\n", "                ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "frame", "is", "None", ":", "\n", "                    ", "break", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "outputs", "=", "self", ".", "single_image_forward", "(", "frame", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "\n", "# move data structures to CPU and append it to the results output array", "\n", "", "def", "cpu", "(", "x", ")", ":", "\n", "                    ", "if", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "                        ", "return", "{", "k", ":", "cpu", "(", "v", ")", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "                        ", "return", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                        ", "return", "x", "\n", "", "", "outputs_cpu", "=", "{", "k", ":", "cpu", "(", "v", ")", "for", "k", ",", "v", "in", "outputs", ".", "items", "(", ")", "}", "\n", "outputs_cpu", ".", "pop", "(", "'input_image'", ")", "\n", "results", ".", "append", "(", "outputs_cpu", ")", "\n", "\n", "\n", "if", "'verts'", "in", "outputs", ".", "keys", "(", ")", "and", "output_file_name", "is", "not", "None", ":", "\n", "                    ", "vis_dict", "=", "{", "'image_org'", ":", "outputs", "[", "'input_image'", "]", ".", "cpu", "(", ")", "}", "\n", "vis_eval_results", "=", "self", ".", "visualizer", ".", "visulize_result_onorg", "(", "outputs", "[", "'verts'", "]", ",", "outputs", "[", "'verts_camed'", "]", ",", "vis_dict", ",", "reorganize_idx", "=", "outputs", "[", "'reorganize_idx'", "]", ")", "\n", "result_frame", "=", "vis_eval_results", "[", "0", "]", "\n", "\n", "if", "writer", "is", "None", ":", "\n", "                        ", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'mp4v'", ")", "\n", "\n", "writer", "=", "cv2", ".", "VideoWriter", "(", "output_file_name", ",", "fourcc", ",", "fps", ",", "\n", "(", "result_frame", ".", "shape", "[", "1", "]", ",", "result_frame", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "#writer.write(result_frame)", "\n", "\n", "", "", "", "if", "writer", "is", "not", "None", ":", "\n", "                ", "writer", ".", "release", "(", ")", "\n", "\n", "", "return", "results", "\n", "\n", "", "", "centerhmr_parser", "=", "Parser", "(", ")", "\n", "results", "=", "centerhmr_parser", ".", "process_video", "(", "video_path", ",", "output_video_path", ")", "\n", "\n", "sys", ".", "argv", "=", "old_args", "\n", "\n", "return", "results", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.trades.trades_bounding_boxes": [[92, 152], ["os.path.join", "print", "dataclasses.dataclass", "params.items", "cv2.VideoCapture", "int", "int", "int", "dataclasses.dataclass.__setattr__", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "pose_pipeline.env.add_path", "Detector", "tqdm.tqdm", "range", "cv2.VideoCapture.read", "cv2.cvtColor", "Detector.run", "tracks.append", "numpy.array", "numpy.array", "trades.trades_bounding_boxes.parse_result"], "function", ["None"], ["def", "trades_bounding_boxes", "(", "file_path", ")", ":", "\n", "\n", "    ", "import", "torch", "\n", "from", "torchvision", "import", "transforms", "\n", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'trades/crowdhuman.pth'", ")", "\n", "print", "(", "model_file", ")", "\n", "opt", "=", "dataclass", "(", ")", "\n", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "opt", ".", "__setattr__", "(", "k", ",", "v", ")", "\n", "\n", "", "opt", ".", "load_model", "=", "model_file", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "file_path", ")", "\n", "\n", "width", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "height", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n", "if", "height", ">", "width", ":", "\n", "# change configuration to better handle portrait mode", "\n", "        ", "opt", ".", "input_h", "=", "864", "\n", "opt", ".", "input_w", "=", "480", "\n", "opt", ".", "input_res", "=", "864", "# unchanged", "\n", "opt", ".", "output_h", "=", "216", "\n", "opt", ".", "output_w", "=", "120", "\n", "opt", ".", "output_res", "=", "216", "# unchanged", "\n", "\n", "", "tracks", "=", "[", "]", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"TRADES_PATH\"", "]", ")", ":", "\n", "        ", "from", "detector", "import", "Detector", "\n", "\n", "detector", "=", "Detector", "(", "opt", ")", "\n", "\n", "tracks", "=", "[", "]", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "frames", ")", ")", ":", "\n", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret", "or", "frame", "is", "None", ":", "\n", "                ", "print", "(", "'Failed to read a frame'", ")", "\n", "break", "\n", "\n", "", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "\n", "results", "=", "detector", ".", "run", "(", "frame", ")", "\n", "\n", "tracks", ".", "append", "(", "results", ")", "\n", "\n", "", "del", "detector", "\n", "\n", "", "def", "parse_result", "(", "x", ")", ":", "\n", "        ", "return", "{", "'track_id'", ":", "x", "[", "'tracking_id'", "]", ",", "\n", "'tlbr'", ":", "np", ".", "array", "(", "x", "[", "'bbox'", "]", ")", ",", "\n", "'tlhw'", ":", "np", ".", "array", "(", "[", "*", "x", "[", "'bbox'", "]", "[", ":", "2", "]", ",", "x", "[", "'bbox'", "]", "[", "2", "]", "-", "x", "[", "'bbox'", "]", "[", "0", "]", ",", "x", "[", "'bbox'", "]", "[", "3", "]", "-", "x", "[", "'bbox'", "]", "[", "1", "]", "]", ")", ",", "\n", "'confidence'", ":", "x", "[", "'score'", "]", "}", "\n", "\n", "", "return", "[", "[", "parse_result", "(", "x", ")", "for", "x", "in", "frame", "[", "'results'", "]", "]", "for", "frame", "in", "tracks", "]", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmtrack.mmtrack_bounding_boxes": [[7, 46], ["mmtrack.apis.init_model", "cv2.VideoCapture", "int", "tqdm.tqdm", "os.path.join", "cv2.VideoCapture.get", "range", "cv2.VideoCapture.read", "cv2.cvtColor", "mmtrack.apis.inference_mot", "tracks.append", "os.path.join", "len", "os.path.join", "Exception", "int", "numpy.array"], "function", ["None"], ["def", "mmtrack_bounding_boxes", "(", "file_path", ",", "method", "=", "'tracktor'", ")", ":", "\n", "\n", "    ", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "\n", "if", "method", "==", "'tracktor'", ":", "\n", "        ", "model_config", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmtracking/mot/tracktor/tracktor_faster-rcnn_r50_fpn_4e_mot17-private.py'", ")", "\n", "", "elif", "method", "==", "'deepsort'", ":", "\n", "        ", "model_config", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmtracking/mot/deepsort/deepsort_faster-rcnn_fpn_4e_mot17-private-half.py'", ")", "\n", "", "elif", "method", "==", "'bytetrack'", ":", "\n", "        ", "model_config", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmtracking/mot/bytetrack/bytetrack_yolox_x_crowdhuman_mot17-private.py'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f'Unknown config file for MMTrack method {method}'", ")", "\n", "", "model", "=", "mmtrack", ".", "apis", ".", "init_model", "(", "model_config", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "file_path", ")", "\n", "video_length", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n", "tracks", "=", "[", "]", "\n", "\n", "for", "frame_id", "in", "tqdm", "(", "range", "(", "video_length", ")", ")", ":", "\n", "        ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "\n", "if", "ret", "!=", "True", "or", "frame", "is", "None", ":", "\n", "             ", "break", "\n", "\n", "", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "result", "=", "mmtrack", ".", "apis", ".", "inference_mot", "(", "model", ",", "frame", ",", "frame_id", ")", "\n", "\n", "assert", "len", "(", "result", "[", "'track_bboxes'", "]", ")", "==", "1", "\n", "track_results", "=", "result", "[", "'track_bboxes'", "]", "[", "0", "]", "\n", "\n", "tracks", ".", "append", "(", "\n", "[", "{", "'track_id'", ":", "int", "(", "x", "[", "0", "]", ")", ",", "\n", "'tlbr'", ":", "x", "[", "1", ":", "5", "]", ",", "\n", "'tlhw'", ":", "np", ".", "array", "(", "[", "x", "[", "1", "]", ",", "x", "[", "2", "]", ",", "x", "[", "3", "]", "-", "x", "[", "1", "]", ",", "x", "[", "4", "]", "-", "x", "[", "2", "]", "]", ")", ",", "\n", "'confidence'", ":", "x", "[", "5", "]", "}", "for", "x", "in", "track_results", "]", ")", "\n", "\n", "", "return", "tracks", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.poseformer.process_liftformer": [[8, 88], ["os.path.join", "poseformer.process_liftformer.coco_h36m"], "function", ["None"], ["def", "process_liftformer", "(", "key", ")", ":", "\n", "\n", "    ", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "poseformer_files", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "__file__", ")", "[", "0", "]", ",", "'../3rdparty/poseformer/'", ")", "\n", "\n", "receptive_field", "=", "81", "\n", "num_joints", "=", "17", "\n", "\n", "def", "coco_h36m", "(", "keypoints", ")", ":", "\n", "# adopted from https://github.com/fabro66/GAST-Net-3DPoseEstimation/blob/97a364affe5cd4f68fab030e0210187333fff25e/tools/mpii_coco_h36m.py#L20", "\n", "# MIT License", "\n", "\n", "        ", "spple_keypoints", "=", "[", "10", ",", "8", ",", "0", ",", "7", "]", "\n", "h36m_coco_order", "=", "[", "9", ",", "11", ",", "14", ",", "12", ",", "15", ",", "13", ",", "16", ",", "4", ",", "1", ",", "5", ",", "2", ",", "6", ",", "3", "]", "\n", "coco_order", "=", "[", "0", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "12", ",", "13", ",", "14", ",", "15", ",", "16", "]", "\n", "\n", "temporal", "=", "keypoints", ".", "shape", "[", "0", "]", "\n", "keypoints_h36m", "=", "np", ".", "zeros_like", "(", "keypoints", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "htps_keypoints", "=", "np", ".", "zeros", "(", "(", "temporal", ",", "4", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# htps_keypoints: head, thorax, pelvis, spine", "\n", "htps_keypoints", "[", ":", ",", "0", ",", "0", "]", "=", "np", ".", "mean", "(", "keypoints", "[", ":", ",", "1", ":", "5", ",", "0", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "htps_keypoints", "[", ":", ",", "0", ",", "1", "]", "=", "np", ".", "sum", "(", "keypoints", "[", ":", ",", "1", ":", "3", ",", "1", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "-", "keypoints", "[", ":", ",", "0", ",", "1", "]", "\n", "htps_keypoints", "[", ":", ",", "1", ",", ":", "]", "=", "np", ".", "mean", "(", "keypoints", "[", ":", ",", "5", ":", "7", ",", ":", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "htps_keypoints", "[", ":", ",", "1", ",", ":", "]", "+=", "(", "keypoints", "[", ":", ",", "0", ",", ":", "]", "-", "htps_keypoints", "[", ":", ",", "1", ",", ":", "]", ")", "/", "3", "\n", "\n", "htps_keypoints", "[", ":", ",", "2", ",", ":", "]", "=", "np", ".", "mean", "(", "keypoints", "[", ":", ",", "11", ":", "13", ",", ":", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "htps_keypoints", "[", ":", ",", "3", ",", ":", "]", "=", "np", ".", "mean", "(", "keypoints", "[", ":", ",", "[", "5", ",", "6", ",", "11", ",", "12", "]", ",", ":", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "keypoints_h36m", "[", ":", ",", "spple_keypoints", ",", ":", "]", "=", "htps_keypoints", "\n", "keypoints_h36m", "[", ":", ",", "h36m_coco_order", ",", ":", "]", "=", "keypoints", "[", ":", ",", "coco_order", ",", ":", "]", "\n", "\n", "keypoints_h36m", "[", ":", ",", "9", ",", ":", "]", "-=", "(", "keypoints_h36m", "[", ":", ",", "9", ",", ":", "]", "-", "np", ".", "mean", "(", "keypoints", "[", ":", ",", "5", ":", "7", ",", ":", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", ")", "/", "4", "\n", "keypoints_h36m", "[", ":", ",", "7", ",", "0", "]", "+=", "2", "*", "(", "keypoints_h36m", "[", ":", ",", "7", ",", "0", "]", "-", "np", ".", "mean", "(", "keypoints_h36m", "[", ":", ",", "[", "0", ",", "8", "]", ",", "0", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "keypoints_h36m", "[", ":", ",", "8", ",", "1", "]", "-=", "(", "np", ".", "mean", "(", "keypoints", "[", ":", ",", "1", ":", "3", ",", "1", "]", ",", "axis", "=", "1", ",", "dtype", "=", "np", ".", "float32", ")", "-", "keypoints", "[", ":", ",", "0", ",", "1", "]", ")", "*", "2", "/", "3", "\n", "\n", "return", "keypoints_h36m", "\n", "\n", "# reformat keypoints from coco detection to the input of the lifting", "\n", "", "keypoints", "=", "coco_h36m", "(", "keypoints", "[", "...", ",", ":", "2", "]", ")", "\n", "keypoints", "=", "keypoints", "/", "np", ".", "array", "(", "[", "height", ",", "width", "]", ")", "[", "None", ",", "None", ",", ":", "]", "\n", "\n", "# reshape into temporal frames. shifted in time as we want to estimate for all", "\n", "# time and PoseFormer only produces the central timepoint", "\n", "dat", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "keypoints", ".", "shape", "[", "0", "]", "-", "receptive_field", "+", "1", ")", ":", "\n", "        ", "dat", ".", "append", "(", "keypoints", "[", "i", ":", "i", "+", "receptive_field", ",", ":", ",", ":", "2", "]", ")", "\n", "", "dat", "=", "np", ".", "stack", "(", "dat", ",", "axis", "=", "0", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"POSEFORMER_PATH\"", "]", ")", ":", "\n", "\n", "        ", "import", "torch", "\n", "import", "torch", ".", "nn", "as", "nn", "\n", "from", "common", ".", "model_poseformer", "import", "PoseTransformer", "\n", "\n", "poseformer", "=", "PoseTransformer", "(", "num_frame", "=", "receptive_field", ",", "num_joints", "=", "num_joints", ",", "in_chans", "=", "2", ",", "embed_dim_ratio", "=", "32", ",", "depth", "=", "4", ",", "\n", "num_heads", "=", "8", ",", "mlp_ratio", "=", "2.", ",", "qkv_bias", "=", "True", ",", "qk_scale", "=", "None", ",", "drop_path_rate", "=", "0.1", ")", "\n", "\n", "poseformer", "=", "nn", ".", "DataParallel", "(", "poseformer", ")", "\n", "\n", "poseformer", ".", "cuda", "(", ")", "\n", "chk", "=", "os", ".", "path", ".", "join", "(", "poseformer_files", ",", "'detected81f.bin'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "chk", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "poseformer", ".", "load_state_dict", "(", "checkpoint", "[", "'model_pos'", "]", ",", "strict", "=", "False", ")", "\n", "\n", "kp3d", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "dat", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "frame", "=", "torch", ".", "Tensor", "(", "dat", "[", "None", ",", "idx", "]", ")", ".", "cuda", "(", ")", "\n", "kp3d", ".", "append", "(", "poseformer", ".", "forward", "(", "frame", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "[", ":", ",", "0", ",", "...", "]", ")", "\n", "\n", "", "del", "poseformer", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "kp3d", "=", "np", ".", "concatenate", "(", "[", "np", ".", "zeros", "(", "(", "40", ",", "17", ",", "3", ")", ")", ",", "*", "kp3d", ",", "np", ".", "zeros", "(", "(", "40", ",", "17", ",", "3", ")", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "key", "[", "'keypoints_3d'", "]", "=", "kp3d", "\n", "return", "key", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.batch_rot2aa": [[12, 54], ["torch.clamp", "torch.acos", "torch.sqrt", "torch.where", "torch.where", "torch.where", "torch.acos.unsqueeze", "torch.stack", "torch.einsum", "torch.abs", "torch.abs", "torch.abs"], "function", ["None"], ["def", "batch_rot2aa", "(", "Rs", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"\n    Rs is B x 3 x 3\n    void cMathUtil::RotMatToAxisAngle(const tMatrix& mat, tVector& out_axis,\n                                      double& out_theta)\n    {\n        double c = 0.5 * (mat(0, 0) + mat(1, 1) + mat(2, 2) - 1);\n        c = cMathUtil::Clamp(c, -1.0, 1.0);\n        out_theta = std::acos(c);\n        if (std::abs(out_theta) < 0.00001)\n        {\n            out_axis = tVector(0, 0, 1, 0);\n        }\n        else\n        {\n            double m21 = mat(2, 1) - mat(1, 2);\n            double m02 = mat(0, 2) - mat(2, 0);\n            double m10 = mat(1, 0) - mat(0, 1);\n            double denom = std::sqrt(m21 * m21 + m02 * m02 + m10 * m10);\n            out_axis[0] = m21 / denom;\n            out_axis[1] = m02 / denom;\n            out_axis[2] = m10 / denom;\n            out_axis[3] = 0;\n        }\n    }\n    \"\"\"", "\n", "\n", "cos", "=", "0.5", "*", "(", "torch", ".", "einsum", "(", "'bii->b'", ",", "[", "Rs", "]", ")", "-", "1", ")", "\n", "cos", "=", "torch", ".", "clamp", "(", "cos", ",", "-", "1", "+", "epsilon", ",", "1", "-", "epsilon", ")", "\n", "\n", "theta", "=", "torch", ".", "acos", "(", "cos", ")", "\n", "\n", "m21", "=", "Rs", "[", ":", ",", "2", ",", "1", "]", "-", "Rs", "[", ":", ",", "1", ",", "2", "]", "\n", "m02", "=", "Rs", "[", ":", ",", "0", ",", "2", "]", "-", "Rs", "[", ":", ",", "2", ",", "0", "]", "\n", "m10", "=", "Rs", "[", ":", ",", "1", ",", "0", "]", "-", "Rs", "[", ":", ",", "0", ",", "1", "]", "\n", "denom", "=", "torch", ".", "sqrt", "(", "m21", "*", "m21", "+", "m02", "*", "m02", "+", "m10", "*", "m10", "+", "epsilon", ")", "\n", "\n", "axis0", "=", "torch", ".", "where", "(", "torch", ".", "abs", "(", "theta", ")", "<", "0.00001", ",", "m21", ",", "m21", "/", "denom", ")", "\n", "axis1", "=", "torch", ".", "where", "(", "torch", ".", "abs", "(", "theta", ")", "<", "0.00001", ",", "m02", ",", "m02", "/", "denom", ")", "\n", "axis2", "=", "torch", ".", "where", "(", "torch", ".", "abs", "(", "theta", ")", "<", "0.00001", ",", "m10", ",", "m10", "/", "denom", ")", "\n", "\n", "return", "theta", ".", "unsqueeze", "(", "1", ")", "*", "torch", ".", "stack", "(", "[", "axis0", ",", "axis1", ",", "axis2", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.process_prohmr": [[56, 159], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "pose_pipeline.env.add_path", "prohmr_config", "ProHMR.load_from_checkpoint().to", "ProHMR.load_from_checkpoint().to.eval", "pose_pipeline.utils.bounding_box.get_person_dataloader", "tqdm.tqdm", "torch.cuda.is_available", "torch.device", "torch.device", "KeypointFitting", "enumerate", "recursive_to", "ProHMR.load_from_checkpoint", "torch.no_grad", "ProHMR.load_from_checkpoint().to.", "numpy.concatenate", "ProHMR.load_from_checkpoint().to.downstream_optimization", "torch.tensor", "perspective_projection", "projected_joints.detach().cpu().numpy.detach().cpu().numpy", "frames.append", "pred_cam.append", "pred_verts.append", "prohmr.batch_rot2aa", "batch_rot2aa().reshape", "pred_pose.append", "pred_betas.append", "pred_joints3d.append", "smpl_joints2d.append", "print", "numpy.array", "numpy.array", "recursive_to.to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "opt_out[].cpu().detach().numpy", "opt_out[].cpu().detach().numpy", "torch.cat().cpu().detach().numpy", "[].cpu().detach().numpy", "opt_out[].cpu().detach().numpy", "numpy.zeros", "torch.ones_like", "projected_joints.detach().cpu().numpy.detach().cpu", "prohmr.batch_rot2aa", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "opt_out[].cpu().detach", "opt_out[].cpu().detach", "torch.cat().cpu().detach", "[].cpu().detach", "opt_out[].cpu().detach", "numpy.array", "projected_joints.detach().cpu().numpy.detach", "opt_out[].cpu", "opt_out[].cpu", "torch.cat().cpu", "[].cpu", "opt_out[].cpu", "torch.cat"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.get_person_dataloader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.batch_rot2aa", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.batch_rot2aa", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "process_prohmr", "(", "key", ",", "optimization", "=", "True", ",", "batch_size", "=", "1", ")", ":", "\n", "\n", "    ", "model_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/'", ")", "\n", "joint_regressor_extra", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/SMPL_to_J19.pkl'", ")", "\n", "mean_params", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/smpl_mean_params.npz'", ")", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/checkpoint.pt'", ")", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'PROHMR_PATH'", "]", ")", ":", "\n", "\n", "        ", "from", "prohmr", ".", "configs", "import", "prohmr_config", "\n", "from", "prohmr", ".", "models", "import", "ProHMR", "\n", "from", "prohmr", ".", "optimization", "import", "KeypointFitting", "\n", "from", "prohmr", ".", "utils", "import", "recursive_to", "\n", "from", "prohmr", ".", "utils", ".", "geometry", "import", "perspective_projection", "\n", "\n", "model_cfg", "=", "prohmr_config", "(", ")", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'MODEL_PATH'", "]", "=", "model_path", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'JOINT_REGRESSOR_EXTRA'", "]", "=", "joint_regressor_extra", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'MEAN_PARAMS'", "]", "=", "mean_params", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "model", "=", "ProHMR", ".", "load_from_checkpoint", "(", "checkpoint", ",", "strict", "=", "False", ",", "cfg", "=", "model_cfg", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", ";", "\n", "\n", "if", "optimization", ":", "\n", "            ", "keypoint_fitting", "=", "KeypointFitting", "(", "model_cfg", ")", "\n", "keypoints", "=", "(", "OpenPosePerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "", "crop_size", "=", "model_cfg", "[", "'MODEL'", "]", "[", "'IMAGE_SIZE'", "]", "\n", "frame_ids", ",", "dataloader", ",", "bbox", "=", "get_person_dataloader", "(", "key", ",", "crop_size", "=", "crop_size", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "frames", "=", "[", "]", "\n", "pred_cam", "=", "[", "]", "\n", "pred_verts", "=", "[", "]", "\n", "pred_pose", "=", "[", "]", "\n", "pred_betas", "=", "[", "]", "\n", "pred_joints3d", "=", "[", "]", "\n", "smpl_joints2d", "=", "[", "]", "\n", "\n", "for", "idx", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "dataloader", ")", ")", ":", "\n", "\n", "            ", "frame_id", "=", "frame_ids", "[", "idx", "]", "\n", "\n", "batch", "=", "recursive_to", "(", "batch", ",", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "out", "=", "model", "(", "{", "'img'", ":", "batch", "}", ")", "\n", "\n", "", "if", "optimization", ":", "\n", "\n", "                ", "kp", "=", "np", ".", "concatenate", "(", "[", "keypoints", "[", "None", ",", "frame_id", ",", "...", "]", ",", "np", ".", "zeros", "(", "(", "1", ",", "19", ",", "3", ")", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "scale", "=", "np", ".", "array", "(", "[", "width", ",", "height", "]", ")", "/", "2.0", "\n", "center", "=", "np", ".", "array", "(", "[", "width", ",", "height", "]", ")", "/", "2.0", "\n", "\n", "batch_opt", "=", "{", "'img'", ":", "batch", ".", "to", "(", "device", ")", ",", "'orig_keypoints_2d'", ":", "torch", ".", "from_numpy", "(", "kp", ")", ".", "to", "(", "device", ")", ",", "\n", "'box_center'", ":", "torch", ".", "from_numpy", "(", "center", "[", "None", ",", "...", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "'box_size'", ":", "torch", ".", "from_numpy", "(", "scale", "[", "None", ",", "0", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "'img_size'", ":", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "[", "width", ",", "height", "]", "]", ")", ")", ".", "to", "(", "device", ")", "}", "\n", "\n", "opt_out", "=", "model", ".", "downstream_optimization", "(", "regression_output", "=", "out", ",", "\n", "batch", "=", "batch_opt", ",", "\n", "opt_task", "=", "keypoint_fitting", ",", "\n", "use_hips", "=", "False", ",", "\n", "full_frame", "=", "True", ")", "\n", "\n", "camera_center", "=", "torch", ".", "tensor", "(", "[", "[", "width", "/", "2", ",", "height", "/", "2", "]", "]", ")", "\n", "projected_joints", "=", "perspective_projection", "(", "opt_out", "[", "'model_joints'", "]", ",", "opt_out", "[", "'camera_translation'", "]", ",", "model_cfg", "[", "'EXTRA'", "]", "[", "'FOCAL_LENGTH'", "]", "*", "torch", ".", "ones_like", "(", "camera_center", ")", ",", "camera_center", "=", "camera_center", ")", "\n", "projected_joints", "=", "projected_joints", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "frames", ".", "append", "(", "frame_id", ")", "\n", "\n", "pred_cam", ".", "append", "(", "opt_out", "[", "'camera_translation'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_verts", ".", "append", "(", "opt_out", "[", "'vertices'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# for consistency with other algos and rendering code", "\n", "global_orient", "=", "opt_out", "[", "'smpl_params'", "]", "[", "'global_orient'", "]", "[", "0", "]", "\n", "global_orient", "=", "batch_rot2aa", "(", "global_orient", ")", "\n", "poses_aa", "=", "batch_rot2aa", "(", "opt_out", "[", "'smpl_params'", "]", "[", "'body_pose'", "]", "[", "0", "]", ")", ".", "reshape", "(", "1", ",", "23", "*", "3", ")", "\n", "pred_pose", ".", "append", "(", "torch", ".", "cat", "(", "[", "global_orient", ",", "poses_aa", "]", ",", "axis", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "pred_betas", ".", "append", "(", "opt_out", "[", "'smpl_params'", "]", "[", "'betas'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_joints3d", ".", "append", "(", "opt_out", "[", "'model_joints'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "smpl_joints2d", ".", "append", "(", "projected_joints", ")", "\n", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Not implemented'", ")", "\n", "\n", "", "", "", "key", "[", "'cams'", "]", "=", "np", ".", "concatenate", "(", "pred_cam", ",", "axis", "=", "0", ")", "\n", "key", "[", "'verts'", "]", "=", "np", ".", "concatenate", "(", "pred_verts", ",", "axis", "=", "0", ")", "\n", "key", "[", "'poses'", "]", "=", "np", ".", "concatenate", "(", "pred_pose", ",", "axis", "=", "0", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "concatenate", "(", "pred_betas", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints3d'", "]", "=", "np", ".", "concatenate", "(", "pred_joints3d", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints2d'", "]", "=", "np", ".", "concatenate", "(", "smpl_joints2d", ",", "axis", "=", "0", ")", "\n", "\n", "N", "=", "key", "[", "'cams'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.process_prohmr_mmpose": [[161, 262], ["os.path.join", "os.path.join", "os.path.join", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "len", "pose_pipeline.env.add_path", "prohmr_config", "ProHMR.load_from_checkpoint().to", "ProHMR.load_from_checkpoint().to.eval", "KeypointFitting", "pose_pipeline.utils.bounding_box.get_person_dataloader", "tqdm.tqdm", "torch.cuda.is_available", "torch.device", "torch.device", "enumerate", "recursive_to", "ProHMR.load_from_checkpoint().to.downstream_optimization", "torch.tensor", "perspective_projection", "projected_joints.detach().cpu().numpy.detach().cpu().numpy", "frames.append", "pred_cam.append", "pred_verts.append", "prohmr.batch_rot2aa", "batch_rot2aa().reshape", "pred_pose.append", "pred_betas.append", "pred_joints3d.append", "smpl_joints2d.append", "ProHMR.load_from_checkpoint", "torch.no_grad", "ProHMR.load_from_checkpoint().to.", "numpy.array", "numpy.array", "recursive_to.to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "opt_out[].cpu().detach().numpy", "opt_out[].cpu().detach().numpy", "torch.cat().cpu().detach().numpy", "[].cpu().detach().numpy", "opt_out[].cpu().detach().numpy", "torch.ones_like", "projected_joints.detach().cpu().numpy.detach().cpu", "prohmr.batch_rot2aa", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "opt_out[].cpu().detach", "opt_out[].cpu().detach", "torch.cat().cpu().detach", "[].cpu().detach", "opt_out[].cpu().detach", "numpy.array", "projected_joints.detach().cpu().numpy.detach", "opt_out[].cpu", "opt_out[].cpu", "torch.cat().cpu", "[].cpu", "opt_out[].cpu", "torch.cat"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.get_person_dataloader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.batch_rot2aa", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.batch_rot2aa", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "process_prohmr_mmpose", "(", "key", ",", "batch_size", "=", "1", ")", ":", "\n", "\n", "    ", "top_down_method", "=", "(", "TopDownMethodLookup", "&", "'top_down_method_name=\"MMPose\"'", ")", ".", "fetch1", "(", "'top_down_method'", ")", "\n", "assert", "len", "(", "TopDownPerson", "&", "key", "&", "f'top_down_method={top_down_method}'", ")", "==", "1", "\n", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/'", ")", "\n", "mean_params", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/smpl_mean_params.npz'", ")", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'prohmr/checkpoint.pt'", ")", "\n", "smpl_to_mmpose", "=", "[", "24", ",", "26", ",", "25", ",", "28", ",", "27", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "1", ",", "2", ",", "4", ",", "5", ",", "7", ",", "8", "]", "\n", "\n", "results", "=", "[", "]", "\n", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'PROHMR_PATH'", "]", ")", ":", "\n", "\n", "        ", "from", "prohmr", ".", "configs", "import", "prohmr_config", "\n", "from", "prohmr", ".", "models", "import", "ProHMR", "\n", "from", "prohmr", ".", "optimization", "import", "KeypointFitting", "\n", "from", "prohmr", ".", "utils", "import", "recursive_to", "\n", "from", "prohmr", ".", "utils", ".", "geometry", "import", "perspective_projection", "\n", "\n", "model_cfg", "=", "prohmr_config", "(", ")", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'MODEL_PATH'", "]", "=", "model_path", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'JOINT_REGRESSOR_EXTRA'", "]", "=", "None", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'JOINT_MAP'", "]", "=", "smpl_to_mmpose", "\n", "model_cfg", "[", "'SMPL'", "]", "[", "'MEAN_PARAMS'", "]", "=", "mean_params", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "model", "=", "ProHMR", ".", "load_from_checkpoint", "(", "checkpoint", ",", "strict", "=", "False", ",", "cfg", "=", "model_cfg", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", ";", "\n", "\n", "keypoint_fitting", "=", "KeypointFitting", "(", "model_cfg", ")", "\n", "keypoints", "=", "(", "TopDownPerson", "&", "key", "&", "f'top_down_method={top_down_method}'", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "crop_size", "=", "model_cfg", "[", "'MODEL'", "]", "[", "'IMAGE_SIZE'", "]", "\n", "frame_ids", ",", "dataloader", ",", "bbox", "=", "get_person_dataloader", "(", "key", ",", "crop_size", "=", "crop_size", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "frames", "=", "[", "]", "\n", "pred_cam", "=", "[", "]", "\n", "pred_verts", "=", "[", "]", "\n", "pred_pose", "=", "[", "]", "\n", "pred_betas", "=", "[", "]", "\n", "pred_joints3d", "=", "[", "]", "\n", "smpl_joints2d", "=", "[", "]", "\n", "\n", "for", "idx", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "dataloader", ")", ")", ":", "\n", "\n", "            ", "frame_id", "=", "frame_ids", "[", "idx", "]", "\n", "\n", "batch", "=", "recursive_to", "(", "batch", ",", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "out", "=", "model", "(", "{", "'img'", ":", "batch", "}", ")", "\n", "\n", "", "kp", "=", "keypoints", "[", "None", ",", "frame_id", ",", "...", "]", "\n", "\n", "scale", "=", "np", ".", "array", "(", "[", "width", ",", "height", "]", ")", "/", "2.0", "\n", "center", "=", "np", ".", "array", "(", "[", "width", ",", "height", "]", ")", "/", "2.0", "\n", "\n", "batch_opt", "=", "{", "'img'", ":", "batch", ".", "to", "(", "device", ")", ",", "'orig_keypoints_2d'", ":", "torch", ".", "from_numpy", "(", "kp", ")", ".", "to", "(", "device", ")", ",", "\n", "'box_center'", ":", "torch", ".", "from_numpy", "(", "center", "[", "None", ",", "...", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "'box_size'", ":", "torch", ".", "from_numpy", "(", "scale", "[", "None", ",", "0", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "'img_size'", ":", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "[", "width", ",", "height", "]", "]", ")", ")", ".", "to", "(", "device", ")", "}", "\n", "\n", "opt_out", "=", "model", ".", "downstream_optimization", "(", "regression_output", "=", "out", ",", "\n", "batch", "=", "batch_opt", ",", "\n", "opt_task", "=", "keypoint_fitting", ",", "\n", "use_hips", "=", "True", ",", "\n", "full_frame", "=", "True", ")", "\n", "\n", "camera_center", "=", "torch", ".", "tensor", "(", "[", "[", "width", "/", "2", ",", "height", "/", "2", "]", "]", ")", "\n", "projected_joints", "=", "perspective_projection", "(", "opt_out", "[", "'model_joints'", "]", ",", "opt_out", "[", "'camera_translation'", "]", ",", "model_cfg", "[", "'EXTRA'", "]", "[", "'FOCAL_LENGTH'", "]", "*", "torch", ".", "ones_like", "(", "camera_center", ")", ",", "camera_center", "=", "camera_center", ")", "\n", "projected_joints", "=", "projected_joints", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "frames", ".", "append", "(", "frame_id", ")", "\n", "\n", "pred_cam", ".", "append", "(", "opt_out", "[", "'camera_translation'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_verts", ".", "append", "(", "opt_out", "[", "'vertices'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# for consistency with other algos and rendering code", "\n", "global_orient", "=", "opt_out", "[", "'smpl_params'", "]", "[", "'global_orient'", "]", "[", "0", "]", "\n", "global_orient", "=", "batch_rot2aa", "(", "global_orient", ")", "\n", "poses_aa", "=", "batch_rot2aa", "(", "opt_out", "[", "'smpl_params'", "]", "[", "'body_pose'", "]", "[", "0", "]", ")", ".", "reshape", "(", "1", ",", "23", "*", "3", ")", "\n", "pred_pose", ".", "append", "(", "torch", ".", "cat", "(", "[", "global_orient", ",", "poses_aa", "]", ",", "axis", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "pred_betas", ".", "append", "(", "opt_out", "[", "'smpl_params'", "]", "[", "'betas'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "pred_joints3d", ".", "append", "(", "opt_out", "[", "'model_joints'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "smpl_joints2d", ".", "append", "(", "projected_joints", ")", "\n", "\n", "", "", "key", "[", "'cams'", "]", "=", "np", ".", "concatenate", "(", "pred_cam", ",", "axis", "=", "0", ")", "\n", "key", "[", "'verts'", "]", "=", "np", ".", "concatenate", "(", "pred_verts", ",", "axis", "=", "0", ")", "\n", "key", "[", "'poses'", "]", "=", "np", ".", "concatenate", "(", "pred_pose", ",", "axis", "=", "0", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "concatenate", "(", "pred_betas", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints3d'", "]", "=", "np", ".", "concatenate", "(", "pred_joints3d", ",", "axis", "=", "0", ")", "\n", "key", "[", "'joints2d'", "]", "=", "np", ".", "concatenate", "(", "smpl_joints2d", ",", "axis", "=", "0", ")", "\n", "\n", "N", "=", "key", "[", "'cams'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.prohmr.get_prohmr_smpl_callback": [[264, 313], ["pose_pipeline.env.add_path", "transforms.Normalize", "transforms.Compose", "SMPL", "[].numpy", "Renderer", "numpy.where", "prohmr_config", "transforms.Compose.", "transforms.ToTensor", "SMPL.get_faces", "numpy.where", "len", "Renderer.", "draw_keypoints", "numpy.transpose", "SMPL.", "cams[].copy", "np.transpose.detach().cpu().numpy", "np.transpose.detach().cpu", "np.transpose.detach"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "get_prohmr_smpl_callback", "(", "key", ",", "poses", ",", "betas", ",", "cams", ")", ":", "\n", "\n", "    ", "from", "pose_estimation", ".", "body_models", ".", "smpl", "import", "SMPL", "\n", "from", "pose_pipeline", "import", "VideoInfo", ",", "PersonBbox", ",", "SMPLPerson", "\n", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "draw_keypoints", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'PROHMR_PATH'", "]", ")", ":", "\n", "        ", "from", "prohmr", ".", "utils", ".", "renderer", "import", "Renderer", "\n", "from", "prohmr", ".", "configs", "import", "prohmr_config", "\n", "\n", "import", "torchvision", ".", "transforms", "as", "transforms", "\n", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "valid_idx", "=", "np", ".", "where", "(", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'present'", ")", ")", "[", "0", "]", "\n", "\n", "smpl", "=", "SMPL", "(", ")", "\n", "verts", "=", "smpl", "(", "poses", ",", "betas", ")", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "renderer", "=", "Renderer", "(", "prohmr_config", "(", ")", ",", "faces", "=", "smpl", ".", "get_faces", "(", ")", ")", "\n", "\n", "joints2d", "=", "(", "SMPLPerson", "&", "key", ")", ".", "fetch1", "(", "'joints2d'", ")", "\n", "\n", "def", "overlay", "(", "frame", ",", "idx", ",", "renderer", "=", "renderer", ",", "verts", "=", "verts", ",", "cams", "=", "cams", ",", "joints2d", "=", "joints2d", ")", ":", "\n", "\n", "            ", "frame", "=", "transform", "(", "frame", ")", "\n", "\n", "smpl_idx", "=", "np", ".", "where", "(", "valid_idx", "==", "idx", ")", "[", "0", "]", "\n", "if", "len", "(", "smpl_idx", ")", "==", "1", ":", "\n", "                ", "smpl_idx", "=", "smpl_idx", "[", "0", "]", "\n", "\n", "frame", "=", "renderer", "(", "verts", "[", "smpl_idx", "]", ",", "cams", "[", "smpl_idx", "]", ".", "copy", "(", ")", ",", "frame", ")", "\n", "frame", "=", "(", "frame", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "frame", "=", "draw_keypoints", "(", "frame", ",", "joints2d", "[", "smpl_idx", "]", ",", "radius", "=", "4", ")", "\n", "", "else", ":", "\n", "                ", "frame", "=", "np", ".", "transpose", "(", "frame", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "*", "0.5", "+", "0.5", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "frame", "=", "(", "frame", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "", "return", "frame", "\n", "\n", "", "return", "overlay", "", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.videopose3d.process_videopose3d": [[17, 77], ["max", "videopose3d.process_videopose3d.normalize_screen_coordinates"], "function", ["None"], ["", "def", "process_videopose3d", "(", "key", ",", "batch_size", "=", "32", ",", "transform_coco", "=", "False", ")", ":", "\n", "\n", "    ", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "N", "=", "keypoints", ".", "shape", "[", "0", "]", "\n", "\n", "def", "normalize_screen_coordinates", "(", "X", ",", "w", ",", "h", ")", ":", "\n", "        ", "assert", "X", ".", "shape", "[", "-", "1", "]", "==", "2", "\n", "\n", "# Normalize so that [0, w] is mapped to [-1, 1], while preserving the aspect ratio", "\n", "if", "w", ">", "h", ":", "\n", "            ", "return", "X", "/", "w", "*", "2", "-", "[", "1", ",", "h", "/", "w", "]", "\n", "", "else", ":", "\n", "            ", "return", "X", "/", "h", "*", "2", "-", "[", "w", "/", "h", ",", "1", "]", "\n", "\n", "", "", "max_dim", "=", "max", "(", "height", ",", "width", ")", "\n", "keypoints", "=", "normalize_screen_coordinates", "(", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", ",", "width", ",", "height", ")", "\n", "keypoints", "=", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", "\n", "valid_frames", "=", "np", ".", "arange", "(", "keypoints", ".", "shape", "[", "0", "]", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"VIDEOPOSE3D_PATH\"", "]", ")", ":", "\n", "\n", "        ", "import", "torch", "\n", "from", "common", ".", "generators", "import", "ChunkedGenerator", "\n", "from", "common", ".", "model", "import", "TemporalModelOptimized1f", ",", "TemporalModel", "\n", "\n", "args", "=", "VideoPoseArgs", "(", ")", "\n", "filter_widths", "=", "[", "int", "(", "x", ")", "for", "x", "in", "args", ".", "architecture", ".", "split", "(", "','", ")", "]", "\n", "model_traj", "=", "TemporalModelOptimized1f", "(", "17", ",", "2", ",", "17", ",", "filter_widths", "=", "filter_widths", ",", "causal", "=", "args", ".", "causal", ",", "dropout", "=", "args", ".", "dropout", ",", "channels", "=", "args", ".", "channels", ")", "\n", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'videopose3d/pretrained_h36m_detectron_coco.bin'", ")", "#pretrained_h36m_cpn.bin')", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "\n", "model_traj", ".", "load_state_dict", "(", "checkpoint", "[", "'model_pos'", "]", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model_traj", ".", "eval", "(", ")", "\n", "\n", "", "receptive_field", "=", "model_traj", ".", "receptive_field", "(", ")", "\n", "pad", "=", "(", "receptive_field", "-", "1", ")", "//", "2", "# Padding on each side", "\n", "causal_shift", "=", "pad", "if", "args", ".", "causal", "else", "0", "\n", "\n", "gen", "=", "ChunkedGenerator", "(", "batch_size", "=", "batch_size", ",", "cameras", "=", "None", ",", "poses_3d", "=", "None", ",", "poses_2d", "=", "[", "keypoints", "[", ":", ",", ":", ",", ":", "2", "]", "]", ",", "chunk_length", "=", "1", ",", "shuffle", "=", "False", ",", "pad", "=", "pad", ",", "causal_shift", "=", "causal_shift", ")", "\n", "\n", "results", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "sample", "in", "tqdm", "(", "gen", ".", "next_epoch", "(", ")", ")", ":", "\n", "                ", "sample", "=", "sample", "[", "2", "]", "\n", "sample", "=", "torch", ".", "from_numpy", "(", "sample", ".", "astype", "(", "'float32'", ")", ")", ".", "contiguous", "(", ")", "\n", "out", "=", "model_traj", "(", "sample", ")", "\n", "\n", "results", ".", "append", "(", "out", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", ",", "0", ",", "...", "]", ")", "\n", "", "", "results", "=", "np", ".", "concatenate", "(", "results", ",", "axis", "=", "0", ")", "#/ 1000.0", "\n", "\n", "keypoints_3d", "=", "np", ".", "zeros", "(", "(", "N", ",", "17", ",", "3", ")", ")", "\n", "keypoints_3d", "[", "valid_frames", "]", "=", "results", "\n", "keypoints_valid", "=", "[", "i", "in", "valid_frames", ".", "tolist", "(", ")", "for", "i", "in", "np", ".", "arange", "(", "keypoints", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "return", "{", "'keypoints_3d'", ":", "keypoints_3d", ",", "'keypoints_valid'", ":", "keypoints_valid", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.VideoWithBoxes.__init__": [[17, 40], ["torch.Dataset.__init__", "cv2.VideoCapture", "len", "os.path.splitext", "numpy.where", "os.path.split"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "video", ",", "\n", "bboxes", ",", "\n", "present", ",", "\n", "transforms", "=", "None", ",", "\n", "scale_factor", "=", "1.2", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "VideoWithBoxes", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# to return with metadata", "\n", "self", ".", "video_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "split", "(", "video", ")", "[", "1", "]", ")", "[", "0", "]", "\n", "\n", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "\n", "# frames with valid bounding box", "\n", "self", ".", "valid_idx", "=", "np", ".", "where", "(", "present", ")", "[", "0", "]", "\n", "\n", "self", ".", "total_frames", "=", "len", "(", "self", ".", "valid_idx", ")", "\n", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n", "self", ".", "bboxes", "=", "bboxes", "[", "self", ".", "valid_idx", "]", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.VideoWithBoxes.__len__": [[41, 43], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "valid_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.VideoWithBoxes.__getitem__": [[44, 82], ["range", "numpy.array", "BoundingBox", "bbox_to_center_scale", "BoundingBox.add_field", "BoundingBox.add_field", "BoundingBox.add_field", "BoundingBox.add_field", "BoundingBox.add_field", "BoundingBox.add_field", "BoundingBox.add_field", "BoundingBox.add_field", "int", "expose.VideoWithBoxes.cap.read", "cv2.cvtColor", "expose.VideoWithBoxes.transforms", "expose.VideoWithBoxes.cap.get", "cv2.cvtColor.astype"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "from", "expose", ".", "data", ".", "targets", "import", "BoundingBox", "\n", "from", "expose", ".", "data", ".", "utils", ".", "bbox", "import", "bbox_to_center_scale", "\n", "\n", "bbox", "=", "self", ".", "bboxes", "[", "index", "]", "\n", "\n", "frame_idx", "=", "self", ".", "valid_idx", "[", "index", "]", "\n", "reads", "=", "1", "+", "frame_idx", "-", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_POS_FRAMES", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "reads", ")", ":", "\n", "            ", "ret", ",", "frame", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "if", "img", ".", "dtype", "==", "np", ".", "uint8", ":", "\n", "                ", "img", "=", "img", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.0", "\n", "\n", "# bounding boxes are stored in datajoint as TLHW format", "\n", "", "", "bbox", "=", "np", ".", "array", "(", "[", "bbox", "[", "0", "]", ",", "bbox", "[", "1", "]", ",", "bbox", "[", "2", "]", "+", "bbox", "[", "0", "]", ",", "bbox", "[", "3", "]", "+", "bbox", "[", "1", "]", "]", ")", "\n", "#bbox = torch.tensor(bbox).to(device=device)", "\n", "\n", "target", "=", "BoundingBox", "(", "bbox", ",", "size", "=", "img", ".", "shape", ")", "\n", "\n", "center", ",", "scale", ",", "bbox_size", "=", "bbox_to_center_scale", "(", "bbox", ",", "dset_scale_factor", "=", "self", ".", "scale_factor", ")", "\n", "target", ".", "add_field", "(", "'bbox_size'", ",", "bbox_size", ")", "\n", "target", ".", "add_field", "(", "'orig_bbox_size'", ",", "bbox_size", ")", "\n", "target", ".", "add_field", "(", "'orig_center'", ",", "center", ")", "\n", "target", ".", "add_field", "(", "'center'", ",", "center", ")", "\n", "target", ".", "add_field", "(", "'scale'", ",", "scale", ")", "\n", "target", ".", "add_field", "(", "'original_bbox'", ",", "bbox", ")", "\n", "target", ".", "add_field", "(", "'frame_idx'", ",", "self", ".", "valid_idx", "[", "index", "]", ")", "\n", "\n", "target", ".", "add_field", "(", "'fname'", ",", "f'{self.video_name}_{index:03d}'", ")", "\n", "\n", "if", "self", ".", "transforms", "is", "not", "None", ":", "\n", "            ", "full_img", ",", "cropped_image", ",", "target", "=", "self", ".", "transforms", "(", "img", ",", "target", ")", "\n", "\n", "", "return", "full_img", ",", "cropped_image", ",", "target", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu": [[84, 86], ["tensor.cpu().detach().numpy", "tensor.cpu().detach", "tensor.cpu"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "", "def", "cpu", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.get_model": [[88, 127], ["loguru.logger.remove", "get_cfg_defaults", "get_cfg_defaults.merge_from_file", "expose.get_model.update_dict"], "function", ["None"], ["", "def", "get_model", "(", "config_file", ",", "device", ",", "return_cfg", "=", "False", ")", ":", "\n", "    ", "from", "expose", ".", "models", ".", "smplx_net", "import", "SMPLXNet", "\n", "from", "expose", ".", "utils", ".", "checkpointer", "import", "Checkpointer", "\n", "\n", "logger", ".", "remove", "(", ")", "\n", "\n", "from", "expose", ".", "config", ".", "defaults", "import", "get_cfg_defaults", "\n", "cfg", "=", "get_cfg_defaults", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "config_file", ")", "\n", "cfg", ".", "is_training", "=", "False", "\n", "\n", "def", "update_dict", "(", "d", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "str", ")", "and", "v", ".", "startswith", "(", "'data'", ")", ":", "\n", "                ", "d", "[", "k", "]", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ",", "v", ")", "\n", "", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                ", "update_dict", "(", "v", ")", "\n", "", "", "", "update_dict", "(", "cfg", ")", "\n", "\n", "# load model with checkpoint", "\n", "model", "=", "SMPLXNet", "(", "cfg", ")", "\n", "model", "=", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "# annoyingly, despite above, still need to change working directory to load model", "\n", "pwd", "=", "os", ".", "getcwd", "(", ")", "\n", "os", ".", "chdir", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ")", "\n", "\n", "checkpoint_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "output_folder", ",", "cfg", ".", "checkpoint_folder", ")", "\n", "checkpointer", "=", "Checkpointer", "(", "model", ",", "save_dir", "=", "checkpoint_folder", ",", "pretrained", "=", "cfg", ".", "pretrained", ")", "\n", "extra_checkpoint_data", "=", "checkpointer", ".", "load_checkpoint", "(", ")", "\n", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "\n", "os", ".", "chdir", "(", "pwd", ")", "\n", "\n", "if", "return_cfg", ":", "\n", "        ", "return", "model", ",", "cfg", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.expose_parse_video": [[129, 205], ["torch.device", "torch.device", "expose.get_model", "cfg.get", "cfg.get.get", "dataset_cfg.get.get", "build_transforms", "expose.VideoWithBoxes", "functools.partial", "torch.DataLoader", "tqdm.tqdm", "to_image_list", "body_imgs.to.to", "full_imgs.to.to", "torch.cuda.synchronize", "torch.cuda.synchronize", "model", "torch.cuda.synchronize", "torch.cuda.synchronize", "[].tolist", "cpu().tolist", "results[].extend", "results[].extend", "results[].extend", "results[].extend", "results[].extend", "results[].extend", "results[].extend", "target.to", "t.get_field", "t.get_field", "t.get_field", "v.cpu().detach().numpy", "dict", "v.cpu().detach().numpy", "dict", "expose.cpu", "params.items", "zip", "zip", "params.items", "zip", "zip", "expose.cpu", "v.cpu().detach", "v.cpu().detach", "initial_params.values", "final_params.values", "v.cpu", "v.cpu"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.get_model", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.cpu"], ["", "def", "expose_parse_video", "(", "video", ",", "bboxes", ",", "present", ",", "config_file", ",", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", ",", "batch_size", "=", "16", ")", ":", "\n", "\n", "    ", "from", "expose", ".", "data", ".", "build", "import", "collate_batch", "\n", "from", "expose", ".", "data", ".", "transforms", "import", "build_transforms", "\n", "from", "expose", ".", "data", ".", "targets", ".", "image_list", "import", "to_image_list", "\n", "\n", "model", ",", "cfg", "=", "get_model", "(", "config_file", ",", "device", ",", "return_cfg", "=", "True", ")", "\n", "\n", "# prepare data parser", "\n", "dataset_cfg", "=", "cfg", ".", "get", "(", "'datasets'", ",", "{", "}", ")", "\n", "body_dsets_cfg", "=", "dataset_cfg", ".", "get", "(", "'body'", ",", "{", "}", ")", "\n", "body_transfs_cfg", "=", "body_dsets_cfg", ".", "get", "(", "'transforms'", ",", "{", "}", ")", "\n", "\n", "# must be zero with the code above", "\n", "num_workers", "=", "0", "\n", "\n", "transforms", "=", "build_transforms", "(", "body_transfs_cfg", ",", "is_train", "=", "False", ")", "\n", "dataset", "=", "VideoWithBoxes", "(", "video", ",", "bboxes", ",", "present", ",", "transforms", "=", "transforms", ")", "\n", "expose_collate", "=", "functools", ".", "partial", "(", "\n", "collate_batch", ",", "use_shared_memory", "=", "num_workers", ">", "0", ",", "\n", "return_full_imgs", "=", "True", ")", "\n", "\n", "expose_dloader", "=", "dutils", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "expose_collate", ",", "\n", "drop_last", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "\n", "results", "=", "{", "'bbox_size'", ":", "[", "]", ",", "'bbox_center'", ":", "[", "]", ",", "'camera_scale'", ":", "[", "]", ",", "'camera_transl'", ":", "[", "]", ",", "\n", "'initial_params'", ":", "[", "]", ",", "'final_params'", ":", "[", "]", ",", "'frames'", ":", "[", "]", ",", "'faces'", ":", "[", "]", "}", "\n", "\n", "for", "batch", "in", "tqdm", "(", "expose_dloader", ",", "dynamic_ncols", "=", "True", ")", ":", "\n", "\n", "        ", "full_imgs_list", ",", "body_imgs", ",", "body_targets", "=", "batch", "\n", "if", "full_imgs_list", "is", "None", ":", "\n", "            ", "continue", "\n", "\n", "", "full_imgs", "=", "to_image_list", "(", "full_imgs_list", ")", "\n", "body_imgs", "=", "body_imgs", ".", "to", "(", "device", "=", "device", ")", "\n", "body_targets", "=", "[", "target", ".", "to", "(", "device", ")", "for", "target", "in", "body_targets", "]", "\n", "full_imgs", "=", "full_imgs", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "model_output", "=", "model", "(", "body_imgs", ",", "body_targets", ",", "full_imgs", "=", "full_imgs", ",", "device", "=", "device", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "# parse the data to save", "\n", "bbox_size", "=", "[", "t", ".", "get_field", "(", "'orig_bbox_size'", ")", "for", "t", "in", "body_targets", "]", "\n", "bbox_center", "=", "[", "t", ".", "get_field", "(", "'orig_center'", ")", "for", "t", "in", "body_targets", "]", "\n", "frame_idx", "=", "[", "t", ".", "get_field", "(", "'frame_idx'", ")", "for", "t", "in", "body_targets", "]", "\n", "camera_parameters", "=", "model_output", "[", "'body'", "]", "[", "'camera_parameters'", "]", "\n", "camera_scale", "=", "cpu", "(", "camera_parameters", "[", "'scale'", "]", ")", "[", ":", ",", "0", "]", ".", "tolist", "(", ")", "\n", "camera_transl", "=", "cpu", "(", "camera_parameters", "[", "'translation'", "]", ")", ".", "tolist", "(", ")", "\n", "\n", "params", "=", "model_output", "[", "'body'", "]", "[", "'stage_02'", "]", "\n", "initial_params", "=", "{", "k", ":", "v", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", "if", "k", "not", "in", "[", "'faces'", "]", "}", "\n", "initial_params", "=", "[", "dict", "(", "zip", "(", "initial_params", ",", "t", ")", ")", "for", "t", "in", "zip", "(", "*", "initial_params", ".", "values", "(", ")", ")", "]", "\n", "\n", "params", "=", "model_output", "[", "'body'", "]", "[", "'final'", "]", "\n", "final_params", "=", "{", "k", ":", "v", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "# k not in ['full_pose'] and", "\n", "final_params", "=", "[", "dict", "(", "zip", "(", "final_params", ",", "t", ")", ")", "for", "t", "in", "zip", "(", "*", "final_params", ".", "values", "(", ")", ")", "]", "\n", "\n", "# add to accumulator", "\n", "results", "[", "'faces'", "]", "=", "model_output", "[", "'body'", "]", "[", "'stage_02'", "]", "[", "'faces'", "]", "\n", "results", "[", "'frames'", "]", ".", "extend", "(", "frame_idx", ")", "\n", "results", "[", "'bbox_size'", "]", ".", "extend", "(", "bbox_size", ")", "\n", "results", "[", "'bbox_center'", "]", ".", "extend", "(", "bbox_center", ")", "\n", "results", "[", "'camera_scale'", "]", ".", "extend", "(", "camera_scale", ")", "\n", "results", "[", "'camera_transl'", "]", ".", "extend", "(", "camera_transl", ")", "\n", "results", "[", "'initial_params'", "]", ".", "extend", "(", "initial_params", ")", "\n", "results", "[", "'final_params'", "]", ".", "extend", "(", "final_params", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.process_expose": [[207, 268], ["os.path.join", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "final_params[].keys", "convert_crop_coords_to_orig_img", "pose_pipeline.env.add_path", "pose_pipeline.Video.get_robust_reader", "expose.expose_parse_video", "os.remove", "numpy.array", "numpy.array", "len", "R.from_matrix().as_rotvec", "R.from_matrix"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.utils.bounding_box.convert_crop_coords_to_orig_img", "home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader", "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.expose_parse_video"], ["", "def", "process_expose", "(", "key", ",", "return_results", "=", "False", ")", ":", "\n", "\n", "# need to add this to path before importing the parse function", "\n", "    ", "exp_cfg", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ",", "'data/conf.yaml'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ")", ":", "\n", "        ", "from", "pose_pipeline", ".", "wrappers", ".", "expose", "import", "expose_parse_video", "\n", "\n", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "return_cap", "=", "False", ")", "\n", "bboxes", ",", "present", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ",", "'present'", ")", "\n", "\n", "results", "=", "expose_parse_video", "(", "video", ",", "bboxes", ",", "present", ",", "exp_cfg", ")", "\n", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n", "", "from", "scipy", ".", "spatial", ".", "transform", "import", "Rotation", "as", "R", "\n", "from", "pose_pipeline", ".", "utils", ".", "bounding_box", "import", "convert_crop_coords_to_orig_img", ",", "convert_crop_cam_to_orig_img", "\n", "crop_size", "=", "224", "\n", "\n", "key", "[", "'joints3d'", "]", "=", "np", ".", "asarray", "(", "[", "r", "[", "'joints'", "]", "for", "r", "in", "results", "[", "'final_params'", "]", "]", ")", "\n", "key", "[", "'joints2d'", "]", "=", "np", ".", "asarray", "(", "[", "r", "[", "'proj_joints'", "]", "for", "r", "in", "results", "[", "'final_params'", "]", "]", ")", "\n", "key", "[", "'verts'", "]", "=", "np", ".", "asarray", "(", "[", "r", "[", "'vertices'", "]", "for", "r", "in", "results", "[", "'final_params'", "]", "]", ")", "\n", "key", "[", "'betas'", "]", "=", "np", ".", "asarray", "(", "[", "r", "[", "'betas'", "]", "for", "r", "in", "results", "[", "'final_params'", "]", "]", ")", "\n", "\n", "# SMPL-X models use a more complex pose representation that is factored", "\n", "# into body type. Try to consistently use the rotation vector format in", "\n", "# this.", "\n", "key", "[", "'poses'", "]", "=", "{", "}", "\n", "final_params", "=", "results", "[", "'final_params'", "]", "\n", "for", "k", "in", "final_params", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "if", "k", "in", "[", "'betas'", ",", "'vertices'", ",", "'joints'", ",", "'proj_joints'", "]", ":", "\n", "# these are stored in other table columns. only keep the", "\n", "# specific pose parameters", "\n", "            ", "continue", "\n", "\n", "", "from", "scipy", ".", "spatial", ".", "transform", "import", "Rotation", "as", "R", "\n", "\n", "# convert matrices to rotation vector format", "\n", "if", "len", "(", "final_params", "[", "0", "]", "[", "k", "]", ".", "shape", ")", "==", "3", "and", "k", "!=", "'proj_joints'", ":", "\n", "            ", "key", "[", "'poses'", "]", "[", "k", "]", "=", "np", ".", "array", "(", "[", "R", ".", "from_matrix", "(", "f", "[", "k", "]", ")", ".", "as_rotvec", "(", ")", "for", "f", "in", "final_params", "]", ")", "\n", "", "else", ":", "\n", "            ", "key", "[", "'poses'", "]", "[", "k", "]", "=", "np", ".", "array", "(", "[", "f", "[", "k", "]", "for", "f", "in", "final_params", "]", ")", "\n", "\n", "# still currently have the ugly format where only present frames are", "\n", "# stored so we need to account for this", "\n", "", "", "bboxes_dj", ",", "present_dj", "=", "(", "Video", "*", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ",", "'present'", ")", "\n", "bbox", "=", "bboxes_dj", "[", "present_dj", "]", "\n", "key", "[", "'joints2d'", "]", "=", "convert_crop_coords_to_orig_img", "(", "bbox", ",", "key", "[", "'joints2d'", "]", ",", "crop_size", ")", "\n", "\n", "key", "[", "'cams'", "]", "=", "{", "\n", "'bbox_size'", ":", "results", "[", "'bbox_size'", "]", ",", "\n", "'bbox_center'", ":", "results", "[", "'bbox_center'", "]", ",", "\n", "'camera_scale'", ":", "results", "[", "'camera_scale'", "]", ",", "\n", "'camera_transl'", ":", "results", "[", "'camera_transl'", "]", "\n", "}", "\n", "\n", "if", "return_results", ":", "\n", "        ", "return", "key", ",", "results", "\n", "\n", "", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.get_expose_callback": [[270, 351], ["[].tolist", "os.path.join", "pose.copy.copy", "betas.copy", "dict", "pose.copy.keys", "get_model.smplx.body_model", "pose_pipeline.env.add_path", "expose.get_model", "pose_pipeline.env.add_path", "HDRenderer", "x.reshape.reshape", "R.from_rotvec().as_matrix", "x.reshape.reshape", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "[].tolist.index", "HDRenderer.", "numpy.transpose", "numpy.where", "R.from_rotvec", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "expose.get_expose_callback.to_mat"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.expose.get_model"], ["", "def", "get_expose_callback", "(", "key", ")", ":", "\n", "\n", "    ", "import", "smplx", "\n", "from", "pose_pipeline", ".", "pipeline", "import", "SMPLPerson", ",", "PersonBbox", "\n", "\n", "focal_length", "=", "5000.0", "\n", "\n", "present", ",", "cams", "=", "(", "SMPLPerson", "*", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'present'", ",", "'cams'", ")", "\n", "frames", "=", "np", ".", "where", "(", "present", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "\n", "# COUNTERINTUITIVE: it appears like the checkpoint for the", "\n", "# Expose model changes the behavior of SMPL-X, so we need to", "\n", "# load this one up to recompute vertices", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ",", "'data/conf.yaml'", ")", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ")", ":", "\n", "        ", "model", "=", "get_model", "(", "config_file", ",", "'cpu'", ")", "\n", "\n", "", "faces", "=", "model", ".", "smplx", ".", "body_model", ".", "faces", "\n", "\n", "# get SMPL parameters", "\n", "betas", ",", "pose", "=", "(", "SMPLPerson", "&", "key", ")", ".", "fetch1", "(", "'betas'", ",", "'poses'", ")", "\n", "pose", "=", "pose", ".", "copy", "(", ")", "\n", "pose", "[", "'betas'", "]", "=", "betas", ".", "copy", "(", ")", "\n", "\n", "# and reformat them back to rotation matrices", "\n", "params", "=", "dict", "(", ")", "\n", "for", "k", "in", "pose", ".", "keys", "(", ")", ":", "\n", "        ", "from", "scipy", ".", "spatial", ".", "transform", "import", "Rotation", "as", "R", "\n", "\n", "if", "k", "in", "[", "'vertices'", ",", "'joints'", ",", "'proj_joints'", "]", ":", "\n", "            ", "continue", "\n", "\n", "", "def", "to_mat", "(", "x", ")", ":", "\n", "            ", "batch", ",", "joints", ",", "_", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "[", "batch", "*", "joints", ",", "3", "]", ")", "\n", "x", "=", "R", ".", "from_rotvec", "(", "x", ")", ".", "as_matrix", "(", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "batch", ",", "joints", ",", "3", ",", "3", "]", ")", "\n", "return", "x", "\n", "\n", "", "if", "k", "in", "[", "'body_pose'", ",", "'global_orient'", ",", "'left_hand_pose'", ",", "\n", "'right_hand_pose'", ",", "'jaw_pose'", "]", ":", "\n", "            ", "params", "[", "k", "]", "=", "torch", ".", "tensor", "(", "to_mat", "(", "pose", "[", "k", "]", ".", "copy", "(", ")", ")", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "params", "[", "k", "]", "=", "torch", ".", "tensor", "(", "pose", "[", "k", "]", ".", "copy", "(", ")", ")", ".", "float", "(", ")", "\n", "\n", "", "", "pred", "=", "model", ".", "smplx", ".", "body_model", "(", "get_skin", "=", "True", ",", "return_shaped", "=", "True", ",", "**", "params", ")", "\n", "verts", "=", "pred", "[", "'vertices'", "]", "\n", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "'EXPOSE_PATH'", "]", ")", ":", "\n", "        ", "from", "expose", ".", "utils", ".", "plot_utils", "import", "HDRenderer", "\n", "renderer", "=", "HDRenderer", "(", ")", "\n", "\n", "def", "overlay_frame", "(", "image", ",", "frame_idx", ")", ":", "\n", "\n", "            ", "if", "frame_idx", "not", "in", "frames", ":", "\n", "                ", "return", "image", "\n", "\n", "", "idx", "=", "frames", ".", "index", "(", "frame_idx", ")", "\n", "\n", "image", "=", "image", "/", "255.0", "\n", "\n", "z", "=", "2", "*", "focal_length", "/", "(", "cams", "[", "'camera_scale'", "]", "[", "idx", "]", "*", "cams", "[", "'bbox_size'", "]", "[", "idx", "]", ")", "\n", "\n", "transl", "=", "[", "*", "cams", "[", "'camera_transl'", "]", "[", "idx", "]", ",", "z", "]", "\n", "\n", "image", "=", "renderer", "(", "verts", "[", "None", ",", "idx", ",", "...", "]", ",", "\n", "faces", ",", "focal_length", "=", "[", "focal_length", "]", ",", "\n", "camera_translation", "=", "[", "transl", "]", ",", "\n", "camera_center", "=", "[", "cams", "[", "'bbox_center'", "]", "[", "idx", "]", "]", ",", "\n", "bg_imgs", "=", "[", "np", ".", "transpose", "(", "image", ",", "[", "2", ",", "0", ",", "1", "]", ")", "]", ",", "\n", "return_with_alpha", "=", "False", ",", "\n", "body_color", "=", "[", "0.4", ",", "0.4", ",", "0.7", "]", "\n", ")", "\n", "\n", "image", "=", "np", ".", "transpose", "(", "image", "[", "0", "]", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "image", "=", "(", "image", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "return", "image", "\n", "\n", "", "return", "overlay_frame", "", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmpose.mmpose_top_down_person": [[9, 43], ["os.path.join", "os.path.join", "pose_pipeline.Video.get_robust_reader", "init_pose_model", "tqdm.tqdm", "numpy.asarray", "Video.get_robust_reader.read", "numpy.any", "cv2.cvtColor", "results.append", "numpy.isnan", "results.append", "inference_top_down_pose_model", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader"], ["def", "mmpose_top_down_person", "(", "key", ")", ":", "\n", "\n", "    ", "from", "mmpose", ".", "apis", "import", "init_pose_model", ",", "inference_top_down_pose_model", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "pose_cfg", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmpose/config/top_down/darkpose/coco/hrnet_w48_coco_384x288_dark.py'", ")", "\n", "pose_ckpt", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmpose/checkpoints/hrnet_w48_coco_384x288_dark-e881a4b6_20210203.pth'", ")", "\n", "\n", "bboxes", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ")", "\n", "cap", "=", "Video", ".", "get_robust_reader", "(", "key", ")", "\n", "\n", "model", "=", "init_pose_model", "(", "pose_cfg", ",", "pose_ckpt", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "bbox", "in", "tqdm", "(", "bboxes", ")", ":", "\n", "\n", "# should match the length of identified person tracks", "\n", "        ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "assert", "ret", "and", "frame", "is", "not", "None", "\n", "\n", "# handle the case where person is not tracked in frame", "\n", "if", "np", ".", "any", "(", "np", ".", "isnan", "(", "bbox", ")", ")", ":", "\n", "            ", "results", ".", "append", "(", "np", ".", "zeros", "(", "(", "17", ",", "3", ")", ")", ")", "\n", "continue", "\n", "\n", "", "bbox_wrap", "=", "{", "'bbox'", ":", "bbox", "}", "\n", "\n", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "res", "=", "inference_top_down_pose_model", "(", "model", ",", "frame", ",", "[", "bbox_wrap", "]", ")", "[", "0", "]", "\n", "results", ".", "append", "(", "res", "[", "0", "]", "[", "'keypoints'", "]", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmpose.mmpose_whole_body": [[45, 81], ["os.path.join", "os.path.join", "pose_pipeline.Video.get_robust_reader", "init_pose_model", "tqdm.tqdm", "numpy.asarray", "Video.get_robust_reader.read", "numpy.any", "cv2.cvtColor", "results.append", "numpy.isnan", "results.append", "inference_top_down_pose_model", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader"], ["", "def", "mmpose_whole_body", "(", "key", ")", ":", "\n", "# keypoint order can be found in ", "\n", "# https://github.com/jin-s13/COCO-WholeBody", "\n", "\n", "    ", "from", "mmpose", ".", "apis", "import", "init_pose_model", ",", "inference_top_down_pose_model", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "pose_cfg", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmpose/config/coco-wholebody/hrnet_w48_coco_wholebody_384x288_dark_plus.py'", ")", "\n", "pose_ckpt", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmpose/checkpoints/hrnet_w48_coco_wholebody_384x288_dark-f5726563_20200918.pth'", ")", "\n", "\n", "bboxes", "=", "(", "PersonBbox", "&", "key", ")", ".", "fetch1", "(", "'bbox'", ")", "\n", "cap", "=", "Video", ".", "get_robust_reader", "(", "key", ")", "\n", "\n", "model", "=", "init_pose_model", "(", "pose_cfg", ",", "pose_ckpt", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "bbox", "in", "tqdm", "(", "bboxes", ")", ":", "\n", "\n", "# should match the length of identified person tracks", "\n", "        ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "assert", "ret", "and", "frame", "is", "not", "None", "\n", "\n", "# handle the case where person is not tracked in frame", "\n", "if", "np", ".", "any", "(", "np", ".", "isnan", "(", "bbox", ")", ")", ":", "\n", "            ", "results", ".", "append", "(", "np", ".", "zeros", "(", "(", "17", ",", "3", ")", ")", ")", "\n", "continue", "\n", "\n", "", "bbox_wrap", "=", "{", "'bbox'", ":", "bbox", "}", "\n", "\n", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "res", "=", "inference_top_down_pose_model", "(", "model", ",", "frame", ",", "[", "bbox_wrap", "]", ")", "[", "0", "]", "\n", "results", ".", "append", "(", "res", "[", "0", "]", "[", "'keypoints'", "]", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmpose.mmpose_bottom_up": [[83, 117], ["os.path.join", "os.path.join", "init_pose_model", "pose_pipeline.Video.get_robust_reader", "cv2.VideoCapture", "int", "tqdm.tqdm", "cv2.VideoCapture.release", "os.remove", "numpy.asarray", "cv2.VideoCapture.get", "range", "cv2.VideoCapture.read", "cv2.cvtColor", "numpy.stack", "keypoints.append", "inference_bottom_up_pose_model"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.Video.get_robust_reader"], ["", "def", "mmpose_bottom_up", "(", "key", ")", ":", "\n", "\n", "    ", "from", "mmpose", ".", "apis", "import", "init_pose_model", ",", "inference_bottom_up_pose_model", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "pose_cfg", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmpose/config/bottom_up/higherhrnet/coco/higher_hrnet48_coco_512x512.py'", ")", "\n", "pose_ckpt", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'mmpose/checkpoints/higher_hrnet48_coco_512x512-60fedcbc_20200712.pth'", ")", "\n", "\n", "model", "=", "init_pose_model", "(", "pose_cfg", ",", "pose_ckpt", ")", "\n", "\n", "video", "=", "Video", ".", "get_robust_reader", "(", "key", ",", "return_cap", "=", "False", ")", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "video", ")", "\n", "\n", "video_length", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n", "keypoints", "=", "[", "]", "\n", "for", "frame_id", "in", "tqdm", "(", "range", "(", "video_length", ")", ")", ":", "\n", "\n", "# should match the length of identified person tracks", "\n", "        ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "assert", "ret", "and", "frame", "is", "not", "None", "\n", "\n", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "res", "=", "inference_bottom_up_pose_model", "(", "model", ",", "frame", ")", "[", "0", "]", "\n", "\n", "kps", "=", "np", ".", "stack", "(", "[", "x", "[", "'keypoints'", "]", "for", "x", "in", "res", "]", ",", "axis", "=", "0", ")", "\n", "keypoints", ".", "append", "(", "kps", ")", "\n", "\n", "", "cap", ".", "release", "(", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "\n", "return", "np", ".", "asarray", "(", "keypoints", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmaction.TopDownPersonVideo.make": [[93, 116], ["PersonBbox.get_overlay_fn", "tempfile.mkstemp", "video_overlay", "mmaction.TopDownPersonVideo.insert1", "os.remove", "os.remove", "draw_keypoints", "PersonBbox.get_overlay_fn."], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.pose_pipeline.pipeline.PersonBbox.get_overlay_fn", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.video_overlay", "home.repos.pwc.inspect_result.peabody124_posepipeline.utils.visualization.draw_keypoints"], ["def", "make", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", ".", "utils", ".", "visualization", "import", "video_overlay", ",", "draw_keypoints", "\n", "\n", "video", "=", "(", "BlurredVideo", "&", "key", ")", ".", "fetch1", "(", "'output_video'", ")", "\n", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "\n", "bbox_fn", "=", "PersonBbox", ".", "get_overlay_fn", "(", "key", ")", "\n", "\n", "def", "overlay_fn", "(", "image", ",", "idx", ")", ":", "\n", "            ", "image", "=", "draw_keypoints", "(", "image", ",", "keypoints", "[", "idx", "]", ")", "\n", "image", "=", "bbox_fn", "(", "image", ",", "idx", ")", "\n", "return", "image", "\n", "\n", "", "_", ",", "out_file_name", "=", "tempfile", ".", "mkstemp", "(", "suffix", "=", "'.mp4'", ")", "\n", "video_overlay", "(", "video", ",", "out_file_name", ",", "overlay_fn", ",", "downsample", "=", "1", ")", "\n", "\n", "key", "[", "'output_video'", "]", "=", "out_file_name", "\n", "\n", "self", ".", "insert1", "(", "key", ")", "\n", "\n", "os", ".", "remove", "(", "out_file_name", ")", "\n", "os", ".", "remove", "(", "video", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.mmaction.mmaction_skeleton_action_person": [[9, 84], ["mmaction.mmaction_skeleton_action_person.load_label_map"], "function", ["None"], ["def", "mmaction_skeleton_action_person", "(", "key", ",", "device", "=", "'cuda'", ",", "stride", "=", "1", ")", ":", "\n", "\n", "    ", "import", "torch", "\n", "import", "mmcv", "\n", "from", "mmcv", ".", "runner", "import", "load_checkpoint", "\n", "from", "mmaction", ".", "datasets", ".", "pipelines", "import", "Compose", "\n", "from", "mmaction", ".", "models", "import", "build_detector", ",", "build_model", ",", "build_recognizer", "\n", "\n", "# fetch data", "\n", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "img_shape", "=", "(", "h", ",", "w", ")", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "# prepare action recognition model", "\n", "skeleton_config_file", "=", "'/home/jcotton/projects/pose/mmaction2/configs/skeleton/posec3d/slowonly_r50_u48_240e_ntu120_xsub_keypoint.py'", "\n", "skeleton_stdet_checkpoint", "=", "'https://download.openmmlab.com/mmaction/skeleton/posec3d/posec3d_ava.pth'", "\n", "label_map", "=", "'/home/jcotton/projects/pose/mmaction2/tools/data/ava/label_map.txt'", "\n", "\n", "def", "load_label_map", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"Load Label Map.\n        Args:\n            file_path (str): The file path of label map.\n        Returns:\n            dict: The label map (int -> label name).\n        \"\"\"", "\n", "lines", "=", "open", "(", "file_path", ")", ".", "readlines", "(", ")", "\n", "lines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "': '", ")", "for", "x", "in", "lines", "]", "\n", "return", "{", "int", "(", "x", "[", "0", "]", ")", ":", "x", "[", "1", "]", "for", "x", "in", "lines", "}", "\n", "\n", "", "label_map", "=", "load_label_map", "(", "label_map", ")", "\n", "num_class", "=", "np", ".", "max", "(", "[", "k", "for", "k", "in", "label_map", ".", "keys", "(", ")", "]", ")", "\n", "\n", "skeleton_config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "skeleton_config_file", ")", "\n", "skeleton_config", ".", "model", ".", "cls_head", ".", "num_classes", "=", "num_class", "+", "1", "# for AVA", "\n", "\n", "skeleton_pipeline", "=", "Compose", "(", "skeleton_config", ".", "test_pipeline", ")", "\n", "skeleton_stdet_model", "=", "build_model", "(", "skeleton_config", ".", "model", ")", "\n", "load_checkpoint", "(", "\n", "skeleton_stdet_model", ",", "\n", "skeleton_stdet_checkpoint", ",", "\n", "map_location", "=", "'cpu'", ")", "\n", "skeleton_stdet_model", ".", "to", "(", "device", ")", "\n", "skeleton_stdet_model", ".", "eval", "(", ")", "\n", "\n", "# analyze video with rolling window. can increase stride to speed things up", "\n", "# but need to account for the fact the time steps won't match", "\n", "clip_len", "=", "skeleton_config", ".", "test_pipeline", "[", "0", "]", "[", "'clip_len'", "]", "\n", "\n", "results", "=", "[", "]", "\n", "for", "start", "in", "tqdm", "(", "range", "(", "0", ",", "keypoints", ".", "shape", "[", "0", "]", "-", "clip_len", "-", "1", ",", "stride", ")", ")", ":", "\n", "        ", "skeleton_imgs", "=", "skeleton_pipeline", "(", "{", "'keypoint'", ":", "keypoints", "[", "None", ",", "start", ":", "start", "+", "clip_len", ",", ":", ",", ":", "2", "]", ",", "\n", "'keypoint_score'", ":", "keypoints", "[", "None", ",", "start", ":", "start", "+", "clip_len", ",", ":", ",", "2", "]", ",", "\n", "'total_frames'", ":", "10", ",", "\n", "'start_index'", ":", "0", ",", "\n", "'modality'", ":", "'Pose'", ",", "\n", "'label'", ":", "-", "1", ",", "\n", "'img_shape'", ":", "img_shape", "}", ")", "[", "'imgs'", "]", "[", "None", "]", "\n", "\n", "skeleton_imgs", "=", "skeleton_imgs", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "skeleton_stdet_model", "(", "return_loss", "=", "False", ",", "imgs", "=", "skeleton_imgs", ")", "[", "0", "]", "\n", "results", ".", "append", "(", "output", ")", "\n", "\n", "", "", "def", "top5", "(", "x", ")", ":", "\n", "        ", "ind", "=", "np", ".", "argpartition", "(", "x", ",", "-", "5", ")", "[", "-", "5", ":", "]", "\n", "ind", "=", "ind", "[", "np", ".", "argsort", "(", "-", "x", "[", "ind", "]", ")", "]", "\n", "return", "[", "(", "label_map", "[", "y", "]", ",", "x", "[", "y", "]", ")", "for", "y", "in", "ind", "]", "\n", "\n", "", "key", "[", "'top5'", "]", "=", "[", "top5", "(", "x", ")", "for", "x", "in", "results", "]", "\n", "key", "[", "'action_scores'", "]", "=", "np", ".", "array", "(", "results", ")", "\n", "key", "[", "'label_map'", "]", "=", "label_map", "\n", "key", "[", "'action_window_len'", "]", "=", "clip_len", "\n", "key", "[", "'stride'", "]", "=", "stride", "\n", "\n", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.wrappers.gastnet_lifting.process_gastnet": [[9, 75], ["key.copy.copy", "os.path.join", "numpy.zeros", "pose_pipeline.env.add_path", "h36m_coco_format", "revise_kpts", "gastnet_lifting.process_gastnet.gast_load_model"], "function", ["None"], ["def", "process_gastnet", "(", "key", ")", ":", "\n", "\n", "    ", "key", "=", "key", ".", "copy", "(", ")", "\n", "\n", "keypoints", "=", "(", "TopDownPerson", "&", "key", ")", ".", "fetch1", "(", "'keypoints'", ")", "\n", "height", ",", "width", "=", "(", "VideoInfo", "&", "key", ")", ".", "fetch1", "(", "'height'", ",", "'width'", ")", "\n", "\n", "gastnet_files", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'gastnet/'", ")", "\n", "\n", "with", "add_path", "(", "os", ".", "environ", "[", "\"GAST_PATH\"", "]", ")", ":", "\n", "\n", "        ", "import", "torch", "\n", "from", "model", ".", "gast_net", "import", "SpatioTemporalModel", ",", "SpatioTemporalModelOptimized1f", "\n", "from", "common", ".", "graph_utils", "import", "adj_mx_from_skeleton", "\n", "from", "common", ".", "skeleton", "import", "Skeleton", "\n", "from", "tools", ".", "inference", "import", "gen_pose", "\n", "from", "tools", ".", "preprocess", "import", "h36m_coco_format", ",", "revise_kpts", "\n", "\n", "def", "gast_load_model", "(", "rf", "=", "27", ")", ":", "\n", "            ", "if", "rf", "==", "27", ":", "\n", "                ", "chk", "=", "gastnet_files", "+", "'27_frame_model.bin'", "\n", "filters_width", "=", "[", "3", ",", "3", ",", "3", "]", "\n", "channels", "=", "128", "\n", "", "elif", "rf", "==", "81", ":", "\n", "                ", "chk", "=", "gastnet_files", "+", "'81_frame_model.bin'", "\n", "filters_width", "=", "[", "3", ",", "3", ",", "3", ",", "3", "]", "\n", "channels", "=", "64", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Only support 27 and 81 receptive field models for inference!'", ")", "\n", "\n", "", "skeleton", "=", "Skeleton", "(", "parents", "=", "[", "-", "1", ",", "0", ",", "1", ",", "2", ",", "0", ",", "4", ",", "5", ",", "0", ",", "7", ",", "8", ",", "9", ",", "8", ",", "11", ",", "12", ",", "8", ",", "14", ",", "15", "]", ",", "\n", "joints_left", "=", "[", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "22", ",", "23", "]", ",", "\n", "joints_right", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "24", ",", "25", ",", "26", ",", "27", ",", "28", ",", "29", ",", "30", ",", "31", "]", ")", "\n", "adj", "=", "adj_mx_from_skeleton", "(", "skeleton", ")", "\n", "\n", "model_pos", "=", "SpatioTemporalModel", "(", "adj", ",", "17", ",", "2", ",", "17", ",", "filter_widths", "=", "filters_width", ",", "channels", "=", "channels", ",", "dropout", "=", "0.05", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "chk", ")", "\n", "model_pos", ".", "load_state_dict", "(", "checkpoint", "[", "'model_pos'", "]", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "model_pos", "=", "model_pos", ".", "cuda", "(", ")", "\n", "", "model_pos", ".", "eval", "(", ")", "\n", "\n", "return", "model_pos", "\n", "\n", "", "keypoints_reformat", ",", "keypoints_score", "=", "keypoints", "[", "None", ",", "...", ",", ":", "2", "]", ",", "keypoints", "[", "None", ",", "...", ",", "2", "]", "\n", "keypoints", ",", "scores", ",", "valid_frames", "=", "h36m_coco_format", "(", "keypoints_reformat", ",", "keypoints_score", ")", "\n", "\n", "re_kpts", "=", "revise_kpts", "(", "keypoints", ",", "scores", ",", "valid_frames", ")", "\n", "assert", "len", "(", "re_kpts", ")", "==", "1", "\n", "\n", "rf", "=", "27", "\n", "model_pos", "=", "gast_load_model", "(", "rf", ")", "\n", "\n", "pad", "=", "(", "rf", "-", "1", ")", "//", "2", "# Padding on each side", "\n", "causal_shift", "=", "0", "\n", "\n", "# Generating 3D poses", "\n", "prediction", "=", "gen_pose", "(", "re_kpts", ",", "valid_frames", ",", "width", ",", "height", ",", "model_pos", ",", "pad", ",", "causal_shift", ")", "\n", "\n", "", "keypoints_3d", "=", "np", ".", "zeros", "(", "(", "keypoints", ".", "shape", "[", "1", "]", ",", "17", ",", "3", ")", ")", "\n", "keypoints_3d", "[", "np", ".", "array", "(", "valid_frames", "[", "0", "]", ")", "]", "=", "prediction", "[", "0", "]", "\n", "keypoints_valid", "=", "[", "i", "in", "valid_frames", "[", "0", "]", "for", "i", "in", "np", ".", "arange", "(", "keypoints", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "return", "{", "'keypoints_3d'", ":", "keypoints_3d", ",", "'keypoints_valid'", ":", "keypoints_valid", "}", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.parser.tracking_bounding_boxes": [[21, 107], ["cv2.VideoCapture", "int", "int", "cv2.VideoCapture.get", "int", "yolo.YOLO", "os.path.join", "tools.generate_detections.create_box_encoder", "deep_sort.nn_matching.NearestNeighborDistanceMetric", "deep_sort.tracker.Tracker", "tqdm.tqdm", "cv2.VideoCapture.release", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "cv2.VideoWriter", "range", "cv2.VideoCapture.read", "PIL.Image.fromarray", "yolo.YOLO.detect_image", "gdet.create_box_encoder.", "numpy.array", "numpy.array", "deep_sort.preprocessing.non_max_suppression", "deep_sort.tracker.Tracker.predict", "deep_sort.tracker.Tracker.update", "tracks.append", "cv2.VideoWriter.release", "deep_sort.detection.Detection", "cv2.VideoWriter.write", "zip", "track.to_tlbr", "cv2.rectangle", "cv2.putText", "cv2.putText", "det.to_tlbr", "cv2.rectangle", "t.to_tlwh", "t.to_tlbr", "len", "cv2.putText", "track.is_confirmed", "int", "int", "int", "int", "str", "int", "int", "str", "int", "int", "round", "int", "int", "int", "int", "int", "int", "str"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.create_box_encoder", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO.detect_image", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.preprocessing.non_max_suppression", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.predict", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlbr", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlbr", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlwh", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlbr", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_confirmed"], ["def", "tracking_bounding_boxes", "(", "file_path", ",", "outfile", "=", "None", ")", ":", "\n", "\n", "    ", "video_capture", "=", "cv2", ".", "VideoCapture", "(", "file_path", ")", "\n", "w", "=", "int", "(", "video_capture", ".", "get", "(", "3", ")", ")", "\n", "h", "=", "int", "(", "video_capture", ".", "get", "(", "4", ")", ")", "\n", "fps", "=", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "video_length", "=", "int", "(", "video_capture", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n", "if", "outfile", "is", "not", "None", ":", "\n", "        ", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'XVID'", ")", "\n", "out", "=", "cv2", ".", "VideoWriter", "(", "outfile", ",", "fourcc", ",", "fps", ",", "(", "w", ",", "h", ")", ")", "\n", "\n", "", "yolo", "=", "YOLO", "(", ")", "\n", "\n", "# Definition of the parameters", "\n", "max_cosine_distance", "=", "0.3", "\n", "nn_budget", "=", "None", "\n", "nms_max_overlap", "=", "1.0", "\n", "\n", "# Deep SORT", "\n", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "\n", "model_filename", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'deep_sort_yolov4/mars-small128.pb'", ")", "\n", "encoder", "=", "gdet", ".", "create_box_encoder", "(", "model_filename", ",", "batch_size", "=", "1", ")", "\n", "\n", "metric", "=", "nn_matching", ".", "NearestNeighborDistanceMetric", "(", "\"cosine\"", ",", "max_cosine_distance", ",", "nn_budget", ")", "\n", "tracker", "=", "Tracker", "(", "metric", ")", "\n", "\n", "tracks", "=", "[", "]", "\n", "for", "frame_id", "in", "tqdm", "(", "range", "(", "video_length", ")", ")", ":", "\n", "\n", "        ", "ret", ",", "frame", "=", "video_capture", ".", "read", "(", ")", "# frame shape 640*480*3", "\n", "if", "ret", "!=", "True", "or", "frame", "is", "None", ":", "\n", "             ", "break", "\n", "\n", "", "image", "=", "Image", ".", "fromarray", "(", "frame", "[", "...", ",", ":", ":", "-", "1", "]", ")", "# bgr to rgb", "\n", "boxes", ",", "confidence", ",", "classes", "=", "yolo", ".", "detect_image", "(", "image", ")", "\n", "\n", "features", "=", "encoder", "(", "frame", ",", "boxes", ")", "\n", "\n", "detections", "=", "[", "Detection", "(", "bbox", ",", "confidence", ",", "cls", ",", "feature", ")", "for", "bbox", ",", "confidence", ",", "cls", ",", "feature", "in", "\n", "zip", "(", "boxes", ",", "confidence", ",", "classes", ",", "features", ")", "]", "\n", "\n", "# Run non-maxima suppression.", "\n", "boxes", "=", "np", ".", "array", "(", "[", "d", ".", "tlwh", "for", "d", "in", "detections", "]", ")", "\n", "scores", "=", "np", ".", "array", "(", "[", "d", ".", "confidence", "for", "d", "in", "detections", "]", ")", "\n", "indices", "=", "preprocessing", ".", "non_max_suppression", "(", "boxes", ",", "nms_max_overlap", ",", "scores", ")", "\n", "detections", "=", "[", "detections", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "\n", "# Call the tracker", "\n", "tracker", ".", "predict", "(", ")", "\n", "tracker", ".", "update", "(", "detections", ")", "\n", "\n", "tracks", ".", "append", "(", "[", "{", "'track_id'", ":", "t", ".", "track_id", ",", "'tlhw'", ":", "t", ".", "to_tlwh", "(", ")", ",", "'tlbr'", ":", "t", ".", "to_tlbr", "(", ")", ",", "\n", "'time_since_update'", ":", "t", ".", "time_since_update", "}", "\n", "for", "t", "in", "tracker", ".", "tracks", "]", ")", "\n", "\n", "if", "outfile", "is", "not", "None", ":", "\n", "\n", "            ", "for", "track", "in", "tracker", ".", "tracks", ":", "\n", "                ", "if", "not", "track", ".", "is_confirmed", "(", ")", "or", "track", ".", "time_since_update", ">", "1", ":", "\n", "                    ", "continue", "\n", "", "bbox", "=", "track", ".", "to_tlbr", "(", ")", "\n", "cv2", ".", "rectangle", "(", "frame", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "(", "255", ",", "255", ",", "255", ")", ",", "2", ")", "\n", "cv2", ".", "putText", "(", "frame", ",", "\"ID: \"", "+", "str", "(", "track", ".", "track_id", ")", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "(", "bbox", "[", "3", "]", "+", "bbox", "[", "1", "]", ")", "/", "2", ")", ")", ",", "0", ",", "\n", "1.5e-3", "*", "frame", ".", "shape", "[", "0", "]", ",", "(", "0", ",", "0", ",", "0", ")", ",", "thickness", "=", "3", ")", "\n", "cv2", ".", "putText", "(", "frame", ",", "\"ID: \"", "+", "str", "(", "track", ".", "track_id", ")", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "(", "bbox", "[", "3", "]", "+", "bbox", "[", "1", "]", ")", "/", "2", ")", ")", ",", "0", ",", "\n", "1.5e-3", "*", "frame", ".", "shape", "[", "0", "]", ",", "(", "0", ",", "255", ",", "0", ")", ",", "thickness", "=", "4", ")", "\n", "\n", "", "for", "det", "in", "detections", ":", "\n", "                ", "bbox", "=", "det", ".", "to_tlbr", "(", ")", "\n", "score", "=", "\"%.2f\"", "%", "round", "(", "det", ".", "confidence", "*", "100", ",", "2", ")", "+", "\"%\"", "\n", "cv2", ".", "rectangle", "(", "frame", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "1", "]", ")", ")", ",", "(", "int", "(", "bbox", "[", "2", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "(", "255", ",", "0", ",", "0", ")", ",", "2", ")", "\n", "if", "len", "(", "classes", ")", ">", "0", ":", "\n", "                    ", "cls", "=", "det", ".", "cls", "\n", "cv2", ".", "putText", "(", "frame", ",", "str", "(", "cls", ")", "+", "\" \"", "+", "score", ",", "(", "int", "(", "bbox", "[", "0", "]", ")", ",", "int", "(", "bbox", "[", "3", "]", ")", ")", ",", "0", ",", "\n", "1.5e-3", "*", "frame", ".", "shape", "[", "0", "]", ",", "(", "0", ",", "255", ",", "0", ")", ",", "1", ")", "\n", "\n", "", "", "out", ".", "write", "(", "frame", ")", "\n", "\n", "", "", "video_capture", ".", "release", "(", ")", "\n", "if", "outfile", "is", "not", "None", ":", "\n", "        ", "out", ".", "release", "(", ")", "\n", "\n", "\n", "", "return", "tracks", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.get_class": [[20, 26], ["os.path.expanduser", "open", "f.readlines", "c.strip"], "methods", ["None"], ["    ", "def", "get_class", "(", "self", ")", ":", "\n", "        ", "classes_path", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "classes_path", ")", "\n", "with", "open", "(", "classes_path", ")", "as", "f", ":", "\n", "            ", "class_names", "=", "f", ".", "readlines", "(", ")", "\n", "", "class_names", "=", "[", "c", ".", "strip", "(", ")", "for", "c", "in", "class_names", "]", "\n", "return", "class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.get_anchors": [[27, 33], ["os.path.expanduser", "numpy.array().reshape", "open", "f.readline", "float", "f.readline.split", "numpy.array"], "methods", ["None"], ["", "def", "get_anchors", "(", "self", ")", ":", "\n", "        ", "anchors_path", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "anchors_path", ")", "\n", "with", "open", "(", "anchors_path", ")", "as", "f", ":", "\n", "            ", "anchors", "=", "f", ".", "readline", "(", ")", "\n", "", "anchors", "=", "[", "float", "(", "x", ")", "for", "x", "in", "anchors", ".", "split", "(", "','", ")", "]", "\n", "return", "np", ".", "array", "(", "anchors", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.load_yolo": [[34, 155], ["os.path.expanduser", "os.path.expanduser.endswith", "convert.Yolo4.get_class", "convert.Yolo4.get_anchors", "len", "len", "list", "list", "tensorflow.compat.v1.Session", "yolo4.model.yolo4_body", "print", "open", "numpy.ndarray", "print", "range", "sorted", "sorted", "range", "open.close", "convert.Yolo4.yolo4_model.save", "keras.backend.placeholder", "yolo4.model.yolo_eval", "map", "map", "keras.layers.Input", "numpy.ndarray", "numpy.ndarray", "len", "layer_name.startswith", "layer_name.startswith", "len", "print", "multi_gpu_model", "len", "range", "open.read", "operator.itemgetter", "operator.itemgetter", "numpy.product", "numpy.ndarray", "numpy.ndarray", "numpy.transpose", "convert.Yolo4.yolo4_model.layers[].set_weights", "numpy.product", "numpy.ndarray", "numpy.ndarray", "convert.Yolo4.yolo4_model.layers[].set_weights", "numpy.ndarray", "numpy.transpose", "convert.Yolo4.yolo4_model.layers[].set_weights", "len", "len", "colorsys.hsv_to_rgb", "open.read", "open.read", "convs_to_load.append", "convs_to_load.append", "bns_to_load.append", "bns_to_load.append", "int", "int", "int", "convert.Yolo4.yolo4_model.layers[].get_weights", "open.read", "open.read", "convert.Yolo4.yolo4_model.layers[].get_weights", "convert.Yolo4.yolo4_model.layers[].get_weights", "open.read", "open.read", "open.read", "int", "int", "convert.Yolo4.yolo4_model.layers[].get_weights"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.get_class", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.get_anchors", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo4_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_eval"], ["", "def", "load_yolo", "(", "self", ")", ":", "\n", "        ", "model_path", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "model_path", ")", "\n", "assert", "model_path", ".", "endswith", "(", "'.h5'", ")", ",", "'Keras model or weights must be a .h5 file.'", "\n", "\n", "self", ".", "class_names", "=", "self", ".", "get_class", "(", ")", "\n", "self", ".", "anchors", "=", "self", ".", "get_anchors", "(", ")", "\n", "\n", "num_anchors", "=", "len", "(", "self", ".", "anchors", ")", "\n", "num_classes", "=", "len", "(", "self", ".", "class_names", ")", "\n", "\n", "# Generate colors for drawing bounding boxes.", "\n", "hsv_tuples", "=", "[", "(", "x", "/", "len", "(", "self", ".", "class_names", ")", ",", "1.", ",", "1.", ")", "\n", "for", "x", "in", "range", "(", "len", "(", "self", ".", "class_names", ")", ")", "]", "\n", "self", ".", "colors", "=", "list", "(", "map", "(", "lambda", "x", ":", "colorsys", ".", "hsv_to_rgb", "(", "*", "x", ")", ",", "hsv_tuples", ")", ")", "\n", "self", ".", "colors", "=", "list", "(", "\n", "map", "(", "lambda", "x", ":", "(", "int", "(", "x", "[", "0", "]", "*", "255", ")", ",", "int", "(", "x", "[", "1", "]", "*", "255", ")", ",", "int", "(", "x", "[", "2", "]", "*", "255", ")", ")", ",", "\n", "self", ".", "colors", ")", ")", "\n", "\n", "self", ".", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "\n", "\n", "# Load model, or construct model and load weights.", "\n", "self", ".", "yolo4_model", "=", "yolo4_body", "(", "Input", "(", "shape", "=", "(", "416", ",", "416", ",", "3", ")", ")", ",", "num_anchors", "//", "3", ",", "num_classes", ")", "\n", "\n", "# Read and convert darknet weight", "\n", "print", "(", "'Loading weights.'", ")", "\n", "weights_file", "=", "open", "(", "self", ".", "weights_path", ",", "'rb'", ")", "\n", "major", ",", "minor", ",", "revision", "=", "np", ".", "ndarray", "(", "\n", "shape", "=", "(", "3", ",", ")", ",", "dtype", "=", "'int32'", ",", "buffer", "=", "weights_file", ".", "read", "(", "12", ")", ")", "\n", "if", "(", "major", "*", "10", "+", "minor", ")", ">=", "2", "and", "major", "<", "1000", "and", "minor", "<", "1000", ":", "\n", "            ", "seen", "=", "np", ".", "ndarray", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "'int64'", ",", "buffer", "=", "weights_file", ".", "read", "(", "8", ")", ")", "\n", "", "else", ":", "\n", "            ", "seen", "=", "np", ".", "ndarray", "(", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "'int32'", ",", "buffer", "=", "weights_file", ".", "read", "(", "4", ")", ")", "\n", "", "print", "(", "'Weights Header: '", ",", "major", ",", "minor", ",", "revision", ",", "seen", ")", "\n", "\n", "convs_to_load", "=", "[", "]", "\n", "bns_to_load", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "yolo4_model", ".", "layers", ")", ")", ":", "\n", "            ", "layer_name", "=", "self", ".", "yolo4_model", ".", "layers", "[", "i", "]", ".", "name", "\n", "if", "layer_name", ".", "startswith", "(", "'conv2d'", ")", ":", "\n", "                ", "if", "layer_name", "==", "'conv2d'", ":", "\n", "                    ", "convs_to_load", ".", "append", "(", "(", "0", ",", "i", ")", ")", "\n", "", "else", ":", "\n", "                    ", "convs_to_load", ".", "append", "(", "(", "int", "(", "layer_name", "[", "7", ":", "]", ")", ",", "i", ")", ")", "\n", "", "", "if", "layer_name", ".", "startswith", "(", "'batch_normalization'", ")", ":", "\n", "                ", "if", "layer_name", "==", "'batch_normalization'", ":", "\n", "                    ", "bns_to_load", ".", "append", "(", "(", "0", ",", "i", ")", ")", "\n", "", "else", ":", "\n", "                    ", "bns_to_load", ".", "append", "(", "(", "int", "(", "layer_name", "[", "20", ":", "]", ")", ",", "i", ")", ")", "\n", "\n", "", "", "", "convs_sorted", "=", "sorted", "(", "convs_to_load", ",", "key", "=", "itemgetter", "(", "0", ")", ")", "\n", "bns_sorted", "=", "sorted", "(", "bns_to_load", ",", "key", "=", "itemgetter", "(", "0", ")", ")", "\n", "\n", "bn_index", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "convs_sorted", ")", ")", ":", "\n", "            ", "print", "(", "'Converting '", ",", "i", ")", "\n", "if", "i", "==", "93", "or", "i", "==", "101", "or", "i", "==", "109", ":", "\n", "#no bn, with bias", "\n", "                ", "weights_shape", "=", "self", ".", "yolo4_model", ".", "layers", "[", "convs_sorted", "[", "i", "]", "[", "1", "]", "]", ".", "get_weights", "(", ")", "[", "0", "]", ".", "shape", "\n", "bias_shape", "=", "self", ".", "yolo4_model", ".", "layers", "[", "convs_sorted", "[", "i", "]", "[", "1", "]", "]", ".", "get_weights", "(", ")", "[", "0", "]", ".", "shape", "[", "3", "]", "\n", "filters", "=", "bias_shape", "\n", "size", "=", "weights_shape", "[", "0", "]", "\n", "darknet_w_shape", "=", "(", "filters", ",", "weights_shape", "[", "2", "]", ",", "size", ",", "size", ")", "\n", "weights_size", "=", "np", ".", "product", "(", "weights_shape", ")", "\n", "\n", "conv_bias", "=", "np", ".", "ndarray", "(", "\n", "shape", "=", "(", "filters", ",", ")", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "buffer", "=", "weights_file", ".", "read", "(", "filters", "*", "4", ")", ")", "\n", "conv_weights", "=", "np", ".", "ndarray", "(", "\n", "shape", "=", "darknet_w_shape", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "buffer", "=", "weights_file", ".", "read", "(", "weights_size", "*", "4", ")", ")", "\n", "conv_weights", "=", "np", ".", "transpose", "(", "conv_weights", ",", "[", "2", ",", "3", ",", "1", ",", "0", "]", ")", "\n", "self", ".", "yolo4_model", ".", "layers", "[", "convs_sorted", "[", "i", "]", "[", "1", "]", "]", ".", "set_weights", "(", "[", "conv_weights", ",", "conv_bias", "]", ")", "\n", "", "else", ":", "\n", "#with bn, no bias", "\n", "                ", "weights_shape", "=", "self", ".", "yolo4_model", ".", "layers", "[", "convs_sorted", "[", "i", "]", "[", "1", "]", "]", ".", "get_weights", "(", ")", "[", "0", "]", ".", "shape", "\n", "size", "=", "weights_shape", "[", "0", "]", "\n", "bn_shape", "=", "self", ".", "yolo4_model", ".", "layers", "[", "bns_sorted", "[", "bn_index", "]", "[", "1", "]", "]", ".", "get_weights", "(", ")", "[", "0", "]", ".", "shape", "\n", "filters", "=", "bn_shape", "[", "0", "]", "\n", "darknet_w_shape", "=", "(", "filters", ",", "weights_shape", "[", "2", "]", ",", "size", ",", "size", ")", "\n", "weights_size", "=", "np", ".", "product", "(", "weights_shape", ")", "\n", "\n", "conv_bias", "=", "np", ".", "ndarray", "(", "\n", "shape", "=", "(", "filters", ",", ")", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "buffer", "=", "weights_file", ".", "read", "(", "filters", "*", "4", ")", ")", "\n", "bn_weights", "=", "np", ".", "ndarray", "(", "\n", "shape", "=", "(", "3", ",", "filters", ")", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "buffer", "=", "weights_file", ".", "read", "(", "filters", "*", "12", ")", ")", "\n", "\n", "bn_weight_list", "=", "[", "\n", "bn_weights", "[", "0", "]", ",", "# scale gamma", "\n", "conv_bias", ",", "# shift beta", "\n", "bn_weights", "[", "1", "]", ",", "# running mean", "\n", "bn_weights", "[", "2", "]", "# running var", "\n", "]", "\n", "self", ".", "yolo4_model", ".", "layers", "[", "bns_sorted", "[", "bn_index", "]", "[", "1", "]", "]", ".", "set_weights", "(", "bn_weight_list", ")", "\n", "\n", "conv_weights", "=", "np", ".", "ndarray", "(", "\n", "shape", "=", "darknet_w_shape", ",", "\n", "dtype", "=", "'float32'", ",", "\n", "buffer", "=", "weights_file", ".", "read", "(", "weights_size", "*", "4", ")", ")", "\n", "conv_weights", "=", "np", ".", "transpose", "(", "conv_weights", ",", "[", "2", ",", "3", ",", "1", ",", "0", "]", ")", "\n", "self", ".", "yolo4_model", ".", "layers", "[", "convs_sorted", "[", "i", "]", "[", "1", "]", "]", ".", "set_weights", "(", "[", "conv_weights", "]", ")", "\n", "\n", "bn_index", "+=", "1", "\n", "\n", "", "", "weights_file", ".", "close", "(", ")", "\n", "\n", "self", ".", "yolo4_model", ".", "save", "(", "self", ".", "model_path", ")", "\n", "\n", "\n", "if", "self", ".", "gpu_num", ">=", "2", ":", "\n", "            ", "self", ".", "yolo4_model", "=", "multi_gpu_model", "(", "self", ".", "yolo4_model", ",", "gpus", "=", "self", ".", "gpu_num", ")", "\n", "\n", "", "self", ".", "input_image_shape", "=", "K", ".", "placeholder", "(", "shape", "=", "(", "2", ",", ")", ")", "\n", "self", ".", "boxes", ",", "self", ".", "scores", ",", "self", ".", "classes", "=", "yolo_eval", "(", "self", ".", "yolo4_model", ".", "output", ",", "self", ".", "anchors", ",", "\n", "len", "(", "self", ".", "class_names", ")", ",", "self", ".", "input_image_shape", ",", "\n", "score_threshold", "=", "self", ".", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.__init__": [[156, 165], ["convert.Yolo4.load_yolo"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.load_yolo"], ["", "def", "__init__", "(", "self", ",", "score", ",", "iou", ",", "anchors_path", ",", "classes_path", ",", "model_path", ",", "weights_path", ",", "gpu_num", "=", "1", ")", ":", "\n", "        ", "self", ".", "score", "=", "score", "\n", "self", ".", "iou", "=", "iou", "\n", "self", ".", "anchors_path", "=", "anchors_path", "\n", "self", ".", "classes_path", "=", "classes_path", "\n", "self", ".", "weights_path", "=", "weights_path", "\n", "self", ".", "model_path", "=", "model_path", "\n", "self", ".", "gpu_num", "=", "gpu_num", "\n", "self", ".", "load_yolo", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.convert.Yolo4.close_session": [[166, 168], ["convert.Yolo4.sess.close"], "methods", ["None"], ["", "def", "close_session", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO.__init__": [[18, 35], ["os.path.join", "os.path.join", "os.path.join", "yolo.YOLO._get_class", "yolo.YOLO._get_anchors", "tensorflow.compat.v1.keras.backend.get_session", "yolo.YOLO.generate"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO._get_class", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO._get_anchors", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO.generate"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "from", "pose_pipeline", "import", "MODEL_DATA_DIR", "\n", "\n", "self", ".", "model_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'deep_sort_yolov4/yolo4.h5'", ")", "\n", "self", ".", "anchors_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'deep_sort_yolov4/yolo_anchors.txt'", ")", "\n", "self", ".", "classes_path", "=", "os", ".", "path", ".", "join", "(", "MODEL_DATA_DIR", ",", "'deep_sort_yolov4/coco_classes.txt'", ")", "\n", "\n", "self", ".", "gpu_num", "=", "1", "\n", "self", ".", "score", "=", "0.5", "\n", "self", ".", "iou", "=", "0.5", "\n", "self", ".", "class_names", "=", "self", ".", "_get_class", "(", ")", "\n", "self", ".", "anchors", "=", "self", ".", "_get_anchors", "(", ")", "\n", "self", ".", "sess", "=", "tf", ".", "compat", ".", "v1", ".", "keras", ".", "backend", ".", "get_session", "(", ")", "\n", "self", ".", "model_image_size", "=", "(", "416", ",", "416", ")", "# fixed size or (None, None)", "\n", "self", ".", "is_fixed_size", "=", "self", ".", "model_image_size", "!=", "(", "None", ",", "None", ")", "\n", "self", ".", "boxes", ",", "self", ".", "scores", ",", "self", ".", "classes", "=", "self", ".", "generate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO._get_class": [[36, 42], ["os.path.expanduser", "open", "f.readlines", "c.strip"], "methods", ["None"], ["", "def", "_get_class", "(", "self", ")", ":", "\n", "        ", "classes_path", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "classes_path", ")", "\n", "with", "open", "(", "classes_path", ")", "as", "f", ":", "\n", "            ", "class_names", "=", "f", ".", "readlines", "(", ")", "\n", "", "class_names", "=", "[", "c", ".", "strip", "(", ")", "for", "c", "in", "class_names", "]", "\n", "return", "class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO._get_anchors": [[43, 50], ["os.path.expanduser", "open", "f.readline", "numpy.array().reshape", "float", "numpy.array().reshape.split", "numpy.array"], "methods", ["None"], ["", "def", "_get_anchors", "(", "self", ")", ":", "\n", "        ", "anchors_path", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "anchors_path", ")", "\n", "with", "open", "(", "anchors_path", ")", "as", "f", ":", "\n", "            ", "anchors", "=", "f", ".", "readline", "(", ")", "\n", "anchors", "=", "[", "float", "(", "x", ")", "for", "x", "in", "anchors", ".", "split", "(", "','", ")", "]", "\n", "anchors", "=", "np", ".", "array", "(", "anchors", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "", "return", "anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO.generate": [[51, 76], ["os.path.expanduser", "os.path.expanduser.endswith", "tensorflow.keras.models.load_model", "list", "list", "numpy.random.seed", "numpy.random.shuffle", "numpy.random.seed", "tensorflow.compat.v1.keras.backend.placeholder", "yolo4.model.yolo_eval", "map", "map", "len", "range", "len", "len", "colorsys.hsv_to_rgb", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_eval"], ["", "def", "generate", "(", "self", ")", ":", "\n", "        ", "model_path", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "model_path", ")", "\n", "assert", "model_path", ".", "endswith", "(", "'.h5'", ")", ",", "'Keras model or weights must be a .h5 file.'", "\n", "\n", "self", ".", "yolo_model", "=", "load_model", "(", "model_path", ",", "custom_objects", "=", "{", "'Mish'", ":", "Mish", "}", ",", "compile", "=", "False", ")", "\n", "\n", "# print('{} model, anchors, and classes loaded.'.format(model_path))", "\n", "\n", "# Generate colors for drawing bounding boxes.", "\n", "hsv_tuples", "=", "[", "(", "x", "/", "len", "(", "self", ".", "class_names", ")", ",", "1.", ",", "1.", ")", "\n", "for", "x", "in", "range", "(", "len", "(", "self", ".", "class_names", ")", ")", "]", "\n", "self", ".", "colors", "=", "list", "(", "map", "(", "lambda", "x", ":", "colorsys", ".", "hsv_to_rgb", "(", "*", "x", ")", ",", "hsv_tuples", ")", ")", "\n", "self", ".", "colors", "=", "list", "(", "\n", "map", "(", "lambda", "x", ":", "(", "int", "(", "x", "[", "0", "]", "*", "255", ")", ",", "int", "(", "x", "[", "1", "]", "*", "255", ")", ",", "int", "(", "x", "[", "2", "]", "*", "255", ")", ")", ",", "\n", "self", ".", "colors", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "10101", ")", "# Fixed seed for consistent colors across runs.", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "colors", ")", "# Shuffle colors to decorrelate adjacent classes.", "\n", "np", ".", "random", ".", "seed", "(", "None", ")", "# Reset seed to default.", "\n", "\n", "# Generate output tensor targets for filtered bounding boxes.", "\n", "self", ".", "input_image_shape", "=", "K", ".", "placeholder", "(", "shape", "=", "(", "2", ",", ")", ")", "\n", "boxes", ",", "scores", ",", "classes", "=", "yolo_eval", "(", "self", ".", "yolo_model", ".", "output", ",", "self", ".", "anchors", ",", "\n", "len", "(", "self", ".", "class_names", ")", ",", "self", ".", "input_image_shape", ",", "\n", "score_threshold", "=", "self", ".", "score", ",", "iou_threshold", "=", "self", ".", "iou", ")", "\n", "return", "boxes", ",", "scores", ",", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO.detect_image": [[77, 124], ["numpy.array", "numpy.expand_dims", "yolo.YOLO.sess.run", "reversed", "yolo4.utils.letterbox_image", "yolo4.utils.letterbox_image", "list", "int", "int", "int", "int", "return_boxes.append", "return_scores.append", "return_class_names.append", "tuple", "enumerate", "reversed", "tensorflow.compat.v1.keras.backend.learning_phase"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.letterbox_image", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.letterbox_image"], ["", "def", "detect_image", "(", "self", ",", "image", ")", ":", "\n", "\n", "        ", "if", "self", ".", "is_fixed_size", ":", "\n", "            ", "assert", "self", ".", "model_image_size", "[", "0", "]", "%", "32", "==", "0", ",", "'Multiples of 32 required'", "\n", "assert", "self", ".", "model_image_size", "[", "1", "]", "%", "32", "==", "0", ",", "'Multiples of 32 required'", "\n", "boxed_image", "=", "letterbox_image", "(", "image", ",", "tuple", "(", "reversed", "(", "self", ".", "model_image_size", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "new_image_size", "=", "(", "image", ".", "width", "-", "(", "image", ".", "width", "%", "32", ")", ",", "\n", "image", ".", "height", "-", "(", "image", ".", "height", "%", "32", ")", ")", "\n", "boxed_image", "=", "letterbox_image", "(", "image", ",", "new_image_size", ")", "\n", "", "image_data", "=", "np", ".", "array", "(", "boxed_image", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "# print(image_data.shape)", "\n", "image_data", "/=", "255.", "\n", "image_data", "=", "np", ".", "expand_dims", "(", "image_data", ",", "0", ")", "# Add batch dimension.", "\n", "\n", "out_boxes", ",", "out_scores", ",", "out_classes", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "boxes", ",", "self", ".", "scores", ",", "self", ".", "classes", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "yolo_model", ".", "input", ":", "image_data", ",", "\n", "self", ".", "input_image_shape", ":", "[", "image", ".", "size", "[", "1", "]", ",", "image", ".", "size", "[", "0", "]", "]", ",", "\n", "K", ".", "learning_phase", "(", ")", ":", "0", "\n", "}", ")", "\n", "return_boxes", "=", "[", "]", "\n", "return_scores", "=", "[", "]", "\n", "return_class_names", "=", "[", "]", "\n", "for", "i", ",", "c", "in", "reversed", "(", "list", "(", "enumerate", "(", "out_classes", ")", ")", ")", ":", "\n", "            ", "predicted_class", "=", "self", ".", "class_names", "[", "c", "]", "\n", "if", "predicted_class", "!=", "'person'", ":", "# Modify to detect other classes.", "\n", "                ", "continue", "\n", "", "box", "=", "out_boxes", "[", "i", "]", "\n", "score", "=", "out_scores", "[", "i", "]", "\n", "x", "=", "int", "(", "box", "[", "1", "]", ")", "\n", "y", "=", "int", "(", "box", "[", "0", "]", ")", "\n", "w", "=", "int", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "\n", "h", "=", "int", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "\n", "if", "x", "<", "0", ":", "\n", "                ", "w", "=", "w", "+", "x", "\n", "x", "=", "0", "\n", "", "if", "y", "<", "0", ":", "\n", "                ", "h", "=", "h", "+", "y", "\n", "y", "=", "0", "\n", "", "return_boxes", ".", "append", "(", "[", "x", ",", "y", ",", "w", ",", "h", "]", ")", "\n", "return_scores", ".", "append", "(", "score", ")", "\n", "return_class_names", ".", "append", "(", "predicted_class", ")", "\n", "\n", "", "return", "return_boxes", ",", "return_scores", ",", "return_class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort_yolov4.yolo.YOLO.close_session": [[125, 127], ["yolo.YOLO.sess.close"], "methods", ["None"], ["", "def", "close_session", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.Mish.__init__": [[29, 32], ["tensorflow.keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Mish", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "supports_masking", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.Mish.call": [[33, 35], ["tensorflow.keras.backend.tanh", "tensorflow.keras.backend.softplus"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "inputs", "*", "K", ".", "tanh", "(", "K", ".", "softplus", "(", "inputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.Mish.get_config": [[36, 39], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.Mish.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "Mish", ",", "self", ")", ".", "get_config", "(", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.Mish.compute_output_shape": [[40, 42], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D": [[44, 51], ["functools.wraps", "darknet_conv_kwargs.update", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.regularizers.l2", "kwargs.get"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update"], ["", "", "@", "wraps", "(", "Conv2D", ")", "\n", "def", "DarknetConv2D", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"", "\n", "darknet_conv_kwargs", "=", "{", "'kernel_regularizer'", ":", "l2", "(", "5e-4", ")", "}", "\n", "darknet_conv_kwargs", "[", "'padding'", "]", "=", "'valid'", "if", "kwargs", ".", "get", "(", "'strides'", ")", "==", "(", "2", ",", "2", ")", "else", "'same'", "\n", "darknet_conv_kwargs", ".", "update", "(", "kwargs", ")", "\n", "return", "Conv2D", "(", "*", "args", ",", "**", "darknet_conv_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky": [[52, 60], ["no_bias_kwargs.update", "utils.compose", "model.DarknetConv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.LeakyReLU"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D"], ["", "def", "DarknetConv2D_BN_Leaky", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"", "\n", "no_bias_kwargs", "=", "{", "'use_bias'", ":", "False", "}", "\n", "no_bias_kwargs", ".", "update", "(", "kwargs", ")", "\n", "return", "compose", "(", "\n", "DarknetConv2D", "(", "*", "args", ",", "**", "no_bias_kwargs", ")", ",", "\n", "BatchNormalization", "(", ")", ",", "\n", "LeakyReLU", "(", "alpha", "=", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish": [[61, 69], ["no_bias_kwargs.update", "utils.compose", "model.DarknetConv2D", "tensorflow.keras.layers.BatchNormalization", "model.Mish"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D"], ["", "def", "DarknetConv2D_BN_Mish", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"", "\n", "no_bias_kwargs", "=", "{", "'use_bias'", ":", "False", "}", "\n", "no_bias_kwargs", ".", "update", "(", "kwargs", ")", "\n", "return", "compose", "(", "\n", "DarknetConv2D", "(", "*", "args", ",", "**", "no_bias_kwargs", ")", ",", "\n", "BatchNormalization", "(", ")", ",", "\n", "Mish", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.resblock_body": [[70, 85], ["range", "tensorflow.keras.layers.ZeroPadding2D", "model.DarknetConv2D_BN_Mish", "model.DarknetConv2D_BN_Mish", "model.DarknetConv2D_BN_Mish", "model.DarknetConv2D_BN_Mish", "tensorflow.keras.layers.Concatenate", "model.DarknetConv2D_BN_Mish", "utils.compose", "tensorflow.keras.layers.Add", "model.DarknetConv2D_BN_Mish", "model.DarknetConv2D_BN_Mish"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish"], ["", "def", "resblock_body", "(", "x", ",", "num_filters", ",", "num_blocks", ",", "all_narrow", "=", "True", ")", ":", "\n", "    ", "'''A series of resblocks starting with a downsampling Convolution2D'''", "\n", "# Darknet uses left and top padding instead of 'same' mode", "\n", "preconv1", "=", "ZeroPadding2D", "(", "(", "(", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ")", ")", "(", "x", ")", "\n", "preconv1", "=", "DarknetConv2D_BN_Mish", "(", "num_filters", ",", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "(", "preconv1", ")", "\n", "shortconv", "=", "DarknetConv2D_BN_Mish", "(", "num_filters", "//", "2", "if", "all_narrow", "else", "num_filters", ",", "(", "1", ",", "1", ")", ")", "(", "preconv1", ")", "\n", "mainconv", "=", "DarknetConv2D_BN_Mish", "(", "num_filters", "//", "2", "if", "all_narrow", "else", "num_filters", ",", "(", "1", ",", "1", ")", ")", "(", "preconv1", ")", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "        ", "y", "=", "compose", "(", "\n", "DarknetConv2D_BN_Mish", "(", "num_filters", "//", "2", ",", "(", "1", ",", "1", ")", ")", ",", "\n", "DarknetConv2D_BN_Mish", "(", "num_filters", "//", "2", "if", "all_narrow", "else", "num_filters", ",", "(", "3", ",", "3", ")", ")", ")", "(", "mainconv", ")", "\n", "mainconv", "=", "Add", "(", ")", "(", "[", "mainconv", ",", "y", "]", ")", "\n", "", "postconv", "=", "DarknetConv2D_BN_Mish", "(", "num_filters", "//", "2", "if", "all_narrow", "else", "num_filters", ",", "(", "1", ",", "1", ")", ")", "(", "mainconv", ")", "\n", "route", "=", "Concatenate", "(", ")", "(", "[", "postconv", ",", "shortconv", "]", ")", "\n", "return", "DarknetConv2D_BN_Mish", "(", "num_filters", ",", "(", "1", ",", "1", ")", ")", "(", "route", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.darknet_body": [[86, 95], ["model.resblock_body", "model.resblock_body", "model.resblock_body", "model.resblock_body", "model.resblock_body", "model.DarknetConv2D_BN_Mish"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.resblock_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.resblock_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.resblock_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.resblock_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.resblock_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Mish"], ["", "def", "darknet_body", "(", "x", ")", ":", "\n", "    ", "'''Darknent body having 52 Convolution2D layers'''", "\n", "x", "=", "DarknetConv2D_BN_Mish", "(", "32", ",", "(", "3", ",", "3", ")", ")", "(", "x", ")", "\n", "x", "=", "resblock_body", "(", "x", ",", "64", ",", "1", ",", "False", ")", "\n", "x", "=", "resblock_body", "(", "x", ",", "128", ",", "2", ")", "\n", "x", "=", "resblock_body", "(", "x", ",", "256", ",", "8", ")", "\n", "x", "=", "resblock_body", "(", "x", ",", "512", ",", "8", ")", "\n", "x", "=", "resblock_body", "(", "x", ",", "1024", ",", "4", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.make_last_layers": [[96, 108], ["utils.compose", "utils.compose", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D"], ["", "def", "make_last_layers", "(", "x", ",", "num_filters", ",", "out_filters", ")", ":", "\n", "    ", "'''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''", "\n", "x", "=", "compose", "(", "\n", "DarknetConv2D_BN_Leaky", "(", "num_filters", ",", "(", "1", ",", "1", ")", ")", ",", "\n", "DarknetConv2D_BN_Leaky", "(", "num_filters", "*", "2", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "DarknetConv2D_BN_Leaky", "(", "num_filters", ",", "(", "1", ",", "1", ")", ")", ",", "\n", "DarknetConv2D_BN_Leaky", "(", "num_filters", "*", "2", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "DarknetConv2D_BN_Leaky", "(", "num_filters", ",", "(", "1", ",", "1", ")", ")", ")", "(", "x", ")", "\n", "y", "=", "compose", "(", "\n", "DarknetConv2D_BN_Leaky", "(", "num_filters", "*", "2", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "DarknetConv2D", "(", "out_filters", ",", "(", "1", ",", "1", ")", ")", ")", "(", "x", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo4_body": [[110, 181], ["tensorflow.keras.models.Model", "tensorflow.keras.models.Model", "model.darknet_body", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.MaxPooling2D", "tensorflow.keras.layers.Concatenate", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "utils.compose", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.Concatenate", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "utils.compose", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.Concatenate", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D", "tensorflow.keras.layers.ZeroPadding2D", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.Concatenate", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D", "tensorflow.keras.layers.ZeroPadding2D", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.Concatenate", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D_BN_Leaky", "model.DarknetConv2D", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.UpSampling2D", "model.DarknetConv2D_BN_Leaky", "tensorflow.keras.layers.UpSampling2D"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.darknet_body", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.DarknetConv2D_BN_Leaky"], ["", "def", "yolo4_body", "(", "inputs", ",", "num_anchors", ",", "num_classes", ")", ":", "\n", "    ", "\"\"\"Create YOLO_V4 model CNN body in Keras.\"\"\"", "\n", "darknet", "=", "Model", "(", "inputs", ",", "darknet_body", "(", "inputs", ")", ")", "\n", "\n", "#19x19 head", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "darknet", ".", "output", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "1024", ",", "(", "3", ",", "3", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "y19", ")", "\n", "maxpool1", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "13", ",", "13", ")", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ")", "(", "y19", ")", "\n", "maxpool2", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "9", ",", "9", ")", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ")", "(", "y19", ")", "\n", "maxpool3", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "5", ",", "5", ")", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ")", "(", "y19", ")", "\n", "y19", "=", "Concatenate", "(", ")", "(", "[", "maxpool1", ",", "maxpool2", ",", "maxpool3", ",", "y19", "]", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "1024", ",", "(", "3", ",", "3", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "y19", ")", "\n", "\n", "y19_upsample", "=", "compose", "(", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", ",", "UpSampling2D", "(", "2", ")", ")", "(", "y19", ")", "\n", "\n", "#38x38 head", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "darknet", ".", "layers", "[", "204", "]", ".", "output", ")", "\n", "y38", "=", "Concatenate", "(", ")", "(", "[", "y38", ",", "y19_upsample", "]", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "3", ",", "3", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "3", ",", "3", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "y38", ")", "\n", "\n", "y38_upsample", "=", "compose", "(", "DarknetConv2D_BN_Leaky", "(", "128", ",", "(", "1", ",", "1", ")", ")", ",", "UpSampling2D", "(", "2", ")", ")", "(", "y38", ")", "\n", "\n", "#76x76 head", "\n", "y76", "=", "DarknetConv2D_BN_Leaky", "(", "128", ",", "(", "1", ",", "1", ")", ")", "(", "darknet", ".", "layers", "[", "131", "]", ".", "output", ")", "\n", "y76", "=", "Concatenate", "(", ")", "(", "[", "y76", ",", "y38_upsample", "]", ")", "\n", "y76", "=", "DarknetConv2D_BN_Leaky", "(", "128", ",", "(", "1", ",", "1", ")", ")", "(", "y76", ")", "\n", "y76", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "3", ",", "3", ")", ")", "(", "y76", ")", "\n", "y76", "=", "DarknetConv2D_BN_Leaky", "(", "128", ",", "(", "1", ",", "1", ")", ")", "(", "y76", ")", "\n", "y76", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "3", ",", "3", ")", ")", "(", "y76", ")", "\n", "y76", "=", "DarknetConv2D_BN_Leaky", "(", "128", ",", "(", "1", ",", "1", ")", ")", "(", "y76", ")", "\n", "\n", "#76x76 output", "\n", "y76_output", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "3", ",", "3", ")", ")", "(", "y76", ")", "\n", "y76_output", "=", "DarknetConv2D", "(", "num_anchors", "*", "(", "num_classes", "+", "5", ")", ",", "(", "1", ",", "1", ")", ")", "(", "y76_output", ")", "\n", "\n", "#38x38 output", "\n", "y76_downsample", "=", "ZeroPadding2D", "(", "(", "(", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ")", ")", "(", "y76", ")", "\n", "y76_downsample", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "(", "y76_downsample", ")", "\n", "y38", "=", "Concatenate", "(", ")", "(", "[", "y76_downsample", ",", "y38", "]", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "3", ",", "3", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "3", ",", "3", ")", ")", "(", "y38", ")", "\n", "y38", "=", "DarknetConv2D_BN_Leaky", "(", "256", ",", "(", "1", ",", "1", ")", ")", "(", "y38", ")", "\n", "\n", "y38_output", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "3", ",", "3", ")", ")", "(", "y38", ")", "\n", "y38_output", "=", "DarknetConv2D", "(", "num_anchors", "*", "(", "num_classes", "+", "5", ")", ",", "(", "1", ",", "1", ")", ")", "(", "y38_output", ")", "\n", "\n", "#19x19 output", "\n", "y38_downsample", "=", "ZeroPadding2D", "(", "(", "(", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", ")", ")", "(", "y38", ")", "\n", "y38_downsample", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "(", "y38_downsample", ")", "\n", "y19", "=", "Concatenate", "(", ")", "(", "[", "y38_downsample", ",", "y19", "]", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "1024", ",", "(", "3", ",", "3", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "1024", ",", "(", "3", ",", "3", ")", ")", "(", "y19", ")", "\n", "y19", "=", "DarknetConv2D_BN_Leaky", "(", "512", ",", "(", "1", ",", "1", ")", ")", "(", "y19", ")", "\n", "\n", "y19_output", "=", "DarknetConv2D_BN_Leaky", "(", "1024", ",", "(", "3", ",", "3", ")", ")", "(", "y19", ")", "\n", "y19_output", "=", "DarknetConv2D", "(", "num_anchors", "*", "(", "num_classes", "+", "5", ")", ",", "(", "1", ",", "1", ")", ")", "(", "y19_output", ")", "\n", "\n", "yolo4_model", "=", "Model", "(", "inputs", ",", "[", "y19_output", ",", "y38_output", ",", "y76_output", "]", ")", "\n", "\n", "return", "yolo4_model", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_head": [[183, 209], ["len", "tensorflow.keras.backend.reshape", "tensorflow.keras.backend.tile", "tensorflow.keras.backend.tile", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.reshape", "tensorflow.keras.backend.sigmoid", "tensorflow.keras.backend.sigmoid", "tensorflow.keras.backend.constant", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.reshape", "tensorflow.keras.backend.reshape", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.arange", "tensorflow.keras.backend.arange", "tensorflow.keras.backend.sigmoid", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.exp", "tensorflow.keras.backend.dtype"], "function", ["None"], ["", "def", "yolo_head", "(", "feats", ",", "anchors", ",", "num_classes", ",", "input_shape", ",", "calc_loss", "=", "False", ")", ":", "\n", "    ", "\"\"\"Convert final layer features to bounding box parameters.\"\"\"", "\n", "num_anchors", "=", "len", "(", "anchors", ")", "\n", "# Reshape to batch, height, width, num_anchors, box_params.", "\n", "anchors_tensor", "=", "K", ".", "reshape", "(", "K", ".", "constant", "(", "anchors", ")", ",", "[", "1", ",", "1", ",", "1", ",", "num_anchors", ",", "2", "]", ")", "\n", "\n", "grid_shape", "=", "K", ".", "shape", "(", "feats", ")", "[", "1", ":", "3", "]", "# height, width", "\n", "grid_y", "=", "K", ".", "tile", "(", "K", ".", "reshape", "(", "K", ".", "arange", "(", "0", ",", "stop", "=", "grid_shape", "[", "0", "]", ")", ",", "[", "-", "1", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "[", "1", ",", "grid_shape", "[", "1", "]", ",", "1", ",", "1", "]", ")", "\n", "grid_x", "=", "K", ".", "tile", "(", "K", ".", "reshape", "(", "K", ".", "arange", "(", "0", ",", "stop", "=", "grid_shape", "[", "1", "]", ")", ",", "[", "1", ",", "-", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "[", "grid_shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "grid", "=", "K", ".", "concatenate", "(", "[", "grid_x", ",", "grid_y", "]", ")", "\n", "grid", "=", "K", ".", "cast", "(", "grid", ",", "K", ".", "dtype", "(", "feats", ")", ")", "\n", "\n", "feats", "=", "K", ".", "reshape", "(", "\n", "feats", ",", "[", "-", "1", ",", "grid_shape", "[", "0", "]", ",", "grid_shape", "[", "1", "]", ",", "num_anchors", ",", "num_classes", "+", "5", "]", ")", "\n", "\n", "# Adjust preditions to each spatial grid point and anchor size.", "\n", "box_xy", "=", "(", "K", ".", "sigmoid", "(", "feats", "[", "...", ",", ":", "2", "]", ")", "+", "grid", ")", "/", "K", ".", "cast", "(", "grid_shape", "[", "...", ",", ":", ":", "-", "1", "]", ",", "K", ".", "dtype", "(", "feats", ")", ")", "\n", "box_wh", "=", "K", ".", "exp", "(", "feats", "[", "...", ",", "2", ":", "4", "]", ")", "*", "anchors_tensor", "/", "K", ".", "cast", "(", "input_shape", "[", "...", ",", ":", ":", "-", "1", "]", ",", "K", ".", "dtype", "(", "feats", ")", ")", "\n", "box_confidence", "=", "K", ".", "sigmoid", "(", "feats", "[", "...", ",", "4", ":", "5", "]", ")", "\n", "box_class_probs", "=", "K", ".", "sigmoid", "(", "feats", "[", "...", ",", "5", ":", "]", ")", "\n", "\n", "if", "calc_loss", "==", "True", ":", "\n", "        ", "return", "grid", ",", "feats", ",", "box_xy", ",", "box_wh", "\n", "", "return", "box_xy", ",", "box_wh", ",", "box_confidence", ",", "box_class_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_correct_boxes": [[211, 235], ["tensorflow.keras.backend.cast", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.round", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.min"], "function", ["None"], ["", "def", "yolo_correct_boxes", "(", "box_xy", ",", "box_wh", ",", "input_shape", ",", "image_shape", ")", ":", "\n", "    ", "'''Get corrected boxes'''", "\n", "box_yx", "=", "box_xy", "[", "...", ",", ":", ":", "-", "1", "]", "\n", "box_hw", "=", "box_wh", "[", "...", ",", ":", ":", "-", "1", "]", "\n", "input_shape", "=", "K", ".", "cast", "(", "input_shape", ",", "K", ".", "dtype", "(", "box_yx", ")", ")", "\n", "image_shape", "=", "K", ".", "cast", "(", "image_shape", ",", "K", ".", "dtype", "(", "box_yx", ")", ")", "\n", "new_shape", "=", "K", ".", "round", "(", "image_shape", "*", "K", ".", "min", "(", "input_shape", "/", "image_shape", ")", ")", "\n", "offset", "=", "(", "input_shape", "-", "new_shape", ")", "/", "2.", "/", "input_shape", "\n", "scale", "=", "input_shape", "/", "new_shape", "\n", "box_yx", "=", "(", "box_yx", "-", "offset", ")", "*", "scale", "\n", "box_hw", "*=", "scale", "\n", "\n", "box_mins", "=", "box_yx", "-", "(", "box_hw", "/", "2.", ")", "\n", "box_maxes", "=", "box_yx", "+", "(", "box_hw", "/", "2.", ")", "\n", "boxes", "=", "K", ".", "concatenate", "(", "[", "\n", "box_mins", "[", "...", ",", "0", ":", "1", "]", ",", "# y_min", "\n", "box_mins", "[", "...", ",", "1", ":", "2", "]", ",", "# x_min", "\n", "box_maxes", "[", "...", ",", "0", ":", "1", "]", ",", "# y_max", "\n", "box_maxes", "[", "...", ",", "1", ":", "2", "]", "# x_max", "\n", "]", ")", "\n", "\n", "# Scale boxes back to original image shape.", "\n", "boxes", "*=", "K", ".", "concatenate", "(", "[", "image_shape", ",", "image_shape", "]", ")", "\n", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_boxes_and_scores": [[237, 246], ["model.yolo_head", "model.yolo_correct_boxes", "tensorflow.keras.backend.reshape", "tensorflow.keras.backend.reshape"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_head", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_correct_boxes"], ["", "def", "yolo_boxes_and_scores", "(", "feats", ",", "anchors", ",", "num_classes", ",", "input_shape", ",", "image_shape", ")", ":", "\n", "    ", "'''Process Conv layer output'''", "\n", "box_xy", ",", "box_wh", ",", "box_confidence", ",", "box_class_probs", "=", "yolo_head", "(", "feats", ",", "\n", "anchors", ",", "num_classes", ",", "input_shape", ")", "\n", "boxes", "=", "yolo_correct_boxes", "(", "box_xy", ",", "box_wh", ",", "input_shape", ",", "image_shape", ")", "\n", "boxes", "=", "K", ".", "reshape", "(", "boxes", ",", "[", "-", "1", ",", "4", "]", ")", "\n", "box_scores", "=", "box_confidence", "*", "box_class_probs", "\n", "box_scores", "=", "K", ".", "reshape", "(", "box_scores", ",", "[", "-", "1", ",", "num_classes", "]", ")", "\n", "return", "boxes", ",", "box_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_eval": [[248, 290], ["len", "range", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.constant", "range", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.concatenate", "model.yolo_boxes_and_scores", "K.concatenate.append", "K.concatenate.append", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.image.non_max_suppression", "tensorflow.keras.backend.gather", "tensorflow.keras.backend.gather", "K.concatenate.append", "K.concatenate.append", "K.concatenate.append", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.ones_like"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_boxes_and_scores", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.preprocessing.non_max_suppression"], ["", "def", "yolo_eval", "(", "yolo_outputs", ",", "\n", "anchors", ",", "\n", "num_classes", ",", "\n", "image_shape", ",", "\n", "max_boxes", "=", "200", ",", "\n", "score_threshold", "=", ".5", ",", "\n", "iou_threshold", "=", ".5", ")", ":", "\n", "    ", "\"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"", "\n", "num_layers", "=", "len", "(", "yolo_outputs", ")", "\n", "anchor_mask", "=", "[", "[", "6", ",", "7", ",", "8", "]", ",", "[", "3", ",", "4", ",", "5", "]", ",", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "input_shape", "=", "K", ".", "shape", "(", "yolo_outputs", "[", "0", "]", ")", "[", "1", ":", "3", "]", "*", "32", "\n", "boxes", "=", "[", "]", "\n", "box_scores", "=", "[", "]", "\n", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "        ", "_boxes", ",", "_box_scores", "=", "yolo_boxes_and_scores", "(", "yolo_outputs", "[", "l", "]", ",", "\n", "anchors", "[", "anchor_mask", "[", "l", "]", "]", ",", "num_classes", ",", "input_shape", ",", "image_shape", ")", "\n", "boxes", ".", "append", "(", "_boxes", ")", "\n", "box_scores", ".", "append", "(", "_box_scores", ")", "\n", "", "boxes", "=", "K", ".", "concatenate", "(", "boxes", ",", "axis", "=", "0", ")", "\n", "box_scores", "=", "K", ".", "concatenate", "(", "box_scores", ",", "axis", "=", "0", ")", "\n", "\n", "mask", "=", "box_scores", ">=", "score_threshold", "\n", "max_boxes_tensor", "=", "K", ".", "constant", "(", "max_boxes", ",", "dtype", "=", "'int32'", ")", "\n", "boxes_", "=", "[", "]", "\n", "scores_", "=", "[", "]", "\n", "classes_", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "num_classes", ")", ":", "\n", "        ", "class_boxes", "=", "tf", ".", "boolean_mask", "(", "boxes", ",", "mask", "[", ":", ",", "c", "]", ")", "\n", "class_box_scores", "=", "tf", ".", "boolean_mask", "(", "box_scores", "[", ":", ",", "c", "]", ",", "mask", "[", ":", ",", "c", "]", ")", "\n", "nms_index", "=", "tf", ".", "image", ".", "non_max_suppression", "(", "\n", "class_boxes", ",", "class_box_scores", ",", "max_boxes_tensor", ",", "iou_threshold", "=", "iou_threshold", ")", "\n", "class_boxes", "=", "K", ".", "gather", "(", "class_boxes", ",", "nms_index", ")", "\n", "class_box_scores", "=", "K", ".", "gather", "(", "class_box_scores", ",", "nms_index", ")", "\n", "classes", "=", "K", ".", "ones_like", "(", "class_box_scores", ",", "'int32'", ")", "*", "c", "\n", "boxes_", ".", "append", "(", "class_boxes", ")", "\n", "scores_", ".", "append", "(", "class_box_scores", ")", "\n", "classes_", ".", "append", "(", "classes", ")", "\n", "", "boxes_", "=", "K", ".", "concatenate", "(", "boxes_", ",", "axis", "=", "0", ")", "\n", "scores_", "=", "K", ".", "concatenate", "(", "scores_", ",", "axis", "=", "0", ")", "\n", "classes_", "=", "K", ".", "concatenate", "(", "classes_", ",", "axis", "=", "0", ")", "\n", "\n", "return", "boxes_", ",", "scores_", ",", "classes_", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.preprocess_true_boxes": [[292, 362], ["numpy.array", "numpy.array", "numpy.expand_dims", "range", "len", "numpy.zeros", "numpy.expand_dims", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.argmax", "enumerate", "range", "range", "len", "range", "len", "numpy.floor().astype", "numpy.floor().astype", "anchor_mask[].index", "true_boxes[].astype", "numpy.floor", "numpy.floor"], "function", ["None"], ["", "def", "preprocess_true_boxes", "(", "true_boxes", ",", "input_shape", ",", "anchors", ",", "num_classes", ")", ":", "\n", "    ", "'''Preprocess true boxes to training input format\n\n    Parameters\n    ----------\n    true_boxes: array, shape=(m, T, 5)\n        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n    input_shape: array-like, hw, multiples of 32\n    anchors: array, shape=(N, 2), wh\n    num_classes: integer\n\n    Returns\n    -------\n    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n\n    '''", "\n", "assert", "(", "true_boxes", "[", "...", ",", "4", "]", "<", "num_classes", ")", ".", "all", "(", ")", ",", "'class id must be less than num_classes'", "\n", "num_layers", "=", "len", "(", "anchors", ")", "//", "3", "# default setting", "\n", "anchor_mask", "=", "[", "[", "6", ",", "7", ",", "8", "]", ",", "[", "3", ",", "4", ",", "5", "]", ",", "[", "0", ",", "1", ",", "2", "]", "]", "if", "num_layers", "==", "3", "else", "[", "[", "3", ",", "4", ",", "5", "]", ",", "[", "1", ",", "2", ",", "3", "]", "]", "\n", "\n", "true_boxes", "=", "np", ".", "array", "(", "true_boxes", ",", "dtype", "=", "'float32'", ")", "\n", "input_shape", "=", "np", ".", "array", "(", "input_shape", ",", "dtype", "=", "'int32'", ")", "\n", "boxes_xy", "=", "(", "true_boxes", "[", "...", ",", "0", ":", "2", "]", "+", "true_boxes", "[", "...", ",", "2", ":", "4", "]", ")", "//", "2", "\n", "boxes_wh", "=", "true_boxes", "[", "...", ",", "2", ":", "4", "]", "-", "true_boxes", "[", "...", ",", "0", ":", "2", "]", "\n", "true_boxes", "[", "...", ",", "0", ":", "2", "]", "=", "boxes_xy", "/", "input_shape", "[", ":", ":", "-", "1", "]", "\n", "true_boxes", "[", "...", ",", "2", ":", "4", "]", "=", "boxes_wh", "/", "input_shape", "[", ":", ":", "-", "1", "]", "\n", "\n", "m", "=", "true_boxes", ".", "shape", "[", "0", "]", "\n", "grid_shapes", "=", "[", "input_shape", "//", "{", "0", ":", "32", ",", "1", ":", "16", ",", "2", ":", "8", "}", "[", "l", "]", "for", "l", "in", "range", "(", "num_layers", ")", "]", "\n", "y_true", "=", "[", "np", ".", "zeros", "(", "(", "m", ",", "grid_shapes", "[", "l", "]", "[", "0", "]", ",", "grid_shapes", "[", "l", "]", "[", "1", "]", ",", "len", "(", "anchor_mask", "[", "l", "]", ")", ",", "5", "+", "num_classes", ")", ",", "\n", "dtype", "=", "'float32'", ")", "for", "l", "in", "range", "(", "num_layers", ")", "]", "\n", "\n", "# Expand dim to apply broadcasting.", "\n", "anchors", "=", "np", ".", "expand_dims", "(", "anchors", ",", "0", ")", "\n", "anchor_maxes", "=", "anchors", "/", "2.", "\n", "anchor_mins", "=", "-", "anchor_maxes", "\n", "valid_mask", "=", "boxes_wh", "[", "...", ",", "0", "]", ">", "0", "\n", "\n", "for", "b", "in", "range", "(", "m", ")", ":", "\n", "# Discard zero rows.", "\n", "        ", "wh", "=", "boxes_wh", "[", "b", ",", "valid_mask", "[", "b", "]", "]", "\n", "if", "len", "(", "wh", ")", "==", "0", ":", "continue", "\n", "# Expand dim to apply broadcasting.", "\n", "wh", "=", "np", ".", "expand_dims", "(", "wh", ",", "-", "2", ")", "\n", "box_maxes", "=", "wh", "/", "2.", "\n", "box_mins", "=", "-", "box_maxes", "\n", "\n", "intersect_mins", "=", "np", ".", "maximum", "(", "box_mins", ",", "anchor_mins", ")", "\n", "intersect_maxes", "=", "np", ".", "minimum", "(", "box_maxes", ",", "anchor_maxes", ")", "\n", "intersect_wh", "=", "np", ".", "maximum", "(", "intersect_maxes", "-", "intersect_mins", ",", "0.", ")", "\n", "intersect_area", "=", "intersect_wh", "[", "...", ",", "0", "]", "*", "intersect_wh", "[", "...", ",", "1", "]", "\n", "box_area", "=", "wh", "[", "...", ",", "0", "]", "*", "wh", "[", "...", ",", "1", "]", "\n", "anchor_area", "=", "anchors", "[", "...", ",", "0", "]", "*", "anchors", "[", "...", ",", "1", "]", "\n", "iou", "=", "intersect_area", "/", "(", "box_area", "+", "anchor_area", "-", "intersect_area", ")", "\n", "\n", "# Find best anchor for each true box", "\n", "best_anchor", "=", "np", ".", "argmax", "(", "iou", ",", "axis", "=", "-", "1", ")", "\n", "\n", "for", "t", ",", "n", "in", "enumerate", "(", "best_anchor", ")", ":", "\n", "            ", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "if", "n", "in", "anchor_mask", "[", "l", "]", ":", "\n", "                    ", "i", "=", "np", ".", "floor", "(", "true_boxes", "[", "b", ",", "t", ",", "0", "]", "*", "grid_shapes", "[", "l", "]", "[", "1", "]", ")", ".", "astype", "(", "'int32'", ")", "\n", "j", "=", "np", ".", "floor", "(", "true_boxes", "[", "b", ",", "t", ",", "1", "]", "*", "grid_shapes", "[", "l", "]", "[", "0", "]", ")", ".", "astype", "(", "'int32'", ")", "\n", "k", "=", "anchor_mask", "[", "l", "]", ".", "index", "(", "n", ")", "\n", "c", "=", "true_boxes", "[", "b", ",", "t", ",", "4", "]", ".", "astype", "(", "'int32'", ")", "\n", "y_true", "[", "l", "]", "[", "b", ",", "j", ",", "i", ",", "k", ",", "0", ":", "4", "]", "=", "true_boxes", "[", "b", ",", "t", ",", "0", ":", "4", "]", "\n", "y_true", "[", "l", "]", "[", "b", ",", "j", ",", "i", ",", "k", ",", "4", "]", "=", "1", "\n", "y_true", "[", "l", "]", "[", "b", ",", "j", ",", "i", ",", "k", ",", "5", "+", "c", "]", "=", "1", "\n", "\n", "", "", "", "", "return", "y_true", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.softmax_focal_loss": [[364, 399], ["tensorflow.nn.softmax", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.math.log", "tensorflow.pow"], "function", ["None"], ["", "def", "softmax_focal_loss", "(", "y_true", ",", "y_pred", ",", "gamma", "=", "2.0", ",", "alpha", "=", "0.25", ")", ":", "\n", "    ", "\"\"\"\n    Compute softmax focal loss.\n    Reference Paper:\n        \"Focal Loss for Dense Object Detection\"\n        https://arxiv.org/abs/1708.02002\n\n    # Arguments\n        y_true: Ground truth targets,\n            tensor of shape (?, num_boxes, num_classes).\n        y_pred: Predicted logits,\n            tensor of shape (?, num_boxes, num_classes).\n        gamma: exponent of the modulating factor (1 - p_t) ^ gamma.\n        alpha: optional alpha weighting factor to balance positives vs negatives.\n\n    # Returns\n        softmax_focal_loss: Softmax focal loss, tensor of shape (?, num_boxes).\n    \"\"\"", "\n", "\n", "# Scale predictions so that the class probas of each sample sum to 1", "\n", "#y_pred /= K.sum(y_pred, axis=-1, keepdims=True)", "\n", "\n", "# Clip the prediction value to prevent NaN's and Inf's", "\n", "#epsilon = K.epsilon()", "\n", "#y_pred = K.clip(y_pred, epsilon, 1. - epsilon)", "\n", "y_pred", "=", "tf", ".", "nn", ".", "softmax", "(", "y_pred", ")", "\n", "y_pred", "=", "tf", ".", "maximum", "(", "tf", ".", "minimum", "(", "y_pred", ",", "1", "-", "1e-15", ")", ",", "1e-15", ")", "\n", "\n", "# Calculate Cross Entropy", "\n", "cross_entropy", "=", "-", "y_true", "*", "tf", ".", "math", ".", "log", "(", "y_pred", ")", "\n", "\n", "# Calculate Focal Loss", "\n", "softmax_focal_loss", "=", "alpha", "*", "tf", ".", "pow", "(", "1", "-", "y_pred", ",", "gamma", ")", "*", "cross_entropy", "\n", "\n", "return", "softmax_focal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.sigmoid_focal_loss": [[401, 430], ["tensorflow.keras.backend.binary_crossentropy", "tensorflow.sigmoid", "tensorflow.pow"], "function", ["None"], ["", "def", "sigmoid_focal_loss", "(", "y_true", ",", "y_pred", ",", "gamma", "=", "2.0", ",", "alpha", "=", "0.25", ")", ":", "\n", "    ", "\"\"\"\n    Compute sigmoid focal loss.\n    Reference Paper:\n        \"Focal Loss for Dense Object Detection\"\n        https://arxiv.org/abs/1708.02002\n\n    # Arguments\n        y_true: Ground truth targets,\n            tensor of shape (?, num_boxes, num_classes).\n        y_pred: Predicted logits,\n            tensor of shape (?, num_boxes, num_classes).\n        gamma: exponent of the modulating factor (1 - p_t) ^ gamma.\n        alpha: optional alpha weighting factor to balance positives vs negatives.\n\n    # Returns\n        sigmoid_focal_loss: Sigmoid focal loss, tensor of shape (?, num_boxes).\n    \"\"\"", "\n", "sigmoid_loss", "=", "K", ".", "binary_crossentropy", "(", "y_true", ",", "y_pred", ",", "from_logits", "=", "True", ")", "\n", "\n", "pred_prob", "=", "tf", ".", "sigmoid", "(", "y_pred", ")", "\n", "p_t", "=", "(", "(", "y_true", "*", "pred_prob", ")", "+", "(", "(", "1", "-", "y_true", ")", "*", "(", "1", "-", "pred_prob", ")", ")", ")", "\n", "modulating_factor", "=", "tf", ".", "pow", "(", "1.0", "-", "p_t", ",", "gamma", ")", "\n", "alpha_weight_factor", "=", "(", "y_true", "*", "alpha", "+", "(", "1", "-", "y_true", ")", "*", "(", "1", "-", "alpha", ")", ")", "\n", "\n", "sigmoid_focal_loss", "=", "modulating_factor", "*", "alpha_weight_factor", "*", "sigmoid_loss", "\n", "#sigmoid_focal_loss = tf.reduce_sum(sigmoid_focal_loss, axis=-1)", "\n", "\n", "return", "sigmoid_focal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_iou": [[432, 470], ["tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.minimum", "tensorflow.keras.backend.maximum"], "function", ["None"], ["", "def", "box_iou", "(", "b1", ",", "b2", ")", ":", "\n", "    ", "\"\"\"\n    Return iou tensor\n\n    Parameters\n    ----------\n    b1: tensor, shape=(i1,...,iN, 4), xywh\n    b2: tensor, shape=(j, 4), xywh\n\n    Returns\n    -------\n    iou: tensor, shape=(i1,...,iN, j)\n    \"\"\"", "\n", "# Expand dim to apply broadcasting.", "\n", "b1", "=", "K", ".", "expand_dims", "(", "b1", ",", "-", "2", ")", "\n", "b1_xy", "=", "b1", "[", "...", ",", ":", "2", "]", "\n", "b1_wh", "=", "b1", "[", "...", ",", "2", ":", "4", "]", "\n", "b1_wh_half", "=", "b1_wh", "/", "2.", "\n", "b1_mins", "=", "b1_xy", "-", "b1_wh_half", "\n", "b1_maxes", "=", "b1_xy", "+", "b1_wh_half", "\n", "\n", "# Expand dim to apply broadcasting.", "\n", "b2", "=", "K", ".", "expand_dims", "(", "b2", ",", "0", ")", "\n", "b2_xy", "=", "b2", "[", "...", ",", ":", "2", "]", "\n", "b2_wh", "=", "b2", "[", "...", ",", "2", ":", "4", "]", "\n", "b2_wh_half", "=", "b2_wh", "/", "2.", "\n", "b2_mins", "=", "b2_xy", "-", "b2_wh_half", "\n", "b2_maxes", "=", "b2_xy", "+", "b2_wh_half", "\n", "\n", "intersect_mins", "=", "K", ".", "maximum", "(", "b1_mins", ",", "b2_mins", ")", "\n", "intersect_maxes", "=", "K", ".", "minimum", "(", "b1_maxes", ",", "b2_maxes", ")", "\n", "intersect_wh", "=", "K", ".", "maximum", "(", "intersect_maxes", "-", "intersect_mins", ",", "0.", ")", "\n", "intersect_area", "=", "intersect_wh", "[", "...", ",", "0", "]", "*", "intersect_wh", "[", "...", ",", "1", "]", "\n", "b1_area", "=", "b1_wh", "[", "...", ",", "0", "]", "*", "b1_wh", "[", "...", ",", "1", "]", "\n", "b2_area", "=", "b2_wh", "[", "...", ",", "0", "]", "*", "b2_wh", "[", "...", ",", "1", "]", "\n", "iou", "=", "intersect_area", "/", "(", "b1_area", "+", "b2_area", "-", "intersect_area", ")", "\n", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_giou": [[472, 520], ["tensorflow.keras.backend.maximum", "tensorflow.keras.backend.minimum", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.minimum", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.epsilon", "tensorflow.keras.backend.epsilon"], "function", ["None"], ["", "def", "box_giou", "(", "b1", ",", "b2", ")", ":", "\n", "    ", "\"\"\"\n    Calculate GIoU loss on anchor boxes\n    Reference Paper:\n        \"Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression\"\n        https://arxiv.org/abs/1902.09630\n\n    Parameters\n    ----------\n    b1: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n    b2: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n\n    Returns\n    -------\n    giou: tensor, shape=(batch, feat_w, feat_h, anchor_num, 1)\n    \"\"\"", "\n", "b1_xy", "=", "b1", "[", "...", ",", ":", "2", "]", "\n", "b1_wh", "=", "b1", "[", "...", ",", "2", ":", "4", "]", "\n", "b1_wh_half", "=", "b1_wh", "/", "2.", "\n", "b1_mins", "=", "b1_xy", "-", "b1_wh_half", "\n", "b1_maxes", "=", "b1_xy", "+", "b1_wh_half", "\n", "\n", "b2_xy", "=", "b2", "[", "...", ",", ":", "2", "]", "\n", "b2_wh", "=", "b2", "[", "...", ",", "2", ":", "4", "]", "\n", "b2_wh_half", "=", "b2_wh", "/", "2.", "\n", "b2_mins", "=", "b2_xy", "-", "b2_wh_half", "\n", "b2_maxes", "=", "b2_xy", "+", "b2_wh_half", "\n", "\n", "intersect_mins", "=", "K", ".", "maximum", "(", "b1_mins", ",", "b2_mins", ")", "\n", "intersect_maxes", "=", "K", ".", "minimum", "(", "b1_maxes", ",", "b2_maxes", ")", "\n", "intersect_wh", "=", "K", ".", "maximum", "(", "intersect_maxes", "-", "intersect_mins", ",", "0.", ")", "\n", "intersect_area", "=", "intersect_wh", "[", "...", ",", "0", "]", "*", "intersect_wh", "[", "...", ",", "1", "]", "\n", "b1_area", "=", "b1_wh", "[", "...", ",", "0", "]", "*", "b1_wh", "[", "...", ",", "1", "]", "\n", "b2_area", "=", "b2_wh", "[", "...", ",", "0", "]", "*", "b2_wh", "[", "...", ",", "1", "]", "\n", "union_area", "=", "b1_area", "+", "b2_area", "-", "intersect_area", "\n", "# calculate IoU, add epsilon in denominator to avoid dividing by 0", "\n", "iou", "=", "intersect_area", "/", "(", "union_area", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "\n", "# get enclosed area", "\n", "enclose_mins", "=", "K", ".", "minimum", "(", "b1_mins", ",", "b2_mins", ")", "\n", "enclose_maxes", "=", "K", ".", "maximum", "(", "b1_maxes", ",", "b2_maxes", ")", "\n", "enclose_wh", "=", "K", ".", "maximum", "(", "enclose_maxes", "-", "enclose_mins", ",", "0.0", ")", "\n", "enclose_area", "=", "enclose_wh", "[", "...", ",", "0", "]", "*", "enclose_wh", "[", "...", ",", "1", "]", "\n", "# calculate GIoU, add epsilon in denominator to avoid dividing by 0", "\n", "giou", "=", "iou", "-", "1.0", "*", "(", "enclose_area", "-", "union_area", ")", "/", "(", "enclose_area", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "giou", "=", "K", ".", "expand_dims", "(", "giou", ",", "-", "1", ")", "\n", "\n", "return", "giou", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_diou": [[522, 578], ["tensorflow.keras.backend.maximum", "tensorflow.keras.backend.minimum", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.minimum", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.square", "tensorflow.keras.backend.square", "tensorflow.keras.backend.epsilon", "tensorflow.keras.backend.epsilon"], "function", ["None"], ["", "def", "box_diou", "(", "b1", ",", "b2", ")", ":", "\n", "    ", "\"\"\"\n    Calculate DIoU loss on anchor boxes\n    Reference Paper:\n        \"Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression\"\n        https://arxiv.org/abs/1911.08287\n\n    Parameters\n    ----------\n    b1: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n    b2: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n\n    Returns\n    -------\n    diou: tensor, shape=(batch, feat_w, feat_h, anchor_num, 1)\n    \"\"\"", "\n", "b1_xy", "=", "b1", "[", "...", ",", ":", "2", "]", "\n", "b1_wh", "=", "b1", "[", "...", ",", "2", ":", "4", "]", "\n", "b1_wh_half", "=", "b1_wh", "/", "2.", "\n", "b1_mins", "=", "b1_xy", "-", "b1_wh_half", "\n", "b1_maxes", "=", "b1_xy", "+", "b1_wh_half", "\n", "\n", "b2_xy", "=", "b2", "[", "...", ",", ":", "2", "]", "\n", "b2_wh", "=", "b2", "[", "...", ",", "2", ":", "4", "]", "\n", "b2_wh_half", "=", "b2_wh", "/", "2.", "\n", "b2_mins", "=", "b2_xy", "-", "b2_wh_half", "\n", "b2_maxes", "=", "b2_xy", "+", "b2_wh_half", "\n", "\n", "intersect_mins", "=", "K", ".", "maximum", "(", "b1_mins", ",", "b2_mins", ")", "\n", "intersect_maxes", "=", "K", ".", "minimum", "(", "b1_maxes", ",", "b2_maxes", ")", "\n", "intersect_wh", "=", "K", ".", "maximum", "(", "intersect_maxes", "-", "intersect_mins", ",", "0.", ")", "\n", "intersect_area", "=", "intersect_wh", "[", "...", ",", "0", "]", "*", "intersect_wh", "[", "...", ",", "1", "]", "\n", "b1_area", "=", "b1_wh", "[", "...", ",", "0", "]", "*", "b1_wh", "[", "...", ",", "1", "]", "\n", "b2_area", "=", "b2_wh", "[", "...", ",", "0", "]", "*", "b2_wh", "[", "...", ",", "1", "]", "\n", "union_area", "=", "b1_area", "+", "b2_area", "-", "intersect_area", "\n", "# calculate IoU, add epsilon in denominator to avoid dividing by 0", "\n", "iou", "=", "intersect_area", "/", "(", "union_area", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "\n", "# box center distance", "\n", "center_distance", "=", "K", ".", "sum", "(", "K", ".", "square", "(", "b1_xy", "-", "b2_xy", ")", ",", "axis", "=", "-", "1", ")", "\n", "# get enclosed area", "\n", "enclose_mins", "=", "K", ".", "minimum", "(", "b1_mins", ",", "b2_mins", ")", "\n", "enclose_maxes", "=", "K", ".", "maximum", "(", "b1_maxes", ",", "b2_maxes", ")", "\n", "enclose_wh", "=", "K", ".", "maximum", "(", "enclose_maxes", "-", "enclose_mins", ",", "0.0", ")", "\n", "# get enclosed diagonal distance", "\n", "enclose_diagonal", "=", "K", ".", "sum", "(", "K", ".", "square", "(", "enclose_wh", ")", ",", "axis", "=", "-", "1", ")", "\n", "# calculate DIoU, add epsilon in denominator to avoid dividing by 0", "\n", "diou", "=", "iou", "-", "1.0", "*", "(", "center_distance", ")", "/", "(", "enclose_diagonal", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "\n", "# calculate param v and alpha to extend to CIoU", "\n", "#v = 4*K.square(tf.math.atan2(b1_wh[..., 0], b1_wh[..., 1]) - tf.math.atan2(b2_wh[..., 0], b2_wh[..., 1])) / (math.pi * math.pi)", "\n", "#alpha = v / (1.0 - iou + v)", "\n", "#diou = diou - alpha*v", "\n", "\n", "diou", "=", "K", ".", "expand_dims", "(", "diou", ",", "-", "1", ")", "\n", "return", "diou", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model._smooth_labels": [[580, 583], ["tensorflow.keras.backend.constant", "tensorflow.keras.backend.floatx"], "function", ["None"], ["", "def", "_smooth_labels", "(", "y_true", ",", "label_smoothing", ")", ":", "\n", "    ", "label_smoothing", "=", "K", ".", "constant", "(", "label_smoothing", ",", "dtype", "=", "K", ".", "floatx", "(", ")", ")", "\n", "return", "y_true", "*", "(", "1.0", "-", "label_smoothing", ")", "+", "0.5", "*", "label_smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo4_loss": [[585, 699], ["tensorflow.keras.backend.cast", "tensorflow.keras.backend.cast", "range", "tensorflow.keras.backend.expand_dims", "len", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.dtype", "model.yolo_head", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.log", "tensorflow.keras.backend.switch", "tensorflow.TensorArray", "tensorflow.keras.backend.cast", "tensorflow.while_loop", "ignore_mask.write.stack", "tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.dtype", "range", "model._smooth_labels", "tensorflow.keras.backend.zeros_like", "tensorflow.keras.backend.dtype", "tensorflow.boolean_mask", "model.box_iou", "tensorflow.keras.backend.max", "ignore_mask.write.write", "model.sigmoid_focal_loss", "model.box_giou", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.cast", "model.softmax_focal_loss", "model.sigmoid_focal_loss", "tensorflow.keras.backend.sum", "model.box_diou", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.square", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.categorical_crossentropy"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_head", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model._smooth_labels", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_iou", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.sigmoid_focal_loss", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_giou", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.softmax_focal_loss", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.sigmoid_focal_loss", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_diou"], ["", "def", "yolo4_loss", "(", "args", ",", "anchors", ",", "num_classes", ",", "ignore_thresh", "=", ".5", ",", "label_smoothing", "=", "0", ",", "use_focal_loss", "=", "False", ",", "use_focal_obj_loss", "=", "False", ",", "use_softmax_loss", "=", "False", ",", "use_giou_loss", "=", "False", ",", "use_diou_loss", "=", "False", ")", ":", "\n", "    ", "'''Return yolo4_loss tensor\n\n    Parameters\n    ----------\n    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n    y_true: list of array, the output of preprocess_true_boxes\n    anchors: array, shape=(N, 2), wh\n    num_classes: integer\n    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n\n    Returns\n    -------\n    loss: tensor, shape=(1,)\n\n    '''", "\n", "num_layers", "=", "len", "(", "anchors", ")", "//", "3", "# default setting", "\n", "yolo_outputs", "=", "args", "[", ":", "num_layers", "]", "\n", "y_true", "=", "args", "[", "num_layers", ":", "]", "\n", "anchor_mask", "=", "[", "[", "6", ",", "7", ",", "8", "]", ",", "[", "3", ",", "4", ",", "5", "]", ",", "[", "0", ",", "1", ",", "2", "]", "]", "if", "num_layers", "==", "3", "else", "[", "[", "3", ",", "4", ",", "5", "]", ",", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "input_shape", "=", "K", ".", "cast", "(", "K", ".", "shape", "(", "yolo_outputs", "[", "0", "]", ")", "[", "1", ":", "3", "]", "*", "32", ",", "K", ".", "dtype", "(", "y_true", "[", "0", "]", ")", ")", "\n", "grid_shapes", "=", "[", "K", ".", "cast", "(", "K", ".", "shape", "(", "yolo_outputs", "[", "l", "]", ")", "[", "1", ":", "3", "]", ",", "K", ".", "dtype", "(", "y_true", "[", "0", "]", ")", ")", "for", "l", "in", "range", "(", "num_layers", ")", "]", "\n", "loss", "=", "0", "\n", "total_location_loss", "=", "0", "\n", "total_confidence_loss", "=", "0", "\n", "total_class_loss", "=", "0", "\n", "m", "=", "K", ".", "shape", "(", "yolo_outputs", "[", "0", "]", ")", "[", "0", "]", "# batch size, tensor", "\n", "mf", "=", "K", ".", "cast", "(", "m", ",", "K", ".", "dtype", "(", "yolo_outputs", "[", "0", "]", ")", ")", "\n", "\n", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "        ", "object_mask", "=", "y_true", "[", "l", "]", "[", "...", ",", "4", ":", "5", "]", "\n", "true_class_probs", "=", "y_true", "[", "l", "]", "[", "...", ",", "5", ":", "]", "\n", "if", "label_smoothing", ":", "\n", "            ", "true_class_probs", "=", "_smooth_labels", "(", "true_class_probs", ",", "label_smoothing", ")", "\n", "\n", "", "grid", ",", "raw_pred", ",", "pred_xy", ",", "pred_wh", "=", "yolo_head", "(", "yolo_outputs", "[", "l", "]", ",", "\n", "anchors", "[", "anchor_mask", "[", "l", "]", "]", ",", "num_classes", ",", "input_shape", ",", "calc_loss", "=", "True", ")", "\n", "pred_box", "=", "K", ".", "concatenate", "(", "[", "pred_xy", ",", "pred_wh", "]", ")", "\n", "\n", "# Darknet raw box to calculate loss.", "\n", "raw_true_xy", "=", "y_true", "[", "l", "]", "[", "...", ",", ":", "2", "]", "*", "grid_shapes", "[", "l", "]", "[", ":", ":", "-", "1", "]", "-", "grid", "\n", "raw_true_wh", "=", "K", ".", "log", "(", "y_true", "[", "l", "]", "[", "...", ",", "2", ":", "4", "]", "/", "anchors", "[", "anchor_mask", "[", "l", "]", "]", "*", "input_shape", "[", ":", ":", "-", "1", "]", ")", "\n", "raw_true_wh", "=", "K", ".", "switch", "(", "object_mask", ",", "raw_true_wh", ",", "K", ".", "zeros_like", "(", "raw_true_wh", ")", ")", "# avoid log(0)=-inf", "\n", "box_loss_scale", "=", "2", "-", "y_true", "[", "l", "]", "[", "...", ",", "2", ":", "3", "]", "*", "y_true", "[", "l", "]", "[", "...", ",", "3", ":", "4", "]", "\n", "\n", "# Find ignore mask, iterate over each of batch.", "\n", "ignore_mask", "=", "tf", ".", "TensorArray", "(", "K", ".", "dtype", "(", "y_true", "[", "0", "]", ")", ",", "size", "=", "1", ",", "dynamic_size", "=", "True", ")", "\n", "object_mask_bool", "=", "K", ".", "cast", "(", "object_mask", ",", "'bool'", ")", "\n", "def", "loop_body", "(", "b", ",", "ignore_mask", ")", ":", "\n", "            ", "true_box", "=", "tf", ".", "boolean_mask", "(", "y_true", "[", "l", "]", "[", "b", ",", "...", ",", "0", ":", "4", "]", ",", "object_mask_bool", "[", "b", ",", "...", ",", "0", "]", ")", "\n", "iou", "=", "box_iou", "(", "pred_box", "[", "b", "]", ",", "true_box", ")", "\n", "best_iou", "=", "K", ".", "max", "(", "iou", ",", "axis", "=", "-", "1", ")", "\n", "ignore_mask", "=", "ignore_mask", ".", "write", "(", "b", ",", "K", ".", "cast", "(", "best_iou", "<", "ignore_thresh", ",", "K", ".", "dtype", "(", "true_box", ")", ")", ")", "\n", "return", "b", "+", "1", ",", "ignore_mask", "\n", "", "_", ",", "ignore_mask", "=", "tf", ".", "while_loop", "(", "lambda", "b", ",", "*", "args", ":", "b", "<", "m", ",", "loop_body", ",", "[", "0", ",", "ignore_mask", "]", ")", "\n", "ignore_mask", "=", "ignore_mask", ".", "stack", "(", ")", "\n", "ignore_mask", "=", "K", ".", "expand_dims", "(", "ignore_mask", ",", "-", "1", ")", "\n", "\n", "if", "use_focal_obj_loss", ":", "\n", "# Focal loss for objectness confidence", "\n", "            ", "confidence_loss", "=", "sigmoid_focal_loss", "(", "object_mask", ",", "raw_pred", "[", "...", ",", "4", ":", "5", "]", ")", "\n", "", "else", ":", "\n", "            ", "confidence_loss", "=", "object_mask", "*", "K", ".", "binary_crossentropy", "(", "object_mask", ",", "raw_pred", "[", "...", ",", "4", ":", "5", "]", ",", "from_logits", "=", "True", ")", "+", "(", "1", "-", "object_mask", ")", "*", "K", ".", "binary_crossentropy", "(", "object_mask", ",", "raw_pred", "[", "...", ",", "4", ":", "5", "]", ",", "from_logits", "=", "True", ")", "*", "ignore_mask", "\n", "\n", "", "if", "use_focal_loss", ":", "\n", "# Focal loss for classification score", "\n", "            ", "if", "use_softmax_loss", ":", "\n", "                ", "class_loss", "=", "softmax_focal_loss", "(", "true_class_probs", ",", "raw_pred", "[", "...", ",", "5", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "class_loss", "=", "sigmoid_focal_loss", "(", "true_class_probs", ",", "raw_pred", "[", "...", ",", "5", ":", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "use_softmax_loss", ":", "\n", "# use softmax style classification output", "\n", "                ", "class_loss", "=", "object_mask", "*", "K", ".", "expand_dims", "(", "K", ".", "categorical_crossentropy", "(", "true_class_probs", ",", "raw_pred", "[", "...", ",", "5", ":", "]", ",", "from_logits", "=", "True", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# use sigmoid style classification output", "\n", "                ", "class_loss", "=", "object_mask", "*", "K", ".", "binary_crossentropy", "(", "true_class_probs", ",", "raw_pred", "[", "...", ",", "5", ":", "]", ",", "from_logits", "=", "True", ")", "\n", "\n", "\n", "", "", "if", "use_giou_loss", ":", "\n", "# Calculate GIoU loss as location loss", "\n", "            ", "raw_true_box", "=", "y_true", "[", "l", "]", "[", "...", ",", "0", ":", "4", "]", "\n", "giou", "=", "box_giou", "(", "pred_box", ",", "raw_true_box", ")", "\n", "giou_loss", "=", "object_mask", "*", "box_loss_scale", "*", "(", "1", "-", "giou", ")", "\n", "giou_loss", "=", "K", ".", "sum", "(", "giou_loss", ")", "/", "mf", "\n", "location_loss", "=", "giou_loss", "\n", "", "elif", "use_diou_loss", ":", "\n", "# Calculate DIoU loss as location loss", "\n", "            ", "raw_true_box", "=", "y_true", "[", "l", "]", "[", "...", ",", "0", ":", "4", "]", "\n", "diou", "=", "box_diou", "(", "pred_box", ",", "raw_true_box", ")", "\n", "diou_loss", "=", "object_mask", "*", "box_loss_scale", "*", "(", "1", "-", "diou", ")", "\n", "diou_loss", "=", "K", ".", "sum", "(", "diou_loss", ")", "/", "mf", "\n", "location_loss", "=", "diou_loss", "\n", "", "else", ":", "\n", "# Standard YOLO location loss", "\n", "# K.binary_crossentropy is helpful to avoid exp overflow.", "\n", "            ", "xy_loss", "=", "object_mask", "*", "box_loss_scale", "*", "K", ".", "binary_crossentropy", "(", "raw_true_xy", ",", "raw_pred", "[", "...", ",", "0", ":", "2", "]", ",", "from_logits", "=", "True", ")", "\n", "wh_loss", "=", "object_mask", "*", "box_loss_scale", "*", "0.5", "*", "K", ".", "square", "(", "raw_true_wh", "-", "raw_pred", "[", "...", ",", "2", ":", "4", "]", ")", "\n", "xy_loss", "=", "K", ".", "sum", "(", "xy_loss", ")", "/", "mf", "\n", "wh_loss", "=", "K", ".", "sum", "(", "wh_loss", ")", "/", "mf", "\n", "location_loss", "=", "xy_loss", "+", "wh_loss", "\n", "\n", "", "confidence_loss", "=", "K", ".", "sum", "(", "confidence_loss", ")", "/", "mf", "\n", "class_loss", "=", "K", ".", "sum", "(", "class_loss", ")", "/", "mf", "\n", "loss", "+=", "location_loss", "+", "confidence_loss", "+", "class_loss", "\n", "total_location_loss", "+=", "location_loss", "\n", "total_confidence_loss", "+=", "confidence_loss", "\n", "total_class_loss", "+=", "class_loss", "\n", "\n", "# Fit for tf 2.0.0 loss shape", "\n", "", "loss", "=", "K", ".", "expand_dims", "(", "loss", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "loss", "#, total_location_loss, total_confidence_loss, total_class_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_loss": [[701, 769], ["tensorflow.keras.backend.cast", "tensorflow.keras.backend.cast", "range", "len", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.dtype", "model.yolo_head", "tensorflow.keras.backend.concatenate", "tensorflow.keras.backend.log", "tensorflow.keras.backend.switch", "tensorflow.TensorArray", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.control_flow_ops.while_loop", "ignore_mask.write.stack", "tensorflow.keras.backend.expand_dims", "tensorflow.keras.backend.dtype", "range", "tensorflow.keras.backend.zeros_like", "tensorflow.keras.backend.dtype", "tensorflow.boolean_mask", "model.box_iou", "tensorflow.keras.backend.max", "ignore_mask.write.write", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.square", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.sum", "tensorflow.keras.backend.sum", "tensorflow.Print", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.shape", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.dtype", "tensorflow.keras.backend.binary_crossentropy", "tensorflow.keras.backend.sum"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.yolo_head", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.model.box_iou"], ["", "def", "yolo_loss", "(", "args", ",", "anchors", ",", "num_classes", ",", "ignore_thresh", "=", ".5", ",", "print_loss", "=", "False", ")", ":", "\n", "    ", "'''Return yolo_loss tensor\n\n    Parameters\n    ----------\n    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n    y_true: list of array, the output of preprocess_true_boxes\n    anchors: array, shape=(N, 2), wh\n    num_classes: integer\n    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n\n    Returns\n    -------\n    loss: tensor, shape=(1,)\n\n    '''", "\n", "num_layers", "=", "len", "(", "anchors", ")", "//", "3", "# default setting", "\n", "yolo_outputs", "=", "args", "[", ":", "num_layers", "]", "\n", "y_true", "=", "args", "[", "num_layers", ":", "]", "\n", "anchor_mask", "=", "[", "[", "6", ",", "7", ",", "8", "]", ",", "[", "3", ",", "4", ",", "5", "]", ",", "[", "0", ",", "1", ",", "2", "]", "]", "if", "num_layers", "==", "3", "else", "[", "[", "3", ",", "4", ",", "5", "]", ",", "[", "1", ",", "2", ",", "3", "]", "]", "\n", "input_shape", "=", "K", ".", "cast", "(", "K", ".", "shape", "(", "yolo_outputs", "[", "0", "]", ")", "[", "1", ":", "3", "]", "*", "32", ",", "K", ".", "dtype", "(", "y_true", "[", "0", "]", ")", ")", "\n", "grid_shapes", "=", "[", "K", ".", "cast", "(", "K", ".", "shape", "(", "yolo_outputs", "[", "l", "]", ")", "[", "1", ":", "3", "]", ",", "K", ".", "dtype", "(", "y_true", "[", "0", "]", ")", ")", "for", "l", "in", "range", "(", "num_layers", ")", "]", "\n", "loss", "=", "0", "\n", "m", "=", "K", ".", "shape", "(", "yolo_outputs", "[", "0", "]", ")", "[", "0", "]", "# batch size, tensor", "\n", "mf", "=", "K", ".", "cast", "(", "m", ",", "K", ".", "dtype", "(", "yolo_outputs", "[", "0", "]", ")", ")", "\n", "\n", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "        ", "object_mask", "=", "y_true", "[", "l", "]", "[", "...", ",", "4", ":", "5", "]", "\n", "true_class_probs", "=", "y_true", "[", "l", "]", "[", "...", ",", "5", ":", "]", "\n", "\n", "grid", ",", "raw_pred", ",", "pred_xy", ",", "pred_wh", "=", "yolo_head", "(", "yolo_outputs", "[", "l", "]", ",", "\n", "anchors", "[", "anchor_mask", "[", "l", "]", "]", ",", "num_classes", ",", "input_shape", ",", "calc_loss", "=", "True", ")", "\n", "pred_box", "=", "K", ".", "concatenate", "(", "[", "pred_xy", ",", "pred_wh", "]", ")", "\n", "\n", "# Darknet raw box to calculate loss.", "\n", "raw_true_xy", "=", "y_true", "[", "l", "]", "[", "...", ",", ":", "2", "]", "*", "grid_shapes", "[", "l", "]", "[", ":", ":", "-", "1", "]", "-", "grid", "\n", "raw_true_wh", "=", "K", ".", "log", "(", "y_true", "[", "l", "]", "[", "...", ",", "2", ":", "4", "]", "/", "anchors", "[", "anchor_mask", "[", "l", "]", "]", "*", "input_shape", "[", ":", ":", "-", "1", "]", ")", "\n", "raw_true_wh", "=", "K", ".", "switch", "(", "object_mask", ",", "raw_true_wh", ",", "K", ".", "zeros_like", "(", "raw_true_wh", ")", ")", "# avoid log(0)=-inf", "\n", "box_loss_scale", "=", "2", "-", "y_true", "[", "l", "]", "[", "...", ",", "2", ":", "3", "]", "*", "y_true", "[", "l", "]", "[", "...", ",", "3", ":", "4", "]", "\n", "\n", "# Find ignore mask, iterate over each of batch.", "\n", "ignore_mask", "=", "tf", ".", "TensorArray", "(", "K", ".", "dtype", "(", "y_true", "[", "0", "]", ")", ",", "size", "=", "1", ",", "dynamic_size", "=", "True", ")", "\n", "object_mask_bool", "=", "K", ".", "cast", "(", "object_mask", ",", "'bool'", ")", "\n", "def", "loop_body", "(", "b", ",", "ignore_mask", ")", ":", "\n", "            ", "true_box", "=", "tf", ".", "boolean_mask", "(", "y_true", "[", "l", "]", "[", "b", ",", "...", ",", "0", ":", "4", "]", ",", "object_mask_bool", "[", "b", ",", "...", ",", "0", "]", ")", "\n", "iou", "=", "box_iou", "(", "pred_box", "[", "b", "]", ",", "true_box", ")", "\n", "best_iou", "=", "K", ".", "max", "(", "iou", ",", "axis", "=", "-", "1", ")", "\n", "ignore_mask", "=", "ignore_mask", ".", "write", "(", "b", ",", "K", ".", "cast", "(", "best_iou", "<", "ignore_thresh", ",", "K", ".", "dtype", "(", "true_box", ")", ")", ")", "\n", "return", "b", "+", "1", ",", "ignore_mask", "\n", "", "_", ",", "ignore_mask", "=", "K", ".", "control_flow_ops", ".", "while_loop", "(", "lambda", "b", ",", "*", "args", ":", "b", "<", "m", ",", "loop_body", ",", "[", "0", ",", "ignore_mask", "]", ")", "\n", "ignore_mask", "=", "ignore_mask", ".", "stack", "(", ")", "\n", "ignore_mask", "=", "K", ".", "expand_dims", "(", "ignore_mask", ",", "-", "1", ")", "\n", "\n", "# K.binary_crossentropy is helpful to avoid exp overflow.", "\n", "xy_loss", "=", "object_mask", "*", "box_loss_scale", "*", "K", ".", "binary_crossentropy", "(", "raw_true_xy", ",", "raw_pred", "[", "...", ",", "0", ":", "2", "]", ",", "from_logits", "=", "True", ")", "\n", "wh_loss", "=", "object_mask", "*", "box_loss_scale", "*", "0.5", "*", "K", ".", "square", "(", "raw_true_wh", "-", "raw_pred", "[", "...", ",", "2", ":", "4", "]", ")", "\n", "confidence_loss", "=", "object_mask", "*", "K", ".", "binary_crossentropy", "(", "object_mask", ",", "raw_pred", "[", "...", ",", "4", ":", "5", "]", ",", "from_logits", "=", "True", ")", "+", "(", "1", "-", "object_mask", ")", "*", "K", ".", "binary_crossentropy", "(", "object_mask", ",", "raw_pred", "[", "...", ",", "4", ":", "5", "]", ",", "from_logits", "=", "True", ")", "*", "ignore_mask", "\n", "class_loss", "=", "object_mask", "*", "K", ".", "binary_crossentropy", "(", "true_class_probs", ",", "raw_pred", "[", "...", ",", "5", ":", "]", ",", "from_logits", "=", "True", ")", "\n", "\n", "xy_loss", "=", "K", ".", "sum", "(", "xy_loss", ")", "/", "mf", "\n", "wh_loss", "=", "K", ".", "sum", "(", "wh_loss", ")", "/", "mf", "\n", "confidence_loss", "=", "K", ".", "sum", "(", "confidence_loss", ")", "/", "mf", "\n", "class_loss", "=", "K", ".", "sum", "(", "class_loss", ")", "/", "mf", "\n", "loss", "+=", "xy_loss", "+", "wh_loss", "+", "confidence_loss", "+", "class_loss", "\n", "if", "print_loss", ":", "\n", "            ", "loss", "=", "tf", ".", "Print", "(", "loss", ",", "[", "loss", ",", "xy_loss", ",", "wh_loss", ",", "confidence_loss", ",", "class_loss", ",", "K", ".", "sum", "(", "ignore_mask", ")", "]", ",", "message", "=", "'loss: '", ")", "\n", "", "", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.compose": [[9, 19], ["functools.reduce", "ValueError", "g", "f"], "function", ["None"], ["def", "compose", "(", "*", "funcs", ")", ":", "\n", "    ", "\"\"\"Compose arbitrarily many functions, evaluated left to right.\n\n    Reference: https://mathieularose.com/function-composition-in-python/\n    \"\"\"", "\n", "# return lambda x: reduce(lambda v, f: f(v), funcs, x)", "\n", "if", "funcs", ":", "\n", "        ", "return", "reduce", "(", "lambda", "f", ",", "g", ":", "lambda", "*", "a", ",", "**", "kw", ":", "g", "(", "f", "(", "*", "a", ",", "**", "kw", ")", ")", ",", "funcs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Composition of empty sequence not supported.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.letterbox_image": [[20, 32], ["min", "int", "int", "image.resize.resize", "PIL.Image.new", "Image.new.paste"], "function", ["None"], ["", "", "def", "letterbox_image", "(", "image", ",", "size", ")", ":", "\n", "    ", "'''resize image with unchanged aspect ratio using padding'''", "\n", "iw", ",", "ih", "=", "image", ".", "size", "\n", "w", ",", "h", "=", "size", "\n", "scale", "=", "min", "(", "w", "/", "iw", ",", "h", "/", "ih", ")", "\n", "nw", "=", "int", "(", "iw", "*", "scale", ")", "\n", "nh", "=", "int", "(", "ih", "*", "scale", ")", "\n", "\n", "image", "=", "image", ".", "resize", "(", "(", "nw", ",", "nh", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "new_image", "=", "Image", ".", "new", "(", "'RGB'", ",", "size", ",", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "new_image", ".", "paste", "(", "image", ",", "(", "(", "w", "-", "nw", ")", "//", "2", ",", "(", "h", "-", "nh", ")", "//", "2", ")", ")", "\n", "return", "new_image", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand": [[33, 35], ["numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand"], ["", "def", "rand", "(", "a", "=", "0", ",", "b", "=", "1", ")", ":", "\n", "    ", "return", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "b", "-", "a", ")", "+", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.get_random_data": [[36, 122], ["annotation_line.split", "PIL.Image.open", "numpy.array", "utils.rand", "image.resize.resize", "int", "int", "PIL.Image.new", "Image.new.paste", "utils.rand", "matplotlib.colors.rgb_to_hsv", "matplotlib.colors.hsv_to_rgb", "numpy.zeros", "min", "int", "int", "numpy.zeros", "utils.rand", "int", "int", "int", "int", "utils.rand", "utils.rand", "utils.rand", "image.resize.transpose", "utils.rand", "utils.rand", "len", "numpy.random.shuffle", "numpy.array", "image.resize.resize", "PIL.Image.new", "Image.new.paste", "len", "numpy.random.shuffle", "utils.rand", "utils.rand", "utils.rand", "utils.rand", "utils.rand", "numpy.array", "len", "list", "numpy.array", "len", "numpy.logical_and", "len", "map", "len", "np.array.split"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand", "home.repos.pwc.inspect_result.peabody124_posepipeline.yolo4.utils.rand"], ["", "def", "get_random_data", "(", "annotation_line", ",", "input_shape", ",", "random", "=", "True", ",", "max_boxes", "=", "100", ",", "jitter", "=", ".3", ",", "hue", "=", ".1", ",", "sat", "=", "1.5", ",", "val", "=", "1.5", ",", "proc_img", "=", "True", ")", ":", "\n", "    ", "'''random preprocessing for real-time data augmentation'''", "\n", "line", "=", "annotation_line", ".", "split", "(", ")", "\n", "image", "=", "Image", ".", "open", "(", "line", "[", "0", "]", ")", "\n", "iw", ",", "ih", "=", "image", ".", "size", "\n", "h", ",", "w", "=", "input_shape", "\n", "box", "=", "np", ".", "array", "(", "[", "np", ".", "array", "(", "list", "(", "map", "(", "int", ",", "box", ".", "split", "(", "','", ")", ")", ")", ")", "for", "box", "in", "line", "[", "1", ":", "]", "]", ")", "\n", "\n", "if", "not", "random", ":", "\n", "# resize image", "\n", "        ", "scale", "=", "min", "(", "w", "/", "iw", ",", "h", "/", "ih", ")", "\n", "nw", "=", "int", "(", "iw", "*", "scale", ")", "\n", "nh", "=", "int", "(", "ih", "*", "scale", ")", "\n", "dx", "=", "(", "w", "-", "nw", ")", "//", "2", "\n", "dy", "=", "(", "h", "-", "nh", ")", "//", "2", "\n", "image_data", "=", "0", "\n", "if", "proc_img", ":", "\n", "            ", "image", "=", "image", ".", "resize", "(", "(", "nw", ",", "nh", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "new_image", "=", "Image", ".", "new", "(", "'RGB'", ",", "(", "w", ",", "h", ")", ",", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "new_image", ".", "paste", "(", "image", ",", "(", "dx", ",", "dy", ")", ")", "\n", "image_data", "=", "np", ".", "array", "(", "new_image", ")", "/", "255.", "\n", "\n", "# correct boxes", "\n", "", "box_data", "=", "np", ".", "zeros", "(", "(", "max_boxes", ",", "5", ")", ")", "\n", "if", "len", "(", "box", ")", ">", "0", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "box", ")", "\n", "if", "len", "(", "box", ")", ">", "max_boxes", ":", "box", "=", "box", "[", ":", "max_boxes", "]", "\n", "box", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "box", "[", ":", ",", "[", "0", ",", "2", "]", "]", "*", "scale", "+", "dx", "\n", "box", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "box", "[", ":", ",", "[", "1", ",", "3", "]", "]", "*", "scale", "+", "dy", "\n", "box_data", "[", ":", "len", "(", "box", ")", "]", "=", "box", "\n", "\n", "", "return", "image_data", ",", "box_data", "\n", "\n", "# resize image", "\n", "", "new_ar", "=", "w", "/", "h", "*", "rand", "(", "1", "-", "jitter", ",", "1", "+", "jitter", ")", "/", "rand", "(", "1", "-", "jitter", ",", "1", "+", "jitter", ")", "\n", "scale", "=", "rand", "(", ".25", ",", "2", ")", "\n", "if", "new_ar", "<", "1", ":", "\n", "        ", "nh", "=", "int", "(", "scale", "*", "h", ")", "\n", "nw", "=", "int", "(", "nh", "*", "new_ar", ")", "\n", "", "else", ":", "\n", "        ", "nw", "=", "int", "(", "scale", "*", "w", ")", "\n", "nh", "=", "int", "(", "nw", "/", "new_ar", ")", "\n", "", "image", "=", "image", ".", "resize", "(", "(", "nw", ",", "nh", ")", ",", "Image", ".", "BICUBIC", ")", "\n", "\n", "# place image", "\n", "dx", "=", "int", "(", "rand", "(", "0", ",", "w", "-", "nw", ")", ")", "\n", "dy", "=", "int", "(", "rand", "(", "0", ",", "h", "-", "nh", ")", ")", "\n", "new_image", "=", "Image", ".", "new", "(", "'RGB'", ",", "(", "w", ",", "h", ")", ",", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "new_image", ".", "paste", "(", "image", ",", "(", "dx", ",", "dy", ")", ")", "\n", "image", "=", "new_image", "\n", "\n", "# flip image or not", "\n", "flip", "=", "rand", "(", ")", "<", ".5", "\n", "if", "flip", ":", "image", "=", "image", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n", "# distort image", "\n", "hue", "=", "rand", "(", "-", "hue", ",", "hue", ")", "\n", "sat", "=", "rand", "(", "1", ",", "sat", ")", "if", "rand", "(", ")", "<", ".5", "else", "1", "/", "rand", "(", "1", ",", "sat", ")", "\n", "val", "=", "rand", "(", "1", ",", "val", ")", "if", "rand", "(", ")", "<", ".5", "else", "1", "/", "rand", "(", "1", ",", "val", ")", "\n", "x", "=", "rgb_to_hsv", "(", "np", ".", "array", "(", "image", ")", "/", "255.", ")", "\n", "x", "[", "...", ",", "0", "]", "+=", "hue", "\n", "x", "[", "...", ",", "0", "]", "[", "x", "[", "...", ",", "0", "]", ">", "1", "]", "-=", "1", "\n", "x", "[", "...", ",", "0", "]", "[", "x", "[", "...", ",", "0", "]", "<", "0", "]", "+=", "1", "\n", "x", "[", "...", ",", "1", "]", "*=", "sat", "\n", "x", "[", "...", ",", "2", "]", "*=", "val", "\n", "x", "[", "x", ">", "1", "]", "=", "1", "\n", "x", "[", "x", "<", "0", "]", "=", "0", "\n", "image_data", "=", "hsv_to_rgb", "(", "x", ")", "# numpy array, 0 to 1", "\n", "\n", "# correct boxes", "\n", "box_data", "=", "np", ".", "zeros", "(", "(", "max_boxes", ",", "5", ")", ")", "\n", "if", "len", "(", "box", ")", ">", "0", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "box", ")", "\n", "box", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "box", "[", ":", ",", "[", "0", ",", "2", "]", "]", "*", "nw", "/", "iw", "+", "dx", "\n", "box", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "box", "[", ":", ",", "[", "1", ",", "3", "]", "]", "*", "nh", "/", "ih", "+", "dy", "\n", "if", "flip", ":", "box", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "w", "-", "box", "[", ":", ",", "[", "2", ",", "0", "]", "]", "\n", "box", "[", ":", ",", "0", ":", "2", "]", "[", "box", "[", ":", ",", "0", ":", "2", "]", "<", "0", "]", "=", "0", "\n", "box", "[", ":", ",", "2", "]", "[", "box", "[", ":", ",", "2", "]", ">", "w", "]", "=", "w", "\n", "box", "[", ":", ",", "3", "]", "[", "box", "[", ":", ",", "3", "]", ">", "h", "]", "=", "h", "\n", "box_w", "=", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", "\n", "box_h", "=", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", "\n", "box", "=", "box", "[", "np", ".", "logical_and", "(", "box_w", ">", "1", ",", "box_h", ">", "1", ")", "]", "# discard invalid box", "\n", "if", "len", "(", "box", ")", ">", "max_boxes", ":", "box", "=", "box", "[", ":", "max_boxes", "]", "\n", "box_data", "[", ":", "len", "(", "box", ")", "]", "=", "box", "\n", "\n", "", "return", "image_data", ",", "box_data", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._batch_norm_fn": [[7, 11], ["tensorflow.batch_norm", "tensorflow.get_variable_scope"], "function", ["None"], ["def", "_batch_norm_fn", "(", "x", ",", "scope", "=", "None", ")", ":", "\n", "    ", "if", "scope", "is", "None", ":", "\n", "        ", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "+", "\"/bn\"", "\n", "", "return", "slim", ".", "batch_norm", "(", "x", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.create_link": [[13, 41], ["tensorflow.truncated_normal_initializer", "freeze_model.residual_block.network_builder", "freeze_model._batch_norm_fn", "nonlinearity", "pre_block_network.get_shape().as_list", "network_builder.get_shape().as_list", "tensorflow.conv2d", "tensorflow.summary.histogram", "pre_block_network.get_shape", "network_builder.get_shape"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._batch_norm_fn"], ["", "def", "create_link", "(", "\n", "incoming", ",", "network_builder", ",", "scope", ",", "nonlinearity", "=", "tf", ".", "nn", ".", "elu", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "1e-3", ")", ",", "\n", "regularizer", "=", "None", ",", "is_first", "=", "False", ",", "summarize_activations", "=", "True", ")", ":", "\n", "    ", "if", "is_first", ":", "\n", "        ", "network", "=", "incoming", "\n", "", "else", ":", "\n", "        ", "network", "=", "_batch_norm_fn", "(", "incoming", ",", "scope", "=", "scope", "+", "\"/bn\"", ")", "\n", "network", "=", "nonlinearity", "(", "network", ")", "\n", "if", "summarize_activations", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "scope", "+", "\"/activations\"", ",", "network", ")", "\n", "\n", "", "", "pre_block_network", "=", "network", "\n", "post_block_network", "=", "network_builder", "(", "pre_block_network", ",", "scope", ")", "\n", "\n", "incoming_dim", "=", "pre_block_network", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "outgoing_dim", "=", "post_block_network", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "if", "incoming_dim", "!=", "outgoing_dim", ":", "\n", "        ", "assert", "outgoing_dim", "==", "2", "*", "incoming_dim", ",", "\"%d != %d\"", "%", "(", "outgoing_dim", ",", "2", "*", "incoming", ")", "\n", "projection", "=", "slim", ".", "conv2d", "(", "\n", "incoming", ",", "outgoing_dim", ",", "1", ",", "2", ",", "padding", "=", "\"SAME\"", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "scope", "+", "\"/projection\"", ",", "weights_initializer", "=", "weights_initializer", ",", "\n", "biases_initializer", "=", "None", ",", "weights_regularizer", "=", "regularizer", ")", "\n", "network", "=", "projection", "+", "post_block_network", "\n", "", "else", ":", "\n", "        ", "network", "=", "incoming", "+", "post_block_network", "\n", "", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.create_inner_block": [[43, 70], ["tensorflow.truncated_normal_initializer", "tensorflow.zeros_initializer", "tensorflow.conv2d", "tensorflow.dropout", "tensorflow.conv2d", "slim.conv2d.get_shape().as_list", "tensorflow.summary.histogram", "slim.conv2d.get_shape"], "function", ["None"], ["", "def", "create_inner_block", "(", "\n", "incoming", ",", "scope", ",", "nonlinearity", "=", "tf", ".", "nn", ".", "elu", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "1e-3", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "regularizer", "=", "None", ",", "\n", "increase_dim", "=", "False", ",", "summarize_activations", "=", "True", ")", ":", "\n", "    ", "n", "=", "incoming", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "stride", "=", "1", "\n", "if", "increase_dim", ":", "\n", "        ", "n", "*=", "2", "\n", "stride", "=", "2", "\n", "\n", "", "incoming", "=", "slim", ".", "conv2d", "(", "\n", "incoming", ",", "n", ",", "[", "3", ",", "3", "]", ",", "stride", ",", "activation_fn", "=", "nonlinearity", ",", "padding", "=", "\"SAME\"", ",", "\n", "normalizer_fn", "=", "_batch_norm_fn", ",", "weights_initializer", "=", "weights_initializer", ",", "\n", "biases_initializer", "=", "bias_initializer", ",", "weights_regularizer", "=", "regularizer", ",", "\n", "scope", "=", "scope", "+", "\"/1\"", ")", "\n", "if", "summarize_activations", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "incoming", ".", "name", "+", "\"/activations\"", ",", "incoming", ")", "\n", "\n", "", "incoming", "=", "slim", ".", "dropout", "(", "incoming", ",", "keep_prob", "=", "0.6", ")", "\n", "\n", "incoming", "=", "slim", ".", "conv2d", "(", "\n", "incoming", ",", "n", ",", "[", "3", ",", "3", "]", ",", "1", ",", "activation_fn", "=", "None", ",", "padding", "=", "\"SAME\"", ",", "\n", "normalizer_fn", "=", "None", ",", "weights_initializer", "=", "weights_initializer", ",", "\n", "biases_initializer", "=", "bias_initializer", ",", "weights_regularizer", "=", "regularizer", ",", "\n", "scope", "=", "scope", "+", "\"/2\"", ")", "\n", "return", "incoming", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block": [[72, 86], ["tensorflow.truncated_normal_initializer", "tensorflow.zeros_initializer", "freeze_model.create_link", "freeze_model.create_inner_block"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.create_link", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.create_inner_block"], ["", "def", "residual_block", "(", "incoming", ",", "scope", ",", "nonlinearity", "=", "tf", ".", "nn", ".", "elu", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "1e3", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "regularizer", "=", "None", ",", "\n", "increase_dim", "=", "False", ",", "is_first", "=", "False", ",", "\n", "summarize_activations", "=", "True", ")", ":", "\n", "\n", "    ", "def", "network_builder", "(", "x", ",", "s", ")", ":", "\n", "        ", "return", "create_inner_block", "(", "\n", "x", ",", "s", ",", "nonlinearity", ",", "weights_initializer", ",", "bias_initializer", ",", "\n", "regularizer", ",", "increase_dim", ",", "summarize_activations", ")", "\n", "\n", "", "return", "create_link", "(", "\n", "incoming", ",", "network_builder", ",", "scope", ",", "nonlinearity", ",", "weights_initializer", ",", "\n", "regularizer", ",", "is_first", ",", "summarize_activations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._create_network": [[88, 158], ["tensorflow.truncated_normal_initializer", "tensorflow.zeros_initializer", "tensorflow.l2_regularizer", "tensorflow.truncated_normal_initializer", "tensorflow.zeros_initializer", "tensorflow.l2_regularizer", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.max_pool2d", "freeze_model.residual_block", "freeze_model.residual_block", "freeze_model.residual_block", "freeze_model.residual_block", "freeze_model.residual_block", "freeze_model.residual_block", "tensorflow.flatten", "tensorflow.dropout", "tensorflow.fully_connected", "tensorflow.batch_norm", "tensorflow.sqrt", "tensorflow.batch_norm", "slim.fully_connected.get_shape().as_list", "tensorflow.constant", "tensorflow.reduce_sum", "slim.fully_connected.get_shape", "tensorflow.square", "tensorflow.get_variable_scope"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.residual_block"], ["", "def", "_create_network", "(", "incoming", ",", "reuse", "=", "None", ",", "weight_decay", "=", "1e-8", ")", ":", "\n", "    ", "nonlinearity", "=", "tf", ".", "nn", ".", "elu", "\n", "conv_weight_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "1e-3", ")", "\n", "conv_bias_init", "=", "tf", ".", "zeros_initializer", "(", ")", "\n", "conv_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "fc_weight_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "1e-3", ")", "\n", "fc_bias_init", "=", "tf", ".", "zeros_initializer", "(", ")", "\n", "fc_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "\n", "def", "batch_norm_fn", "(", "x", ")", ":", "\n", "        ", "return", "slim", ".", "batch_norm", "(", "x", ",", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "+", "\"/bn\"", ")", "\n", "\n", "", "network", "=", "incoming", "\n", "network", "=", "slim", ".", "conv2d", "(", "\n", "network", ",", "32", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "activation_fn", "=", "nonlinearity", ",", "\n", "padding", "=", "\"SAME\"", ",", "normalizer_fn", "=", "batch_norm_fn", ",", "scope", "=", "\"conv1_1\"", ",", "\n", "weights_initializer", "=", "conv_weight_init", ",", "biases_initializer", "=", "conv_bias_init", ",", "\n", "weights_regularizer", "=", "conv_regularizer", ")", "\n", "network", "=", "slim", ".", "conv2d", "(", "\n", "network", ",", "32", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "activation_fn", "=", "nonlinearity", ",", "\n", "padding", "=", "\"SAME\"", ",", "normalizer_fn", "=", "batch_norm_fn", ",", "scope", "=", "\"conv1_2\"", ",", "\n", "weights_initializer", "=", "conv_weight_init", ",", "biases_initializer", "=", "conv_bias_init", ",", "\n", "weights_regularizer", "=", "conv_regularizer", ")", "\n", "\n", "# NOTE(nwojke): This is missing a padding=\"SAME\" to match the CNN", "\n", "# architecture in Table 1 of the paper. Information on how this affects", "\n", "# performance on MOT 16 training sequences can be found in", "\n", "# issue 10 https://github.com/nwojke/deep_sort/issues/10", "\n", "network", "=", "slim", ".", "max_pool2d", "(", "network", ",", "[", "3", ",", "3", "]", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "\"pool1\"", ")", "\n", "\n", "network", "=", "residual_block", "(", "\n", "network", ",", "\"conv2_1\"", ",", "nonlinearity", ",", "conv_weight_init", ",", "conv_bias_init", ",", "\n", "conv_regularizer", ",", "increase_dim", "=", "False", ",", "is_first", "=", "True", ")", "\n", "network", "=", "residual_block", "(", "\n", "network", ",", "\"conv2_3\"", ",", "nonlinearity", ",", "conv_weight_init", ",", "conv_bias_init", ",", "\n", "conv_regularizer", ",", "increase_dim", "=", "False", ")", "\n", "\n", "network", "=", "residual_block", "(", "\n", "network", ",", "\"conv3_1\"", ",", "nonlinearity", ",", "conv_weight_init", ",", "conv_bias_init", ",", "\n", "conv_regularizer", ",", "increase_dim", "=", "True", ")", "\n", "network", "=", "residual_block", "(", "\n", "network", ",", "\"conv3_3\"", ",", "nonlinearity", ",", "conv_weight_init", ",", "conv_bias_init", ",", "\n", "conv_regularizer", ",", "increase_dim", "=", "False", ")", "\n", "\n", "network", "=", "residual_block", "(", "\n", "network", ",", "\"conv4_1\"", ",", "nonlinearity", ",", "conv_weight_init", ",", "conv_bias_init", ",", "\n", "conv_regularizer", ",", "increase_dim", "=", "True", ")", "\n", "network", "=", "residual_block", "(", "\n", "network", ",", "\"conv4_3\"", ",", "nonlinearity", ",", "conv_weight_init", ",", "conv_bias_init", ",", "\n", "conv_regularizer", ",", "increase_dim", "=", "False", ")", "\n", "\n", "feature_dim", "=", "network", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "network", "=", "slim", ".", "flatten", "(", "network", ")", "\n", "\n", "network", "=", "slim", ".", "dropout", "(", "network", ",", "keep_prob", "=", "0.6", ")", "\n", "network", "=", "slim", ".", "fully_connected", "(", "\n", "network", ",", "feature_dim", ",", "activation_fn", "=", "nonlinearity", ",", "\n", "normalizer_fn", "=", "batch_norm_fn", ",", "weights_regularizer", "=", "fc_regularizer", ",", "\n", "scope", "=", "\"fc1\"", ",", "weights_initializer", "=", "fc_weight_init", ",", "\n", "biases_initializer", "=", "fc_bias_init", ")", "\n", "\n", "features", "=", "network", "\n", "\n", "# Features in rows, normalize axis 1.", "\n", "features", "=", "slim", ".", "batch_norm", "(", "features", ",", "scope", "=", "\"ball\"", ",", "reuse", "=", "reuse", ")", "\n", "feature_norm", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "constant", "(", "1e-8", ",", "tf", ".", "float32", ")", "+", "\n", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "features", ")", ",", "[", "1", "]", ",", "keepdims", "=", "True", ")", ")", "\n", "features", "=", "features", "/", "feature_norm", "\n", "return", "features", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._network_factory": [[160, 173], ["tensorflow.arg_scope", "tensorflow.arg_scope", "freeze_model._create_network"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._create_network"], ["", "def", "_network_factory", "(", "weight_decay", "=", "1e-8", ")", ":", "\n", "\n", "    ", "def", "factory_fn", "(", "image", ",", "reuse", ")", ":", "\n", "            ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "False", ")", ":", "\n", "                ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", ",", "\n", "slim", ".", "batch_norm", ",", "slim", ".", "layer_norm", "]", ",", "\n", "reuse", "=", "reuse", ")", ":", "\n", "                    ", "features", ",", "logits", "=", "_create_network", "(", "\n", "image", ",", "reuse", "=", "reuse", ",", "weight_decay", "=", "weight_decay", ")", "\n", "return", "features", ",", "logits", "\n", "\n", "", "", "", "return", "factory_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._preprocess": [[175, 178], ["None"], "function", ["None"], ["", "def", "_preprocess", "(", "image", ")", ":", "\n", "    ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "# BGR to RGB", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.parse_args": [[180, 192], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\"Parse command line arguments.\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Freeze old model\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--checkpoint_in\"", ",", "\n", "default", "=", "\"resources/networks/mars-small128.ckpt-68577\"", ",", "\n", "help", "=", "\"Path to checkpoint file\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--graphdef_out\"", ",", "\n", "default", "=", "\"resources/networks/mars-small128.pb\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model.main": [[194, 216], ["freeze_model.parse_args", "tensorflow.Session", "tensorflow.placeholder", "tensorflow.map_fn", "freeze_model._network_factory", "_network_factory.", "tensorflow.identity", "tensorflow.train.Saver", "tf.train.Saver.restore", "tensorflow.graph_util.convert_variables_to_constants", "tensorflow.cast", "tensorflow.get_variables_to_restore", "tensorflow.get_default_graph().as_graph_def", "tensorflow.gfile.GFile", "file_handle.write", "tensorflow.Graph", "freeze_model._preprocess", "tf.graph_util.convert_variables_to_constants.SerializeToString", "tensorflow.get_default_graph", "tf.identity.name.split"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.parse_args", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._network_factory", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.freeze_model._preprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "as", "session", ":", "\n", "        ", "input_var", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "uint8", ",", "(", "None", ",", "128", ",", "64", ",", "3", ")", ",", "name", "=", "\"images\"", ")", "\n", "image_var", "=", "tf", ".", "map_fn", "(", "\n", "lambda", "x", ":", "_preprocess", "(", "x", ")", ",", "tf", ".", "cast", "(", "input_var", ",", "tf", ".", "float32", ")", ",", "\n", "back_prop", "=", "False", ")", "\n", "\n", "factory_fn", "=", "_network_factory", "(", ")", "\n", "features", ",", "_", "=", "factory_fn", "(", "image_var", ",", "reuse", "=", "None", ")", "\n", "features", "=", "tf", ".", "identity", "(", "features", ",", "name", "=", "\"features\"", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "slim", ".", "get_variables_to_restore", "(", ")", ")", "\n", "saver", ".", "restore", "(", "session", ",", "args", ".", "checkpoint_in", ")", "\n", "\n", "output_graph_def", "=", "tf", ".", "graph_util", ".", "convert_variables_to_constants", "(", "\n", "session", ",", "tf", ".", "get_default_graph", "(", ")", ".", "as_graph_def", "(", ")", ",", "\n", "[", "features", ".", "name", ".", "split", "(", "\":\"", ")", "[", "0", "]", "]", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "args", ".", "graphdef_out", ",", "\"wb\"", ")", "as", "file_handle", ":", "\n", "            ", "file_handle", ".", "write", "(", "output_graph_def", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.ImageEncoder.__init__": [[74, 90], ["tensorflow.Session", "tensorflow.Session", "tensorflow.import_graph_def", "tensorflow.import_graph_def", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.gfile.GFile", "tensorflow.gfile.GFile", "tensorflow.GraphDef", "tensorflow.GraphDef", "tensorflow.GraphDef.ParseFromString", "len", "len", "generate_detections.ImageEncoder.output_var.get_shape().as_list", "generate_detections.ImageEncoder.input_var.get_shape().as_list", "file_handle.read", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "generate_detections.ImageEncoder.output_var.get_shape", "generate_detections.ImageEncoder.input_var.get_shape", "generate_detections.ImageEncoder.output_var.get_shape", "generate_detections.ImageEncoder.input_var.get_shape"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "checkpoint_filename", ",", "input_name", "=", "\"images\"", ",", "\n", "output_name", "=", "\"features\"", ")", ":", "\n", "        ", "self", ".", "session", "=", "tf", ".", "Session", "(", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "checkpoint_filename", ",", "\"rb\"", ")", "as", "file_handle", ":", "\n", "            ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "file_handle", ".", "read", "(", ")", ")", "\n", "", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "\"net\"", ")", "\n", "self", ".", "input_var", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\n", "\"net/%s:0\"", "%", "input_name", ")", "\n", "self", ".", "output_var", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\n", "\"net/%s:0\"", "%", "output_name", ")", "\n", "\n", "assert", "len", "(", "self", ".", "output_var", ".", "get_shape", "(", ")", ")", "==", "2", "\n", "assert", "len", "(", "self", ".", "input_var", ".", "get_shape", "(", ")", ")", "==", "4", "\n", "self", ".", "feature_dim", "=", "self", ".", "output_var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "self", ".", "image_shape", "=", "self", ".", "input_var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.ImageEncoder.__call__": [[91, 97], ["numpy.zeros", "generate_detections._run_in_batches", "len", "generate_detections.ImageEncoder.session.run"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections._run_in_batches"], ["", "def", "__call__", "(", "self", ",", "data_x", ",", "batch_size", "=", "32", ")", ":", "\n", "        ", "out", "=", "np", ".", "zeros", "(", "(", "len", "(", "data_x", ")", ",", "self", ".", "feature_dim", ")", ",", "np", ".", "float32", ")", "\n", "_run_in_batches", "(", "\n", "lambda", "x", ":", "self", ".", "session", ".", "run", "(", "self", ".", "output_var", ",", "feed_dict", "=", "x", ")", ",", "\n", "{", "self", ".", "input_var", ":", "data_x", "}", ",", "out", ",", "batch_size", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections._run_in_batches": [[11, 23], ["len", "int", "range", "f", "len", "f", "data_dict.items", "data_dict.items"], "function", ["None"], ["def", "_run_in_batches", "(", "f", ",", "data_dict", ",", "out", ",", "batch_size", ")", ":", "\n", "    ", "data_len", "=", "len", "(", "out", ")", "\n", "num_batches", "=", "int", "(", "data_len", "/", "batch_size", ")", "\n", "\n", "s", ",", "e", "=", "0", ",", "0", "\n", "for", "i", "in", "range", "(", "num_batches", ")", ":", "\n", "        ", "s", ",", "e", "=", "i", "*", "batch_size", ",", "(", "i", "+", "1", ")", "*", "batch_size", "\n", "batch_data_dict", "=", "{", "k", ":", "v", "[", "s", ":", "e", "]", "for", "k", ",", "v", "in", "data_dict", ".", "items", "(", ")", "}", "\n", "out", "[", "s", ":", "e", "]", "=", "f", "(", "batch_data_dict", ")", "\n", "", "if", "e", "<", "len", "(", "out", ")", ":", "\n", "        ", "batch_data_dict", "=", "{", "k", ":", "v", "[", "e", ":", "]", "for", "k", ",", "v", "in", "data_dict", ".", "items", "(", ")", "}", "\n", "out", "[", "e", ":", "]", "=", "f", "(", "batch_data_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.extract_image_patch": [[25, 70], ["numpy.array", "bbox.astype.astype", "numpy.maximum", "numpy.minimum", "numpy.any", "cv2.resize", "tuple", "float", "numpy.asarray"], "function", ["None"], ["", "", "def", "extract_image_patch", "(", "image", ",", "bbox", ",", "patch_shape", ")", ":", "\n", "    ", "\"\"\"Extract image patch from bounding box.\n\n    Parameters\n    ----------\n    image : ndarray\n        The full image.\n    bbox : array_like\n        The bounding box in format (x, y, width, height).\n    patch_shape : Optional[array_like]\n        This parameter can be used to enforce a desired patch shape\n        (height, width). First, the `bbox` is adapted to the aspect ratio\n        of the patch shape, then it is clipped at the image boundaries.\n        If None, the shape is computed from :arg:`bbox`.\n\n    Returns\n    -------\n    ndarray | NoneType\n        An image patch showing the :arg:`bbox`, optionally reshaped to\n        :arg:`patch_shape`.\n        Returns None if the bounding box is empty or fully outside of the image\n        boundaries.\n\n    \"\"\"", "\n", "bbox", "=", "np", ".", "array", "(", "bbox", ")", "\n", "if", "patch_shape", "is", "not", "None", ":", "\n", "# correct aspect ratio to patch shape", "\n", "        ", "target_aspect", "=", "float", "(", "patch_shape", "[", "1", "]", ")", "/", "patch_shape", "[", "0", "]", "\n", "new_width", "=", "target_aspect", "*", "bbox", "[", "3", "]", "\n", "bbox", "[", "0", "]", "-=", "(", "new_width", "-", "bbox", "[", "2", "]", ")", "/", "2", "\n", "bbox", "[", "2", "]", "=", "new_width", "\n", "\n", "# convert to top left, bottom right", "\n", "", "bbox", "[", "2", ":", "]", "+=", "bbox", "[", ":", "2", "]", "\n", "bbox", "=", "bbox", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# clip at image boundaries", "\n", "bbox", "[", ":", "2", "]", "=", "np", ".", "maximum", "(", "0", ",", "bbox", "[", ":", "2", "]", ")", "\n", "bbox", "[", "2", ":", "]", "=", "np", ".", "minimum", "(", "np", ".", "asarray", "(", "image", ".", "shape", "[", ":", "2", "]", "[", ":", ":", "-", "1", "]", ")", "-", "1", ",", "bbox", "[", "2", ":", "]", ")", "\n", "if", "np", ".", "any", "(", "bbox", "[", ":", "2", "]", ">=", "bbox", "[", "2", ":", "]", ")", ":", "\n", "        ", "return", "None", "\n", "", "sx", ",", "sy", ",", "ex", ",", "ey", "=", "bbox", "\n", "image", "=", "image", "[", "sy", ":", "ey", ",", "sx", ":", "ex", "]", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "tuple", "(", "patch_shape", "[", ":", ":", "-", "1", "]", ")", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.create_box_encoder": [[99, 117], ["generate_detections.ImageEncoder", "numpy.asarray", "ImageEncoder.", "generate_detections.extract_image_patch", "np.asarray.append", "print", "numpy.random.uniform().astype", "str", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.extract_image_patch"], ["", "", "def", "create_box_encoder", "(", "model_filename", ",", "input_name", "=", "\"images\"", ",", "\n", "output_name", "=", "\"features\"", ",", "batch_size", "=", "32", ")", ":", "\n", "    ", "image_encoder", "=", "ImageEncoder", "(", "model_filename", ",", "input_name", ",", "output_name", ")", "\n", "image_shape", "=", "image_encoder", ".", "image_shape", "\n", "\n", "def", "encoder", "(", "image", ",", "boxes", ")", ":", "\n", "        ", "image_patches", "=", "[", "]", "\n", "for", "box", "in", "boxes", ":", "\n", "            ", "patch", "=", "extract_image_patch", "(", "image", ",", "box", ",", "image_shape", "[", ":", "2", "]", ")", "\n", "if", "patch", "is", "None", ":", "\n", "                ", "print", "(", "\"WARNING: Failed to extract image patch: %s.\"", "%", "str", "(", "box", ")", ")", "\n", "patch", "=", "np", ".", "random", ".", "uniform", "(", "\n", "0.", ",", "255.", ",", "image_shape", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "image_patches", ".", "append", "(", "patch", ")", "\n", "", "image_patches", "=", "np", ".", "asarray", "(", "image_patches", ")", "\n", "return", "image_encoder", "(", "image_patches", ",", "batch_size", ")", "\n", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.generate_detections": [[119, 183], ["os.listdir", "os.makedirs", "print", "os.path.join", "os.path.join", "os.path.join", "numpy.loadtxt", "detections_in[].astype", "detections_in[].astype.astype().min", "detections_in[].astype.astype().max", "range", "os.path.join", "numpy.save", "int", "os.path.join", "print", "cv2.imread", "generate_detections.create_box_encoder.encoder", "numpy.asarray", "os.path.isdir", "ValueError", "os.listdir", "detections_in[].astype.astype", "detections_in[].astype.astype", "print", "rows[].copy", "os.path.splitext", "zip"], "function", ["None"], ["", "def", "generate_detections", "(", "encoder", ",", "mot_dir", ",", "output_dir", ",", "detection_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Generate detections with features.\n\n    Parameters\n    ----------\n    encoder : Callable[image, ndarray] -> ndarray\n        The encoder function takes as input a BGR color image and a matrix of\n        bounding boxes in format `(x, y, w, h)` and returns a matrix of\n        corresponding feature vectors.\n    mot_dir : str\n        Path to the MOTChallenge directory (can be either train or test).\n    output_dir\n        Path to the output directory. Will be created if it does not exist.\n    detection_dir\n        Path to custom detections. The directory structure should be the default\n        MOTChallenge structure: `[sequence]/det/det.txt`. If None, uses the\n        standard MOTChallenge detections.\n\n    \"\"\"", "\n", "if", "detection_dir", "is", "None", ":", "\n", "        ", "detection_dir", "=", "mot_dir", "\n", "", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "except", "OSError", "as", "exception", ":", "\n", "        ", "if", "exception", ".", "errno", "==", "errno", ".", "EEXIST", "and", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Failed to created output directory '%s'\"", "%", "output_dir", ")", "\n", "\n", "", "", "for", "sequence", "in", "os", ".", "listdir", "(", "mot_dir", ")", ":", "\n", "        ", "print", "(", "\"Processing %s\"", "%", "sequence", ")", "\n", "sequence_dir", "=", "os", ".", "path", ".", "join", "(", "mot_dir", ",", "sequence", ")", "\n", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "sequence_dir", ",", "\"img1\"", ")", "\n", "image_filenames", "=", "{", "\n", "int", "(", "os", ".", "path", ".", "splitext", "(", "f", ")", "[", "0", "]", ")", ":", "os", ".", "path", ".", "join", "(", "image_dir", ",", "f", ")", "\n", "for", "f", "in", "os", ".", "listdir", "(", "image_dir", ")", "}", "\n", "\n", "detection_file", "=", "os", ".", "path", ".", "join", "(", "\n", "detection_dir", ",", "sequence", ",", "\"det/det.txt\"", ")", "\n", "detections_in", "=", "np", ".", "loadtxt", "(", "detection_file", ",", "delimiter", "=", "','", ")", "\n", "detections_out", "=", "[", "]", "\n", "\n", "frame_indices", "=", "detections_in", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", "\n", "min_frame_idx", "=", "frame_indices", ".", "astype", "(", "np", ".", "int", ")", ".", "min", "(", ")", "\n", "max_frame_idx", "=", "frame_indices", ".", "astype", "(", "np", ".", "int", ")", ".", "max", "(", ")", "\n", "for", "frame_idx", "in", "range", "(", "min_frame_idx", ",", "max_frame_idx", "+", "1", ")", ":", "\n", "            ", "print", "(", "\"Frame %05d/%05d\"", "%", "(", "frame_idx", ",", "max_frame_idx", ")", ")", "\n", "mask", "=", "frame_indices", "==", "frame_idx", "\n", "rows", "=", "detections_in", "[", "mask", "]", "\n", "\n", "if", "frame_idx", "not", "in", "image_filenames", ":", "\n", "                ", "print", "(", "\"WARNING could not find image for frame %d\"", "%", "frame_idx", ")", "\n", "continue", "\n", "", "bgr_image", "=", "cv2", ".", "imread", "(", "\n", "image_filenames", "[", "frame_idx", "]", ",", "cv2", ".", "IMREAD_COLOR", ")", "\n", "features", "=", "encoder", "(", "bgr_image", ",", "rows", "[", ":", ",", "2", ":", "6", "]", ".", "copy", "(", ")", ")", "\n", "detections_out", "+=", "[", "np", ".", "r_", "[", "(", "row", ",", "feature", ")", "]", "for", "row", ",", "feature", "\n", "in", "zip", "(", "rows", ",", "features", ")", "]", "\n", "\n", "", "output_filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"%s.npy\"", "%", "sequence", ")", "\n", "np", ".", "save", "(", "\n", "output_filename", ",", "np", ".", "asarray", "(", "detections_out", ")", ",", "allow_pickle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.parse_args": [[185, 204], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\"Parse command line arguments.\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Re-ID feature extractor\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "\n", "default", "=", "\"resources/networks/mars-small128.pb\"", ",", "\n", "help", "=", "\"Path to freezed inference graph protobuf.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mot_dir\"", ",", "help", "=", "\"Path to MOTChallenge directory (train or test)\"", ",", "\n", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--detection_dir\"", ",", "help", "=", "\"Path to custom detections. Defaults to \"", "\n", "\"standard MOT detections Directory structure should be the default \"", "\n", "\"MOTChallenge structure: [sequence]/det/det.txt\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "help", "=", "\"Output directory. Will be created if it does not\"", "\n", "\" exist.\"", ",", "default", "=", "\"detections\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.main": [[206, 211], ["generate_detections.parse_args", "generate_detections.create_box_encoder", "generate_detections.generate_detections"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.parse_args", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.create_box_encoder", "home.repos.pwc.inspect_result.peabody124_posepipeline.tools.generate_detections.generate_detections"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "encoder", "=", "create_box_encoder", "(", "args", ".", "model", ",", "batch_size", "=", "32", ")", "\n", "generate_detections", "(", "encoder", ",", "args", ".", "mot_dir", ",", "args", ".", "output_dir", ",", "\n", "args", ".", "detection_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching.NearestNeighborDistanceMetric.__init__": [[123, 136], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "metric", ",", "matching_threshold", ",", "budget", "=", "None", ")", ":", "\n", "\n", "\n", "        ", "if", "metric", "==", "\"euclidean\"", ":", "\n", "            ", "self", ".", "_metric", "=", "_nn_euclidean_distance", "\n", "", "elif", "metric", "==", "\"cosine\"", ":", "\n", "            ", "self", ".", "_metric", "=", "_nn_cosine_distance", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Invalid metric; must be either 'euclidean' or 'cosine'\"", ")", "\n", "", "self", ".", "matching_threshold", "=", "matching_threshold", "\n", "self", ".", "budget", "=", "budget", "\n", "self", ".", "samples", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching.NearestNeighborDistanceMetric.partial_fit": [[137, 155], ["zip", "nn_matching.NearestNeighborDistanceMetric.samples.setdefault().append", "nn_matching.NearestNeighborDistanceMetric.samples.setdefault"], "methods", ["None"], ["", "def", "partial_fit", "(", "self", ",", "features", ",", "targets", ",", "active_targets", ")", ":", "\n", "        ", "\"\"\"Update the distance metric with new data.\n\n        Parameters\n        ----------\n        features : ndarray\n            An NxM matrix of N features of dimensionality M.\n        targets : ndarray\n            An integer array of associated target identities.\n        active_targets : List[int]\n            A list of targets that are currently present in the scene.\n\n        \"\"\"", "\n", "for", "feature", ",", "target", "in", "zip", "(", "features", ",", "targets", ")", ":", "\n", "            ", "self", ".", "samples", ".", "setdefault", "(", "target", ",", "[", "]", ")", ".", "append", "(", "feature", ")", "\n", "if", "self", ".", "budget", "is", "not", "None", ":", "\n", "                ", "self", ".", "samples", "[", "target", "]", "=", "self", ".", "samples", "[", "target", "]", "[", "-", "self", ".", "budget", ":", "]", "\n", "", "", "self", ".", "samples", "=", "{", "k", ":", "self", ".", "samples", "[", "k", "]", "for", "k", "in", "active_targets", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching.NearestNeighborDistanceMetric.distance": [[156, 178], ["numpy.zeros", "enumerate", "nn_matching.NearestNeighborDistanceMetric._metric", "len", "len"], "methods", ["None"], ["", "def", "distance", "(", "self", ",", "features", ",", "targets", ")", ":", "\n", "        ", "\"\"\"Compute distance between features and targets.\n\n        Parameters\n        ----------\n        features : ndarray\n            An NxM matrix of N features of dimensionality M.\n        targets : List[int]\n            A list of targets to match the given `features` against.\n\n        Returns\n        -------\n        ndarray\n            Returns a cost matrix of shape len(targets), len(features), where\n            element (i, j) contains the closest squared distance between\n            `targets[i]` and `features[j]`.\n\n        \"\"\"", "\n", "cost_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "targets", ")", ",", "len", "(", "features", ")", ")", ")", "\n", "for", "i", ",", "target", "in", "enumerate", "(", "targets", ")", ":", "\n", "            ", "cost_matrix", "[", "i", ",", ":", "]", "=", "self", ".", "_metric", "(", "self", ".", "samples", "[", "target", "]", ",", "features", ")", "\n", "", "return", "cost_matrix", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching._pdist": [[5, 29], ["numpy.clip", "numpy.asarray", "numpy.asarray", "numpy.zeros", "numpy.square().sum", "numpy.square().sum", "float", "len", "len", "len", "len", "numpy.square", "numpy.square", "numpy.dot"], "function", ["None"], ["def", "_pdist", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Compute pair-wise squared distance between points in `a` and `b`.\n\n    Parameters\n    ----------\n    a : array_like\n        An NxM matrix of N samples of dimensionality M.\n    b : array_like\n        An LxM matrix of L samples of dimensionality M.\n\n    Returns\n    -------\n    ndarray\n        Returns a matrix of size len(a), len(b) such that eleement (i, j)\n        contains the squared distance between `a[i]` and `b[j]`.\n\n    \"\"\"", "\n", "a", ",", "b", "=", "np", ".", "asarray", "(", "a", ")", ",", "np", ".", "asarray", "(", "b", ")", "\n", "if", "len", "(", "a", ")", "==", "0", "or", "len", "(", "b", ")", "==", "0", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "(", "len", "(", "a", ")", ",", "len", "(", "b", ")", ")", ")", "\n", "", "a2", ",", "b2", "=", "np", ".", "square", "(", "a", ")", ".", "sum", "(", "axis", "=", "1", ")", ",", "np", ".", "square", "(", "b", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "r2", "=", "-", "2.", "*", "np", ".", "dot", "(", "a", ",", "b", ".", "T", ")", "+", "a2", "[", ":", ",", "None", "]", "+", "b2", "[", "None", ",", ":", "]", "\n", "r2", "=", "np", ".", "clip", "(", "r2", ",", "0.", ",", "float", "(", "np", ".", "inf", ")", ")", "\n", "return", "r2", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching._cosine_distance": [[31, 55], ["numpy.dot", "numpy.asarray", "numpy.linalg.norm", "numpy.asarray", "numpy.linalg.norm"], "function", ["None"], ["", "def", "_cosine_distance", "(", "a", ",", "b", ",", "data_is_normalized", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute pair-wise cosine distance between points in `a` and `b`.\n\n    Parameters\n    ----------\n    a : array_like\n        An NxM matrix of N samples of dimensionality M.\n    b : array_like\n        An LxM matrix of L samples of dimensionality M.\n    data_is_normalized : Optional[bool]\n        If True, assumes rows in a and b are unit length vectors.\n        Otherwise, a and b are explicitly normalized to lenght 1.\n\n    Returns\n    -------\n    ndarray\n        Returns a matrix of size len(a), len(b) such that eleement (i, j)\n        contains the squared distance between `a[i]` and `b[j]`.\n\n    \"\"\"", "\n", "if", "not", "data_is_normalized", ":", "\n", "        ", "a", "=", "np", ".", "asarray", "(", "a", ")", "/", "np", ".", "linalg", ".", "norm", "(", "a", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "b", "=", "np", ".", "asarray", "(", "b", ")", "/", "np", ".", "linalg", ".", "norm", "(", "b", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "", "return", "1.", "-", "np", ".", "dot", "(", "a", ",", "b", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching._nn_euclidean_distance": [[57, 76], ["nn_matching._pdist", "numpy.maximum", "_pdist.min"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching._pdist"], ["", "def", "_nn_euclidean_distance", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\" Helper function for nearest neighbor distance metric (Euclidean).\n\n    Parameters\n    ----------\n    x : ndarray\n        A matrix of N row-vectors (sample points).\n    y : ndarray\n        A matrix of M row-vectors (query points).\n\n    Returns\n    -------\n    ndarray\n        A vector of length M that contains for each entry in `y` the\n        smallest Euclidean distance to a sample in `x`.\n\n    \"\"\"", "\n", "distances", "=", "_pdist", "(", "x", ",", "y", ")", "\n", "return", "np", ".", "maximum", "(", "0.0", ",", "distances", ".", "min", "(", "axis", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching._nn_cosine_distance": [[78, 97], ["nn_matching._cosine_distance", "_cosine_distance.min"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching._cosine_distance"], ["", "def", "_nn_cosine_distance", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\" Helper function for nearest neighbor distance metric (cosine).\n\n    Parameters\n    ----------\n    x : ndarray\n        A matrix of N row-vectors (sample points).\n    y : ndarray\n        A matrix of M row-vectors (query points).\n\n    Returns\n    -------\n    ndarray\n        A vector of length M that contains for each entry in `y` the\n        smallest cosine distance to a sample in `x`.\n\n    \"\"\"", "\n", "distances", "=", "_cosine_distance", "(", "x", ",", "y", ")", "\n", "return", "distances", ".", "min", "(", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.__init__": [[40, 54], ["numpy.eye", "range", "numpy.eye"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "ndim", ",", "dt", "=", "4", ",", "1.", "\n", "\n", "# Create Kalman filter model matrices.", "\n", "self", ".", "_motion_mat", "=", "np", ".", "eye", "(", "2", "*", "ndim", ",", "2", "*", "ndim", ")", "\n", "for", "i", "in", "range", "(", "ndim", ")", ":", "\n", "            ", "self", ".", "_motion_mat", "[", "i", ",", "ndim", "+", "i", "]", "=", "dt", "\n", "", "self", ".", "_update_mat", "=", "np", ".", "eye", "(", "ndim", ",", "2", "*", "ndim", ")", "\n", "\n", "# Motion and observation uncertainty are chosen relative to the current", "\n", "# state estimate. These weights control the amount of uncertainty in", "\n", "# the model. This is a bit hacky.", "\n", "self", ".", "_std_weight_position", "=", "1.", "/", "20", "\n", "self", ".", "_std_weight_velocity", "=", "1.", "/", "160", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.initiate": [[55, 87], ["numpy.zeros_like", "numpy.diag", "numpy.square"], "methods", ["None"], ["", "def", "initiate", "(", "self", ",", "measurement", ")", ":", "\n", "        ", "\"\"\"Create track from unassociated measurement.\n\n        Parameters\n        ----------\n        measurement : ndarray\n            Bounding box coordinates (x, y, a, h) with center position (x, y),\n            aspect ratio a, and height h.\n\n        Returns\n        -------\n        (ndarray, ndarray)\n            Returns the mean vector (8 dimensional) and covariance matrix (8x8\n            dimensional) of the new track. Unobserved velocities are initialized\n            to 0 mean.\n\n        \"\"\"", "\n", "mean_pos", "=", "measurement", "\n", "mean_vel", "=", "np", ".", "zeros_like", "(", "mean_pos", ")", "\n", "mean", "=", "np", ".", "r_", "[", "mean_pos", ",", "mean_vel", "]", "\n", "\n", "std", "=", "[", "\n", "2", "*", "self", ".", "_std_weight_position", "*", "measurement", "[", "3", "]", ",", "\n", "2", "*", "self", ".", "_std_weight_position", "*", "measurement", "[", "3", "]", ",", "\n", "1e-2", ",", "\n", "2", "*", "self", ".", "_std_weight_position", "*", "measurement", "[", "3", "]", ",", "\n", "10", "*", "self", ".", "_std_weight_velocity", "*", "measurement", "[", "3", "]", ",", "\n", "10", "*", "self", ".", "_std_weight_velocity", "*", "measurement", "[", "3", "]", ",", "\n", "1e-5", ",", "\n", "10", "*", "self", ".", "_std_weight_velocity", "*", "measurement", "[", "3", "]", "]", "\n", "covariance", "=", "np", ".", "diag", "(", "np", ".", "square", "(", "std", ")", ")", "\n", "return", "mean", ",", "covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.predict": [[88, 124], ["numpy.diag", "numpy.dot", "numpy.square", "numpy.linalg.multi_dot"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "mean", ",", "covariance", ")", ":", "\n", "        ", "\"\"\"Run Kalman filter prediction step.\n\n        Parameters\n        ----------\n        mean : ndarray\n            The 8 dimensional mean vector of the object state at the previous\n            time step.\n        covariance : ndarray\n            The 8x8 dimensional covariance matrix of the object state at the\n            previous time step.\n\n        Returns\n        -------\n        (ndarray, ndarray)\n            Returns the mean vector and covariance matrix of the predicted\n            state. Unobserved velocities are initialized to 0 mean.\n\n        \"\"\"", "\n", "std_pos", "=", "[", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "\n", "1e-2", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", "]", "\n", "std_vel", "=", "[", "\n", "self", ".", "_std_weight_velocity", "*", "mean", "[", "3", "]", ",", "\n", "self", ".", "_std_weight_velocity", "*", "mean", "[", "3", "]", ",", "\n", "1e-5", ",", "\n", "self", ".", "_std_weight_velocity", "*", "mean", "[", "3", "]", "]", "\n", "motion_cov", "=", "np", ".", "diag", "(", "np", ".", "square", "(", "np", ".", "r_", "[", "std_pos", ",", "std_vel", "]", ")", ")", "\n", "\n", "mean", "=", "np", ".", "dot", "(", "self", ".", "_motion_mat", ",", "mean", ")", "\n", "covariance", "=", "np", ".", "linalg", ".", "multi_dot", "(", "(", "\n", "self", ".", "_motion_mat", ",", "covariance", ",", "self", ".", "_motion_mat", ".", "T", ")", ")", "+", "motion_cov", "\n", "\n", "return", "mean", ",", "covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.project": [[125, 153], ["numpy.diag", "numpy.dot", "numpy.linalg.multi_dot", "numpy.square"], "methods", ["None"], ["", "def", "project", "(", "self", ",", "mean", ",", "covariance", ")", ":", "\n", "        ", "\"\"\"Project state distribution to measurement space.\n\n        Parameters\n        ----------\n        mean : ndarray\n            The state's mean vector (8 dimensional array).\n        covariance : ndarray\n            The state's covariance matrix (8x8 dimensional).\n\n        Returns\n        -------\n        (ndarray, ndarray)\n            Returns the projected mean and covariance matrix of the given state\n            estimate.\n\n        \"\"\"", "\n", "std", "=", "[", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", ",", "\n", "1e-1", ",", "\n", "self", ".", "_std_weight_position", "*", "mean", "[", "3", "]", "]", "\n", "innovation_cov", "=", "np", ".", "diag", "(", "np", ".", "square", "(", "std", ")", ")", "\n", "\n", "mean", "=", "np", ".", "dot", "(", "self", ".", "_update_mat", ",", "mean", ")", "\n", "covariance", "=", "np", ".", "linalg", ".", "multi_dot", "(", "(", "\n", "self", ".", "_update_mat", ",", "covariance", ",", "self", ".", "_update_mat", ".", "T", ")", ")", "\n", "return", "mean", ",", "covariance", "+", "innovation_cov", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.update": [[154, 187], ["kalman_filter.KalmanFilter.project", "scipy.linalg.cho_factor", "scipy.linalg.cho_solve", "numpy.dot", "numpy.linalg.multi_dot", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.project"], ["", "def", "update", "(", "self", ",", "mean", ",", "covariance", ",", "measurement", ")", ":", "\n", "        ", "\"\"\"Run Kalman filter correction step.\n\n        Parameters\n        ----------\n        mean : ndarray\n            The predicted state's mean vector (8 dimensional).\n        covariance : ndarray\n            The state's covariance matrix (8x8 dimensional).\n        measurement : ndarray\n            The 4 dimensional measurement vector (x, y, a, h), where (x, y)\n            is the center position, a the aspect ratio, and h the height of the\n            bounding box.\n\n        Returns\n        -------\n        (ndarray, ndarray)\n            Returns the measurement-corrected state distribution.\n\n        \"\"\"", "\n", "projected_mean", ",", "projected_cov", "=", "self", ".", "project", "(", "mean", ",", "covariance", ")", "\n", "\n", "chol_factor", ",", "lower", "=", "scipy", ".", "linalg", ".", "cho_factor", "(", "\n", "projected_cov", ",", "lower", "=", "True", ",", "check_finite", "=", "False", ")", "\n", "kalman_gain", "=", "scipy", ".", "linalg", ".", "cho_solve", "(", "\n", "(", "chol_factor", ",", "lower", ")", ",", "np", ".", "dot", "(", "covariance", ",", "self", ".", "_update_mat", ".", "T", ")", ".", "T", ",", "\n", "check_finite", "=", "False", ")", ".", "T", "\n", "innovation", "=", "measurement", "-", "projected_mean", "\n", "\n", "new_mean", "=", "mean", "+", "np", ".", "dot", "(", "innovation", ",", "kalman_gain", ".", "T", ")", "\n", "new_covariance", "=", "covariance", "-", "np", ".", "linalg", ".", "multi_dot", "(", "(", "\n", "kalman_gain", ",", "projected_cov", ",", "kalman_gain", ".", "T", ")", ")", "\n", "return", "new_mean", ",", "new_covariance", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.gating_distance": [[188, 230], ["kalman_filter.KalmanFilter.project", "numpy.linalg.cholesky", "scipy.linalg.solve_triangular", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.project"], ["", "def", "gating_distance", "(", "self", ",", "mean", ",", "covariance", ",", "measurements", ",", "\n", "only_position", "=", "False", ")", ":", "\n", "        ", "\"\"\"Compute gating distance between state distribution and measurements.\n\n        A suitable distance threshold can be obtained from `chi2inv95`. If\n        `only_position` is False, the chi-square distribution has 4 degrees of\n        freedom, otherwise 2.\n\n        Parameters\n        ----------\n        mean : ndarray\n            Mean vector over the state distribution (8 dimensional).\n        covariance : ndarray\n            Covariance of the state distribution (8x8 dimensional).\n        measurements : ndarray\n            An Nx4 dimensional matrix of N measurements, each in\n            format (x, y, a, h) where (x, y) is the bounding box center\n            position, a the aspect ratio, and h the height.\n        only_position : Optional[bool]\n            If True, distance computation is done with respect to the bounding\n            box center position only.\n\n        Returns\n        -------\n        ndarray\n            Returns an array of length N, where the i-th element contains the\n            squared Mahalanobis distance between (mean, covariance) and\n            `measurements[i]`.\n\n        \"\"\"", "\n", "mean", ",", "covariance", "=", "self", ".", "project", "(", "mean", ",", "covariance", ")", "\n", "if", "only_position", ":", "\n", "            ", "mean", ",", "covariance", "=", "mean", "[", ":", "2", "]", ",", "covariance", "[", ":", "2", ",", ":", "2", "]", "\n", "measurements", "=", "measurements", "[", ":", ",", ":", "2", "]", "\n", "\n", "", "cholesky_factor", "=", "np", ".", "linalg", ".", "cholesky", "(", "covariance", ")", "\n", "d", "=", "measurements", "-", "mean", "\n", "z", "=", "scipy", ".", "linalg", ".", "solve_triangular", "(", "\n", "cholesky_factor", ",", "d", ".", "T", ",", "lower", "=", "True", ",", "check_finite", "=", "False", ",", "\n", "overwrite_b", "=", "True", ")", "\n", "squared_maha", "=", "np", ".", "sum", "(", "z", "*", "z", ",", "axis", "=", "0", ")", "\n", "return", "squared_maha", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection_yolo.Detection_YOLO.__init__": [[29, 33], ["numpy.asarray", "float"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tlwh", ",", "confidence", ",", "cls", ")", ":", "\n", "        ", "self", ".", "tlwh", "=", "np", ".", "asarray", "(", "tlwh", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "confidence", "=", "float", "(", "confidence", ")", "\n", "self", ".", "cls", "=", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection_yolo.Detection_YOLO.to_tlbr": [[34, 41], ["detection_yolo.Detection_YOLO.tlwh.copy"], "methods", ["None"], ["", "def", "to_tlbr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Convert bounding box to format `(min x, min y, max x, max y)`, i.e.,\n        `(top left, bottom right)`.\n        \"\"\"", "\n", "ret", "=", "self", ".", "tlwh", ".", "copy", "(", ")", "\n", "ret", "[", "2", ":", "]", "+=", "ret", "[", ":", "2", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection_yolo.Detection_YOLO.to_xyah": [[42, 50], ["detection_yolo.Detection_YOLO.tlwh.copy"], "methods", ["None"], ["", "def", "to_xyah", "(", "self", ")", ":", "\n", "        ", "\"\"\"Convert bounding box to format `(center x, center y, aspect ratio,\n        height)`, where the aspect ratio is `width / height`.\n        \"\"\"", "\n", "ret", "=", "self", ".", "tlwh", ".", "copy", "(", ")", "\n", "ret", "[", ":", "2", "]", "+=", "ret", "[", "2", ":", "]", "/", "2", "\n", "ret", "[", "2", "]", "/=", "ret", "[", "3", "]", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.min_cost_matching": [[13, 80], ["distance_metric", "scipy.optimize.linear_sum_assignment", "numpy.asarray", "numpy.transpose", "enumerate", "enumerate", "numpy.arange", "numpy.arange", "len", "len", "len", "len", "unmatched_detections.append", "unmatched_tracks.append", "unmatched_tracks.append", "unmatched_detections.append", "matches.append"], "function", ["None"], ["def", "min_cost_matching", "(", "\n", "distance_metric", ",", "max_distance", ",", "tracks", ",", "detections", ",", "track_indices", "=", "None", ",", "\n", "detection_indices", "=", "None", ")", ":", "\n", "    ", "\"\"\"Solve linear assignment problem.\n\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should\n        return the NxM dimensional cost matrix, where element (i, j) is the\n        association cost between the i-th track in the given track indices and\n        the j-th detection in the given detection_indices.\n    max_distance : float\n        Gating threshold. Associations with cost larger than this value are\n        disregarded.\n    tracks : List[track.Track]\n        A list of predicted tracks at the current time step.\n    detections : List[detection.Detection]\n        A list of detections at the current time step.\n    track_indices : List[int]\n        List of track indices that maps rows in `cost_matrix` to tracks in\n        `tracks` (see description above).\n    detection_indices : List[int]\n        List of detection indices that maps columns in `cost_matrix` to\n        detections in `detections` (see description above).\n\n    Returns\n    -------\n    (List[(int, int)], List[int], List[int])\n        Returns a tuple with the following three entries:\n        * A list of matched track and detection indices.\n        * A list of unmatched track indices.\n        * A list of unmatched detection indices.\n\n    \"\"\"", "\n", "if", "track_indices", "is", "None", ":", "\n", "        ", "track_indices", "=", "np", ".", "arange", "(", "len", "(", "tracks", ")", ")", "\n", "", "if", "detection_indices", "is", "None", ":", "\n", "        ", "detection_indices", "=", "np", ".", "arange", "(", "len", "(", "detections", ")", ")", "\n", "\n", "", "if", "len", "(", "detection_indices", ")", "==", "0", "or", "len", "(", "track_indices", ")", "==", "0", ":", "\n", "        ", "return", "[", "]", ",", "track_indices", ",", "detection_indices", "# Nothing to match.", "\n", "\n", "", "cost_matrix", "=", "distance_metric", "(", "\n", "tracks", ",", "detections", ",", "track_indices", ",", "detection_indices", ")", "\n", "cost_matrix", "[", "cost_matrix", ">", "max_distance", "]", "=", "max_distance", "+", "1e-5", "\n", "indices", "=", "linear_sum_assignment", "(", "cost_matrix", ")", "\n", "indices", "=", "np", ".", "asarray", "(", "indices", ")", "\n", "indices", "=", "np", ".", "transpose", "(", "indices", ")", "\n", "\n", "matches", ",", "unmatched_tracks", ",", "unmatched_detections", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "col", ",", "detection_idx", "in", "enumerate", "(", "detection_indices", ")", ":", "\n", "        ", "if", "col", "not", "in", "indices", "[", ":", ",", "1", "]", ":", "\n", "            ", "unmatched_detections", ".", "append", "(", "detection_idx", ")", "\n", "", "", "for", "row", ",", "track_idx", "in", "enumerate", "(", "track_indices", ")", ":", "\n", "        ", "if", "row", "not", "in", "indices", "[", ":", ",", "0", "]", ":", "\n", "            ", "unmatched_tracks", ".", "append", "(", "track_idx", ")", "\n", "", "", "for", "row", ",", "col", "in", "indices", ":", "\n", "        ", "track_idx", "=", "track_indices", "[", "row", "]", "\n", "detection_idx", "=", "detection_indices", "[", "col", "]", "\n", "if", "cost_matrix", "[", "row", ",", "col", "]", ">", "max_distance", ":", "\n", "            ", "unmatched_tracks", ".", "append", "(", "track_idx", ")", "\n", "unmatched_detections", ".", "append", "(", "detection_idx", ")", "\n", "", "else", ":", "\n", "            ", "matches", ".", "append", "(", "(", "track_idx", ",", "detection_idx", ")", ")", "\n", "", "", "return", "matches", ",", "unmatched_tracks", ",", "unmatched_detections", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.matching_cascade": [[82, 146], ["range", "list", "list", "list", "linear_assignment.min_cost_matching", "range", "range", "len", "len", "set", "set", "len", "len"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.min_cost_matching"], ["", "def", "matching_cascade", "(", "\n", "distance_metric", ",", "max_distance", ",", "cascade_depth", ",", "tracks", ",", "detections", ",", "\n", "track_indices", "=", "None", ",", "detection_indices", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run matching cascade.\n\n    Parameters\n    ----------\n    distance_metric : Callable[List[Track], List[Detection], List[int], List[int]) -> ndarray\n        The distance metric is given a list of tracks and detections as well as\n        a list of N track indices and M detection indices. The metric should\n        return the NxM dimensional cost matrix, where element (i, j) is the\n        association cost between the i-th track in the given track indices and\n        the j-th detection in the given detection indices.\n    max_distance : float\n        Gating threshold. Associations with cost larger than this value are\n        disregarded.\n    cascade_depth: int\n        The cascade depth, should be se to the maximum track age.\n    tracks : List[track.Track]\n        A list of predicted tracks at the current time step.\n    detections : List[detection.Detection]\n        A list of detections at the current time step.\n    track_indices : Optional[List[int]]\n        List of track indices that maps rows in `cost_matrix` to tracks in\n        `tracks` (see description above). Defaults to all tracks.\n    detection_indices : Optional[List[int]]\n        List of detection indices that maps columns in `cost_matrix` to\n        detections in `detections` (see description above). Defaults to all\n        detections.\n\n    Returns\n    -------\n    (List[(int, int)], List[int], List[int])\n        Returns a tuple with the following three entries:\n        * A list of matched track and detection indices.\n        * A list of unmatched track indices.\n        * A list of unmatched detection indices.\n\n    \"\"\"", "\n", "if", "track_indices", "is", "None", ":", "\n", "        ", "track_indices", "=", "list", "(", "range", "(", "len", "(", "tracks", ")", ")", ")", "\n", "", "if", "detection_indices", "is", "None", ":", "\n", "        ", "detection_indices", "=", "list", "(", "range", "(", "len", "(", "detections", ")", ")", ")", "\n", "\n", "", "unmatched_detections", "=", "detection_indices", "\n", "matches", "=", "[", "]", "\n", "for", "level", "in", "range", "(", "cascade_depth", ")", ":", "\n", "        ", "if", "len", "(", "unmatched_detections", ")", "==", "0", ":", "# No detections left", "\n", "            ", "break", "\n", "\n", "", "track_indices_l", "=", "[", "\n", "k", "for", "k", "in", "track_indices", "\n", "if", "tracks", "[", "k", "]", ".", "time_since_update", "==", "1", "+", "level", "\n", "]", "\n", "if", "len", "(", "track_indices_l", ")", "==", "0", ":", "# Nothing to match at this level", "\n", "            ", "continue", "\n", "\n", "", "matches_l", ",", "_", ",", "unmatched_detections", "=", "min_cost_matching", "(", "\n", "distance_metric", ",", "max_distance", ",", "tracks", ",", "detections", ",", "\n", "track_indices_l", ",", "unmatched_detections", ")", "\n", "matches", "+=", "matches_l", "\n", "", "unmatched_tracks", "=", "list", "(", "set", "(", "track_indices", ")", "-", "set", "(", "k", "for", "k", ",", "_", "in", "matches", ")", ")", "\n", "return", "matches", ",", "unmatched_tracks", ",", "unmatched_detections", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.gate_cost_matrix": [[148, 195], ["numpy.asarray", "enumerate", "kf.gating_distance", "detections[].to_xyah"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.gating_distance", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection.Detection.to_xyah"], ["", "def", "gate_cost_matrix", "(", "\n", "kf", ",", "cost_matrix", ",", "tracks", ",", "detections", ",", "track_indices", ",", "detection_indices", ",", "\n", "gated_cost", "=", "INFTY_COST", ",", "only_position", "=", "False", ")", ":", "\n", "    ", "\"\"\"Invalidate infeasible entries in cost matrix based on the state\n    distributions obtained by Kalman filtering.\n\n    Parameters\n    ----------\n    kf : The Kalman filter.\n    cost_matrix : ndarray\n        The NxM dimensional cost matrix, where N is the number of track indices\n        and M is the number of detection indices, such that entry (i, j) is the\n        association cost between `tracks[track_indices[i]]` and\n        `detections[detection_indices[j]]`.\n    tracks : List[track.Track]\n        A list of predicted tracks at the current time step.\n    detections : List[detection.Detection]\n        A list of detections at the current time step.\n    track_indices : List[int]\n        List of track indices that maps rows in `cost_matrix` to tracks in\n        `tracks` (see description above).\n    detection_indices : List[int]\n        List of detection indices that maps columns in `cost_matrix` to\n        detections in `detections` (see description above).\n    gated_cost : Optional[float]\n        Entries in the cost matrix corresponding to infeasible associations are\n        set this value. Defaults to a very large value.\n    only_position : Optional[bool]\n        If True, only the x, y position of the state distribution is considered\n        during gating. Defaults to False.\n\n    Returns\n    -------\n    ndarray\n        Returns the modified cost matrix.\n\n    \"\"\"", "\n", "gating_dim", "=", "2", "if", "only_position", "else", "4", "\n", "gating_threshold", "=", "kalman_filter", ".", "chi2inv95", "[", "gating_dim", "]", "\n", "measurements", "=", "np", ".", "asarray", "(", "\n", "[", "detections", "[", "i", "]", ".", "to_xyah", "(", ")", "for", "i", "in", "detection_indices", "]", ")", "\n", "for", "row", ",", "track_idx", "in", "enumerate", "(", "track_indices", ")", ":", "\n", "        ", "track", "=", "tracks", "[", "track_idx", "]", "\n", "gating_distance", "=", "kf", ".", "gating_distance", "(", "\n", "track", ".", "mean", ",", "track", ".", "covariance", ",", "measurements", ",", "only_position", ")", "\n", "cost_matrix", "[", "row", ",", "gating_distance", ">", "gating_threshold", "]", "=", "gated_cost", "\n", "", "return", "cost_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker.__init__": [[40, 49], ["kalman_filter.KalmanFilter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "metric", ",", "max_iou_distance", "=", "0.7", ",", "max_age", "=", "30", ",", "n_init", "=", "3", ")", ":", "\n", "        ", "self", ".", "metric", "=", "metric", "\n", "self", ".", "max_iou_distance", "=", "max_iou_distance", "\n", "self", ".", "max_age", "=", "max_age", "\n", "self", ".", "n_init", "=", "n_init", "\n", "\n", "self", ".", "kf", "=", "kalman_filter", ".", "KalmanFilter", "(", ")", "\n", "self", ".", "tracks", "=", "[", "]", "\n", "self", ".", "_next_id", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker.predict": [[50, 57], ["track.predict"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.predict"], ["", "def", "predict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Propagate track state distributions one time step forward.\n\n        This function should be called once every time step, before `update`.\n        \"\"\"", "\n", "for", "track", "in", "self", ".", "tracks", ":", "\n", "            ", "track", ".", "predict", "(", "self", ".", "kf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker.update": [[58, 92], ["tracker.Tracker._match", "tracker.Tracker.metric.partial_fit", "tracker.Tracker.tracks[].update", "tracker.Tracker.tracks[].mark_missed", "tracker.Tracker._initiate_track", "numpy.asarray", "numpy.asarray", "t.is_confirmed", "track.is_confirmed", "t.is_deleted"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker._match", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching.NearestNeighborDistanceMetric.partial_fit", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.mark_missed", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker._initiate_track", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_confirmed", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_confirmed", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_deleted"], ["", "", "def", "update", "(", "self", ",", "detections", ")", ":", "\n", "        ", "\"\"\"Perform measurement update and track management.\n\n        Parameters\n        ----------\n        detections : List[deep_sort.detection.Detection]\n            A list of detections at the current time step.\n\n        \"\"\"", "\n", "# Run matching cascade.", "\n", "matches", ",", "unmatched_tracks", ",", "unmatched_detections", "=", "self", ".", "_match", "(", "detections", ")", "\n", "\n", "# Update track set.", "\n", "for", "track_idx", ",", "detection_idx", "in", "matches", ":", "\n", "            ", "self", ".", "tracks", "[", "track_idx", "]", ".", "update", "(", "\n", "self", ".", "kf", ",", "detections", "[", "detection_idx", "]", ")", "\n", "", "for", "track_idx", "in", "unmatched_tracks", ":", "\n", "            ", "self", ".", "tracks", "[", "track_idx", "]", ".", "mark_missed", "(", ")", "\n", "", "for", "detection_idx", "in", "unmatched_detections", ":", "\n", "            ", "self", ".", "_initiate_track", "(", "detections", "[", "detection_idx", "]", ")", "\n", "", "self", ".", "tracks", "=", "[", "t", "for", "t", "in", "self", ".", "tracks", "if", "not", "t", ".", "is_deleted", "(", ")", "]", "\n", "\n", "# Update distance metric.", "\n", "active_targets", "=", "[", "t", ".", "track_id", "for", "t", "in", "self", ".", "tracks", "if", "t", ".", "is_confirmed", "(", ")", "]", "\n", "features", ",", "targets", "=", "[", "]", ",", "[", "]", "\n", "for", "track", "in", "self", ".", "tracks", ":", "\n", "            ", "if", "not", "track", ".", "is_confirmed", "(", ")", ":", "\n", "                ", "continue", "\n", "", "features", "+=", "track", ".", "features", "\n", "targets", "+=", "[", "track", ".", "track_id", "for", "_", "in", "track", ".", "features", "]", "\n", "track", ".", "features", "=", "[", "]", "\n", "", "self", ".", "metric", ".", "partial_fit", "(", "\n", "np", ".", "asarray", "(", "features", ")", ",", "np", ".", "asarray", "(", "targets", ")", ",", "active_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker._match": [[93, 132], ["linear_assignment.matching_cascade", "linear_assignment.min_cost_matching", "list", "numpy.array", "numpy.array", "tracker.Tracker.metric.distance", "linear_assignment.gate_cost_matrix", "set", "enumerate", "t.is_confirmed", "enumerate", "t.is_confirmed"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.matching_cascade", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.min_cost_matching", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.nn_matching.NearestNeighborDistanceMetric.distance", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.linear_assignment.gate_cost_matrix", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_confirmed", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_confirmed"], ["", "def", "_match", "(", "self", ",", "detections", ")", ":", "\n", "\n", "        ", "def", "gated_metric", "(", "tracks", ",", "dets", ",", "track_indices", ",", "detection_indices", ")", ":", "\n", "            ", "features", "=", "np", ".", "array", "(", "[", "dets", "[", "i", "]", ".", "feature", "for", "i", "in", "detection_indices", "]", ")", "\n", "targets", "=", "np", ".", "array", "(", "[", "tracks", "[", "i", "]", ".", "track_id", "for", "i", "in", "track_indices", "]", ")", "\n", "cost_matrix", "=", "self", ".", "metric", ".", "distance", "(", "features", ",", "targets", ")", "\n", "cost_matrix", "=", "linear_assignment", ".", "gate_cost_matrix", "(", "\n", "self", ".", "kf", ",", "cost_matrix", ",", "tracks", ",", "dets", ",", "track_indices", ",", "\n", "detection_indices", ")", "\n", "\n", "return", "cost_matrix", "\n", "\n", "# Split track set into confirmed and unconfirmed tracks.", "\n", "", "confirmed_tracks", "=", "[", "\n", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "tracks", ")", "if", "t", ".", "is_confirmed", "(", ")", "]", "\n", "unconfirmed_tracks", "=", "[", "\n", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "tracks", ")", "if", "not", "t", ".", "is_confirmed", "(", ")", "]", "\n", "\n", "# Associate confirmed tracks using appearance features.", "\n", "matches_a", ",", "unmatched_tracks_a", ",", "unmatched_detections", "=", "linear_assignment", ".", "matching_cascade", "(", "\n", "gated_metric", ",", "self", ".", "metric", ".", "matching_threshold", ",", "self", ".", "max_age", ",", "\n", "self", ".", "tracks", ",", "detections", ",", "confirmed_tracks", ")", "\n", "\n", "# Associate remaining tracks together with unconfirmed tracks using IOU.", "\n", "iou_track_candidates", "=", "unconfirmed_tracks", "+", "[", "\n", "k", "for", "k", "in", "unmatched_tracks_a", "if", "\n", "self", ".", "tracks", "[", "k", "]", ".", "time_since_update", "==", "1", "]", "\n", "unmatched_tracks_a", "=", "[", "\n", "k", "for", "k", "in", "unmatched_tracks_a", "if", "\n", "self", ".", "tracks", "[", "k", "]", ".", "time_since_update", "!=", "1", "]", "\n", "matches_b", ",", "unmatched_tracks_b", ",", "unmatched_detections", "=", "linear_assignment", ".", "min_cost_matching", "(", "\n", "iou_matching", ".", "iou_cost", ",", "self", ".", "max_iou_distance", ",", "self", ".", "tracks", ",", "\n", "detections", ",", "iou_track_candidates", ",", "unmatched_detections", ")", "\n", "\n", "matches", "=", "matches_a", "+", "matches_b", "\n", "unmatched_tracks", "=", "list", "(", "set", "(", "unmatched_tracks_a", "+", "unmatched_tracks_b", ")", ")", "\n", "return", "matches", ",", "unmatched_tracks", ",", "unmatched_detections", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.tracker.Tracker._initiate_track": [[133, 139], ["tracker.Tracker.kf.initiate", "tracker.Tracker.tracks.append", "detection.to_xyah", "track.Track"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.kalman_filter.KalmanFilter.initiate", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection.Detection.to_xyah"], ["", "def", "_initiate_track", "(", "self", ",", "detection", ")", ":", "\n", "        ", "mean", ",", "covariance", "=", "self", ".", "kf", ".", "initiate", "(", "detection", ".", "to_xyah", "(", ")", ")", "\n", "self", ".", "tracks", ".", "append", "(", "Track", "(", "\n", "mean", ",", "covariance", ",", "self", ".", "_next_id", ",", "self", ".", "n_init", ",", "self", ".", "max_age", ",", "\n", "detection", ".", "feature", ")", ")", "\n", "self", ".", "_next_id", "+=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.preprocessing.non_max_suppression": [[6, 74], ["boxes.astype.astype", "len", "numpy.argsort", "numpy.argsort", "len", "pick.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.delete", "len", "numpy.concatenate", "numpy.where"], "function", ["None"], ["def", "non_max_suppression", "(", "boxes", ",", "max_bbox_overlap", ",", "scores", "=", "None", ")", ":", "\n", "    ", "\"\"\"Suppress overlapping detections.\n\n    Original code from [1]_ has been adapted to include confidence score.\n\n    .. [1] http://www.pyimagesearch.com/2015/02/16/\n           faster-non-maximum-suppression-python/\n\n    Examples\n    --------\n\n        >>> boxes = [d.roi for d in detections]\n        >>> scores = [d.confidence for d in detections]\n        >>> indices = non_max_suppression(boxes, max_bbox_overlap, scores)\n        >>> detections = [detections[i] for i in indices]\n\n    Parameters\n    ----------\n    boxes : ndarray\n        Array of ROIs (x, y, width, height).\n    max_bbox_overlap : float\n        ROIs that overlap more than this values are suppressed.\n    scores : Optional[array_like]\n        Detector confidence score.\n\n    Returns\n    -------\n    List[int]\n        Returns indices of detections that have survived non-maxima suppression.\n\n    \"\"\"", "\n", "if", "len", "(", "boxes", ")", "==", "0", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "boxes", "=", "boxes", ".", "astype", "(", "np", ".", "float", ")", "\n", "pick", "=", "[", "]", "\n", "\n", "x1", "=", "boxes", "[", ":", ",", "0", "]", "\n", "y1", "=", "boxes", "[", ":", ",", "1", "]", "\n", "x2", "=", "boxes", "[", ":", ",", "2", "]", "+", "boxes", "[", ":", ",", "0", "]", "\n", "y2", "=", "boxes", "[", ":", ",", "3", "]", "+", "boxes", "[", ":", ",", "1", "]", "\n", "\n", "area", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "if", "scores", "is", "not", "None", ":", "\n", "        ", "idxs", "=", "np", ".", "argsort", "(", "scores", ")", "\n", "", "else", ":", "\n", "        ", "idxs", "=", "np", ".", "argsort", "(", "y2", ")", "\n", "\n", "", "while", "len", "(", "idxs", ")", ">", "0", ":", "\n", "        ", "last", "=", "len", "(", "idxs", ")", "-", "1", "\n", "i", "=", "idxs", "[", "last", "]", "\n", "pick", ".", "append", "(", "i", ")", "\n", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "idxs", "[", ":", "last", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "idxs", "[", ":", "last", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "idxs", "[", ":", "last", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "idxs", "[", ":", "last", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "\n", "overlap", "=", "(", "w", "*", "h", ")", "/", "area", "[", "idxs", "[", ":", "last", "]", "]", "\n", "\n", "idxs", "=", "np", ".", "delete", "(", "\n", "idxs", ",", "np", ".", "concatenate", "(", "\n", "(", "[", "last", "]", ",", "np", ".", "where", "(", "overlap", ">", "max_bbox_overlap", ")", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "return", "pick", "\n", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection.Detection.__init__": [[29, 34], ["numpy.asarray", "float", "numpy.asarray"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tlwh", ",", "confidence", ",", "cls", ",", "feature", ")", ":", "\n", "        ", "self", ".", "tlwh", "=", "np", ".", "asarray", "(", "tlwh", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "confidence", "=", "float", "(", "confidence", ")", "\n", "self", ".", "cls", "=", "cls", "\n", "self", ".", "feature", "=", "np", ".", "asarray", "(", "feature", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection.Detection.to_tlbr": [[35, 42], ["detection.Detection.tlwh.copy"], "methods", ["None"], ["", "def", "to_tlbr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Convert bounding box to format `(min x, min y, max x, max y)`, i.e.,\n        `(top left, bottom right)`.\n        \"\"\"", "\n", "ret", "=", "self", ".", "tlwh", ".", "copy", "(", ")", "\n", "ret", "[", "2", ":", "]", "+=", "ret", "[", ":", "2", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection.Detection.to_xyah": [[43, 51], ["detection.Detection.tlwh.copy"], "methods", ["None"], ["", "def", "to_xyah", "(", "self", ")", ":", "\n", "        ", "\"\"\"Convert bounding box to format `(center x, center y, aspect ratio,\n        height)`, where the aspect ratio is `width / height`.\n        \"\"\"", "\n", "ret", "=", "self", ".", "tlwh", ".", "copy", "(", ")", "\n", "ret", "[", ":", "2", "]", "+=", "ret", "[", "2", ":", "]", "/", "2", "\n", "ret", "[", "2", "]", "/=", "ret", "[", "3", "]", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.__init__": [[66, 82], ["track.Track.features.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "covariance", ",", "track_id", ",", "n_init", ",", "max_age", ",", "\n", "feature", "=", "None", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "covariance", "=", "covariance", "\n", "self", ".", "track_id", "=", "track_id", "\n", "self", ".", "hits", "=", "1", "\n", "self", ".", "age", "=", "1", "\n", "self", ".", "time_since_update", "=", "0", "\n", "\n", "self", ".", "state", "=", "TrackState", ".", "Tentative", "\n", "self", ".", "features", "=", "[", "]", "\n", "if", "feature", "is", "not", "None", ":", "\n", "            ", "self", ".", "features", ".", "append", "(", "feature", ")", "\n", "\n", "", "self", ".", "_n_init", "=", "n_init", "\n", "self", ".", "_max_age", "=", "max_age", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlwh": [[83, 97], ["track.Track.mean[].copy"], "methods", ["None"], ["", "def", "to_tlwh", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get current position in bounding box format `(top left x, top left y,\n        width, height)`.\n\n        Returns\n        -------\n        ndarray\n            The bounding box.\n\n        \"\"\"", "\n", "ret", "=", "self", ".", "mean", "[", ":", "4", "]", ".", "copy", "(", ")", "\n", "ret", "[", "2", "]", "*=", "ret", "[", "3", "]", "\n", "ret", "[", ":", "2", "]", "-=", "ret", "[", "2", ":", "]", "/", "2", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlbr": [[98, 111], ["track.Track.to_tlwh"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlwh"], ["", "def", "to_tlbr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get current position in bounding box format `(min x, miny, max x,\n        max y)`.\n\n        Returns\n        -------\n        ndarray\n            The bounding box.\n\n        \"\"\"", "\n", "ret", "=", "self", ".", "to_tlwh", "(", ")", "\n", "ret", "[", "2", ":", "]", "=", "ret", "[", ":", "2", "]", "+", "ret", "[", "2", ":", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.predict": [[112, 125], ["kf.predict"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.predict"], ["", "def", "predict", "(", "self", ",", "kf", ")", ":", "\n", "        ", "\"\"\"Propagate the state distribution to the current time step using a\n        Kalman filter prediction step.\n\n        Parameters\n        ----------\n        kf : kalman_filter.KalmanFilter\n            The Kalman filter.\n\n        \"\"\"", "\n", "self", ".", "mean", ",", "self", ".", "covariance", "=", "kf", ".", "predict", "(", "self", ".", "mean", ",", "self", ".", "covariance", ")", "\n", "self", ".", "age", "+=", "1", "\n", "self", ".", "time_since_update", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update": [[126, 146], ["kf.update", "track.Track.features.append", "detection.to_xyah"], "methods", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.update", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.detection.Detection.to_xyah"], ["", "def", "update", "(", "self", ",", "kf", ",", "detection", ")", ":", "\n", "        ", "\"\"\"Perform Kalman filter measurement update step and update the feature\n        cache.\n\n        Parameters\n        ----------\n        kf : kalman_filter.KalmanFilter\n            The Kalman filter.\n        detection : Detection\n            The associated detection.\n\n        \"\"\"", "\n", "self", ".", "mean", ",", "self", ".", "covariance", "=", "kf", ".", "update", "(", "\n", "self", ".", "mean", ",", "self", ".", "covariance", ",", "detection", ".", "to_xyah", "(", ")", ")", "\n", "self", ".", "features", ".", "append", "(", "detection", ".", "feature", ")", "\n", "\n", "self", ".", "hits", "+=", "1", "\n", "self", ".", "time_since_update", "=", "0", "\n", "if", "self", ".", "state", "==", "TrackState", ".", "Tentative", "and", "self", ".", "hits", ">=", "self", ".", "_n_init", ":", "\n", "            ", "self", ".", "state", "=", "TrackState", ".", "Confirmed", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.mark_missed": [[147, 154], ["None"], "methods", ["None"], ["", "", "def", "mark_missed", "(", "self", ")", ":", "\n", "        ", "\"\"\"Mark this track as missed (no association at the current time step).\n        \"\"\"", "\n", "if", "self", ".", "state", "==", "TrackState", ".", "Tentative", ":", "\n", "            ", "self", ".", "state", "=", "TrackState", ".", "Deleted", "\n", "", "elif", "self", ".", "time_since_update", ">", "self", ".", "_max_age", ":", "\n", "            ", "self", ".", "state", "=", "TrackState", ".", "Deleted", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_tentative": [[155, 159], ["None"], "methods", ["None"], ["", "", "def", "is_tentative", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns True if this track is tentative (unconfirmed).\n        \"\"\"", "\n", "return", "self", ".", "state", "==", "TrackState", ".", "Tentative", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_confirmed": [[160, 163], ["None"], "methods", ["None"], ["", "def", "is_confirmed", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns True if this track is confirmed.\"\"\"", "\n", "return", "self", ".", "state", "==", "TrackState", ".", "Confirmed", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.is_deleted": [[164, 167], ["None"], "methods", ["None"], ["", "def", "is_deleted", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns True if this track is dead and should be deleted.\"\"\"", "\n", "return", "self", ".", "state", "==", "TrackState", ".", "Deleted", "\n", "", "", ""]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.iou_matching.iou": [[7, 40], ["numpy.maximum", "np.maximum.prod", "bbox[].prod", "candidates[].prod", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum"], "function", ["None"], ["def", "iou", "(", "bbox", ",", "candidates", ")", ":", "\n", "    ", "\"\"\"Computer intersection over union.\n\n    Parameters\n    ----------\n    bbox : ndarray\n        A bounding box in format `(top left x, top left y, width, height)`.\n    candidates : ndarray\n        A matrix of candidate bounding boxes (one per row) in the same format\n        as `bbox`.\n\n    Returns\n    -------\n    ndarray\n        The intersection over union in [0, 1] between the `bbox` and each\n        candidate. A higher score means a larger fraction of the `bbox` is\n        occluded by the candidate.\n\n    \"\"\"", "\n", "bbox_tl", ",", "bbox_br", "=", "bbox", "[", ":", "2", "]", ",", "bbox", "[", ":", "2", "]", "+", "bbox", "[", "2", ":", "]", "\n", "candidates_tl", "=", "candidates", "[", ":", ",", ":", "2", "]", "\n", "candidates_br", "=", "candidates", "[", ":", ",", ":", "2", "]", "+", "candidates", "[", ":", ",", "2", ":", "]", "\n", "\n", "tl", "=", "np", ".", "c_", "[", "np", ".", "maximum", "(", "bbox_tl", "[", "0", "]", ",", "candidates_tl", "[", ":", ",", "0", "]", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "np", ".", "maximum", "(", "bbox_tl", "[", "1", "]", ",", "candidates_tl", "[", ":", ",", "1", "]", ")", "[", ":", ",", "np", ".", "newaxis", "]", "]", "\n", "br", "=", "np", ".", "c_", "[", "np", ".", "minimum", "(", "bbox_br", "[", "0", "]", ",", "candidates_br", "[", ":", ",", "0", "]", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "np", ".", "minimum", "(", "bbox_br", "[", "1", "]", ",", "candidates_br", "[", ":", ",", "1", "]", ")", "[", ":", ",", "np", ".", "newaxis", "]", "]", "\n", "wh", "=", "np", ".", "maximum", "(", "0.", ",", "br", "-", "tl", ")", "\n", "\n", "area_intersection", "=", "wh", ".", "prod", "(", "axis", "=", "1", ")", "\n", "area_bbox", "=", "bbox", "[", "2", ":", "]", ".", "prod", "(", ")", "\n", "area_candidates", "=", "candidates", "[", ":", ",", "2", ":", "]", ".", "prod", "(", "axis", "=", "1", ")", "\n", "return", "area_intersection", "/", "(", "area_bbox", "+", "area_candidates", "-", "area_intersection", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.iou_matching.iou_cost": [[42, 82], ["numpy.zeros", "enumerate", "numpy.arange", "numpy.arange", "tracks[].to_tlwh", "numpy.asarray", "len", "len", "len", "len", "iou_matching.iou"], "function", ["home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.track.Track.to_tlwh", "home.repos.pwc.inspect_result.peabody124_posepipeline.deep_sort.iou_matching.iou"], ["", "def", "iou_cost", "(", "tracks", ",", "detections", ",", "track_indices", "=", "None", ",", "\n", "detection_indices", "=", "None", ")", ":", "\n", "    ", "\"\"\"An intersection over union distance metric.\n\n    Parameters\n    ----------\n    tracks : List[deep_sort.track.Track]\n        A list of tracks.\n    detections : List[deep_sort.detection.Detection]\n        A list of detections.\n    track_indices : Optional[List[int]]\n        A list of indices to tracks that should be matched. Defaults to\n        all `tracks`.\n    detection_indices : Optional[List[int]]\n        A list of indices to detections that should be matched. Defaults\n        to all `detections`.\n\n    Returns\n    -------\n    ndarray\n        Returns a cost matrix of shape\n        len(track_indices), len(detection_indices) where entry (i, j) is\n        `1 - iou(tracks[track_indices[i]], detections[detection_indices[j]])`.\n\n    \"\"\"", "\n", "if", "track_indices", "is", "None", ":", "\n", "        ", "track_indices", "=", "np", ".", "arange", "(", "len", "(", "tracks", ")", ")", "\n", "", "if", "detection_indices", "is", "None", ":", "\n", "        ", "detection_indices", "=", "np", ".", "arange", "(", "len", "(", "detections", ")", ")", "\n", "\n", "", "cost_matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "track_indices", ")", ",", "len", "(", "detection_indices", ")", ")", ")", "\n", "for", "row", ",", "track_idx", "in", "enumerate", "(", "track_indices", ")", ":", "\n", "        ", "if", "tracks", "[", "track_idx", "]", ".", "time_since_update", ">", "1", ":", "\n", "            ", "cost_matrix", "[", "row", ",", ":", "]", "=", "linear_assignment", ".", "INFTY_COST", "\n", "continue", "\n", "\n", "", "bbox", "=", "tracks", "[", "track_idx", "]", ".", "to_tlwh", "(", ")", "\n", "candidates", "=", "np", ".", "asarray", "(", "[", "detections", "[", "i", "]", ".", "tlwh", "for", "i", "in", "detection_indices", "]", ")", "\n", "cost_matrix", "[", "row", ",", ":", "]", "=", "1.", "-", "iou", "(", "bbox", ",", "candidates", ")", "\n", "", "return", "cost_matrix", "\n", "", ""]]}