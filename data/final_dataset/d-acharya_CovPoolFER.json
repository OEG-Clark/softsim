{"home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolTrain.main": [[51, 189], ["datetime.datetime.strftime", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.random.seed", "random.seed", "tempPoolFramework.get_video_dataset", "len", "print", "print", "tf.Session.close", "datetime.datetime.now", "os.path.expanduser", "os.path.expanduser", "os.path.isdir", "os.path.isdir", "os.makedirs", "os.makedirs", "os.path.expanduser", "os.path.expanduser", "os.path.isdir", "os.path.isdir", "os.makedirs", "os.makedirs", "os.path.expanduser", "os.path.expanduser", "print", "tensorflow.Graph().as_default", "tensorflow.set_random_seed", "tensorflow.Variable", "tempPoolFramework.get_video_paths_and_labels", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.train.range_input_producer", "tf.train.range_input_producer.dequeue_many", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.python.ops.data_flow_ops.FIFOQueue", "data_flow_ops.FIFOQueue.enqueue_many", "range", "tensorflow.train.batch_join", "print", "tensorflow.reshape", "tensorflow.identity", "tensorflow.identity", "tensorflow.identity", "print", "print", "print", "tempPoolNetwork.inference", "tensorflow.fully_connected", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.add_to_collection", "tensorflow.get_collection", "tensorflow.add_n", "tempPoolFramework.trainspd", "tensorflow.train.Saver", "tensorflow.summary.merge_all", "tensorflow.GPUOptions", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "tensorflow.summary.FileWriter", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "len", "tensorflow.python.ops.array_ops.shape", "data_flow_ops.FIFOQueue.dequeue", "tensorflow.unstack", "videos_and_labels.append", "tensorflow.shape", "len", "tempPoolFramework.center_loss", "tensorflow.add_to_collection", "tensorflow.global_variables", "tensorflow.trainable_variables", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tf.Session.as_default", "print", "tensorflow.Graph", "tensorflow.py_func", "tf.py_func.set_shape", "cov_matrices.append", "len", "tensorflow.truncated_normal_initializer", "tensorflow.l2_regularizer", "print", "tf.train.Saver.restore", "tf.Session.run", "tempPoolTrain.train", "tempPoolTrain.save_variables_and_metagraph"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_video_dataset", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_video_paths_and_labels", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2.inference", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.trainspd", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.center_loss", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.train", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.save_variables_and_metagraph"], ["def", "main", "(", "args", ")", ":", "\n", "\t", "subdir", "=", "datetime", ".", "strftime", "(", "datetime", ".", "now", "(", ")", ",", "'%Y%m%d-%H%M%S'", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "args", ".", "logs_base_dir", ")", ",", "subdir", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "log_dir", ")", ":", "# Create the log directory if it doesn't exist", "\n", "\t\t", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "", "model_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "args", ".", "models_base_dir", ")", ",", "subdir", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "model_dir", ")", ":", "# Create the model directory if it doesn't exist", "\n", "\t\t", "os", ".", "makedirs", "(", "model_dir", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", "=", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "train_set", "=", "tempPoolFramework", ".", "get_video_dataset", "(", "args", ".", "data_dir", ")", "\n", "nrof_classes", "=", "len", "(", "train_set", ")", "\n", "print", "(", "'Model directory: %s'", "%", "model_dir", ")", "\n", "print", "(", "'Log directory: %s'", "%", "log_dir", ")", "\n", "\n", "pretrained_model", "=", "None", "\n", "if", "args", ".", "pretrained_model", ":", "\n", "\t\t", "pretrained_model", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "pretrained_model", ")", "\n", "print", "(", "'Pre-trained model: %s'", "%", "pretrained_model", ")", "\n", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "\t\t", "tf", ".", "set_random_seed", "(", "args", ".", "seed", ")", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "\n", "# Get a list of video paths and their labels", "\n", "vid_list", ",", "label_list", "=", "tempPoolFramework", ".", "get_video_paths_and_labels", "(", "train_set", ")", "\n", "assert", "len", "(", "vid_list", ")", ">", "0", ",", "'The dataset should not be empty'", "\n", "# Create a queue that produces indices into the video_list and label_list ", "\n", "labels", "=", "ops", ".", "convert_to_tensor", "(", "label_list", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "range_size", "=", "array_ops", ".", "shape", "(", "labels", ")", "[", "0", "]", "\n", "index_queue", "=", "tf", ".", "train", ".", "range_input_producer", "(", "range_size", ",", "num_epochs", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "seed", "=", "None", ",", "capacity", "=", "32", ")", "\n", "\n", "index_dequeue_op", "=", "index_queue", ".", "dequeue_many", "(", "args", ".", "batch_size", "*", "args", ".", "epoch_size", ",", "'index_dequeue'", ")", "\n", "\n", "learning_rate_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'learning_rate'", ")", "\n", "\n", "batch_size_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "name", "=", "'batch_size'", ")", "\n", "\n", "phase_train_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "name", "=", "'phase_train'", ")", "\n", "\n", "video_paths_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'video_paths'", ")", "\n", "\n", "labels_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "int64", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'labels'", ")", "\n", "\n", "input_queue", "=", "data_flow_ops", ".", "FIFOQueue", "(", "capacity", "=", "100000", ",", "\n", "dtypes", "=", "[", "tf", ".", "string", ",", "tf", ".", "int64", "]", ",", "\n", "shapes", "=", "[", "(", "1", ",", ")", ",", "(", "1", ",", ")", "]", ",", "\n", "shared_name", "=", "None", ",", "name", "=", "None", ")", "\n", "enqueue_op", "=", "input_queue", ".", "enqueue_many", "(", "[", "video_paths_placeholder", ",", "labels_placeholder", "]", ",", "name", "=", "'enqueue_op'", ")", "\n", "nrof_preprocess_threads", "=", "4", "\n", "videos_and_labels", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "nrof_preprocess_threads", ")", ":", "\n", "\t\t\t", "foldernames", ",", "label", "=", "input_queue", ".", "dequeue", "(", ")", "\n", "cov_matrices", "=", "[", "]", "\n", "for", "foldername", "in", "tf", ".", "unstack", "(", "foldernames", ")", ":", "\n", "\t\t\t\t", "cov_mat", "=", "tf", ".", "py_func", "(", "tempPoolFramework", ".", "compute_cov_matrix_from_csv_np", ",", "[", "foldername", "]", ",", "tf", ".", "float32", ")", "\n", "cov_mat", ".", "set_shape", "(", "(", "128", ",", "128", ")", ")", "\n", "cov_matrices", ".", "append", "(", "cov_mat", ")", "\n", "", "videos_and_labels", ".", "append", "(", "[", "cov_matrices", ",", "label", "]", ")", "\n", "\n", "", "video_batch", ",", "label_batch", "=", "tf", ".", "train", ".", "batch_join", "(", "\n", "# get batch", "\n", "videos_and_labels", ",", "batch_size", "=", "batch_size_placeholder", ",", "\n", "shapes", "=", "[", "(", "128", ",", "128", ")", ",", "(", ")", "]", ",", "enqueue_many", "=", "True", ",", "\n", "capacity", "=", "4", "*", "nrof_preprocess_threads", "*", "args", ".", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "False", ")", "\n", "print", "(", "tf", ".", "shape", "(", "video_batch", ")", ")", "\n", "video_batch", "=", "tf", ".", "reshape", "(", "video_batch", ",", "[", "args", ".", "batch_size", ",", "128", ",", "128", "]", ")", "\n", "video_batch", "=", "tf", ".", "identity", "(", "video_batch", ",", "'video_batch'", ")", "\n", "video_batch", "=", "tf", ".", "identity", "(", "video_batch", ",", "'input'", ")", "\n", "label_batch", "=", "tf", ".", "identity", "(", "label_batch", ",", "'label_batch'", ")", "\n", "\n", "print", "(", "'Total number of classes: %d'", "%", "nrof_classes", ")", "\n", "print", "(", "'Total number of examples: %d'", "%", "len", "(", "vid_list", ")", ")", "\n", "\n", "print", "(", "'Building training graph'", ")", "\n", "prelogits", "=", "tempPoolNetwork", ".", "inference", "(", "video_batch", ",", "phase_train", "=", "phase_train_placeholder", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "batch_size", "=", "args", ".", "batch_size", ")", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "prelogits", ",", "len", "(", "train_set", ")", ",", "activation_fn", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "args", ".", "weight_decay", ")", ",", "\n", "scope", "=", "'Logits'", ",", "reuse", "=", "False", ")", "\n", "\n", "#Add center loss", "\n", "if", "args", ".", "center_loss_factor", ">", "0.0", ":", "\n", "\t\t\t", "prelogits_center_loss", ",", "_", "=", "tempPoolFramework", ".", "center_loss", "(", "prelogits", ",", "label_batch", ",", "args", ".", "center_loss_alfa", ",", "nrof_classes", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ",", "prelogits_center_loss", "*", "args", ".", "center_loss_factor", ")", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "learning_rate_placeholder", ",", "global_step", ",", "\n", "args", ".", "learning_rate_decay_epochs", "*", "args", ".", "epoch_size", ",", "args", ".", "learning_rate_decay_factor", ",", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "# Calculate the average cross entropy loss across the batch", "\n", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "label_batch", ",", "logits", "=", "logits", ",", "name", "=", "'cross_entropy_per_example'", ")", "\n", "cross_entropy_mean", "=", "tf", ".", "reduce_mean", "(", "cross_entropy", ",", "name", "=", "'cross_entropy'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "cross_entropy_mean", ")", "\n", "\n", "\n", "# Calculate the total losses", "\n", "regularization_losses", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "total_loss", "=", "tf", ".", "add_n", "(", "[", "cross_entropy_mean", "]", "+", "regularization_losses", ",", "name", "=", "'total_loss'", ")", "\n", "# Build a Graph that trains the model with one batch of examples and updates the model parameters", "\n", "train_op", ",", "redun", "=", "tempPoolFramework", ".", "trainspd", "(", "total_loss", ",", "global_step", ",", "args", ".", "optimizer", ",", "\n", "learning_rate", ",", "args", ".", "moving_average_decay", ",", "tf", ".", "global_variables", "(", ")", ")", "\n", "\n", "# Create a saver", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "max_to_keep", "=", "3", ")", "\n", "\n", "# Build the summary operation based on the TF collection of Summaries.", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "# Start running operations on the Graph.", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "args", ".", "gpu_memory_fraction", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", ",", "sess", ".", "graph", ")", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "tf", ".", "train", ".", "start_queue_runners", "(", "coord", "=", "coord", ",", "sess", "=", "sess", ")", "\n", "\n", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "\t\t\t", "if", "pretrained_model", ":", "\n", "\t\t\t\t", "print", "(", "'Restoring pretrained model: %s'", "%", "pretrained_model", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "pretrained_model", ")", "\n", "", "print", "(", "'Running training'", ")", "\n", "epoch", "=", "0", "\n", "while", "epoch", "<", "args", ".", "max_nrof_epochs", ":", "\n", "\t\t\t\t", "step", "=", "sess", ".", "run", "(", "global_step", ",", "feed_dict", "=", "None", ")", "\n", "epoch", "=", "step", "//", "args", ".", "epoch_size", "\n", "# Train for one epoch", "\n", "train", "(", "args", ",", "sess", ",", "epoch", ",", "vid_list", ",", "label_list", ",", "index_dequeue_op", ",", "enqueue_op", ",", "video_paths_placeholder", ",", "labels_placeholder", ",", "\n", "learning_rate_placeholder", ",", "phase_train_placeholder", ",", "batch_size_placeholder", ",", "global_step", ",", "\n", "total_loss", ",", "train_op", ",", "redun", ",", "summary_op", ",", "summary_writer", ",", "regularization_losses", ",", "args", ".", "learning_rate_schedule_file", ")", "\n", "save_variables_and_metagraph", "(", "sess", ",", "saver", ",", "summary_writer", ",", "model_dir", ",", "subdir", ",", "step", ")", "\n", "", "", "", "sess", ".", "close", "(", ")", "\n", "return", "model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolTrain.train": [[190, 230], ["sess.run", "numpy.expand_dims", "numpy.expand_dims", "sess.run", "tensorflow.Summary", "tf.Summary.value.add", "summary_writer.add_summary", "tempPoolFramework.get_learning_rate_from_file", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "time.time", "print", "sess.run", "summary_writer.add_summary", "sess.run", "time.time", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_learning_rate_from_file"], ["", "def", "train", "(", "args", ",", "sess", ",", "epoch", ",", "video_list", ",", "label_list", ",", "index_dequeue_op", ",", "enqueue_op", ",", "video_paths_placeholder", ",", "labels_placeholder", ",", "\n", "learning_rate_placeholder", ",", "phase_train_placeholder", ",", "batch_size_placeholder", ",", "global_step", ",", "\n", "loss", ",", "train_op", ",", "redun", ",", "summary_op", ",", "summary_writer", ",", "regularization_losses", ",", "learning_rate_schedule_file", ")", ":", "\n", "\t", "batch_number", "=", "0", "\n", "\n", "if", "args", ".", "learning_rate", ">", "0.0", ":", "\n", "\t\t", "lr", "=", "args", ".", "learning_rate", "\n", "", "else", ":", "\n", "\t\t", "lr", "=", "tempPoolFramework", ".", "get_learning_rate_from_file", "(", "learning_rate_schedule_file", ",", "epoch", ")", "\n", "\n", "", "index_epoch", "=", "sess", ".", "run", "(", "index_dequeue_op", ")", "\n", "label_epoch", "=", "np", ".", "array", "(", "label_list", ")", "[", "index_epoch", "]", "\n", "video_epoch", "=", "np", ".", "array", "(", "video_list", ")", "[", "index_epoch", "]", "\n", "\n", "# Enqueue one epoch of video paths and labels", "\n", "labels_array", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "label_epoch", ")", ",", "1", ")", "\n", "video_paths_array", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "video_epoch", ")", ",", "1", ")", "\n", "sess", ".", "run", "(", "enqueue_op", ",", "{", "video_paths_placeholder", ":", "video_paths_array", ",", "labels_placeholder", ":", "labels_array", "}", ")", "\n", "\n", "# Training loop", "\n", "train_time", "=", "0", "\n", "while", "batch_number", "<", "args", ".", "epoch_size", ":", "\n", "\t\t", "start_time", "=", "time", ".", "time", "(", ")", "\n", "feed_dict", "=", "{", "learning_rate_placeholder", ":", "lr", ",", "phase_train_placeholder", ":", "True", ",", "batch_size_placeholder", ":", "args", ".", "batch_size", "}", "\n", "if", "(", "batch_number", "%", "100", "==", "0", ")", ":", "\n", "\t\t\t", "err", ",", "_", ",", "_", ",", "step", ",", "reg_loss", ",", "summary_str", "=", "sess", ".", "run", "(", "[", "loss", ",", "train_op", ",", "redun", ",", "global_step", ",", "regularization_losses", ",", "summary_op", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary_str", ",", "global_step", "=", "step", ")", "\n", "", "else", ":", "\n", "\t\t\t", "err", ",", "_", ",", "_", ",", "step", ",", "reg_loss", "=", "sess", ".", "run", "(", "[", "loss", ",", "train_op", ",", "redun", ",", "global_step", ",", "regularization_losses", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'Epoch: [%d][%d/%d]\\tTime %.3f\\tLoss %2.3f\\tRegLoss %2.3f'", "%", "\n", "(", "epoch", ",", "batch_number", "+", "1", ",", "args", ".", "epoch_size", ",", "duration", ",", "err", ",", "np", ".", "sum", "(", "reg_loss", ")", ")", ")", "\n", "batch_number", "+=", "1", "\n", "train_time", "+=", "duration", "\n", "# Add validation loss and accuracy to summary", "\n", "", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "#pylint: disable=maybe-no-member", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'time/total'", ",", "simple_value", "=", "train_time", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolTrain.save_variables_and_metagraph": [[231, 252], ["print", "time.time", "os.path.join", "os.path.join", "saver.save", "print", "os.path.join", "os.path.join", "tensorflow.Summary", "tf.Summary.value.add", "tf.Summary.value.add", "summary_writer.add_summary", "time.time", "os.path.exists", "os.path.exists", "print", "time.time", "saver.export_meta_graph", "print", "time.time"], "function", ["None"], ["", "def", "save_variables_and_metagraph", "(", "sess", ",", "saver", ",", "summary_writer", ",", "model_dir", ",", "model_name", ",", "step", ")", ":", "\n", "# Save the model checkpoint", "\n", "\t", "print", "(", "'Saving variables'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'model-%s.ckpt'", "%", "model_name", ")", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ",", "global_step", "=", "step", ",", "write_meta_graph", "=", "False", ")", "\n", "save_time_variables", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'Variables saved in %.2f seconds'", "%", "save_time_variables", ")", "\n", "metagraph_filename", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'model-%s.meta'", "%", "model_name", ")", "\n", "save_time_metagraph", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "metagraph_filename", ")", ":", "\n", "\t\t", "print", "(", "'Saving metagraph'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "saver", ".", "export_meta_graph", "(", "metagraph_filename", ")", "\n", "save_time_metagraph", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'Metagraph saved in %.2f seconds'", "%", "save_time_metagraph", ")", "\n", "", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "#pylint: disable=maybe-no-member", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'time/save_variables'", ",", "simple_value", "=", "save_time_variables", ")", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'time/save_metagraph'", ",", "simple_value", "=", "save_time_metagraph", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolTrain.parse_arguments": [[253, 294], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "parse_arguments", "(", "argv", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--logs_base_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory where to write event logs.'", ",", "default", "=", "'~/logs/temporalPoolFramework'", ")", "\n", "parser", ".", "add_argument", "(", "'--models_base_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory where to write trained models and checkpoints.'", ",", "default", "=", "'~/models/tempPoolFramework'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_memory_fraction'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Upper bound on the amount of GPU memory that will be used by the process.'", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_model'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Load a pretrained model before training starts.'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to the data directory containing aligned face patches. Multiple directories are separated with colon.'", ",", "\n", "default", "=", "'~/datasets/afew_128'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_nrof_epochs'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of epochs to run.'", ",", "default", "=", "400", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of videos to process in a batch.'", ",", "default", "=", "90", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of batches per epoch.'", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--center_loss_factor'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Center loss factor.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--center_loss_alfa'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Center update rate for center loss.'", ",", "default", "=", "0.95", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "choices", "=", "[", "'ADAGRAD'", ",", "'ADADELTA'", ",", "'ADAM'", ",", "'RMSPROP'", ",", "'MOM'", "]", ",", "\n", "help", "=", "'The optimization algorithm to use'", ",", "default", "=", "'ADAGRAD'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Initial learning rate. If set to a negative value a learning rate '", "+", "\n", "'schedule can be specified in the file \"learning_rate_schedule.txt\"'", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "\n", "help", "=", "'L2 weight regularization.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_factor'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Learning rate decay factor.'", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_epochs'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of epochs between learning rate decay.'", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--moving_average_decay'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Exponential decay for tracking of training parameters.'", ",", "default", "=", "0.9999", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Random seed.'", ",", "default", "=", "666", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_schedule_file'", ",", "type", "=", "str", ",", "\n", "help", "=", "'File containing the learning rate schedule that is used when learning_rate is set to to -1.'", ",", "default", "=", "'data/learning_rate_schedule.txt'", ")", "\n", "return", "parser", ".", "parse_args", "(", "argv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.softmaxClassifier.compute_cov_matrix": [[40, 46], ["video_path.split", "numpy.load", "tempPoolFramework.cov_computation", "os.path.join"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.cov_computation"], ["def", "compute_cov_matrix", "(", "video_path", ")", ":", "\n", "    ", "video_path_split", "=", "video_path", ".", "split", "(", "'/'", ")", "\n", "video_path_split", "=", "video_path_split", "[", "-", "1", "]", "\n", "array", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "video_path", ",", "video_path_split", "+", "'.npy'", ")", ")", "\n", "feature_list", "=", "array", "\n", "return", "tempPoolFramework", ".", "cov_computation", "(", "feature_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.softmaxClassifier.main": [[47, 128], ["tensorflow.Graph().as_default", "tensorflow.Session", "numpy.random.seed", "tempPoolFramework.get_video_dataset", "tempPoolFramework.get_video_paths_and_labels", "print", "print", "print", "tempPoolFramework.load_model", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.nn.softmax", "print", "len", "int", "numpy.zeros", "numpy.zeros", "range", "print", "print", "numpy.mean", "print", "print", "numpy.set_printoptions", "numpy.unique", "numpy.zeros", "numpy.zeros", "range", "print", "range", "tensorflow.Graph", "cls.name.replace", "tf.get_default_graph().get_tensor_by_name.get_shape", "math.ceil", "min", "numpy.zeros", "sess.run", "numpy.argmax", "numpy.equal", "len", "len", "len", "len", "print", "len", "len", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "paths_batch.extend", "softmaxClassifier.compute_cov_matrix", "numpy.equal", "float", "float"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_video_dataset", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_video_paths_and_labels", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.load_model", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.softmaxClassifier.compute_cov_matrix"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "            ", "np", ".", "random", ".", "seed", "(", "seed", "=", "args", ".", "seed", ")", "\n", "\n", "dataset", "=", "tempPoolFramework", ".", "get_video_dataset", "(", "args", ".", "data_dir", ")", "\n", "class_names", "=", "[", "cls", ".", "name", ".", "replace", "(", "'_'", ",", "' '", ")", "for", "cls", "in", "dataset", "]", "\n", "paths", ",", "labels", "=", "tempPoolFramework", ".", "get_video_paths_and_labels", "(", "dataset", ")", "\n", "\n", "print", "(", "'Number of classes: %d'", "%", "len", "(", "dataset", ")", ")", "\n", "print", "(", "'Number of videos: %d'", "%", "len", "(", "paths", ")", ")", "\n", "\n", "# Load the model", "\n", "print", "(", "'Loading feature extraction model'", ")", "\n", "tempPoolFramework", ".", "load_model", "(", "args", ".", "model", ")", "\n", "\n", "# Get input and output tensors", "\n", "cov_placeholder", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\"input:0\"", ")", "\n", "logits", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\"Logits/BiasAdd:0\"", ")", "\n", "phase_train_placeholder", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\"phase_train:0\"", ")", "\n", "logit_size", "=", "logits", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "prediction", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "# Run forward pass to calculate embeddings", "\n", "print", "(", "'Calculating features for videos'", ")", "\n", "nrof_videos", "=", "len", "(", "paths", ")", "\n", "nrof_batches_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "1.0", "*", "nrof_videos", "/", "args", ".", "batch_size", ")", ")", "\n", "emb_array", "=", "np", ".", "zeros", "(", "(", "nrof_videos", ",", "logit_size", ")", ")", "\n", "count", "=", "0", "\n", "best_class_indices", "=", "np", ".", "zeros", "(", "(", "nrof_videos", ")", ")", "\n", "for", "i", "in", "range", "(", "nrof_batches_per_epoch", ")", ":", "\n", "                ", "start_index", "=", "i", "*", "args", ".", "batch_size", "\n", "end_index", "=", "min", "(", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", "nrof_videos", ")", "\n", "count", "=", "count", "+", "(", "end_index", "-", "start_index", ")", "\n", "paths_batch", "=", "paths", "[", "start_index", ":", "end_index", "]", "\n", "if", "(", "end_index", "-", "start_index", ")", "!=", "args", ".", "batch_size", ":", "\n", "                    ", "paths_batch", ".", "extend", "(", "paths", "[", "0", ":", "(", "args", ".", "batch_size", "-", "(", "end_index", "-", "start_index", ")", ")", "]", ")", "\n", "#print(paths_batch)", "\n", "", "cov_matrices", "=", "np", ".", "zeros", "(", "(", "args", ".", "batch_size", ",", "128", ",", "128", ")", ")", "\n", "fc", "=", "0", "\n", "for", "filename", "in", "paths_batch", ":", "\n", "                    ", "cov_matrices", "[", "fc", ",", ":", ",", ":", "]", "=", "compute_cov_matrix", "(", "filename", ")", "\n", "fc", "=", "fc", "+", "1", "\n", "", "feed_dict", "=", "{", "cov_placeholder", ":", "cov_matrices", ",", "phase_train_placeholder", ":", "False", "}", "\n", "arr", "=", "sess", ".", "run", "(", "prediction", ",", "feed_dict", "=", "feed_dict", ")", "\n", "if", "(", "end_index", "-", "start_index", ")", "!=", "args", ".", "batch_size", ":", "\n", "                    ", "arr", "=", "arr", "[", "0", ":", "end_index", "-", "start_index", "]", "\n", "", "best_class_indices", "[", "start_index", ":", "end_index", "]", "=", "np", ".", "argmax", "(", "arr", ",", "axis", "=", "1", ")", "\n", "\n", "", "print", "(", "\"Samples considered: {}. Total Videos: {}\"", ".", "format", "(", "count", ",", "nrof_videos", ")", ")", "\n", "\n", "# Classify extracted features", "\n", "print", "(", "'Testing classifier'", ")", "\n", "accuracy", "=", "np", ".", "mean", "(", "np", ".", "equal", "(", "best_class_indices", ",", "labels", ")", ")", "\n", "print", "(", "'Total Accuracy: %.3f%%'", "%", "(", "accuracy", "*", "100.0", ")", ")", "\n", "\n", "# normalized accuracy (on face detection by MTCNN)", "\n", "# 383 is total videos in afew validation set", "\n", "norm_acc", "=", "(", "(", "100.0", "*", "accuracy", "*", "float", "(", "nrof_videos", ")", ")", "+", "(", "1.0", "/", "7.0", ")", "*", "(", "383.", "-", "float", "(", "nrof_videos", ")", ")", ")", "/", "383.0", "\n", "print", "(", "'Total Accuracy accounting for face detection failure: %.3f%%'", "%", "(", "norm_acc", ")", ")", "\n", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "2", ")", "\n", "# compute accuracy for each class:", "\n", "classes", "=", "np", ".", "unique", "(", "labels", ")", "\n", "classes", "=", "np", ".", "zeros", "(", "len", "(", "classes", ")", ")", "\n", "classCount", "=", "np", ".", "zeros", "(", "len", "(", "classes", ")", ")", "\n", "tCount", "=", "0", "\n", "for", "i", "in", "labels", ":", "\n", "                ", "classes", "[", "i", "]", "=", "classes", "[", "i", "]", "+", "np", ".", "equal", "(", "best_class_indices", "[", "tCount", "]", ",", "i", ")", "\n", "tCount", "=", "tCount", "+", "1", "\n", "classCount", "[", "i", "]", "=", "classCount", "[", "i", "]", "+", "1", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "classCount", ")", ")", ":", "\n", "                ", "classes", "[", "i", "]", "=", "classes", "[", "i", "]", "/", "classCount", "[", "i", "]", "\n", "", "print", "(", "'Per Class Accuracy: '", ")", "\n", "accuracy", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "classCount", ")", ")", ":", "\n", "                ", "print", "(", "'Accuracy of {} {}%'", ".", "format", "(", "class_names", "[", "i", "]", ",", "100", "*", "classes", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.softmaxClassifier.parse_arguments": [[130, 143], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "", "", "def", "parse_arguments", "(", "argv", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'data_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to the data directory containing aligned AFEW face patches.'", ")", "\n", "parser", ".", "add_argument", "(", "'model'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of videos to process in a batch.'", ",", "default", "=", "90", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Random seed.'", ",", "default", "=", "666", ")", "\n", "parser", ".", "add_argument", "(", "'--min_nrof_videos_per_class'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Only include classes with at least this number of videos in the dataset'", ",", "default", "=", "20", ")", "\n", "return", "parser", ".", "parse_args", "(", "argv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.VideoClass.__init__": [[218, 221], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "video_paths", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "video_paths", "=", "video_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.VideoClass.__str__": [[222, 224], ["str", "len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "+", "', '", "+", "str", "(", "len", "(", "self", ".", "video_paths", ")", ")", "+", "' videos'", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.VideoClass.__len__": [[225, 227], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "video_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.compute_cov_matrix_from_csv_np": [[40, 63], ["video_path.decode().split", "numpy.load", "min", "random.randint", "tempPoolFramework.cov_computation", "os.path.join", "numpy.shape", "range", "video_path.decode", "video_path.decode", "max", "random.sample", "max", "numpy.int32", "random.randint", "range", "numpy.int32", "range", "numpy.int32", "numpy.ceil"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.cov_computation"], ["def", "compute_cov_matrix_from_csv_np", "(", "video_path", ")", ":", "\n", "    ", "video_path_split", "=", "video_path", ".", "decode", "(", ")", ".", "split", "(", "'/'", ")", "\n", "video_path_split", "=", "video_path_split", "[", "-", "1", "]", "\n", "array", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "video_path", ".", "decode", "(", ")", ",", "video_path_split", "+", "'.npy'", ")", ")", "\n", "size", "=", "np", ".", "shape", "(", "array", ")", "[", "0", "]", "\n", "# either select all frames, ", "\n", "# or select 60% frames randomly or centered at center", "\n", "min_len", "=", "min", "(", "size", ",", "10", ")", "\n", "ratio", "=", ".6", "\n", "r", "=", "random", ".", "randint", "(", "0", ",", "2", ")", "\n", "if", "r", "==", "0", ":", "\n", "        ", "subset_index", "=", "range", "(", "0", ",", "size", ")", "\n", "", "elif", "r", "==", "1", ":", "\n", "        ", "subset_size", "=", "max", "(", "np", ".", "int32", "(", "ratio", "*", "size", ")", ",", "min_len", ")", "\n", "subset_index", "=", "random", ".", "sample", "(", "range", "(", "0", ",", "size", ")", ",", "subset_size", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "subset_size", "=", "max", "(", "np", ".", "int32", "(", "ratio", "*", "size", ")", ",", "min_len", ")", "\n", "origin_of_subclip", "=", "np", ".", "int32", "(", "np", ".", "ceil", "(", "size", "/", "2", "-", "subset_size", "/", "2", ")", ")", "\n", "noise", "=", "random", ".", "randint", "(", "-", "origin_of_subclip", ",", "origin_of_subclip", ")", "\n", "perturbed_origin", "=", "origin_of_subclip", "+", "noise", "\n", "subset_index", "=", "range", "(", "perturbed_origin", ",", "perturbed_origin", "+", "subset_size", "-", "1", ")", "\n", "", "feature_list", "=", "[", "array", "[", "i", "]", "for", "i", "in", "subset_index", "]", "\n", "return", "cov_computation", "(", "feature_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.cov_computation": [[64, 77], ["numpy.shape", "numpy.mean", "numpy.subtract", "numpy.transpose", "numpy.trace", "numpy.tile", "numpy.add", "ret.astype.astype", "numpy.matmul", "numpy.diag"], "function", ["None"], ["", "def", "cov_computation", "(", "feature_list", ")", ":", "\n", "    ", "features", "=", "feature_list", "\n", "shape_", "=", "np", ".", "shape", "(", "features", ")", "\n", "centers", "=", "np", ".", "mean", "(", "features", ",", "axis", "=", "0", ")", "\n", "tmp", "=", "np", ".", "subtract", "(", "features", ",", "centers", ")", "\n", "tmp_t", "=", "np", ".", "transpose", "(", "tmp", ")", "\n", "features_t", "=", "1.", "/", "(", "shape_", "[", "0", "]", "-", "1.", ")", "*", "np", ".", "matmul", "(", "tmp_t", ",", "tmp", ")", "\n", "trace_t", "=", "np", ".", "trace", "(", "features_t", ")", "\n", "trace_t", "=", "np", ".", "tile", "(", "trace_t", ",", "[", "shape_", "[", "1", "]", "]", ")", "\n", "trace_t", "=", "1e-3", "*", "np", ".", "diag", "(", "trace_t", ")", "\n", "ret", "=", "np", ".", "add", "(", "features_t", ",", "trace_t", ")", "\n", "ret", "=", "ret", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.center_loss": [[103, 116], ["tensorflow.get_variable", "tensorflow.reshape", "tensorflow.gather", "tensorflow.scatter_sub", "tensorflow.reduce_mean", "features.get_shape", "tensorflow.square", "tensorflow.constant_initializer"], "function", ["None"], ["def", "center_loss", "(", "features", ",", "label", ",", "alfa", ",", "nrof_classes", ")", ":", "\n", "    ", "\"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\n       (http://ydwen.github.io/papers/WenECCV16.pdf)\n    \"\"\"", "\n", "nrof_features", "=", "features", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "centers", "=", "tf", ".", "get_variable", "(", "'centers'", ",", "[", "nrof_classes", ",", "nrof_features", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "trainable", "=", "False", ")", "\n", "label", "=", "tf", ".", "reshape", "(", "label", ",", "[", "-", "1", "]", ")", "\n", "centers_batch", "=", "tf", ".", "gather", "(", "centers", ",", "label", ")", "\n", "diff", "=", "(", "1", "-", "alfa", ")", "*", "(", "centers_batch", "-", "features", ")", "\n", "centers", "=", "tf", ".", "scatter_sub", "(", "centers", ",", "label", ",", "diff", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "features", "-", "centers_batch", ")", ")", "\n", "return", "loss", ",", "centers", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework._add_loss_summaries": [[117, 142], ["tensorflow.train.ExponentialMovingAverage", "tensorflow.get_collection", "tf.train.ExponentialMovingAverage.apply", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tf.train.ExponentialMovingAverage.average"], "function", ["None"], ["", "def", "_add_loss_summaries", "(", "total_loss", ")", ":", "\n", "    ", "\"\"\"Add summaries for losses.\n  \n    Generates moving average for all losses and associated summaries for\n    visualizing the performance of the network.\n  \n    Args:\n      total_loss: Total loss from loss().\n    Returns:\n      loss_averages_op: op for generating moving averages of losses.\n    \"\"\"", "\n", "# Compute the moving average of all individual losses and the total loss.", "\n", "loss_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "0.9", ",", "name", "=", "'avg'", ")", "\n", "losses", "=", "tf", ".", "get_collection", "(", "'losses'", ")", "\n", "loss_averages_op", "=", "loss_averages", ".", "apply", "(", "losses", "+", "[", "total_loss", "]", ")", "\n", "\n", "# Attach a scalar summmary to all individual losses and the total loss; do the", "\n", "# same for the averaged version of the losses.", "\n", "for", "l", "in", "losses", "+", "[", "total_loss", "]", ":", "\n", "# Name each loss as '(raw)' and name the moving average version of the loss", "\n", "# as the original loss name.", "\n", "        ", "tf", ".", "summary", ".", "scalar", "(", "l", ".", "op", ".", "name", "+", "' (raw)'", ",", "l", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "l", ".", "op", ".", "name", ",", "loss_averages", ".", "average", "(", "l", ")", ")", "\n", "\n", "", "return", "loss_averages_op", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.trainspd": [[143, 202], ["tempPoolFramework._add_loss_summaries", "enumerate", "tf.train.MomentumOptimizer.apply_gradients", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.control_dependencies", "tf.train.MomentumOptimizer.compute_gradients", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.train.AdagradOptimizer", "tensorflow.matmul", "tensorflow.qr", "tensorflow.summary.histogram", "tensorflow.train.AdadeltaOptimizer", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.summary.histogram", "tensorflow.train.AdamOptimizer", "tensorflow.transpose", "var.assign", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.MomentumOptimizer", "ValueError"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework._add_loss_summaries"], ["", "def", "trainspd", "(", "total_loss", ",", "global_step", ",", "optimizer", ",", "learning_rate", ",", "moving_average_decay", ",", "update_gradient_vars", ",", "log_histograms", "=", "True", ")", ":", "\n", "# Generate moving averages of all losses and associated summaries.", "\n", "    ", "loss_averages_op", "=", "_add_loss_summaries", "(", "total_loss", ")", "\n", "# Compute gradients.", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "loss_averages_op", "]", ")", ":", "\n", "        ", "if", "optimizer", "==", "'ADAGRAD'", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdagradOptimizer", "(", "learning_rate", ")", "\n", "", "elif", "optimizer", "==", "'ADADELTA'", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdadeltaOptimizer", "(", "learning_rate", ",", "rho", "=", "0.9", ",", "epsilon", "=", "1e-6", ")", "\n", "", "elif", "optimizer", "==", "'ADAM'", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "0.1", ")", "\n", "", "elif", "optimizer", "==", "'RMSPROP'", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", ",", "decay", "=", "0.9", ",", "momentum", "=", "0.9", ",", "epsilon", "=", "1.0", ")", "\n", "", "elif", "optimizer", "==", "'MOM'", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", ",", "0.9", ",", "use_nesterov", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid optimization algorithm'", ")", "\n", "", "grads", "=", "opt", ".", "compute_gradients", "(", "total_loss", ",", "update_gradient_vars", ")", "\n", "\n", "", "for", "idx", ",", "(", "egrad", ",", "var", ")", "in", "enumerate", "(", "grads", ")", ":", "\n", "        ", "if", "'orth'", "in", "var", ".", "name", ":", "\n", "# print('var1.name:%s', var.name)", "\n", "#egrad=tf.Print(egrad,[egrad],'RGradient: Before'+var.name)", "\n", "            ", "tmp1", "=", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "var", ")", ",", "egrad", ")", "\n", "tmp2", "=", "0.5", "*", "(", "tmp1", "+", "tf", ".", "transpose", "(", "tmp1", ")", ")", "\n", "rgrad", "=", "egrad", "-", "tf", ".", "matmul", "(", "var", ",", "tmp2", ")", "\n", "#rgrad=tf.Print(rgrad,[rgrad],'RGradient: After'+var.name)", "\n", "grads", "[", "idx", "]", "=", "(", "rgrad", ",", "var", ")", "\n", "\n", "# Apply gradients.", "\n", "", "", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "grads", ",", "global_step", "=", "global_step", ")", "\n", "\n", "# stiefel update", "\n", "redun", "=", "0.", "\n", "for", "grad", ",", "var", "in", "grads", ":", "\n", "        ", "if", "'orth'", "in", "var", ".", "name", ":", "\n", "            ", "o_n", ",", "_", "=", "tf", ".", "qr", "(", "var", ")", "\n", "redun", "=", "redun", "+", "tf", ".", "reduce_sum", "(", "var", ".", "assign", "(", "o_n", ")", ",", "[", "0", ",", "1", "]", ")", "\n", "\n", "# Add histograms for trainable variables.", "\n", "", "", "if", "log_histograms", ":", "\n", "        ", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", ",", "var", ")", "\n", "\n", "# Add histograms for gradients.", "\n", "", "", "if", "log_histograms", ":", "\n", "        ", "for", "grad", ",", "var", "in", "grads", ":", "\n", "            ", "if", "grad", "is", "not", "None", ":", "\n", "                ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "'/gradients'", ",", "grad", ")", "\n", "\n", "# Track the moving averages of all trainable variables.", "\n", "", "", "", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "moving_average_decay", ",", "global_step", ")", "\n", "variables_averages_op", "=", "variable_averages", ".", "apply", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "apply_gradient_op", ",", "variables_averages_op", "]", ")", ":", "\n", "        ", "train_op", "=", "tf", ".", "no_op", "(", "name", "=", "'train'", ")", "\n", "\n", "", "return", "train_op", ",", "redun", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_learning_rate_from_file": [[203, 215], ["open", "f.readlines", "line.split", "line.strip().split", "int", "float", "line.strip"], "function", ["None"], ["", "def", "get_learning_rate_from_file", "(", "filename", ",", "epoch", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "split", "(", "'#'", ",", "1", ")", "[", "0", "]", "\n", "if", "line", ":", "\n", "                ", "par", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "e", "=", "int", "(", "par", "[", "0", "]", ")", "\n", "lr", "=", "float", "(", "par", "[", "1", "]", ")", "\n", "if", "e", "<=", "epoch", ":", "\n", "                    ", "learning_rate", "=", "lr", "\n", "", "else", ":", "\n", "                    ", "return", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_video_dataset": [[228, 244], ["paths.split", "os.path.expanduser", "os.listdir", "os.listdir.sort", "len", "range", "os.path.join", "os.path.isdir", "os.listdir", "dataset.append", "os.path.join", "tempPoolFramework.VideoClass", "os.path.isdir"], "function", ["None"], ["", "", "def", "get_video_dataset", "(", "paths", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "for", "path", "in", "paths", ".", "split", "(", "':'", ")", ":", "\n", "        ", "path_exp", "=", "os", ".", "path", ".", "expanduser", "(", "path", ")", "\n", "classes", "=", "os", ".", "listdir", "(", "path_exp", ")", "\n", "classes", ".", "sort", "(", ")", "\n", "nrof_classes", "=", "len", "(", "classes", ")", "\n", "for", "i", "in", "range", "(", "nrof_classes", ")", ":", "\n", "            ", "class_name", "=", "classes", "[", "i", "]", "\n", "facedir", "=", "os", ".", "path", ".", "join", "(", "path_exp", ",", "class_name", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "facedir", ")", ":", "\n", "                ", "videos", "=", "os", ".", "listdir", "(", "facedir", ")", "\n", "videos", "=", "[", "os", ".", "path", ".", "join", "(", "facedir", ",", "vid_name", ")", "for", "vid_name", "in", "videos", "]", "\n", "videos", "=", "[", "vid", "for", "vid", "in", "videos", "if", "os", ".", "path", ".", "isdir", "(", "vid", ")", "]", "\n", "dataset", ".", "append", "(", "VideoClass", "(", "class_name", ",", "videos", ")", ")", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_video_paths_and_labels": [[245, 252], ["range", "len", "len"], "function", ["None"], ["", "def", "get_video_paths_and_labels", "(", "dataset", ")", ":", "\n", "    ", "video_paths_flat", "=", "[", "]", "\n", "labels_flat", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "video_paths_flat", "+=", "dataset", "[", "i", "]", ".", "video_paths", "\n", "labels_flat", "+=", "[", "i", "]", "*", "len", "(", "dataset", "[", "i", "]", ".", "video_paths", ")", "\n", "", "return", "video_paths_flat", ",", "labels_flat", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.load_model": [[253, 272], ["os.path.expanduser", "os.path.isfile", "print", "print", "tempPoolFramework.get_model_filenames", "print", "print", "tensorflow.train.import_meta_graph", "tf.train.import_meta_graph.restore", "tensorflow.python.platform.gfile.FastGFile", "tensorflow.GraphDef", "tf.GraphDef.ParseFromString", "tensorflow.import_graph_def", "os.path.join", "tensorflow.get_default_session", "os.path.join", "f.read"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_model_filenames"], ["", "def", "load_model", "(", "model", ")", ":", "\n", "# Check if the model is a model directory (containing a metagraph and a checkpoint file)", "\n", "#  or if it is a protobuf file with a frozen graph", "\n", "    ", "model_exp", "=", "os", ".", "path", ".", "expanduser", "(", "model", ")", "\n", "if", "(", "os", ".", "path", ".", "isfile", "(", "model_exp", ")", ")", ":", "\n", "        ", "print", "(", "'Model filename: %s'", "%", "model_exp", ")", "\n", "with", "gfile", ".", "FastGFile", "(", "model_exp", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "graph_def", "=", "tf", ".", "GraphDef", "(", ")", "\n", "graph_def", ".", "ParseFromString", "(", "f", ".", "read", "(", ")", ")", "\n", "tf", ".", "import_graph_def", "(", "graph_def", ",", "name", "=", "''", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Model directory: %s'", "%", "model_exp", ")", "\n", "meta_file", ",", "ckpt_file", "=", "get_model_filenames", "(", "model_exp", ")", "\n", "\n", "print", "(", "'Metagraph file: %s'", "%", "meta_file", ")", "\n", "print", "(", "'Checkpoint file: %s'", "%", "ckpt_file", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "os", ".", "path", ".", "join", "(", "model_exp", ",", "meta_file", ")", ")", "\n", "saver", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "os", ".", "path", ".", "join", "(", "model_exp", ",", "ckpt_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_model_filenames": [[273, 291], ["os.listdir", "len", "ValueError", "re.match", "s.endswith", "len", "ValueError", "int", "len", "re.match.groups", "re.match.groups", "re.match.groups"], "function", ["None"], ["", "", "def", "get_model_filenames", "(", "model_dir", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "model_dir", ")", "\n", "meta_files", "=", "[", "s", "for", "s", "in", "files", "if", "s", ".", "endswith", "(", "'.meta'", ")", "]", "\n", "if", "len", "(", "meta_files", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'No meta file found in the model directory (%s)'", "%", "model_dir", ")", "\n", "", "elif", "len", "(", "meta_files", ")", ">", "1", ":", "\n", "        ", "raise", "ValueError", "(", "'There should not be more than one meta file in the model directory (%s)'", "%", "model_dir", ")", "\n", "", "meta_file", "=", "meta_files", "[", "0", "]", "\n", "meta_files", "=", "[", "s", "for", "s", "in", "files", "if", "'.ckpt'", "in", "s", "]", "\n", "max_step", "=", "-", "1", "\n", "for", "f", "in", "files", ":", "\n", "        ", "step_str", "=", "re", ".", "match", "(", "r'(^model-[\\w\\- ]+.ckpt-(\\d+))'", ",", "f", ")", "\n", "if", "step_str", "is", "not", "None", "and", "len", "(", "step_str", ".", "groups", "(", ")", ")", ">=", "2", ":", "\n", "            ", "step", "=", "int", "(", "step_str", ".", "groups", "(", ")", "[", "1", "]", ")", "\n", "if", "step", ">", "max_step", ":", "\n", "                ", "max_step", "=", "step", "\n", "ckpt_file", "=", "step_str", ".", "groups", "(", ")", "[", "0", "]", "\n", "", "", "", "return", "meta_file", ",", "ckpt_file", "\n", "", ""]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork.inference": [[8, 21], ["tensorflow.arg_scope", "tempPoolNetwork.temporal_pool", "tensorflow.truncated_normal_initializer", "tensorflow.l2_regularizer"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork.temporal_pool"], ["def", "inference", "(", "cov_matrices", ",", "phase_train", "=", "True", ",", "reuse", "=", "None", ",", "weight_decay", "=", "0.0", ",", "batch_size", "=", "31", ")", ":", "\n", "    ", "batch_norm_params", "=", "{", "\n", "'decay'", ":", "0.995", ",", "\n", "'epsilon'", ":", "0.001", ",", "\n", "'updates_collections'", ":", "None", ",", "\n", "'variables_collections'", ":", "[", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", "]", "\n", "}", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "normalizer_params", "=", "batch_norm_params", ")", ":", "\n", "        ", "return", "temporal_pool", "(", "cov_matrices", ",", "is_training", "=", "phase_train", ",", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork.temporal_pool": [[22, 55], ["tensorflow.variable_scope", "tensorflow.arg_scope", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.variable_scope", "inputs.get_shape().as_list", "tempPoolNetwork._variable_with_orth_weight_decay", "tensorflow.matmul", "tempPoolNetwork._cal_rect_cov", "_cal_rect_cov.get_shape().as_list", "tempPoolNetwork._variable_with_orth_weight_decay", "tensorflow.matmul", "tempPoolNetwork._cal_rect_cov", "_cal_rect_cov.get_shape().as_list", "print", "tempPoolNetwork._variable_with_orth_weight_decay", "tensorflow.matmul", "tempPoolNetwork._cal_rect_cov", "_cal_rect_cov.get_shape().as_list", "tempPoolNetwork._variable_with_orth_weight_decay", "tensorflow.matmul", "tempPoolNetwork._cal_rect_cov", "tempPoolNetwork._cal_log_cov", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "inputs.get_shape", "_cal_rect_cov.get_shape", "_cal_rect_cov.get_shape", "_cal_rect_cov.get_shape"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._variable_with_orth_weight_decay", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_rect_cov", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._variable_with_orth_weight_decay", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_rect_cov", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._variable_with_orth_weight_decay", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_rect_cov", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._variable_with_orth_weight_decay", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_rect_cov", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_log_cov"], ["", "", "def", "temporal_pool", "(", "inputs", ",", "is_training", "=", "True", ",", "reuse", "=", "None", ",", "scope", "=", "'TemporalPool'", ",", "batch_size", "=", "31", ")", ":", "\n", "#dropout_keep_prob=1", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'TemporalPool'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "is_training", "=", "is_training", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'spdpooling'", ")", "as", "scope", ":", "\n", "            ", "shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "# BiRe-1", "\n", "weight1", ",", "weight2", "=", "_variable_with_orth_weight_decay", "(", "'orth_weight0'", ",", "shape", ",", "2", ")", "\n", "local6", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "weight2", ",", "inputs", ")", ",", "weight1", ",", "name", "=", "'matmulout'", ")", "\n", "local7", "=", "_cal_rect_cov", "(", "local6", ")", "\n", "# BiRe-2                    ", "\n", "shape", "=", "local7", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "weight3", ",", "weight4", "=", "_variable_with_orth_weight_decay", "(", "'orth_weight1'", ",", "shape", ",", "2", ")", "\n", "local8", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "weight4", ",", "local7", ")", ",", "weight3", ")", "\n", "local9", "=", "_cal_rect_cov", "(", "local8", ")", "\n", "# BiRe-3                    ", "\n", "shape", "=", "local9", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "print", "(", "'spdpooling feature2: D1:%d, D2:%d, D3:%d'", ",", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", "\n", "weight5", ",", "weight6", "=", "_variable_with_orth_weight_decay", "(", "'orth_weight2'", ",", "shape", ",", "2", ")", "\n", "local10", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "weight6", ",", "local9", ")", ",", "weight5", ")", "\n", "local11", "=", "_cal_rect_cov", "(", "local10", ")", "\n", "# BiRe-4", "\n", "shape", "=", "local11", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "weight7", ",", "weight8", "=", "_variable_with_orth_weight_decay", "(", "'orth_weight3'", ",", "shape", ",", "2", ")", "\n", "local12", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "weight8", ",", "local11", ")", ",", "weight7", ")", "\n", "local14", "=", "_cal_rect_cov", "(", "local12", ")", "\n", "# LogEig Layer", "\n", "local13", "=", "_cal_log_cov", "(", "local14", ")", "\n", "# The batch size 31 here corresponds to batch size and", "\n", "# had to be hard coded while flattening the matrix", "\n", "", "net", "=", "tf", ".", "reshape", "(", "local13", ",", "[", "batch_size", ",", "-", "1", "]", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "32", ",", "activation_fn", "=", "None", ",", "scope", "=", "'Bottleneck'", ",", "reuse", "=", "False", ")", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork._cal_cov_pooling": [[57, 72], ["features.get_shape().as_list", "tensorflow.shape", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.tile", "tensorflow.subtract", "tensorflow.transpose", "tensorflow.trace", "tensorflow.reshape", "tensorflow.tile", "tensorflow.add", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matrix_diag", "features.get_shape", "tensorflow.cast"], "function", ["None"], ["", "def", "_cal_cov_pooling", "(", "features", ")", ":", "\n", "    ", "shape_f", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "shape_f", "=", "tf", ".", "shape", "(", "features", ")", "\n", "centers_batch", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "transpose", "(", "features", ",", "[", "0", ",", "2", ",", "1", "]", ")", ",", "2", ")", "\n", "centers_batch", "=", "tf", ".", "reshape", "(", "centers_batch", ",", "[", "shape_f", "[", "0", "]", ",", "1", ",", "shape_f", "[", "2", "]", "]", ")", "\n", "centers_batch", "=", "tf", ".", "tile", "(", "centers_batch", ",", "[", "1", ",", "shape_f", "[", "1", "]", ",", "1", "]", ")", "\n", "tmp", "=", "tf", ".", "subtract", "(", "features", ",", "centers_batch", ")", "\n", "tmp_t", "=", "tf", ".", "transpose", "(", "tmp", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "features_t", "=", "1", "/", "tf", ".", "cast", "(", "(", "shape_f", "[", "1", "]", "-", "1", ")", ",", "tf", ".", "float32", ")", "*", "tf", ".", "matmul", "(", "tmp_t", ",", "tmp", ")", "\n", "trace_t", "=", "tf", ".", "trace", "(", "features_t", ")", "\n", "trace_t", "=", "tf", ".", "reshape", "(", "trace_t", ",", "[", "shape_f", "[", "0", "]", ",", "1", "]", ")", "\n", "trace_t", "=", "tf", ".", "tile", "(", "trace_t", ",", "[", "1", ",", "shape_f", "[", "2", "]", "]", ")", "\n", "# 0.001 is regularization factor so that the matrix is SPD Matrix", "\n", "trace_t", "=", "0.001", "*", "tf", ".", "matrix_diag", "(", "trace_t", ")", "\n", "return", "tf", ".", "add", "(", "features_t", ",", "trace_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork._cal_log_cov": [[98, 104], ["tensorflow.self_adjoint_eig", "tensorflow.log", "tensorflow.matrix_diag", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose"], "function", ["None"], ["def", "_cal_log_cov", "(", "features", ")", ":", "\n", "    ", "[", "s_f", ",", "v_f", "]", "=", "tf", ".", "self_adjoint_eig", "(", "features", ")", "\n", "s_f", "=", "tf", ".", "log", "(", "s_f", ")", "\n", "s_f", "=", "tf", ".", "matrix_diag", "(", "s_f", ")", "\n", "features_t", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "v_f", ",", "s_f", ")", ",", "tf", ".", "transpose", "(", "v_f", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "return", "features_t", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork._variable_with_orth_weight_decay": [[107, 117], ["tensorflow.cast", "tensorflow.cast", "tensorflow.qr", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tile", "tensorflow.tile", "tensorflow.random_normal", "tensorflow.transpose"], "function", ["None"], ["", "def", "_variable_with_orth_weight_decay", "(", "name1", ",", "shape", ",", "red", ")", ":", "\n", "    ", "s1", "=", "tf", ".", "cast", "(", "shape", "[", "2", "]", ",", "tf", ".", "int32", ")", "\n", "s2", "=", "tf", ".", "cast", "(", "shape", "[", "2", "]", "/", "red", ",", "tf", ".", "int32", ")", "\n", "w0_init", ",", "_", "=", "tf", ".", "qr", "(", "tf", ".", "random_normal", "(", "[", "s1", ",", "s2", "]", ",", "mean", "=", "0.0", ",", "stddev", "=", "1.0", ")", ")", "\n", "w0", "=", "tf", ".", "get_variable", "(", "name1", ",", "initializer", "=", "w0_init", ")", "\n", "tmp1", "=", "tf", ".", "reshape", "(", "w0", ",", "(", "1", ",", "s1", ",", "s2", ")", ")", "\n", "tmp2", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "w0", ")", ",", "(", "1", ",", "s2", ",", "s1", ")", ")", "\n", "tmp1", "=", "tf", ".", "tile", "(", "tmp1", ",", "[", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "tmp2", "=", "tf", ".", "tile", "(", "tmp2", ",", "[", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "return", "tmp1", ",", "tmp2", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolNetwork._cal_rect_cov": [[119, 125], ["tensorflow.self_adjoint_eig", "tensorflow.clip_by_value", "tensorflow.matrix_diag", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose"], "function", ["None"], ["", "def", "_cal_rect_cov", "(", "features", ")", ":", "\n", "    ", "[", "s_f", ",", "v_f", "]", "=", "tf", ".", "self_adjoint_eig", "(", "features", ")", "\n", "s_f", "=", "tf", ".", "clip_by_value", "(", "s_f", ",", "1e-4", ",", "10000", ")", "\n", "s_f", "=", "tf", ".", "matrix_diag", "(", "s_f", ")", "\n", "features_t", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "v_f", ",", "s_f", ")", ",", "tf", ".", "transpose", "(", "v_f", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "return", "features_t", "\n", "", ""]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.main": [[26, 187], ["importlib.import_module", "datetime.datetime.strftime", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.random.seed", "random.seed", "framework.get_dataset", "len", "print", "print", "tf.Session.close", "datetime.datetime.now", "os.path.expanduser", "os.path.expanduser", "os.path.isdir", "os.path.isdir", "os.makedirs", "os.makedirs", "os.path.expanduser", "os.path.expanduser", "os.path.isdir", "os.path.isdir", "os.makedirs", "os.makedirs", "os.path.expanduser", "os.path.expanduser", "print", "tensorflow.Graph().as_default", "tensorflow.set_random_seed", "tensorflow.Variable", "framework.get_image_paths_and_labels", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.train.range_input_producer", "tf.train.range_input_producer.dequeue_many", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.python.ops.data_flow_ops.FIFOQueue", "data_flow_ops.FIFOQueue.enqueue_many", "range", "tensorflow.train.batch_join", "tensorflow.reshape", "tensorflow.identity", "tensorflow.identity", "tensorflow.identity", "print", "print", "print", "importlib.import_module.inference", "tensorflow.fully_connected", "print", "tensorflow.nn.l2_normalize", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.add_to_collection", "tensorflow.get_collection", "tensorflow.add_n", "framework.trainspd", "tensorflow.train.Saver", "tensorflow.summary.merge_all", "tensorflow.GPUOptions", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "tensorflow.summary.FileWriter", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "len", "tensorflow.python.ops.array_ops.shape", "data_flow_ops.FIFOQueue.dequeue", "tensorflow.unstack", "images_and_labels.append", "len", "framework.center_loss", "tensorflow.add_to_collection", "tensorflow.global_variables", "tensorflow.trainable_variables", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tf.Session.as_default", "print", "tensorflow.Graph", "tensorflow.read_file", "tensorflow.image.decode_image", "tf.image.random_flip_left_right.set_shape", "images.append", "len", "tensorflow.truncated_normal_initializer", "tensorflow.l2_regularizer", "print", "tf.train.Saver.restore", "tf.Session.run", "train.train", "train.save_variables_and_metagraph", "tensorflow.py_func", "tensorflow.random_crop", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.image.random_flip_left_right", "tensorflow.image.per_image_standardization"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2.inference", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.trainspd", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.center_loss", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.train", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.save_variables_and_metagraph"], ["def", "main", "(", "args", ")", ":", "\n", "\t", "network", "=", "importlib", ".", "import_module", "(", "args", ".", "model_def", ")", "\n", "subdir", "=", "datetime", ".", "strftime", "(", "datetime", ".", "now", "(", ")", ",", "'%Y%m%d-%H%M%S'", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "args", ".", "logs_base_dir", ")", ",", "subdir", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "log_dir", ")", ":", "# Create the log directory if it doesn't exist", "\n", "\t\t", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "", "model_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "args", ".", "models_base_dir", ")", ",", "subdir", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "model_dir", ")", ":", "# Create the model directory if it doesn't exist", "\n", "\t\t", "os", ".", "makedirs", "(", "model_dir", ")", "\n", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", "=", "args", ".", "seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "train_set", "=", "framework", ".", "get_dataset", "(", "args", ".", "data_dir", ")", "\n", "nrof_classes", "=", "len", "(", "train_set", ")", "\n", "print", "(", "'Model directory: %s'", "%", "model_dir", ")", "\n", "print", "(", "'Log directory: %s'", "%", "log_dir", ")", "\n", "\n", "pretrained_model", "=", "None", "\n", "if", "args", ".", "pretrained_model", ":", "\n", "\t\t", "pretrained_model", "=", "os", ".", "path", ".", "expanduser", "(", "args", ".", "pretrained_model", ")", "\n", "print", "(", "'Pre-trained model: %s'", "%", "pretrained_model", ")", "\n", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "\t\t", "tf", ".", "set_random_seed", "(", "args", ".", "seed", ")", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "\n", "# Get a list of image paths and their labels", "\n", "image_list", ",", "label_list", "=", "framework", ".", "get_image_paths_and_labels", "(", "train_set", ")", "\n", "assert", "len", "(", "image_list", ")", ">", "0", ",", "'The dataset should not be empty'", "\n", "\n", "# Create a queue that produces indices into the image_list and label_list ", "\n", "labels", "=", "ops", ".", "convert_to_tensor", "(", "label_list", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "range_size", "=", "array_ops", ".", "shape", "(", "labels", ")", "[", "0", "]", "\n", "index_queue", "=", "tf", ".", "train", ".", "range_input_producer", "(", "range_size", ",", "num_epochs", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "seed", "=", "None", ",", "capacity", "=", "32", ")", "\n", "\n", "index_dequeue_op", "=", "index_queue", ".", "dequeue_many", "(", "args", ".", "batch_size", "*", "args", ".", "epoch_size", ",", "'index_dequeue'", ")", "\n", "\n", "learning_rate_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'learning_rate'", ")", "\n", "\n", "batch_size_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "name", "=", "'batch_size'", ")", "\n", "\n", "phase_train_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "name", "=", "'phase_train'", ")", "\n", "\n", "image_paths_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'image_paths'", ")", "\n", "\n", "labels_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "int64", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'labels'", ")", "\n", "\n", "input_queue", "=", "data_flow_ops", ".", "FIFOQueue", "(", "capacity", "=", "100000", ",", "\n", "dtypes", "=", "[", "tf", ".", "string", ",", "tf", ".", "int64", "]", ",", "\n", "shapes", "=", "[", "(", "1", ",", ")", ",", "(", "1", ",", ")", "]", ",", "\n", "shared_name", "=", "None", ",", "name", "=", "None", ")", "\n", "enqueue_op", "=", "input_queue", ".", "enqueue_many", "(", "[", "image_paths_placeholder", ",", "labels_placeholder", "]", ",", "name", "=", "'enqueue_op'", ")", "\n", "\n", "nrof_preprocess_threads", "=", "4", "\n", "images_and_labels", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "nrof_preprocess_threads", ")", ":", "\n", "\t\t\t", "filenames", ",", "label", "=", "input_queue", ".", "dequeue", "(", ")", "\n", "images", "=", "[", "]", "\n", "for", "filename", "in", "tf", ".", "unstack", "(", "filenames", ")", ":", "\n", "\t\t\t\t", "file_contents", "=", "tf", ".", "read_file", "(", "filename", ")", "\n", "image", "=", "tf", ".", "image", ".", "decode_image", "(", "file_contents", ",", "channels", "=", "3", ")", "\n", "if", "args", ".", "random_rotate", ":", "\n", "\t\t\t\t\t", "image", "=", "tf", ".", "py_func", "(", "framework", ".", "random_rotate_image", ",", "[", "image", "]", ",", "tf", ".", "uint8", ")", "\n", "", "if", "args", ".", "random_crop", ":", "\n", "\t\t\t\t\t", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "args", ".", "image_size", ",", "args", ".", "image_size", ",", "3", "]", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "args", ".", "image_size", ",", "args", ".", "image_size", ")", "\n", "", "if", "args", ".", "random_flip", ":", "\n", "\t\t\t\t\t", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "\n", "#pylint: disable=no-member", "\n", "", "image", ".", "set_shape", "(", "(", "args", ".", "image_size", ",", "args", ".", "image_size", ",", "3", ")", ")", "\n", "images", ".", "append", "(", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", ")", "\n", "", "images_and_labels", ".", "append", "(", "[", "images", ",", "label", "]", ")", "\n", "\n", "", "image_batch", ",", "label_batch", "=", "tf", ".", "train", ".", "batch_join", "(", "\n", "images_and_labels", ",", "batch_size", "=", "batch_size_placeholder", ",", "\n", "shapes", "=", "[", "(", "args", ".", "image_size", ",", "args", ".", "image_size", ",", "3", ")", ",", "(", ")", "]", ",", "enqueue_many", "=", "True", ",", "\n", "capacity", "=", "4", "*", "nrof_preprocess_threads", "*", "args", ".", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ")", "\n", "image_batch", "=", "tf", ".", "reshape", "(", "image_batch", ",", "[", "args", ".", "batch_size", ",", "100", ",", "100", ",", "3", "]", ")", "\n", "image_batch", "=", "tf", ".", "identity", "(", "image_batch", ",", "'image_batch'", ")", "\n", "image_batch", "=", "tf", ".", "identity", "(", "image_batch", ",", "'input'", ")", "\n", "label_batch", "=", "tf", ".", "identity", "(", "label_batch", ",", "'label_batch'", ")", "\n", "print", "(", "'Total number of classes: %d'", "%", "nrof_classes", ")", "\n", "print", "(", "'Total number of examples: %d'", "%", "len", "(", "image_list", ")", ")", "\n", "print", "(", "'Building training graph'", ")", "\n", "prelogits", "=", "network", ".", "inference", "(", "image_batch", ",", "args", ".", "keep_probability", ",", "\n", "phase_train", "=", "phase_train_placeholder", ",", "bottleneck_layer_size", "=", "args", ".", "embedding_size", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ",", "batch_size", "=", "args", ".", "batch_size", ")", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "prelogits", ",", "len", "(", "train_set", ")", ",", "activation_fn", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "args", ".", "weight_decay", ")", ",", "\n", "scope", "=", "'Logits'", ",", "reuse", "=", "False", ")", "\n", "print", "(", "logits", ".", "name", ")", "\n", "embeddings", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "prelogits", ",", "1", ",", "1e-10", ",", "name", "=", "'embeddings'", ")", "\n", "\n", "# Add center loss", "\n", "if", "args", ".", "center_loss_factor", ">", "0.0", ":", "\n", "\t\t\t", "prelogits_center_loss", ",", "_", "=", "framework", ".", "center_loss", "(", "prelogits", ",", "label_batch", ",", "args", ".", "center_loss_alfa", ",", "nrof_classes", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ",", "prelogits_center_loss", "*", "args", ".", "center_loss_factor", ")", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "learning_rate_placeholder", ",", "global_step", ",", "\n", "args", ".", "learning_rate_decay_epochs", "*", "args", ".", "epoch_size", ",", "args", ".", "learning_rate_decay_factor", ",", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "# Calculate the average cross entropy loss across the batch", "\n", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "label_batch", ",", "logits", "=", "logits", ",", "name", "=", "'cross_entropy_per_example'", ")", "\n", "cross_entropy_mean", "=", "tf", ".", "reduce_mean", "(", "cross_entropy", ",", "name", "=", "'cross_entropy'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "cross_entropy_mean", ")", "\n", "\n", "\n", "# Calculate the total losses", "\n", "regularization_losses", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "total_loss", "=", "tf", ".", "add_n", "(", "[", "cross_entropy_mean", "]", "+", "regularization_losses", ",", "name", "=", "'total_loss'", ")", "\n", "\n", "# Build a Graph that trains the model with one batch of examples and updates the model parameters", "\n", "train_op", ",", "redun", "=", "framework", ".", "trainspd", "(", "total_loss", ",", "global_step", ",", "args", ".", "optimizer", ",", "\n", "learning_rate", ",", "args", ".", "moving_average_decay", ",", "tf", ".", "global_variables", "(", ")", ",", "args", ".", "log_histograms", ")", "\n", "\n", "# Create a saver", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "max_to_keep", "=", "3", ")", "\n", "\n", "# Build the summary operation based on the TF collection of Summaries.", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "# Start running operations on the Graph.", "\n", "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "args", ".", "gpu_memory_fraction", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", ",", "sess", ".", "graph", ")", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "tf", ".", "train", ".", "start_queue_runners", "(", "coord", "=", "coord", ",", "sess", "=", "sess", ")", "\n", "\n", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "\n", "\t\t\t", "if", "pretrained_model", ":", "\n", "\t\t\t\t", "print", "(", "'Restoring pretrained model: %s'", "%", "pretrained_model", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "pretrained_model", ")", "\n", "\n", "# Training and validation loop", "\n", "", "print", "(", "'Running training'", ")", "\n", "epoch", "=", "0", "\n", "while", "epoch", "<", "args", ".", "max_nrof_epochs", ":", "\n", "\t\t\t\t", "step", "=", "sess", ".", "run", "(", "global_step", ",", "feed_dict", "=", "None", ")", "\n", "epoch", "=", "step", "//", "args", ".", "epoch_size", "\n", "# Train for one epoch", "\n", "train", "(", "args", ",", "sess", ",", "epoch", ",", "image_list", ",", "label_list", ",", "index_dequeue_op", ",", "enqueue_op", ",", "image_paths_placeholder", ",", "labels_placeholder", ",", "\n", "learning_rate_placeholder", ",", "phase_train_placeholder", ",", "batch_size_placeholder", ",", "global_step", ",", "\n", "total_loss", ",", "train_op", ",", "redun", ",", "summary_op", ",", "summary_writer", ",", "regularization_losses", ",", "args", ".", "learning_rate_schedule_file", ")", "\n", "\n", "# Save variables and the metagraph if it doesn't exist already", "\n", "save_variables_and_metagraph", "(", "sess", ",", "saver", ",", "summary_writer", ",", "model_dir", ",", "subdir", ",", "step", ")", "\n", "\n", "", "", "", "sess", ".", "close", "(", ")", "\n", "return", "model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.train": [[189, 229], ["sess.run", "numpy.expand_dims", "numpy.expand_dims", "sess.run", "tensorflow.Summary", "tf.Summary.value.add", "summary_writer.add_summary", "framework.get_learning_rate_from_file", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "time.time", "print", "sess.run", "summary_writer.add_summary", "sess.run", "time.time", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.tempPoolFramework.get_learning_rate_from_file"], ["", "def", "train", "(", "args", ",", "sess", ",", "epoch", ",", "image_list", ",", "label_list", ",", "index_dequeue_op", ",", "enqueue_op", ",", "image_paths_placeholder", ",", "labels_placeholder", ",", "\n", "learning_rate_placeholder", ",", "phase_train_placeholder", ",", "batch_size_placeholder", ",", "global_step", ",", "\n", "loss", ",", "train_op", ",", "redun", ",", "summary_op", ",", "summary_writer", ",", "regularization_losses", ",", "learning_rate_schedule_file", ")", ":", "\n", "\t", "batch_number", "=", "0", "\n", "\n", "if", "args", ".", "learning_rate", ">", "0.0", ":", "\n", "\t\t", "lr", "=", "args", ".", "learning_rate", "\n", "", "else", ":", "\n", "\t\t", "lr", "=", "framework", ".", "get_learning_rate_from_file", "(", "learning_rate_schedule_file", ",", "epoch", ")", "\n", "\n", "", "index_epoch", "=", "sess", ".", "run", "(", "index_dequeue_op", ")", "\n", "label_epoch", "=", "np", ".", "array", "(", "label_list", ")", "[", "index_epoch", "]", "\n", "image_epoch", "=", "np", ".", "array", "(", "image_list", ")", "[", "index_epoch", "]", "\n", "\n", "# Enqueue one epoch of image paths and labels", "\n", "labels_array", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "label_epoch", ")", ",", "1", ")", "\n", "image_paths_array", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "image_epoch", ")", ",", "1", ")", "\n", "sess", ".", "run", "(", "enqueue_op", ",", "{", "image_paths_placeholder", ":", "image_paths_array", ",", "labels_placeholder", ":", "labels_array", "}", ")", "\n", "\n", "# Training loop", "\n", "train_time", "=", "0", "\n", "while", "batch_number", "<", "args", ".", "epoch_size", ":", "\n", "\t\t", "start_time", "=", "time", ".", "time", "(", ")", "\n", "feed_dict", "=", "{", "learning_rate_placeholder", ":", "lr", ",", "phase_train_placeholder", ":", "True", ",", "batch_size_placeholder", ":", "args", ".", "batch_size", "}", "\n", "if", "(", "batch_number", "%", "100", "==", "0", ")", ":", "\n", "\t\t\t", "err", ",", "_", ",", "_", ",", "step", ",", "reg_loss", ",", "summary_str", "=", "sess", ".", "run", "(", "[", "loss", ",", "train_op", ",", "redun", ",", "global_step", ",", "regularization_losses", ",", "summary_op", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary_str", ",", "global_step", "=", "step", ")", "\n", "", "else", ":", "\n", "\t\t\t", "err", ",", "_", ",", "_", ",", "step", ",", "reg_loss", "=", "sess", ".", "run", "(", "[", "loss", ",", "train_op", ",", "redun", ",", "global_step", ",", "regularization_losses", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'Epoch: [%d][%d/%d]\\tTime %.3f\\tLoss %2.3f\\tRegLoss %2.3f'", "%", "\n", "(", "epoch", ",", "batch_number", "+", "1", ",", "args", ".", "epoch_size", ",", "duration", ",", "err", ",", "np", ".", "sum", "(", "reg_loss", ")", ")", ")", "\n", "batch_number", "+=", "1", "\n", "train_time", "+=", "duration", "\n", "# Add validation loss and accuracy to summary", "\n", "", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "#pylint: disable=maybe-no-member", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'time/total'", ",", "simple_value", "=", "train_time", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.save_variables_and_metagraph": [[231, 252], ["print", "time.time", "os.path.join", "os.path.join", "saver.save", "print", "os.path.join", "os.path.join", "tensorflow.Summary", "tf.Summary.value.add", "tf.Summary.value.add", "summary_writer.add_summary", "time.time", "os.path.exists", "os.path.exists", "print", "time.time", "saver.export_meta_graph", "print", "time.time"], "function", ["None"], ["", "def", "save_variables_and_metagraph", "(", "sess", ",", "saver", ",", "summary_writer", ",", "model_dir", ",", "model_name", ",", "step", ")", ":", "\n", "# Save the model checkpoint", "\n", "\t", "print", "(", "'Saving variables'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'model-%s.ckpt'", "%", "model_name", ")", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ",", "global_step", "=", "step", ",", "write_meta_graph", "=", "False", ")", "\n", "save_time_variables", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'Variables saved in %.2f seconds'", "%", "save_time_variables", ")", "\n", "metagraph_filename", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'model-%s.meta'", "%", "model_name", ")", "\n", "save_time_metagraph", "=", "0", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "metagraph_filename", ")", ":", "\n", "\t\t", "print", "(", "'Saving metagraph'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "saver", ".", "export_meta_graph", "(", "metagraph_filename", ")", "\n", "save_time_metagraph", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'Metagraph saved in %.2f seconds'", "%", "save_time_metagraph", ")", "\n", "", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "#pylint: disable=maybe-no-member", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'time/save_variables'", ",", "simple_value", "=", "save_time_variables", ")", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'time/save_metagraph'", ",", "simple_value", "=", "save_time_metagraph", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.src.train.parse_arguments": [[253, 315], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "parse_arguments", "(", "argv", ")", ":", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--logs_base_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory where to write event logs.'", ",", "default", "=", "'~/logs/'", ")", "\n", "parser", ".", "add_argument", "(", "'--models_base_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory where to write trained models and checkpoints.'", ",", "default", "=", "'~/models/'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_memory_fraction'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Upper bound on the amount of GPU memory that will be used by the process.'", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_model'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Load a pretrained model before training starts.'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to the data directory containing aligned face patches. Multiple directories are separated with colon.'", ",", "\n", "default", "=", "'~/data/SFEW/Train'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_def'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Model definition. Points to a module containing the definition of the inference graph.'", ",", "default", "=", "'models.covpoolnet'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_nrof_epochs'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of epochs to run.'", ",", "default", "=", "500", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of images to process in a batch.'", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--image_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Image size (height, width) in pixels.'", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of batches per epoch.'", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--embedding_size'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the embedding.'", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--random_crop'", ",", "\n", "help", "=", "'Performs random cropping of training images. If false, the center image_size pixels from the training images are used. '", "+", "\n", "'If the size of the images in the data directory is equal to image_size no cropping is performed'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--random_flip'", ",", "\n", "help", "=", "'Performs random horizontal flipping of training images.'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--random_rotate'", ",", "\n", "help", "=", "'Performs random rotations of training images.'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--keep_probability'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Keep probability of dropout for the fully connected layer(s).'", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "\n", "help", "=", "'L2 weight regularization.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--decov_loss_factor'", ",", "type", "=", "float", ",", "\n", "help", "=", "'DeCov loss factor.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--center_loss_factor'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Center loss factor.'", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--center_loss_alfa'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Center update rate for center loss.'", ",", "default", "=", "0.95", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "choices", "=", "[", "'ADAGRAD'", ",", "'ADADELTA'", ",", "'ADAM'", ",", "'RMSPROP'", ",", "'MOM'", "]", ",", "\n", "help", "=", "'The optimization algorithm to use'", ",", "default", "=", "'ADAGRAD'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Initial learning rate. If set to a negative value a learning rate '", "+", "\n", "'schedule can be specified in the file \"learning_rate_schedule.txt\"'", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_epochs'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of epochs between learning rate decay.'", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_factor'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Learning rate decay factor.'", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--moving_average_decay'", ",", "type", "=", "float", ",", "\n", "help", "=", "'Exponential decay for tracking of training parameters.'", ",", "default", "=", "0.9999", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Random seed.'", ",", "default", "=", "666", ")", "\n", "parser", ".", "add_argument", "(", "'--nrof_preprocess_threads'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of preprocessing (data loading and augumentation) threads.'", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--log_histograms'", ",", "\n", "help", "=", "'Enables logging of weight/bias histograms in tensorboard.'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_schedule_file'", ",", "type", "=", "str", ",", "\n", "help", "=", "'File containing the learning rate schedule that is used when learning_rate is set to to -1.'", ",", "default", "=", "'data/learning_rate_schedule.txt'", ")", "\n", "return", "parser", ".", "parse_args", "(", "argv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2.inference": [[8, 21], ["tensorflow.arg_scope", "dlp_cnn", "tensorflow.truncated_normal_initializer", "tensorflow.l2_regularizer"], "function", ["None"], ["def", "inference", "(", "images", ",", "keep_probability", ",", "phase_train", "=", "True", ",", "bottleneck_layer_size", "=", "7", ",", "weight_decay", "=", "0.0", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "batch_norm_params", "=", "{", "\n", "'decay'", ":", "0.995", ",", "\n", "'epsilon'", ":", "0.001", ",", "\n", "'updates_collections'", ":", "None", ",", "\n", "'variables_collections'", ":", "[", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", "]", "\n", "}", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "normalizer_params", "=", "batch_norm_params", ")", ":", "\n", "        ", "return", "dlp_cnn", "(", "images", ",", "is_training", "=", "phase_train", ",", "dropout_keep_prob", "=", "keep_probability", ",", "bottleneck_layer_size", "=", "bottleneck_layer_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2.network": [[22, 68], ["tensorflow.variable_scope", "tensorflow.arg_scope", "tensorflow.arg_scope", "tensorflow.conv2d", "tensorflow.nn.relu", "tensorflow.max_pool2d", "tensorflow.conv2d", "tensorflow.nn.relu", "tensorflow.max_pool2d", "tensorflow.conv2d", "tensorflow.nn.relu", "tensorflow.conv2d", "tensorflow.nn.relu", "tensorflow.max_pool2d", "tensorflow.conv2d", "print", "tensorflow.nn.relu", "tensorflow.conv2d", "tensorflow.nn.relu", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.nn.relu", "tensorflow.fully_connected", "tensorflow.variable_scope", "slim.fully_connected.get_shape().as_list", "tensorflow.reshape", "covpoolnet2._cal_cov_pooling", "_cal_cov_pooling.get_shape().as_list", "covpoolnet2._variable_with_orth_weight_decay", "tensorflow.matmul", "covpoolnet2._cal_rect_cov", "covpoolnet2._cal_log_cov", "tensorflow.matmul", "slim.fully_connected.get_shape", "_cal_cov_pooling.get_shape"], "function", ["home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_cov_pooling", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._variable_with_orth_weight_decay", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_rect_cov", "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_log_cov"], ["", "", "def", "network", "(", "inputs", ",", "is_training", "=", "True", ",", "dropout_keep_prob", "=", "1", ",", "bottleneck_layer_size", "=", "7", ",", "reuse", "=", "None", ",", "scope", "=", "'CovPool2'", ")", ":", "\n", "#dropout_keep_prob=1", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'CovPool2'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "is_training", "=", "is_training", ")", ":", "\n", "            ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "#1", "\n", "                ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_1'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "2", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'MaxPool_1'", ")", "\n", "#4", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_2'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "2", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'MaxPool_2'", ")", "\n", "\n", "#7", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_3'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_4'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "2", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'MaxPool_3'", ")", "\n", "\n", "#12", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2d_5'", ")", "\n", "print", "(", "'Conv2d_4: {}'", ".", "format", "(", "net", ".", "shape", ")", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "\n", "#14", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "scope", "=", "'Conv2dfo_6'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'spdpooling1'", ")", "as", "scope", ":", "\n", "                    ", "shape", "=", "net", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "reshaped", "=", "tf", ".", "reshape", "(", "net", ",", "[", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", "*", "shape", "[", "2", "]", ",", "shape", "[", "3", "]", "]", ")", "\n", "local5", "=", "_cal_cov_pooling", "(", "reshaped", ")", "\n", "shape", "=", "local5", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "weight1", ",", "weight2", "=", "_variable_with_orth_weight_decay", "(", "'orth_weight0'", ",", "shape", ")", "\n", "local6", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "weight2", ",", "local5", ")", ",", "weight1", ",", "name", "=", "'matmulout'", ")", "\n", "local7", "=", "_cal_rect_cov", "(", "local6", ")", "\n", "local13", "=", "_cal_log_cov", "(", "local7", ")", "\n", "\n", "", "net", "=", "tf", ".", "reshape", "(", "local13", ",", "[", "128", ",", "-", "1", "]", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "2000", ",", "activation_fn", "=", "None", ",", "scope", "=", "'fc_1'", ",", "reuse", "=", "False", ")", "\n", "net", "=", "tf", ".", "nn", ".", "relu", "(", "net", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "bottleneck_layer_size", ",", "activation_fn", "=", "None", ",", "scope", "=", "'Bottleneck'", ",", "reuse", "=", "False", ")", "\n", "", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_cov_pooling": [[73, 86], ["features.get_shape().as_list", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.tile", "tensorflow.subtract", "tensorflow.transpose", "tensorflow.trace", "tensorflow.reshape", "tensorflow.tile", "tensorflow.add", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matrix_diag", "features.get_shape", "tensorflow.cast"], "function", ["None"], ["def", "_cal_cov_pooling", "(", "features", ")", ":", "\n", "    ", "shape_f", "=", "features", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "centers_batch", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "transpose", "(", "features", ",", "[", "0", ",", "2", ",", "1", "]", ")", ",", "2", ")", "\n", "centers_batch", "=", "tf", ".", "reshape", "(", "centers_batch", ",", "[", "shape_f", "[", "0", "]", ",", "1", ",", "shape_f", "[", "2", "]", "]", ")", "\n", "centers_batch", "=", "tf", ".", "tile", "(", "centers_batch", ",", "[", "1", ",", "shape_f", "[", "1", "]", ",", "1", "]", ")", "\n", "tmp", "=", "tf", ".", "subtract", "(", "features", ",", "centers_batch", ")", "\n", "tmp_t", "=", "tf", ".", "transpose", "(", "tmp", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "features_t", "=", "1", "/", "tf", ".", "cast", "(", "(", "shape_f", "[", "1", "]", "-", "1", ")", ",", "tf", ".", "float32", ")", "*", "tf", ".", "matmul", "(", "tmp_t", ",", "tmp", ")", "\n", "trace_t", "=", "tf", ".", "trace", "(", "features_t", ")", "\n", "trace_t", "=", "tf", ".", "reshape", "(", "trace_t", ",", "[", "shape_f", "[", "0", "]", ",", "1", "]", ")", "\n", "trace_t", "=", "tf", ".", "tile", "(", "trace_t", ",", "[", "1", ",", "shape_f", "[", "2", "]", "]", ")", "\n", "trace_t", "=", "0.0001", "*", "tf", ".", "matrix_diag", "(", "trace_t", ")", "\n", "return", "tf", ".", "add", "(", "features_t", ",", "trace_t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_log_cov": [[88, 94], ["tensorflow.self_adjoint_eig", "tensorflow.log", "tensorflow.matrix_diag", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose"], "function", ["None"], ["", "def", "_cal_log_cov", "(", "features", ")", ":", "\n", "    ", "[", "s_f", ",", "v_f", "]", "=", "tf", ".", "self_adjoint_eig", "(", "features", ")", "\n", "s_f", "=", "tf", ".", "log", "(", "s_f", ")", "\n", "s_f", "=", "tf", ".", "matrix_diag", "(", "s_f", ")", "\n", "features_t", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "v_f", ",", "s_f", ")", ",", "tf", ".", "transpose", "(", "v_f", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "return", "features_t", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._variable_with_orth_weight_decay": [[96, 106], ["tensorflow.cast", "tensorflow.cast", "tensorflow.qr", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tile", "tensorflow.tile", "tensorflow.random_normal", "tensorflow.transpose"], "function", ["None"], ["", "def", "_variable_with_orth_weight_decay", "(", "name1", ",", "shape", ")", ":", "\n", "    ", "s1", "=", "tf", ".", "cast", "(", "shape", "[", "2", "]", ",", "tf", ".", "int32", ")", "\n", "s2", "=", "tf", ".", "cast", "(", "shape", "[", "2", "]", "/", "2", ",", "tf", ".", "int32", ")", "\n", "w0_init", ",", "_", "=", "tf", ".", "qr", "(", "tf", ".", "random_normal", "(", "[", "s1", ",", "s2", "]", ",", "mean", "=", "0.0", ",", "stddev", "=", "1.0", ")", ")", "\n", "w0", "=", "tf", ".", "get_variable", "(", "name1", ",", "initializer", "=", "w0_init", ")", "\n", "tmp1", "=", "tf", ".", "reshape", "(", "w0", ",", "(", "1", ",", "s1", ",", "s2", ")", ")", "\n", "tmp2", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "w0", ")", ",", "(", "1", ",", "s2", ",", "s1", ")", ")", "\n", "tmp1", "=", "tf", ".", "tile", "(", "tmp1", ",", "[", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "tmp2", "=", "tf", ".", "tile", "(", "tmp2", ",", "[", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "\n", "return", "tmp1", ",", "tmp2", "\n", "\n"]], "home.repos.pwc.inspect_result.d-acharya_CovPoolFER.models.covpoolnet2._cal_rect_cov": [[108, 114], ["tensorflow.self_adjoint_eig", "tensorflow.clip_by_value", "tensorflow.matrix_diag", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose"], "function", ["None"], ["", "def", "_cal_rect_cov", "(", "features", ")", ":", "\n", "    ", "[", "s_f", ",", "v_f", "]", "=", "tf", ".", "self_adjoint_eig", "(", "features", ")", "\n", "s_f", "=", "tf", ".", "clip_by_value", "(", "s_f", ",", "0.0001", ",", "10000", ")", "\n", "s_f", "=", "tf", ".", "matrix_diag", "(", "s_f", ")", "\n", "features_t", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "v_f", ",", "s_f", ")", ",", "tf", ".", "transpose", "(", "v_f", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "\n", "return", "features_t", "\n", "", ""]]}