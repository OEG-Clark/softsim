{"home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.__init__": [[49, 62], ["multiprocessing.Lock", "multiprocessing.Value", "multiprocessing.Value", "logging.debug"], "methods", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug"], ["def", "__init__", "(", "self", ",", "name", "=", "\"LT\"", ")", ":", "\n", "# Init variables to None", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "ratelock", "=", "None", "\n", "self", ".", "cnt", "=", "None", "\n", "self", ".", "last_time_called", "=", "None", "\n", "\n", "# Instantiate control variables", "\n", "self", ".", "ratelock", "=", "multiprocessing", ".", "Lock", "(", ")", "\n", "self", ".", "cnt", "=", "multiprocessing", ".", "Value", "(", "\"i\"", ",", "0", ")", "\n", "self", ".", "last_time_called", "=", "multiprocessing", ".", "Value", "(", "\"d\"", ",", "0.0", ")", "\n", "\n", "logging", ".", "debug", "(", "\"\\t__init__: name=[{!s}]\"", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.acquire": [[63, 65], ["download_images.LastTime.ratelock.acquire"], "methods", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.acquire"], ["", "def", "acquire", "(", "self", ")", ":", "\n", "        ", "self", ".", "ratelock", ".", "acquire", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.release": [[66, 68], ["download_images.LastTime.ratelock.release"], "methods", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.release"], ["", "def", "release", "(", "self", ")", ":", "\n", "        ", "self", ".", "ratelock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.set_last_time_called": [[69, 71], ["time.time"], "methods", ["None"], ["", "def", "set_last_time_called", "(", "self", ")", ":", "\n", "        ", "self", ".", "last_time_called", ".", "value", "=", "time", ".", "time", "(", ")", "\n", "# self.debug('set_last_time_called')", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.get_last_time_called": [[73, 75], ["None"], "methods", ["None"], ["", "def", "get_last_time_called", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_time_called", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.add_cnt": [[76, 78], ["None"], "methods", ["None"], ["", "def", "add_cnt", "(", "self", ")", ":", "\n", "        ", "self", ".", "cnt", ".", "value", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.get_cnt": [[79, 81], ["None"], "methods", ["None"], ["", "def", "get_cnt", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cnt", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug": [[82, 103], ["time.time", "logging.debug", "time.strftime", "time.strftime", "time.localtime", "time.localtime", "str().split", "str().split", "str", "str", "int", "int"], "methods", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug"], ["", "def", "debug", "(", "self", ",", "debugname", "=", "\"LT\"", ")", ":", "\n", "        ", "now", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "debug", "(", "\n", "\"___Rate name:[{!s}] \"", "\n", "\"debug=[{!s}] \"", "\n", "\"\\n\\t        cnt:[{!s}] \"", "\n", "\"\\n\\tlast_called:{!s} \"", "\n", "\"\\n\\t  timenow():{!s} \"", ".", "format", "(", "\n", "self", ".", "name", ",", "\n", "debugname", ",", "\n", "self", ".", "cnt", ".", "value", ",", "\n", "time", ".", "strftime", "(", "\n", "\"%T.{}\"", ".", "format", "(", "\n", "str", "(", "self", ".", "last_time_called", ".", "value", "-", "int", "(", "self", ".", "last_time_called", ".", "value", ")", ")", ".", "split", "(", "\n", "\".\"", "\n", ")", "[", "1", "]", "[", ":", "3", "]", "\n", ")", ",", "\n", "time", ".", "localtime", "(", "self", ".", "last_time_called", ".", "value", ")", ",", "\n", ")", ",", "\n", "time", ".", "strftime", "(", "\n", "\"%T.{}\"", ".", "format", "(", "str", "(", "now", "-", "int", "(", "now", ")", ")", ".", "split", "(", "\".\"", ")", "[", "1", "]", "[", ":", "3", "]", ")", ",", "time", ".", "localtime", "(", "now", ")", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.rate_limited": [[108, 184], ["download_images.LastTime", "download_images.LastTime.acquire", "download_images.LastTime.debug", "download_images.LastTime.release", "functools.wraps", "download_images.LastTime.get_last_time_called", "download_images.LastTime.set_last_time_called", "logging.debug", "download_images.LastTime.acquire", "download_images.LastTime.add_cnt", "time.time", "logging.debug", "func", "download_images.LastTime.debug", "download_images.LastTime.set_last_time_called", "download_images.LastTime.debug", "download_images.LastTime.release", "download_images.LastTime.get_last_time_called", "time.sleep", "sys.stderr.write", "sys.stderr.flush", "download_images.LastTime.get_cnt", "time.strftime", "time.strftime", "time.localtime", "time.localtime", "download_images.LastTime.get_last_time_called"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.acquire", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.release", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.get_last_time_called", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.set_last_time_called", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.acquire", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.add_cnt", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.set_last_time_called", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.debug", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.release", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.get_last_time_called", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.get_cnt", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.LastTime.get_last_time_called"], ["", "", "def", "rate_limited", "(", "max_per_second", ")", ":", "\n", "    ", "\"\"\"\n    Decorator to rate limit a python function.\n\n    Example, limits to 10 requests per second, and works w/ multiprocessing as well:\n\n        > @rate_limited(10)\n        > def download_img(media_url):\n        > ...\n\n    Credit: Copied and modified this: https://gist.github.com/gregburek/1441055\n    \"\"\"", "\n", "min_interval", "=", "1.0", "/", "max_per_second", "\n", "LT", "=", "LastTime", "(", "\"rate_limited\"", ")", "\n", "\n", "def", "decorate", "(", "func", ")", ":", "\n", "        ", "LT", ".", "acquire", "(", ")", "\n", "if", "LT", ".", "get_last_time_called", "(", ")", "==", "0", ":", "\n", "            ", "LT", ".", "set_last_time_called", "(", ")", "\n", "", "LT", ".", "debug", "(", "\"DECORATE\"", ")", "\n", "LT", ".", "release", "(", ")", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "rate_limited_function", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\n", "            ", "logging", ".", "debug", "(", "\n", "\"___Rate_limited f():[{!s}]: \"", "\n", "\"Max_per_Second:[{!s}]\"", ".", "format", "(", "func", ".", "__name__", ",", "max_per_second", ")", "\n", ")", "\n", "\n", "try", ":", "\n", "                ", "LT", ".", "acquire", "(", ")", "\n", "LT", ".", "add_cnt", "(", ")", "\n", "xfrom", "=", "time", ".", "time", "(", ")", "\n", "\n", "elapsed", "=", "xfrom", "-", "LT", ".", "get_last_time_called", "(", ")", "\n", "left_to_wait", "=", "min_interval", "-", "elapsed", "\n", "logging", ".", "debug", "(", "\n", "\"___Rate f():[{!s}] \"", "\n", "\"cnt:[{!s}] \"", "\n", "\"\\n\\tlast_called:{!s} \"", "\n", "\"\\n\\t time now():{!s} \"", "\n", "\"elapsed:{:6.2f} \"", "\n", "\"min:{!s} \"", "\n", "\"to_wait:{:6.2f}\"", ".", "format", "(", "\n", "func", ".", "__name__", ",", "\n", "LT", ".", "get_cnt", "(", ")", ",", "\n", "time", ".", "strftime", "(", "\"%T\"", ",", "time", ".", "localtime", "(", "LT", ".", "get_last_time_called", "(", ")", ")", ")", ",", "\n", "time", ".", "strftime", "(", "\"%T\"", ",", "time", ".", "localtime", "(", "xfrom", ")", ")", ",", "\n", "elapsed", ",", "\n", "min_interval", ",", "\n", "left_to_wait", ",", "\n", ")", "\n", ")", "\n", "if", "left_to_wait", ">", "0", ":", "\n", "                    ", "time", ".", "sleep", "(", "left_to_wait", ")", "\n", "\n", "", "ret", "=", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "LT", ".", "debug", "(", "\"OVER\"", ")", "\n", "LT", ".", "set_last_time_called", "(", ")", "\n", "LT", ".", "debug", "(", "\"NEXT\"", ")", "\n", "\n", "", "except", "Exception", "as", "ex", ":", "\n", "                ", "sys", ".", "stderr", ".", "write", "(", "\n", "\"+++000 \"", "\"Exception on rate_limited_function: [{!s}]\\n\"", ".", "format", "(", "ex", ")", "\n", ")", "\n", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "LT", ".", "release", "(", ")", "\n", "", "return", "ret", "\n", "\n", "", "return", "rate_limited_function", "\n", "\n", "", "return", "decorate", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.save_image": [[186, 223], ["download_images.rate_limited", "save_dest.parent.mkdir", "save_dest.exists", "requests.get", "logger.error", "time.sleep", "open", "shutil.copyfileobj", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.rate_limited"], ["", "@", "rate_limited", "(", "30", ")", "\n", "def", "save_image", "(", "idx", ",", "img_row", ",", "images_dir", ":", "Path", ",", "size", "=", "\"large\"", ")", ":", "\n", "    ", "\"\"\"\n    Download and save image to path.\n\n    Args:\n\n        image: The url of the image.\n        path: The directory where the image will be saved.\n        filename:\n        size: Which size of images to download.\n    \"\"\"", "\n", "if", "img_row", "[", "\"media_url\"", "]", ":", "\n", "        ", "save_dest", ":", "Path", "=", "images_dir", "/", "img_row", "[", "\"filename\"", "]", "\n", "save_dest", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "if", "not", "save_dest", ".", "exists", "(", ")", ":", "\n", "# logger.info(f\"Saving image: {save_dest.name}\")", "\n", "            ", "r", "=", "requests", ".", "get", "(", "img_row", "[", "\"media_url\"", "]", "+", "\":\"", "+", "size", ",", "stream", "=", "True", ")", "\n", "if", "r", ".", "status_code", "==", "200", ":", "\n", "                ", "with", "open", "(", "save_dest", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                    ", "r", ".", "raw", ".", "decode_content", "=", "True", "\n", "shutil", ".", "copyfileobj", "(", "r", ".", "raw", ",", "f", ")", "\n", "", "", "elif", "r", ".", "status_code", "in", "[", "403", ",", "404", "]", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "print", "(", "f\"Error on {idx}, tweet_id:{img_row['tweet_id']}, url:{img_row['media_url']}\"", ")", "\n", "print", "(", "r", ".", "headers", ")", "\n", "print", "(", "r", ".", "status_code", ",", "\", \"", ",", "r", ".", "reason", ")", "\n", "print", "(", "r", ".", "text", ")", "\n", "", "if", "r", ".", "status_code", "in", "[", "429", "]", ":", "\n", "                ", "sleep_seconds", "=", "15", "*", "60", "\n", "logger", ".", "error", "(", "f\"Rate limit hit... Will retry in {sleep_seconds} seconds...\"", ")", "\n", "time", ".", "sleep", "(", "sleep_seconds", ")", "\n", "", "", "else", ":", "\n", "# print(f\"Skipping {save_dest}: already downloaded\")", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.fake_save_image": [[225, 235], ["download_images.rate_limited", "time.sleep", "float", "random.randrange"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.rate_limited"], ["", "", "", "@", "rate_limited", "(", "3", ")", "\n", "def", "fake_save_image", "(", "idx", ",", "img_row", ",", "images_dir", ":", "Path", ",", "size", "=", "\"large\"", ")", ":", "\n", "    ", "\"\"\"\n    This is just for testing purposes, when we don't want to hit the twitter servers.\n    \"\"\"", "\n", "import", "random", "\n", "\n", "r", "=", "float", "(", "random", ".", "randrange", "(", "420", ")", ")", "/", "1000.0", "\n", "time", ".", "sleep", "(", "r", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.dl_images": [[237, 243], ["df_media.iterrows", "download_images.save_image"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.save_image"], ["", "def", "dl_images", "(", "df_media", ":", "pd", ".", "DataFrame", ",", "images_dir", ":", "Path", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Single process, just download one images at a time.\n    \"\"\"", "\n", "for", "idx", ",", "row", "in", "df_media", ".", "iterrows", "(", ")", ":", "\n", "        ", "save_image", "(", "idx", ",", "row", ",", "images_dir", ",", "size", "=", "\"orig\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.dl_images_mp": [[245, 268], ["numpy.array_split", "range", "logger.info", "multiprocessing.Process", "TaskPool.append", "multiprocessing.Process.start", "process_num.join", "print", "len", "process_num.is_alive"], "function", ["None"], ["", "", "def", "dl_images_mp", "(", "df_media", ":", "pd", ".", "DataFrame", ",", "images_dir", ":", "Path", ",", "num_processes", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Split the `df_media` `DataFrame` into N equal parts and use python multiprocessing to download\n    the images for each part. N = `num_processes`.\n    \"\"\"", "\n", "TaskPool", "=", "[", "]", "\n", "df_media_splits", "=", "np", ".", "array_split", "(", "df_media", ",", "num_processes", ")", "\n", "\n", "for", "process_num", "in", "range", "(", "1", ",", "num_processes", "+", "1", ")", ":", "\n", "        ", "Task", "=", "multiprocessing", ".", "Process", "(", "\n", "target", "=", "dl_images_mp_helper", ",", "\n", "args", "=", "(", "process_num", ",", "df_media_splits", "[", "process_num", "-", "1", "]", ",", "images_dir", ")", ",", "\n", ")", "\n", "TaskPool", ".", "append", "(", "Task", ")", "\n", "Task", ".", "start", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Started {num_processes} ({len(TaskPool)}) processes to download images\"", ")", "\n", "\n", "for", "process_num", "in", "TaskPool", ":", "\n", "        ", "process_num", ".", "join", "(", ")", "\n", "print", "(", "\n", "\"==={!s} (is alive: {!s}).exitcode = {!s}\"", ".", "format", "(", "\n", "process_num", ".", "name", ",", "process_num", ".", "is_alive", "(", ")", ",", "process_num", ".", "exitcode", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.dl_images_mp_helper": [[272, 280], ["logger.info", "tqdm.tqdm", "df_media.iterrows", "save_dest.parent.mkdir", "len", "save_dest.exists", "download_images.save_image"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.save_image"], ["", "", "def", "dl_images_mp_helper", "(", "process_num", ":", "int", ",", "df_media", ":", "pd", ".", "DataFrame", ",", "images_dir", ":", "Path", ")", "->", "None", ":", "\n", "    ", "logger", ".", "info", "(", "f\"process_num:{process_num}, df_media shape: {df_media.shape}\"", ")", "\n", "for", "idx", ",", "img_row", "in", "tqdm", "(", "df_media", ".", "iterrows", "(", ")", ",", "total", "=", "len", "(", "df_media", ")", ",", "position", "=", "process_num", "-", "1", ")", ":", "\n", "        ", "save_dest", ":", "Path", "=", "images_dir", "/", "img_row", "[", "\"filename\"", "]", "\n", "save_dest", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "if", "not", "save_dest", ".", "exists", "(", ")", ":", "\n", "            ", "save_image", "(", "idx", ",", "img_row", ",", "images_dir", ",", "size", "=", "\"orig\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.main": [[282, 308], ["args.data_dir.resolve", "logger.info", "logger.info", "str", "input_file.exists", "str", "logger.info", "images_dir.mkdir", "download_images.get_photo_urls", "print", "df_media[].copy.apply", "df_media[].copy", "download_images.dl_images", "download_images.dl_images_mp"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.get_photo_urls", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.dl_images", "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.dl_images_mp"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "# Prepare paths:", "\n", "    ", "data_dir", ":", "Path", "=", "args", ".", "data_dir", ".", "resolve", "(", ")", "\n", "logger", ".", "info", "(", "f\"Data_dir: {data_dir}\"", ")", "\n", "input_file", ":", "Path", "=", "(", "data_dir", "/", "args", ".", "input_file", ")", ".", "resolve", "(", ")", "\n", "logger", ".", "info", "(", "f\"input_file: {input_file}\"", ")", "\n", "assert", "data_dir", ".", "exists", ",", "str", "(", "data_dir", ")", "\n", "assert", "input_file", ".", "exists", "(", ")", ",", "str", "(", "input_file", ")", "\n", "images_dir", ":", "Path", "=", "data_dir", "/", "\"images\"", "/", "input_file", ".", "stem", "\n", "logger", ".", "info", "(", "f\"images_dir: {images_dir}\"", ")", "\n", "images_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "\n", "# Load url's from twitter json", "\n", "df_media", "=", "get_photo_urls", "(", "input_file", ")", "\n", "# Remove images that are already downloaded:", "\n", "print", "(", "\"Checking for already downloaded images. Images_dir: \"", ",", "images_dir", ")", "\n", "df_media", "[", "\"is_downloaded\"", "]", "=", "df_media", ".", "apply", "(", "\n", "lambda", "x", ":", "(", "images_dir", "/", "x", "[", "\"filename\"", "]", ")", ".", "exists", "(", ")", ",", "axis", "=", "1", "\n", ")", "\n", "df_media", "=", "df_media", "[", "(", "~", "df_media", ".", "is_downloaded", ")", "]", ".", "copy", "(", "deep", "=", "True", ")", "\n", "\n", "num_processes", "=", "10", "\n", "if", "num_processes", "<", "2", ":", "\n", "        ", "dl_images", "(", "df_media", ",", "images_dir", ")", "\n", "", "else", ":", "\n", "        ", "dl_images_mp", "(", "df_media", ",", "images_dir", ",", "num_processes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.load_tweets": [[310, 331], ["json_path.exists", "str", "pandas.read_json", "df.drop_duplicates.id.astype", "df.drop_duplicates.drop_duplicates", "df.drop_duplicates.set_index", "df.drop_duplicates.geo.apply", "typing.cast", "isinstance"], "function", ["None"], ["", "", "def", "load_tweets", "(", "json_path", ":", "Path", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "assert", "json_path", ".", "exists", "(", ")", ",", "str", "(", "json_path", ")", "\n", "df", "=", "pd", ".", "read_json", "(", "\n", "json_path", ",", "\n", "lines", "=", "True", ",", "\n", "precise_float", "=", "True", ",", "\n", "dtype", "=", "{", "\"id\"", ":", "int", "}", ",", "\n", ")", "\n", "# Note: id_str matches the tweet_id's that are passed into hydrator:", "\n", "df", "[", "\"tweet_id\"", "]", "=", "df", ".", "id", ".", "astype", "(", "int", ")", "\n", "df", "=", "df", ".", "drop_duplicates", "(", "\"tweet_id\"", ")", "\n", "df", ".", "set_index", "(", "\n", "\"tweet_id\"", ",", "\n", "drop", "=", "False", ",", "\n", "inplace", "=", "True", ",", "\n", "verify_integrity", "=", "True", ",", "\n", ")", "\n", "df", "[", "\"country\"", "]", "=", "df", ".", "geo", ".", "apply", "(", "\n", "lambda", "x", ":", "x", "[", "\"country\"", "]", "if", "isinstance", "(", "x", ",", "dict", ")", "and", "\"country\"", "in", "x", "else", "None", "\n", ")", "\n", "return", "cast", "(", "pd", ".", "DataFrame", ",", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.pre_json_normalize": [[333, 360], ["isinstance", "prop_type"], "function", ["None"], ["", "def", "pre_json_normalize", "(", "\n", "row", ",", "parent_col_name", ":", "str", ",", "target_col_name", ":", "str", ",", "child_properties", ":", "list", "=", "None", "\n", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Prepares a column of a dataframe (`target_col_name`) to be run through\n    `json_normalize()`. To achieve this it takes a row of a dataframe containing tweet\n    data, and:\n\n    1. Adds the `parent_col_name: row[parent_col_name]` as a key-value pair to the dict\n        object contained in `row[target_col_name]`. This helps link the rows of the\n        original DataFrame to those of the DataFrame that is output when the target\n        column is run thru `json_normalize()`.\n\n    2. Adds a `\"media\": []` key-value pair if no media key is in the target dict.\n\n    3. If the target dict is null, a new one is created.\n    \"\"\"", "\n", "target_dict", "=", "row", "[", "target_col_name", "]", "\n", "if", "not", "isinstance", "(", "target_dict", ",", "dict", ")", ":", "\n", "        ", "target_dict", "=", "{", "}", "\n", "", "if", "parent_col_name", "not", "in", "target_dict", ":", "\n", "        ", "target_dict", "[", "parent_col_name", "]", "=", "row", "[", "parent_col_name", "]", "\n", "", "if", "child_properties", ":", "\n", "        ", "for", "prop_name", ",", "prop_type", "in", "child_properties", ":", "\n", "            ", "if", "prop_name", "not", "in", "target_dict", ":", "\n", "                ", "target_dict", "[", "prop_name", "]", "=", "prop_type", "(", ")", "\n", "", "", "", "return", "target_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.get_photo_urls": [[362, 401], ["download_images.load_tweets", "pd.json_normalize.reset_index", "pd.json_normalize.apply", "logger.info", "print", "typing.cast", "load_tweets.apply", "pandas.json_normalize", "load_tweets.apply", "pandas.json_normalize", "download_images.get_photo_urls._get_filename"], "function", ["home.repos.pwc.inspect_result.giscardbiamby_twitter-comms.scripts.download_images.load_tweets"], ["", "def", "get_photo_urls", "(", "json_path", ":", "Path", ",", "media_type", ":", "str", "=", "\"photo\"", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Returns a DataFrame of media info from the give json file. The input file should be a twitter\n    json file that came from the Twitter v2 Search API.\n\n    Example output:\n\n        >       height              id_str   type                                              url  width  duration_ms preview_image_url  public_metrics.view_count alt_text             tweet_id             filename\n        > 0       1920  3_1427530554480619521  photo  https://pbs.twimg.com/media/E8-bedXVcAEqkXA.jpg   1080          NaN               NaN                        NaN      NaN  1427531793771622400    xx/<filename>.jpg\n        > 1        409  3_1427531788591771661  photo  https://pbs.twimg.com/media/E8-cmSyXMA0ETDr.jpg    615          NaN               NaN                        NaN      NaN  1427531789392883727    xx/<filename>.jpg\n        > 2       1000  3_1427531783868878850  photo  https://pbs.twimg.com/media/E8-cmBMVkAIcD4a.jpg   1000          NaN               NaN                        NaN      NaN  1427531786746163202    xx/<filename>.jpg\n        > 3        546  3_1427531482029903875  photo  https://pbs.twimg.com/media/E8-cUcwUUAMRefa.jpg    728          NaN               NaN                        NaN      NaN  1427531786477740034    xx/<filename>.jpg\n        > 4        375  3_1427526863543578632  photo  https://pbs.twimg.com/media/E8-YHnjXsAgRpIu.jpg    500          NaN               NaN                        NaN      NaN  1427531785458659334    xx/<filename>.jpg\n        > ...      ...                    ...    ...                                              ...    ...          ...               ...                        ...      ...                  ...                  ...\n    \"\"\"", "\n", "df", "=", "load_tweets", "(", "json_path", ")", "\n", "if", "\"attachments\"", "in", "df", ".", "columns", ":", "\n", "        ", "df", "[", "\"attachments\"", "]", "=", "df", ".", "apply", "(", "\n", "lambda", "row", ":", "pre_json_normalize", "(", "row", ",", "\"tweet_id\"", ",", "\"attachments\"", ",", "[", "(", "\"media\"", ",", "list", ")", "]", ")", ",", "axis", "=", "1", "\n", ")", "\n", "df_media", "=", "pd", ".", "json_normalize", "(", "df", ".", "attachments", ",", "record_path", "=", "\"media\"", ",", "meta", "=", "[", "\"tweet_id\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "df", "[", "\"entities\"", "]", "=", "df", ".", "apply", "(", "\n", "lambda", "row", ":", "pre_json_normalize", "(", "row", ",", "\"tweet_id\"", ",", "\"entities\"", ",", "[", "(", "\"media\"", ",", "list", ")", "]", ")", ",", "axis", "=", "1", "\n", ")", "\n", "df_media", "=", "pd", ".", "json_normalize", "(", "df", ".", "entities", ",", "record_path", "=", "\"media\"", ",", "meta", "=", "[", "\"tweet_id\"", "]", ")", "\n", "", "df_media", "=", "df_media", "[", "(", "df_media", ".", "type", "==", "media_type", ")", "&", "~", "df_media", ".", "media_url", ".", "isna", "(", ")", "]", "\n", "df_media", ".", "reset_index", "(", "inplace", "=", "True", ")", "\n", "df_media", ".", "index", ".", "name", "=", "\"id\"", "\n", "\n", "def", "_get_filename", "(", "row", ")", ":", "\n", "        ", "extension", "=", "Path", "(", "row", "[", "\"media_url\"", "]", ")", ".", "suffix", "if", "row", "[", "\"media_url\"", "]", "and", "not", "pd", ".", "isna", "(", "row", "[", "\"media_url\"", "]", ")", "else", "None", "\n", "filename", "=", "f\"{row['id_str'][-2:]}/{row['tweet_id']}-{row['id_str']}{extension}\"", "\n", "return", "filename", "\n", "\n", "", "df_media", "[", "\"filename\"", "]", "=", "df_media", ".", "apply", "(", "lambda", "row", ":", "_get_filename", "(", "row", ")", ",", "axis", "=", "1", ")", "\n", "logger", ".", "info", "(", "f\"Found {len(df_media)} media urls of type: '{media_type}'\"", ")", "\n", "print", "(", "df_media", ")", "\n", "return", "cast", "(", "pd", ".", "DataFrame", ",", "df_media", ")", "\n", "\n"]]}