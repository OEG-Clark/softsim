{"home.repos.pwc.inspect_result.mrjleo_ranking-models.None.predict.main": [[13, 39], ["hydra.main", "hydra.utils.instantiate", "hydra.utils.instantiate", "iter", "collections.defaultdict", "hydra.utils.instantiate.predict", "ranking_utils.write_trec_eval_file", "hydra.utils.instantiate.ids", "zip", "pathlib.Path.cwd", "hydra.utils.instantiate", "hydra.utils.instantiate", "hydra.utils.instantiate", "item[].detach().numpy", "item[].detach().numpy", "next", "item[].detach", "item[].detach"], "function", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.None.train.main"], ["@", "hydra", ".", "main", "(", "config_path", "=", "\"config\"", ",", "config_name", "=", "\"prediction\"", ")", "\n", "def", "main", "(", "config", ":", "DictConfig", ")", "->", "None", ":", "\n", "    ", "dataset", "=", "instantiate", "(", "\n", "config", ".", "prediction_data", ",", "data_processor", "=", "instantiate", "(", "config", ".", "ranker", ".", "data_processor", ")", "\n", ")", "\n", "trainer", "=", "instantiate", "(", "config", ".", "trainer", ")", "\n", "\n", "ids_iter", "=", "iter", "(", "dataset", ".", "ids", "(", ")", ")", "\n", "result", "=", "defaultdict", "(", "dict", ")", "\n", "for", "item", "in", "trainer", ".", "predict", "(", "\n", "model", "=", "instantiate", "(", "config", ".", "ranker", ".", "model", ")", ",", "\n", "dataloaders", "=", "instantiate", "(", "\n", "config", ".", "data_loader", ",", "dataset", "=", "dataset", ",", "collate_fn", "=", "dataset", ".", "collate_fn", "\n", ")", ",", "\n", "ckpt_path", "=", "config", ".", "ckpt_path", ",", "\n", ")", ":", "\n", "        ", "for", "index", ",", "score", "in", "zip", "(", "\n", "item", "[", "\"indices\"", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "item", "[", "\"scores\"", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "\n", ")", ":", "\n", "            ", "i", ",", "q_id", ",", "doc_id", "=", "next", "(", "ids_iter", ")", "\n", "assert", "index", "==", "i", "\n", "result", "[", "q_id", "]", "[", "doc_id", "]", "=", "score", "\n", "\n", "# include the rank in the file name, otherwise multiple processes compete with each other", "\n", "", "", "out_file", "=", "Path", ".", "cwd", "(", ")", "/", "f\"predictions_{trainer.global_rank}.tsv\"", "\n", "write_trec_eval_file", "(", "out_file", ",", "result", ",", "config", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.None.train.main": [[11, 29], ["hydra.main", "pytorch_lightning.seed_everything", "hydra.utils.instantiate", "hydra.utils.instantiate", "hydra.utils.instantiate", "hydra.utils.instantiate.fit", "hydra.utils.instantiate.test", "hydra.utils.instantiate"], "function", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.None.train.main"], ["@", "hydra", ".", "main", "(", "config_path", "=", "\"config\"", ",", "config_name", "=", "\"training\"", ")", "\n", "def", "main", "(", "config", ":", "DictConfig", ")", "->", "None", ":", "\n", "    ", "seed_everything", "(", "config", ".", "random_seed", ",", "workers", "=", "True", ")", "\n", "model", "=", "instantiate", "(", "config", ".", "ranker", ".", "model", ")", "\n", "data_module", "=", "instantiate", "(", "\n", "config", ".", "training_data", ",", "data_processor", "=", "instantiate", "(", "config", ".", "ranker", ".", "data_processor", ")", "\n", ")", "\n", "\n", "model", ".", "training_mode", "=", "data_module", ".", "training_mode", "=", "{", "\n", "\"pointwise\"", ":", "TrainingMode", ".", "POINTWISE", ",", "\n", "\"pairwise\"", ":", "TrainingMode", ".", "PAIRWISE", ",", "\n", "}", "[", "config", ".", "training_mode", "]", "\n", "model", ".", "pairwise_loss_margin", "=", "config", ".", "pairwise_loss_margin", "\n", "\n", "trainer", "=", "instantiate", "(", "config", ".", "trainer", ")", "\n", "trainer", ".", "fit", "(", "model", "=", "model", ",", "datamodule", "=", "data_module", ")", "\n", "if", "config", ".", "test", ":", "\n", "        ", "trainer", ".", "test", "(", "datamodule", "=", "data_module", ",", "ckpt_path", "=", "\"best\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert.BERTDataProcessor.__init__": [[16, 29], ["ranking_utils.model.data.DataProcessor.__init__", "transformers.BertTokenizer.from_pretrained", "transformers.logging.set_verbosity_error"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "bert_model", ":", "str", ",", "char_limit", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            bert_model (str): Pre-trained BERT model.\n            char_limit (int): Maximum number of characters per query/document.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ")", "\n", "self", ".", "char_limit", "=", "char_limit", "\n", "\n", "# without this, there will be a message for each tokenizer call", "\n", "transformers", ".", "logging", ".", "set_verbosity_error", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert.BERTDataProcessor.get_model_input": [[30, 39], ["len", "len", "query.strip", "doc.strip"], "methods", ["None"], ["", "def", "get_model_input", "(", "self", ",", "query", ":", "str", ",", "doc", ":", "str", ")", "->", "BERTInput", ":", "\n", "# empty queries or documents might cause problems later on", "\n", "        ", "if", "len", "(", "query", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "query", "=", "\"(empty)\"", "\n", "", "if", "len", "(", "doc", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "doc", "=", "\"(empty)\"", "\n", "\n", "# limit characters to avoid tokenization bottlenecks", "\n", "", "return", "query", "[", ":", "self", ".", "char_limit", "]", ",", "doc", "[", ":", "self", ".", "char_limit", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert.BERTDataProcessor.get_model_batch": [[40, 47], ["zip", "bert.BERTDataProcessor.tokenizer", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "get_model_batch", "(", "self", ",", "inputs", ":", "Iterable", "[", "BERTInput", "]", ")", "->", "BERTBatch", ":", "\n", "        ", "queries", ",", "docs", "=", "zip", "(", "*", "inputs", ")", "\n", "inputs", "=", "self", ".", "tokenizer", "(", "queries", ",", "docs", ",", "padding", "=", "True", ",", "truncation", "=", "True", ")", "\n", "return", "(", "\n", "torch", ".", "LongTensor", "(", "inputs", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "LongTensor", "(", "inputs", "[", "\"attention_mask\"", "]", ")", ",", "\n", "torch", ".", "LongTensor", "(", "inputs", "[", "\"token_type_ids\"", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert.BERTRanker.__init__": [[53, 72], ["ranking_utils.model.Ranker.__init__", "bert.BERTRanker.save_hyperparameters", "transformers.BertModel.from_pretrained", "bert.BERTRanker.bert.parameters", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "lr", ":", "float", ",", "warmup_steps", ":", "int", ",", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ",", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "hparams", "[", "\"bert_model\"", "]", ",", "return_dict", "=", "True", ")", "\n", "for", "p", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "not", "hparams", "[", "\"freeze_bert\"", "]", "\n", "", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "hparams", "[", "\"dropout\"", "]", ")", "\n", "self", ".", "classification", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "dense", ".", "out_features", ",", "1", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert.BERTRanker.forward": [[74, 85], ["bert.BERTRanker.classification", "bert.BERTRanker.dropout", "bert.BERTRanker.bert"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ":", "BERTBatch", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute the relevance scores for a batch.\n\n        Args:\n            batch (BERTBatch): BERT inputs.\n\n        Returns:\n            torch.Tensor: The output scores, shape (batch_size, 1).\n        \"\"\"", "\n", "cls_out", "=", "self", ".", "bert", "(", "*", "batch", ")", "[", "\"last_hidden_state\"", "]", "[", ":", ",", "0", "]", "\n", "return", "self", ".", "classification", "(", "self", ".", "dropout", "(", "cls_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert.BERTRanker.configure_optimizers": [[86, 92], ["torch.optim.AdamW", "transformers.get_constant_schedule_with_warmup", "filter", "bert.BERTRanker.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "        ", "opt", "=", "torch", ".", "optim", ".", "AdamW", "(", "\n", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", ",", "lr", "=", "self", ".", "lr", "\n", ")", "\n", "sched", "=", "get_constant_schedule_with_warmup", "(", "opt", ",", "self", ".", "warmup_steps", ")", "\n", "return", "[", "opt", "]", ",", "[", "{", "\"scheduler\"", ":", "sched", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNDataProcessor.__init__": [[28, 41], ["ranking_utils.model.data.DataProcessor.__init__", "transformers.BertTokenizer.from_pretrained", "transformers.logging.set_verbosity_error"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "bert_model", ":", "str", ",", "char_limit", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            bert_model (str): Pre-trained BERT model.\n            char_limit (int): Maximum number of characters per query/document.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ")", "\n", "self", ".", "char_limit", "=", "char_limit", "\n", "\n", "# without this, there will be a message for each tokenizer call", "\n", "transformers", ".", "logging", ".", "set_verbosity_error", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNDataProcessor.get_model_input": [[42, 57], ["bert_dmn.BERTDMNDataProcessor.tokenizer.tokenize", "nltk.sent_tokenize", "len", "len", "bert_dmn.BERTDMNDataProcessor.tokenizer.tokenize", "doc_tokenized.extend", "sentence_lengths.append", "torch.IntTensor", "query.strip", "doc.strip", "len"], "methods", ["None"], ["", "def", "get_model_input", "(", "self", ",", "query", ":", "str", ",", "doc", ":", "str", ")", "->", "BERTDMNInput", ":", "\n", "# empty queries or documents might cause problems later on", "\n", "        ", "if", "len", "(", "query", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "query", "=", "\"(empty)\"", "\n", "", "if", "len", "(", "doc", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "doc", "=", "\"(empty)\"", "\n", "\n", "", "query_tokenized", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "query", "[", ":", "self", ".", "char_limit", "]", ")", "\n", "doc_tokenized", "=", "[", "]", "\n", "sentence_lengths", "=", "[", "]", "\n", "for", "sentence", "in", "nltk", ".", "sent_tokenize", "(", "doc", "[", ":", "self", ".", "char_limit", "]", ")", ":", "\n", "            ", "sentence_tokenized", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "sentence", ")", "\n", "doc_tokenized", ".", "extend", "(", "sentence_tokenized", ")", "\n", "sentence_lengths", ".", "append", "(", "len", "(", "sentence_tokenized", ")", ")", "\n", "", "return", "query_tokenized", ",", "doc_tokenized", ",", "torch", ".", "IntTensor", "(", "sentence_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNDataProcessor.get_model_batch": [[58, 68], ["zip", "bert_dmn.BERTDMNDataProcessor.tokenizer", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.nn.utils.rnn.pad_sequence"], "methods", ["None"], ["", "def", "get_model_batch", "(", "self", ",", "inputs", ":", "Iterable", "[", "BERTDMNInput", "]", ")", "->", "BERTDMNBatch", ":", "\n", "        ", "queries_tokenized", ",", "docs_tokenized", ",", "sentence_lengths", "=", "zip", "(", "*", "inputs", ")", "\n", "inputs", "=", "self", ".", "tokenizer", "(", "\n", "queries_tokenized", ",", "docs_tokenized", ",", "padding", "=", "True", ",", "truncation", "=", "True", "\n", ")", "\n", "return", "(", "\n", "torch", ".", "LongTensor", "(", "inputs", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "LongTensor", "(", "inputs", "[", "\"attention_mask\"", "]", ")", ",", "\n", "torch", ".", "LongTensor", "(", "inputs", "[", "\"token_type_ids\"", "]", ")", ",", "\n", "pad_sequence", "(", "sentence_lengths", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.InputModule.__init__": [[76, 92], ["super().__init__", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "bert_dim", ":", "int", ",", "rep_dim", ":", "int", ",", "dropout", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            bert_dim (int): Number of hidden BERT units.\n            rep_dim (int): The dimension of fact and query representations.\n            dropout (float): Dropout value.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rep_dim", "=", "rep_dim", "\n", "\n", "self", ".", "input_gru", "=", "torch", ".", "nn", ".", "GRU", "(", "\n", "bert_dim", ",", "rep_dim", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", "\n", ")", "\n", "self", ".", "question_gru", "=", "torch", ".", "nn", ".", "GRU", "(", "bert_dim", ",", "rep_dim", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.InputModule._forward_queries": [[93, 112], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "bert_dmn.InputModule.question_gru", "torch.transpose"], "methods", ["None"], ["", "def", "_forward_queries", "(", "\n", "self", ",", "queries", ":", "torch", ".", "Tensor", ",", "query_lengths", ":", "List", "[", "int", "]", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Apply a GRU to a batch of queries.\n\n        Args:\n            queries (torch.Tensor): The query representations from BERT, each of shape (query_len, bert_dim).\n            query_lengths (List[int]): The query lengths, shape (batch_size,).\n\n        Returns:\n            torch.Tensor: The last GRU outputs, shape (batch_size, 1, rep_dim).\n        \"\"\"", "\n", "queries_padded", "=", "pad_sequence", "(", "queries", ",", "batch_first", "=", "True", ")", "\n", "queries_packed", "=", "pack_padded_sequence", "(", "\n", "queries_padded", ",", "query_lengths", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", "\n", ")", "\n", "_", ",", "h", "=", "self", ".", "question_gru", "(", "queries_packed", ")", "\n", "# transpose back to batch-first", "\n", "return", "torch", ".", "transpose", "(", "h", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.InputModule._forward_facts": [[113, 134], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "bert_dmn.InputModule.input_gru", "torch.nn.utils.rnn.pad_packed_sequence", "bert_dmn.InputModule.dropout"], "methods", ["None"], ["", "def", "_forward_facts", "(", "self", ",", "facts", ":", "torch", ".", "Tensor", ",", "num_facts", ":", "List", "[", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Apply dropout and a GRU to a batch of facts (input fusion).\n\n        Args:\n            facts (torch.Tensor): The fact representations from BERT, each of shape (num_facts, bert_dim).\n            num_facts (List[int]): The number of facts, shape (batch_size,).\n\n        Returns:\n            torch.Tensor: The GRU output, shape (batch_size, max_facts_len, rep_dim).\n        \"\"\"", "\n", "facts_padded", "=", "pad_sequence", "(", "facts", ",", "batch_first", "=", "True", ")", "\n", "facts_packed", "=", "pack_padded_sequence", "(", "\n", "self", ".", "dropout", "(", "facts_padded", ")", ",", "\n", "num_facts", ",", "\n", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ",", "\n", ")", "\n", "gru_output", ",", "_", "=", "self", ".", "input_gru", "(", "facts_packed", ")", "\n", "padded_output", ",", "_", "=", "pad_packed_sequence", "(", "gru_output", ",", "batch_first", "=", "True", ")", "\n", "# sum outputs of both directions", "\n", "return", "padded_output", "[", ":", ",", ":", ",", ":", "self", ".", "rep_dim", "]", "+", "padded_output", "[", ":", ",", ":", ",", "self", ".", "rep_dim", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.InputModule.forward": [[135, 163], ["bert_dmn.InputModule.input_gru.flatten_parameters", "bert_dmn.InputModule.question_gru.flatten_parameters", "zip", "query_lengths.append", "num_facts.append", "bert_dmn.InputModule._forward_queries", "bert_dmn.InputModule._forward_facts"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._forward_queries", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._forward_facts"], ["", "def", "forward", "(", "\n", "self", ",", "queries", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "facts", ":", "List", "[", "torch", ".", "Tensor", "]", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "\"\"\"Extract the query representation and facts from BERT outputs and apply input fusion.\n\n        Args:\n            queries (List[torch.Tensor]): The query representations from BERT, each of shape (query_len, bert_dim).\n            facts (List[torch.Tensor]): The fact representations from BERT, each of shape (num_facts, bert_dim).\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, List[int]]: A tuple containing\n                * the query representations, shape (batch_size, 1, rep_dim),\n                * the fact representations, shape (batch_size, max_num_facts, rep_dim),\n                * the number of facts for each query, shape (batch_size,).\n        \"\"\"", "\n", "# for multi-gpu training", "\n", "self", ".", "input_gru", ".", "flatten_parameters", "(", ")", "\n", "self", ".", "question_gru", ".", "flatten_parameters", "(", ")", "\n", "\n", "query_lengths", ",", "num_facts", "=", "[", "]", ",", "[", "]", "\n", "for", "query_out", ",", "facts_out", "in", "zip", "(", "queries", ",", "facts", ")", ":", "\n", "            ", "query_lengths", ".", "append", "(", "query_out", ".", "shape", "[", "0", "]", ")", "\n", "num_facts", ".", "append", "(", "facts_out", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "return", "(", "\n", "self", ".", "_forward_queries", "(", "queries", ",", "query_lengths", ")", ",", "\n", "self", ".", "_forward_facts", "(", "facts", ",", "num_facts", ")", ",", "\n", "num_facts", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.AnswerModule.__init__": [[169, 180], ["super().__init__", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "dropout", ":", "float", ",", "bert_dim", ":", "int", ",", "rep_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            dropout (float): Dropout value.\n            bert_dim (int): Number of hidden BERT units.\n            rep_dim (int): The dimension of the memory.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "bert_dim", "+", "2", "*", "rep_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.AnswerModule.forward": [[181, 196], ["bert_dmn.AnswerModule.linear", "bert_dmn.AnswerModule.dropout", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "cls_outputs", ":", "torch", ".", "Tensor", ",", "queries", ":", "torch", ".", "Tensor", ",", "memories", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Return a batch of scores.\n\n        Args:\n            cls_outputs (torch.Tensor): The CLS outputs from BERT, shape (batch_size, bert_dim).\n            queries (torch.Tensor): The query representations, shape (batch_size, rep_dim).\n            memories (torch.Tensor): The final memories, shape (batch_size, rep_dim).\n\n        Returns:\n            torch.Tensor: The scores, shape (batch_size, 1).\n        \"\"\"", "\n", "return", "self", ".", "linear", "(", "\n", "self", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "cls_outputs", ",", "queries", ",", "memories", "]", ",", "dim", "=", "1", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.DMN.__init__": [[202, 226], ["super().__init__", "bert_dmn.InputModule", "models.dmn.MemoryModule", "bert_dmn.AnswerModule"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "bert_dim", ":", "int", ",", "\n", "rep_dim", ":", "int", ",", "\n", "attention_dim", ":", "int", ",", "\n", "agru_dim", ":", "int", ",", "\n", "dropout", ":", "float", ",", "\n", "num_episodes", ":", "int", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            bert_dim (int): Number of hidden BERT units.\n            rep_dim (int): The dimension of fact and query representations and memory.\n            attention_dim (int): The dimension of the linear layer applied to the interactions.\n            agru_dim (int): The hidden dimension of the attention GRU.\n            dropout (float): Dropout value.\n            num_episodes (int): The number of DMN episodes.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_module", "=", "InputModule", "(", "bert_dim", ",", "rep_dim", ",", "dropout", ")", "\n", "self", ".", "memory_module", "=", "MemoryModule", "(", "rep_dim", ",", "attention_dim", ",", "agru_dim", ")", "\n", "self", ".", "answer_module", "=", "AnswerModule", "(", "dropout", ",", "bert_dim", ",", "rep_dim", ")", "\n", "self", ".", "num_episodes", "=", "num_episodes", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.DMN.forward": [[227, 248], ["bert_dmn.DMN.input_module", "range", "bert_dmn.DMN.answer_module", "bert_dmn.DMN.memory_module", "queries.squeeze", "bert_dmn.DMN.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "cls_outputs", ":", "torch", ".", "Tensor", ",", "\n", "queries", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", "facts", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute the relevance scores for a batch.\n\n        Args:\n            cls_outputs (torch.Tensor): BERT outputs corresponding to the CLS tokens, shape (batch_size, bert_dim).\n            queries (List[torch.Tensor]): The query representations from BERT, each of shape (query_len, bert_dim).\n            facts (List[torch.Tensor]): The fact representations from BERT, each of shape (num_facts, bert_dim).\n\n        Returns:\n            torch.Tensor: The scores, shape (batch_size, 1).\n        \"\"\"", "\n", "queries", ",", "facts", ",", "num_facts", "=", "self", ".", "input_module", "(", "queries", ",", "facts", ")", "\n", "m", "=", "queries", "\n", "for", "_", "in", "range", "(", "self", ".", "num_episodes", ")", ":", "\n", "            ", "m", "=", "self", ".", "memory_module", "(", "queries", ",", "facts", ",", "num_facts", ",", "m", ")", "\n", "", "return", "self", ".", "answer_module", "(", "cls_outputs", ",", "queries", ".", "squeeze", "(", "1", ")", ",", "m", ".", "squeeze", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker.__init__": [[253, 282], ["ranking_utils.model.Ranker.__init__", "bert_dmn.BERTDMNRanker.save_hyperparameters", "transformers.BertModel.from_pretrained", "bert_dmn.DMN", "transformers.BertTokenizer.from_pretrained", "bert_dmn.BERTDMNRanker.bert.parameters"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "lr", ":", "float", ",", "warmup_steps", ":", "int", ",", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ",", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "\n", "self", ".", "cache", ",", "self", ".", "pos_cache", ",", "self", ".", "neg_cache", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "hparams", "[", "\"bert_model\"", "]", ",", "return_dict", "=", "True", ")", "\n", "\n", "self", ".", "dmn", "=", "DMN", "(", "\n", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "dense", ".", "out_features", ",", "\n", "hparams", "[", "\"rep_dim\"", "]", ",", "\n", "hparams", "[", "\"attention_dim\"", "]", ",", "\n", "hparams", "[", "\"agru_dim\"", "]", ",", "\n", "hparams", "[", "\"dropout\"", "]", ",", "\n", "hparams", "[", "\"num_episodes\"", "]", ",", "\n", ")", "\n", "self", ".", "sep_id", "=", "BertTokenizer", ".", "from_pretrained", "(", "hparams", "[", "\"bert_model\"", "]", ")", ".", "sep_token_id", "\n", "\n", "if", "hparams", "[", "\"lite\"", "]", ":", "\n", "            ", "for", "p", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker.forward": [[283, 370], ["bert_dmn.BERTDMNRanker.dmn", "enumerate", "zip", "torch.stack", "int", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "zip", "cls_outputs.append", "query_outputs.append", "fact_outputs.append", "bert_dmn.BERTDMNRanker.bert", "bert_dmn.BERTDMNRanker._split_outputs", "cls_outputs.append", "query_outputs.append", "fact_outputs.append", "missing_idxs.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "bert_dmn.BERTDMNRanker.bert", "bert_dmn.BERTDMNRanker._split_outputs", "t.to", "cls_out.cpu", "query_out.cpu", "facts_out.cpu", "int"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker._split_outputs", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker._split_outputs"], ["", "", "", "def", "forward", "(", "\n", "self", ",", "\n", "batch", ":", "BERTDMNBatch", ",", "\n", "data_indices", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "cache", ":", "Dict", "[", "int", ",", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute the relevance scores for a batch.\n\n        Args:\n            batch (BERTDMNBatch): BERT-DMN inputs.\n            data_indices (torch.Tensor, optional): Unique data IDs used for caching. Defaults to None.\n            cache (Dict[int, torch.Tensor], optional): Maps IDs to cached output tensors. Defaults to None.\n\n        Returns:\n            torch.Tensor: The scores, shape (batch_size, 1).\n        \"\"\"", "\n", "in_ids", ",", "masks", ",", "tt_ids", ",", "sentence_lengths", "=", "batch", "\n", "cls_outputs", ",", "query_outputs", ",", "fact_outputs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# BERT-DMN-lite caching", "\n", "if", "self", ".", "hparams", "[", "\"lite\"", "]", "and", "not", "self", ".", "hparams", "[", "\"no_cache\"", "]", "and", "self", ".", "training", ":", "\n", "            ", "temp_outputs", "=", "{", "}", "\n", "missing_idxs", "=", "[", "]", "\n", "missing_in_ids", "=", "[", "]", "\n", "missing_masks", "=", "[", "]", "\n", "missing_tt_ids", "=", "[", "]", "\n", "missing_sentence_lengths", "=", "[", "]", "\n", "\n", "# the inputs have a unique ID each", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "data_indices", ")", ":", "\n", "                ", "idx", "=", "int", "(", "idx", ")", "\n", "\n", "# if the output for the ID was already cached, put it back on this device", "\n", "if", "idx", "in", "cache", ":", "\n", "                    ", "temp_outputs", "[", "idx", "]", "=", "[", "t", ".", "to", "(", "in_ids", ".", "device", ")", "for", "t", "in", "cache", "[", "idx", "]", "]", "\n", "\n", "# all missing outputs will be computed in one batch", "\n", "", "else", ":", "\n", "                    ", "missing_idxs", ".", "append", "(", "idx", ")", "\n", "missing_in_ids", ".", "append", "(", "in_ids", "[", "i", "]", ")", "\n", "missing_masks", ".", "append", "(", "masks", "[", "i", "]", ")", "\n", "missing_tt_ids", ".", "append", "(", "tt_ids", "[", "i", "]", ")", "\n", "missing_sentence_lengths", ".", "append", "(", "sentence_lengths", "[", "i", "]", ")", "\n", "\n", "# compute missing outputs if there are any and put them in the cache", "\n", "", "", "if", "len", "(", "missing_idxs", ")", ">", "0", ":", "\n", "                ", "missing_in_ids", "=", "torch", ".", "stack", "(", "missing_in_ids", ")", "\n", "missing_masks", "=", "torch", ".", "stack", "(", "missing_masks", ")", "\n", "missing_tt_ids", "=", "torch", ".", "stack", "(", "missing_tt_ids", ")", "\n", "missing_sentence_lengths", "=", "torch", ".", "stack", "(", "missing_sentence_lengths", ")", "\n", "\n", "last_hidden_state", "=", "self", ".", "bert", "(", "\n", "missing_in_ids", ",", "missing_masks", ",", "missing_tt_ids", "\n", ")", "[", "\"last_hidden_state\"", "]", "\n", "for", "idx", ",", "item_in", ",", "item_out", ",", "item_sentence_lengths", "in", "zip", "(", "\n", "missing_idxs", ",", "\n", "missing_in_ids", ",", "\n", "last_hidden_state", ",", "\n", "missing_sentence_lengths", ",", "\n", ")", ":", "\n", "                    ", "cls_out", ",", "query_out", ",", "facts_out", "=", "self", ".", "_split_outputs", "(", "\n", "item_in", ",", "item_out", ",", "item_sentence_lengths", "\n", ")", "\n", "temp_outputs", "[", "idx", "]", "=", "cls_out", ",", "query_out", ",", "facts_out", "\n", "cache", "[", "idx", "]", "=", "cls_out", ".", "cpu", "(", ")", ",", "query_out", ".", "cpu", "(", ")", ",", "facts_out", ".", "cpu", "(", ")", "\n", "\n", "# assemble all outputs in the correct order", "\n", "", "", "for", "idx", "in", "data_indices", ":", "\n", "                ", "cls_out", ",", "query_out", ",", "facts_out", "=", "temp_outputs", "[", "int", "(", "idx", ")", "]", "\n", "cls_outputs", ".", "append", "(", "cls_out", ")", "\n", "query_outputs", ".", "append", "(", "query_out", ")", "\n", "fact_outputs", ".", "append", "(", "facts_out", ")", "\n", "\n", "# inference/regular BERT-DMN training", "\n", "", "", "else", ":", "\n", "            ", "last_hidden_state", "=", "self", ".", "bert", "(", "in_ids", ",", "masks", ",", "tt_ids", ")", "[", "\"last_hidden_state\"", "]", "\n", "for", "item_in", ",", "item_out", ",", "item_sentence_lengths", "in", "zip", "(", "\n", "in_ids", ",", "last_hidden_state", ",", "sentence_lengths", "\n", ")", ":", "\n", "                ", "cls_out", ",", "query_out", ",", "facts_out", "=", "self", ".", "_split_outputs", "(", "\n", "item_in", ",", "item_out", ",", "item_sentence_lengths", "\n", ")", "\n", "cls_outputs", ".", "append", "(", "cls_out", ")", "\n", "query_outputs", ".", "append", "(", "query_out", ")", "\n", "fact_outputs", ".", "append", "(", "facts_out", ")", "\n", "\n", "", "", "return", "self", ".", "dmn", "(", "torch", ".", "stack", "(", "cls_outputs", ")", ",", "query_outputs", ",", "fact_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker._split_outputs": [[371, 407], ["torch.stack", "len", "fact_outputs.append", "torch.mean"], "methods", ["None"], ["", "def", "_split_outputs", "(", "\n", "self", ",", "\n", "item_in", ":", "torch", ".", "Tensor", ",", "\n", "item_out", ":", "torch", ".", "Tensor", ",", "\n", "item_sentence_lengths", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Split a BERT output sequence into query and fact outputs.\n\n        Args:\n            item_in (torch.Tensor): BERT input IDs, shape (seq_len,).\n            item_out (torch.Tensor): Corresponding BERT outputs, shape (seq_len, bert_dim).\n            item_sentence_lengths (torch.Tensor): Sentence lengths, shape (max_num_sent).\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing\n                * the BERT outputs for the CLS token, shape (bert_dim,),\n                * the query outputs, shape (query_len, bert_dim),\n                * the document facts as averaged sentence outputs, shape (num_sentences, bert_dim).\n        \"\"\"", "\n", "# we always have 2 separators", "\n", "sep1", ",", "sep2", "=", "(", "item_in", "==", "self", ".", "sep_id", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", ")", "\n", "\n", "# split outputs into query and document parts", "\n", "query_outputs", "=", "item_out", "[", "1", ":", "sep1", "]", "\n", "doc_outputs", "=", "item_out", "[", "sep1", "+", "1", ":", "sep2", "]", "\n", "\n", "# split the document outputs into facts", "\n", "fact_outputs", "=", "[", "]", "\n", "idx", "=", "0", "\n", "# we will get all sentences this way, even if the last one was truncated", "\n", "for", "length", "in", "item_sentence_lengths", ":", "\n", "            ", "s", "=", "doc_outputs", "[", "idx", ":", "idx", "+", "length", "]", "\n", "idx", "+=", "length", "\n", "if", "len", "(", "s", ")", ">", "0", ":", "\n", "                ", "fact_outputs", ".", "append", "(", "torch", ".", "mean", "(", "s", ",", "dim", "=", "0", ")", ")", "\n", "", "", "return", "item_out", "[", "0", "]", ",", "query_outputs", ",", "torch", ".", "stack", "(", "fact_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker.configure_optimizers": [[408, 415], ["torch.optim.AdamW", "transformers.get_constant_schedule_with_warmup", "params.append", "bert_dmn.BERTDMNRanker.dmn.parameters", "bert_dmn.BERTDMNRanker.bert.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "        ", "params", "=", "[", "{", "\"params\"", ":", "self", ".", "dmn", ".", "parameters", "(", ")", ",", "\"lr\"", ":", "self", ".", "lr", "}", "]", "\n", "if", "not", "self", ".", "hparams", "[", "\"lite\"", "]", ":", "\n", "            ", "params", ".", "append", "(", "{", "\"params\"", ":", "self", ".", "bert", ".", "parameters", "(", ")", ",", "\"lr\"", ":", "self", ".", "lr", "}", ")", "\n", "", "opt", "=", "AdamW", "(", "params", ")", "\n", "sched", "=", "get_constant_schedule_with_warmup", "(", "opt", ",", "self", ".", "warmup_steps", ")", "\n", "return", "[", "opt", "]", ",", "[", "{", "\"scheduler\"", ":", "sched", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.bert_dmn.BERTDMNRanker.training_step": [[416, 437], ["bert_dmn.BERTDMNRanker.log", "torch.sigmoid", "bert_dmn.BERTDMNRanker.bce", "bert_dmn.BERTDMNRanker.", "torch.sigmoid.flatten", "labels.flatten", "torch.sigmoid", "torch.sigmoid", "torch.mean", "bert_dmn.BERTDMNRanker.", "bert_dmn.BERTDMNRanker.", "torch.clamp"], "methods", ["None"], ["", "def", "training_step", "(", "\n", "self", ",", "\n", "batch", ":", "Union", "[", "PointwiseTrainingBatch", ",", "PairwiseTrainingBatch", "]", ",", "\n", "batch_idx", ":", "int", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "training_mode", "==", "TrainingMode", ".", "POINTWISE", ":", "\n", "            ", "model_batch", ",", "labels", ",", "indices", "=", "batch", "\n", "outputs", "=", "torch", ".", "sigmoid", "(", "self", "(", "model_batch", ",", "indices", ",", "self", ".", "cache", ")", ")", "\n", "loss", "=", "self", ".", "bce", "(", "outputs", ".", "flatten", "(", ")", ",", "labels", ".", "flatten", "(", ")", ")", "\n", "", "elif", "self", ".", "training_mode", "==", "TrainingMode", ".", "PAIRWISE", ":", "\n", "            ", "pos_inputs", ",", "neg_inputs", ",", "indices", "=", "batch", "\n", "pos_outputs", "=", "torch", ".", "sigmoid", "(", "self", "(", "pos_inputs", ",", "indices", ",", "self", ".", "pos_cache", ")", ")", "\n", "neg_outputs", "=", "torch", ".", "sigmoid", "(", "self", "(", "neg_inputs", ",", "indices", ",", "self", ".", "neg_cache", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "\n", "torch", ".", "clamp", "(", "\n", "self", ".", "pairwise_loss_margin", "-", "pos_outputs", "+", "neg_outputs", ",", "min", "=", "0", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\"train_loss\"", ",", "loss", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRDataProcessor.__init__": [[26, 52], ["ranking_utils.model.data.DataProcessor.__init__", "transformers.BertTokenizer.from_pretrained", "transformers.logging.set_verbosity_error"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "bert_model", ":", "str", ",", "\n", "max_query_tokens", ":", "int", ",", "\n", "max_doc_tokens", ":", "int", ",", "\n", "max_sentences", ":", "int", ",", "\n", "passage_length", ":", "int", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            bert_model (str): Pre-trained BERT model.\n            max_query_tokens (int): Maximum number of query tokens.\n            max_doc_tokens (int): Maximum number of document tokens.\n            max_sentences (int): Maximum number of sentences considered in a document.\n            passage_length (int): Number of sentences per passage.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ")", "\n", "self", ".", "max_query_tokens", "=", "max_query_tokens", "\n", "self", ".", "max_doc_tokens", "=", "max_doc_tokens", "\n", "self", ".", "max_sentences", "=", "max_sentences", "\n", "self", ".", "passage_length", "=", "passage_length", "\n", "\n", "# without this, there will be a message for each tokenizer call", "\n", "transformers", ".", "logging", ".", "set_verbosity_error", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRDataProcessor.get_model_input": [[53, 87], ["range", "len", "len", "len", "nltk.sent_tokenize", "len", "len", "sum", "len", "torch.LongTensor", "torch.LongTensor", "torch.IntTensor", "query.strip", "doc.strip", "select_and_rank.SRDataProcessor.tokenizer", "select_and_rank.SRDataProcessor.tokenizer", "doc_inputs.extend", "lengths.append", "doc_inputs.extend", "lengths.append", "sum", "len", "sum", "len"], "methods", ["None"], ["", "def", "get_model_input", "(", "self", ",", "query", ":", "str", ",", "doc", ":", "str", ")", "->", "SRInput", ":", "\n", "# empty queries or documents might cause problems later on", "\n", "        ", "if", "len", "(", "query", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "query", "=", "\"(empty)\"", "\n", "", "if", "len", "(", "doc", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "doc", "=", "\"(empty)\"", "\n", "\n", "", "query_inputs", "=", "self", ".", "tokenizer", "(", "query", ",", "add_special_tokens", "=", "False", ")", "[", "\"input_ids\"", "]", "[", "\n", ":", "self", ".", "max_query_tokens", "\n", "]", "\n", "assert", "len", "(", "query_inputs", ")", "<=", "self", ".", "max_query_tokens", "\n", "\n", "doc_inputs", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "tokens", "=", "nltk", ".", "sent_tokenize", "(", "doc", ")", "[", ":", "self", ".", "max_sentences", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "tokens", ")", ",", "self", ".", "passage_length", ")", ":", "\n", "            ", "passage", "=", "\" \"", ".", "join", "(", "tokens", "[", "i", ":", "i", "+", "self", ".", "passage_length", "]", ")", "\n", "inputs", "=", "self", ".", "tokenizer", "(", "passage", ",", "add_special_tokens", "=", "False", ")", "[", "\"input_ids\"", "]", "\n", "\n", "if", "sum", "(", "lengths", ")", "+", "len", "(", "inputs", ")", ">", "self", ".", "max_doc_tokens", ":", "\n", "                ", "remaining", "=", "self", ".", "max_doc_tokens", "-", "sum", "(", "lengths", ")", "\n", "doc_inputs", ".", "extend", "(", "inputs", "[", ":", "remaining", "]", ")", "\n", "lengths", ".", "append", "(", "remaining", ")", "\n", "break", "\n", "", "else", ":", "\n", "                ", "doc_inputs", ".", "extend", "(", "inputs", ")", "\n", "lengths", ".", "append", "(", "len", "(", "inputs", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "doc_inputs", ")", "==", "sum", "(", "lengths", ")", "\n", "assert", "len", "(", "doc_inputs", ")", "<=", "self", ".", "max_doc_tokens", "\n", "return", "(", "\n", "torch", ".", "LongTensor", "(", "query_inputs", ")", ",", "\n", "torch", ".", "LongTensor", "(", "doc_inputs", ")", ",", "\n", "torch", ".", "IntTensor", "(", "lengths", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRDataProcessor.get_model_batch": [[89, 104], ["zip", "torch.IntTensor", "torch.IntTensor", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "list", "list", "map", "map"], "methods", ["None"], ["", "def", "get_model_batch", "(", "self", ",", "inputs", ":", "Iterable", "[", "SRInput", "]", ")", "->", "SRBatch", ":", "\n", "        ", "query_inputs", ",", "doc_inputs", ",", "lengths", "=", "zip", "(", "*", "inputs", ")", "\n", "query_lengths", "=", "torch", ".", "IntTensor", "(", "list", "(", "map", "(", "len", ",", "query_inputs", ")", ")", ")", "\n", "doc_lengths", "=", "torch", ".", "IntTensor", "(", "list", "(", "map", "(", "len", ",", "doc_inputs", ")", ")", ")", "\n", "query_inputs_padded", "=", "pad_sequence", "(", "\n", "query_inputs", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", "\n", ")", "\n", "doc_inputs_padded", "=", "pad_sequence", "(", "doc_inputs", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "lengths_padded", "=", "pad_sequence", "(", "lengths", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "return", "(", "\n", "query_inputs_padded", ",", "\n", "query_lengths", ",", "\n", "doc_inputs_padded", ",", "\n", "doc_lengths", ",", "\n", "lengths_padded", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector.__init__": [[112, 144], ["super().__init__", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Softmax", "torch.nn.Dropout", "torch.nn.CosineSimilarity"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding", ":", "torch", ".", "nn", ".", "Embedding", ",", "\n", "input_dim", ":", "int", ",", "\n", "hidden_dim", ":", "int", ",", "\n", "attention_dim", ":", "int", ",", "\n", "dropout", ":", "float", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embedding (Embedding): Embedding for query and document tokens.\n            input_dim (int): Input dimension.\n            hidden_dim (int): LSTM hidden dimension.\n            attention_dim (int): Attention dimension.\n            dropout (float): Dropout rate.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding", "=", "embedding", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "\n", "input_dim", ",", "hidden_dim", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", "\n", ")", "\n", "\n", "# attention", "\n", "self", ".", "W_attn_q", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", "*", "2", ",", "attention_dim", ")", "\n", "self", ".", "W_attn_s", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", "*", "2", ",", "attention_dim", ")", "\n", "self", ".", "w_attn", "=", "torch", ".", "nn", ".", "Linear", "(", "attention_dim", ",", "1", ")", "\n", "self", ".", "tanh", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "softmax_attn", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "cos_sim", "=", "torch", ".", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector.encode_batch": [[145, 159], ["select_and_rank.AttentionSelector._encode", "select_and_rank.AttentionSelector._max_pool"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._encode", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._max_pool"], ["", "def", "encode_batch", "(", "\n", "self", ",", "sequences", ":", "torch", ".", "LongTensor", ",", "lengths", ":", "torch", ".", "IntTensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Encode a batch of sequences using the LSTM and apply max pooling.\n\n        Args:\n            sequences (torch.LongTensor): A batch of sequences.\n            lengths (torch.IntTensor): Sequence lengths.\n\n        Returns:\n            torch.Tensor: The sequence representations.\n        \"\"\"", "\n", "seq_enc", "=", "self", ".", "_encode", "(", "sequences", ",", "lengths", ")", "\n", "return", "self", ".", "_max_pool", "(", "seq_enc", ",", "lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector._encode": [[160, 179], ["select_and_rank.AttentionSelector.embedding", "torch.nn.utils.rnn.pack_padded_sequence", "select_and_rank.AttentionSelector.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.cpu"], "methods", ["None"], ["", "def", "_encode", "(", "\n", "self", ",", "inputs", ":", "torch", ".", "LongTensor", ",", "lengths", ":", "torch", ".", "IntTensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Encode sequences using the LSTM.\n\n        Args:\n            inputs (torch.LongTensor): Input IDs.\n            lengths (torch.IntTensor): Input lengths.\n\n        Returns:\n            torch.Tensor: The LSTM outputs.\n        \"\"\"", "\n", "inputs_emb", "=", "self", ".", "embedding", "(", "inputs", ")", "\n", "inputs_packed", "=", "pack_padded_sequence", "(", "\n", "inputs_emb", ",", "lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", "\n", ")", "\n", "lstm_out", ",", "_", "=", "self", ".", "lstm", "(", "inputs_packed", ")", "\n", "out", ",", "_", "=", "pad_packed_sequence", "(", "lstm_out", ",", "batch_first", "=", "True", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector._max_pool": [[180, 209], ["torch.arange().unsqueeze().expand", "rng.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "inputs.clone", "float", "torch.max", "torch.arange().unsqueeze", "rng.unsqueeze().expand.unsqueeze().expand.unsqueeze", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze", "torch.arange"], "methods", ["None"], ["", "def", "_max_pool", "(", "\n", "self", ",", "inputs", ":", "torch", ".", "FloatTensor", ",", "lengths", ":", "torch", ".", "IntTensor", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"Masked max pooling.\n\n        Args:\n            inputs (torch.FloatTensor): Input sequences.\n            lengths (torch.IntTensor): Sequence lengths.\n\n        Returns:\n            torch.FloatTensor: Output tensor.\n        \"\"\"", "\n", "num_items", ",", "max_len", ",", "num_hidden", "=", "inputs", ".", "shape", "\n", "\n", "# create mask", "\n", "rng", "=", "(", "\n", "torch", ".", "arange", "(", "max_len", ",", "device", "=", "inputs", ".", "device", ")", "\n", ".", "unsqueeze", "(", "0", ")", "\n", ".", "expand", "(", "num_items", ",", "-", "1", ")", "\n", ")", "\n", "rng", "=", "rng", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "num_hidden", ")", "\n", "lengths", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "num_hidden", ")", "\n", "lengths", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "max_len", ",", "-", "1", ")", "\n", "mask", "=", "rng", "<", "lengths", "[", ":", "num_items", "]", "\n", "\n", "# set padding outputs to -inf so they dont affect max pooling", "\n", "inputs_clone", "=", "inputs", ".", "clone", "(", ")", "\n", "inputs_clone", "[", "~", "mask", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "return", "torch", ".", "max", "(", "inputs_clone", ",", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector._get_passage_outputs": [[210, 234], ["torch.nn.utils.rnn.pad_sequence", "result.append"], "methods", ["None"], ["", "def", "_get_passage_outputs", "(", "\n", "self", ",", "doc_encoded", ":", "torch", ".", "FloatTensor", ",", "lengths", ":", "torch", ".", "IntTensor", "\n", ")", "->", "List", "[", "torch", ".", "FloatTensor", "]", ":", "\n", "        ", "\"\"\"Split the outputs of a single document into passages.\n\n        Args:\n            doc_encoded (torch.FloatTensor): The LSTM document outputs.\n            lengths (torch.IntTensor): The passage lengths.\n\n        Returns:\n            torch.FloatTensor: The passage outputs, padded.\n        \"\"\"", "\n", "result", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "length", "in", "lengths", ":", "\n", "\n", "# if the length is zero, we reached the padding", "\n", "            ", "if", "length", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "next_idx", "=", "idx", "+", "length", "\n", "result", ".", "append", "(", "doc_encoded", "[", "idx", ":", "next_idx", "]", ")", "\n", "idx", "=", "next_idx", "\n", "", "return", "pad_sequence", "(", "result", ",", "batch_first", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector._attention": [[235, 263], ["select_and_rank.AttentionSelector.W_attn_s", "select_and_rank.AttentionSelector.w_attn", "float", "query_rep_attn.expand_as", "select_and_rank.AttentionSelector.tanh", "select_and_rank.AttentionSelector.softmax_attn", "torch.arange"], "methods", ["None"], ["", "def", "_attention", "(", "\n", "self", ",", "\n", "query_rep_attn", ":", "torch", ".", "FloatTensor", ",", "\n", "outputs", ":", "torch", ".", "FloatTensor", ",", "\n", "lengths", ":", "torch", ".", "IntTensor", ",", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"Compute a simple query-passage attention.\n\n        Args:\n            query_rep_attn (torch.FloatTensor): Query representation (pre-computed attention).\n            outputs (torch.FloatTensor): Outputs for each passage in a document.\n            lengths (torch.IntTensor): Passage lengths.\n\n        Returns:\n            torch.FloatTensor: Results to be pooled and used as passage representations.\n        \"\"\"", "\n", "num", ",", "max_len", ",", "_", "=", "outputs", ".", "shape", "\n", "attn", "=", "self", ".", "W_attn_s", "(", "outputs", ")", "\n", "attn_sum", "=", "query_rep_attn", ".", "expand_as", "(", "attn", ")", "+", "attn", "\n", "attn_weights", "=", "self", ".", "w_attn", "(", "self", ".", "tanh", "(", "attn_sum", ")", ")", "\n", "\n", "# mask the padding tokens before computing the softmax by setting the corresponding values to -inf", "\n", "mask", "=", "(", "\n", "torch", ".", "arange", "(", "max_len", ",", "device", "=", "query_rep_attn", ".", "device", ")", "[", "None", ",", ":", "]", "\n", "<", "lengths", "[", ":", "num", ",", "None", "]", "\n", ")", "\n", "attn_weights", "[", "~", "mask", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "return", "outputs", "*", "self", ".", "softmax_attn", "(", "attn_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector._get_scores": [[264, 279], ["query_rep.expand_as", "select_and_rank.AttentionSelector.cos_sim", "select_and_rank.AttentionSelector.dropout", "select_and_rank.AttentionSelector.dropout"], "methods", ["None"], ["", "def", "_get_scores", "(", "\n", "self", ",", "query_rep", ":", "torch", ".", "FloatTensor", ",", "passage_reps", ":", "torch", ".", "FloatTensor", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"Return scores between query and each passage using cosine similarity, applying dropout.\n\n        Args:\n            query_rep (torch.FloatTensor): Query representation.\n            passage_reps (torch.FloatTensor): Passage representations.\n\n        Returns:\n            torch.FloatTensor: A score for each passage.\n        \"\"\"", "\n", "a", "=", "query_rep", ".", "expand_as", "(", "passage_reps", ")", "\n", "b", "=", "passage_reps", "\n", "return", "self", ".", "cos_sim", "(", "self", ".", "dropout", "(", "a", ")", ",", "self", ".", "dropout", "(", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector.forward": [[280, 308], ["select_and_rank.AttentionSelector._encode", "select_and_rank.AttentionSelector._encode", "select_and_rank.AttentionSelector._max_pool", "select_and_rank.AttentionSelector.W_attn_q", "zip", "select_and_rank.AttentionSelector._get_passage_outputs", "select_and_rank.AttentionSelector._attention", "select_and_rank.AttentionSelector._max_pool", "scores.append", "select_and_rank.AttentionSelector._get_scores"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._encode", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._encode", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._max_pool", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.AttentionSelector._get_passage_outputs", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._attention", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._max_pool", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector._get_scores"], ["", "def", "forward", "(", "self", ",", "batch", ":", "SRBatch", ")", "->", "List", "[", "torch", ".", "FloatTensor", "]", ":", "\n", "        ", "\"\"\"Return passage scores.\n\n        Args:\n            batch (SRBatch): Input batch.\n\n        Returns:\n            List[torch.FloatTensor]: A score for each passage in each input sequence.\n        \"\"\"", "\n", "q_in", ",", "q_lens", ",", "d_in", ",", "d_lens", ",", "p_lens", "=", "batch", "\n", "\n", "# queries and docs are encoded using the shared LSTM", "\n", "q_enc", "=", "self", ".", "_encode", "(", "q_in", ",", "q_lens", ")", "\n", "d_enc", "=", "self", ".", "_encode", "(", "d_in", ",", "d_lens", ")", "\n", "\n", "# queries are represented as the average of the LSTM outputs", "\n", "q_reps", "=", "self", ".", "_max_pool", "(", "q_enc", ",", "q_lens", ")", "\n", "\n", "# pre-compute query representations for the attention", "\n", "q_reps_att", "=", "self", ".", "W_attn_q", "(", "q_reps", ")", "\n", "\n", "scores", "=", "[", "]", "\n", "for", "q_rep", ",", "q_rep_att", ",", "d_enc_", ",", "p_lens_", "in", "zip", "(", "q_reps", ",", "q_reps_att", ",", "d_enc", ",", "p_lens", ")", ":", "\n", "            ", "p_out", "=", "self", ".", "_get_passage_outputs", "(", "d_enc_", ",", "p_lens_", ")", "\n", "p_out_attn", "=", "self", ".", "_attention", "(", "q_rep_att", ",", "p_out", ",", "p_lens_", ")", "\n", "p_reps", "=", "self", ".", "_max_pool", "(", "p_out_attn", ",", "p_lens_", ")", "\n", "scores", ".", "append", "(", "self", ".", "_get_scores", "(", "q_rep", ",", "p_reps", ")", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector.__init__": [[315, 334], ["super().__init__", "torch.nn.Linear", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embedding", ":", "torch", ".", "nn", ".", "Embedding", ",", "\n", "input_dim", ":", "int", ",", "\n", "hidden_dim", ":", "int", ",", "\n", "dropout", ":", "float", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embedding (Embedding): Embedding for query and document tokens.\n            input_dim (int): Input dimension.\n            hidden_dim (int): Hidden dimension.\n            dropout (float): Dropout rate.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding", "=", "embedding", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector.encode_batch": [[335, 360], ["select_and_rank.LinearSelector.embedding", "mask.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "select_and_rank.LinearSelector.linear", "torch.arange().unsqueeze", "lengths.unsqueeze", "torch.sum", "lengths.unsqueeze", "mask.unsqueeze().expand.unsqueeze().expand.unsqueeze", "torch.arange"], "methods", ["None"], ["", "def", "encode_batch", "(", "\n", "self", ",", "sequences", ":", "torch", ".", "LongTensor", ",", "lengths", ":", "torch", ".", "IntTensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Encode a batch of sequences, each as the average of its embeddings, and apply the linear layer.\n\n        Args:\n            sequences (torch.LongTensor): A batch of sequences.\n            lengths (torch.IntTensor): Sequence lengths.\n\n        Returns:\n            torch.Tensor: The sequence representations.\n        \"\"\"", "\n", "# embed all sequences", "\n", "sequences_emb", "=", "self", ".", "embedding", "(", "sequences", ")", "\n", "\n", "# create a mask corresponding to sequence lengths", "\n", "_", ",", "max_len", ",", "emb_dim", "=", "sequences_emb", ".", "shape", "\n", "mask", "=", "torch", ".", "arange", "(", "max_len", ",", "device", "=", "lengths", ".", "device", ")", ".", "unsqueeze", "(", "\n", "0", "\n", ")", "<", "lengths", ".", "unsqueeze", "(", "-", "1", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "emb_dim", ")", "\n", "\n", "# compute the mean for each passage", "\n", "passage_reps", "=", "torch", ".", "sum", "(", "mask", "*", "sequences_emb", ",", "dim", "=", "1", ")", "/", "lengths", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "self", ".", "linear", "(", "passage_reps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector._get_encoded_passages": [[361, 388], ["torch.nn.utils.rnn.pad_sequence", "select_and_rank.LinearSelector.encode_batch", "passages.append"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector.encode_batch"], ["", "def", "_get_encoded_passages", "(", "\n", "self", ",", "doc_inputs", ":", "torch", ".", "FloatTensor", ",", "lengths", ":", "torch", ".", "IntTensor", "\n", ")", "->", "List", "[", "torch", ".", "FloatTensor", "]", ":", "\n", "        ", "\"\"\"Split a document into passages and encode them.\n\n        Args:\n            doc_inputs (torch.FloatTensor): The document input IDs.\n            lengths (torch.IntTensor): The passage lengths.\n\n        Returns:\n            torch.FloatTensor: The encoded passages.\n        \"\"\"", "\n", "passages", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "length", "in", "lengths", ":", "\n", "\n", "# if the length is zero, we reached the padding", "\n", "            ", "if", "length", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "next_idx", "=", "idx", "+", "length", "\n", "passages", ".", "append", "(", "doc_inputs", "[", "idx", ":", "next_idx", "]", ")", "\n", "idx", "=", "next_idx", "\n", "\n", "", "passages_padded", "=", "pad_sequence", "(", "passages", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "num_passages", "=", "passages_padded", ".", "shape", "[", "0", "]", "\n", "return", "self", ".", "encode_batch", "(", "passages_padded", ",", "lengths", "[", ":", "num_passages", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector._get_scores": [[389, 405], ["query_encoded.expand_as", "select_and_rank.LinearSelector.dropout", "select_and_rank.LinearSelector.dropout"], "methods", ["None"], ["", "def", "_get_scores", "(", "\n", "self", ",", "query_encoded", ":", "torch", ".", "FloatTensor", ",", "passages_encoded", ":", "torch", ".", "FloatTensor", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"Return all scores between a query and each corresponding passage using a dot product, applying dropout.\n\n        Args:\n            query_encoded (torch.FloatTensor): Query representation.\n            passages_encoded (torch.FloatTensor): Passage representations.\n\n        Returns:\n            torch.FloatTensor: A score for each passage.\n        \"\"\"", "\n", "# row-wise dot product with individual dropout", "\n", "a", "=", "query_encoded", ".", "expand_as", "(", "passages_encoded", ")", "\n", "b", "=", "passages_encoded", "\n", "return", "(", "self", ".", "dropout", "(", "a", ")", "*", "self", ".", "dropout", "(", "b", ")", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector.forward": [[406, 424], ["select_and_rank.LinearSelector.encode_batch", "zip", "select_and_rank.LinearSelector._get_encoded_passages", "scores.append", "select_and_rank.LinearSelector._get_scores"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector.encode_batch", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector._get_encoded_passages", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.LinearSelector._get_scores"], ["", "def", "forward", "(", "self", ",", "batch", ":", "SRBatch", ")", "->", "List", "[", "torch", ".", "FloatTensor", "]", ":", "\n", "        ", "\"\"\"Return passage scores.\n\n        Args:\n            batch (SRBatch): Input batch\n\n        Returns:\n            List[torch.FloatTensor]: A score for each passage in each input sequence.\n        \"\"\"", "\n", "queries", ",", "query_lengths", ",", "docs", ",", "_", ",", "passage_lengths", "=", "batch", "\n", "queries_encoded", "=", "self", ".", "encode_batch", "(", "queries", ",", "query_lengths", ")", "\n", "scores", "=", "[", "]", "\n", "for", "query_encoded", ",", "doc", ",", "passage_lengths_item", "in", "zip", "(", "\n", "queries_encoded", ",", "docs", ",", "passage_lengths", "\n", ")", ":", "\n", "            ", "passages_encoded", "=", "self", ".", "_get_encoded_passages", "(", "doc", ",", "passage_lengths_item", ")", "\n", "scores", ".", "append", "(", "self", ".", "_get_scores", "(", "query_encoded", ",", "passages_encoded", ")", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.BERTRanker.__init__": [[431, 454], ["super().__init__", "transformers.BertModel.from_pretrained", "torch.nn.Dropout", "torch.nn.Linear", "transformers.BertTokenizer.from_pretrained", "select_and_rank.BERTRanker.parameters"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "bert_model", ":", "str", ",", "dropout", ":", "float", ",", "freeze", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            bert_model (str): Pre-trained BERT model.\n            dropout (float): Dropout value.\n            freeze (bool, optional): Don't update ranker weights during training. Defaults to False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ",", "return_dict", "=", "True", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "classification", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "self", ".", "bert", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "dense", ".", "out_features", ",", "1", "\n", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ")", "\n", "self", ".", "cls_id", "=", "tokenizer", ".", "cls_token_id", "\n", "self", ".", "sep_id", "=", "tokenizer", ".", "sep_token_id", "\n", "self", ".", "pad_id", "=", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "max_len", "=", "512", "\n", "\n", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "not", "freeze", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.BERTRanker._get_single_input": [[455, 539], ["torch.as_tensor", "torch.as_tensor", "zip", "in_ids.append", "tt_ids.append", "in_weights.append", "len", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "min", "in_ids.append", "mask.append", "torch.as_tensor", "torch.as_tensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "in_ids.append", "tt_ids.append", "in_weights.extend", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "weight.unsqueeze"], "methods", ["None"], ["", "", "def", "_get_single_input", "(", "\n", "self", ",", "\n", "query_in", ":", "torch", ".", "LongTensor", ",", "\n", "doc_in", ":", "torch", ".", "LongTensor", ",", "\n", "lengths", ":", "torch", ".", "IntTensor", ",", "\n", "weights", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Construct a single BERT input sequence.\n\n        Args:\n            query_in (torch.LongTensor): Query input IDs.\n            doc_in (torch.LongTensor): Document input IDs.\n            lengths (Sequence[int]): Passage lengths.\n            weights (torch.Tensor): Passage weights.\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: BERT inputs and weights.\n        \"\"\"", "\n", "# device for new tensors", "\n", "dev", "=", "query_in", ".", "device", "\n", "cls_tensor", "=", "torch", ".", "as_tensor", "(", "[", "self", ".", "cls_id", "]", ",", "device", "=", "dev", ")", "\n", "sep_tensor", "=", "torch", ".", "as_tensor", "(", "[", "self", ".", "sep_id", "]", ",", "device", "=", "dev", ")", "\n", "\n", "# keep track of sequence length to construct padding, mask and token type IDs", "\n", "in_ids", "=", "[", "cls_tensor", ",", "query_in", ",", "sep_tensor", "]", "\n", "running_seq_len", "=", "len", "(", "query_in", ")", "+", "2", "\n", "\n", "# token types are 0 up until (including) the 1st SEP", "\n", "tt_ids", "=", "[", "torch", ".", "as_tensor", "(", "[", "0", "]", "*", "running_seq_len", ",", "device", "=", "dev", ")", "]", "\n", "\n", "# CLS/query part -- set all weights to 1, as we always keep the query", "\n", "in_weights", "=", "[", "torch", ".", "as_tensor", "(", "[", "1.0", "]", "*", "running_seq_len", ",", "device", "=", "dev", ")", "]", "\n", "\n", "# document part -- drop passages with weight of 0, copy the weights for all", "\n", "idx", "=", "0", "\n", "for", "length", ",", "weight", "in", "zip", "(", "lengths", ",", "weights", ")", ":", "\n", "# we should never see padding here as the number of weights is equal to the number of passages", "\n", "            ", "assert", "length", ">", "0", "\n", "\n", "next_idx", "=", "idx", "+", "length", "\n", "if", "weight", "==", "1.0", ":", "\n", "                ", "in_ids", ".", "append", "(", "doc_in", "[", "idx", ":", "next_idx", "]", ")", "\n", "\n", "# token types are 1 up until (including) the 2nd SEP", "\n", "tt_ids", ".", "append", "(", "torch", ".", "as_tensor", "(", "[", "1", "]", "*", "length", ",", "device", "=", "dev", ")", ")", "\n", "\n", "in_weights", ".", "extend", "(", "[", "weight", ".", "unsqueeze", "(", "0", ")", "]", "*", "length", ")", "\n", "running_seq_len", "+=", "length", "\n", "", "idx", "=", "next_idx", "\n", "\n", "# last token should be SEP", "\n", "", "in_ids", ".", "append", "(", "sep_tensor", ")", "\n", "running_seq_len", "+=", "1", "\n", "\n", "# mask is 1 up until the 2nd SEP", "\n", "mask", "=", "[", "torch", ".", "as_tensor", "(", "[", "1.0", "]", "*", "running_seq_len", ",", "device", "=", "dev", ")", "]", "\n", "\n", "# if the sequence is not max length, pad", "\n", "remaining", "=", "self", ".", "max_len", "-", "min", "(", "running_seq_len", ",", "self", ".", "max_len", ")", "\n", "if", "remaining", ">", "0", ":", "\n", "            ", "in_ids", ".", "append", "(", "torch", ".", "as_tensor", "(", "[", "self", ".", "pad_id", "]", "*", "remaining", ",", "device", "=", "dev", ")", ")", "\n", "\n", "# token types and mask are 0 after the 2st SEP", "\n", "mask", ".", "append", "(", "torch", ".", "as_tensor", "(", "[", "0.0", "]", "*", "remaining", ",", "device", "=", "dev", ")", ")", "\n", "\n", "# these need one more for the separator", "\n", "", "tt_ids", ".", "append", "(", "torch", ".", "as_tensor", "(", "[", "0", "]", "*", "(", "remaining", "+", "1", ")", ",", "device", "=", "dev", ")", ")", "\n", "in_weights", ".", "append", "(", "torch", ".", "as_tensor", "(", "[", "1.0", "]", "*", "(", "remaining", "+", "1", ")", ",", "device", "=", "dev", ")", ")", "\n", "\n", "# truncate to maximum length", "\n", "in_ids", "=", "torch", ".", "cat", "(", "in_ids", ")", "[", ":", "self", ".", "max_len", "]", "\n", "mask", "=", "torch", ".", "cat", "(", "mask", ")", "[", ":", "self", ".", "max_len", "]", "\n", "tt_ids", "=", "torch", ".", "cat", "(", "tt_ids", ")", "[", ":", "self", ".", "max_len", "]", "\n", "in_weights", "=", "torch", ".", "cat", "(", "in_weights", ")", "[", ":", "self", ".", "max_len", "]", "\n", "\n", "# make sure lengths match", "\n", "assert", "(", "\n", "in_ids", ".", "shape", "[", "-", "1", "]", "\n", "==", "mask", ".", "shape", "[", "-", "1", "]", "\n", "==", "tt_ids", ".", "shape", "[", "-", "1", "]", "\n", "==", "in_weights", ".", "shape", "[", "-", "1", "]", "\n", "==", "self", ".", "max_len", "\n", ")", "\n", "return", "in_ids", ",", "mask", ",", "tt_ids", ",", "in_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.BERTRanker.forward": [[540, 585], ["zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "select_and_rank.BERTRanker.bert.embeddings", "select_and_rank.BERTRanker.bert", "select_and_rank.BERTRanker.classification", "select_and_rank.BERTRanker._get_single_input", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.unsqueeze().expand_as", "select_and_rank.BERTRanker.dropout", "torch.stack.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.BERTRanker._get_single_input"], ["", "def", "forward", "(", "self", ",", "batch", ":", "SRBatch", ",", "weights", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"Classify a batch of inputs, using the k highest scored passages as BERT input.\n\n        Args:\n            batch (SRBatch): The input batch.\n            weights (torch.Tensor): The weights.\n\n        Returns:\n            torch.FloatTensor: Relevance scores for each input.\n        \"\"\"", "\n", "batch_in_ids", ",", "batch_masks", ",", "batch_tt_ids", ",", "batch_weights", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "query_in", ",", "query_length", ",", "doc_in", ",", "doc_length", ",", "lengths", ",", "weights_", "in", "zip", "(", "\n", "*", "batch", ",", "weights", "\n", ")", ":", "\n", "\n", "# remove padding", "\n", "            ", "query_in", "=", "query_in", "[", ":", "query_length", "]", "\n", "doc_in", "=", "doc_in", "[", ":", "doc_length", "]", "\n", "\n", "# create BERT inputs", "\n", "in_ids", ",", "mask", ",", "tt_ids", ",", "weights_in", "=", "self", ".", "_get_single_input", "(", "\n", "query_in", ",", "doc_in", ",", "lengths", ",", "weights_", "\n", ")", "\n", "batch_in_ids", ".", "append", "(", "in_ids", ")", "\n", "batch_masks", ".", "append", "(", "mask", ")", "\n", "batch_tt_ids", ".", "append", "(", "tt_ids", ")", "\n", "batch_weights", ".", "append", "(", "weights_in", ")", "\n", "\n", "# create a batch of BERT inputs", "\n", "", "batch_in_ids", "=", "torch", ".", "stack", "(", "batch_in_ids", ")", "\n", "batch_masks", "=", "torch", ".", "stack", "(", "batch_masks", ")", "\n", "batch_tt_ids", "=", "torch", ".", "stack", "(", "batch_tt_ids", ")", "\n", "batch_weights", "=", "torch", ".", "stack", "(", "batch_weights", ")", "\n", "\n", "# create actual input by multiplying weights with input embeddings", "\n", "batch_emb", "=", "self", ".", "bert", ".", "embeddings", "(", "input_ids", "=", "batch_in_ids", ")", "\n", "bert_in_batch", "=", "batch_emb", "*", "batch_weights", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand_as", "(", "batch_emb", ")", "\n", "\n", "bert_out", "=", "self", ".", "bert", "(", "\n", "inputs_embeds", "=", "bert_in_batch", ",", "\n", "token_type_ids", "=", "batch_tt_ids", ",", "\n", "attention_mask", "=", "batch_masks", ",", "\n", ")", "\n", "cls_out", "=", "bert_out", "[", "\"last_hidden_state\"", "]", "[", ":", ",", "0", "]", "\n", "return", "self", ".", "classification", "(", "self", ".", "dropout", "(", "cls_out", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase.__init__": [[596, 611], ["super().__init__", "select_and_rank.SRBase.save_hyperparameters", "torch.finfo"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "lr", ":", "int", ",", "warmup_steps", ":", "int", ",", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "\n", "# used for sampling", "\n", "self", ".", "eps", "=", "torch", ".", "finfo", "(", "torch", ".", "float32", ")", ".", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase.get_selector": [[612, 620], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_selector", "(", "self", ")", "->", "Any", ":", "\n", "        ", "\"\"\"Return the selector.\n\n        Returns:\n            Any: The selector.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase.get_ranker": [[621, 629], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_ranker", "(", "self", ")", "->", "Any", ":", "\n", "        ", "\"\"\"Return the ranker.\n\n        Returns:\n            Any: The ranker.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase._sample_subset": [[630, 668], ["torch.nn.functional.softmax", "torch.log", "torch.rand", "min", "range", "torch.stack().sum", "torch.stack().sum.topk", "torch.zeros_like().scatter_", "torch.log", "torch.nn.functional.softmax", "p.append", "torch.log", "torch.stack", "torch.zeros_like", "torch.log"], "methods", ["None"], ["", "def", "_sample_subset", "(", "self", ",", "scores", ":", "torch", ".", "FloatTensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Create a subset as a k-hot vector using Gumbel-softmax sampling.\n        The gradients are preserved by the straight-through trick.\n\n        Args:\n            scores (torch.FloatTensor): Scores output by the selector.\n\n        Returns:\n            torch.Tensor: A k-hot subset sample.\n        \"\"\"", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores", ",", "dim", "=", "0", ")", "\n", "log_probs", "=", "torch", ".", "log", "(", "probs", ")", "\n", "\n", "# gumbel softmax sampling", "\n", "U", "=", "torch", ".", "rand", "(", "log_probs", ".", "shape", ",", "device", "=", "log_probs", ".", "device", ")", "\n", "r_hat", "=", "log_probs", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "self", ".", "eps", ")", "+", "self", ".", "eps", ")", "\n", "\n", "# there might be less than k passages", "\n", "k", "=", "min", "(", "self", ".", "hparams", "[", "\"k\"", "]", ",", "r_hat", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# relaxed top-k procedure", "\n", "t", "=", "self", ".", "hparams", "[", "\"temperature\"", "]", "\n", "p", "=", "[", "]", "\n", "alpha", "=", "r_hat", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "p_j", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "alpha", "/", "t", ",", "dim", "=", "0", ")", "\n", "p", ".", "append", "(", "p_j", ")", "\n", "alpha", "+=", "torch", ".", "log", "(", "1", "-", "p_j", ")", "\n", "\n", "# the approximated k-hot vector", "\n", "", "v", "=", "torch", ".", "stack", "(", "p", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "# exact k-hot vector", "\n", "_", ",", "topk_indices", "=", "v", ".", "topk", "(", "k", ")", "\n", "k_hot", "=", "torch", ".", "zeros_like", "(", "v", ")", ".", "scatter_", "(", "0", ",", "topk_indices", ",", "1", ")", "\n", "\n", "# return the exact k-hot vector with soft gradients (straight-through)", "\n", "return", "(", "k_hot", "-", "v", ")", ".", "detach", "(", ")", "+", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase._get_topk": [[669, 682], ["min", "scores.topk", "torch.zeros_like().scatter_", "torch.zeros_like"], "methods", ["None"], ["", "def", "_get_topk", "(", "self", ",", "scores", ":", "torch", ".", "FloatTensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Return a k-hot vector with the top passages, without sampling or gradients.\n\n        Args:\n            scores (torch.FloatTensor): Scores output by the selector.\n\n        Returns:\n            torch.Tensor: A k-hot vector.\n        \"\"\"", "\n", "# there might be less than k passages", "\n", "k", "=", "min", "(", "self", ".", "hparams", "[", "\"k\"", "]", ",", "scores", ".", "shape", "[", "-", "1", "]", ")", "\n", "_", ",", "topk_indices", "=", "scores", ".", "topk", "(", "k", ")", "\n", "return", "torch", ".", "zeros_like", "(", "scores", ")", ".", "scatter_", "(", "0", ",", "topk_indices", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase.forward": [[683, 699], ["select_and_rank.SRBase.get_selector", "select_and_rank.SRBase.get_ranker", "select_and_rank.SRBase._sample_subset", "select_and_rank.SRBase._get_topk"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankLinear.get_selector", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankLinear.get_ranker", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase._sample_subset", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase._get_topk"], ["", "def", "forward", "(", "self", ",", "batch", ":", "SRBatch", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass. Return scores for a batch of inputs.\n\n        Args:\n            batch (SRBatch): The input batch.\n\n        Returns:\n            torch.Tensor: The scores.\n        \"\"\"", "\n", "scores", "=", "self", ".", "get_selector", "(", ")", "(", "batch", ")", "\n", "# during training we sample, during inference we take the best k", "\n", "weights", "=", "[", "\n", "self", ".", "_sample_subset", "(", "s", ")", "if", "self", ".", "training", "else", "self", ".", "_get_topk", "(", "s", ")", "\n", "for", "s", "in", "scores", "\n", "]", "\n", "return", "self", ".", "get_ranker", "(", ")", "(", "batch", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SRBase.configure_optimizers": [[700, 705], ["filter", "torch.optim.AdamW", "transformers.get_constant_schedule_with_warmup", "select_and_rank.SRBase.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "        ", "params_with_grad", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "\n", "opt", "=", "AdamW", "(", "params_with_grad", ",", "lr", "=", "self", ".", "lr", ")", "\n", "sched", "=", "get_constant_schedule_with_warmup", "(", "opt", ",", "self", ".", "warmup_steps", ")", "\n", "return", "[", "opt", "]", ",", "[", "{", "\"scheduler\"", ":", "sched", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankAttention.__init__": [[710, 730], ["select_and_rank.SRBase.__init__", "select_and_rank.BERTRanker", "select_and_rank.AttentionSelector", "select_and_rank.SelectAndRankAttention.ranker.bert.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "lr", ":", "int", ",", "warmup_steps", ":", "int", ",", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "lr", ",", "warmup_steps", ",", "hparams", ")", "\n", "self", ".", "ranker", "=", "BERTRanker", "(", "\n", "hparams", "[", "\"bert_model\"", "]", ",", "hparams", "[", "\"dropout\"", "]", ",", "hparams", "[", "\"freeze_ranker\"", "]", ",", "\n", ")", "\n", "\n", "# we re-use the embedding of the ranker so the selector has the same vocabulary", "\n", "self", ".", "selector", "=", "AttentionSelector", "(", "\n", "self", ".", "ranker", ".", "bert", ".", "get_input_embeddings", "(", ")", ",", "\n", "self", ".", "ranker", ".", "bert", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "dense", ".", "out_features", ",", "\n", "hparams", "[", "\"lstm_dim\"", "]", ",", "\n", "hparams", "[", "\"attention_dim\"", "]", ",", "\n", "hparams", "[", "\"dropout\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankAttention.get_selector": [[732, 734], ["None"], "methods", ["None"], ["", "def", "get_selector", "(", "self", ")", "->", "AttentionSelector", ":", "\n", "        ", "return", "self", ".", "selector", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankAttention.get_ranker": [[735, 737], ["None"], "methods", ["None"], ["", "def", "get_ranker", "(", "self", ")", "->", "BERTRanker", ":", "\n", "        ", "return", "self", ".", "ranker", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankLinear.__init__": [[742, 761], ["select_and_rank.SRBase.__init__", "select_and_rank.BERTRanker", "select_and_rank.LinearSelector", "select_and_rank.SelectAndRankLinear.ranker.bert.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "lr", ":", "int", ",", "warmup_steps", ":", "int", ",", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "lr", ",", "warmup_steps", ",", "hparams", ")", "\n", "self", ".", "ranker", "=", "BERTRanker", "(", "\n", "hparams", "[", "\"bert_model\"", "]", ",", "hparams", "[", "\"dropout\"", "]", ",", "hparams", "[", "\"freeze_ranker\"", "]", ",", "\n", ")", "\n", "\n", "# we re-use the embedding of the ranker so the selector has the same vocabulary", "\n", "self", ".", "selector", "=", "LinearSelector", "(", "\n", "self", ".", "ranker", ".", "bert", ".", "get_input_embeddings", "(", ")", ",", "\n", "self", ".", "ranker", ".", "bert", ".", "encoder", ".", "layer", "[", "-", "1", "]", ".", "output", ".", "dense", ".", "out_features", ",", "\n", "hparams", "[", "\"hidden_dim\"", "]", ",", "\n", "hparams", "[", "\"dropout\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankLinear.get_selector": [[763, 765], ["None"], "methods", ["None"], ["", "def", "get_selector", "(", "self", ")", "->", "LinearSelector", ":", "\n", "        ", "return", "self", ".", "selector", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.select_and_rank.SelectAndRankLinear.get_ranker": [[766, 768], ["None"], "methods", ["None"], ["", "def", "get_ranker", "(", "self", ")", "->", "BERTRanker", ":", "\n", "        ", "return", "self", ".", "ranker", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMDataProcessor.__init__": [[21, 31], ["ranking_utils.model.data.DataProcessor.__init__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "embeddings", ":", "Vectors", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embeddings (Vectors): Pre-trained embedding vectors (torchtext).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stoi", "=", "embeddings", ".", "stoi", "\n", "self", ".", "unk_id", "=", "len", "(", "self", ".", "stoi", ")", "\n", "self", ".", "pad_id", "=", "len", "(", "self", ".", "stoi", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMDataProcessor.get_model_input": [[32, 45], ["len", "len", "torch.LongTensor", "torch.LongTensor", "query.strip", "doc.strip", "qa_lstm.QALSTMDataProcessor.stoi.get", "qa_lstm.QALSTMDataProcessor.stoi.get", "nltk.word_tokenize", "nltk.word_tokenize"], "methods", ["None"], ["", "def", "get_model_input", "(", "self", ",", "query", ":", "str", ",", "doc", ":", "str", ")", "->", "QALSTMInput", ":", "\n", "# empty queries or documents might cause problems later on", "\n", "        ", "if", "len", "(", "query", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "query", "=", "\"(empty)\"", "\n", "", "if", "len", "(", "doc", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "doc", "=", "\"(empty)\"", "\n", "\n", "", "return", "(", "\n", "torch", ".", "LongTensor", "(", "\n", "[", "self", ".", "stoi", ".", "get", "(", "w", ",", "self", ".", "unk_id", ")", "for", "w", "in", "nltk", ".", "word_tokenize", "(", "query", ")", "]", "\n", ")", ",", "\n", "torch", ".", "LongTensor", "(", "\n", "[", "self", ".", "stoi", ".", "get", "(", "w", ",", "self", ".", "unk_id", ")", "for", "w", "in", "nltk", ".", "word_tokenize", "(", "doc", ")", "]", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMDataProcessor.get_model_batch": [[48, 59], ["zip", "len", "len", "torch.nn.utils.rnn.pad_sequence", "torch.IntTensor", "torch.nn.utils.rnn.pad_sequence", "torch.IntTensor"], "methods", ["None"], ["", "def", "get_model_batch", "(", "self", ",", "inputs", ":", "Iterable", "[", "QALSTMInput", "]", ")", "->", "QALSTMBatch", ":", "\n", "        ", "batch_query_tokens", ",", "batch_doc_tokens", "=", "zip", "(", "*", "inputs", ")", "\n", "query_lengths", "=", "[", "len", "(", "x", ")", "for", "x", "in", "batch_query_tokens", "]", "\n", "doc_lengths", "=", "[", "len", "(", "x", ")", "for", "x", "in", "batch_doc_tokens", "]", "\n", "return", "(", "\n", "pad_sequence", "(", "\n", "batch_query_tokens", ",", "batch_first", "=", "True", ",", "padding_value", "=", "self", ".", "pad_id", "\n", ")", ",", "\n", "torch", ".", "IntTensor", "(", "query_lengths", ")", ",", "\n", "pad_sequence", "(", "batch_doc_tokens", ",", "batch_first", "=", "True", ",", "padding_value", "=", "self", ".", "pad_id", ")", ",", "\n", "torch", ".", "IntTensor", "(", "doc_lengths", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker.__init__": [[63, 111], ["ranking_utils.model.Ranker.__init__", "qa_lstm.QALSTMRanker.save_hyperparameters", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Softmax", "torch.nn.Dropout", "torch.nn.CosineSimilarity", "len", "torch.no_grad", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "embeddings", ":", "Vectors", ",", "\n", "lr", ":", "float", ",", "\n", "warmup_steps", ":", "int", ",", "\n", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embeddings (Vectors): Pre-trained embedding vectors (torchtext).\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "\n", "# add <unk> and <pad>", "\n", "num_embeddings", "=", "len", "(", "embeddings", ".", "vectors", ")", "+", "2", "\n", "emb_dim", "=", "embeddings", ".", "vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "embedding", "=", "torch", ".", "nn", ".", "Embedding", "(", "\n", "num_embeddings", ",", "emb_dim", ",", "padding_idx", "=", "len", "(", "embeddings", ".", "vectors", ")", "+", "1", "\n", ")", "\n", "\n", "# load pre-trained embeddings", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "embedding", ".", "weight", "[", "0", ":", "len", "(", "embeddings", ".", "vectors", ")", "]", "=", "embeddings", ".", "vectors", "\n", "\n", "", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "\n", "emb_dim", ",", "hparams", "[", "\"hidden_dim\"", "]", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", "\n", ")", "\n", "\n", "# attention weights", "\n", "self", ".", "W_am", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "hparams", "[", "\"hidden_dim\"", "]", "*", "2", ",", "hparams", "[", "\"hidden_dim\"", "]", "*", "2", "\n", ")", "\n", "self", ".", "W_qm", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "hparams", "[", "\"hidden_dim\"", "]", "*", "2", ",", "hparams", "[", "\"hidden_dim\"", "]", "*", "2", "\n", ")", "\n", "self", ".", "w_ms", "=", "torch", ".", "nn", ".", "Linear", "(", "hparams", "[", "\"hidden_dim\"", "]", "*", "2", ",", "1", ")", "\n", "self", ".", "tanh", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "hparams", "[", "\"dropout\"", "]", ")", "\n", "self", ".", "cos_sim", "=", "torch", ".", "nn", ".", "CosineSimilarity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._encode": [[112, 129], ["qa_lstm.QALSTMRanker.embedding", "torch.nn.utils.rnn.pack_padded_sequence", "qa_lstm.QALSTMRanker.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.cpu"], "methods", ["None"], ["", "def", "_encode", "(", "self", ",", "inputs", ":", "torch", ".", "Tensor", ",", "lengths", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Embed and encode a batch of padded sequences using the shared LSTM.\n\n        Args:\n            inputs (torch.Tensor): The padded input sequences.\n            lengths (torch.Tensor): The sequence lengths.\n\n        Returns:\n            torch.Tensor: The LSTM outputs.\n        \"\"\"", "\n", "input_embed", "=", "self", ".", "embedding", "(", "inputs", ")", "\n", "input_seqs", "=", "pack_padded_sequence", "(", "\n", "input_embed", ",", "lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", "\n", ")", "\n", "lstm_out", ",", "_", "=", "self", ".", "lstm", "(", "input_seqs", ")", "\n", "out_seqs", ",", "_", "=", "pad_packed_sequence", "(", "lstm_out", ",", "batch_first", "=", "True", ")", "\n", "return", "out_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._max_pool": [[130, 159], ["torch.arange().unsqueeze().expand", "rng.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "lstm_outputs.clone", "float", "torch.max", "torch.arange().unsqueeze", "rng.unsqueeze().expand.unsqueeze().expand.unsqueeze", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze", "lengths.unsqueeze().expand.unsqueeze().expand.unsqueeze", "torch.arange"], "methods", ["None"], ["", "def", "_max_pool", "(", "\n", "self", ",", "lstm_outputs", ":", "torch", ".", "Tensor", ",", "lengths", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Perform max-pooling on the LSTM outputs, masking padding tokens.\n\n        Args:\n            lstm_outputs (torch.Tensor): LSTM output sequences.\n            lengths (torch.Tensor): Sequence lengths.\n\n        Returns:\n            torch.Tensor: Maximum along dimension 1.\n        \"\"\"", "\n", "num_sequences", ",", "max_seq_len", ",", "num_hidden", "=", "lstm_outputs", ".", "shape", "\n", "\n", "# create mask", "\n", "rng", "=", "(", "\n", "torch", ".", "arange", "(", "max_seq_len", ",", "device", "=", "lstm_outputs", ".", "device", ")", "\n", ".", "unsqueeze", "(", "0", ")", "\n", ".", "expand", "(", "num_sequences", ",", "-", "1", ")", "\n", ")", "\n", "rng", "=", "rng", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "num_hidden", ")", "\n", "lengths", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "num_hidden", ")", "\n", "lengths", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "max_seq_len", ",", "-", "1", ")", "\n", "mask", "=", "rng", "<", "lengths", "\n", "\n", "# set padding outputs to -inf so they dont affect max pooling", "\n", "lstm_outputs_clone", "=", "lstm_outputs", ".", "clone", "(", ")", "\n", "lstm_outputs_clone", "[", "~", "mask", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "return", "torch", ".", "max", "(", "lstm_outputs_clone", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._attention": [[160, 194], ["qa_lstm.QALSTMRanker.tanh", "qa_lstm.QALSTMRanker.w_ms", "float", "qa_lstm.QALSTMRanker.softmax", "qa_lstm.QALSTMRanker.W_am", "qa_lstm.QALSTMRanker.W_qm().unsqueeze().expand", "torch.arange", "qa_lstm.QALSTMRanker.W_qm().unsqueeze", "qa_lstm.QALSTMRanker.W_qm"], "methods", ["None"], ["", "def", "_attention", "(", "\n", "self", ",", "\n", "query_outputs_pooled", ":", "torch", ".", "Tensor", ",", "\n", "doc_outputs", ":", "torch", ".", "Tensor", ",", "\n", "doc_lengths", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute attention-weighted outputs for a batch of queries and documents, masking padding tokens.\n\n        Args:\n            query_outputs_pooled (torch.Tensor): Encoded queries after pooling.\n            doc_outputs (torch.Tensor): Encoded documents.\n            doc_lengths (torch.Tensor): Document lengths.\n\n        Returns:\n            torch.Tensor: Attention-weighted outputs.\n        \"\"\"", "\n", "# doc_outputs has shape (num_docs, max_seq_len, 2 * hidden_dim)", "\n", "# query_outputs_pooled has shape (num_docs, 2 * hidden_dim)", "\n", "# expand its shape so they match", "\n", "max_seq_len", "=", "doc_outputs", ".", "shape", "[", "1", "]", "\n", "m", "=", "self", ".", "tanh", "(", "\n", "self", ".", "W_am", "(", "doc_outputs", ")", "\n", "+", "self", ".", "W_qm", "(", "query_outputs_pooled", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "max_seq_len", ",", "-", "1", ")", "\n", ")", "\n", "wm", "=", "self", ".", "w_ms", "(", "m", ")", "\n", "\n", "# mask the padding tokens before computing the softmax by setting the corresponding values to -inf", "\n", "mask", "=", "(", "\n", "torch", ".", "arange", "(", "max_seq_len", ",", "device", "=", "wm", ".", "device", ")", "[", "None", ",", ":", "]", "<", "doc_lengths", "[", ":", ",", "None", "]", "\n", ")", "\n", "wm", "[", "~", "mask", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "\n", "s", "=", "self", ".", "softmax", "(", "wm", ")", "\n", "return", "doc_outputs", "*", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker.forward": [[195, 217], ["qa_lstm.QALSTMRanker.lstm.flatten_parameters", "qa_lstm.QALSTMRanker._encode", "qa_lstm.QALSTMRanker._max_pool", "qa_lstm.QALSTMRanker._encode", "qa_lstm.QALSTMRanker._attention", "qa_lstm.QALSTMRanker._max_pool", "qa_lstm.QALSTMRanker.cos_sim().unsqueeze", "qa_lstm.QALSTMRanker.cos_sim", "qa_lstm.QALSTMRanker.dropout", "qa_lstm.QALSTMRanker.dropout"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._encode", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._max_pool", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._encode", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._attention", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker._max_pool"], ["", "def", "forward", "(", "self", ",", "batch", ":", "QALSTMBatch", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Return the similarities for all query and document pairs.\n\n        Args:\n            batch (QALSTMBatch): The input batch.\n\n        Returns:\n            torch.Tensor: The similarities.\n        \"\"\"", "\n", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "queries", ",", "query_lengths", ",", "docs", ",", "doc_lengths", "=", "batch", "\n", "\n", "query_outputs", "=", "self", ".", "_encode", "(", "queries", ",", "query_lengths", ")", "\n", "query_outputs_pooled", "=", "self", ".", "_max_pool", "(", "query_outputs", ",", "query_lengths", ")", "\n", "\n", "doc_outputs", "=", "self", ".", "_encode", "(", "docs", ",", "doc_lengths", ")", "\n", "attention", "=", "self", ".", "_attention", "(", "query_outputs_pooled", ",", "doc_outputs", ",", "doc_lengths", ")", "\n", "attention_pooled", "=", "self", ".", "_max_pool", "(", "attention", ",", "doc_lengths", ")", "\n", "\n", "return", "self", ".", "cos_sim", "(", "\n", "self", ".", "dropout", "(", "query_outputs_pooled", ")", ",", "self", ".", "dropout", "(", "attention_pooled", ")", "\n", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.qa_lstm.QALSTMRanker.configure_optimizers": [[218, 223], ["filter", "torch.optim.Adam", "transformers.get_constant_schedule_with_warmup", "qa_lstm.QALSTMRanker.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "        ", "params_with_grad", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "\n", "opt", "=", "Adam", "(", "params_with_grad", ",", "lr", "=", "self", ".", "lr", ")", "\n", "sched", "=", "get_constant_schedule_with_warmup", "(", "opt", ",", "self", ".", "warmup_steps", ")", "\n", "return", "[", "opt", "]", ",", "[", "{", "\"scheduler\"", ":", "sched", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNDataProcessor.__init__": [[19, 29], ["ranking_utils.model.data.DataProcessor.__init__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "embeddings", ":", "Vectors", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embeddings (Vectors): Pre-trained embedding vectors (torchtext).\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stoi", "=", "embeddings", ".", "stoi", "\n", "self", ".", "unk_id", "=", "len", "(", "self", ".", "stoi", ")", "\n", "self", ".", "pad_id", "=", "len", "(", "self", ".", "stoi", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNDataProcessor.get_model_input": [[30, 52], ["nltk.sent_tokenize", "len", "len", "dmn.DMNDataProcessor.stoi.get", "doc_tokens.extend", "sentence_lengths.append", "torch.LongTensor", "torch.LongTensor", "torch.IntTensor", "query.strip", "doc.strip", "nltk.word_tokenize", "dmn.DMNDataProcessor.stoi.get", "len", "nltk.word_tokenize"], "methods", ["None"], ["", "def", "get_model_input", "(", "self", ",", "query", ":", "str", ",", "doc", ":", "str", ")", "->", "DMNInput", ":", "\n", "# empty queries or documents might cause problems later on", "\n", "        ", "if", "len", "(", "query", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "query", "=", "\"(empty)\"", "\n", "", "if", "len", "(", "doc", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "doc", "=", "\"(empty)\"", "\n", "\n", "", "query_tokens", "=", "[", "\n", "self", ".", "stoi", ".", "get", "(", "w", ",", "self", ".", "unk_id", ")", "for", "w", "in", "nltk", ".", "word_tokenize", "(", "query", ")", "\n", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "sentence_lengths", "=", "[", "]", "\n", "for", "sentence", "in", "nltk", ".", "sent_tokenize", "(", "doc", ")", ":", "\n", "            ", "sentence_tokens", "=", "[", "\n", "self", ".", "stoi", ".", "get", "(", "w", ",", "self", ".", "unk_id", ")", "for", "w", "in", "nltk", ".", "word_tokenize", "(", "sentence", ")", "\n", "]", "\n", "doc_tokens", ".", "extend", "(", "sentence_tokens", ")", "\n", "sentence_lengths", ".", "append", "(", "len", "(", "sentence_tokens", ")", ")", "\n", "", "return", "(", "\n", "torch", ".", "LongTensor", "(", "query_tokens", ")", ",", "\n", "torch", ".", "LongTensor", "(", "doc_tokens", ")", ",", "\n", "torch", ".", "IntTensor", "(", "sentence_lengths", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNDataProcessor.get_model_batch": [[54, 64], ["zip", "len", "torch.nn.utils.rnn.pad_sequence", "torch.IntTensor", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence"], "methods", ["None"], ["", "def", "get_model_batch", "(", "self", ",", "inputs", ":", "Iterable", "[", "DMNInput", "]", ")", "->", "DMNBatch", ":", "\n", "        ", "batch_query_tokens", ",", "batch_doc_tokens", ",", "batch_sentence_lengths", "=", "zip", "(", "*", "inputs", ")", "\n", "query_lengths", "=", "[", "len", "(", "x", ")", "for", "x", "in", "batch_query_tokens", "]", "\n", "return", "(", "\n", "pad_sequence", "(", "\n", "batch_query_tokens", ",", "batch_first", "=", "True", ",", "padding_value", "=", "self", ".", "pad_id", "\n", ")", ",", "\n", "torch", ".", "IntTensor", "(", "query_lengths", ")", ",", "\n", "pad_sequence", "(", "batch_doc_tokens", ",", "batch_first", "=", "True", ",", "padding_value", "=", "self", ".", "pad_id", ")", ",", "\n", "pad_sequence", "(", "batch_sentence_lengths", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule.__init__": [[70, 97], ["super().__init__", "torch.nn.Embedding", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.Dropout", "len", "torch.no_grad", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "embeddings", ":", "Vectors", ",", "rep_dim", ":", "int", ",", "dropout", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embeddings (Vectors): Pre-trained embedding vectors (torchtext).\n            rep_dim (int): The dimension of the fact representations.\n            dropout (float): Dropout value.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rep_dim", "=", "rep_dim", "\n", "\n", "# add <unk> and <pad>", "\n", "num_embeddings", "=", "len", "(", "embeddings", ".", "vectors", ")", "+", "2", "\n", "emb_dim", "=", "embeddings", ".", "vectors", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "embedding", "=", "torch", ".", "nn", ".", "Embedding", "(", "\n", "num_embeddings", ",", "emb_dim", ",", "padding_idx", "=", "len", "(", "embeddings", ".", "vectors", ")", "+", "1", "\n", ")", "\n", "\n", "# load pre-trained embeddings", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "embedding", ".", "weight", "[", "0", ":", "len", "(", "embeddings", ".", "vectors", ")", "]", "=", "embeddings", ".", "vectors", "\n", "\n", "", "self", ".", "input_gru", "=", "torch", ".", "nn", ".", "GRU", "(", "\n", "emb_dim", ",", "rep_dim", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", "\n", ")", "\n", "self", ".", "question_gru", "=", "torch", ".", "nn", ".", "GRU", "(", "emb_dim", ",", "rep_dim", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._get_facts": [[98, 119], ["torch.stack", "len", "facts.append", "torch.mean"], "methods", ["None"], ["", "def", "_get_facts", "(", "\n", "self", ",", "embedded_doc", ":", "torch", ".", "Tensor", ",", "item_sentence_lengths", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Return all facts from a document.\n\n        Args:\n            embedded_doc (torch.Tensor): The embedded document, shape (doc_len, emb_dim).\n            item_sentence_lengths (torch.Tensor): Sentence lengths, shape (max_num_sent,).\n\n        Returns:\n            torch.Tensor: The facts, shape (num_facts, emb_dim).\n        \"\"\"", "\n", "facts", "=", "[", "]", "\n", "idx", "=", "0", "\n", "# we will get all sentences this way, even if the last one was truncated", "\n", "for", "length", "in", "item_sentence_lengths", ":", "\n", "            ", "s", "=", "embedded_doc", "[", "idx", ":", "idx", "+", "length", "]", "\n", "idx", "+=", "length", "\n", "if", "len", "(", "s", ")", ">", "0", ":", "\n", "                ", "facts", ".", "append", "(", "torch", ".", "mean", "(", "s", ",", "dim", "=", "0", ")", ")", "\n", "", "", "return", "torch", ".", "stack", "(", "facts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._forward_queries": [[120, 138], ["torch.nn.utils.rnn.pack_padded_sequence", "dmn.InputModule.question_gru", "torch.transpose", "query_lengths.cpu"], "methods", ["None"], ["", "def", "_forward_queries", "(", "\n", "self", ",", "queries", ":", "torch", ".", "Tensor", ",", "query_lengths", ":", "List", "[", "int", "]", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Apply a GRU to a batch of queries.\n\n        Args:\n            queries (torch.Tensor): The query representations, shape (batch_size, max_query_len, glove_dim).\n            query_lengths (List[int]): The query lengths, shape (batch_size,).\n\n        Returns:\n            torch.Tensor: The last GRU outputs, shape (batch_size, 1, rep_dim).\n        \"\"\"", "\n", "queries_packed", "=", "pack_padded_sequence", "(", "\n", "queries", ",", "query_lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", "\n", ")", "\n", "_", ",", "h", "=", "self", ".", "question_gru", "(", "queries_packed", ")", "\n", "# transpose back to batch-first", "\n", "return", "torch", ".", "transpose", "(", "h", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._forward_facts": [[139, 160], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "dmn.InputModule.input_gru", "torch.nn.utils.rnn.pad_packed_sequence", "dmn.InputModule.dropout"], "methods", ["None"], ["", "def", "_forward_facts", "(", "self", ",", "facts", ":", "torch", ".", "Tensor", ",", "num_facts", ":", "List", "[", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Apply dropout and a GRU to a batch of facts (input fusion).\n\n        Args:\n            facts (torch.Tensor): The fact representations, shape (batch_size, max_facts_len, glove_dim).\n            num_facts (List[int]): The facts lengths, shape (batch_size,).\n\n        Returns:\n            torch.Tensor: The GRU output, shape (batch_size, max_facts_len, rep_dim).\n        \"\"\"", "\n", "facts_padded", "=", "pad_sequence", "(", "facts", ",", "batch_first", "=", "True", ")", "\n", "facts_packed", "=", "pack_padded_sequence", "(", "\n", "self", ".", "dropout", "(", "facts_padded", ")", ",", "\n", "num_facts", ",", "\n", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ",", "\n", ")", "\n", "gru_output", ",", "_", "=", "self", ".", "input_gru", "(", "facts_packed", ")", "\n", "padded_output", ",", "_", "=", "pad_packed_sequence", "(", "gru_output", ",", "batch_first", "=", "True", ")", "\n", "# sum outputs of both directions", "\n", "return", "padded_output", "[", ":", ",", ":", ",", ":", "self", ".", "rep_dim", "]", "+", "padded_output", "[", ":", ",", ":", ",", "self", ".", "rep_dim", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule.forward": [[161, 197], ["dmn.InputModule.input_gru.flatten_parameters", "dmn.InputModule.question_gru.flatten_parameters", "zip", "dmn.InputModule.embedding", "dmn.InputModule._get_facts", "facts.append", "num_facts.append", "dmn.InputModule._forward_queries", "dmn.InputModule._forward_facts", "dmn.InputModule.embedding"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._get_facts", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._forward_queries", "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.InputModule._forward_facts"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "queries", ":", "torch", ".", "Tensor", ",", "\n", "query_lengths", ":", "torch", ".", "Tensor", ",", "\n", "docs", ":", "torch", ".", "Tensor", ",", "\n", "sentence_lengths", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "\"\"\"Extract the query and fact representations and apply input fusion.\n\n        Args:\n            queries (torch.Tensor): Padded queries, shape (batch_size, max_query_len).\n            query_lengths (torch.Tensor): Query lenghts, shape (batch_size,).\n            docs (torch.Tensor): Padded documents, shape (batch_size, max_doc_len).\n            sentence_lengths (torch.Tensor): Document lenghts, shape (batch_size, max_num_sent).\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor, List[int]]: A tuple containing\n                * the query representations, shape (batch_size, 1, rep_dim),\n                * the fact representations, shape (batch_size, max_facts_len, rep_dim),\n                * the number of facts, shape (batch_size,).\n        \"\"\"", "\n", "self", ".", "input_gru", ".", "flatten_parameters", "(", ")", "\n", "self", ".", "question_gru", ".", "flatten_parameters", "(", ")", "\n", "\n", "facts", ",", "num_facts", "=", "[", "]", ",", "[", "]", "\n", "for", "embedded_doc", ",", "item_sentence_lengths", "in", "zip", "(", "\n", "self", ".", "embedding", "(", "docs", ")", ",", "sentence_lengths", "\n", ")", ":", "\n", "            ", "fact_outputs", "=", "self", ".", "_get_facts", "(", "embedded_doc", ",", "item_sentence_lengths", ")", "\n", "facts", ".", "append", "(", "fact_outputs", ")", "\n", "num_facts", ".", "append", "(", "fact_outputs", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "return", "(", "\n", "self", ".", "_forward_queries", "(", "self", ".", "embedding", "(", "queries", ")", ",", "query_lengths", ")", ",", "\n", "self", ".", "_forward_facts", "(", "facts", ",", "num_facts", ")", ",", "\n", "num_facts", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.AttentionGRUCell.__init__": [[203, 215], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "rep_dim", ":", "int", ",", "agru_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            rep_dim (int): Input (fact) dimension.\n            agru_dim (int): Hidden dimension.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "Wr", "=", "torch", ".", "nn", ".", "Linear", "(", "rep_dim", ",", "agru_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Ur", "=", "torch", ".", "nn", ".", "Linear", "(", "agru_dim", ",", "agru_dim", ")", "\n", "self", ".", "W", "=", "torch", ".", "nn", ".", "Linear", "(", "rep_dim", ",", "agru_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "U", "=", "torch", ".", "nn", ".", "Linear", "(", "agru_dim", ",", "agru_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.AttentionGRUCell.forward": [[216, 234], ["torch.sigmoid", "torch.tanh", "g_fact.expand_as.expand_as.expand_as", "dmn.AttentionGRUCell.Wr", "dmn.AttentionGRUCell.Ur", "dmn.AttentionGRUCell.W", "dmn.AttentionGRUCell.U"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "fact", ":", "torch", ".", "Tensor", ",", "h_old", ":", "torch", ".", "Tensor", ",", "g_fact", ":", "torch", ".", "Tensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"A single GRU step.\n\n        Args:\n            fact (torch.Tensor): Input fact, shape (batch_size, rep_dim).\n            h_old (torch.Tensor): Previous hidden states, shape (batch_size, agru_dim).\n            g_fact (torch.Tensor): Attention scores for the fact, shape (batch_size, 1).\n\n        Returns:\n            torch.Tensor: The new hidden states, shape (batch_size, agru_dim).\n        \"\"\"", "\n", "r", "=", "torch", ".", "sigmoid", "(", "self", ".", "Wr", "(", "fact", ")", "+", "self", ".", "Ur", "(", "h_old", ")", ")", "\n", "h_t", "=", "torch", ".", "tanh", "(", "self", ".", "W", "(", "fact", ")", "+", "r", "*", "self", ".", "U", "(", "h_old", ")", ")", "\n", "\n", "g_fact", "=", "g_fact", ".", "expand_as", "(", "h_t", ")", "\n", "return", "g_fact", "*", "h_t", "+", "(", "1", "-", "g_fact", ")", "*", "h_old", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.AttentionGRU.__init__": [[239, 249], ["super().__init__", "dmn.AttentionGRUCell"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "rep_dim", ":", "int", ",", "agru_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            rep_dim (int): Input (fact) dimension.\n            agru_dim (int): GRU hidden dimension.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agru_dim", "=", "agru_dim", "\n", "self", ".", "cell", "=", "AttentionGRUCell", "(", "rep_dim", ",", "agru_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.AttentionGRU.forward": [[250, 281], ["mem_old.squeeze", "range", "torch.transpose", "torch.stack", "dmn.AttentionGRU.cell", "torch.transpose.append", "torch.stack", "zip"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "facts", ":", "torch", ".", "Tensor", ",", "\n", "num_facts", ":", "List", "[", "int", "]", ",", "\n", "g", ":", "torch", ".", "Tensor", ",", "\n", "mem_old", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Apply the attention GRU to a batch.\n\n        Args:\n            facts (torch.Tensor): Input facts, shape (batch_size, max_facts_len, rep_dim).\n            num_facts (List[int]): The number of facts, shape (batch_size,).\n            g (torch.Tensor): Attention scores, shape (batch_size, max_facts_len, 1).\n            mem_old (torch.Tensor): The previous memory, shape (batch_size, 1, rep_dim).\n\n        Returns:\n            torch.Tensor: The last hidden states, shape (batch_size, agru_dim).\n        \"\"\"", "\n", "_", ",", "max_num_facts", ",", "_", "=", "facts", ".", "shape", "\n", "states", "=", "[", "]", "\n", "\n", "# initial hidden state from previous memory", "\n", "h", "=", "mem_old", ".", "squeeze", "(", "1", ")", "\n", "for", "i", "in", "range", "(", "max_num_facts", ")", ":", "\n", "            ", "fact", "=", "facts", "[", ":", ",", "i", "]", "\n", "h", "=", "self", ".", "cell", "(", "fact", ",", "h", ",", "g", "[", ":", ",", "i", "]", ")", "\n", "states", ".", "append", "(", "h", ")", "\n", "", "states", "=", "torch", ".", "transpose", "(", "torch", ".", "stack", "(", "states", ")", ",", "0", ",", "1", ")", "\n", "\n", "# select the correct hidden state for each example depending on the length", "\n", "return", "torch", ".", "stack", "(", "[", "state", "[", "i", "-", "1", "]", "for", "state", ",", "i", "in", "zip", "(", "states", ",", "num_facts", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.MemoryModule.__init__": [[288, 303], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softmax", "dmn.AttentionGRU", "torch.nn.Linear", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "rep_dim", ":", "int", ",", "attention_dim", ":", "int", ",", "agru_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            rep_dim (int): The dimension of the query and fact representations and the memory.\n            attention_dim (int): The dimension of the linear layer applied to the interactions.\n            agru_dim (int): The hidden dimension of the attention GRU.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W1", "=", "torch", ".", "nn", ".", "Linear", "(", "4", "*", "rep_dim", ",", "attention_dim", ")", "\n", "self", ".", "W2", "=", "torch", ".", "nn", ".", "Linear", "(", "attention_dim", ",", "1", ")", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "agru", "=", "AttentionGRU", "(", "rep_dim", ",", "agru_dim", ")", "\n", "self", ".", "Wt", "=", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "rep_dim", "+", "agru_dim", ",", "rep_dim", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.MemoryModule._get_attention": [[304, 349], ["queries.expand_as", "m_old.expand_as", "torch.cat", "dmn.MemoryModule.W2", "torch.arange().unsqueeze().expand", "torch.LongTensor().to", "lengths.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "float", "dmn.MemoryModule.softmax", "torch.abs", "torch.abs", "torch.tanh", "dmn.MemoryModule.W1", "torch.arange().unsqueeze", "torch.LongTensor", "lengths.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.arange"], "methods", ["None"], ["", "def", "_get_attention", "(", "\n", "self", ",", "\n", "facts", ":", "torch", ".", "Tensor", ",", "\n", "num_facts", ":", "List", "[", "int", "]", ",", "\n", "queries", ":", "torch", ".", "Tensor", ",", "\n", "m_old", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute the interactions between queries and facts and apply a linear layer.\n\n        Args:\n            facts (torch.Tensor): Input facts, shape (batch_size, max_facts_len, rep_dim).\n            num_facts (List[int]): The number of facts, shape (batch_size,).\n            queries (torch.Tensor): The query representations, shape (batch_size, 1, rep_dim).\n            m_old (torch.Tensor): The previous memory, shape (batch_size, 1, rep_dim).\n\n        Returns:\n            torch.Tensor: Attention scores, shape (batch_size, max_facts_len, 1).\n        \"\"\"", "\n", "# we need to expand queries and memories to use element wise operations", "\n", "queries_expanded", "=", "queries", ".", "expand_as", "(", "facts", ")", "\n", "m_expanded", "=", "m_old", ".", "expand_as", "(", "facts", ")", "\n", "\n", "interactions", "=", "[", "\n", "facts", "*", "queries_expanded", ",", "\n", "facts", "*", "m_expanded", ",", "\n", "torch", ".", "abs", "(", "facts", "-", "queries_expanded", ")", ",", "\n", "torch", ".", "abs", "(", "facts", "-", "m_expanded", ")", ",", "\n", "]", "\n", "z", "=", "torch", ".", "cat", "(", "interactions", ",", "dim", "=", "2", ")", "\n", "Z", "=", "self", ".", "W2", "(", "torch", ".", "tanh", "(", "self", ".", "W1", "(", "z", ")", ")", ")", "\n", "\n", "# create mask", "\n", "batch_size", ",", "max_len", ",", "_", "=", "facts", ".", "shape", "\n", "rng", "=", "(", "\n", "torch", ".", "arange", "(", "max_len", ",", "device", "=", "m_old", ".", "device", ")", "\n", ".", "unsqueeze", "(", "0", ")", "\n", ".", "expand", "(", "batch_size", ",", "-", "1", ")", "\n", ")", "\n", "lengths", "=", "torch", ".", "LongTensor", "(", "num_facts", ")", ".", "to", "(", "m_old", ".", "device", ")", "\n", "lengths", "=", "lengths", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "rng", ")", "\n", "mask", "=", "(", "rng", "<", "lengths", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# set the values that correspond to padded tokens to -inf so they don't affect the softmax", "\n", "Z", "[", "~", "mask", "]", "=", "float", "(", "\"-inf\"", ")", "\n", "return", "self", ".", "softmax", "(", "Z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.MemoryModule.forward": [[350, 374], ["dmn.MemoryModule._get_attention", "dmn.MemoryModule.agru", "dmn.MemoryModule.relu", "dmn.MemoryModule.unsqueeze", "dmn.MemoryModule.Wt", "torch.cat", "m_old.squeeze", "queries.squeeze"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.MemoryModule._get_attention"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "queries", ":", "torch", ".", "Tensor", ",", "\n", "facts", ":", "torch", ".", "Tensor", ",", "\n", "num_facts", ":", "List", "[", "int", "]", ",", "\n", "m_old", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute the next memory.\n\n        Args:\n            queries (torch.Tensor): Input queries, shape (batch_size, 1, rep_dim).\n            facts (torch.Tensor): Input facts, shape (batch_size, max_facts_len, rep_dim).\n            num_facts (List[int]): The number of facts, shape (batch_size,).\n            m_old (torch.Tensor): The previous memory, shape (batch_size, 1, rep_dim).\n\n        Returns:\n            torch.Tensor: The next memory, shape (batch_size, 1, rep_dim).\n        \"\"\"", "\n", "g", "=", "self", ".", "_get_attention", "(", "facts", ",", "num_facts", ",", "queries", ",", "m_old", ")", "\n", "c", "=", "self", ".", "agru", "(", "facts", ",", "num_facts", ",", "g", ",", "m_old", ")", "\n", "m", "=", "self", ".", "relu", "(", "\n", "self", ".", "Wt", "(", "torch", ".", "cat", "(", "[", "m_old", ".", "squeeze", "(", "1", ")", ",", "c", ",", "queries", ".", "squeeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", ")", "\n", ")", "\n", "return", "m", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.AnswerModule.__init__": [[379, 389], ["super().__init__", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "self", ",", "dropout", ":", "float", ",", "rep_dim", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            dropout (float): Dropout value.\n            rep_dim (int): The dimension of the memory.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "rep_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.AnswerModule.forward": [[390, 401], ["dmn.AnswerModule.linear", "dmn.AnswerModule.dropout", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "queries", ":", "torch", ".", "Tensor", ",", "memories", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Return a batch of scores.\n\n        Args:\n            queries (torch.Tensor): The query representations, shape (batch_size, rep_dim).\n            memories (torch.Tensor): The final memories, shape (batch_size, rep_dim).\n\n        Returns:\n            torch.Tensor: The scores, shape (batch_size, 1).\n        \"\"\"", "\n", "return", "self", ".", "linear", "(", "self", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "queries", ",", "memories", "]", ",", "dim", "=", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__": [[406, 433], ["ranking_utils.model.Ranker.__init__", "dmn.DMNRanker.save_hyperparameters", "dmn.InputModule", "dmn.MemoryModule", "dmn.AnswerModule"], "methods", ["home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embeddings", ":", "Vectors", ",", "\n", "lr", ":", "float", ",", "\n", "warmup_steps", ":", "int", ",", "\n", "hparams", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            embeddings (Vectors): Pre-trained embedding vectors (torchtext).\n            lr (float): Learning rate.\n            warmup_steps (int): Number of warmup steps.\n            hparams (Dict[str, Any]): Hyperparameters.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "\n", "self", ".", "input_module", "=", "InputModule", "(", "\n", "embeddings", ",", "hparams", "[", "\"rep_dim\"", "]", ",", "hparams", "[", "\"dropout\"", "]", "\n", ")", "\n", "self", ".", "memory_module", "=", "MemoryModule", "(", "\n", "hparams", "[", "\"rep_dim\"", "]", ",", "hparams", "[", "\"attention_dim\"", "]", ",", "hparams", "[", "\"agru_dim\"", "]", "\n", ")", "\n", "self", ".", "answer_module", "=", "AnswerModule", "(", "hparams", "[", "\"dropout\"", "]", ",", "hparams", "[", "\"rep_dim\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.forward": [[434, 448], ["dmn.DMNRanker.input_module", "range", "dmn.DMNRanker.answer_module", "dmn.DMNRanker.memory_module", "queries.squeeze", "dmn.DMNRanker.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ":", "DMNBatch", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Compute the relevance scores for a batch.\n\n        Args:\n            batch (DMNBatch): The queries, query lengths, docs and doc lengths.\n\n        Returns:\n            torch.Tensor: The scores, shape (batch_size, 1).\n        \"\"\"", "\n", "queries", ",", "facts", ",", "num_facts", "=", "self", ".", "input_module", "(", "*", "batch", ")", "\n", "m", "=", "queries", "\n", "for", "_", "in", "range", "(", "self", ".", "hparams", "[", "\"num_episodes\"", "]", ")", ":", "\n", "            ", "m", "=", "self", ".", "memory_module", "(", "queries", ",", "facts", ",", "num_facts", ",", "m", ")", "\n", "", "return", "self", ".", "answer_module", "(", "queries", ".", "squeeze", "(", "1", ")", ",", "m", ".", "squeeze", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mrjleo_ranking-models.models.dmn.DMNRanker.configure_optimizers": [[449, 454], ["filter", "torch.optim.Adam", "transformers.get_constant_schedule_with_warmup", "dmn.DMNRanker.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", "->", "Tuple", "[", "List", "[", "Any", "]", ",", "List", "[", "Any", "]", "]", ":", "\n", "        ", "params_with_grad", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "\n", "opt", "=", "Adam", "(", "params_with_grad", ",", "lr", "=", "self", ".", "lr", ")", "\n", "sched", "=", "get_constant_schedule_with_warmup", "(", "opt", ",", "self", ".", "warmup_steps", ")", "\n", "return", "[", "opt", "]", ",", "[", "{", "\"scheduler\"", ":", "sched", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "", "", ""]]}