{"home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager.__init__": [[12, 26], ["collections.OrderedDict", "collections.OrderedDict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n", "# equipped item (1-hot encoded in get_img_vec):", "\n", "self", ".", "item_list", "=", "[", "'none'", ",", "'wooden_pickaxe'", ",", "'stone_pickaxe'", ",", "'iron_pickaxe'", "]", "\n", "\n", "# dict of avg values in the human data: (converted to normalized float values in get_img_vec)", "\n", "self", ".", "float_inventory_list", "=", "OrderedDict", "(", "[", "(", "'dirt'", ",", "5.", ")", ",", "(", "'cobblestone'", ",", "100.", ")", ",", "(", "'stone'", ",", "15.", ")", "]", ")", "\n", "\n", "# dict of maximal values in most of the human data: (converted to multi-hot vectors in get_img_vec)", "\n", "self", ".", "inventory_list", "=", "OrderedDict", "(", "[", "(", "'coal'", ",", "16", ")", ",", "(", "'crafting_table'", ",", "3", ")", ",", "(", "'furnace'", ",", "3", ")", ",", "(", "'cobblestone'", ",", "16", ")", ",", "\n", "(", "'iron_ingot'", ",", "8", ")", ",", "(", "'iron_ore'", ",", "8", ")", ",", "(", "'iron_pickaxe'", ",", "3", ")", ",", "(", "'log'", ",", "32", ")", ",", "\n", "(", "'planks'", ",", "64", ")", ",", "(", "'stick'", ",", "32", ")", ",", "\n", "(", "'stone_pickaxe'", ",", "4", ")", ",", "(", "'torch'", ",", "16", ")", ",", "(", "'wooden_pickaxe'", ",", "4", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager.get_img_vec": [[27, 44], ["state[].items", "data_manager.StateManager.item_list.index", "len", "data_manager.StateManager._item_vector", "numpy.clip", "float"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager._item_vector"], ["", "def", "get_img_vec", "(", "self", ",", "state", ")", ":", "\n", "        ", "img", "=", "state", "[", "'pov'", "]", "\n", "item_type", "=", "state", "[", "'equipped_items'", "]", "[", "'mainhand'", "]", "[", "'type'", "]", "\n", "if", "item_type", "in", "self", ".", "item_list", ":", "\n", "            ", "item_id", "=", "self", ".", "item_list", ".", "index", "(", "item_type", ")", "\n", "", "else", ":", "\n", "            ", "item_id", "=", "0", "\n", "", "vec", "=", "[", "0.", "]", "*", "len", "(", "self", ".", "item_list", ")", "\n", "vec", "[", "item_id", "]", "=", "1.", "\n", "for", "k", ",", "v", "in", "state", "[", "'inventory'", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "float_inventory_list", ":", "\n", "                ", "avg", "=", "self", ".", "float_inventory_list", "[", "k", "]", "\n", "vec", "+=", "[", "np", ".", "clip", "(", "float", "(", "v", ")", "/", "avg", ",", "0.", ",", "5.", "*", "avg", ")", "]", "# norm by avg amount in human data, max: 5 x avg value", "\n", "", "if", "k", "in", "self", ".", "inventory_list", ":", "\n", "                ", "vec", "+=", "self", ".", "_item_vector", "(", "v", ",", "self", ".", "inventory_list", "[", "k", "]", ")", "\n", "\n", "", "", "return", "img", ",", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager._item_vector": [[45, 47], ["range"], "methods", ["None"], ["", "def", "_item_vector", "(", "self", ",", "amount", ",", "total_amount", ")", ":", "\n", "        ", "return", "[", "1.", "if", "i", "<", "amount", "else", "0.", "for", "i", "in", "range", "(", "total_amount", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager.get_torch_img_vec": [[48, 52], ["torch.tensor().div_().permute", "torch.tensor", "torch.tensor().div_", "torch.tensor"], "methods", ["None"], ["", "def", "get_torch_img_vec", "(", "self", ",", "img_list", ",", "vec_list", ")", ":", "\n", "        ", "img_torch", "=", "torch", ".", "tensor", "(", "img_list", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", ".", "div_", "(", "255", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "vec_torch", "=", "torch", ".", "tensor", "(", "vec_list", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "img_torch", ",", "vec_torch", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.__init__": [[57, 167], ["collections.OrderedDict", "collections.OrderedDict", "list", "list", "collections.OrderedDict", "collections.OrderedDict", "list", "collections.OrderedDict", "enumerate", "data_manager.ActionManager.separate_dict.keys", "data_manager.ActionManager.separate_dict.values", "itertools.product", "data_manager.ActionManager.fully_connected_list.remove", "copy.deepcopy", "zip", "data_manager.ActionManager.action_list.append", "collections.OrderedDict", "len", "range", "sum", "copy.deepcopy", "len", "data_manager.ActionManager.action_list.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "sum", "remove.append", "remove.append", "remove.append", "data_manager.ActionManager.fully_connected.index", "data_manager.ActionManager.fully_connected.index", "data_manager.ActionManager.fully_connected.index"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append"], ["def", "__init__", "(", "self", ",", "device", ",", "c_action_magnitude", "=", "22.5", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "c_action_magnitude", "=", "c_action_magnitude", "\n", "\n", "self", ".", "zero_action", "=", "OrderedDict", "(", "[", "(", "'attack'", ",", "0", ")", ",", "\n", "(", "'back'", ",", "0", ")", ",", "\n", "(", "'camera'", ",", "np", ".", "array", "(", "[", "0.", ",", "0.", "]", ")", ")", ",", "\n", "(", "'craft'", ",", "0", ")", ",", "\n", "(", "'equip'", ",", "0", ")", ",", "\n", "(", "'forward'", ",", "0", ")", ",", "\n", "(", "'jump'", ",", "0", ")", ",", "\n", "(", "'left'", ",", "0", ")", ",", "\n", "(", "'nearbyCraft'", ",", "0", ")", ",", "\n", "(", "'nearbySmelt'", ",", "0", ")", ",", "\n", "(", "'place'", ",", "0", ")", ",", "\n", "(", "'right'", ",", "0", ")", ",", "\n", "(", "'sneak'", ",", "0", ")", ",", "\n", "(", "'sprint'", ",", "0", ")", "]", ")", "\n", "\n", "# ['sneak'] is ignored", "\n", "\n", "# Simplified crafting options:", "\n", "\n", "self", ".", "separate_dict", "=", "OrderedDict", "(", "[", "\n", "(", "'craft'", ",", "[", "1", ",", "2", ",", "3", ",", "4", "]", ")", ",", "\n", "(", "'equip'", ",", "[", "1", ",", "3", ",", "5", ",", "7", "]", ")", ",", "\n", "(", "'nearbyCraft'", ",", "[", "2", ",", "4", ",", "6", ",", "7", "]", ")", ",", "\n", "(", "'nearbySmelt'", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "(", "'place'", ",", "[", "1", ",", "4", ",", "5", ",", "6", "]", ")", "\n", "]", ")", "\n", "\n", "self", ".", "separate", "=", "list", "(", "self", ".", "separate_dict", ".", "keys", "(", ")", ")", "\n", "self", ".", "separate_values", "=", "list", "(", "self", ".", "separate_dict", ".", "values", "(", ")", ")", "\n", "\n", "self", ".", "separate_str_lists", "=", "OrderedDict", "(", "[", "\n", "(", "'craft'", ",", "[", "\"none\"", ",", "\"torch\"", ",", "\"stick\"", ",", "\"planks\"", ",", "\"crafting_table\"", "]", ")", ",", "\n", "(", "'equip'", ",", "[", "\"none\"", ",", "\"air\"", ",", "\"wooden_axe\"", ",", "\"wooden_pickaxe\"", ",", "\"stone_axe\"", ",", "\"stone_pickaxe\"", ",", "\"iron_axe\"", ",", "\"iron_pickaxe\"", "]", ")", ",", "\n", "(", "'nearbyCraft'", ",", "[", "\"none\"", ",", "\"wooden_axe\"", ",", "\"wooden_pickaxe\"", ",", "\"stone_axe\"", ",", "\"stone_pickaxe\"", ",", "\"iron_axe\"", ",", "\"iron_pickaxe\"", ",", "\"furnace\"", "]", ")", ",", "\n", "(", "'nearbySmelt'", ",", "[", "\"none\"", ",", "\"iron_ingot\"", ",", "\"coal\"", "]", ")", ",", "\n", "(", "'place'", ",", "[", "\"none\"", ",", "\"dirt\"", ",", "\"stone\"", ",", "\"cobblestone\"", ",", "\"crafting_table\"", ",", "\"furnace\"", ",", "\"torch\"", "]", ")", "\n", "]", ")", "\n", "\n", "# camera discretization:", "\n", "self", ".", "camera_dict", "=", "OrderedDict", "(", "[", "\n", "(", "'turn_up'", ",", "np", ".", "array", "(", "[", "-", "c_action_magnitude", ",", "0.", "]", ")", ")", ",", "\n", "(", "'turn_down'", ",", "np", ".", "array", "(", "[", "c_action_magnitude", ",", "0.", "]", ")", ")", ",", "\n", "(", "'turn_left'", ",", "np", ".", "array", "(", "[", "0.", ",", "-", "c_action_magnitude", "]", ")", ")", ",", "\n", "(", "'turn_right'", ",", "np", ".", "array", "(", "[", "0.", ",", "c_action_magnitude", "]", ")", ")", "\n", "]", ")", "\n", "\n", "self", ".", "fully_connected_no_camera", "=", "[", "'attack'", ",", "'back'", ",", "'forward'", ",", "'jump'", ",", "'left'", ",", "'right'", ",", "'sprint'", "]", "\n", "self", ".", "camera_actions", "=", "[", "'turn_up'", ",", "'turn_down'", ",", "'turn_left'", ",", "'turn_right'", "]", "\n", "self", ".", "fully_connected", "=", "self", ".", "fully_connected_no_camera", "+", "self", ".", "camera_actions", "\n", "\n", "# following action combinations are excluded:", "\n", "self", ".", "exclude", "=", "[", "(", "'forward'", ",", "'back'", ")", ",", "(", "'left'", ",", "'right'", ")", ",", "(", "'attack'", ",", "'jump'", ")", ",", "\n", "(", "'turn_up'", ",", "'turn_down'", ",", "'turn_left'", ",", "'turn_right'", ")", "]", "\n", "\n", "# sprint only allowed when forward is used:", "\n", "self", ".", "only_if", "=", "[", "(", "'sprint'", ",", "'forward'", ")", "]", "\n", "\n", "# Maximal allowed mount of actions within one action:", "\n", "self", ".", "remove_size", "=", "3", "\n", "\n", "# if more than 3 actions are present, actions are removed using this list until only 3 actions remain:", "\n", "self", ".", "remove_first_list", "=", "[", "'sprint'", ",", "'left'", ",", "'right'", ",", "'back'", ",", "\n", "'turn_up'", ",", "'turn_down'", ",", "'turn_left'", ",", "'turn_right'", ",", "\n", "'attack'", ",", "'jump'", ",", "'forward'", "]", "\n", "\n", "self", ".", "fully_connected_list", "=", "list", "(", "product", "(", "range", "(", "2", ")", ",", "repeat", "=", "len", "(", "self", ".", "fully_connected", ")", ")", ")", "\n", "\n", "remove", "=", "[", "]", "\n", "for", "el", "in", "self", ".", "fully_connected_list", ":", "\n", "            ", "for", "tuple_", "in", "self", ".", "exclude", ":", "\n", "                ", "if", "sum", "(", "[", "el", "[", "self", ".", "fully_connected", ".", "index", "(", "a", ")", "]", "for", "a", "in", "tuple_", "]", ")", ">", "1", ":", "\n", "                    ", "if", "el", "not", "in", "remove", ":", "\n", "                        ", "remove", ".", "append", "(", "el", ")", "\n", "", "", "", "for", "a", ",", "b", "in", "self", ".", "only_if", ":", "\n", "                ", "if", "el", "[", "self", ".", "fully_connected", ".", "index", "(", "a", ")", "]", "==", "1", "and", "el", "[", "self", ".", "fully_connected", ".", "index", "(", "b", ")", "]", "==", "0", ":", "\n", "                    ", "if", "el", "not", "in", "remove", ":", "\n", "                        ", "remove", ".", "append", "(", "el", ")", "\n", "", "", "", "if", "sum", "(", "el", ")", ">", "self", ".", "remove_size", ":", "\n", "                ", "if", "el", "not", "in", "remove", ":", "\n", "                    ", "remove", ".", "append", "(", "el", ")", "\n", "\n", "", "", "", "for", "r", "in", "remove", ":", "\n", "            ", "self", ".", "fully_connected_list", ".", "remove", "(", "r", ")", "\n", "\n", "", "self", ".", "action_list", "=", "[", "]", "\n", "for", "el", "in", "self", ".", "fully_connected_list", ":", "\n", "            ", "new_action", "=", "copy", ".", "deepcopy", "(", "self", ".", "zero_action", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "self", ".", "fully_connected", ",", "el", ")", ":", "\n", "                ", "if", "key", "in", "self", ".", "camera_actions", ":", "\n", "                    ", "if", "value", ":", "\n", "                        ", "new_action", "[", "'camera'", "]", "=", "self", ".", "camera_dict", "[", "key", "]", "\n", "", "", "else", ":", "\n", "                    ", "new_action", "[", "key", "]", "=", "value", "\n", "", "", "self", ".", "action_list", ".", "append", "(", "new_action", ")", "\n", "\n", "", "self", ".", "separate_id_dict", "=", "OrderedDict", "(", ")", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "self", ".", "separate", ")", ":", "\n", "            ", "self", ".", "separate_id_dict", "[", "key", "]", "=", "OrderedDict", "(", ")", "\n", "for", "id_", "in", "self", ".", "separate_values", "[", "i", "]", ":", "\n", "                ", "new_action", "=", "copy", ".", "deepcopy", "(", "self", ".", "zero_action", ")", "\n", "new_action", "[", "key", "]", "=", "id_", "\n", "self", ".", "separate_id_dict", "[", "key", "]", "[", "id_", "]", "=", "len", "(", "self", ".", "action_list", ")", "\n", "self", ".", "action_list", ".", "append", "(", "new_action", ")", "\n", "\n", "", "", "self", ".", "num_action_ids_list", "=", "[", "len", "(", "self", ".", "action_list", ")", "]", "\n", "self", ".", "act_continuous_size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_action": [[168, 172], ["copy.deepcopy", "numpy.random.normal", "int"], "methods", ["None"], ["", "def", "get_action", "(", "self", ",", "id_", ")", ":", "\n", "        ", "a", "=", "copy", ".", "deepcopy", "(", "self", ".", "action_list", "[", "int", "(", "id_", ")", "]", ")", "\n", "a", "[", "'camera'", "]", "+=", "np", ".", "random", ".", "normal", "(", "0.", ",", "0.5", ",", "2", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.print_action": [[173, 188], ["copy.deepcopy", "copy.deepcopy.items", "print", "int", "numpy.zeros"], "methods", ["None"], ["", "def", "print_action", "(", "self", ",", "id_", ")", ":", "\n", "        ", "a", "=", "copy", ".", "deepcopy", "(", "self", ".", "action_list", "[", "int", "(", "id_", ")", "]", ")", "\n", "out", "=", "\"\"", "\n", "for", "k", ",", "v", "in", "a", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "!=", "'camera'", ":", "\n", "                ", "if", "v", "!=", "0", ":", "\n", "                    ", "if", "k", "in", "self", ".", "separate_str_lists", ":", "\n", "                        ", "out", "+=", "f'{k} {self.separate_str_lists[k][v]} '", "\n", "", "else", ":", "\n", "                        ", "out", "+=", "f'{k} '", "\n", "", "", "", "else", ":", "\n", "                ", "if", "(", "v", "!=", "np", ".", "zeros", "(", "2", ")", ")", ".", "any", "(", ")", ":", "\n", "                    ", "out", "+=", "k", "\n", "\n", "", "", "", "print", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_id": [[189, 247], ["copy.deepcopy", "data_manager.ActionManager.camera_dict.items", "tuple", "data_manager.ActionManager.fully_connected_list.index", "numpy.sign", "len", "sum", "numpy.sign", "numpy.array"], "methods", ["None"], ["", "def", "get_id", "(", "self", ",", "action", ")", ":", "\n", "\n", "        ", "for", "key", "in", "self", ".", "separate", ":", "\n", "            ", "if", "action", "[", "key", "]", "!=", "0", ":", "\n", "                ", "if", "action", "[", "key", "]", "in", "self", ".", "separate_id_dict", "[", "key", "]", ":", "\n", "                    ", "action_id", "=", "self", ".", "separate_id_dict", "[", "key", "]", "[", "action", "[", "key", "]", "]", "\n", "return", "action_id", "\n", "\n", "", "", "", "action", "=", "copy", ".", "deepcopy", "(", "action", ")", "\n", "\n", "# discretize 'camera':", "\n", "camera", "=", "action", "[", "'camera'", "]", "\n", "camera_action_amount", "=", "0", "\n", "if", "-", "self", ".", "c_action_magnitude", "/", "2.", "<", "camera", "[", "0", "]", "<", "self", ".", "c_action_magnitude", "/", "2.", ":", "\n", "            ", "action", "[", "'camera'", "]", "[", "0", "]", "=", "0.", "\n", "if", "-", "self", ".", "c_action_magnitude", "/", "2.", "<", "camera", "[", "1", "]", "<", "self", ".", "c_action_magnitude", "/", "2.", ":", "\n", "                ", "action", "[", "'camera'", "]", "[", "1", "]", "=", "0.", "\n", "", "else", ":", "\n", "                ", "camera_action_amount", "=", "1", "\n", "action", "[", "'camera'", "]", "[", "1", "]", "=", "self", ".", "c_action_magnitude", "*", "np", ".", "sign", "(", "camera", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "camera_action_amount", "=", "1", "\n", "action", "[", "'camera'", "]", "[", "0", "]", "=", "self", ".", "c_action_magnitude", "*", "np", ".", "sign", "(", "camera", "[", "0", "]", ")", "\n", "\n", "action", "[", "'camera'", "]", "[", "1", "]", "=", "0.", "\n", "\n", "# simplify action:", "\n", "", "for", "tuple_", "in", "self", ".", "exclude", ":", "\n", "            ", "if", "len", "(", "tuple_", ")", "==", "2", ":", "\n", "                ", "a", ",", "b", "=", "tuple_", "\n", "if", "action", "[", "a", "]", "and", "action", "[", "b", "]", ":", "\n", "                    ", "action", "[", "b", "]", "=", "0", "\n", "", "", "", "for", "a", ",", "b", "in", "self", ".", "only_if", ":", "\n", "            ", "if", "not", "action", "[", "b", "]", ":", "\n", "                ", "if", "action", "[", "a", "]", ":", "\n", "                    ", "action", "[", "a", "]", "=", "0", "\n", "", "", "", "for", "a", "in", "self", ".", "remove_first_list", ":", "\n", "            ", "if", "sum", "(", "[", "action", "[", "key", "]", "for", "key", "in", "self", ".", "fully_connected_no_camera", "]", ")", ">", "(", "self", ".", "remove_size", "-", "camera_action_amount", ")", ":", "\n", "                ", "if", "a", "in", "self", ".", "camera_actions", ":", "\n", "                    ", "action", "[", "'camera'", "]", "=", "np", ".", "array", "(", "[", "0.", ",", "0.", "]", ")", "\n", "camera_action_amount", "=", "0", "\n", "", "else", ":", "\n", "                    ", "action", "[", "a", "]", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "\n", "# set one_hot camera keys:", "\n", "", "", "for", "key", "in", "self", ".", "camera_actions", ":", "\n", "            ", "action", "[", "key", "]", "=", "0", "\n", "", "for", "key", ",", "val", "in", "self", ".", "camera_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "(", "action", "[", "'camera'", "]", "==", "val", ")", ".", "all", "(", ")", ":", "\n", "                ", "action", "[", "key", "]", "=", "1", "\n", "break", "\n", "\n", "", "", "non_separate_values", "=", "tuple", "(", "action", "[", "key", "]", "for", "key", "in", "self", ".", "fully_connected", ")", "\n", "\n", "return", "self", ".", "fully_connected_list", ".", "index", "(", "non_separate_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_torch_action": [[248, 253], ["torch.tensor"], "methods", ["None"], ["", "def", "get_torch_action", "(", "self", ",", "a_id_batch_list", ")", ":", "\n", "        ", "a_id_torch_list", "=", "[", "torch", ".", "tensor", "(", "a_id_batch", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "self", ".", "device", ")", "for", "a_id_batch", "in", "\n", "a_id_batch_list", "]", "\n", "\n", "return", "a_id_torch_list", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_left_right_reversed_mapping": [[254, 275], ["copy.deepcopy", "data_manager.ActionManager.get_id", "action_mapping.append"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_id", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append"], ["", "def", "get_left_right_reversed_mapping", "(", "self", ")", ":", "\n", "        ", "action_mapping", "=", "[", "]", "\n", "for", "action", "in", "self", ".", "action_list", ":", "\n", "            ", "reversed_action", "=", "copy", ".", "deepcopy", "(", "action", ")", "\n", "if", "action", "[", "'left'", "]", "==", "1", ":", "\n", "                ", "reversed_action", "[", "'left'", "]", "=", "0", "\n", "reversed_action", "[", "'right'", "]", "=", "1", "\n", "assert", "action", "[", "'right'", "]", "==", "0", "\n", "", "if", "action", "[", "'right'", "]", "==", "1", ":", "\n", "                ", "reversed_action", "[", "'right'", "]", "=", "0", "\n", "reversed_action", "[", "'left'", "]", "=", "1", "\n", "assert", "action", "[", "'left'", "]", "==", "0", "\n", "", "if", "(", "action", "[", "'camera'", "]", "==", "[", "0", ",", "-", "22.5", "]", ")", ".", "all", "(", ")", ":", "\n", "                ", "reversed_action", "[", "'camera'", "]", "[", "1", "]", "=", "22.5", "\n", "", "if", "(", "action", "[", "'camera'", "]", "==", "[", "0", ",", "22.5", "]", ")", ".", "all", "(", ")", ":", "\n", "                ", "reversed_action", "[", "'camera'", "]", "[", "1", "]", "=", "-", "22.5", "\n", "\n", "", "rev_action_id", "=", "self", ".", "get_id", "(", "reversed_action", ")", "\n", "action_mapping", ".", "append", "(", "rev_action_id", ")", "\n", "\n", "", "return", "action_mapping", "\n", "", "", ""]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.main.str2bool": [[30, 37], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.main.get_args": [[39, 94], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", "raw_args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Rainbow'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "123", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.0000625", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_eps'", ",", "type", "=", "float", ",", "default", "=", "1.5e-4", ")", "\n", "parser", ".", "add_argument", "(", "'--enable_cudnn'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logdir\"", ",", "default", "=", "\".\"", ",", "type", "=", "str", ",", "help", "=", "\"used for logging and to save network snapshots\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--c_action_magnitude'", ",", "type", "=", "float", ",", "default", "=", "22.5", ",", "help", "=", "\"magnitude of discretized camera action\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--net\"", ",", "default", "=", "'deep_resnet'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'normal'", ",", "'resnet'", ",", "'deep_resnet'", ",", "'double_deep_resnet'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "\"size of main fully-connected layers\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset_path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"use if dataset is already created\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--trainsteps'", ",", "type", "=", "int", ",", "default", "=", "3000000", ")", "\n", "parser", ".", "add_argument", "(", "'--augment_flip'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset_only_successful'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_use_max_duration_steps'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_continuous_action_stacking'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_max_reward'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--minecraft_human_data_dir'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"location of MineRL human data\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--save_dataset_path'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--quit_after_saving_dataset'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dueling'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--scale_rewards'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--eval_policy'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_policy_path'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_policy_model_id'", ",", "type", "=", "str", ",", "default", "=", "\"last\"", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_policy_episodes'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--add_treechop_data'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ",", "\n", "help", "=", "\"Set to true to create a dataset with additional Treechop trajectories\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ",", "help", "=", "\"for debugging\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--stop_time'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Maximal training time in hours.\"", "\n", "\"Will save tmp snapshot after the time limit is over.\"", "\n", "\"Starting a training run with identical logdir will \"", "\n", "\"continue the training from the tmp snapshot.\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", "raw_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.main.rl": [[96, 335], ["time.time", "print", "vars().items", "os.path.exists", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed", "torch.device", "print", "data_manager.StateManager", "data_manager.ActionManager", "minecraft.Env", "print", "minecraft.Env.reset", "print", "print", "list", "int", "SummaryWriter", "agent.Agent", "minecraft.Env.close", "os.path.exists", "os.path.exists", "print", "numpy.random.randint", "numpy.random.randint", "gym.make", "minecraft.DummyMinecraft.seed", "minecraft.DummyMinecraft", "minecraft.DummyMinecraft.seed", "open", "status_file.write", "SummaryWriter.flush", "SummaryWriter.close", "minecraft.Env.close", "sys.__excepthook__", "dataset.Dataset", "range", "agent.Agent.load", "print", "minecraft.test_policy", "print", "agent.Agent.train", "time.time", "range", "agent.Agent.save", "print", "open", "status_file.write", "os.path.join", "print", "os.path.join", "print", "vars", "os.path.join", "open", "status_file_.write", "print", "dataset.Dataset.load", "print", "print", "get_dataset.put_data_into_dataset", "get_dataset.put_data_into_dataset", "dataset.Transition", "open", "status_file.write", "pickle.load", "print", "agent.Agent.load", "open", "status_file.write", "agent.Agent.learn", "os.path.join", "str", "os.path.join", "get_dataset.put_data_into_dataset", "dataset.Dataset.save", "print", "print", "dataset.Dataset.transitions.data[].state.pin_memory", "dataset.Dataset.transitions.data[].vector.pin_memory", "os.path.join", "open", "os.path.join", "agent.Agent.save", "SummaryWriter.add_scalar", "print", "print", "os.path.join", "print", "agent.Agent.save", "pickle.dump", "SummaryWriter.close", "print", "float", "int", "open", "time.time", "os.path.join", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.seed", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.reset", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.close", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.seed", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.seed", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.close", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.close", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.test_policy", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.train", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.get_dataset.put_data_into_dataset", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.get_dataset.put_data_into_dataset", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.learn", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.get_dataset.put_data_into_dataset", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.close"], ["", "def", "rl", "(", "args", ")", ":", "\n", "    ", "\"\"\" main function for both training and evaluation. Default is set to train mode.\n    Set args.eval_policy = True for evaluation\n\n    :param args: Get default parameters from get_args()\n    \"\"\"", "\n", "\n", "init_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "not", "args", ".", "eval_policy", ":", "\n", "        ", "if", "p_exists", "(", "p_join", "(", "args", ".", "logdir", ",", "'model_last.pth'", ")", ")", ":", "\n", "            ", "print", "(", "\"Training already finished\"", ")", "\n", "return", "\n", "\n", "", "if", "p_exists", "(", "p_join", "(", "args", ".", "logdir", ",", "\"tmp_time.p\"", ")", ")", ":", "\n", "            ", "print", "(", "\"Detected tmp snapshot, will continue training from there\"", ")", "\n", "continue_from_tmp", "=", "True", "\n", "", "else", ":", "\n", "            ", "continue_from_tmp", "=", "False", "\n", "\n", "# Setup", "\n", "\n", "", "", "print", "(", "' '", "*", "26", "+", "'Options'", ")", "\n", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "' '", "*", "26", "+", "k", "+", "': '", "+", "str", "(", "v", ")", ")", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "args", ".", "logdir", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "np", ".", "random", ".", "randint", "(", "1", ",", "10000", ")", ")", "\n", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "np", ".", "random", ".", "randint", "(", "1", ",", "10000", ")", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "=", "args", ".", "enable_cudnn", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "print", "(", "f\"Running on {args.device}\"", ")", "\n", "\n", "state_manager", "=", "StateManager", "(", "args", ".", "device", ")", "\n", "action_manager", "=", "ActionManager", "(", "args", ".", "device", ",", "args", ".", "c_action_magnitude", ")", "\n", "\n", "# ########################################### CREATE ENVIRONMENT ###################################################", "\n", "\n", "if", "args", ".", "eval_policy", "and", "not", "args", ".", "test", ":", "\n", "        ", "env_", "=", "gym", ".", "make", "(", "'MineRLObtainDiamond-v0'", ")", "\n", "env_", ".", "seed", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "env_", "=", "DummyMinecraft", "(", ")", "\n", "env_", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "env", "=", "Env", "(", "env_", ",", "state_manager", ",", "action_manager", ")", "\n", "\n", "print", "(", "\"started env\"", ")", "\n", "\n", "img", ",", "vec", "=", "env", ".", "reset", "(", ")", "\n", "\n", "print", "(", "\"env reset\"", ")", "\n", "\n", "print", "(", "\"img, vec shapes: \"", ",", "img", ".", "shape", ",", "vec", ".", "shape", ")", "\n", "\n", "# ########################################### GET ENV DATA AND WRITER ##############################################", "\n", "\n", "num_actions", "=", "action_manager", ".", "num_action_ids_list", "[", "0", "]", "\n", "image_channels", "=", "img", ".", "shape", "[", "1", "]", "\n", "\n", "vec_size", "=", "vec", ".", "shape", "[", "1", "]", "\n", "vec_shape", "=", "vec", ".", "shape", "[", "1", ":", "]", "\n", "\n", "img_shape", "=", "list", "(", "img", ".", "shape", "[", "1", ":", "]", ")", "\n", "img_shape", "[", "0", "]", "=", "int", "(", "img_shape", "[", "0", "]", ")", "\n", "\n", "writer", "=", "SummaryWriter", "(", "args", ".", "logdir", ")", "\n", "\n", "with", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"status.txt\"", ")", ",", "'w'", ")", "as", "status_file", ":", "\n", "        ", "status_file", ".", "write", "(", "'running'", ")", "\n", "\n", "# extended error exception:", "\n", "", "def", "handle_exception", "(", "exc_type", ",", "exc_value", ",", "exc_traceback", ")", ":", "\n", "\n", "        ", "with", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"status.txt\"", ")", ",", "'w'", ")", "as", "status_file_", ":", "\n", "            ", "status_file_", ".", "write", "(", "'error'", ")", "\n", "\n", "", "writer", ".", "flush", "(", ")", "\n", "writer", ".", "close", "(", ")", "\n", "env", ".", "close", "(", ")", "\n", "sys", ".", "__excepthook__", "(", "exc_type", ",", "exc_value", ",", "exc_traceback", ")", "\n", "\n", "", "sys", ".", "excepthook", "=", "handle_exception", "\n", "\n", "# ########################################### GET DATASET ##########################################################", "\n", "\n", "if", "not", "args", ".", "eval_policy", ":", "\n", "        ", "dataset", "=", "Dataset", "(", "args", ".", "device", ",", "2000000", ",", "img_shape", ",", "vec_shape", ",", "\n", "state_manager", ",", "action_manager", ",", "\n", "scale_rewards", "=", "args", ".", "scale_rewards", ")", "\n", "\n", "if", "args", ".", "dataset_path", "is", "not", "None", ":", "# default None", "\n", "\n", "            ", "print", "(", "f\"loading dataset {args.dataset_path}\"", ")", "\n", "dataset", ".", "load", "(", "args", ".", "dataset_path", ")", "\n", "print", "(", "f\"loaded dataset\"", ")", "\n", "\n", "", "else", ":", "# creating dataset:", "\n", "\n", "            ", "assert", "args", ".", "minecraft_human_data_dir", "is", "not", "None", "\n", "\n", "print", "(", "\"creating dataset\"", ")", "\n", "\n", "if", "args", ".", "dataset_use_max_duration_steps", ":", "# default: True", "\n", "                ", "max_iron_pickaxe_duration", "=", "6000", "\n", "max_diamond_duration", "=", "18000", "\n", "", "else", ":", "\n", "                ", "max_iron_pickaxe_duration", "=", "None", "\n", "max_diamond_duration", "=", "None", "\n", "\n", "", "put_data_into_dataset", "(", "\n", "'MineRLObtainIronPickaxe-v0'", ",", "action_manager", ",", "dataset", ",", "args", ".", "minecraft_human_data_dir", ",", "\n", "args", ".", "dataset_continuous_action_stacking", ",", "\n", "args", ".", "dataset_only_successful", ",", "\n", "max_iron_pickaxe_duration", ",", "\n", "args", ".", "dataset_max_reward", ",", "\n", "args", ".", "test", ")", "\n", "\n", "put_data_into_dataset", "(", "\n", "'MineRLObtainDiamond-v0'", ",", "action_manager", ",", "dataset", ",", "args", ".", "minecraft_human_data_dir", ",", "\n", "args", ".", "dataset_continuous_action_stacking", ",", "\n", "args", ".", "dataset_only_successful", ",", "\n", "max_diamond_duration", ",", "\n", "args", ".", "dataset_max_reward", ",", "\n", "args", ".", "test", ")", "\n", "\n", "if", "args", ".", "add_treechop_data", ":", "\n", "                ", "put_data_into_dataset", "(", "\n", "'MineRLTreechop-v0'", ",", "action_manager", ",", "dataset", ",", "args", ".", "minecraft_human_data_dir", ",", "\n", "args", ".", "dataset_continuous_action_stacking", ",", "\n", "args", ".", "dataset_only_successful", ",", "\n", "None", ",", "\n", "args", ".", "dataset_max_reward", ",", "\n", "args", ".", "test", ")", "\n", "\n", "", "if", "args", ".", "save_dataset_path", "is", "not", "None", ":", "\n", "                ", "dataset", ".", "save", "(", "args", ".", "save_dataset_path", ")", "\n", "print", "(", "f\"saved new dataset{args.save_dataset_path} with {dataset.transitions.index} transitions\"", ")", "\n", "\n", "if", "args", ".", "quit_after_saving_dataset", ":", "\n", "                    ", "print", "(", "\"stopping after saving the new dataset\"", ")", "\n", "return", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"continuing with new dataset\"", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"continuing with new dataset without saving\"", ")", "\n", "\n", "", "", "for", "j", "in", "range", "(", "dataset", ".", "transitions", ".", "index", ")", ":", "\n", "            ", "dataset", ".", "transitions", ".", "data", "[", "j", "]", "=", "Transition", "(", "\n", "dataset", ".", "transitions", ".", "data", "[", "j", "]", ".", "state", ".", "pin_memory", "(", ")", ",", "\n", "dataset", ".", "transitions", ".", "data", "[", "j", "]", ".", "vector", ".", "pin_memory", "(", ")", ",", "\n", "dataset", ".", "transitions", ".", "data", "[", "j", "]", ".", "action", ",", "\n", "dataset", ".", "transitions", ".", "data", "[", "j", "]", ".", "reward", ",", "\n", "dataset", ".", "transitions", ".", "data", "[", "j", "]", ".", "nonterminal", "\n", ")", "\n", "\n", "# ########################################### CREATE NETWORK #######################################################", "\n", "\n", "", "", "agent", "=", "Agent", "(", "num_actions", ",", "image_channels", ",", "vec_size", ",", "writer", ",", "\n", "args", ".", "net", ",", "args", ".", "batch_size", ",", "args", ".", "augment_flip", ",", "args", ".", "hidden_size", ",", "args", ".", "dueling", ",", "\n", "args", ".", "learning_rate", ",", "args", ".", "adam_eps", ",", "args", ".", "device", ")", "\n", "\n", "# ########################################### EVALUATION ###########################################################  ", "\n", "\n", "if", "args", ".", "eval_policy", ":", "\n", "\n", "        ", "assert", "args", ".", "eval_policy_path", "is", "not", "None", "\n", "\n", "agent", ".", "load", "(", "args", ".", "eval_policy_path", ",", "args", ".", "eval_policy_model_id", ")", "\n", "\n", "print", "(", "f\"loaded network {args.eval_policy_path} {args.eval_policy_model_id}\"", ")", "\n", "\n", "policy", "=", "agent", ".", "act", "\n", "\n", "with", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"status.txt\"", ")", ",", "'w'", ")", "as", "status_file", ":", "\n", "            ", "status_file", ".", "write", "(", "'running test_policy'", ")", "\n", "\n", "", "if", "args", ".", "test", ":", "\n", "            ", "args", ".", "eval_policy_episodes", "=", "2", "\n", "\n", "", "test_policy", "(", "writer", ",", "env", ",", "policy", ",", "img", ",", "vec", ",", "args", ".", "eval_policy_episodes", ")", "\n", "\n", "# ########################################### TRAINING #############################################################", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"starting TRAINING\"", ")", "\n", "\n", "if", "continue_from_tmp", ":", "\n", "            ", "start_int", "=", "pickle", ".", "load", "(", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"tmp_time.p\"", ")", ",", "\"rb\"", ")", ")", "\n", "print", "(", "f\"continuing from {start_int} trainstep\"", ")", "\n", "agent", ".", "load", "(", "args", ".", "logdir", ",", "\"tmp\"", ")", "\n", "", "else", ":", "\n", "            ", "start_int", "=", "0", "\n", "\n", "", "agent", ".", "train", "(", ")", "\n", "\n", "with", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"status.txt\"", ")", ",", "'w'", ")", "as", "status_file", ":", "\n", "            ", "status_file", ".", "write", "(", "'running training'", ")", "\n", "\n", "", "if", "args", ".", "test", ":", "\n", "            ", "args", ".", "trainsteps", "=", "10", "\n", "\n", "", "fps_t0", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_int", ",", "args", ".", "trainsteps", ")", ":", "\n", "\n", "            ", "agent", ".", "learn", "(", "i", ",", "dataset", ",", "write", "=", "(", "i", "%", "1000", "==", "0", ")", ")", "\n", "\n", "if", "i", "and", "i", "%", "100000", "==", "0", ":", "\n", "                ", "agent", ".", "save", "(", "args", ".", "logdir", ",", "i", "//", "100000", ")", "\n", "\n", "", "if", "args", ".", "stop_time", "is", "not", "None", ":", "\n", "                ", "if", "(", "(", "time", ".", "time", "(", ")", "-", "init_time", ")", "/", "60.", "/", "60.", ")", ">", "args", ".", "stop_time", ":", "\n", "                    ", "print", "(", "f\"{(time.time() - init_time) / 60. / 60.} h passed, saving tmp snapshot\"", ",", "flush", "=", "True", ")", "\n", "agent", ".", "save", "(", "args", ".", "logdir", ",", "\"tmp\"", ")", "\n", "pickle", ".", "dump", "(", "int", "(", "i", ")", ",", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"tmp_time.p\"", ")", ",", "'wb'", ")", ")", "\n", "writer", ".", "close", "(", ")", "\n", "print", "(", "'saved'", ")", "\n", "return", "\n", "\n", "", "", "if", "(", "i", "+", "1", ")", "%", "5000", "==", "0", ":", "\n", "                ", "fps", "=", "float", "(", "i", "-", "start_int", ")", "/", "(", "time", ".", "time", "(", ")", "-", "fps_t0", ")", "\n", "writer", ".", "add_scalar", "(", "\"fps\"", ",", "fps", ",", "i", ")", "\n", "\n", "", "", "agent", ".", "save", "(", "args", ".", "logdir", ",", "'last'", ")", "\n", "\n", "print", "(", "\"finished TRAINING\"", ")", "\n", "\n", "# ########################################### OUTRO  ###############################################################", "\n", "\n", "", "with", "open", "(", "p_join", "(", "args", ".", "logdir", ",", "\"status.txt\"", ")", ",", "'w'", ")", "as", "status_file", ":", "\n", "        ", "status_file", ".", "write", "(", "'finished'", ")", "\n", "\n", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.__init__": [[13, 86], ["numpy.full", "minerl.Discrete", "minerl.Discrete", "minerl.Box", "minerl.Enum", "minerl.Enum", "minerl.Discrete", "minerl.Discrete", "minerl.Discrete", "minerl.Enum", "minerl.Enum", "minerl.Enum", "minerl.Discrete", "minerl.Discrete", "minerl.Discrete", "minerl.Box", "numpy.full", "numpy.full", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "minerl.Box", "numpy.full", "numpy.full", "minerl.Box", "minerl.Box", "minerl.Enum", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full", "numpy.full"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "=", "{", "\n", "'equipped_items'", ":", "{", "'mainhand'", ":", "{", "'damage'", ":", "0", ",", "'maxDamage'", ":", "0", ",", "'type'", ":", "0", "}", "}", ",", "\n", "'inventory'", ":", "{", "'coal'", ":", "0", ",", "\n", "'cobblestone'", ":", "0", ",", "\n", "'crafting_table'", ":", "0", ",", "\n", "'dirt'", ":", "0", ",", "\n", "'furnace'", ":", "0", ",", "\n", "'iron_axe'", ":", "0", ",", "\n", "'iron_ingot'", ":", "0", ",", "\n", "'iron_ore'", ":", "0", ",", "\n", "'iron_pickaxe'", ":", "0", ",", "\n", "'log'", ":", "0", ",", "\n", "'planks'", ":", "0", ",", "\n", "'stick'", ":", "0", ",", "\n", "'stone'", ":", "0", ",", "\n", "'stone_axe'", ":", "0", ",", "\n", "'stone_pickaxe'", ":", "0", ",", "\n", "'torch'", ":", "0", ",", "\n", "'wooden_axe'", ":", "0", ",", "\n", "'wooden_pickaxe'", ":", "0", "}", ",", "\n", "'pov'", ":", "np", ".", "full", "(", "[", "64", ",", "64", ",", "3", "]", ",", "127", ",", "dtype", "=", "np", ".", "uint8", ")", "}", "\n", "\n", "self", ".", "action_space", "=", "{", "\n", "'attack'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'back'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'camera'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "2", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "2", "]", ",", "1", ")", ")", ",", "\n", "'craft'", ":", "spaces", ".", "Enum", "(", "'none'", ",", "'torch'", ",", "'stick'", ",", "'planks'", ",", "'crafting_table'", ")", ",", "\n", "'equip'", ":", "spaces", ".", "Enum", "(", "'none'", ",", "'air'", ",", "'wooden_axe'", ",", "'wooden_pickaxe'", ",", "'stone_axe'", ",", "\n", "'stone_pickaxe'", ",", "'iron_axe'", ",", "'iron_pickaxe'", ")", ",", "\n", "'forward'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'jump'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'left'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'nearbyCraft'", ":", "spaces", ".", "Enum", "(", "'none'", ",", "'wooden_axe'", ",", "'wooden_pickaxe'", ",", "'stone_axe'", ",", "\n", "'stone_pickaxe'", ",", "'iron_axe'", ",", "'iron_pickaxe'", ",", "'furnace'", ")", ",", "\n", "'nearbySmelt'", ":", "spaces", ".", "Enum", "(", "'none'", ",", "'iron_ingot'", ",", "'coal'", ")", ",", "\n", "'place'", ":", "spaces", ".", "Enum", "(", "'none'", ",", "'dirt'", ",", "'stone'", ",", "'cobblestone'", ",", "'crafting_table'", ",", "'furnace'", ",", "'torch'", ")", ",", "\n", "'right'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'sneak'", ":", "spaces", ".", "Discrete", "(", "2", ")", ",", "\n", "'sprint'", ":", "spaces", ".", "Discrete", "(", "2", ")", "}", "\n", "\n", "self", ".", "observation_space", "=", "{", "\n", "'equipped_items'", ":", "{", "\n", "'mainhand'", ":", "{", "\n", "'damage'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "2", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "2", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'maxDamage'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "2", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "2", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'type'", ":", "spaces", ".", "Enum", "(", "'none'", ",", "'air'", ",", "'wooden_axe'", ",", "'wooden_pickaxe'", ",", "'stone_axe'", ",", "'stone_pickaxe'", ",", "\n", "'iron_axe'", ",", "'iron_pickaxe'", ",", "'other'", ")", "}", "}", ",", "\n", "'inventory'", ":", "{", "\n", "'coal'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'cobblestone'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'crafting_table'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'dirt'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'furnace'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'iron_axe'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'iron_ingot'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'iron_ore'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'iron_pickaxe'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'log'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'planks'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'stick'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'stone'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'stone_axe'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'stone_pickaxe'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'torch'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'wooden_axe'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", ",", "\n", "'wooden_pickaxe'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "1", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "}", ",", "\n", "'pov'", ":", "spaces", ".", "Box", "(", "np", ".", "full", "(", "[", "64", ",", "64", ",", "3", "]", ",", "-", "1", ")", ",", "np", ".", "full", "(", "[", "64", ",", "64", ",", "3", "]", ",", "-", "1", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "}", "\n", "\n", "self", ".", "reward_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", "\n", "self", ".", "metadata", "=", "{", "'render.modes'", ":", "[", "'rgb_array'", ",", "'human'", "]", "}", "\n", "\n", "self", ".", "t", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.reset": [[87, 91], ["copy.deepcopy"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "t", "=", "0", "\n", "self", ".", "state", "[", "'pov'", "]", "[", ":", ",", ":", ",", ":", "]", "=", "0", "\n", "return", "deepcopy", "(", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.step": [[92, 99], ["copy.deepcopy", "copy.deepcopy"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "t", "+=", "1", "\n", "self", ".", "state", "[", "'pov'", "]", "[", ":", ",", ":", ",", ":", "]", "=", "0", "\n", "if", "self", ".", "t", "<", "1000", ":", "\n", "            ", "return", "deepcopy", "(", "self", ".", "state", ")", ",", "0.1", ",", "False", ",", "{", "}", "\n", "", "else", ":", "\n", "            ", "return", "deepcopy", "(", "self", ".", "state", ")", ",", "0.1", ",", "True", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.close": [[100, 102], ["None"], "methods", ["None"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.seed": [[103, 105], ["None"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "_", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.__init__": [[112, 122], ["gym.core.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "state_manager", ",", "action_manager", ")", ":", "\n", "\n", "        ", "self", ".", "state_manager", "=", "state_manager", "\n", "self", ".", "action_manager", "=", "action_manager", "\n", "\n", "self", ".", "done", "=", "False", "\n", "\n", "self", ".", "last_obs", "=", "None", "# used for logging", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env._process_obs": [[123, 129], ["minecraft.Env.state_manager.get_img_vec", "minecraft.Env.state_manager.get_torch_img_vec"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager.get_img_vec", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager.get_torch_img_vec"], ["", "def", "_process_obs", "(", "self", ",", "obs", ")", ":", "\n", "        ", "img", ",", "vec", "=", "self", ".", "state_manager", ".", "get_img_vec", "(", "obs", ")", "\n", "\n", "torch_img", ",", "torch_vec", "=", "self", ".", "state_manager", ".", "get_torch_img_vec", "(", "[", "img", "]", ",", "[", "vec", "]", ")", "\n", "\n", "return", "torch_img", ",", "torch_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.reset": [[130, 137], ["minecraft.Env.env.reset", "minecraft.Env._process_obs"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.reset", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env._process_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "self", ".", "last_obs", "=", "obs", "\n", "\n", "self", ".", "done", "=", "False", "\n", "return", "self", ".", "_process_obs", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.step": [[138, 161], ["minecraft.Env.action_manager.get_action", "super().step", "minecraft.Env._process_obs"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_action", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.step", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env._process_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "assert", "not", "self", ".", "done", "\n", "\n", "action", "=", "self", ".", "action_manager", ".", "get_action", "(", "action", ")", "\n", "\n", "if", "'craft'", "in", "action", ":", "\n", "            ", "if", "action", "[", "'attack'", "]", "==", "0", "and", "action", "[", "'craft'", "]", "==", "0", "and", "action", "[", "'nearbyCraft'", "]", "==", "0", "and", "action", "[", "'nearbySmelt'", "]", "==", "0", "and", "action", "[", "'place'", "]", "==", "0", ":", "\n", "                ", "action", "[", "'jump'", "]", "=", "1", "\n", "", "", "else", ":", "\n", "            ", "if", "action", "[", "'attack'", "]", "==", "0", ":", "\n", "                ", "action", "[", "'jump'", "]", "=", "1", "\n", "\n", "", "", "obs", ",", "r", ",", "self", ".", "done", ",", "info", "=", "super", "(", ")", ".", "step", "(", "action", ")", "\n", "\n", "self", ".", "last_obs", "=", "obs", "\n", "\n", "torch_img", ",", "torch_vec", "=", "self", ".", "_process_obs", "(", "obs", ")", "\n", "return", "torch_img", ",", "torch_vec", ",", "r", ",", "self", ".", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.test_policy": [[163, 237], ["print", "writer.add_scalar", "writer.add_scalar", "writer.flush", "writer.close", "print", "numpy.mean", "numpy.mean", "wrapped_env.seed", "wrapped_env.reset", "copy.deepcopy", "policy", "wrapped_env.step", "print", "reward_list.append", "steps_list.append", "print", "print", "writer.add_scalar", "writer.add_scalar", "writer.flush", "numpy.mean", "writer.add_scalars", "copy.deepcopy", "print", "writer.add_scalars", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.close", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.DummyMinecraft.seed", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.reset", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.step", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append"], ["", "", "def", "test_policy", "(", "writer", ",", "wrapped_env", ",", "policy", ",", "init_img", ",", "init_vec", ",", "episodes", "=", "100", ")", ":", "\n", "\n", "    ", "reward_list", "=", "[", "]", "\n", "steps_list", "=", "[", "]", "\n", "\n", "amount_of_episodes_with_saved_inventory", "=", "30", "\n", "\n", "first", "=", "True", "\n", "i", "=", "0", "\n", "while", "i", "<", "episodes", ":", "\n", "\n", "        ", "if", "first", ":", "\n", "            ", "img", ",", "vec", "=", "init_img", ",", "init_vec", "\n", "first", "=", "False", "\n", "", "else", ":", "\n", "            ", "wrapped_env", ".", "seed", "(", "i", ")", "\n", "img", ",", "vec", "=", "wrapped_env", ".", "reset", "(", ")", "\n", "\n", "", "print", "(", "\"episode {}\"", ".", "format", "(", "i", ")", ")", "\n", "reward", "=", "0.", "\n", "frame_steps", "=", "0", "\n", "steps", "=", "0", "\n", "last_obs", "=", "wrapped_env", ".", "last_obs", "\n", "last_meta_id", "=", "0", "\n", "\n", "if", "'inventory'", "in", "last_obs", ":", "\n", "            ", "last_print_dict", "=", "deepcopy", "(", "last_obs", "[", "'inventory'", "]", ")", "\n", "last_print_dict", "[", "'meta_id'", "]", "=", "last_meta_id", "\n", "if", "i", "<", "amount_of_episodes_with_saved_inventory", ":", "\n", "                ", "writer", ".", "add_scalars", "(", "f\"episode {i} inventory\"", ",", "last_print_dict", ",", "steps", ")", "\n", "\n", "", "", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "            ", "a_id", "=", "policy", "(", "img", ",", "vec", ")", "\n", "\n", "img", ",", "vec", ",", "r", ",", "done", "=", "wrapped_env", ".", "step", "(", "a_id", ")", "\n", "\n", "reward", "+=", "r", "\n", "steps", "+=", "1", "\n", "frame_steps", "+=", "1", "\n", "\n", "obs", "=", "wrapped_env", ".", "last_obs", "\n", "\n", "if", "'inventory'", "in", "last_obs", ":", "\n", "                ", "print_dict", "=", "deepcopy", "(", "obs", "[", "'inventory'", "]", ")", "\n", "if", "i", "<", "amount_of_episodes_with_saved_inventory", ":", "\n", "                    ", "if", "print_dict", "!=", "last_print_dict", ":", "\n", "                        ", "writer", ".", "add_scalars", "(", "f\"episode {i} inventory\"", ",", "print_dict", ",", "steps", ")", "\n", "", "", "last_print_dict", "=", "print_dict", "\n", "\n", "", "tmp_p", "=", "6000", "\n", "if", "steps", "%", "tmp_p", "==", "0", ":", "\n", "                ", "print", "(", "f\"{frame_steps} / {18000}\"", ")", "\n", "\n", "", "", "if", "steps", "==", "1", ":", "\n", "            ", "print", "(", "\"always terminal bug detected\"", ")", "\n", "raise", "RuntimeError", "\n", "\n", "", "else", ":", "\n", "            ", "reward_list", ".", "append", "(", "reward", ")", "\n", "steps_list", ".", "append", "(", "steps", ")", "\n", "print", "(", "f\"episode reward: {reward} , episode terminated after {steps} env steps\"", ")", "\n", "print", "(", "f\"avg_reward after {i + 1} (out of {episodes}) episodes: {np.mean(reward_list)}\"", ")", "\n", "writer", ".", "add_scalar", "(", "\"reward\"", ",", "reward", ",", "i", ")", "\n", "writer", ".", "add_scalar", "(", "\"steps\"", ",", "steps", ",", "i", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n", "", "i", "+=", "1", "\n", "\n", "", "print", "(", "\"Total avg_reward: {}\"", ".", "format", "(", "np", ".", "mean", "(", "reward_list", ")", ")", ")", "\n", "writer", ".", "add_scalar", "(", "\"avg_reward\"", ",", "np", ".", "mean", "(", "reward_list", ")", ",", "0", ")", "\n", "writer", ".", "add_scalar", "(", "\"avg_steps\"", ",", "np", ".", "mean", "(", "steps_list", ")", ",", "0", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "writer", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.__init__": [[12, 52], ["model.Network().to", "agent.Agent.net.train", "torch.optim.Adam", "torch.optim.Adam", "agent.Agent.net.parameters", "model.Network", "ValueError", "model.FixupResNetCNN"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.train"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ",", "image_channels", ",", "vec_size", ",", "writer", ",", "\n", "net", ",", "batch_size", ",", "augment_flip", ",", "hidden_size", ",", "dueling", ",", "learning_rate", ",", "adam_eps", ",", "device", ")", ":", "\n", "        ", "self", ".", "num_actions", "=", "num_actions", "\n", "self", ".", "writer", "=", "writer", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "self", ".", "augment_flip", "=", "augment_flip", "\n", "\n", "self", ".", "rev_action_map", "=", "None", "\n", "\n", "if", "self", ".", "augment_flip", ":", "\n", "# flipping the actions horizontally, for the horizontal image flip augmentation:", "\n", "            ", "self", ".", "rev_action_map", "=", "[", "0", ",", "2", ",", "1", ",", "3", ",", "4", ",", "10", ",", "12", ",", "11", ",", "13", ",", "14", ",", "5", ",", "7", ",", "6", ",", "8", ",", "9", ",", "15", ",", "17", ",", "16", ",", "18", ",", "19", ",", "\n", "25", ",", "27", ",", "26", ",", "28", ",", "29", ",", "20", ",", "22", ",", "21", ",", "23", ",", "24", ",", "30", ",", "32", ",", "31", ",", "33", ",", "34", ",", "35", ",", "37", ",", "\n", "36", ",", "38", ",", "39", ",", "46", ",", "48", ",", "47", ",", "49", ",", "50", ",", "51", ",", "40", ",", "42", ",", "41", ",", "43", ",", "44", ",", "45", ",", "52", ",", "54", ",", "\n", "53", ",", "55", ",", "56", ",", "57", ",", "59", ",", "58", ",", "60", ",", "62", ",", "61", ",", "63", ",", "64", ",", "70", ",", "72", ",", "71", ",", "73", ",", "74", ",", "65", ",", "\n", "67", ",", "66", ",", "68", ",", "69", ",", "75", ",", "77", ",", "76", ",", "78", ",", "79", ",", "81", ",", "80", ",", "82", ",", "84", ",", "83", ",", "85", ",", "86", ",", "92", ",", "\n", "94", ",", "93", ",", "95", ",", "96", ",", "87", ",", "89", ",", "88", ",", "90", ",", "91", ",", "97", ",", "99", ",", "98", ",", "100", ",", "101", ",", "102", ",", "104", ",", "\n", "103", ",", "105", ",", "107", ",", "106", ",", "108", ",", "109", ",", "111", ",", "110", ",", "112", ",", "113", ",", "114", ",", "115", ",", "116", ",", "117", ",", "\n", "118", ",", "119", ",", "120", ",", "121", ",", "122", ",", "123", ",", "124", ",", "125", ",", "126", ",", "127", ",", "128", ",", "129", "]", "\n", "# this id list can be received by running get_left_right_reversed_mapping() from the ActionManager", "\n", "\n", "", "if", "net", "==", "'normal'", ":", "\n", "            ", "cnn_module", "=", "AtariCNN", "\n", "", "elif", "net", "==", "'resnet'", ":", "\n", "            ", "cnn_module", "=", "ImpalaResNetCNN", "\n", "", "elif", "net", "==", "'deep_resnet'", ":", "\n", "            ", "cnn_module", "=", "FixupResNetCNN", "\n", "", "elif", "net", "==", "'double_deep_resnet'", ":", "\n", "            ", "cnn_module", "=", "lambda", "x", ":", "FixupResNetCNN", "(", "x", ",", "double_channels", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown args.net\"", ")", "\n", "\n", "", "self", ".", "net", "=", "Network", "(", "num_actions", ",", "image_channels", ",", "vec_size", ",", "cnn_module", ",", "hidden_size", ",", "\n", "dueling", "=", "dueling", ",", "\n", "double_channels", "=", "(", "net", "==", "'double_deep_resnet'", ")", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "self", ".", "net", ".", "train", "(", ")", "\n", "\n", "self", ".", "optimiser", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "eps", "=", "adam_eps", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.act": [[53, 64], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "agent.Agent.net", "torch.softmax().detach().cpu().numpy", "torch.softmax().detach().cpu().numpy", "numpy.random.choice", "len", "torch.softmax().detach().cpu", "torch.softmax().detach().cpu", "len", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "act", "(", "self", ",", "img", ",", "vec", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "logits", "=", "self", ".", "net", "(", "img", ",", "vec", ")", "\n", "probs", "=", "F", ".", "softmax", "(", "logits", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "actions", "=", "[", "np", ".", "random", ".", "choice", "(", "len", "(", "p", ")", ",", "p", "=", "p", ")", "for", "p", "in", "probs", "]", "\n", "\n", "assert", "len", "(", "actions", ")", "==", "1", "# only used with batchsize 1", "\n", "\n", "return", "actions", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.learn": [[65, 87], ["dataset.sample_line", "agent.Agent.net", "torch.cross_entropy", "torch.cross_entropy", "agent.Agent.net.zero_grad", "torch.cross_entropy.backward", "agent.Agent.optimiser.step", "numpy.random.binomial", "torch.flip", "torch.flip", "torch.flip", "torch.flip", "range", "agent.Agent.writer.add_scalar", "torch.cross_entropy.detach().cpu().numpy", "torch.cross_entropy.detach().cpu", "torch.cross_entropy.detach"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.sample_line", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.minecraft.Env.step"], ["", "", "def", "learn", "(", "self", ",", "time_", ",", "dataset", ",", "write", "=", "False", ")", ":", "\n", "\n", "        ", "states", ",", "vecs", ",", "actions", ",", "returns", ",", "next_states", ",", "next_vecs", ",", "nonterminals", "=", "dataset", ".", "sample_line", "(", "self", ".", "batch_size", ",", "1", ")", "\n", "\n", "if", "self", ".", "augment_flip", ":", "\n", "            ", "if", "np", ".", "random", ".", "binomial", "(", "n", "=", "1", ",", "p", "=", "0.5", ")", ":", "\n", "                ", "states", "=", "torch", ".", "flip", "(", "states", ",", "(", "3", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "actions", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "actions", "[", "i", "]", "=", "self", ".", "rev_action_map", "[", "actions", "[", "i", "]", "]", "\n", "\n", "", "", "", "logits", "=", "self", ".", "net", "(", "states", ",", "vecs", ")", "\n", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "actions", ")", "\n", "\n", "if", "write", ":", "\n", "            ", "if", "self", ".", "writer", "is", "not", "None", ":", "\n", "                ", "self", ".", "writer", ".", "add_scalar", "(", "'loss/cross_entropy'", ",", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "time_", ")", "\n", "\n", "", "", "self", ".", "net", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimiser", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.save": [[88, 97], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "agent.Agent.net.state_dict", "os.path.join", "agent.Agent.optimiser.state_dict", "os.path.join", "agent.Agent.net.state_dict", "os.path.join", "agent.Agent.optimiser.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save"], ["", "def", "save", "(", "self", ",", "path", ",", "id_", "=", "None", ")", ":", "\n", "        ", "if", "id_", "is", "None", ":", "\n", "            ", "torch", ".", "save", "(", "self", ".", "net", ".", "state_dict", "(", ")", ",", "p_join", "(", "path", ",", "'model.pth'", ")", ")", "\n", "state", "=", "{", "'optimizer'", ":", "self", ".", "optimiser", ".", "state_dict", "(", ")", "}", "\n", "torch", ".", "save", "(", "state", ",", "p_join", "(", "path", ",", "'state.pth'", ")", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "save", "(", "self", ".", "net", ".", "state_dict", "(", ")", ",", "p_join", "(", "path", ",", "f'model_{id_}.pth'", ")", ")", "\n", "state", "=", "{", "'optimizer'", ":", "self", ".", "optimiser", ".", "state_dict", "(", ")", "}", "\n", "torch", ".", "save", "(", "state", ",", "p_join", "(", "path", ",", "f'state_{id_}.pth'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.load": [[98, 107], ["agent.Agent.net.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "agent.Agent.optimiser.load_state_dict", "agent.Agent.net.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "agent.Agent.optimiser.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load"], ["", "", "def", "load", "(", "self", ",", "path", ",", "id_", "=", "None", ")", ":", "\n", "        ", "if", "id_", "is", "None", ":", "\n", "            ", "self", ".", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "p_join", "(", "path", ",", "'model.pth'", ")", ")", ")", "\n", "state", "=", "torch", ".", "load", "(", "p_join", "(", "path", ",", "'state.pth'", ")", ")", "\n", "self", ".", "optimiser", ".", "load_state_dict", "(", "state", "[", "'optimizer'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "p_join", "(", "path", ",", "f'model_{id_}.pth'", ")", ")", ")", "\n", "state", "=", "torch", ".", "load", "(", "p_join", "(", "path", ",", "f'state_{id_}.pth'", ")", ")", "\n", "self", ".", "optimiser", ".", "load_state_dict", "(", "state", "[", "'optimizer'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.train": [[108, 110], ["agent.Agent.net.train"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.train"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "net", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.eval": [[111, 113], ["agent.Agent.net.eval"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.agent.Agent.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "net", ".", "eval", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.__init__": [[12, 18], ["numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "index", "=", "0", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "full", "=", "False", "\n", "self", ".", "data", "=", "np", ".", "array", "(", "[", "None", "]", "*", "size", ")", "\n", "self", ".", "last_reward_index", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.current_size": [[19, 24], ["None"], "methods", ["None"], ["", "def", "current_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "full", ":", "\n", "            ", "return", "self", ".", "size", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append": [[25, 30], ["None"], "methods", ["None"], ["", "", "def", "append", "(", "self", ",", "data", ")", ":", "\n", "        ", "assert", "not", "self", ".", "full", "\n", "self", ".", "data", "[", "self", ".", "index", "]", "=", "data", "\n", "self", ".", "index", "+=", "1", "\n", "self", ".", "full", "=", "self", ".", "index", "==", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.get": [[31, 33], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "data_index", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "data_index", "%", "self", ".", "size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.update_last_reward_index": [[34, 37], ["None"], "methods", ["None"], ["", "def", "update_last_reward_index", "(", "self", ")", ":", "\n", "        ", "assert", "not", "self", ".", "full", "\n", "self", ".", "last_reward_index", "=", "self", ".", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.remove_new_data": [[38, 46], ["list", "len", "range"], "methods", ["None"], ["", "def", "remove_new_data", "(", "self", ")", ":", "\n", "        ", "assert", "not", "self", ".", "full", "\n", "removed_ids_list", "=", "list", "(", "range", "(", "self", ".", "last_reward_index", ",", "self", ".", "index", ")", ")", "\n", "removed_amount", "=", "len", "(", "removed_ids_list", ")", "\n", "\n", "self", ".", "index", "=", "self", ".", "last_reward_index", "\n", "\n", "return", "removed_amount", ",", "removed_ids_list", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.__init__": [[49, 72], ["dataset.Data", "Transition", "Transition", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "capacity", ",", "state_shape", ",", "state_vec_shape", ",", "state_manager", ",", "action_manager", ",", "\n", "scale_rewards", "=", "True", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "state_shape", "=", "state_shape", "\n", "\n", "if", "state_vec_shape", "is", "not", "None", ":", "\n", "            ", "self", ".", "blank_trans", "=", "Transition", "(", "torch", ".", "zeros", "(", "state_shape", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "\n", "torch", ".", "zeros", "(", "state_vec_shape", ")", ",", "None", ",", "0", ",", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "blank_trans", "=", "Transition", "(", "torch", ".", "zeros", "(", "state_shape", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "None", ",", "None", ",", "0", ",", "False", ")", "\n", "\n", "", "self", ".", "discount", "=", "1.", "\n", "self", ".", "n", "=", "1", "\n", "\n", "self", ".", "state_manager", "=", "state_manager", "\n", "self", ".", "action_manager", "=", "action_manager", "\n", "\n", "self", ".", "transitions", "=", "Data", "(", "capacity", ")", "\n", "\n", "self", ".", "scale_rewards", "=", "scale_rewards", "\n", "\n", "self", ".", "gatherlog_sample_id_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.reward_reshaping": [[73, 81], ["None"], "methods", ["None"], ["", "def", "reward_reshaping", "(", "self", ",", "r", ")", ":", "\n", "        ", "if", "self", ".", "scale_rewards", ":", "\n", "            ", "if", "r", "==", "0.", ":", "\n", "                ", "return", "0.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "\n", "", "", "else", ":", "\n", "            ", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.append_sample": [[82, 106], ["dataset.Dataset.state_manager.get_img_vec", "dataset.Dataset.action_manager.get_id", "torch.from_numpy().permute", "dataset.Dataset.transitions.append", "dataset.Dataset.gatherlog_sample_id_list.append", "random.choice", "dataset.Dataset.transitions.data[].vector.clone", "torch.tensor", "Transition", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.StateManager.get_img_vec", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_id", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append"], ["", "", "def", "append_sample", "(", "self", ",", "sample", ",", "gatherlog_sample", "=", "False", ",", "treechop_data", "=", "False", ")", ":", "\n", "\n", "# Saving ids of samples from the getlog part of data (all data until first reward > 1.)", "\n", "        ", "if", "gatherlog_sample", "and", "not", "treechop_data", ":", "\n", "            ", "self", ".", "gatherlog_sample_id_list", ".", "append", "(", "self", ".", "transitions", ".", "index", ")", "\n", "\n", "", "state", ",", "action", ",", "reward", ",", "done", "=", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "sample", "[", "2", "]", ",", "sample", "[", "4", "]", "\n", "\n", "img", ",", "vec", "=", "self", ".", "state_manager", ".", "get_img_vec", "(", "state", ")", "\n", "\n", "if", "treechop_data", ":", "\n", "# When dealing with treechop_data that has no inventory information, we insert a random inventory", "\n", "# from the other demonstrations:", "\n", "\n", "            ", "random_get_log_id", "=", "random", ".", "choice", "(", "self", ".", "gatherlog_sample_id_list", ")", "\n", "torch_vec", "=", "self", ".", "transitions", ".", "data", "[", "random_get_log_id", "]", ".", "vector", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "torch_vec", "=", "torch", ".", "tensor", "(", "vec", ")", "\n", "\n", "", "action_id", "=", "self", ".", "action_manager", ".", "get_id", "(", "action", ")", "\n", "\n", "torch_img", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "\n", "self", ".", "transitions", ".", "append", "(", "Transition", "(", "torch_img", ",", "torch_vec", ",", "action_id", ",", "reward", ",", "not", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.update_last_reward_index": [[107, 109], ["dataset.Dataset.transitions.update_last_reward_index"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.update_last_reward_index"], ["", "def", "update_last_reward_index", "(", "self", ")", ":", "\n", "        ", "self", ".", "transitions", ".", "update_last_reward_index", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.remove_new_data": [[110, 118], ["dataset.Dataset.transitions.remove_new_data", "dataset.Dataset.gatherlog_sample_id_list.remove"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.remove_new_data"], ["", "def", "remove_new_data", "(", "self", ")", ":", "\n", "        ", "removed_amount", ",", "removed_ids_list", "=", "self", ".", "transitions", ".", "remove_new_data", "(", ")", "\n", "\n", "for", "id_", "in", "removed_ids_list", ":", "\n", "            ", "if", "id_", "in", "self", ".", "gatherlog_sample_id_list", ":", "\n", "                ", "self", ".", "gatherlog_sample_id_list", ".", "remove", "(", "id_", ")", "\n", "\n", "", "", "return", "removed_amount", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.save": [[119, 122], ["pickle.dump", "open"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "pickle", ".", "dump", "(", "[", "self", ".", "transitions", ".", "index", ",", "self", ".", "transitions", ".", "size", ",", "self", ".", "transitions", ".", "full", ",", "self", ".", "transitions", ".", "data", ",", "\n", "self", ".", "transitions", ".", "last_reward_index", "]", ",", "open", "(", "path", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load": [[123, 126], ["pickle.load", "open"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.load"], ["", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "transitions", ".", "index", ",", "self", ".", "transitions", ".", "size", ",", "self", ".", "transitions", ".", "full", ",", "self", ".", "transitions", ".", "data", ",", "self", ".", "transitions", ".", "last_reward_index", "=", "pickle", ".", "load", "(", "open", "(", "path", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset._get_transition": [[127, 136], ["numpy.array", "dataset.Dataset.transitions.get", "range", "dataset.Dataset.transitions.get"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.get", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.get"], ["", "def", "_get_transition", "(", "self", ",", "idx", ")", ":", "\n", "        ", "transition", "=", "np", ".", "array", "(", "[", "None", "]", "*", "(", "self", ".", "n", "+", "1", ")", ")", "\n", "transition", "[", "0", "]", "=", "self", ".", "transitions", ".", "get", "(", "idx", ")", "\n", "for", "t", "in", "range", "(", "1", ",", "1", "+", "self", ".", "n", ")", ":", "\n", "            ", "if", "transition", "[", "t", "-", "1", "]", ".", "nonterminal", ":", "\n", "                ", "transition", "[", "t", "]", "=", "self", ".", "transitions", ".", "get", "(", "idx", "+", "t", ")", "\n", "", "else", ":", "\n", "                ", "transition", "[", "t", "]", "=", "self", ".", "blank_trans", "\n", "", "", "return", "transition", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.sample_line": [[137, 178], ["numpy.random.randint", "list", "dataset.Dataset._get_transition", "states.append", "next_states.append", "actions.append", "returns.append", "nonterminals.append", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.stack", "range", "transition[].state.to().to().div_", "transition[].state.to().to().div_", "vecs.append", "next_vecs.append", "vecs.append", "next_vecs.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "dataset.Dataset.transitions.current_size", "transition[].vector.to().to", "transition[].vector.to().to", "transition[].state.to().to", "transition[].state.to().to", "sum", "transition[].vector.to", "transition[].vector.to", "transition[].state.to", "transition[].state.to", "dataset.Dataset.reward_reshaping", "range"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset._get_transition", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.current_size", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.reward_reshaping"], ["", "def", "sample_line", "(", "self", ",", "size", ",", "length", ")", ":", "\n", "        ", "ids", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "transitions", ".", "current_size", "(", ")", "-", "length", "-", "self", ".", "n", ",", "size", "=", "size", ")", "\n", "\n", "ids", "=", "[", "list", "(", "range", "(", "i", ",", "i", "+", "length", ")", ")", "for", "i", "in", "ids", "]", "\n", "ids", "=", "[", "item", "for", "sublist", "in", "ids", "for", "item", "in", "sublist", "]", "\n", "\n", "states", ",", "vecs", ",", "next_states", ",", "next_vecs", ",", "actions", ",", "returns", ",", "nonterminals", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "no_vecs", "=", "False", "\n", "for", "id_", "in", "ids", ":", "\n", "            ", "transition", "=", "self", ".", "_get_transition", "(", "id_", ")", "\n", "\n", "states", ".", "append", "(", "transition", "[", "0", "]", ".", "state", ".", "to", "(", "device", "=", "self", ".", "device", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ".", "div_", "(", "255", ")", ")", "\n", "next_states", ".", "append", "(", "transition", "[", "self", ".", "n", "]", ".", "state", ".", "to", "(", "device", "=", "self", ".", "device", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ".", "div_", "(", "255", ")", ")", "\n", "\n", "if", "transition", "[", "0", "]", ".", "vector", "is", "not", "None", ":", "\n", "                ", "vecs", ".", "append", "(", "transition", "[", "0", "]", ".", "vector", ".", "to", "(", "device", "=", "self", ".", "device", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ")", "\n", "next_vecs", ".", "append", "(", "transition", "[", "self", ".", "n", "]", ".", "vector", ".", "to", "(", "device", "=", "self", ".", "device", ")", ".", "to", "(", "dtype", "=", "torch", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "                ", "vecs", ".", "append", "(", "None", ")", "\n", "next_vecs", ".", "append", "(", "None", ")", "\n", "no_vecs", "=", "True", "\n", "\n", "", "actions", ".", "append", "(", "torch", ".", "tensor", "(", "[", "transition", "[", "0", "]", ".", "action", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "returns", ".", "append", "(", "\n", "torch", ".", "tensor", "(", "[", "sum", "(", "self", ".", "discount", "**", "n", "*", "\n", "self", ".", "reward_reshaping", "(", "transition", "[", "n", "]", ".", "reward", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n", ")", ")", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "nonterminals", ".", "append", "(", "\n", "torch", ".", "tensor", "(", "[", "transition", "[", "self", ".", "n", "]", ".", "nonterminal", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "\n", "", "states", ",", "next_states", "=", "torch", ".", "stack", "(", "states", ")", ",", "torch", ".", "stack", "(", "next_states", ")", "\n", "actions", ",", "returns", ",", "nonterminals", "=", "torch", ".", "cat", "(", "actions", ")", ",", "torch", ".", "cat", "(", "returns", ")", ",", "torch", ".", "stack", "(", "nonterminals", ")", "\n", "\n", "if", "not", "no_vecs", ":", "\n", "            ", "vecs", ",", "next_vecs", "=", "torch", ".", "stack", "(", "vecs", ")", ",", "torch", ".", "stack", "(", "next_vecs", ")", "\n", "\n", "", "return", "states", ",", "vecs", ",", "actions", ",", "returns", ",", "next_states", ",", "next_vecs", ",", "nonterminals", "\n", "", "", ""]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.Network.__init__": [[10, 36], ["torch.nn.Module.__init__", "cnn_module", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_actions", ",", "image_channels", ",", "vec_size", ",", "cnn_module", ",", "hidden_size", "=", "256", ",", "\n", "dueling", "=", "True", ",", "double_channels", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_actions", "=", "num_actions", "\n", "self", ".", "dueling", "=", "dueling", "\n", "\n", "self", ".", "cnn", "=", "cnn_module", "(", "image_channels", ")", "\n", "\n", "self", ".", "conv_output_size", "=", "self", ".", "cnn", ".", "output_size", "\n", "self", ".", "fc_im", "=", "nn", ".", "Linear", "(", "self", ".", "conv_output_size", ",", "hidden_size", ")", "\n", "\n", "if", "not", "double_channels", ":", "\n", "            ", "vec_channel_size", "=", "128", "\n", "", "else", ":", "\n", "            ", "vec_channel_size", "=", "256", "\n", "\n", "", "self", ".", "fc_vec", "=", "nn", ".", "Linear", "(", "vec_size", ",", "vec_channel_size", ")", "\n", "\n", "self", ".", "fc_h_a", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "vec_channel_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "fc_a", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_actions", ")", "\n", "\n", "if", "self", ".", "dueling", ":", "\n", "            ", "self", ".", "fc_h_v", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "vec_channel_size", ",", "hidden_size", ")", "\n", "self", ".", "fc_v", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.Network.forward": [[37, 52], ["model.Network.cnn", "torch.nn.functional.relu.view", "model.Network.fc_im", "model.Network.fc_vec", "torch.nn.functional.relu", "model.Network.fc_a", "torch.cat", "torch.nn.functional.relu", "model.Network.fc_v", "model.Network.fc_h_a", "torch.nn.functional.relu", "model.Network.mean", "model.Network.fc_h_v"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "vec", ")", ":", "\n", "        ", "x", "=", "self", ".", "cnn", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "conv_output_size", ")", "\n", "x", "=", "self", ".", "fc_im", "(", "x", ")", "\n", "vec", "=", "self", ".", "fc_vec", "(", "vec", ")", "\n", "\n", "x", "=", "F", ".", "relu", "(", "torch", ".", "cat", "(", "(", "x", ",", "vec", ")", ",", "1", ")", ")", "\n", "\n", "output", "=", "self", ".", "fc_a", "(", "F", ".", "relu", "(", "self", ".", "fc_h_a", "(", "x", ")", ")", ")", "\n", "\n", "if", "self", ".", "dueling", ":", "\n", "            ", "v", "=", "self", ".", "fc_v", "(", "F", ".", "relu", "(", "self", ".", "fc_h_v", "(", "x", ")", ")", ")", "\n", "output", "=", "v", "+", "output", "-", "output", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.AtariCNN.__init__": [[55, 65], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "input_channels", ",", "32", ",", "8", ",", "stride", "=", "4", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "self", ".", "output_size", "=", "64", "*", "4", "*", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.AtariCNN.forward": [[66, 68], ["model.AtariCNN.conv_layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv_layers", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.ImpalaResNetCNN.__init__": [[85, 99], ["torch.nn.Module.__init__", "torch.nn.Sequential", "layers.extend", "torch.nn.ReLU", "math.ceil", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "model.ImpalaResNetCNN._ImpalaResidual", "model.ImpalaResNetCNN._ImpalaResidual"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.__init__"], ["", "", "def", "__init__", "(", "self", ",", "input_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "depth_in", "=", "input_channels", "\n", "layers", "=", "[", "]", "\n", "for", "depth_out", "in", "[", "32", ",", "64", ",", "64", "]", ":", "\n", "            ", "layers", ".", "extend", "(", "[", "\n", "nn", ".", "Conv2d", "(", "depth_in", ",", "depth_out", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "self", ".", "_ImpalaResidual", "(", "depth_out", ")", ",", "\n", "self", ".", "_ImpalaResidual", "(", "depth_out", ")", ",", "\n", "]", ")", "\n", "depth_in", "=", "depth_out", "\n", "", "self", ".", "conv_layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "output_size", "=", "math", ".", "ceil", "(", "64", "/", "8", ")", "**", "2", "*", "depth_in", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.ImpalaResNetCNN.forward": [[100, 102], ["model.ImpalaResNetCNN.conv_layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv_layers", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.__init__": [[134, 157], ["torch.nn.Module.__init__", "layers.extend", "torch.nn.Sequential", "layers.extend", "torch.nn.ReLU", "model.FixupResNetCNN._FixupResidual", "model.FixupResNetCNN._FixupResidual", "math.ceil", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "model.FixupResNetCNN._FixupResidual", "model.FixupResNetCNN._FixupResidual"], "methods", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.__init__"], ["", "", "def", "__init__", "(", "self", ",", "input_channels", ",", "double_channels", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "depth_in", "=", "input_channels", "\n", "\n", "layers", "=", "[", "]", "\n", "if", "not", "double_channels", ":", "\n", "            ", "channel_sizes", "=", "[", "32", ",", "64", ",", "64", "]", "\n", "", "else", ":", "\n", "            ", "channel_sizes", "=", "[", "64", ",", "128", ",", "128", "]", "\n", "", "for", "depth_out", "in", "channel_sizes", ":", "\n", "            ", "layers", ".", "extend", "(", "[", "\n", "nn", ".", "Conv2d", "(", "depth_in", ",", "depth_out", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "self", ".", "_FixupResidual", "(", "depth_out", ",", "8", ")", ",", "\n", "self", ".", "_FixupResidual", "(", "depth_out", ",", "8", ")", ",", "\n", "]", ")", "\n", "depth_in", "=", "depth_out", "\n", "", "layers", ".", "extend", "(", "[", "\n", "self", ".", "_FixupResidual", "(", "depth_in", ",", "8", ")", ",", "\n", "self", ".", "_FixupResidual", "(", "depth_in", ",", "8", ")", ",", "\n", "]", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "output_size", "=", "math", ".", "ceil", "(", "64", "/", "8", ")", "**", "2", "*", "depth_in", "\n", "\n"]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.model.FixupResNetCNN.forward": [[158, 160], ["model.FixupResNetCNN.conv_layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "conv_layers", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.get_dataset.put_data_into_dataset": [[10, 172], ["print", "minerl.data.make", "minerl.data.make.get_trajectory_names", "collections.deque", "dataset.transitions.current_size", "enumerate", "action_manager.get_id", "enumerate", "collections.deque.clear", "print", "type", "action_manager.zero_action.items", "collections.OrderedDict", "collections.OrderedDict", "minerl.data.make.load_data", "collections.deque.append", "len", "range", "dataset.remove_new_data", "copy.deepcopy", "dataset.Transition", "dataset.append_sample", "dataset.update_last_reward_index", "dataset.append_sample", "print", "len", "range", "get_dataset.put_data_into_dataset.process_sample"], "function", ["home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.current_size", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.data_manager.ActionManager.get_id", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Data.append", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.remove_new_data", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.append_sample", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.update_last_reward_index", "home.repos.pwc.inspect_result.amiranas_minerl_imitation_learning.None.dataset.Dataset.append_sample"], ["def", "put_data_into_dataset", "(", "env_name", ",", "action_manager", ",", "dataset", ",", "minecraft_human_data_dir", ",", "\n", "continuous_action_stacking_amount", "=", "3", ",", "\n", "only_successful", "=", "True", ",", "max_duration_steps", "=", "None", ",", "max_reward", "=", "256.", ",", "\n", "test", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param env_name: Minecraft env name\n    :param action_manager: expects object of data_manager.ActionManager\n    :param dataset: expects object of dataset.Dataset\n    :param minecraft_human_data_dir: location of Minecraft human data\n    :param continuous_action_stacking_amount: number of consecutive states that are used to get the continuous action\n    (since humans move the camera slowly we add up the continuous actions of multiple consecutive states)\n    :param only_successful: skip trajectories that don't reach final reward when true\n    :param max_duration_steps: skip trajectories that take longer than max_duration_steps to reach the final reward\n    :param max_reward: remove trajectory part beyond the max_reward. Used to remove the \"obtain diamond\" part, since\n    the imitation policy never obtains diamonds anyway\n    :param test: if true a mini dataset is created for debugging\n\n    further all samples without rewards, and without terminal states, and with no_op action are removed\n    \"\"\"", "\n", "\n", "print", "(", "f\"\\n Adding data from {env_name} \\n\"", ")", "\n", "\n", "treechop_data", "=", "env_name", "==", "\"MineRLTreechop-v0\"", "\n", "\n", "def", "is_success", "(", "sample", ")", ":", "\n", "        ", "if", "max_duration_steps", "is", "None", ":", "\n", "            ", "return", "sample", "[", "-", "1", "]", "[", "'success'", "]", "\n", "", "else", ":", "\n", "            ", "return", "sample", "[", "-", "1", "]", "[", "'success'", "]", "and", "sample", "[", "-", "1", "]", "[", "'duration_steps'", "]", "<", "max_duration_steps", "\n", "\n", "", "", "def", "is_no_op", "(", "sample", ")", ":", "\n", "        ", "action", "=", "sample", "[", "1", "]", "\n", "a_id", "=", "action_manager", ".", "get_id", "(", "action", ")", "\n", "assert", "type", "(", "a_id", ")", "==", "int", "\n", "return", "a_id", "==", "0", "# no_op action has id of 0", "\n", "\n", "", "def", "process_sample", "(", "sample", ",", "last_reward", ")", ":", "\n", "        ", "\"\"\"adding single sample to dataset if all conditions are met, expects sample with already stacked\n        camera action\"\"\"", "\n", "\n", "reward", "=", "sample", "[", "2", "]", "\n", "\n", "if", "reward", ">", "last_reward", ":", "\n", "            ", "last_reward", "=", "reward", "\n", "\n", "", "gatherlog_sample", "=", "last_reward", "<", "2.", "\n", "\n", "if", "treechop_data", ":", "\n", "# fill missing action and state parts with zeros:", "\n", "            ", "for", "key", ",", "value", "in", "action_manager", ".", "zero_action", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "sample", "[", "1", "]", ":", "\n", "                    ", "sample", "[", "1", "]", "[", "key", "]", "=", "value", "\n", "\n", "", "", "sample", "[", "0", "]", "[", "'equipped_items'", "]", "=", "OrderedDict", "(", "[", "(", "\n", "'mainhand'", ",", "\n", "OrderedDict", "(", "[", "(", "'damage'", ",", "0", ")", ",", "(", "'maxDamage'", ",", "0", ")", ",", "(", "'type'", ",", "0", ")", "]", ")", "\n", ")", "]", ")", "\n", "\n", "sample", "[", "0", "]", "[", "\"inventory\"", "]", "=", "OrderedDict", "(", "[", "\n", "(", "'coal'", ",", "0", ")", ",", "\n", "(", "'cobblestone'", ",", "0", ")", ",", "\n", "(", "'crafting_table'", ",", "0", ")", ",", "\n", "(", "'dirt'", ",", "0", ")", ",", "\n", "(", "'furnace'", ",", "0", ")", ",", "\n", "(", "'iron_axe'", ",", "0", ")", ",", "\n", "(", "'iron_ingot'", ",", "0", ")", ",", "\n", "(", "'iron_ore'", ",", "0", ")", ",", "\n", "(", "'iron_pickaxe'", ",", "0", ")", ",", "\n", "(", "'log'", ",", "0", ")", ",", "\n", "(", "'planks'", ",", "0", ")", ",", "\n", "(", "'stick'", ",", "0", ")", ",", "\n", "(", "'stone'", ",", "0", ")", ",", "\n", "(", "'stone_axe'", ",", "0", ")", ",", "\n", "(", "'stone_pickaxe'", ",", "0", ")", ",", "\n", "(", "'torch'", ",", "0", ")", ",", "\n", "(", "'wooden_axe'", ",", "0", ")", ",", "\n", "(", "'wooden_pickaxe'", ",", "0", ")", "\n", "]", ")", "\n", "\n", "", "if", "reward", "!=", "0.", ":", "\n", "            ", "if", "reward", ">", "max_reward", ":", "\n", "# if a larger reward is encountered, the transition is deleted until previous reward:", "\n", "                ", "counter_change", "=", "-", "dataset", ".", "remove_new_data", "(", ")", "\n", "", "else", ":", "\n", "                ", "dataset", ".", "append_sample", "(", "sample", ",", "gatherlog_sample", ",", "treechop_data", ")", "\n", "dataset", ".", "update_last_reward_index", "(", ")", "\n", "counter_change", "=", "1", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "is_no_op", "(", "sample", ")", "or", "sample", "[", "4", "]", ":", "# remove no_op transitions, unless it is a terminal state", "\n", "                ", "dataset", ".", "append_sample", "(", "sample", ",", "gatherlog_sample", ",", "treechop_data", ")", "\n", "counter_change", "=", "1", "\n", "", "else", ":", "\n", "                ", "counter_change", "=", "0", "\n", "\n", "", "", "return", "counter_change", ",", "last_reward", "\n", "\n", "", "data", "=", "minerl", ".", "data", ".", "make", "(", "env_name", ",", "data_dir", "=", "minecraft_human_data_dir", ")", "\n", "trajs", "=", "data", ".", "get_trajectory_names", "(", ")", "\n", "\n", "# the ring buffer is used to stack the camera action of multiple consecutive states:", "\n", "sample_que", "=", "deque", "(", "maxlen", "=", "continuous_action_stacking_amount", ")", "\n", "\n", "total_trajs_counter", "=", "0", "\n", "added_sample_counter", "=", "0", "\n", "\n", "initial_sample_amount", "=", "dataset", ".", "transitions", ".", "current_size", "(", ")", "\n", "\n", "for", "n", ",", "traj", "in", "enumerate", "(", "trajs", ")", ":", "\n", "        ", "for", "j", ",", "sample", "in", "enumerate", "(", "data", ".", "load_data", "(", "traj", ",", "include_metadata", "=", "True", ")", ")", ":", "\n", "\n", "# checking if the trajectory will be used first:", "\n", "            ", "if", "j", "==", "0", ":", "\n", "                ", "print", "(", "sample", "[", "-", "1", "]", ")", "\n", "\n", "if", "only_successful", ":", "\n", "                    ", "if", "not", "is_success", "(", "sample", ")", ":", "\n", "                        ", "print", "(", "\"skipping trajectory\"", ")", "\n", "break", "\n", "\n", "", "", "total_trajs_counter", "+=", "1", "\n", "last_reward", "=", "0.", "\n", "\n", "", "sample_que", ".", "append", "(", "sample", ")", "\n", "\n", "# Only continue when we have enough states to stack the camera actions:", "\n", "if", "len", "(", "sample_que", ")", "==", "continuous_action_stacking_amount", ":", "\n", "\n", "# Stacking camera action for the oldest sample in the queue:", "\n", "                ", "for", "i", "in", "range", "(", "1", ",", "continuous_action_stacking_amount", ")", ":", "\n", "                    ", "sample_que", "[", "0", "]", "[", "1", "]", "[", "'camera'", "]", "+=", "sample_que", "[", "i", "]", "[", "1", "]", "[", "'camera'", "]", "\n", "\n", "if", "sample_que", "[", "i", "]", "[", "2", "]", "!=", "0.", ":", "# (if reward != 0)", "\n", "                        ", "break", "# no camera action stacking after a reward", "\n", "\n", "", "", "added_samples", ",", "last_reward", "=", "process_sample", "(", "sample_que", "[", "0", "]", ",", "last_reward", ")", "\n", "\n", "added_sample_counter", "+=", "added_samples", "\n", "\n", "", "", "if", "len", "(", "sample_que", ")", ">", "0", ":", "# otherwise not successful traj", "\n", "# for the last samples in the queue we don't stack the the camera actions", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "continuous_action_stacking_amount", ")", ":", "\n", "                ", "added_samples", ",", "last_reward", "=", "process_sample", "(", "sample_que", "[", "i", "]", ",", "last_reward", ")", "\n", "added_sample_counter", "+=", "added_samples", "\n", "\n", "# a terminal state could be reached without exceeding max_reward:", "\n", "", "added_sample_counter", "-=", "dataset", ".", "remove_new_data", "(", ")", "\n", "\n", "# making sure the last state from trajectory is terminal:", "\n", "last_transition", "=", "deepcopy", "(", "dataset", ".", "transitions", ".", "data", "[", "dataset", ".", "transitions", ".", "index", "-", "1", "]", ")", "\n", "dataset", ".", "transitions", ".", "data", "[", "dataset", ".", "transitions", ".", "index", "-", "1", "]", "=", "Transition", "(", "last_transition", ".", "state", ",", "last_transition", ".", "vector", ",", "\n", "last_transition", ".", "action", ",", "last_transition", ".", "reward", ",", "False", ")", "\n", "\n", "", "sample_que", ".", "clear", "(", ")", "\n", "\n", "print", "(", "f\"{n+1} / {len(trajs)}, added: {total_trajs_counter}\"", ")", "\n", "assert", "dataset", ".", "transitions", ".", "current_size", "(", ")", "-", "initial_sample_amount", "==", "added_sample_counter", "\n", "\n", "if", "test", ":", "\n", "            ", "if", "total_trajs_counter", ">=", "2", ":", "\n", "                ", "assert", "total_trajs_counter", "==", "2", "\n", "break", "\n", "", "", "", "", ""]]}