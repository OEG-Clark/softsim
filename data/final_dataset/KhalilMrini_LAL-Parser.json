{"home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BatchIndices.__init__": [[84, 95], ["from_numpy", "int", "numpy.concatenate", "int", "numpy.nonzero", "len", "numpy.max", "numpy.max"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_idxs_np", ")", ":", "\n", "        ", "self", ".", "batch_idxs_np", "=", "batch_idxs_np", "\n", "self", ".", "batch_idxs_torch", "=", "from_numpy", "(", "batch_idxs_np", ")", "\n", "\n", "self", ".", "batch_size", "=", "int", "(", "1", "+", "np", ".", "max", "(", "batch_idxs_np", ")", ")", "\n", "\n", "batch_idxs_np_extra", "=", "np", ".", "concatenate", "(", "[", "[", "-", "1", "]", ",", "batch_idxs_np", ",", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "boundaries_np", "=", "np", ".", "nonzero", "(", "batch_idxs_np_extra", "[", "1", ":", "]", "!=", "batch_idxs_np_extra", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "self", ".", "seq_lens_np", "=", "self", ".", "boundaries_np", "[", "1", ":", "]", "-", "self", ".", "boundaries_np", "[", ":", "-", "1", "]", "\n", "assert", "len", "(", "self", ".", "seq_lens_np", ")", "==", "self", ".", "batch_size", "\n", "self", ".", "max_len", "=", "int", "(", "np", ".", "max", "(", "self", ".", "boundaries_np", "[", "1", ":", "]", "-", "self", ".", "boundaries_np", "[", ":", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.FeatureDropoutFunction.forward": [[98, 124], ["ValueError", "ctx.mark_dirty", "input.clone", "input.new().resize_", "input.clone.mul_", "input.size", "ctx.noise.fill_", "ctx.noise.bernoulli_().div_", "input.new", "ctx.noise.bernoulli_"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["    ", "@", "classmethod", "\n", "def", "forward", "(", "cls", ",", "ctx", ",", "input", ",", "batch_idxs", ",", "p", "=", "0.5", ",", "train", "=", "False", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "if", "p", "<", "0", "or", "p", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p", ")", ")", "\n", "\n", "", "ctx", ".", "p", "=", "p", "\n", "ctx", ".", "train", "=", "train", "\n", "ctx", ".", "inplace", "=", "inplace", "\n", "\n", "if", "ctx", ".", "inplace", ":", "\n", "            ", "ctx", ".", "mark_dirty", "(", "input", ")", "\n", "output", "=", "input", "\n", "", "else", ":", "\n", "            ", "output", "=", "input", ".", "clone", "(", ")", "\n", "\n", "", "if", "ctx", ".", "p", ">", "0", "and", "ctx", ".", "train", ":", "\n", "            ", "ctx", ".", "noise", "=", "input", ".", "new", "(", ")", ".", "resize_", "(", "batch_idxs", ".", "batch_size", ",", "input", ".", "size", "(", "1", ")", ")", "\n", "if", "ctx", ".", "p", "==", "1", ":", "\n", "                ", "ctx", ".", "noise", ".", "fill_", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "ctx", ".", "noise", ".", "bernoulli_", "(", "1", "-", "ctx", ".", "p", ")", ".", "div_", "(", "1", "-", "ctx", ".", "p", ")", "\n", "", "ctx", ".", "noise", "=", "ctx", ".", "noise", "[", "batch_idxs", ".", "batch_idxs_torch", ",", ":", "]", "\n", "output", ".", "mul_", "(", "ctx", ".", "noise", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.FeatureDropoutFunction.backward": [[125, 131], ["grad_output.mul"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "if", "ctx", ".", "p", ">", "0", "and", "ctx", ".", "train", ":", "\n", "            ", "return", "grad_output", ".", "mul", "(", "ctx", ".", "noise", ")", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "", "else", ":", "\n", "            ", "return", "grad_output", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.FeatureDropout.__init__": [[139, 146], ["torch.Module.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "p", "=", "0.5", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "p", "<", "0", "or", "p", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"dropout probability has to be between 0 and 1, \"", "\n", "\"but got {}\"", ".", "format", "(", "p", ")", ")", "\n", "", "self", ".", "p", "=", "p", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.FeatureDropout.forward": [[147, 149], ["FeatureDropoutFunction.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "batch_idxs", ")", ":", "\n", "        ", "return", "FeatureDropoutFunction", ".", "apply", "(", "input", ",", "batch_idxs", ",", "self", ".", "p", ",", "self", ".", "training", ",", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LayerNormalization.__init__": [[152, 160], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "eps", "=", "1e-3", ",", "affine", "=", "True", ")", ":", "\n", "        ", "super", "(", "LayerNormalization", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "affine", "=", "affine", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "d_hid", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "d_hid", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LayerNormalization.forward": [[161, 172], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "z.size", "torch.mean.expand_as", "torch.mean.expand_as", "torch.mean.expand_as", "torch.std.expand_as", "torch.std.expand_as", "torch.std.expand_as", "KM_parser.LayerNormalization.b_2.expand_as", "KM_parser.LayerNormalization.a_2.expand_as"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "if", "z", ".", "size", "(", "-", "1", ")", "==", "1", ":", "\n", "            ", "return", "z", "\n", "\n", "", "mu", "=", "torch", ".", "mean", "(", "z", ",", "keepdim", "=", "True", ",", "dim", "=", "-", "1", ")", "\n", "sigma", "=", "torch", ".", "std", "(", "z", ",", "keepdim", "=", "True", ",", "dim", "=", "-", "1", ")", "\n", "ln_out", "=", "(", "z", "-", "mu", ".", "expand_as", "(", "z", ")", ")", "/", "(", "sigma", ".", "expand_as", "(", "z", ")", "+", "self", ".", "eps", ")", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "ln_out", "=", "ln_out", "*", "self", ".", "a_2", ".", "expand_as", "(", "ln_out", ")", "+", "self", ".", "b_2", ".", "expand_as", "(", "ln_out", ")", "\n", "\n", "", "return", "ln_out", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ScaledAttention.__init__": [[175, 181], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "attention_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "ScaledAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "temper", "=", "hparams", ".", "d_model", "**", "0.5", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attention_dropout", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ScaledAttention.forward": [[182, 203], ["KM_parser.ScaledAttention.softmax().transpose", "KM_parser.ScaledAttention.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "KM_parser.ScaledAttention.data.masked_fill_", "k.transpose", "attn_mask.size", "KM_parser.ScaledAttention.size", "attn_mask.size", "KM_parser.ScaledAttention.size", "KM_parser.ScaledAttention.softmax", "float", "KM_parser.ScaledAttention.transpose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attn_mask", "=", "None", ")", ":", "\n", "# q: [batch, slot, feat]", "\n", "# k: [batch, slot, feat]", "\n", "# v: [batch, slot, feat]", "\n", "\n", "        ", "attn", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "/", "self", ".", "temper", "\n", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "assert", "attn_mask", ".", "size", "(", ")", "==", "attn", ".", "size", "(", ")", ",", "'Attention mask shape {} mismatch '", "'with Attention logit tensor shape '", "'{}.'", ".", "format", "(", "attn_mask", ".", "size", "(", ")", ",", "attn", ".", "size", "(", ")", ")", "\n", "\n", "attn", ".", "data", ".", "masked_fill_", "(", "attn_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "attn", "=", "self", ".", "softmax", "(", "attn", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ScaledDotProductAttention.__init__": [[207, 212], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "attention_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "ScaledDotProductAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temper", "=", "d_model", "**", "0.5", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attention_dropout", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ScaledDotProductAttention.forward": [[213, 242], ["KM_parser.ScaledDotProductAttention.softmax", "KM_parser.ScaledDotProductAttention.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "KM_parser.ScaledDotProductAttention.data.masked_fill_", "k.transpose", "attn_mask.size", "KM_parser.ScaledDotProductAttention.size", "attn_mask.size", "KM_parser.ScaledDotProductAttention.size", "float"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attn_mask", "=", "None", ")", ":", "\n", "# q: [batch, slot, feat] or (batch * d_l) x max_len x d_k", "\n", "# k: [batch, slot, feat] or (batch * d_l) x max_len x d_k", "\n", "# v: [batch, slot, feat] or (batch * d_l) x max_len x d_v", "\n", "# q in LAL is (batch * d_l) x 1 x d_k", "\n", "\n", "        ", "attn", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "/", "self", ".", "temper", "# (batch * d_l) x max_len x max_len", "\n", "# in LAL, gives: (batch * d_l) x 1 x max_len", "\n", "# attention weights from each word to each word, for each label", "\n", "# in best model (repeated q): attention weights from label (as vector weights) to each word", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "assert", "attn_mask", ".", "size", "(", ")", "==", "attn", ".", "size", "(", ")", ",", "'Attention mask shape {} mismatch '", "'with Attention logit tensor shape '", "'{}.'", ".", "format", "(", "attn_mask", ".", "size", "(", ")", ",", "attn", ".", "size", "(", ")", ")", "\n", "\n", "attn", ".", "data", ".", "masked_fill_", "(", "attn_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "# Note that this makes the distribution not sum to 1. At some point it", "\n", "# may be worth researching whether this is the right way to apply", "\n", "# dropout to the attention.", "\n", "# Note that the t2t code also applies dropout in this manner", "\n", "attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "attn", ",", "v", ")", "# (batch * d_l) x max_len x d_v", "\n", "# in LAL, gives: (batch * d_l) x 1 x d_v", "\n", "\n", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiHeadAttention.__init__": [[249, 302], ["torch.Module.__init__", "KM_parser.ScaledDotProductAttention", "KM_parser.LayerNormalization", "KM_parser.FeatureDropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "residual_dropout", "=", "0.1", ",", "attention_dropout", "=", "0.1", ",", "d_positional", "=", "None", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "if", "d_positional", "is", "None", ":", "\n", "            ", "self", ".", "partitioned", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "partitioned", "=", "True", "\n", "\n", "", "if", "self", ".", "partitioned", ":", "\n", "            ", "self", ".", "d_content", "=", "d_model", "-", "d_positional", "\n", "self", ".", "d_positional", "=", "d_positional", "\n", "\n", "self", ".", "w_qs1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "self", ".", "d_content", ",", "d_k", "//", "2", ")", ")", "\n", "self", ".", "w_ks1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "self", ".", "d_content", ",", "d_k", "//", "2", ")", ")", "\n", "self", ".", "w_vs1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "self", ".", "d_content", ",", "d_v", "//", "2", ")", ")", "\n", "\n", "self", ".", "w_qs2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "self", ".", "d_positional", ",", "d_k", "//", "2", ")", ")", "\n", "self", ".", "w_ks2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "self", ".", "d_positional", ",", "d_k", "//", "2", ")", ")", "\n", "self", ".", "w_vs2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "self", ".", "d_positional", ",", "d_v", "//", "2", ")", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs1", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks1", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_vs1", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs2", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks2", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_vs2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "w_qs", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "d_model", ",", "d_k", ")", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "d_model", ",", "d_k", ")", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "n_head", ",", "d_model", ",", "d_v", ")", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_vs", ")", "\n", "\n", "", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "d_model", ",", "attention_dropout", "=", "attention_dropout", ")", "\n", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "d_model", ")", "\n", "\n", "if", "not", "self", ".", "partitioned", ":", "\n", "# The lack of a bias term here is consistent with the t2t code, though", "\n", "# in my experiments I have never observed this making a difference.", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj1", "=", "nn", ".", "Linear", "(", "n_head", "*", "(", "d_v", "//", "2", ")", ",", "self", ".", "d_content", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj2", "=", "nn", ".", "Linear", "(", "n_head", "*", "(", "d_v", "//", "2", ")", ",", "self", ".", "d_positional", ",", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "residual_dropout", "=", "FeatureDropout", "(", "residual_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiHeadAttention.split_qkv_packed": [[303, 328], ["inp.repeat().view", "inp.size", "qk_inp.repeat().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inp.repeat", "qk_inp.size", "qk_inp.repeat", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "split_qkv_packed", "(", "self", ",", "inp", ",", "qk_inp", "=", "None", ")", ":", "\n", "        ", "v_inp_repeated", "=", "inp", ".", "repeat", "(", "self", ".", "n_head", ",", "1", ")", ".", "view", "(", "self", ".", "n_head", ",", "-", "1", ",", "inp", ".", "size", "(", "-", "1", ")", ")", "# n_head x len_inp x d_model", "\n", "if", "qk_inp", "is", "None", ":", "\n", "            ", "qk_inp_repeated", "=", "v_inp_repeated", "\n", "", "else", ":", "\n", "            ", "qk_inp_repeated", "=", "qk_inp", ".", "repeat", "(", "self", ".", "n_head", ",", "1", ")", ".", "view", "(", "self", ".", "n_head", ",", "-", "1", ",", "qk_inp", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "partitioned", ":", "\n", "            ", "q_s", "=", "torch", ".", "bmm", "(", "qk_inp_repeated", ",", "self", ".", "w_qs", ")", "# n_head x len_inp x d_k", "\n", "k_s", "=", "torch", ".", "bmm", "(", "qk_inp_repeated", ",", "self", ".", "w_ks", ")", "# n_head x len_inp x d_k", "\n", "v_s", "=", "torch", ".", "bmm", "(", "v_inp_repeated", ",", "self", ".", "w_vs", ")", "# n_head x len_inp x d_v", "\n", "", "else", ":", "\n", "            ", "q_s", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "bmm", "(", "qk_inp_repeated", "[", ":", ",", ":", ",", ":", "self", ".", "d_content", "]", ",", "self", ".", "w_qs1", ")", ",", "\n", "torch", ".", "bmm", "(", "qk_inp_repeated", "[", ":", ",", ":", ",", "self", ".", "d_content", ":", "]", ",", "self", ".", "w_qs2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "k_s", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "bmm", "(", "qk_inp_repeated", "[", ":", ",", ":", ",", ":", "self", ".", "d_content", "]", ",", "self", ".", "w_ks1", ")", ",", "\n", "torch", ".", "bmm", "(", "qk_inp_repeated", "[", ":", ",", ":", ",", "self", ".", "d_content", ":", "]", ",", "self", ".", "w_ks2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "v_s", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "bmm", "(", "v_inp_repeated", "[", ":", ",", ":", ",", ":", "self", ".", "d_content", "]", ",", "self", ".", "w_vs1", ")", ",", "\n", "torch", ".", "bmm", "(", "v_inp_repeated", "[", ":", ",", ":", ",", "self", ".", "d_content", ":", "]", ",", "self", ".", "w_vs2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "", "return", "q_s", ",", "k_s", ",", "v_s", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiHeadAttention.pad_and_rearrange": [[329, 355], ["q_s.new_zeros", "k_s.new_zeros", "v_s.new_zeros", "q_s.new_ones", "enumerate", "zip", "invalid_mask[].fill_", "q_s.new_zeros.view", "k_s.new_zeros.view", "v_s.new_zeros.view", "q_s.new_ones.unsqueeze().expand().repeat", "q_s.new_ones.unsqueeze().expand", "q_s.new_ones.unsqueeze"], "methods", ["None"], ["", "def", "pad_and_rearrange", "(", "self", ",", "q_s", ",", "k_s", ",", "v_s", ",", "batch_idxs", ")", ":", "\n", "# Input is padded representation: n_head x len_inp x d", "\n", "# Output is packed representation: (n_head * mb_size) x len_padded x d", "\n", "# (along with masks for the attention and output)", "\n", "        ", "n_head", "=", "self", ".", "n_head", "\n", "d_k", ",", "d_v", "=", "self", ".", "d_k", ",", "self", ".", "d_v", "\n", "\n", "len_padded", "=", "batch_idxs", ".", "max_len", "\n", "mb_size", "=", "batch_idxs", ".", "batch_size", "\n", "q_padded", "=", "q_s", ".", "new_zeros", "(", "(", "n_head", ",", "mb_size", ",", "len_padded", ",", "d_k", ")", ")", "\n", "k_padded", "=", "k_s", ".", "new_zeros", "(", "(", "n_head", ",", "mb_size", ",", "len_padded", ",", "d_k", ")", ")", "\n", "v_padded", "=", "v_s", ".", "new_zeros", "(", "(", "n_head", ",", "mb_size", ",", "len_padded", ",", "d_v", ")", ")", "\n", "invalid_mask", "=", "q_s", ".", "new_ones", "(", "(", "mb_size", ",", "len_padded", ")", ",", "dtype", "=", "DTYPE", ")", "\n", "\n", "for", "i", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "zip", "(", "batch_idxs", ".", "boundaries_np", "[", ":", "-", "1", "]", ",", "batch_idxs", ".", "boundaries_np", "[", "1", ":", "]", ")", ")", ":", "\n", "            ", "q_padded", "[", ":", ",", "i", ",", ":", "end", "-", "start", ",", ":", "]", "=", "q_s", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "k_padded", "[", ":", ",", "i", ",", ":", "end", "-", "start", ",", ":", "]", "=", "k_s", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "v_padded", "[", ":", ",", "i", ",", ":", "end", "-", "start", ",", ":", "]", "=", "v_s", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "invalid_mask", "[", "i", ",", ":", "end", "-", "start", "]", ".", "fill_", "(", "False", ")", "\n", "\n", "", "return", "(", "\n", "q_padded", ".", "view", "(", "-", "1", ",", "len_padded", ",", "d_k", ")", ",", "\n", "k_padded", ".", "view", "(", "-", "1", ",", "len_padded", ",", "d_k", ")", ",", "\n", "v_padded", ".", "view", "(", "-", "1", ",", "len_padded", ",", "d_v", ")", ",", "\n", "invalid_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "mb_size", ",", "len_padded", ",", "len_padded", ")", ".", "repeat", "(", "n_head", ",", "1", ",", "1", ")", ",", "\n", "(", "~", "invalid_mask", ")", ".", "repeat", "(", "n_head", ",", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiHeadAttention.combine_v": [[357, 380], ["torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "KM_parser.MultiHeadAttention.proj", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "KM_parser.MultiHeadAttention.proj1", "KM_parser.MultiHeadAttention.proj2", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "methods", ["None"], ["", "def", "combine_v", "(", "self", ",", "outputs", ")", ":", "\n", "# Combine attention information from the different heads", "\n", "        ", "n_head", "=", "self", ".", "n_head", "\n", "outputs", "=", "outputs", ".", "view", "(", "n_head", ",", "-", "1", ",", "self", ".", "d_v", ")", "# n_head x len_inp x d_kv", "\n", "\n", "if", "not", "self", ".", "partitioned", ":", "\n", "# Switch from n_head x len_inp x d_v to len_inp x (n_head * d_v)", "\n", "            ", "outputs", "=", "torch", ".", "transpose", "(", "outputs", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_head", "*", "self", ".", "d_v", ")", "\n", "\n", "# Project back to residual size", "\n", "outputs", "=", "self", ".", "proj", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "d_v1", "=", "self", ".", "d_v", "//", "2", "\n", "outputs1", "=", "outputs", "[", ":", ",", ":", ",", ":", "d_v1", "]", "\n", "outputs2", "=", "outputs", "[", ":", ",", ":", ",", "d_v1", ":", "]", "\n", "outputs1", "=", "torch", ".", "transpose", "(", "outputs1", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_head", "*", "d_v1", ")", "\n", "outputs2", "=", "torch", ".", "transpose", "(", "outputs2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_head", "*", "d_v1", ")", "\n", "outputs", "=", "torch", ".", "cat", "(", "[", "\n", "self", ".", "proj1", "(", "outputs1", ")", ",", "\n", "self", ".", "proj2", "(", "outputs2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiHeadAttention.forward": [[381, 405], ["KM_parser.MultiHeadAttention.split_qkv_packed", "KM_parser.MultiHeadAttention.pad_and_rearrange", "KM_parser.MultiHeadAttention.attention", "KM_parser.MultiHeadAttention.combine_v", "KM_parser.MultiHeadAttention.residual_dropout", "KM_parser.MultiHeadAttention.layer_norm"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.split_qkv_packed", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.pad_and_rearrange", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.combine_v"], ["", "def", "forward", "(", "self", ",", "inp", ",", "batch_idxs", ",", "qk_inp", "=", "None", ")", ":", "\n", "        ", "residual", "=", "inp", "\n", "\n", "# While still using a packed representation, project to obtain the", "\n", "# query/key/value for each head", "\n", "q_s", ",", "k_s", ",", "v_s", "=", "self", ".", "split_qkv_packed", "(", "inp", ",", "qk_inp", "=", "qk_inp", ")", "\n", "# n_head x len_inp x d_kv", "\n", "\n", "# Switch to padded representation, perform attention, then switch back", "\n", "q_padded", ",", "k_padded", ",", "v_padded", ",", "attn_mask", ",", "output_mask", "=", "self", ".", "pad_and_rearrange", "(", "q_s", ",", "k_s", ",", "v_s", ",", "batch_idxs", ")", "\n", "# (n_head * batch) x len_padded x d_kv", "\n", "\n", "outputs_padded", ",", "attns_padded", "=", "self", ".", "attention", "(", "\n", "q_padded", ",", "k_padded", ",", "v_padded", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", ")", "\n", "outputs", "=", "outputs_padded", "[", "output_mask", "]", "\n", "# (n_head * len_inp) x d_kv", "\n", "outputs", "=", "self", ".", "combine_v", "(", "outputs", ")", "\n", "# len_inp x d_model", "\n", "\n", "outputs", "=", "self", ".", "residual_dropout", "(", "outputs", ",", "batch_idxs", ")", "\n", "\n", "return", "self", ".", "layer_norm", "(", "outputs", "+", "residual", ")", ",", "attns_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.PositionwiseFeedForward.__init__": [[415, 424], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.LayerNormalization", "KM_parser.FeatureDropout", "KM_parser.FeatureDropout", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "d_hid", ",", "d_ff", ",", "relu_dropout", "=", "0.1", ",", "residual_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_hid", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "d_hid", ")", "\n", "self", ".", "relu_dropout", "=", "FeatureDropout", "(", "relu_dropout", ")", "\n", "self", ".", "residual_dropout", "=", "FeatureDropout", "(", "residual_dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.PositionwiseFeedForward.forward": [[426, 435], ["KM_parser.PositionwiseFeedForward.w_1", "KM_parser.PositionwiseFeedForward.relu_dropout", "KM_parser.PositionwiseFeedForward.w_2", "KM_parser.PositionwiseFeedForward.residual_dropout", "KM_parser.PositionwiseFeedForward.layer_norm", "KM_parser.PositionwiseFeedForward.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "batch_idxs", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "output", "=", "self", ".", "w_1", "(", "x", ")", "\n", "output", "=", "self", ".", "relu_dropout", "(", "self", ".", "relu", "(", "output", ")", ",", "batch_idxs", ")", "\n", "output", "=", "self", ".", "w_2", "(", "output", ")", "\n", "\n", "output", "=", "self", ".", "residual_dropout", "(", "output", ",", "batch_idxs", ")", "\n", "return", "self", ".", "layer_norm", "(", "output", "+", "residual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.PartitionedPositionwiseFeedForward.__init__": [[438, 449], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.LayerNormalization", "KM_parser.FeatureDropout", "KM_parser.FeatureDropout", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_hid", ",", "d_ff", ",", "d_positional", ",", "relu_dropout", "=", "0.1", ",", "residual_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_content", "=", "d_hid", "-", "d_positional", "\n", "self", ".", "w_1c", "=", "nn", ".", "Linear", "(", "self", ".", "d_content", ",", "d_ff", "//", "2", ")", "\n", "self", ".", "w_1p", "=", "nn", ".", "Linear", "(", "d_positional", ",", "d_ff", "//", "2", ")", "\n", "self", ".", "w_2c", "=", "nn", ".", "Linear", "(", "d_ff", "//", "2", ",", "self", ".", "d_content", ")", "\n", "self", ".", "w_2p", "=", "nn", ".", "Linear", "(", "d_ff", "//", "2", ",", "d_positional", ")", "\n", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "d_hid", ")", "\n", "self", ".", "relu_dropout", "=", "FeatureDropout", "(", "relu_dropout", ")", "\n", "self", ".", "residual_dropout", "=", "FeatureDropout", "(", "residual_dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.PartitionedPositionwiseFeedForward.forward": [[450, 467], ["KM_parser.PartitionedPositionwiseFeedForward.w_1c", "KM_parser.PartitionedPositionwiseFeedForward.relu_dropout", "KM_parser.PartitionedPositionwiseFeedForward.w_2c", "KM_parser.PartitionedPositionwiseFeedForward.w_1p", "KM_parser.PartitionedPositionwiseFeedForward.relu_dropout", "KM_parser.PartitionedPositionwiseFeedForward.w_2p", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KM_parser.PartitionedPositionwiseFeedForward.residual_dropout", "KM_parser.PartitionedPositionwiseFeedForward.layer_norm", "KM_parser.PartitionedPositionwiseFeedForward.relu", "KM_parser.PartitionedPositionwiseFeedForward.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "batch_idxs", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "xc", "=", "x", "[", ":", ",", ":", "self", ".", "d_content", "]", "\n", "xp", "=", "x", "[", ":", ",", "self", ".", "d_content", ":", "]", "\n", "\n", "outputc", "=", "self", ".", "w_1c", "(", "xc", ")", "\n", "outputc", "=", "self", ".", "relu_dropout", "(", "self", ".", "relu", "(", "outputc", ")", ",", "batch_idxs", ")", "\n", "outputc", "=", "self", ".", "w_2c", "(", "outputc", ")", "\n", "\n", "outputp", "=", "self", ".", "w_1p", "(", "xp", ")", "\n", "outputp", "=", "self", ".", "relu_dropout", "(", "self", ".", "relu", "(", "outputp", ")", ",", "batch_idxs", ")", "\n", "outputp", "=", "self", ".", "w_2p", "(", "outputp", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "[", "outputc", ",", "outputp", "]", ",", "-", "1", ")", "\n", "\n", "output", "=", "self", ".", "residual_dropout", "(", "output", ",", "batch_idxs", ")", "\n", "return", "self", ".", "layer_norm", "(", "output", "+", "residual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiLevelEmbedding.__init__": [[470, 547], ["torch.Module.__init__", "enumerate", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "KM_parser.FeatureDropout", "KM_parser.FeatureDropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.normal_", "torch.normal_", "torch.normal_", "len", "len", "len", "zip", "embs.append", "KM_parser.FeatureDropout", "emb_dropouts.append", "torch.Embedding", "torch.Embedding", "torch.Embedding", "KM_parser.MultiLevelEmbedding.pretrain_emb.weight.data.copy_", "KM_parser.MultiLevelEmbedding.pretrain_emb.weight.requires_grad_", "KM_parser.FeatureDropout", "KM_parser.FeatureDropout", "KM_parser.LayerNormalization", "torch_t.FloatTensor", "len", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "num_embeddings_list", ",", "\n", "d_embedding", ",", "\n", "hparams", ",", "\n", "d_positional", "=", "None", ",", "\n", "max_len", "=", "300", ",", "\n", "normalize", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "timing_dropout", "=", "0.0", ",", "\n", "emb_dropouts_list", "=", "None", ",", "\n", "extra_content_dropout", "=", "None", ",", "\n", "word_table_np", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_embedding", "=", "d_embedding", "\n", "self", ".", "partitioned", "=", "d_positional", "is", "not", "None", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "if", "self", ".", "partitioned", ":", "\n", "            ", "self", ".", "d_positional", "=", "d_positional", "\n", "self", ".", "d_content", "=", "self", ".", "d_embedding", "-", "self", ".", "d_positional", "\n", "", "else", ":", "\n", "            ", "self", ".", "d_positional", "=", "self", ".", "d_embedding", "\n", "self", ".", "d_content", "=", "self", ".", "d_embedding", "\n", "\n", "", "if", "emb_dropouts_list", "is", "None", ":", "\n", "            ", "emb_dropouts_list", "=", "[", "0.0", "]", "*", "len", "(", "num_embeddings_list", ")", "\n", "", "assert", "len", "(", "emb_dropouts_list", ")", "==", "len", "(", "num_embeddings_list", ")", "\n", "\n", "if", "word_table_np", "is", "not", "None", ":", "\n", "            ", "self", ".", "pretrain_dim", "=", "word_table_np", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "pretrain_dim", "=", "0", "\n", "\n", "", "embs", "=", "[", "]", "\n", "emb_dropouts", "=", "[", "]", "\n", "cun", "=", "len", "(", "num_embeddings_list", ")", "*", "2", "\n", "for", "i", ",", "(", "num_embeddings", ",", "emb_dropout", ")", "in", "enumerate", "(", "zip", "(", "num_embeddings_list", ",", "emb_dropouts_list", ")", ")", ":", "\n", "            ", "if", "hparams", ".", "use_cat", ":", "\n", "                ", "if", "i", "==", "len", "(", "num_embeddings_list", ")", "-", "1", ":", "\n", "#last is word", "\n", "                    ", "emb", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "self", ".", "d_content", "//", "cun", "-", "self", ".", "pretrain_dim", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "                    ", "emb", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "self", ".", "d_content", "//", "cun", ",", "**", "kwargs", ")", "\n", "", "", "else", ":", "\n", "                ", "emb", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "self", ".", "d_content", "-", "self", ".", "pretrain_dim", ",", "**", "kwargs", ")", "\n", "", "embs", ".", "append", "(", "emb", ")", "\n", "emb_dropout", "=", "FeatureDropout", "(", "emb_dropout", ")", "\n", "emb_dropouts", ".", "append", "(", "emb_dropout", ")", "\n", "\n", "", "if", "word_table_np", "is", "not", "None", ":", "\n", "            ", "self", ".", "pretrain_emb", "=", "nn", ".", "Embedding", "(", "word_table_np", ".", "shape", "[", "0", "]", ",", "self", ".", "pretrain_dim", ")", "\n", "self", ".", "pretrain_emb", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "word_table_np", ")", ")", "\n", "self", ".", "pretrain_emb", ".", "weight", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "pretrain_emb_dropout", "=", "FeatureDropout", "(", "0.33", ")", "\n", "\n", "", "self", ".", "embs", "=", "nn", ".", "ModuleList", "(", "embs", ")", "\n", "self", ".", "emb_dropouts", "=", "nn", ".", "ModuleList", "(", "emb_dropouts", ")", "\n", "\n", "if", "extra_content_dropout", "is", "not", "None", ":", "\n", "            ", "self", ".", "extra_content_dropout", "=", "FeatureDropout", "(", "extra_content_dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "extra_content_dropout", "=", "None", "\n", "\n", "", "if", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "d_embedding", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "lambda", "x", ":", "x", "\n", "\n", "", "self", ".", "dropout", "=", "FeatureDropout", "(", "dropout", ")", "\n", "self", ".", "timing_dropout", "=", "FeatureDropout", "(", "timing_dropout", ")", "\n", "\n", "# Learned embeddings", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "position_table", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "max_len", ",", "self", ".", "d_positional", ")", ")", "\n", "init", ".", "normal_", "(", "self", ".", "position_table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.MultiLevelEmbedding.forward": [[548, 593], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KM_parser.MultiLevelEmbedding.timing_dropout", "KM_parser.MultiLevelEmbedding.layer_norm", "KM_parser.MultiLevelEmbedding.dropout", "emb_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KM_parser.MultiLevelEmbedding.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KM_parser.MultiLevelEmbedding.dropout", "emb", "zip", "KM_parser.MultiLevelEmbedding.extra_content_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KM_parser.MultiLevelEmbedding.append", "KM_parser.MultiLevelEmbedding.pretrain_emb_dropout", "KM_parser.MultiLevelEmbedding.pretrain_emb"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xs", ",", "pre_words_idxs", ",", "batch_idxs", ",", "extra_content_annotations", "=", "None", ")", ":", "\n", "        ", "content_annotations", "=", "[", "\n", "emb_dropout", "(", "emb", "(", "x", ")", ",", "batch_idxs", ")", "\n", "for", "x", ",", "emb", ",", "emb_dropout", "in", "zip", "(", "xs", ",", "self", ".", "embs", ",", "self", ".", "emb_dropouts", ")", "\n", "]", "\n", "if", "self", ".", "hparams", ".", "use_cat", ":", "\n", "            ", "content_annotations", "=", "torch", ".", "cat", "(", "content_annotations", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "content_annotations", "=", "sum", "(", "content_annotations", ")", "\n", "", "if", "self", ".", "pretrain_dim", "!=", "0", ":", "\n", "            ", "content_annotations", "=", "torch", ".", "cat", "(", "[", "content_annotations", ",", "self", ".", "pretrain_emb_dropout", "(", "self", ".", "pretrain_emb", "(", "pre_words_idxs", ")", ",", "batch_idxs", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "extra_content_annotations", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "extra_content_dropout", "is", "not", "None", ":", "\n", "                ", "extra_content_annotations", "=", "self", ".", "extra_content_dropout", "(", "extra_content_annotations", ",", "batch_idxs", ")", "\n", "\n", "", "if", "self", ".", "hparams", ".", "use_cat", ":", "\n", "                ", "content_annotations", "=", "torch", ".", "cat", "(", "\n", "[", "content_annotations", ",", "extra_content_annotations", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "content_annotations", "+=", "extra_content_annotations", "\n", "\n", "", "", "timing_signal", "=", "[", "]", "\n", "for", "seq_len", "in", "batch_idxs", ".", "seq_lens_np", ":", "\n", "            ", "this_seq_len", "=", "seq_len", "\n", "timing_signal", ".", "append", "(", "self", ".", "position_table", "[", ":", "this_seq_len", ",", ":", "]", ")", "\n", "this_seq_len", "-=", "self", ".", "max_len", "\n", "while", "this_seq_len", ">", "0", ":", "\n", "                ", "timing_signal", ".", "append", "(", "self", ".", "position_table", "[", ":", "this_seq_len", ",", ":", "]", ")", "\n", "this_seq_len", "-=", "self", ".", "max_len", "\n", "\n", "", "", "timing_signal", "=", "torch", ".", "cat", "(", "timing_signal", ",", "dim", "=", "0", ")", "\n", "timing_signal", "=", "self", ".", "timing_dropout", "(", "timing_signal", ",", "batch_idxs", ")", "\n", "\n", "# Combine the content and timing signals", "\n", "if", "self", ".", "partitioned", ":", "\n", "            ", "annotations", "=", "torch", ".", "cat", "(", "[", "content_annotations", ",", "timing_signal", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "annotations", "=", "content_annotations", "+", "timing_signal", "\n", "\n", "#print(annotations.shape)", "\n", "", "annotations", "=", "self", ".", "layer_norm", "(", "self", ".", "dropout", "(", "annotations", ",", "batch_idxs", ")", ")", "\n", "content_annotations", "=", "self", ".", "dropout", "(", "content_annotations", ",", "batch_idxs", ")", "\n", "\n", "return", "annotations", ",", "content_annotations", ",", "timing_signal", ",", "batch_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.CharacterLSTM.__init__": [[597, 616], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "print", "KM_parser.LayerNormalization"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["    ", "def", "__init__", "(", "self", ",", "num_embeddings", ",", "d_embedding", ",", "d_out", ",", "\n", "char_dropout", "=", "0.0", ",", "\n", "normalize", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CharacterLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_embedding", "=", "d_embedding", "\n", "self", ".", "d_out", "=", "d_out", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "self", ".", "d_embedding", ",", "self", ".", "d_out", "//", "2", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ")", "\n", "\n", "self", ".", "emb", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "self", ".", "d_embedding", ",", "**", "kwargs", ")", "\n", "self", ".", "char_dropout", "=", "nn", ".", "Dropout", "(", "char_dropout", ")", "\n", "\n", "if", "normalize", ":", "\n", "            ", "print", "(", "\"This experiment: layer-normalizing after character LSTM\"", ")", "\n", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "self", ".", "d_out", ",", "affine", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.CharacterLSTM.forward": [[617, 641], ["[].copy", "from_numpy", "from_numpy.requires_grad_", "from_numpy", "from_numpy.requires_grad_", "from_numpy", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.PackedSequence", "torch.utils.rnn.PackedSequence", "torch.utils.rnn.PackedSequence", "KM_parser.CharacterLSTM.lstm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "KM_parser.CharacterLSTM.index_copy_", "KM_parser.CharacterLSTM.layer_norm", "KM_parser.CharacterLSTM.char_dropout", "KM_parser.CharacterLSTM.emb", "numpy.argsort"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "chars_padded_np", ",", "word_lens_np", ",", "batch_idxs", ")", ":", "\n", "# copy to ensure nonnegative stride for successful transfer to pytorch", "\n", "        ", "decreasing_idxs_np", "=", "np", ".", "argsort", "(", "word_lens_np", ")", "[", ":", ":", "-", "1", "]", ".", "copy", "(", ")", "\n", "decreasing_idxs_torch", "=", "from_numpy", "(", "decreasing_idxs_np", ")", "\n", "decreasing_idxs_torch", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "chars_padded", "=", "from_numpy", "(", "chars_padded_np", "[", "decreasing_idxs_np", "]", ")", "\n", "chars_padded", ".", "requires_grad_", "(", "False", ")", "\n", "word_lens", "=", "from_numpy", "(", "word_lens_np", "[", "decreasing_idxs_np", "]", ")", "\n", "\n", "inp_sorted", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "chars_padded", ",", "word_lens_np", "[", "decreasing_idxs_np", "]", ",", "batch_first", "=", "True", ")", "\n", "inp_sorted_emb", "=", "nn", ".", "utils", ".", "rnn", ".", "PackedSequence", "(", "\n", "self", ".", "char_dropout", "(", "self", ".", "emb", "(", "inp_sorted", ".", "data", ")", ")", ",", "\n", "inp_sorted", ".", "batch_sizes", ")", "\n", "_", ",", "(", "lstm_out", ",", "_", ")", "=", "self", ".", "lstm", "(", "inp_sorted_emb", ")", "\n", "\n", "lstm_out", "=", "torch", ".", "cat", "(", "[", "lstm_out", "[", "0", "]", ",", "lstm_out", "[", "1", "]", "]", ",", "-", "1", ")", "\n", "\n", "# Undo sorting by decreasing word length", "\n", "res", "=", "torch", ".", "zeros_like", "(", "lstm_out", ")", "\n", "res", ".", "index_copy_", "(", "0", ",", "decreasing_idxs_torch", ",", "lstm_out", ")", "\n", "\n", "res", "=", "self", ".", "layer_norm", "(", "res", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BiLinear.__init__": [[741, 766], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "KM_parser.BiLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "KM_parser.BiLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BiLinear.reset_parameters"], ["def", "__init__", "(", "self", ",", "left_features", ",", "right_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "'''\n\n        Args:\n            left_features: size of left input\n            right_features: size of right input\n            out_features: size of output\n            bias: If set to False, the layer will not learn an additive bias.\n                Default: True\n        '''", "\n", "super", "(", "BiLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "left_features", "=", "left_features", "\n", "self", ".", "right_features", "=", "right_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "\n", "self", ".", "U", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ",", "self", ".", "right_features", ")", ")", "\n", "self", ".", "W_l", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "self", ".", "W_r", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BiLinear.reset_parameters": [[767, 772], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_l", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_r", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BiLinear.forward": [[773, 794], ["input_left.view.view.view", "input_right.view.view.view", "torch.functional.bilinear", "torch.functional.bilinear", "torch.functional.bilinear", "torch.functional.linear", "torch.functional.linear", "torch.functional.linear", "torch.functional.linear", "torch.functional.linear", "torch.functional.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_left", ",", "input_right", ")", ":", "\n", "        ", "'''\n\n        Args:\n            input_left: Tensor\n                the left input tensor with shape = [batch1, batch2, ..., left_features]\n            input_right: Tensor\n                the right input tensor with shape = [batch1, batch2, ..., right_features]\n\n        Returns:\n\n        '''", "\n", "# convert left and right input to matrices [batch, left_features], [batch, right_features]", "\n", "input_left", "=", "input_left", ".", "view", "(", "-", "1", ",", "self", ".", "left_features", ")", "\n", "input_right", "=", "input_right", ".", "view", "(", "-", "1", ",", "self", ".", "right_features", ")", "\n", "\n", "# output [batch, out_features]", "\n", "output", "=", "nn", ".", "functional", ".", "bilinear", "(", "input_left", ",", "input_right", ",", "self", ".", "U", ",", "self", ".", "bias", ")", "\n", "output", "=", "output", "+", "nn", ".", "functional", ".", "linear", "(", "input_left", ",", "self", ".", "W_l", ",", "None", ")", "+", "nn", ".", "functional", ".", "linear", "(", "input_right", ",", "self", ".", "W_r", ",", "None", ")", "\n", "# convert back to [batch1, batch2, ..., out_features]", "\n", "return", "output", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BiAAttention.__init__": [[800, 806], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch_t.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "BiAAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "self", ".", "dep_weight", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "hparams", ".", "d_biaffine", "+", "1", ",", "hparams", ".", "d_biaffine", "+", "1", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "dep_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.BiAAttention.forward": [[807, 817], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch_t.FloatTensor().fill_().requires_grad_", "torch_t.FloatTensor().fill_().requires_grad_", "torch_t.FloatTensor().fill_", "torch_t.FloatTensor().fill_", "torch_t.FloatTensor", "input_d.size", "torch_t.FloatTensor", "input_e.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_d", ",", "input_e", ",", "input_s", "=", "None", ")", ":", "\n", "\n", "        ", "score", "=", "torch", ".", "matmul", "(", "torch", ".", "cat", "(", "\n", "[", "input_d", ",", "torch_t", ".", "FloatTensor", "(", "input_d", ".", "size", "(", "0", ")", ",", "1", ")", ".", "fill_", "(", "1", ")", ".", "requires_grad_", "(", "False", ")", "]", ",", "\n", "dim", "=", "1", ")", ",", "self", ".", "dep_weight", ")", "\n", "score1", "=", "torch", ".", "matmul", "(", "score", ",", "torch", ".", "transpose", "(", "torch", ".", "cat", "(", "\n", "[", "input_e", ",", "torch_t", ".", "FloatTensor", "(", "input_e", ".", "size", "(", "0", ")", ",", "1", ")", ".", "fill_", "(", "1", ")", ".", "requires_grad_", "(", "False", ")", "]", ",", "\n", "dim", "=", "1", ")", ",", "0", ",", "1", ")", ")", "\n", "\n", "return", "score1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.Dep_score.__init__": [[819, 833], ["torch.Module.__init__", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.BiAAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.BiLinear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "Dep_score", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout_out", "=", "nn", ".", "Dropout2d", "(", "p", "=", "0.33", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "out_dim", "=", "hparams", ".", "d_biaffine", "#d_biaffine", "\n", "self", ".", "arc_h", "=", "nn", ".", "Linear", "(", "hparams", ".", "annotation_dim", ",", "hparams", ".", "d_biaffine", ")", "\n", "self", ".", "arc_c", "=", "nn", ".", "Linear", "(", "hparams", ".", "annotation_dim", ",", "hparams", ".", "d_biaffine", ")", "\n", "\n", "self", ".", "attention", "=", "BiAAttention", "(", "hparams", ")", "\n", "\n", "self", ".", "type_h", "=", "nn", ".", "Linear", "(", "hparams", ".", "annotation_dim", ",", "hparams", ".", "d_label_hidden", ")", "\n", "self", ".", "type_c", "=", "nn", ".", "Linear", "(", "hparams", ".", "annotation_dim", ",", "hparams", ".", "d_label_hidden", ")", "\n", "self", ".", "bilinear", "=", "BiLinear", "(", "hparams", ".", "d_label_hidden", ",", "hparams", ".", "d_label_hidden", ",", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.Dep_score.forward": [[834, 867], ["KM_parser.Dep_score.dropout_out().transpose", "KM_parser.Dep_score.dropout_out().transpose", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "KM_parser.Dep_score.dropout_out().transpose", "KM_parser.Dep_score.chunk", "KM_parser.Dep_score.dropout_out().transpose", "KM_parser.Dep_score.chunk", "type_h.contiguous.contiguous.contiguous", "type_c.contiguous.contiguous.contiguous", "KM_parser.Dep_score.attention", "KM_parser.Dep_score.bilinear", "KM_parser.Dep_score.arc_h", "KM_parser.Dep_score.arc_c", "KM_parser.Dep_score.type_h", "KM_parser.Dep_score.type_c", "KM_parser.Dep_score.dropout_out", "KM_parser.Dep_score.dropout_out", "KM_parser.Dep_score.dropout_out", "KM_parser.Dep_score.dropout_out", "KM_parser.Dep_score.transpose", "KM_parser.Dep_score.transpose", "KM_parser.Dep_score.transpose", "KM_parser.Dep_score.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "outputs", ",", "outpute", ")", ":", "\n", "# output from rnn [batch, length, hidden_size]", "\n", "\n", "# apply dropout for output", "\n", "# [batch, length, hidden_size] --> [batch, hidden_size, length] --> [batch, length, hidden_size]", "\n", "        ", "outpute", "=", "self", ".", "dropout_out", "(", "outpute", ".", "transpose", "(", "1", ",", "0", ")", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "outputs", "=", "self", ".", "dropout_out", "(", "outputs", ".", "transpose", "(", "1", ",", "0", ")", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "# output size [batch, length, arc_space]", "\n", "arc_h", "=", "nn", ".", "functional", ".", "relu", "(", "self", ".", "arc_h", "(", "outputs", ")", ")", "\n", "arc_c", "=", "nn", ".", "functional", ".", "relu", "(", "self", ".", "arc_c", "(", "outpute", ")", ")", "\n", "\n", "# output size [batch, length, type_space]", "\n", "type_h", "=", "nn", ".", "functional", ".", "relu", "(", "self", ".", "type_h", "(", "outputs", ")", ")", "\n", "type_c", "=", "nn", ".", "functional", ".", "relu", "(", "self", ".", "type_c", "(", "outpute", ")", ")", "\n", "\n", "# apply dropout", "\n", "# [batch, length, dim] --> [batch, 2 * length, dim]", "\n", "arc", "=", "torch", ".", "cat", "(", "[", "arc_h", ",", "arc_c", "]", ",", "dim", "=", "0", ")", "\n", "type", "=", "torch", ".", "cat", "(", "[", "type_h", ",", "type_c", "]", ",", "dim", "=", "0", ")", "\n", "\n", "arc", "=", "self", ".", "dropout_out", "(", "arc", ".", "transpose", "(", "1", ",", "0", ")", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "arc_h", ",", "arc_c", "=", "arc", ".", "chunk", "(", "2", ",", "0", ")", "\n", "\n", "type", "=", "self", ".", "dropout_out", "(", "type", ".", "transpose", "(", "1", ",", "0", ")", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "type_h", ",", "type_c", "=", "type", ".", "chunk", "(", "2", ",", "0", ")", "\n", "type_h", "=", "type_h", ".", "contiguous", "(", ")", "\n", "type_c", "=", "type_c", ".", "contiguous", "(", ")", "\n", "\n", "out_arc", "=", "self", ".", "attention", "(", "arc_h", ",", "arc_c", ")", "\n", "out_type", "=", "self", ".", "bilinear", "(", "type_h", ",", "type_c", ")", "\n", "\n", "return", "out_arc", ",", "out_type", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.__init__": [[873, 951], ["torch.Module.__init__", "KM_parser.ScaledDotProductAttention", "KM_parser.FeatureDropout", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "KM_parser.LayerNormalization", "KM_parser.LayerNormalization", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor", "torch_t.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "d_model", ",", "d_k", ",", "d_v", ",", "d_l", ",", "d_proj", ",", "use_resdrop", "=", "True", ",", "q_as_matrix", "=", "False", ",", "residual_dropout", "=", "0.1", ",", "attention_dropout", "=", "0.1", ",", "d_positional", "=", "None", ")", ":", "\n", "        ", "super", "(", "LabelAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "self", ".", "d_l", "=", "d_l", "# Number of Labels", "\n", "self", ".", "d_model", "=", "d_model", "# Model Dimensionality", "\n", "self", ".", "d_proj", "=", "d_proj", "# Projection dimension of each label output", "\n", "self", ".", "use_resdrop", "=", "use_resdrop", "# Using Residual Dropout?", "\n", "self", ".", "q_as_matrix", "=", "q_as_matrix", "# Using a Matrix of Q to be multiplied with input instead of learned q vectors", "\n", "self", ".", "combine_as_self", "=", "hparams", ".", "lal_combine_as_self", "# Using the Combination Method of Self-Attention", "\n", "\n", "if", "d_positional", "is", "None", ":", "\n", "            ", "self", ".", "partitioned", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "partitioned", "=", "True", "\n", "\n", "", "if", "self", ".", "partitioned", ":", "\n", "            ", "self", ".", "d_content", "=", "d_model", "-", "d_positional", "\n", "self", ".", "d_positional", "=", "d_positional", "\n", "\n", "if", "self", ".", "q_as_matrix", ":", "\n", "                ", "self", ".", "w_qs1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "self", ".", "d_content", ",", "d_k", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "w_qs1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "d_k", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "w_ks1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "self", ".", "d_content", ",", "d_k", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "w_vs1", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "self", ".", "d_content", ",", "d_v", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "if", "self", ".", "q_as_matrix", ":", "\n", "                ", "self", ".", "w_qs2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "self", ".", "d_positional", ",", "d_k", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "w_qs2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "d_k", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "w_ks2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "self", ".", "d_positional", ",", "d_k", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "w_vs2", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "self", ".", "d_positional", ",", "d_v", "//", "2", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs1", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks1", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_vs1", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs2", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks2", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_vs2", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "q_as_matrix", ":", "\n", "                ", "self", ".", "w_qs", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "d_model", ",", "d_k", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "w_qs", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "d_k", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "self", ".", "w_ks", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "d_model", ",", "d_k", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Parameter", "(", "torch_t", ".", "FloatTensor", "(", "self", ".", "d_l", ",", "d_model", ",", "d_v", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "w_vs", ")", "\n", "\n", "", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "d_model", ",", "attention_dropout", "=", "attention_dropout", ")", "\n", "if", "self", ".", "combine_as_self", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "d_model", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer_norm", "=", "LayerNormalization", "(", "self", ".", "d_proj", ")", "\n", "\n", "", "if", "not", "self", ".", "partitioned", ":", "\n", "# The lack of a bias term here is consistent with the t2t code, though", "\n", "# in my experiments I have never observed this making a difference.", "\n", "            ", "if", "self", ".", "combine_as_self", ":", "\n", "                ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "self", ".", "d_l", "*", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "d_v", ",", "d_model", ",", "bias", "=", "False", ")", "# input dimension does not match, should be d_l * d_v", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "combine_as_self", ":", "\n", "                ", "self", ".", "proj1", "=", "nn", ".", "Linear", "(", "self", ".", "d_l", "*", "(", "d_v", "//", "2", ")", ",", "self", ".", "d_content", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj2", "=", "nn", ".", "Linear", "(", "self", ".", "d_l", "*", "(", "d_v", "//", "2", ")", ",", "self", ".", "d_positional", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "proj1", "=", "nn", ".", "Linear", "(", "d_v", "//", "2", ",", "self", ".", "d_content", ",", "bias", "=", "False", ")", "\n", "self", ".", "proj2", "=", "nn", ".", "Linear", "(", "d_v", "//", "2", ",", "self", ".", "d_positional", ",", "bias", "=", "False", ")", "\n", "", "", "if", "not", "self", ".", "combine_as_self", ":", "\n", "            ", "self", ".", "reduce_proj", "=", "nn", ".", "Linear", "(", "d_model", ",", "self", ".", "d_proj", ",", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "residual_dropout", "=", "FeatureDropout", "(", "residual_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.split_qkv_packed": [[952, 987], ["inp.size", "inp.repeat().view", "inp.size", "k_inp.repeat().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inp.repeat", "k_inp.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "KM_parser.LabelAttention.w_qs.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "k_inp.repeat", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "KM_parser.LabelAttention.w_qs1.unsqueeze", "KM_parser.LabelAttention.w_qs2.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "split_qkv_packed", "(", "self", ",", "inp", ",", "k_inp", "=", "None", ")", ":", "\n", "        ", "len_inp", "=", "inp", ".", "size", "(", "0", ")", "\n", "v_inp_repeated", "=", "inp", ".", "repeat", "(", "self", ".", "d_l", ",", "1", ")", ".", "view", "(", "self", ".", "d_l", ",", "-", "1", ",", "inp", ".", "size", "(", "-", "1", ")", ")", "# d_l x len_inp x d_model", "\n", "if", "k_inp", "is", "None", ":", "\n", "            ", "k_inp_repeated", "=", "v_inp_repeated", "\n", "", "else", ":", "\n", "            ", "k_inp_repeated", "=", "k_inp", ".", "repeat", "(", "self", ".", "d_l", ",", "1", ")", ".", "view", "(", "self", ".", "d_l", ",", "-", "1", ",", "k_inp", ".", "size", "(", "-", "1", ")", ")", "# d_l x len_inp x d_model", "\n", "\n", "", "if", "not", "self", ".", "partitioned", ":", "\n", "            ", "if", "self", ".", "q_as_matrix", ":", "\n", "                ", "q_s", "=", "torch", ".", "bmm", "(", "k_inp_repeated", ",", "self", ".", "w_qs", ")", "# d_l x len_inp x d_k", "\n", "", "else", ":", "\n", "                ", "q_s", "=", "self", ".", "w_qs", ".", "unsqueeze", "(", "1", ")", "# d_l x 1 x d_k", "\n", "", "k_s", "=", "torch", ".", "bmm", "(", "k_inp_repeated", ",", "self", ".", "w_ks", ")", "# d_l x len_inp x d_k", "\n", "v_s", "=", "torch", ".", "bmm", "(", "v_inp_repeated", ",", "self", ".", "w_vs", ")", "# d_l x len_inp x d_v", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "q_as_matrix", ":", "\n", "                ", "q_s", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "bmm", "(", "k_inp_repeated", "[", ":", ",", ":", ",", ":", "self", ".", "d_content", "]", ",", "self", ".", "w_qs1", ")", ",", "\n", "torch", ".", "bmm", "(", "k_inp_repeated", "[", ":", ",", ":", ",", "self", ".", "d_content", ":", "]", ",", "self", ".", "w_qs2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "q_s", "=", "torch", ".", "cat", "(", "[", "\n", "self", ".", "w_qs1", ".", "unsqueeze", "(", "1", ")", ",", "\n", "self", ".", "w_qs2", ".", "unsqueeze", "(", "1", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "", "k_s", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "bmm", "(", "k_inp_repeated", "[", ":", ",", ":", ",", ":", "self", ".", "d_content", "]", ",", "self", ".", "w_ks1", ")", ",", "\n", "torch", ".", "bmm", "(", "k_inp_repeated", "[", ":", ",", ":", ",", "self", ".", "d_content", ":", "]", ",", "self", ".", "w_ks2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "v_s", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "bmm", "(", "v_inp_repeated", "[", ":", ",", ":", ",", ":", "self", ".", "d_content", "]", ",", "self", ".", "w_vs1", ")", ",", "\n", "torch", ".", "bmm", "(", "v_inp_repeated", "[", ":", ",", ":", ",", "self", ".", "d_content", ":", "]", ",", "self", ".", "w_vs2", ")", ",", "\n", "]", ",", "-", "1", ")", "\n", "", "return", "q_s", ",", "k_s", ",", "v_s", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.pad_and_rearrange": [[988, 1026], ["k_s.new_zeros", "v_s.new_zeros", "q_s.new_ones", "enumerate", "q_s.new_zeros", "q_s.repeat", "zip", "invalid_mask[].fill_", "q_padded.view.view.view", "q_s.new_ones.unsqueeze().expand().repeat", "q_s.new_ones.unsqueeze().repeat", "k_s.new_zeros.view", "v_s.new_zeros.view", "q_s.new_ones.unsqueeze().expand", "q_s.new_ones.unsqueeze", "q_s.new_ones.unsqueeze"], "methods", ["None"], ["", "def", "pad_and_rearrange", "(", "self", ",", "q_s", ",", "k_s", ",", "v_s", ",", "batch_idxs", ")", ":", "\n", "# Input is padded representation: n_head x len_inp x d", "\n", "# Output is packed representation: (n_head * mb_size) x len_padded x d", "\n", "# (along with masks for the attention and output)", "\n", "        ", "n_head", "=", "self", ".", "d_l", "\n", "d_k", ",", "d_v", "=", "self", ".", "d_k", ",", "self", ".", "d_v", "\n", "\n", "len_padded", "=", "batch_idxs", ".", "max_len", "\n", "mb_size", "=", "batch_idxs", ".", "batch_size", "\n", "if", "self", ".", "q_as_matrix", ":", "\n", "            ", "q_padded", "=", "q_s", ".", "new_zeros", "(", "(", "n_head", ",", "mb_size", ",", "len_padded", ",", "d_k", ")", ")", "\n", "", "else", ":", "\n", "            ", "q_padded", "=", "q_s", ".", "repeat", "(", "mb_size", ",", "1", ",", "1", ")", "# (d_l * mb_size) x 1 x d_k", "\n", "", "k_padded", "=", "k_s", ".", "new_zeros", "(", "(", "n_head", ",", "mb_size", ",", "len_padded", ",", "d_k", ")", ")", "\n", "v_padded", "=", "v_s", ".", "new_zeros", "(", "(", "n_head", ",", "mb_size", ",", "len_padded", ",", "d_v", ")", ")", "\n", "invalid_mask", "=", "q_s", ".", "new_ones", "(", "(", "mb_size", ",", "len_padded", ")", ",", "dtype", "=", "DTYPE", ")", "\n", "\n", "for", "i", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "zip", "(", "batch_idxs", ".", "boundaries_np", "[", ":", "-", "1", "]", ",", "batch_idxs", ".", "boundaries_np", "[", "1", ":", "]", ")", ")", ":", "\n", "            ", "if", "self", ".", "q_as_matrix", ":", "\n", "                ", "q_padded", "[", ":", ",", "i", ",", ":", "end", "-", "start", ",", ":", "]", "=", "q_s", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "", "k_padded", "[", ":", ",", "i", ",", ":", "end", "-", "start", ",", ":", "]", "=", "k_s", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "v_padded", "[", ":", ",", "i", ",", ":", "end", "-", "start", ",", ":", "]", "=", "v_s", "[", ":", ",", "start", ":", "end", ",", ":", "]", "\n", "invalid_mask", "[", "i", ",", ":", "end", "-", "start", "]", ".", "fill_", "(", "False", ")", "\n", "\n", "", "if", "self", ".", "q_as_matrix", ":", "\n", "            ", "q_padded", "=", "q_padded", ".", "view", "(", "-", "1", ",", "len_padded", ",", "d_k", ")", "\n", "attn_mask", "=", "invalid_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "mb_size", ",", "len_padded", ",", "len_padded", ")", ".", "repeat", "(", "n_head", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "attn_mask", "=", "invalid_mask", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "n_head", ",", "1", ",", "1", ")", "\n", "\n", "", "output_mask", "=", "(", "~", "invalid_mask", ")", ".", "repeat", "(", "n_head", ",", "1", ")", "\n", "\n", "return", "(", "\n", "q_padded", ",", "\n", "k_padded", ".", "view", "(", "-", "1", ",", "len_padded", ",", "d_k", ")", ",", "\n", "v_padded", ".", "view", "(", "-", "1", ",", "len_padded", ",", "d_v", ")", ",", "\n", "attn_mask", ",", "\n", "output_mask", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.combine_v": [[1028, 1057], ["torch.transpose.view", "torch.transpose.view", "torch.transpose.view", "KM_parser.LabelAttention.proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "KM_parser.LabelAttention.proj1", "KM_parser.LabelAttention.proj2", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "methods", ["None"], ["", "def", "combine_v", "(", "self", ",", "outputs", ")", ":", "\n", "# Combine attention information from the different labels", "\n", "        ", "d_l", "=", "self", ".", "d_l", "\n", "outputs", "=", "outputs", ".", "view", "(", "d_l", ",", "-", "1", ",", "self", ".", "d_v", ")", "# d_l x len_inp x d_v", "\n", "\n", "if", "not", "self", ".", "partitioned", ":", "\n", "# Switch from d_l x len_inp x d_v to len_inp x d_l x d_v", "\n", "            ", "if", "self", ".", "combine_as_self", ":", "\n", "                ", "outputs", "=", "torch", ".", "transpose", "(", "outputs", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "d_l", "*", "self", ".", "d_v", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "torch", ".", "transpose", "(", "outputs", ",", "0", ",", "1", ")", "#.contiguous() #.view(-1, d_l * self.d_v)", "\n", "# Project back to residual size", "\n", "", "outputs", "=", "self", ".", "proj", "(", "outputs", ")", "# Becomes len_inp x d_l x d_model", "\n", "", "else", ":", "\n", "            ", "d_v1", "=", "self", ".", "d_v", "//", "2", "\n", "outputs1", "=", "outputs", "[", ":", ",", ":", ",", ":", "d_v1", "]", "\n", "outputs2", "=", "outputs", "[", ":", ",", ":", ",", "d_v1", ":", "]", "\n", "if", "self", ".", "combine_as_self", ":", "\n", "                ", "outputs1", "=", "torch", ".", "transpose", "(", "outputs1", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "d_l", "*", "d_v1", ")", "\n", "outputs2", "=", "torch", ".", "transpose", "(", "outputs2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "d_l", "*", "d_v1", ")", "\n", "", "else", ":", "\n", "                ", "outputs1", "=", "torch", ".", "transpose", "(", "outputs1", ",", "0", ",", "1", ")", "#.contiguous() #.view(-1, d_l * d_v1)", "\n", "outputs2", "=", "torch", ".", "transpose", "(", "outputs2", ",", "0", ",", "1", ")", "#.contiguous() #.view(-1, d_l * d_v1)", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "[", "\n", "self", ".", "proj1", "(", "outputs1", ")", ",", "\n", "self", ".", "proj2", "(", "outputs2", ")", ",", "\n", "]", ",", "-", "1", ")", "#.contiguous()", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.forward": [[1058, 1104], ["inp.size", "KM_parser.LabelAttention.split_qkv_packed", "KM_parser.LabelAttention.pad_and_rearrange", "KM_parser.LabelAttention.attention", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "KM_parser.LabelAttention.combine_v", "outputs_padded.repeat.repeat.repeat", "KM_parser.LabelAttention.layer_norm", "range", "KM_parser.LabelAttention.reduce_proj", "KM_parser.LabelAttention.layer_norm", "torch.cat.view().contiguous", "torch.cat.view().contiguous", "torch.cat.view().contiguous", "output_mask.size", "KM_parser.LabelAttention.residual_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.view", "torch.cat.view", "torch.cat.view", "KM_parser.LabelAttention.residual_dropout().unsqueeze", "range", "KM_parser.LabelAttention.residual_dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.split_qkv_packed", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.pad_and_rearrange", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.LabelAttention.combine_v", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "inp", ",", "batch_idxs", ",", "k_inp", "=", "None", ")", ":", "\n", "        ", "residual", "=", "inp", "# len_inp x d_model", "\n", "len_inp", "=", "inp", ".", "size", "(", "0", ")", "\n", "\n", "# While still using a packed representation, project to obtain the", "\n", "# query/key/value for each head", "\n", "q_s", ",", "k_s", ",", "v_s", "=", "self", ".", "split_qkv_packed", "(", "inp", ",", "k_inp", "=", "k_inp", ")", "\n", "# d_l x len_inp x d_k", "\n", "# q_s is d_l x 1 x d_k", "\n", "\n", "# Switch to padded representation, perform attention, then switch back", "\n", "q_padded", ",", "k_padded", ",", "v_padded", ",", "attn_mask", ",", "output_mask", "=", "self", ".", "pad_and_rearrange", "(", "q_s", ",", "k_s", ",", "v_s", ",", "batch_idxs", ")", "\n", "# q_padded, k_padded, v_padded: (d_l * batch_size) x max_len x d_kv", "\n", "# q_s is (d_l * batch_size) x 1 x d_kv", "\n", "\n", "outputs_padded", ",", "attns_padded", "=", "self", ".", "attention", "(", "\n", "q_padded", ",", "k_padded", ",", "v_padded", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", ")", "\n", "# outputs_padded: (d_l * batch_size) x max_len x d_kv", "\n", "# in LAL: (d_l * batch_size) x 1 x d_kv", "\n", "# on the best model, this is one value vector per label that is repeated max_len times", "\n", "if", "not", "self", ".", "q_as_matrix", ":", "\n", "            ", "outputs_padded", "=", "outputs_padded", ".", "repeat", "(", "1", ",", "output_mask", ".", "size", "(", "-", "1", ")", ",", "1", ")", "\n", "", "outputs", "=", "outputs_padded", "[", "output_mask", "]", "\n", "# outputs: (d_l * len_inp) x d_kv or LAL: (d_l * len_inp) x d_kv", "\n", "# output_mask: (d_l * batch_size) x max_len", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "outputs", "=", "self", ".", "combine_v", "(", "outputs", ")", "\n", "# outputs: len_inp x d_l x d_model, whereas a normal self-attention layer gets len_inp x d_model", "\n", "if", "self", ".", "use_resdrop", ":", "\n", "            ", "if", "self", ".", "combine_as_self", ":", "\n", "                ", "outputs", "=", "self", ".", "residual_dropout", "(", "outputs", ",", "batch_idxs", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "torch", ".", "cat", "(", "[", "self", ".", "residual_dropout", "(", "outputs", "[", ":", ",", "i", ",", ":", "]", ",", "batch_idxs", ")", ".", "unsqueeze", "(", "1", ")", "for", "i", "in", "range", "(", "self", ".", "d_l", ")", "]", ",", "1", ")", "\n", "", "", "if", "self", ".", "combine_as_self", ":", "\n", "            ", "outputs", "=", "self", ".", "layer_norm", "(", "outputs", "+", "inp", ")", "\n", "", "else", ":", "\n", "            ", "for", "l", "in", "range", "(", "self", ".", "d_l", ")", ":", "\n", "                ", "outputs", "[", ":", ",", "l", ",", ":", "]", "=", "outputs", "[", ":", ",", "l", ",", ":", "]", "+", "inp", "\n", "\n", "", "outputs", "=", "self", ".", "reduce_proj", "(", "outputs", ")", "# len_inp x d_l x d_proj", "\n", "outputs", "=", "self", ".", "layer_norm", "(", "outputs", ")", "# len_inp x d_l x d_proj", "\n", "outputs", "=", "outputs", ".", "view", "(", "len_inp", ",", "-", "1", ")", ".", "contiguous", "(", ")", "# len_inp x (d_l * d_proj)", "\n", "\n", "", "return", "outputs", ",", "attns_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.Encoder.__init__": [[1106, 1164], ["torch.Module.__init__", "range", "KM_parser.MultiHeadAttention", "KM_parser.Encoder.add_module", "KM_parser.Encoder.add_module", "KM_parser.Encoder.stacks.append", "KM_parser.LabelAttention", "KM_parser.Encoder.add_module", "KM_parser.Encoder.add_module", "KM_parser.Encoder.stacks.append", "KM_parser.PositionwiseFeedForward", "KM_parser.PartitionedPositionwiseFeedForward", "KM_parser.PositionwiseFeedForward", "KM_parser.PartitionedPositionwiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "embedding", ",", "\n", "num_layers", "=", "1", ",", "num_heads", "=", "2", ",", "d_kv", "=", "32", ",", "d_ff", "=", "1024", ",", "d_l", "=", "112", ",", "\n", "d_positional", "=", "None", ",", "\n", "num_layers_position_only", "=", "0", ",", "\n", "relu_dropout", "=", "0.1", ",", "residual_dropout", "=", "0.1", ",", "attention_dropout", "=", "0.1", ",", "\n", "use_lal", "=", "True", ",", "\n", "lal_d_kv", "=", "128", ",", "\n", "lal_d_proj", "=", "128", ",", "\n", "lal_resdrop", "=", "True", ",", "\n", "lal_pwff", "=", "True", ",", "\n", "lal_q_as_matrix", "=", "False", ",", "\n", "lal_partitioned", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_container", "=", "[", "embedding", "]", "\n", "d_model", "=", "embedding", ".", "d_embedding", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "d_k", "=", "d_v", "=", "d_kv", "\n", "\n", "self", ".", "stacks", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "hparams", ".", "num_layers", ")", ":", "\n", "            ", "attn", "=", "MultiHeadAttention", "(", "hparams", ",", "num_heads", ",", "d_model", ",", "d_k", ",", "d_v", ",", "residual_dropout", "=", "residual_dropout", ",", "\n", "attention_dropout", "=", "attention_dropout", ",", "d_positional", "=", "d_positional", ")", "\n", "if", "d_positional", "is", "None", ":", "\n", "                ", "ff", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "relu_dropout", "=", "relu_dropout", ",", "\n", "residual_dropout", "=", "residual_dropout", ")", "\n", "", "else", ":", "\n", "                ", "ff", "=", "PartitionedPositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "d_positional", ",", "relu_dropout", "=", "relu_dropout", ",", "\n", "residual_dropout", "=", "residual_dropout", ")", "\n", "\n", "", "self", ".", "add_module", "(", "f\"attn_{i}\"", ",", "attn", ")", "\n", "self", ".", "add_module", "(", "f\"ff_{i}\"", ",", "ff", ")", "\n", "\n", "self", ".", "stacks", ".", "append", "(", "(", "attn", ",", "ff", ")", ")", "\n", "\n", "", "if", "use_lal", ":", "\n", "            ", "lal_d_positional", "=", "d_positional", "if", "lal_partitioned", "else", "None", "\n", "attn", "=", "LabelAttention", "(", "hparams", ",", "d_model", ",", "lal_d_kv", ",", "lal_d_kv", ",", "d_l", ",", "lal_d_proj", ",", "use_resdrop", "=", "lal_resdrop", ",", "q_as_matrix", "=", "lal_q_as_matrix", ",", "\n", "residual_dropout", "=", "residual_dropout", ",", "attention_dropout", "=", "attention_dropout", ",", "d_positional", "=", "lal_d_positional", ")", "\n", "ff_dim", "=", "lal_d_proj", "*", "d_l", "\n", "if", "hparams", ".", "lal_combine_as_self", ":", "\n", "                ", "ff_dim", "=", "d_model", "\n", "", "if", "lal_pwff", ":", "\n", "                ", "if", "d_positional", "is", "None", "or", "not", "lal_partitioned", ":", "\n", "                    ", "ff", "=", "PositionwiseFeedForward", "(", "ff_dim", ",", "d_ff", ",", "relu_dropout", "=", "relu_dropout", ",", "residual_dropout", "=", "residual_dropout", ")", "\n", "", "else", ":", "\n", "                    ", "ff", "=", "PartitionedPositionwiseFeedForward", "(", "ff_dim", ",", "d_ff", ",", "d_positional", ",", "relu_dropout", "=", "relu_dropout", ",", "residual_dropout", "=", "residual_dropout", ")", "\n", "", "", "else", ":", "\n", "                ", "ff", "=", "None", "\n", "\n", "", "self", ".", "add_module", "(", "f\"attn_{num_layers}\"", ",", "attn", ")", "\n", "self", ".", "add_module", "(", "f\"ff_{num_layers}\"", ",", "ff", ")", "\n", "self", ".", "stacks", ".", "append", "(", "(", "attn", ",", "ff", ")", ")", "\n", "\n", "", "self", ".", "num_layers_position_only", "=", "num_layers_position_only", "\n", "if", "self", ".", "num_layers_position_only", ">", "0", ":", "\n", "            ", "assert", "d_positional", "is", "None", ",", "\"num_layers_position_only and partitioned are incompatible\"", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.Encoder.forward": [[1165, 1175], ["emb", "enumerate", "attn", "ff"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "xs", ",", "pre_words_idxs", ",", "batch_idxs", ",", "extra_content_annotations", "=", "None", ")", ":", "\n", "        ", "emb", "=", "self", ".", "embedding_container", "[", "0", "]", "\n", "res", ",", "res_c", ",", "timing_signal", ",", "batch_idxs", "=", "emb", "(", "xs", ",", "pre_words_idxs", ",", "batch_idxs", ",", "extra_content_annotations", "=", "extra_content_annotations", ")", "\n", "\n", "for", "i", ",", "(", "attn", ",", "ff", ")", "in", "enumerate", "(", "self", ".", "stacks", ")", ":", "\n", "            ", "res", ",", "current_attns", "=", "attn", "(", "res", ",", "batch_idxs", ")", "\n", "if", "ff", "is", "not", "None", ":", "\n", "                ", "res", "=", "ff", "(", "res", ",", "batch_idxs", ")", "\n", "\n", "", "", "return", "res", ",", "current_attns", "#batch_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.__init__": [[1177, 1405], ["torch.Module.__init__", "locals", "KM_parser.ChartParser.spec.pop", "KM_parser.ChartParser.spec.pop", "hparams.to_dict", "torch.Sequential", "torch.Sequential", "torch.Sequential", "KM_parser.Dep_score", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "KM_parser.ChartParser.emb_types.append", "KM_parser.ChartParser.emb_types.append", "KM_parser.CharacterLSTM", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.get_xlnet", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.get_bert", "KM_parser.get_roberta", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.MultiLevelEmbedding", "KM_parser.Encoder", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.LayerNormalization", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "hasattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "KM_parser.ChartParser.cuda", "KM_parser.get_elmo_class", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "utils.load_embedding_dict", "numpy.sqrt", "numpy.zeros", "enumerate", "print", "torch.Linear", "torch.Linear", "torch.Linear", "KM_parser.LayerNormalization", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "numpy.random.uniform().astype", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_dict", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_xlnet", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_bert", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_roberta", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_elmo_class", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.utils.load_embedding_dict", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tag_vocab", ",", "\n", "word_vocab", ",", "\n", "label_vocab", ",", "\n", "char_vocab", ",", "\n", "type_vocab", ",", "\n", "hparams", ",", "\n", "exp_name", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "spec", "=", "locals", "(", ")", "\n", "self", ".", "spec", ".", "pop", "(", "\"self\"", ")", "\n", "self", ".", "spec", ".", "pop", "(", "\"__class__\"", ")", "\n", "self", ".", "spec", "[", "'hparams'", "]", "=", "hparams", ".", "to_dict", "(", ")", "\n", "\n", "self", ".", "tag_vocab", "=", "tag_vocab", "\n", "self", ".", "word_vocab", "=", "word_vocab", "\n", "self", ".", "label_vocab", "=", "label_vocab", "\n", "self", ".", "char_vocab", "=", "char_vocab", "\n", "self", ".", "type_vocab", "=", "type_vocab", "\n", "\n", "self", ".", "hparams", "=", "hparams", "\n", "self", ".", "d_model", "=", "hparams", ".", "d_model", "\n", "self", ".", "partitioned", "=", "hparams", ".", "partitioned", "\n", "self", ".", "d_content", "=", "(", "self", ".", "d_model", "//", "2", ")", "if", "self", ".", "partitioned", "else", "self", ".", "d_model", "\n", "self", ".", "d_positional", "=", "(", "hparams", ".", "d_model", "//", "2", ")", "if", "self", ".", "partitioned", "else", "None", "\n", "\n", "self", ".", "use_lal", "=", "hparams", ".", "use_lal", "\n", "if", "self", ".", "use_lal", ":", "\n", "            ", "self", ".", "lal_d_kv", "=", "hparams", ".", "lal_d_kv", "\n", "self", ".", "lal_d_proj", "=", "hparams", ".", "lal_d_proj", "\n", "self", ".", "lal_resdrop", "=", "hparams", ".", "lal_resdrop", "\n", "self", ".", "lal_pwff", "=", "hparams", ".", "lal_pwff", "\n", "self", ".", "lal_q_as_matrix", "=", "hparams", ".", "lal_q_as_matrix", "\n", "self", ".", "lal_partitioned", "=", "hparams", ".", "lal_partitioned", "\n", "self", ".", "lal_combine_as_self", "=", "hparams", ".", "lal_combine_as_self", "\n", "\n", "", "self", ".", "contributions", "=", "False", "\n", "\n", "num_embeddings_map", "=", "{", "\n", "'tags'", ":", "tag_vocab", ".", "size", ",", "\n", "'words'", ":", "word_vocab", ".", "size", ",", "\n", "'chars'", ":", "char_vocab", ".", "size", ",", "\n", "}", "\n", "emb_dropouts_map", "=", "{", "\n", "'tags'", ":", "hparams", ".", "tag_emb_dropout", ",", "\n", "'words'", ":", "hparams", ".", "word_emb_dropout", ",", "\n", "}", "\n", "\n", "self", ".", "emb_types", "=", "[", "]", "\n", "if", "hparams", ".", "use_tags", ":", "\n", "            ", "self", ".", "emb_types", ".", "append", "(", "'tags'", ")", "\n", "", "if", "hparams", ".", "use_words", ":", "\n", "            ", "self", ".", "emb_types", ".", "append", "(", "'words'", ")", "\n", "\n", "", "self", ".", "use_tags", "=", "hparams", ".", "use_tags", "\n", "\n", "self", ".", "morpho_emb_dropout", "=", "None", "\n", "\n", "self", ".", "char_encoder", "=", "None", "\n", "self", ".", "elmo", "=", "None", "\n", "self", ".", "bert", "=", "None", "\n", "self", ".", "xlnet", "=", "None", "\n", "self", ".", "pad_left", "=", "hparams", ".", "pad_left", "\n", "self", ".", "roberta", "=", "None", "\n", "ex_dim", "=", "self", ".", "d_content", "\n", "if", "self", ".", "hparams", ".", "use_cat", ":", "\n", "            ", "cun", "=", "0", "\n", "if", "hparams", ".", "use_words", "or", "hparams", ".", "use_tags", ":", "\n", "                ", "ex_dim", "=", "ex_dim", "//", "2", "#word dim = self.d_content/2", "\n", "", "if", "hparams", ".", "use_chars_lstm", ":", "\n", "                ", "cun", "=", "cun", "+", "1", "\n", "", "if", "hparams", ".", "use_elmo", "or", "hparams", ".", "use_bert", "or", "hparams", ".", "use_xlnet", ":", "\n", "                ", "cun", "=", "cun", "+", "1", "\n", "", "if", "cun", ">", "0", ":", "\n", "                ", "ex_dim", "=", "ex_dim", "//", "cun", "\n", "", "", "if", "hparams", ".", "use_chars_lstm", ":", "\n", "            ", "self", ".", "char_encoder", "=", "CharacterLSTM", "(", "\n", "num_embeddings_map", "[", "'chars'", "]", ",", "\n", "hparams", ".", "d_char_emb", ",", "\n", "ex_dim", ",", "\n", "char_dropout", "=", "hparams", ".", "char_lstm_input_dropout", ",", "\n", ")", "\n", "", "if", "hparams", ".", "use_elmo", ":", "\n", "            ", "self", ".", "elmo", "=", "get_elmo_class", "(", ")", "(", "\n", "options_file", "=", "\"data/elmo_2x4096_512_2048cnn_2xhighway_options.json\"", ",", "\n", "weight_file", "=", "\"data/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"", ",", "\n", "num_output_representations", "=", "1", ",", "\n", "requires_grad", "=", "False", ",", "\n", "do_layer_norm", "=", "False", ",", "\n", "dropout", "=", "hparams", ".", "elmo_dropout", ",", "\n", ")", "\n", "d_elmo_annotations", "=", "1024", "\n", "\n", "# Don't train gamma parameter for ELMo - the projection can do any", "\n", "# necessary scaling", "\n", "self", ".", "elmo", ".", "scalar_mix_0", ".", "gamma", ".", "requires_grad", "=", "False", "\n", "\n", "# Reshapes the embeddings to match the model dimension, and making", "\n", "# the projection trainable appears to improve parsing accuracy", "\n", "self", ".", "project_elmo", "=", "nn", ".", "Linear", "(", "d_elmo_annotations", ",", "ex_dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "if", "hparams", ".", "use_xlnet", ":", "\n", "\n", "            ", "self", ".", "xlnet_tokenizer", ",", "self", ".", "xlnet", "=", "get_xlnet", "(", "hparams", ".", "xlnet_model", ",", "hparams", ".", "xlnet_do_lower_case", ")", "\n", "if", "hparams", ".", "bert_transliterate", ":", "\n", "                ", "from", "transliterate", "import", "TRANSLITERATIONS", "\n", "self", ".", "bert_transliterate", "=", "TRANSLITERATIONS", "[", "hparams", ".", "bert_transliterate", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "bert_transliterate", "=", "None", "\n", "\n", "", "d_xlnet_annotations", "=", "self", ".", "xlnet", ".", "d_model", "\n", "self", ".", "xlnet_max_len", "=", "768", "\n", "\n", "self", ".", "project_xlnet", "=", "nn", ".", "Linear", "(", "d_xlnet_annotations", ",", "ex_dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "if", "hparams", ".", "use_bert", "or", "hparams", ".", "use_bert_only", ":", "\n", "            ", "self", ".", "bert_tokenizer", ",", "self", ".", "bert", "=", "get_bert", "(", "hparams", ".", "bert_model", ",", "hparams", ".", "bert_do_lower_case", ")", "\n", "if", "hparams", ".", "bert_transliterate", ":", "\n", "                ", "from", "transliterate", "import", "TRANSLITERATIONS", "\n", "self", ".", "bert_transliterate", "=", "TRANSLITERATIONS", "[", "hparams", ".", "bert_transliterate", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "bert_transliterate", "=", "None", "\n", "\n", "", "d_bert_annotations", "=", "self", ".", "bert", ".", "pooler", ".", "dense", ".", "in_features", "\n", "self", ".", "bert_max_len", "=", "self", ".", "bert", ".", "embeddings", ".", "position_embeddings", ".", "num_embeddings", "\n", "\n", "if", "hparams", ".", "use_bert_only", ":", "\n", "                ", "self", ".", "project_bert", "=", "nn", ".", "Linear", "(", "d_bert_annotations", ",", "hparams", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "project_bert", "=", "nn", ".", "Linear", "(", "d_bert_annotations", ",", "ex_dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "", "if", "hparams", ".", "use_roberta", ":", "\n", "            ", "self", ".", "roberta_tokenizer", ",", "self", ".", "roberta", "=", "get_roberta", "(", "hparams", ".", "roberta_model", ",", "hparams", ".", "roberta_do_lower_case", ")", "\n", "if", "hparams", ".", "bert_transliterate", ":", "\n", "                ", "from", "transliterate", "import", "TRANSLITERATIONS", "\n", "self", ".", "bert_transliterate", "=", "TRANSLITERATIONS", "[", "hparams", ".", "bert_transliterate", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "bert_transliterate", "=", "None", "\n", "\n", "", "d_roberta_annotations", "=", "self", ".", "roberta", ".", "pooler", ".", "dense", ".", "in_features", "\n", "self", ".", "roberta_max_len", "=", "self", ".", "roberta", ".", "embeddings", ".", "position_embeddings", ".", "num_embeddings", "\n", "\n", "self", ".", "project_roberta", "=", "nn", ".", "Linear", "(", "d_roberta_annotations", ",", "self", ".", "d_content", ",", "bias", "=", "False", ")", "\n", "\n", "", "if", "not", "hparams", ".", "use_bert_only", ":", "\n", "\n", "            ", "if", "hparams", ".", "embedding_type", "!=", "'random'", "and", "hparams", ".", "use_words", ":", "\n", "                ", "embedd_dict", ",", "embedd_dim", "=", "utils", ".", "load_embedding_dict", "(", "hparams", ".", "embedding_type", ",", "hparams", ".", "embedding_path", ")", "\n", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "embedd_dim", ")", "\n", "table", "=", "np", ".", "zeros", "(", "[", "word_vocab", ".", "size", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "oov", "=", "0", "\n", "for", "index", ",", "word", "in", "enumerate", "(", "word_vocab", ".", "indices", ")", ":", "\n", "                    ", "if", "word", "in", "embedd_dict", ":", "\n", "                        ", "embedding", "=", "embedd_dict", "[", "word", "]", "\n", "", "else", ":", "\n", "                        ", "embedding", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "embedd_dim", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "oov", "+=", "1", "\n", "", "table", "[", "index", ",", ":", "embedd_dim", "]", "=", "embedding", "\n", "", "print", "(", "'oov: %d'", "%", "oov", ")", "\n", "word_table_np", "=", "table", "\n", "# self.project_pretrain = nn.Linear(embedd_dim, self.d_content, bias=False)", "\n", "", "else", ":", "\n", "                ", "word_table_np", "=", "None", "\n", "\n", "", "self", ".", "embedding", "=", "MultiLevelEmbedding", "(", "\n", "[", "num_embeddings_map", "[", "emb_type", "]", "for", "emb_type", "in", "self", ".", "emb_types", "]", ",", "\n", "hparams", ".", "d_model", ",", "\n", "hparams", "=", "hparams", ",", "\n", "d_positional", "=", "self", ".", "d_positional", ",", "\n", "dropout", "=", "hparams", ".", "embedding_dropout", ",", "\n", "timing_dropout", "=", "hparams", ".", "timing_dropout", ",", "\n", "emb_dropouts_list", "=", "[", "emb_dropouts_map", "[", "emb_type", "]", "for", "emb_type", "in", "self", ".", "emb_types", "]", ",", "\n", "extra_content_dropout", "=", "self", ".", "morpho_emb_dropout", ",", "\n", "max_len", "=", "hparams", ".", "sentence_max_len", ",", "\n", "word_table_np", "=", "word_table_np", ",", "\n", ")", "\n", "\n", "self", ".", "encoder", "=", "Encoder", "(", "\n", "hparams", ",", "\n", "self", ".", "embedding", ",", "\n", "num_layers", "=", "hparams", ".", "num_layers", ",", "\n", "num_heads", "=", "hparams", ".", "num_heads", ",", "\n", "d_kv", "=", "hparams", ".", "d_kv", ",", "\n", "d_ff", "=", "hparams", ".", "d_ff", ",", "\n", "d_positional", "=", "self", ".", "d_positional", ",", "\n", "relu_dropout", "=", "hparams", ".", "relu_dropout", ",", "\n", "residual_dropout", "=", "hparams", ".", "residual_dropout", ",", "\n", "attention_dropout", "=", "hparams", ".", "attention_dropout", ",", "\n", "use_lal", "=", "hparams", ".", "use_lal", ",", "\n", "lal_d_kv", "=", "hparams", ".", "lal_d_kv", ",", "\n", "lal_d_proj", "=", "hparams", ".", "lal_d_proj", ",", "\n", "lal_resdrop", "=", "hparams", ".", "lal_resdrop", ",", "\n", "lal_pwff", "=", "hparams", ".", "lal_pwff", ",", "\n", "lal_q_as_matrix", "=", "hparams", ".", "lal_q_as_matrix", ",", "\n", "lal_partitioned", "=", "hparams", ".", "lal_partitioned", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "None", "\n", "self", ".", "encoder", "=", "None", "\n", "\n", "", "annotation_dim", "=", "(", "(", "label_vocab", ".", "size", "-", "2", ")", "*", "self", ".", "lal_d_proj", ")", "if", "(", "self", ".", "use_lal", "and", "not", "self", ".", "lal_combine_as_self", ")", "else", "hparams", ".", "d_model", "\n", "hparams", ".", "annotation_dim", "=", "annotation_dim", "\n", "\n", "self", ".", "f_label", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "annotation_dim", ",", "hparams", ".", "d_label_hidden", ")", ",", "\n", "LayerNormalization", "(", "hparams", ".", "d_label_hidden", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hparams", ".", "d_label_hidden", ",", "label_vocab", ".", "size", "-", "1", ")", ",", "\n", ")", "\n", "self", ".", "dep_score", "=", "Dep_score", "(", "hparams", ",", "type_vocab", ".", "size", ")", "\n", "self", ".", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "size_average", "=", "False", ")", "\n", "self", ".", "loss_funt", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "size_average", "=", "False", ")", "\n", "\n", "if", "not", "hparams", ".", "use_tags", "and", "hasattr", "(", "hparams", ",", "'d_tag_hidden'", ")", ":", "\n", "            ", "self", ".", "f_tag", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "annotation_dim", ",", "hparams", ".", "d_tag_hidden", ")", ",", "\n", "LayerNormalization", "(", "hparams", ".", "d_tag_hidden", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hparams", ".", "d_tag_hidden", ",", "tag_vocab", ".", "size", ")", ",", "\n", ")", "\n", "self", ".", "tag_loss_scale", "=", "hparams", ".", "tag_loss_scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "f_tag", "=", "None", "\n", "\n", "", "if", "use_cuda", ":", "\n", "            ", "self", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.model": [[1406, 1409], ["KM_parser.ChartParser.state_dict"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "model", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.from_spec": [[1410, 1464], ["spec.copy.copy.copy", "makehp.HParams", "cls", "cls.cpu", "cls.load_state_dict", "state.update", "cls.load_state_dict", "cls.cuda", "cls.state_dict().items", "cls.state_dict"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_spec", "(", "cls", ",", "spec", ",", "model", ")", ":", "\n", "        ", "spec", "=", "spec", ".", "copy", "(", ")", "\n", "hparams", "=", "spec", "[", "'hparams'", "]", "\n", "if", "'sentence_max_len'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'sentence_max_len'", "]", "=", "300", "\n", "", "if", "'use_elmo'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'use_elmo'", "]", "=", "False", "\n", "", "if", "'elmo_dropout'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'elmo_dropout'", "]", "=", "0.5", "\n", "", "if", "'const_lada'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'const_lada'", "]", "=", "0.5", "\n", "", "if", "'use_bert'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'use_bert'", "]", "=", "False", "\n", "", "if", "'use_bert_only'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'use_bert_only'", "]", "=", "False", "\n", "", "if", "'bert_model'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'bert_model'", "]", "=", "\"bert-large-uncased\"", "\n", "", "if", "'bert_do_lower_case'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'bert_do_lower_case'", "]", "=", "False", "\n", "", "if", "'bert_transliterate'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'bert_transliterate'", "]", "=", "\"\"", "\n", "\n", "", "if", "'use_xlnet'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'use_xlnet'", "]", "=", "False", "\n", "", "if", "'use_roberta'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'use_roberta'", "]", "=", "False", "\n", "", "if", "'xlnet_model'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'xlnet_model'", "]", "=", "\"xlnet-large-cased\"", "\n", "", "if", "'xlnet_do_lower_case'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'xlnet_do_lower_case'", "]", "=", "False", "\n", "", "if", "'pad_left'", "not", "in", "hparams", ":", "\n", "            ", "hparams", "[", "'pad_left'", "]", "=", "False", "\n", "\n", "", "for", "param", "in", "'use_lal lal_resdrop lal_pwff lal_partitioned lal_q_as_matrix lal_combine_as_self'", ".", "split", "(", "' '", ")", ":", "\n", "            ", "if", "param", "not", "in", "hparams", ":", "\n", "                ", "hparams", "[", "param", "]", "=", "False", "\n", "", "", "for", "param", "in", "'lal_d_kv lal_d_proj'", ".", "split", "(", "' '", ")", ":", "\n", "            ", "if", "param", "not", "in", "hparams", ":", "\n", "                ", "hparams", "[", "param", "]", "=", "64", "\n", "\n", "", "", "spec", "[", "'hparams'", "]", "=", "makehp", ".", "HParams", "(", "**", "hparams", ")", "\n", "res", "=", "cls", "(", "**", "spec", ")", "\n", "if", "use_cuda", ":", "\n", "            ", "res", ".", "cpu", "(", ")", "\n", "", "if", "not", "hparams", "[", "'use_elmo'", "]", ":", "\n", "            ", "res", ".", "load_state_dict", "(", "model", ")", "\n", "", "else", ":", "\n", "            ", "state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "res", ".", "state_dict", "(", ")", ".", "items", "(", ")", "if", "k", "not", "in", "model", "}", "\n", "state", ".", "update", "(", "model", ")", "\n", "res", ".", "load_state_dict", "(", "state", ")", "\n", "", "if", "use_cuda", ":", "\n", "            ", "res", ".", "cuda", "(", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.split_batch": [[1465, 1481], ["numpy.asarray", "numpy.argsort().tolist", "len", "numpy.argsort", "len"], "methods", ["None"], ["", "def", "split_batch", "(", "self", ",", "sentences", ",", "golds", ",", "subbatch_max_tokens", "=", "3000", ")", ":", "\n", "        ", "lens", "=", "[", "len", "(", "sentence", ")", "+", "2", "for", "sentence", "in", "sentences", "]", "\n", "\n", "lens", "=", "np", ".", "asarray", "(", "lens", ",", "dtype", "=", "int", ")", "\n", "lens_argsort", "=", "np", ".", "argsort", "(", "lens", ")", ".", "tolist", "(", ")", "\n", "\n", "num_subbatches", "=", "0", "\n", "subbatch_size", "=", "1", "\n", "while", "lens_argsort", ":", "\n", "            ", "if", "(", "subbatch_size", "==", "len", "(", "lens_argsort", ")", ")", "or", "(", "subbatch_size", "*", "lens", "[", "lens_argsort", "[", "subbatch_size", "]", "]", ">", "subbatch_max_tokens", ")", ":", "\n", "                ", "yield", "[", "sentences", "[", "i", "]", "for", "i", "in", "lens_argsort", "[", ":", "subbatch_size", "]", "]", ",", "[", "golds", "[", "i", "]", "for", "i", "in", "lens_argsort", "[", ":", "subbatch_size", "]", "]", "\n", "lens_argsort", "=", "lens_argsort", "[", "subbatch_size", ":", "]", "\n", "num_subbatches", "+=", "1", "\n", "subbatch_size", "=", "1", "\n", "", "else", ":", "\n", "                ", "subbatch_size", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.parse_batch": [[1482, 1866], ["KM_parser.ChartParser.train", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "KM_parser.BatchIndices", "from_numpy().requires_grad_", "from_numpy", "from_numpy", "from_numpy", "KM_parser.ChartParser.f_label", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "enumerate", "from_numpy().requires_grad_", "from_numpy", "isinstance", "max", "numpy.zeros", "numpy.zeros", "enumerate", "extra_content_annotations_list.append", "max", "numpy.zeros", "enumerate", "from_numpy().requires_grad_", "KM_parser.ChartParser.elmo.forward", "elmo_rep0[].view", "extra_content_annotations_list.append", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "from_numpy", "from_numpy", "from_numpy", "from_numpy", "KM_parser.ChartParser.bert", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "KM_parser.ChartParser.xlnet", "KM_parser.ChartParser.masked_select().reshape", "KM_parser.ChartParser.project_xlnet", "KM_parser.ChartParser.encoder", "KM_parser.ChartParser.project_bert", "KM_parser.ChartParser.masked_select().reshape", "KM_parser.ChartParser.masked_select().reshape", "enumerate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "zip", "KM_parser.ChartParser.dep_score", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "len", "KM_parser.ChartParser.word_vocab.index", "from_numpy", "max", "enumerate", "KM_parser.ChartParser.char_encoder", "enumerate", "KM_parser.ChartParser.project_elmo", "tokens.append", "word_start_mask.append", "word_end_mask.append", "tokens.append", "word_start_mask.append", "word_end_mask.append", "KM_parser.ChartParser.bert_tokenizer.convert_tokens_to_ids", "max", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "KM_parser.ChartParser.masked_select().reshape", "KM_parser.ChartParser.project_bert", "tokens.append", "word_start_mask.append", "word_end_mask.append", "KM_parser.ChartParser.xlnet_tokenizer.convert_tokens_to_ids", "max", "from_numpy", "from_numpy", "from_numpy", "from_numpy", "from_numpy", "from_numpy", "from_numpy", "from_numpy", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zip", "KM_parser.ChartParser.parse_from_annotations", "trees.append", "scores.append", "zip", "KM_parser.ChartParser.parse_from_annotations", "pis.append", "pjs.append", "gis.append", "gjs.append", "plabels.append", "glabels.append", "torch.gather.new_zeros", "torch.gather.new_zeros", "torch.gather.new_zeros", "cells_label_scores[].sum", "cells_label_scores[].sum", "KM_parser.ChartParser.type_vocab.index", "len", "len", "KM_parser.ChartParser.tag_vocab.index_or_unk", "KM_parser.ChartParser.word_vocab.count", "from_numpy", "max", "KM_parser.ChartParser.char_vocab.index", "KM_parser.ChartParser.char_vocab.index", "len", "len", "from_numpy", "len", "len", "len", "len", "KM_parser.ChartParser.bert_tokenizer.tokenize", "range", "tokens.extend", "len", "len", "len", "len", "len", "len", "tokens.append", "word_start_mask.append", "word_end_mask.append", "KM_parser.ChartParser.xlnet_tokenizer.tokenize", "range", "tokens.extend", "tokens.append", "word_start_mask.append", "word_end_mask.append", "len", "len", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "KM_parser.ChartParser.masked_select", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum", "len", "KM_parser.ChartParser.masked_select", "KM_parser.ChartParser.masked_select", "golds[].leaves", "golds[].leaves", "KM_parser.ChartParser.loss_funt", "KM_parser.ChartParser.char_vocab.index", "BERT_TOKEN_MAPPING.get.encode", "BERT_TOKEN_MAPPING.get", "cleaned_words.append", "KM_parser.ChartParser.bert_transliterate", "len", "word_start_mask.append", "word_end_mask.append", "KM_parser.ChartParser.masked_select", "BERT_TOKEN_MAPPING.get", "cleaned_words.append", "KM_parser.ChartParser.bert_transliterate", "len", "len", "word_start_mask.append", "word_end_mask.append", "from_numpy.to().unsqueeze", "from_numpy.to().unsqueeze", "from_numpy.to().unsqueeze", "torch.gather.size", "torch.gather.size", "torch.gather.size", "KM_parser.ChartParser.loss_func", "from_numpy().requires_grad_", "len", "KM_parser.ChartParser.char_vocab.index_or_unk", "elmo_mask.byte", "len", "len", "len", "len", "len", "from_numpy.to().unsqueeze", "len", "from_numpy().requires_grad_", "numpy.random.rand", "len", "len", "len", "len", "from_numpy.to", "range", "range", "from_numpy.to", "from_numpy.to", "from_numpy", "from_numpy.to", "len", "len", "len", "len", "from_numpy", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForQuestionAnswering.forward", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.parse_from_annotations", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.parse_from_annotations", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index_or_unk", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.count", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index_or_unk"], ["", "", "", "def", "parse_batch", "(", "self", ",", "sentences", ",", "golds", "=", "None", ")", ":", "\n", "        ", "is_train", "=", "golds", "is", "not", "None", "\n", "self", ".", "train", "(", "is_train", ")", "\n", "torch", ".", "set_grad_enabled", "(", "is_train", ")", "\n", "self", ".", "current_attns", "=", "None", "\n", "\n", "if", "golds", "is", "None", ":", "\n", "            ", "golds", "=", "[", "None", "]", "*", "len", "(", "sentences", ")", "\n", "\n", "", "packed_len", "=", "sum", "(", "[", "(", "len", "(", "sentence", ")", "+", "2", ")", "for", "sentence", "in", "sentences", "]", ")", "\n", "\n", "i", "=", "0", "\n", "tag_idxs", "=", "np", ".", "zeros", "(", "packed_len", ",", "dtype", "=", "int", ")", "\n", "word_idxs", "=", "np", ".", "zeros", "(", "packed_len", ",", "dtype", "=", "int", ")", "\n", "batch_idxs", "=", "np", ".", "zeros", "(", "packed_len", ",", "dtype", "=", "int", ")", "\n", "for", "snum", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "#print(sentence)", "\n", "            ", "for", "(", "tag", ",", "word", ")", "in", "[", "(", "START", ",", "START", ")", "]", "+", "sentence", "+", "[", "(", "STOP", ",", "STOP", ")", "]", ":", "\n", "                ", "tag_idxs", "[", "i", "]", "=", "0", "if", "(", "not", "self", ".", "use_tags", "and", "self", ".", "f_tag", "is", "None", ")", "else", "self", ".", "tag_vocab", ".", "index_or_unk", "(", "tag", ",", "TAG_UNK", ")", "\n", "if", "word", "not", "in", "(", "START", ",", "STOP", ")", ":", "\n", "                    ", "count", "=", "self", ".", "word_vocab", ".", "count", "(", "word", ")", "\n", "if", "not", "count", "or", "(", "is_train", "and", "np", ".", "random", ".", "rand", "(", ")", "<", "1", "/", "(", "1", "+", "count", ")", ")", ":", "\n", "                        ", "word", "=", "UNK", "\n", "", "", "word_idxs", "[", "i", "]", "=", "self", ".", "word_vocab", ".", "index", "(", "word", ")", "\n", "batch_idxs", "[", "i", "]", "=", "snum", "\n", "i", "+=", "1", "\n", "", "", "assert", "i", "==", "packed_len", "\n", "\n", "batch_idxs", "=", "BatchIndices", "(", "batch_idxs", ")", "\n", "\n", "emb_idxs_map", "=", "{", "\n", "'tags'", ":", "tag_idxs", ",", "\n", "'words'", ":", "word_idxs", ",", "\n", "}", "\n", "emb_idxs", "=", "[", "\n", "from_numpy", "(", "emb_idxs_map", "[", "emb_type", "]", ")", ".", "requires_grad_", "(", "False", ")", "\n", "for", "emb_type", "in", "self", ".", "emb_types", "\n", "]", "\n", "pre_words_idxs", "=", "from_numpy", "(", "word_idxs", ")", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "if", "is_train", "and", "self", ".", "f_tag", "is", "not", "None", ":", "\n", "            ", "gold_tag_idxs", "=", "from_numpy", "(", "emb_idxs_map", "[", "'tags'", "]", ")", "\n", "\n", "", "extra_content_annotations_list", "=", "[", "]", "\n", "extra_content_annotations", "=", "None", "\n", "if", "self", ".", "char_encoder", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "char_encoder", ",", "CharacterLSTM", ")", "\n", "max_word_len", "=", "max", "(", "[", "max", "(", "[", "len", "(", "word", ")", "for", "tag", ",", "word", "in", "sentence", "]", ")", "for", "sentence", "in", "sentences", "]", ")", "\n", "# Add 2 for start/stop tokens", "\n", "max_word_len", "=", "max", "(", "max_word_len", ",", "3", ")", "+", "2", "\n", "char_idxs_encoder", "=", "np", ".", "zeros", "(", "(", "packed_len", ",", "max_word_len", ")", ",", "dtype", "=", "int", ")", "\n", "word_lens_encoder", "=", "np", ".", "zeros", "(", "packed_len", ",", "dtype", "=", "int", ")", "\n", "i", "=", "0", "\n", "for", "snum", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                ", "for", "wordnum", ",", "(", "tag", ",", "word", ")", "in", "enumerate", "(", "[", "(", "START", ",", "START", ")", "]", "+", "sentence", "+", "[", "(", "STOP", ",", "STOP", ")", "]", ")", ":", "\n", "                    ", "j", "=", "0", "\n", "char_idxs_encoder", "[", "i", ",", "j", "]", "=", "self", ".", "char_vocab", ".", "index", "(", "CHAR_START_WORD", ")", "\n", "j", "+=", "1", "\n", "if", "word", "in", "(", "START", ",", "STOP", ")", ":", "\n", "                        ", "char_idxs_encoder", "[", "i", ",", "j", ":", "j", "+", "3", "]", "=", "self", ".", "char_vocab", ".", "index", "(", "\n", "CHAR_START_SENTENCE", "if", "(", "word", "==", "START", ")", "else", "CHAR_STOP_SENTENCE", "\n", ")", "\n", "j", "+=", "3", "\n", "", "else", ":", "\n", "                        ", "for", "char", "in", "word", ":", "\n", "                            ", "char_idxs_encoder", "[", "i", ",", "j", "]", "=", "self", ".", "char_vocab", ".", "index_or_unk", "(", "char", ",", "CHAR_UNK", ")", "\n", "j", "+=", "1", "\n", "", "", "char_idxs_encoder", "[", "i", ",", "j", "]", "=", "self", ".", "char_vocab", ".", "index", "(", "CHAR_STOP_WORD", ")", "\n", "word_lens_encoder", "[", "i", "]", "=", "j", "+", "1", "\n", "i", "+=", "1", "\n", "", "", "assert", "i", "==", "packed_len", "\n", "\n", "extra_content_annotations_list", ".", "append", "(", "self", ".", "char_encoder", "(", "char_idxs_encoder", ",", "word_lens_encoder", ",", "batch_idxs", ")", ")", "\n", "", "if", "self", ".", "elmo", "is", "not", "None", ":", "\n", "# See https://github.com/allenai/allennlp/blob/c3c3549887a6b1fb0bc8abf77bc820a3ab97f788/allennlp/data/token_indexers/elmo_indexer.py#L61", "\n", "# ELMO_START_SENTENCE = 256", "\n", "# ELMO_STOP_SENTENCE = 257", "\n", "            ", "ELMO_START_WORD", "=", "258", "\n", "ELMO_STOP_WORD", "=", "259", "\n", "ELMO_CHAR_PAD", "=", "260", "\n", "\n", "# Sentence start/stop tokens are added inside the ELMo module", "\n", "max_sentence_len", "=", "max", "(", "[", "(", "len", "(", "sentence", ")", ")", "for", "sentence", "in", "sentences", "]", ")", "\n", "max_word_len", "=", "50", "\n", "char_idxs_encoder", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "max_sentence_len", ",", "max_word_len", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "for", "snum", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                ", "for", "wordnum", ",", "(", "tag", ",", "word", ")", "in", "enumerate", "(", "sentence", ")", ":", "\n", "                    ", "char_idxs_encoder", "[", "snum", ",", "wordnum", ",", ":", "]", "=", "ELMO_CHAR_PAD", "\n", "\n", "j", "=", "0", "\n", "char_idxs_encoder", "[", "snum", ",", "wordnum", ",", "j", "]", "=", "ELMO_START_WORD", "\n", "j", "+=", "1", "\n", "assert", "word", "not", "in", "(", "START", ",", "STOP", ")", "\n", "for", "char_id", "in", "word", ".", "encode", "(", "'utf-8'", ",", "'ignore'", ")", "[", ":", "(", "max_word_len", "-", "2", ")", "]", ":", "\n", "                        ", "char_idxs_encoder", "[", "snum", ",", "wordnum", ",", "j", "]", "=", "char_id", "\n", "j", "+=", "1", "\n", "", "char_idxs_encoder", "[", "snum", ",", "wordnum", ",", "j", "]", "=", "ELMO_STOP_WORD", "\n", "\n", "# +1 for masking (everything that stays 0 is past the end of the sentence)", "\n", "char_idxs_encoder", "[", "snum", ",", "wordnum", ",", ":", "]", "+=", "1", "\n", "\n", "", "", "char_idxs_encoder", "=", "from_numpy", "(", "char_idxs_encoder", ")", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "elmo_out", "=", "self", ".", "elmo", ".", "forward", "(", "char_idxs_encoder", ")", "\n", "elmo_rep0", "=", "elmo_out", "[", "'elmo_representations'", "]", "[", "0", "]", "\n", "elmo_mask", "=", "elmo_out", "[", "'mask'", "]", "\n", "\n", "elmo_annotations_packed", "=", "elmo_rep0", "[", "elmo_mask", ".", "byte", "(", ")", "]", ".", "view", "(", "packed_len", ",", "-", "1", ")", "\n", "\n", "# Apply projection to match dimensionality", "\n", "extra_content_annotations_list", ".", "append", "(", "self", ".", "project_elmo", "(", "elmo_annotations_packed", ")", ")", "\n", "\n", "", "if", "self", ".", "bert", "is", "not", "None", ":", "\n", "            ", "all_input_ids", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "bert_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "all_input_mask", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "bert_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "all_word_start_mask", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "bert_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "all_word_end_mask", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "bert_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "subword_max_len", "=", "0", "\n", "for", "snum", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                ", "tokens", "=", "[", "]", "\n", "word_start_mask", "=", "[", "]", "\n", "word_end_mask", "=", "[", "]", "\n", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "word_start_mask", ".", "append", "(", "1", ")", "\n", "word_end_mask", ".", "append", "(", "1", ")", "\n", "\n", "if", "self", ".", "bert_transliterate", "is", "None", ":", "\n", "                    ", "cleaned_words", "=", "[", "]", "\n", "for", "_", ",", "word", "in", "sentence", ":", "\n", "                        ", "word", "=", "BERT_TOKEN_MAPPING", ".", "get", "(", "word", ",", "word", ")", "\n", "if", "word", "==", "\"n't\"", "and", "cleaned_words", ":", "\n", "                            ", "cleaned_words", "[", "-", "1", "]", "=", "cleaned_words", "[", "-", "1", "]", "+", "\"n\"", "\n", "word", "=", "\"'t\"", "\n", "", "cleaned_words", ".", "append", "(", "word", ")", "\n", "", "", "else", ":", "\n", "# When transliterating, assume that the token mapping is", "\n", "# taken care of elsewhere", "\n", "                    ", "cleaned_words", "=", "[", "self", ".", "bert_transliterate", "(", "word", ")", "for", "_", ",", "word", "in", "sentence", "]", "\n", "\n", "", "for", "word", "in", "cleaned_words", ":", "\n", "                    ", "word_tokens", "=", "self", ".", "bert_tokenizer", ".", "tokenize", "(", "word", ")", "\n", "for", "_", "in", "range", "(", "len", "(", "word_tokens", ")", ")", ":", "\n", "                        ", "word_start_mask", ".", "append", "(", "0", ")", "\n", "word_end_mask", ".", "append", "(", "0", ")", "\n", "", "word_start_mask", "[", "len", "(", "tokens", ")", "]", "=", "1", "\n", "word_end_mask", "[", "-", "1", "]", "=", "1", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "word_start_mask", ".", "append", "(", "1", ")", "\n", "word_end_mask", ".", "append", "(", "1", ")", "\n", "\n", "input_ids", "=", "self", ".", "bert_tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "subword_max_len", "=", "max", "(", "subword_max_len", ",", "len", "(", "input_ids", ")", ")", "\n", "\n", "all_input_ids", "[", "snum", ",", ":", "len", "(", "input_ids", ")", "]", "=", "input_ids", "\n", "all_input_mask", "[", "snum", ",", ":", "len", "(", "input_mask", ")", "]", "=", "input_mask", "\n", "all_word_start_mask", "[", "snum", ",", ":", "len", "(", "word_start_mask", ")", "]", "=", "word_start_mask", "\n", "all_word_end_mask", "[", "snum", ",", ":", "len", "(", "word_end_mask", ")", "]", "=", "word_end_mask", "\n", "\n", "", "all_input_ids", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_input_ids", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_input_mask", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_input_mask", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_word_start_mask", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_word_start_mask", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_word_end_mask", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_word_end_mask", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_encoder_layers", ",", "_", "=", "self", ".", "bert", "(", "all_input_ids", ",", "attention_mask", "=", "all_input_mask", ")", "\n", "del", "_", "\n", "features", "=", "all_encoder_layers", "[", "-", "1", "]", "\n", "\n", "if", "self", ".", "encoder", "is", "not", "None", ":", "\n", "                ", "features_packed", "=", "features", ".", "masked_select", "(", "all_word_end_mask", ".", "to", "(", "DTYPE", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "reshape", "(", "-", "1", ",", "features", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# For now, just project the features from the last word piece in each word", "\n", "extra_content_annotations", "=", "self", ".", "project_bert", "(", "features_packed", ")", "\n", "\n", "", "", "if", "self", ".", "xlnet", "is", "not", "None", ":", "\n", "#(XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]", "\n", "            ", "all_input_ids", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "xlnet_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "all_input_mask", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "xlnet_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "all_word_start_mask", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "xlnet_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "all_word_end_mask", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentences", ")", ",", "self", ".", "xlnet_max_len", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "subword_max_len", "=", "0", "\n", "for", "snum", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                ", "tokens", "=", "[", "]", "\n", "word_start_mask", "=", "[", "]", "\n", "word_end_mask", "=", "[", "]", "\n", "\n", "# tokens.append(\"[CLS]\")", "\n", "# word_start_mask.append(1)", "\n", "# word_end_mask.append(1)", "\n", "if", "not", "self", ".", "hparams", ".", "pad_left", ":", "\n", "                    ", "tokens", ".", "append", "(", "self", ".", "xlnet_tokenizer", ".", "cls_token", ")", "\n", "word_start_mask", ".", "append", "(", "1", ")", "\n", "word_end_mask", ".", "append", "(", "1", ")", "\n", "\n", "", "if", "self", ".", "bert_transliterate", "is", "None", ":", "\n", "                    ", "cleaned_words", "=", "[", "]", "\n", "for", "_", ",", "word", "in", "sentence", ":", "\n", "                        ", "word", "=", "BERT_TOKEN_MAPPING", ".", "get", "(", "word", ",", "word", ")", "\n", "if", "word", "==", "\"n't\"", "and", "cleaned_words", ":", "\n", "                            ", "cleaned_words", "[", "-", "1", "]", "=", "cleaned_words", "[", "-", "1", "]", "+", "\"n\"", "\n", "word", "=", "\"'t\"", "\n", "", "cleaned_words", ".", "append", "(", "word", ")", "\n", "", "", "else", ":", "\n", "# When transliterating, assume that the token mapping is", "\n", "# taken care of elsewhere", "\n", "                    ", "cleaned_words", "=", "[", "self", ".", "bert_transliterate", "(", "word", ")", "for", "_", ",", "word", "in", "sentence", "]", "\n", "\n", "", "for", "word", "in", "cleaned_words", ":", "\n", "                    ", "word_tokens", "=", "self", ".", "xlnet_tokenizer", ".", "tokenize", "(", "word", ")", "\n", "if", "len", "(", "word_tokens", ")", "==", "0", ":", "\n", "                        ", "word_tokens", "=", "[", "self", ".", "xlnet_tokenizer", ".", "unk_token", "]", "\n", "", "for", "_", "in", "range", "(", "len", "(", "word_tokens", ")", ")", ":", "\n", "                        ", "word_start_mask", ".", "append", "(", "0", ")", "\n", "word_end_mask", ".", "append", "(", "0", ")", "\n", "", "word_start_mask", "[", "len", "(", "tokens", ")", "]", "=", "1", "\n", "word_end_mask", "[", "-", "1", "]", "=", "1", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "", "tokens", ".", "append", "(", "self", ".", "xlnet_tokenizer", ".", "sep_token", ")", "\n", "word_start_mask", ".", "append", "(", "1", ")", "\n", "word_end_mask", ".", "append", "(", "1", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "pad_left", ":", "\n", "                    ", "tokens", ".", "append", "(", "self", ".", "xlnet_tokenizer", ".", "cls_token", ")", "\n", "word_start_mask", ".", "append", "(", "1", ")", "\n", "word_end_mask", ".", "append", "(", "1", ")", "\n", "\n", "", "input_ids", "=", "self", ".", "xlnet_tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "subword_max_len", "=", "max", "(", "subword_max_len", ",", "len", "(", "input_ids", ")", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "pad_left", ":", "\n", "                    ", "all_input_ids", "[", "snum", ",", "self", ".", "xlnet_max_len", "-", "len", "(", "input_ids", ")", ":", "]", "=", "input_ids", "\n", "all_input_mask", "[", "snum", ",", "self", ".", "xlnet_max_len", "-", "len", "(", "input_mask", ")", ":", "]", "=", "input_mask", "\n", "all_word_start_mask", "[", "snum", ",", "self", ".", "xlnet_max_len", "-", "len", "(", "word_start_mask", ")", ":", "]", "=", "word_start_mask", "\n", "all_word_end_mask", "[", "snum", ",", "self", ".", "xlnet_max_len", "-", "len", "(", "word_end_mask", ")", ":", "]", "=", "word_end_mask", "\n", "", "else", ":", "\n", "                    ", "all_input_ids", "[", "snum", ",", ":", "len", "(", "input_ids", ")", "]", "=", "input_ids", "\n", "all_input_mask", "[", "snum", ",", ":", "len", "(", "input_mask", ")", "]", "=", "input_mask", "\n", "all_word_start_mask", "[", "snum", ",", ":", "len", "(", "word_start_mask", ")", "]", "=", "word_start_mask", "\n", "all_word_end_mask", "[", "snum", ",", ":", "len", "(", "word_end_mask", ")", "]", "=", "word_end_mask", "\n", "\n", "", "", "if", "self", ".", "hparams", ".", "pad_left", ":", "\n", "                ", "all_input_ids", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_input_ids", "[", ":", ",", "self", ".", "xlnet_max_len", "-", "subword_max_len", ":", "]", ")", ")", "\n", "all_input_mask", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_input_mask", "[", ":", ",", "self", ".", "xlnet_max_len", "-", "subword_max_len", ":", "]", ")", ")", "\n", "all_word_start_mask", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_word_start_mask", "[", ":", ",", "self", ".", "xlnet_max_len", "-", "subword_max_len", ":", "]", ")", ")", "\n", "all_word_end_mask", "=", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "all_word_end_mask", "[", ":", ",", "self", ".", "xlnet_max_len", "-", "subword_max_len", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "all_input_ids", "=", "from_numpy", "(", "\n", "np", ".", "ascontiguousarray", "(", "all_input_ids", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_input_mask", "=", "from_numpy", "(", "\n", "np", ".", "ascontiguousarray", "(", "all_input_mask", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_word_start_mask", "=", "from_numpy", "(", "\n", "np", ".", "ascontiguousarray", "(", "all_word_start_mask", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "all_word_end_mask", "=", "from_numpy", "(", "\n", "np", ".", "ascontiguousarray", "(", "all_word_end_mask", "[", ":", ",", ":", "subword_max_len", "]", ")", ")", "\n", "\n", "", "transformer_outputs", "=", "self", ".", "xlnet", "(", "all_input_ids", ",", "attention_mask", "=", "all_input_mask", ")", "\n", "# features = all_encoder_layers[-1]", "\n", "features", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "features_packed", "=", "features", ".", "masked_select", "(", "all_word_end_mask", ".", "to", "(", "DTYPE", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "reshape", "(", "-", "1", ",", "\n", "features", ".", "shape", "[", "\n", "-", "1", "]", ")", "\n", "\n", "# For now, just project the features from the last word piece in each word", "\n", "extra_content_annotations", "=", "self", ".", "project_xlnet", "(", "features_packed", ")", "\n", "\n", "", "if", "self", ".", "encoder", "is", "not", "None", ":", "\n", "\n", "            ", "if", "len", "(", "extra_content_annotations_list", ")", ">", "1", ":", "\n", "                ", "if", "self", ".", "hparams", ".", "use_cat", ":", "\n", "                    ", "extra_content_annotations", "=", "torch", ".", "cat", "(", "extra_content_annotations_list", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "extra_content_annotations", "=", "sum", "(", "extra_content_annotations_list", ")", "\n", "", "", "elif", "len", "(", "extra_content_annotations_list", ")", "==", "1", ":", "\n", "                ", "extra_content_annotations", "=", "extra_content_annotations_list", "[", "0", "]", "\n", "\n", "", "annotations", ",", "self", ".", "current_attns", "=", "self", ".", "encoder", "(", "emb_idxs", ",", "pre_words_idxs", ",", "batch_idxs", ",", "extra_content_annotations", "=", "extra_content_annotations", ")", "\n", "\n", "if", "self", ".", "partitioned", "and", "not", "self", ".", "use_lal", ":", "\n", "                ", "annotations", "=", "torch", ".", "cat", "(", "[", "\n", "annotations", "[", ":", ",", "0", ":", ":", "2", "]", ",", "\n", "annotations", "[", ":", ",", "1", ":", ":", "2", "]", ",", "\n", "]", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "use_lal", "and", "not", "self", ".", "lal_combine_as_self", ":", "\n", "                ", "half_dim", "=", "self", ".", "lal_d_proj", "//", "2", "\n", "d_l", "=", "self", ".", "label_vocab", ".", "size", "-", "1", "\n", "fencepost_annotations", "=", "torch", ".", "cat", "(", "\n", "[", "annotations", "[", ":", "-", "1", ",", "(", "i", "*", "self", ".", "lal_d_proj", ")", ":", "(", "i", "*", "self", ".", "lal_d_proj", "+", "half_dim", ")", "]", "for", "i", "in", "range", "(", "d_l", ")", "]", "\n", "+", "[", "annotations", "[", "1", ":", ",", "(", "i", "*", "self", ".", "lal_d_proj", "+", "half_dim", ")", ":", "(", "(", "i", "+", "1", ")", "*", "self", ".", "lal_d_proj", ")", "]", "for", "i", "in", "range", "(", "d_l", ")", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "fencepost_annotations", "=", "torch", ".", "cat", "(", "[", "\n", "annotations", "[", ":", "-", "1", ",", ":", "self", ".", "d_model", "//", "2", "]", ",", "\n", "annotations", "[", "1", ":", ",", "self", ".", "d_model", "//", "2", ":", "]", ",", "\n", "]", ",", "1", ")", "\n", "\n", "", "fencepost_annotations_start", "=", "fencepost_annotations", "\n", "fencepost_annotations_end", "=", "fencepost_annotations", "\n", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "bert", "is", "not", "None", "\n", "features", "=", "self", ".", "project_bert", "(", "features", ")", "\n", "fencepost_annotations_start", "=", "features", ".", "masked_select", "(", "all_word_start_mask", ".", "to", "(", "DTYPE", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "reshape", "(", "-", "1", ",", "features", ".", "shape", "[", "-", "1", "]", ")", "\n", "fencepost_annotations_end", "=", "features", ".", "masked_select", "(", "all_word_end_mask", ".", "to", "(", "DTYPE", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "reshape", "(", "-", "1", ",", "features", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "fp_startpoints", "=", "batch_idxs", ".", "boundaries_np", "[", ":", "-", "1", "]", "\n", "fp_endpoints", "=", "batch_idxs", ".", "boundaries_np", "[", "1", ":", "]", "-", "1", "\n", "\n", "if", "not", "is_train", ":", "\n", "            ", "trees", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "i", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "zip", "(", "fp_startpoints", ",", "fp_endpoints", ")", ")", ":", "\n", "                ", "tree", ",", "score", "=", "self", ".", "parse_from_annotations", "(", "fencepost_annotations_start", "[", "start", ":", "end", ",", ":", "]", ",", "\n", "fencepost_annotations_end", "[", "start", ":", "end", ",", ":", "]", ",", "sentences", "[", "i", "]", ",", "i", ")", "\n", "trees", ".", "append", "(", "tree", ")", "\n", "scores", ".", "append", "(", "score", ")", "\n", "\n", "", "return", "trees", ",", "scores", "\n", "\n", "", "pis", "=", "[", "]", "\n", "pjs", "=", "[", "]", "\n", "plabels", "=", "[", "]", "\n", "paugment_total", "=", "0.0", "\n", "cun", "=", "0", "\n", "num_p", "=", "0", "\n", "gis", "=", "[", "]", "\n", "gjs", "=", "[", "]", "\n", "glabels", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "zip", "(", "fp_startpoints", ",", "fp_endpoints", ")", ")", ":", "\n", "\n", "                ", "p_i", ",", "p_j", ",", "p_label", ",", "p_augment", ",", "g_i", ",", "g_j", ",", "g_label", "=", "self", ".", "parse_from_annotations", "(", "fencepost_annotations_start", "[", "start", ":", "end", ",", ":", "]", ",", "fencepost_annotations_end", "[", "start", ":", "end", ",", ":", "]", ",", "sentences", "[", "i", "]", ",", "i", ",", "gold", "=", "golds", "[", "i", "]", ")", "\n", "\n", "paugment_total", "+=", "p_augment", "\n", "num_p", "+=", "p_i", ".", "shape", "[", "0", "]", "\n", "pis", ".", "append", "(", "p_i", "+", "start", ")", "\n", "pjs", ".", "append", "(", "p_j", "+", "start", ")", "\n", "gis", ".", "append", "(", "g_i", "+", "start", ")", "\n", "gjs", ".", "append", "(", "g_j", "+", "start", ")", "\n", "plabels", ".", "append", "(", "p_label", ")", "\n", "glabels", ".", "append", "(", "g_label", ")", "\n", "\n", "", "", "cells_i", "=", "from_numpy", "(", "np", ".", "concatenate", "(", "pis", "+", "gis", ")", ")", "\n", "cells_j", "=", "from_numpy", "(", "np", ".", "concatenate", "(", "pjs", "+", "gjs", ")", ")", "\n", "cells_label", "=", "from_numpy", "(", "np", ".", "concatenate", "(", "plabels", "+", "glabels", ")", ")", "\n", "\n", "cells_label_scores", "=", "self", ".", "f_label", "(", "fencepost_annotations_end", "[", "cells_j", "]", "-", "fencepost_annotations_start", "[", "cells_i", "]", ")", "\n", "cells_label_scores", "=", "torch", ".", "cat", "(", "[", "\n", "cells_label_scores", ".", "new_zeros", "(", "(", "cells_label_scores", ".", "size", "(", "0", ")", ",", "1", ")", ")", ",", "\n", "cells_label_scores", "\n", "]", ",", "1", ")", "\n", "cells_label_scores", "=", "torch", ".", "gather", "(", "cells_label_scores", ",", "1", ",", "cells_label", "[", ":", ",", "None", "]", ")", "\n", "loss", "=", "cells_label_scores", "[", ":", "num_p", "]", ".", "sum", "(", ")", "-", "cells_label_scores", "[", "num_p", ":", "]", ".", "sum", "(", ")", "+", "paugment_total", "\n", "\n", "cun", "=", "0", "\n", "for", "snum", ",", "(", "start", ",", "end", ")", "in", "enumerate", "(", "zip", "(", "fp_startpoints", ",", "fp_endpoints", ")", ")", ":", "\n", "\n", "#[start,....,end-1]->[<root>,1, 2,...,n]", "\n", "            ", "leng", "=", "end", "-", "start", "\n", "arc_score", ",", "type_score", "=", "self", ".", "dep_score", "(", "fencepost_annotations_start", "[", "start", ":", "end", ",", ":", "]", ",", "fencepost_annotations_end", "[", "start", ":", "end", ",", ":", "]", ")", "\n", "#arc_gather = gfather[cun] - start", "\n", "arc_gather", "=", "[", "leaf", ".", "father", "for", "leaf", "in", "golds", "[", "snum", "]", ".", "leaves", "(", ")", "]", "\n", "type_gather", "=", "[", "self", ".", "type_vocab", ".", "index", "(", "leaf", ".", "type", ")", "for", "leaf", "in", "golds", "[", "snum", "]", ".", "leaves", "(", ")", "]", "\n", "cun", "+=", "1", "\n", "assert", "len", "(", "arc_gather", ")", "==", "leng", "-", "1", "\n", "arc_score", "=", "torch", ".", "transpose", "(", "arc_score", ",", "0", ",", "1", ")", "\n", "loss", "=", "loss", "+", "0.5", "*", "self", ".", "loss_func", "(", "arc_score", "[", "1", ":", ",", ":", "]", ",", "from_numpy", "(", "np", ".", "array", "(", "arc_gather", ")", ")", ".", "requires_grad_", "(", "False", ")", ")", "+", "0.5", "*", "self", ".", "loss_funt", "(", "type_score", "[", "1", ":", ",", ":", "]", ",", "from_numpy", "(", "np", ".", "array", "(", "type_gather", ")", ")", ".", "requires_grad_", "(", "False", ")", ")", "\n", "\n", "", "return", "None", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.label_scores_from_annotations": [[1867, 1893], ["KM_parser.ChartParser.f_label", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "numpy.zeros", "range", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "range", "numpy.min", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "span_features[].sum", "span_features[].sum", "numpy.max", "numpy.min"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "label_scores_from_annotations", "(", "self", ",", "fencepost_annotations_start", ",", "fencepost_annotations_end", ")", ":", "\n", "\n", "        ", "span_features", "=", "(", "torch", ".", "unsqueeze", "(", "fencepost_annotations_end", ",", "0", ")", "\n", "-", "torch", ".", "unsqueeze", "(", "fencepost_annotations_start", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "contributions", "and", "self", ".", "use_lal", ":", "\n", "            ", "contributions", "=", "np", ".", "zeros", "(", "(", "span_features", ".", "shape", "[", "0", "]", ",", "span_features", ".", "shape", "[", "1", "]", ",", "span_features", ".", "shape", "[", "2", "]", "//", "self", ".", "lal_d_proj", ")", ")", "\n", "half_vector", "=", "span_features", ".", "shape", "[", "-", "1", "]", "//", "2", "\n", "half_dim", "=", "self", ".", "lal_d_proj", "//", "2", "\n", "for", "i", "in", "range", "(", "contributions", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "contributions", ".", "shape", "[", "1", "]", ")", ":", "\n", "                    ", "for", "l", "in", "range", "(", "contributions", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "                        ", "contributions", "[", "i", ",", "j", ",", "l", "]", "=", "span_features", "[", "i", ",", "j", ",", "l", "*", "half_dim", ":", "(", "l", "+", "1", ")", "*", "half_dim", "]", ".", "sum", "(", ")", "+", "span_features", "[", "i", ",", "j", ",", "half_vector", "+", "l", "*", "half_dim", ":", "half_vector", "+", "(", "l", "+", "1", ")", "*", "half_dim", "]", ".", "sum", "(", ")", "\n", "", "contributions", "[", "i", ",", "j", ",", ":", "]", "=", "(", "contributions", "[", "i", ",", "j", ",", ":", "]", "-", "np", ".", "min", "(", "contributions", "[", "i", ",", "j", ",", ":", "]", ")", ")", "\n", "contributions", "[", "i", ",", "j", ",", ":", "]", "=", "(", "contributions", "[", "i", ",", "j", ",", ":", "]", ")", "/", "(", "np", ".", "max", "(", "contributions", "[", "i", ",", "j", ",", ":", "]", ")", "-", "np", ".", "min", "(", "contributions", "[", "i", ",", "j", ",", ":", "]", ")", ")", "\n", "#contributions[i,j,:] = contributions[i,j,:]/np.sum(contributions[i,j,:])", "\n", "", "", "contributions", "=", "torch", ".", "softmax", "(", "torch", ".", "Tensor", "(", "contributions", ")", ",", "-", "1", ")", "\n", "\n", "", "label_scores_chart", "=", "self", ".", "f_label", "(", "span_features", ")", "\n", "label_scores_chart", "=", "torch", ".", "cat", "(", "[", "\n", "label_scores_chart", ".", "new_zeros", "(", "(", "label_scores_chart", ".", "size", "(", "0", ")", ",", "label_scores_chart", ".", "size", "(", "1", ")", ",", "1", ")", ")", ",", "\n", "label_scores_chart", "\n", "]", ",", "2", ")", "\n", "if", "self", ".", "contributions", "and", "self", ".", "use_lal", ":", "\n", "            ", "return", "label_scores_chart", ",", "contributions", "\n", "", "return", "label_scores_chart", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.parse_from_annotations": [[1894, 1924], ["KM_parser.ChartParser.cpu().data.numpy", "KM_parser.ChartParser.label_scores_from_annotations", "KM_parser.ChartParser.label_scores_from_annotations", "dict", "const_decoder.decode", "const_decoder.decode", "KM_parser.ChartParser.dep_score", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose.cpu().data.numpy", "torch.transpose.cpu().data.numpy", "torch.transpose.cpu().data.numpy", "type_score.cpu().data.numpy", "type_score.cpu().data.numpy.argmax", "KM_parser.ChartParser.decode_from_chart", "KM_parser.ChartParser.cpu", "len", "torch.transpose.cpu", "torch.transpose.cpu", "torch.transpose.cpu", "type_score.cpu"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.label_scores_from_annotations", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.label_scores_from_annotations", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.decode_from_chart"], ["", "def", "parse_from_annotations", "(", "self", ",", "fencepost_annotations_start", ",", "fencepost_annotations_end", ",", "sentence", ",", "sentence_idx", ",", "gold", "=", "None", ")", ":", "\n", "        ", "is_train", "=", "gold", "is", "not", "None", "\n", "contributions", "=", "None", "\n", "if", "self", ".", "contributions", "and", "self", ".", "use_lal", ":", "\n", "            ", "label_scores_chart", ",", "contributions", "=", "self", ".", "label_scores_from_annotations", "(", "fencepost_annotations_start", ",", "fencepost_annotations_end", ")", "\n", "", "else", ":", "\n", "            ", "label_scores_chart", "=", "self", ".", "label_scores_from_annotations", "(", "fencepost_annotations_start", ",", "fencepost_annotations_end", ")", "\n", "", "label_scores_chart_np", "=", "label_scores_chart", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "if", "is_train", ":", "\n", "            ", "decoder_args", "=", "dict", "(", "\n", "sentence_len", "=", "len", "(", "sentence", ")", ",", "\n", "label_scores_chart", "=", "label_scores_chart_np", ",", "\n", "gold", "=", "gold", ",", "\n", "label_vocab", "=", "self", ".", "label_vocab", ",", "\n", "is_train", "=", "is_train", ")", "\n", "\n", "p_score", ",", "p_i", ",", "p_j", ",", "p_label", ",", "p_augment", "=", "const_decoder", ".", "decode", "(", "False", ",", "**", "decoder_args", ")", "\n", "g_score", ",", "g_i", ",", "g_j", ",", "g_label", ",", "g_augment", "=", "const_decoder", ".", "decode", "(", "True", ",", "**", "decoder_args", ")", "\n", "return", "p_i", ",", "p_j", ",", "p_label", ",", "p_augment", ",", "g_i", ",", "g_j", ",", "g_label", "\n", "", "else", ":", "\n", "            ", "arc_score", ",", "type_score", "=", "self", ".", "dep_score", "(", "fencepost_annotations_start", ",", "fencepost_annotations_end", ")", "\n", "\n", "arc_score_dc", "=", "torch", ".", "transpose", "(", "arc_score", ",", "0", ",", "1", ")", "\n", "arc_dc_np", "=", "arc_score_dc", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "type_np", "=", "type_score", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "type_np", "=", "type_np", "[", "1", ":", ",", ":", "]", "# remove root", "\n", "type", "=", "type_np", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "return", "self", ".", "decode_from_chart", "(", "sentence", ",", "label_scores_chart_np", ",", "arc_dc_np", ",", "type", ",", "sentence_idx", "=", "sentence_idx", ",", "contributions", "=", "contributions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.decode_from_chart_batch": [[1925, 1935], ["zip", "KM_parser.ChartParser.decode_from_chart", "trees.append", "scores.append", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.decode_from_chart"], ["", "", "def", "decode_from_chart_batch", "(", "self", ",", "sentences", ",", "charts_np", ",", "golds", "=", "None", ")", ":", "\n", "        ", "trees", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "if", "golds", "is", "None", ":", "\n", "            ", "golds", "=", "[", "None", "]", "*", "len", "(", "sentences", ")", "\n", "", "for", "sentence", ",", "chart_np", ",", "gold", "in", "zip", "(", "sentences", ",", "charts_np", ",", "golds", ")", ":", "\n", "            ", "tree", ",", "score", "=", "self", ".", "decode_from_chart", "(", "sentence", ",", "chart_np", ",", "gold", ")", "\n", "trees", ".", "append", "(", "tree", ")", "\n", "scores", ".", "append", "(", "score", ")", "\n", "", "return", "trees", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.decode_from_chart": [[1936, 1995], ["dict", "hpsg_decoder.decode", "KM_parser.ChartParser.decode_from_chart.make_tree"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "decode_from_chart", "(", "self", ",", "sentence", ",", "label_scores_chart_np", ",", "arc_dc_np", ",", "type", ",", "sentence_idx", "=", "None", ",", "gold", "=", "None", ",", "contributions", "=", "None", ")", ":", "\n", "\n", "        ", "decoder_args", "=", "dict", "(", "\n", "sentence_len", "=", "len", "(", "sentence", ")", ",", "\n", "label_scores_chart", "=", "label_scores_chart_np", "*", "self", ".", "hparams", ".", "const_lada", ",", "\n", "type_scores_chart", "=", "arc_dc_np", "*", "(", "1.0", "-", "self", ".", "hparams", ".", "const_lada", ")", ",", "\n", "gold", "=", "gold", ",", "\n", "label_vocab", "=", "self", ".", "label_vocab", ",", "\n", "type_vocab", "=", "self", ".", "type_vocab", ",", "\n", "is_train", "=", "False", ")", "\n", "\n", "force_gold", "=", "(", "gold", "is", "not", "None", ")", "\n", "\n", "# The optimized cython decoder implementation doesn't actually", "\n", "# generate trees, only scores and span indices. When converting to a", "\n", "# tree, we assume that the indices follow a preorder traversal.", "\n", "\n", "score", ",", "p_i", ",", "p_j", ",", "p_label", ",", "p_father", ",", "p_type", ",", "_", "=", "hpsg_decoder", ".", "decode", "(", "force_gold", ",", "**", "decoder_args", ")", "\n", "if", "contributions", "is", "not", "None", ":", "\n", "            ", "d_l", "=", "(", "self", ".", "label_vocab", ".", "size", "-", "2", ")", "\n", "mb_size", "=", "(", "self", ".", "current_attns", ".", "shape", "[", "0", "]", "//", "d_l", ")", "\n", "print", "(", "'SENTENCE'", ",", "sentence", ")", "\n", "\n", "", "idx", "=", "-", "1", "\n", "def", "make_tree", "(", ")", ":", "\n", "            ", "nonlocal", "idx", "\n", "idx", "+=", "1", "\n", "i", ",", "j", ",", "label_idx", "=", "p_i", "[", "idx", "]", ",", "p_j", "[", "idx", "]", ",", "p_label", "[", "idx", "]", "\n", "label", "=", "self", ".", "label_vocab", ".", "value", "(", "label_idx", ")", "\n", "if", "contributions", "is", "not", "None", ":", "\n", "                ", "if", "label_idx", ">", "0", ":", "\n", "                    ", "print", "(", "i", ",", "sentence", "[", "i", "]", ",", "j", ",", "sentence", "[", "j", "-", "1", "]", ",", "label", ",", "label_idx", ",", "contributions", "[", "i", ",", "j", ",", "label_idx", "-", "1", "]", ")", "\n", "print", "(", "\"CONTRIBUTIONS\"", ")", "\n", "print", "(", "list", "(", "enumerate", "(", "contributions", "[", "i", ",", "j", "]", ")", ")", ")", "\n", "print", "(", "\"ATTENTION DIST\"", ")", "\n", "print", "(", "torch", ".", "softmax", "(", "self", ".", "current_attns", "[", "sentence_idx", ":", ":", "mb_size", ",", "0", ",", "i", ":", "j", "+", "1", "]", ",", "-", "1", ")", ")", "\n", "", "", "if", "(", "i", "+", "1", ")", ">=", "j", ":", "\n", "                ", "tag", ",", "word", "=", "sentence", "[", "i", "]", "\n", "if", "type", "is", "not", "None", ":", "\n", "                    ", "tree", "=", "trees", ".", "LeafParseNode", "(", "int", "(", "i", ")", ",", "tag", ",", "word", ",", "p_father", "[", "i", "]", ",", "self", ".", "type_vocab", ".", "value", "(", "type", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "tree", "=", "trees", ".", "LeafParseNode", "(", "int", "(", "i", ")", ",", "tag", ",", "word", ",", "p_father", "[", "i", "]", ",", "self", ".", "type_vocab", ".", "value", "(", "p_type", "[", "i", "]", ")", ")", "\n", "", "if", "label", ":", "\n", "                    ", "assert", "label", "[", "0", "]", "!=", "Sub_Head", "\n", "tree", "=", "trees", ".", "InternalParseNode", "(", "label", ",", "[", "tree", "]", ")", "\n", "", "return", "[", "tree", "]", "\n", "", "else", ":", "\n", "                ", "left_trees", "=", "make_tree", "(", ")", "\n", "right_trees", "=", "make_tree", "(", ")", "\n", "children", "=", "left_trees", "+", "right_trees", "\n", "if", "label", "and", "label", "[", "0", "]", "!=", "Sub_Head", ":", "\n", "                    ", "return", "[", "trees", ".", "InternalParseNode", "(", "label", ",", "children", ")", "]", "\n", "", "else", ":", "\n", "                    ", "return", "children", "\n", "\n", "", "", "", "tree_list", "=", "make_tree", "(", ")", "\n", "assert", "len", "(", "tree_list", ")", "==", "1", "\n", "tree", "=", "tree_list", "[", "0", "]", "\n", "return", "tree", ",", "score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_elmo_class": [[642, 691], ["inputs.size", "KM_parser.._elmo_lstm", "range", "len", "len", "getattr", "getattr.", "representations.append", "KM_parser.._dropout"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "get_elmo_class", "(", ")", ":", "\n", "# Avoid a hard dependency by only importing Elmo if it's being used", "\n", "    ", "from", "allennlp", ".", "modules", ".", "elmo", "import", "Elmo", "\n", "\n", "class", "ModElmo", "(", "Elmo", ")", ":", "\n", "       ", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "            ", "\"\"\"\n            Unlike Elmo.forward, return vector representations for bos/eos tokens\n\n            This modified version does not support extra tensor dimensions\n\n            Parameters\n            ----------\n            inputs : ``torch.autograd.Variable``\n                Shape ``(batch_size, timesteps, 50)`` of character ids representing the current batch.\n\n            Returns\n            -------\n            Dict with keys:\n            ``'elmo_representations'``: ``List[torch.autograd.Variable]``\n                A ``num_output_representations`` list of ELMo representations for the input sequence.\n                Each representation is shape ``(batch_size, timesteps + 2, embedding_dim)``\n            ``'mask'``:  ``torch.autograd.Variable``\n                Shape ``(batch_size, timesteps + 2)`` long tensor with sequence mask.\n            \"\"\"", "\n", "# reshape the input if needed", "\n", "original_shape", "=", "inputs", ".", "size", "(", ")", "\n", "timesteps", ",", "num_characters", "=", "original_shape", "[", "-", "2", ":", "]", "\n", "assert", "len", "(", "original_shape", ")", "==", "3", ",", "\"Only 3D tensors supported here\"", "\n", "reshaped_inputs", "=", "inputs", "\n", "\n", "# run the biLM", "\n", "bilm_output", "=", "self", ".", "_elmo_lstm", "(", "reshaped_inputs", ")", "\n", "layer_activations", "=", "bilm_output", "[", "'activations'", "]", "\n", "mask_with_bos_eos", "=", "bilm_output", "[", "'mask'", "]", "\n", "\n", "# compute the elmo representations", "\n", "representations", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_scalar_mixes", ")", ")", ":", "\n", "                ", "scalar_mix", "=", "getattr", "(", "self", ",", "'scalar_mix_{}'", ".", "format", "(", "i", ")", ")", "\n", "representation_with_bos_eos", "=", "scalar_mix", "(", "layer_activations", ",", "mask_with_bos_eos", ")", "\n", "# We don't remove bos/eos here!", "\n", "representations", ".", "append", "(", "self", ".", "_dropout", "(", "representation_with_bos_eos", ")", ")", "\n", "\n", "", "mask", "=", "mask_with_bos_eos", "\n", "elmo_representations", "=", "representations", "\n", "\n", "return", "{", "'elmo_representations'", ":", "elmo_representations", ",", "'mask'", ":", "mask", "}", "\n", "", "", "return", "ModElmo", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_xlnet": [[692, 703], ["XLNetTokenizer.from_pretrained", "XLNetModel.from_pretrained"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "def", "get_xlnet", "(", "xlnet_model", ",", "xlnet_do_lower_case", ")", ":", "\n", "# Avoid a hard dependency on BERT by only importing it if it's being used", "\n", "    ", "from", "transformers", "import", "(", "WEIGHTS_NAME", ",", "XLNetModel", ",", "\n", "XLMConfig", ",", "XLMForSequenceClassification", ",", "\n", "XLMTokenizer", ",", "XLNetConfig", ",", "\n", "XLNetForSequenceClassification", ",", "\n", "XLNetTokenizer", ")", "\n", "tokenizer", "=", "XLNetTokenizer", ".", "from_pretrained", "(", "xlnet_model", ",", "do_lower_case", "=", "xlnet_do_lower_case", ")", "\n", "xlnet", "=", "XLNetModel", ".", "from_pretrained", "(", "xlnet_model", ")", "\n", "\n", "return", "tokenizer", ",", "xlnet", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_roberta": [[704, 714], ["RobertaTokenizer.from_pretrained", "RobertaModel.from_pretrained"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "def", "get_roberta", "(", "roberta_model", ",", "roberta_do_lower_case", ")", ":", "\n", "# Avoid a hard dependency on BERT by only importing it if it's being used", "\n", "    ", "from", "transformers", "import", "(", "WEIGHTS_NAME", ",", "RobertaModel", ",", "\n", "RobertaConfig", ",", "\n", "RobertaForSequenceClassification", ",", "\n", "RobertaTokenizer", ")", "\n", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "roberta_model", ",", "do_lower_case", "=", "roberta_do_lower_case", ",", "add_special_tokens", "=", "True", ")", "\n", "roberta", "=", "RobertaModel", ".", "from_pretrained", "(", "roberta_model", ")", "\n", "\n", "return", "tokenizer", ",", "roberta", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.get_bert": [[716, 725], ["bert_model.endswith", "BertModel.from_pretrained", "BertTokenizer.from_pretrained", "BertTokenizer.from_pretrained", "bert_model.replace"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "def", "get_bert", "(", "bert_model", ",", "bert_do_lower_case", ")", ":", "\n", "# Avoid a hard dependency on BERT by only importing it if it's being used", "\n", "    ", "from", "pretrained_bert", "import", "BertTokenizer", ",", "BertModel", "\n", "if", "bert_model", ".", "endswith", "(", "'.tar.gz'", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ".", "replace", "(", "'.tar.gz'", ",", "'-vocab.txt'", ")", ",", "do_lower_case", "=", "bert_do_lower_case", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ",", "do_lower_case", "=", "bert_do_lower_case", ")", "\n", "", "bert", "=", "BertModel", ".", "from_pretrained", "(", "bert_model", ")", "\n", "return", "tokenizer", ",", "bert", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.__init__": [[4, 9], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "frozen", "=", "False", "\n", "self", ".", "values", "=", "[", "]", "\n", "self", ".", "indices", "=", "{", "}", "\n", "self", ".", "counts", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size": [[10, 13], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.value": [[14, 17], ["len"], "methods", ["None"], ["", "def", "value", "(", "self", ",", "index", ")", ":", "\n", "        ", "assert", "0", "<=", "index", "<", "len", "(", "self", ".", "values", ")", "\n", "return", "self", ".", "values", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index": [[18, 32], ["vocabulary.Vocabulary.values.append", "ValueError", "len"], "methods", ["None"], ["", "def", "index", "(", "self", ",", "value", ")", ":", "\n", "        ", "if", "not", "self", ".", "frozen", ":", "\n", "            ", "self", ".", "counts", "[", "value", "]", "+=", "1", "\n", "\n", "", "if", "value", "in", "self", ".", "indices", ":", "\n", "            ", "return", "self", ".", "indices", "[", "value", "]", "\n", "\n", "", "elif", "not", "self", ".", "frozen", ":", "\n", "            ", "self", ".", "values", ".", "append", "(", "value", ")", "\n", "self", ".", "indices", "[", "value", "]", "=", "len", "(", "self", ".", "values", ")", "-", "1", "\n", "return", "self", ".", "indices", "[", "value", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown value: {}\"", ".", "format", "(", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index_or_unk": [[33, 39], ["None"], "methods", ["None"], ["", "", "def", "index_or_unk", "(", "self", ",", "value", ",", "unk_value", ")", ":", "\n", "        ", "assert", "self", ".", "frozen", "\n", "if", "value", "in", "self", ".", "indices", ":", "\n", "            ", "return", "self", ".", "indices", "[", "value", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "indices", "[", "unk_value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.count": [[40, 42], ["None"], "methods", ["None"], ["", "", "def", "count", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "counts", "[", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.freeze": [[43, 45], ["None"], "methods", ["None"], ["", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "self", ".", "frozen", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.torch_load": [[30, 35], ["torch.load", "torch.load", "torch.load", "torch.load"], "function", ["None"], ["def", "torch_load", "(", "load_path", ")", ":", "\n", "    ", "if", "KM_parser", ".", "use_cuda", ":", "\n", "        ", "return", "torch", ".", "load", "(", "load_path", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.format_elapsed": [[36, 45], ["int", "divmod", "divmod", "divmod", "time.time"], "function", ["None"], ["", "", "def", "format_elapsed", "(", "start_time", ")", ":", "\n", "    ", "elapsed_time", "=", "int", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "\n", "minutes", ",", "seconds", "=", "divmod", "(", "elapsed_time", ",", "60", ")", "\n", "hours", ",", "minutes", "=", "divmod", "(", "minutes", ",", "60", ")", "\n", "days", ",", "hours", "=", "divmod", "(", "hours", ",", "24", ")", "\n", "elapsed_string", "=", "\"{}h{:02}m{:02}s\"", ".", "format", "(", "hours", ",", "minutes", ",", "seconds", ")", "\n", "if", "days", ">", "0", ":", "\n", "        ", "elapsed_string", "=", "\"{}d{}\"", ".", "format", "(", "days", ",", "elapsed_string", ")", "\n", "", "return", "elapsed_string", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.make_hparams": [[46, 122], ["makehp.HParams"], "function", ["None"], ["", "def", "make_hparams", "(", ")", ":", "\n", "    ", "return", "makehp", ".", "HParams", "(", "\n", "max_len_train", "=", "0", ",", "# no length limit", "\n", "max_len_dev", "=", "0", ",", "# no length limit", "\n", "\n", "sentence_max_len", "=", "300", ",", "\n", "\n", "learning_rate", "=", "0.0008", ",", "\n", "learning_rate_warmup_steps", "=", "160", ",", "\n", "clip_grad_norm", "=", "0.", ",", "#no clipping", "\n", "step_decay", "=", "True", ",", "# note that disabling step decay is not implemented", "\n", "step_decay_factor", "=", "0.5", ",", "\n", "step_decay_patience", "=", "5", ",", "\n", "\n", "partitioned", "=", "True", ",", "\n", "\n", "use_cat", "=", "False", ",", "\n", "const_lada", "=", "0.5", ",", "\n", "\n", "num_layers", "=", "12", ",", "\n", "d_model", "=", "1024", ",", "\n", "num_heads", "=", "8", ",", "\n", "d_kv", "=", "64", ",", "\n", "d_ff", "=", "2048", ",", "\n", "d_label_hidden", "=", "250", ",", "\n", "d_biaffine", "=", "1024", ",", "\n", "\n", "# Label Attention Layer", "\n", "use_lal", "=", "True", ",", "# Whether the LAL is used at all", "\n", "lal_d_kv", "=", "64", ",", "# Dimension of Key and Query Vectors in the LAL", "\n", "lal_d_proj", "=", "64", ",", "# Dimension of the output vector from each label attention head", "\n", "lal_resdrop", "=", "True", ",", "# True means the LAL uses Residual Dropout", "\n", "lal_pwff", "=", "True", ",", "# True means the LAL has a Position-wise Feed-forward Layer", "\n", "lal_q_as_matrix", "=", "False", ",", "# False means the LAL uses learned query vectors", "\n", "lal_partitioned", "=", "True", ",", "# Partitioned as per the Berkeley Self-Attentive Parser", "\n", "lal_combine_as_self", "=", "False", ",", "# False means the LAL uses concatenation", "\n", "\n", "attention_dropout", "=", "0.2", ",", "\n", "embedding_dropout", "=", "0.2", ",", "\n", "relu_dropout", "=", "0.2", ",", "\n", "residual_dropout", "=", "0.2", ",", "\n", "\n", "use_tags", "=", "False", ",", "\n", "use_words", "=", "False", ",", "\n", "use_elmo", "=", "False", ",", "\n", "use_bert", "=", "False", ",", "\n", "use_xlnet", "=", "False", ",", "\n", "use_roberta", "=", "False", ",", "\n", "use_bert_only", "=", "False", ",", "\n", "use_chars_lstm", "=", "False", ",", "\n", "\n", "dataset", "=", "'ptb'", ",", "\n", "\n", "model_name", "=", "\"joint\"", ",", "\n", "embedding_type", "=", "'random'", ",", "\n", "#['glove','sskip','random']", "\n", "embedding_path", "=", "\"/data/glove.gz\"", ",", "\n", "punctuation", "=", "'.'", "'``'", "\"''\"", "':'", "','", ",", "\n", "\n", "d_char_emb", "=", "64", ",", "# A larger value may be better for use_chars_lstm", "\n", "\n", "tag_emb_dropout", "=", "0.2", ",", "\n", "word_emb_dropout", "=", "0.4", ",", "\n", "morpho_emb_dropout", "=", "0.2", ",", "\n", "timing_dropout", "=", "0.0", ",", "\n", "char_lstm_input_dropout", "=", "0.2", ",", "\n", "elmo_dropout", "=", "0.5", ",", "# Note that this semi-stacks with morpho_emb_dropout!", "\n", "\n", "bert_model", "=", "\"bert-large-uncased\"", ",", "\n", "bert_do_lower_case", "=", "True", ",", "\n", "bert_transliterate", "=", "\"\"", ",", "\n", "xlnet_model", "=", "\"xlnet-large-cased\"", ",", "\n", "xlnet_do_lower_case", "=", "False", ",", "\n", "pad_left", "=", "False", ",", "\n", "roberta_model", "=", "\"roberta-large\"", ",", "\n", "roberta_do_lower_case", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.count_wh": [[124, 135], ["enumerate", "print", "nodes.pop", "isinstance", "nodes.extend", "reversed"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["", "def", "count_wh", "(", "str", ",", "data", ",", "heads", ",", "types", ")", ":", "\n", "    ", "cun_w", "=", "0", "\n", "for", "i", ",", "c_tree", "in", "enumerate", "(", "data", ")", ":", "\n", "        ", "nodes", "=", "[", "c_tree", "]", "\n", "while", "nodes", ":", "\n", "            ", "node", "=", "nodes", ".", "pop", "(", ")", "\n", "if", "isinstance", "(", "node", ",", "trees", ".", "InternalParseNode", ")", ":", "\n", "                ", "cun_w", "+=", "node", ".", "cun_w", "\n", "nodes", ".", "extend", "(", "reversed", "(", "node", ".", "children", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"total wrong head of :\"", ",", "str", ",", "\"is\"", ",", "cun_w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.run_train": [[136, 533], ["numpy.random.randint", "print", "torch.manual_seed", "torch.manual_seed", "hparams.set_from_args", "print", "hparams.print", "dep_reader.CoNLLXReader", "print", "dep_reader.CoNLLXReader", "print", "dep_reader.CoNLLXReader.getNext", "dep_reader.CoNLLXReader.close", "print", "dep_reader.CoNLLXReader.getNext", "numpy.zeros", "numpy.zeros", "dep_reader.CoNLLXReader.close", "print", "trees.load_trees", "print", "print", "trees.load_trees", "print", "print", "main.count_wh", "main.count_wh", "print", "vocabulary.Vocabulary", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary", "set", "enumerate", "vocabulary.Vocabulary", "max", "vocabulary.Vocabulary.freeze", "vocabulary.Vocabulary.freeze", "vocabulary.Vocabulary.freeze", "vocabulary.Vocabulary.freeze", "vocabulary.Vocabulary.freeze", "print", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "print", "print", "time.time", "itertools.count", "print", "numpy.random.seed", "dep_reader.getNext.length", "dep_data.append", "dep_sentences.append", "dep_heads.append", "dep_types.append", "dep_reader.CoNLLXReader.getNext", "dep_dev_reader.getNext.length", "dep_dev_data.append", "range", "dep_dev_type.append", "dep_dev_word.append", "dep_dev_pos.append", "dep_reader.CoNLLXReader.getNext", "tree.convert", "tree.convert", "tuple", "range", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "vocabulary.Vocabulary.index", "sorted", "print", "main.run_train.print_vocabulary"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.set_from_args", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.load_trees", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.load_trees", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.count_wh", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.count_wh", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.freeze", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.freeze", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.freeze", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.freeze", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.freeze", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.count", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.DependencyInstance.length", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.DependencyInstance.length", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["", "def", "run_train", "(", "args", ",", "hparams", ")", ":", "\n", "    ", "if", "args", ".", "numpy_seed", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Setting numpy random seed to {}...\"", ".", "format", "(", "args", ".", "numpy_seed", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "numpy_seed", ")", "\n", "\n", "# Make sure that pytorch is actually being initialized randomly.", "\n", "# On my cluster I was getting highly correlated results from multiple", "\n", "# runs, but calling reset_parameters() changed that. A brief look at the", "\n", "# pytorch source code revealed that pytorch initializes its RNG by", "\n", "# calling std::random_device, which according to the C++ spec is allowed", "\n", "# to be deterministic.", "\n", "", "seed_from_numpy", "=", "np", ".", "random", ".", "randint", "(", "2147483648", ")", "\n", "print", "(", "\"Manual seed for pytorch:\"", ",", "seed_from_numpy", ")", "\n", "torch", ".", "manual_seed", "(", "seed_from_numpy", ")", "\n", "\n", "hparams", ".", "set_from_args", "(", "args", ")", "\n", "print", "(", "\"Hyperparameters:\"", ")", "\n", "hparams", ".", "print", "(", ")", "\n", "\n", "train_path", "=", "args", ".", "train_ptb_path", "\n", "dev_path", "=", "args", ".", "dev_ptb_path", "\n", "\n", "dep_train_path", "=", "args", ".", "dep_train_ptb_path", "\n", "dep_dev_path", "=", "args", ".", "dep_dev_ptb_path", "\n", "\n", "if", "hparams", ".", "dataset", "==", "'ctb'", ":", "\n", "        ", "train_path", "=", "args", ".", "train_ctb_path", "\n", "dev_path", "=", "args", ".", "dev_ctb_path", "\n", "\n", "dep_train_path", "=", "args", ".", "dep_train_ctb_path", "\n", "dep_dev_path", "=", "args", ".", "dep_dev_ctb_path", "\n", "\n", "", "dep_reader", "=", "CoNLLXReader", "(", "dep_train_path", ")", "\n", "print", "(", "'Reading dependency parsing data from %s'", "%", "dep_train_path", ")", "\n", "\n", "dep_dev_reader", "=", "CoNLLXReader", "(", "dep_dev_path", ")", "\n", "print", "(", "'Reading dependency parsing data from %s'", "%", "dep_dev_path", ")", "\n", "\n", "\n", "counter", "=", "0", "\n", "dep_sentences", "=", "[", "]", "\n", "dep_data", "=", "[", "]", "\n", "dep_heads", "=", "[", "]", "\n", "dep_types", "=", "[", "]", "\n", "inst", "=", "dep_reader", ".", "getNext", "(", ")", "\n", "while", "inst", "is", "not", "None", ":", "\n", "\n", "        ", "inst_size", "=", "inst", ".", "length", "(", ")", "\n", "if", "hparams", ".", "max_len_train", ">", "0", "and", "inst_size", "-", "1", ">", "hparams", ".", "max_len_train", ":", "\n", "            ", "inst", "=", "dep_reader", ".", "getNext", "(", ")", "\n", "continue", "\n", "\n", "", "counter", "+=", "1", "\n", "if", "counter", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "\"reading data: %d\"", "%", "counter", ")", "\n", "", "sent", "=", "inst", ".", "sentence", "\n", "dep_data", ".", "append", "(", "(", "sent", ".", "words", ",", "inst", ".", "postags", ",", "inst", ".", "heads", ",", "inst", ".", "types", ")", ")", "\n", "#dep_sentences.append([(tag, word) for i, (word, tag) in enumerate(zip(sent.words, sent.postags))])", "\n", "dep_sentences", ".", "append", "(", "sent", ".", "words", ")", "\n", "dep_heads", ".", "append", "(", "inst", ".", "heads", ")", "\n", "dep_types", ".", "append", "(", "inst", ".", "types", ")", "\n", "inst", "=", "dep_reader", ".", "getNext", "(", ")", "\n", "", "dep_reader", ".", "close", "(", ")", "\n", "print", "(", "\"Total number of data: %d\"", "%", "counter", ")", "\n", "\n", "dep_dev_data", "=", "[", "]", "\n", "dev_inst", "=", "dep_dev_reader", ".", "getNext", "(", ")", "\n", "dep_dev_headid", "=", "np", ".", "zeros", "(", "[", "3000", ",", "300", "]", ",", "dtype", "=", "int", ")", "\n", "dep_dev_type", "=", "[", "]", "\n", "dep_dev_word", "=", "[", "]", "\n", "dep_dev_pos", "=", "[", "]", "\n", "dep_dev_lengs", "=", "np", ".", "zeros", "(", "3000", ",", "dtype", "=", "int", ")", "\n", "cun", "=", "0", "\n", "while", "dev_inst", "is", "not", "None", ":", "\n", "        ", "inst_size", "=", "dev_inst", ".", "length", "(", ")", "\n", "if", "hparams", ".", "max_len_dev", ">", "0", "and", "inst_size", "-", "1", ">", "hparams", ".", "max_len_dev", ":", "\n", "            ", "dev_inst", "=", "dep_dev_reader", ".", "getNext", "(", ")", "\n", "continue", "\n", "", "dep_dev_lengs", "[", "cun", "]", "=", "inst_size", "\n", "sent", "=", "dev_inst", ".", "sentence", "\n", "dep_dev_data", ".", "append", "(", "(", "sent", ".", "words", ",", "dev_inst", ".", "postags", ",", "dev_inst", ".", "heads", ",", "dev_inst", ".", "types", ")", ")", "\n", "for", "i", "in", "range", "(", "inst_size", ")", ":", "\n", "            ", "dep_dev_headid", "[", "cun", "]", "[", "i", "]", "=", "dev_inst", ".", "heads", "[", "i", "]", "\n", "\n", "", "dep_dev_type", ".", "append", "(", "dev_inst", ".", "types", ")", "\n", "dep_dev_word", ".", "append", "(", "sent", ".", "words", ")", "\n", "dep_dev_pos", ".", "append", "(", "sent", ".", "postags", ")", "\n", "#dep_sentences.append([(tag, word) for i, (word, tag) in enumerate(zip(sent.words, sent.postags))])", "\n", "dev_inst", "=", "dep_dev_reader", ".", "getNext", "(", ")", "\n", "cun", "=", "cun", "+", "1", "\n", "", "dep_dev_reader", ".", "close", "(", ")", "\n", "\n", "\n", "print", "(", "\"Loading training trees from {}...\"", ".", "format", "(", "train_path", ")", ")", "\n", "train_treebank", "=", "trees", ".", "load_trees", "(", "train_path", ",", "dep_heads", ",", "dep_types", ",", "dep_sentences", ")", "\n", "if", "hparams", ".", "max_len_train", ">", "0", ":", "\n", "        ", "train_treebank", "=", "[", "tree", "for", "tree", "in", "train_treebank", "if", "len", "(", "list", "(", "tree", ".", "leaves", "(", ")", ")", ")", "<=", "hparams", ".", "max_len_train", "]", "\n", "", "print", "(", "\"Loaded {:,} training examples.\"", ".", "format", "(", "len", "(", "train_treebank", ")", ")", ")", "\n", "\n", "print", "(", "\"Loading development trees from {}...\"", ".", "format", "(", "dev_path", ")", ")", "\n", "dev_treebank", "=", "trees", ".", "load_trees", "(", "dev_path", ",", "dep_dev_headid", ",", "dep_dev_type", ",", "dep_dev_word", ")", "\n", "if", "hparams", ".", "max_len_dev", ">", "0", ":", "\n", "        ", "dev_treebank", "=", "[", "tree", "for", "tree", "in", "dev_treebank", "if", "len", "(", "list", "(", "tree", ".", "leaves", "(", ")", ")", ")", "<=", "hparams", ".", "max_len_dev", "]", "\n", "", "print", "(", "\"Loaded {:,} development examples.\"", ".", "format", "(", "len", "(", "dev_treebank", ")", ")", ")", "\n", "\n", "\n", "print", "(", "\"Processing trees for training...\"", ")", "\n", "train_parse", "=", "[", "tree", ".", "convert", "(", ")", "for", "tree", "in", "train_treebank", "]", "\n", "dev_parse", "=", "[", "tree", ".", "convert", "(", ")", "for", "tree", "in", "dev_treebank", "]", "\n", "\n", "count_wh", "(", "\"train data:\"", ",", "train_parse", ",", "dep_heads", ",", "dep_types", ")", "\n", "count_wh", "(", "\"dev data:\"", ",", "dev_parse", ",", "dep_dev_headid", ",", "dep_dev_type", ")", "\n", "\n", "print", "(", "\"Constructing vocabularies...\"", ")", "\n", "\n", "tag_vocab", "=", "vocabulary", ".", "Vocabulary", "(", ")", "\n", "tag_vocab", ".", "index", "(", "KM_parser", ".", "START", ")", "\n", "tag_vocab", ".", "index", "(", "KM_parser", ".", "STOP", ")", "\n", "tag_vocab", ".", "index", "(", "KM_parser", ".", "TAG_UNK", ")", "\n", "\n", "word_vocab", "=", "vocabulary", ".", "Vocabulary", "(", ")", "\n", "word_vocab", ".", "index", "(", "KM_parser", ".", "START", ")", "\n", "word_vocab", ".", "index", "(", "KM_parser", ".", "STOP", ")", "\n", "word_vocab", ".", "index", "(", "KM_parser", ".", "UNK", ")", "\n", "\n", "label_vocab", "=", "vocabulary", ".", "Vocabulary", "(", ")", "\n", "label_vocab", ".", "index", "(", "(", ")", ")", "\n", "sublabels", "=", "[", "KM_parser", ".", "Sub_Head", "]", "\n", "label_vocab", ".", "index", "(", "tuple", "(", "sublabels", ")", ")", "\n", "\n", "type_vocab", "=", "vocabulary", ".", "Vocabulary", "(", ")", "\n", "\n", "char_set", "=", "set", "(", ")", "\n", "\n", "for", "i", ",", "tree", "in", "enumerate", "(", "train_parse", ")", ":", "\n", "\n", "        ", "const_sentences", "=", "[", "leaf", ".", "word", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "\n", "assert", "len", "(", "const_sentences", ")", "==", "len", "(", "dep_sentences", "[", "i", "]", ")", "\n", "nodes", "=", "[", "tree", "]", "\n", "while", "nodes", ":", "\n", "            ", "node", "=", "nodes", ".", "pop", "(", ")", "\n", "if", "isinstance", "(", "node", ",", "trees", ".", "InternalParseNode", ")", ":", "\n", "                ", "label_vocab", ".", "index", "(", "node", ".", "label", ")", "\n", "if", "node", ".", "type", "is", "not", "KM_parser", ".", "ROOT", ":", "#not include root type", "\n", "                    ", "type_vocab", ".", "index", "(", "node", ".", "type", ")", "\n", "", "nodes", ".", "extend", "(", "reversed", "(", "node", ".", "children", ")", ")", "\n", "", "else", ":", "\n", "                ", "tag_vocab", ".", "index", "(", "node", ".", "tag", ")", "\n", "word_vocab", ".", "index", "(", "node", ".", "word", ")", "\n", "type_vocab", ".", "index", "(", "node", ".", "type", ")", "\n", "char_set", "|=", "set", "(", "node", ".", "word", ")", "\n", "\n", "", "", "", "char_vocab", "=", "vocabulary", ".", "Vocabulary", "(", ")", "\n", "\n", "#char_vocab.index(tokens.CHAR_PAD)", "\n", "\n", "# If codepoints are small (e.g. Latin alphabet), index by codepoint directly", "\n", "highest_codepoint", "=", "max", "(", "ord", "(", "char", ")", "for", "char", "in", "char_set", ")", "\n", "if", "highest_codepoint", "<", "512", ":", "\n", "        ", "if", "highest_codepoint", "<", "256", ":", "\n", "            ", "highest_codepoint", "=", "256", "\n", "", "else", ":", "\n", "            ", "highest_codepoint", "=", "512", "\n", "\n", "# This also takes care of constants like tokens.CHAR_PAD", "\n", "", "for", "codepoint", "in", "range", "(", "highest_codepoint", ")", ":", "\n", "            ", "char_index", "=", "char_vocab", ".", "index", "(", "chr", "(", "codepoint", ")", ")", "\n", "assert", "char_index", "==", "codepoint", "\n", "", "", "else", ":", "\n", "        ", "char_vocab", ".", "index", "(", "tokens", ".", "CHAR_UNK", ")", "\n", "char_vocab", ".", "index", "(", "tokens", ".", "CHAR_START_SENTENCE", ")", "\n", "char_vocab", ".", "index", "(", "tokens", ".", "CHAR_START_WORD", ")", "\n", "char_vocab", ".", "index", "(", "tokens", ".", "CHAR_STOP_WORD", ")", "\n", "char_vocab", ".", "index", "(", "tokens", ".", "CHAR_STOP_SENTENCE", ")", "\n", "for", "char", "in", "sorted", "(", "char_set", ")", ":", "\n", "            ", "char_vocab", ".", "index", "(", "char", ")", "\n", "\n", "", "", "tag_vocab", ".", "freeze", "(", ")", "\n", "word_vocab", ".", "freeze", "(", ")", "\n", "label_vocab", ".", "freeze", "(", ")", "\n", "char_vocab", ".", "freeze", "(", ")", "\n", "type_vocab", ".", "freeze", "(", ")", "\n", "\n", "punctuation", "=", "hparams", ".", "punctuation", "\n", "punct_set", "=", "punctuation", "\n", "\n", "def", "print_vocabulary", "(", "name", ",", "vocab", ")", ":", "\n", "        ", "special", "=", "{", "tokens", ".", "START", ",", "tokens", ".", "STOP", ",", "tokens", ".", "UNK", "}", "\n", "print", "(", "\"{} ({:,}): {}\"", ".", "format", "(", "\n", "name", ",", "vocab", ".", "size", ",", "\n", "sorted", "(", "value", "for", "value", "in", "vocab", ".", "values", "if", "value", "in", "special", ")", "+", "\n", "sorted", "(", "value", "for", "value", "in", "vocab", ".", "values", "if", "value", "not", "in", "special", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "print_vocabs", ":", "\n", "        ", "print_vocabulary", "(", "\"Tag\"", ",", "tag_vocab", ")", "\n", "print_vocabulary", "(", "\"Word\"", ",", "word_vocab", ")", "\n", "print_vocabulary", "(", "\"Label\"", ",", "label_vocab", ")", "\n", "print_vocabulary", "(", "\"Char\"", ",", "char_vocab", ")", "\n", "print_vocabulary", "(", "\"Type\"", ",", "type_vocab", ")", "\n", "\n", "\n", "", "print", "(", "\"Initializing model...\"", ")", "\n", "\n", "load_path", "=", "None", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "print", "(", "f\"Loading parameters from {load_path}\"", ")", "\n", "info", "=", "torch_load", "(", "load_path", ")", "\n", "parser", "=", "KM_parser", ".", "ChartParser", ".", "from_spec", "(", "info", "[", "'spec'", "]", ",", "info", "[", "'state_dict'", "]", ")", "\n", "", "else", ":", "\n", "        ", "parser", "=", "KM_parser", ".", "ChartParser", "(", "\n", "tag_vocab", ",", "\n", "word_vocab", ",", "\n", "label_vocab", ",", "\n", "char_vocab", ",", "\n", "type_vocab", ",", "\n", "hparams", ",", "\n", ")", "\n", "\n", "", "print", "(", "\"Initializing optimizer...\"", ")", "\n", "trainable_parameters", "=", "[", "param", "for", "param", "in", "parser", ".", "parameters", "(", ")", "if", "param", ".", "requires_grad", "]", "\n", "trainer", "=", "torch", ".", "optim", ".", "Adam", "(", "trainable_parameters", ",", "lr", "=", "1.", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "trainer", ".", "load_state_dict", "(", "info", "[", "'trainer'", "]", ")", "\n", "\n", "", "def", "set_lr", "(", "new_lr", ")", ":", "\n", "        ", "for", "param_group", "in", "trainer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "new_lr", "\n", "\n", "", "", "assert", "hparams", ".", "step_decay", ",", "\"Only step_decay schedule is supported\"", "\n", "\n", "warmup_coeff", "=", "hparams", ".", "learning_rate", "/", "hparams", ".", "learning_rate_warmup_steps", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "\n", "trainer", ",", "'max'", ",", "\n", "factor", "=", "hparams", ".", "step_decay_factor", ",", "\n", "patience", "=", "hparams", ".", "step_decay_patience", ",", "\n", "verbose", "=", "True", ",", "\n", ")", "\n", "def", "schedule_lr", "(", "iteration", ")", ":", "\n", "        ", "iteration", "=", "iteration", "+", "1", "\n", "if", "iteration", "<=", "hparams", ".", "learning_rate_warmup_steps", ":", "\n", "            ", "set_lr", "(", "iteration", "*", "warmup_coeff", ")", "\n", "\n", "", "", "clippable_parameters", "=", "trainable_parameters", "\n", "grad_clip_threshold", "=", "np", ".", "inf", "if", "hparams", ".", "clip_grad_norm", "==", "0", "else", "hparams", ".", "clip_grad_norm", "\n", "\n", "\n", "print", "(", "\"Training...\"", ")", "\n", "total_processed", "=", "0", "\n", "current_processed", "=", "0", "\n", "check_every", "=", "len", "(", "train_parse", ")", "/", "args", ".", "checks_per_epoch", "\n", "best_dev_score", "=", "-", "np", ".", "inf", "\n", "best_model_path", "=", "None", "\n", "model_name", "=", "hparams", ".", "model_name", "\n", "\n", "print", "(", "\"This is \"", ",", "model_name", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "def", "check_dev", "(", "epoch_num", ")", ":", "\n", "        ", "nonlocal", "best_dev_score", "\n", "nonlocal", "best_model_path", "\n", "\n", "dev_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "parser", ".", "eval", "(", ")", "\n", "\n", "dev_predicted", "=", "[", "]", "\n", "\n", "for", "dev_start_index", "in", "range", "(", "0", ",", "len", "(", "dev_treebank", ")", ",", "args", ".", "eval_batch_size", ")", ":", "\n", "            ", "subbatch_trees", "=", "dev_treebank", "[", "dev_start_index", ":", "dev_start_index", "+", "args", ".", "eval_batch_size", "]", "\n", "subbatch_sentences", "=", "[", "[", "(", "leaf", ".", "tag", ",", "leaf", ".", "word", ")", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "subbatch_trees", "]", "\n", "\n", "predicted", ",", "_", ",", "=", "parser", ".", "parse_batch", "(", "subbatch_sentences", ")", "\n", "del", "_", "\n", "\n", "dev_predicted", ".", "extend", "(", "[", "p", ".", "convert", "(", ")", "for", "p", "in", "predicted", "]", ")", "\n", "\n", "", "dev_fscore", "=", "evaluate", ".", "evalb", "(", "args", ".", "evalb_dir", ",", "dev_treebank", ",", "dev_predicted", ")", "\n", "\n", "print", "(", "\n", "\"dev-fscore {} \"", "\n", "\"dev-elapsed {} \"", "\n", "\"total-elapsed {}\"", ".", "format", "(", "\n", "dev_fscore", ",", "\n", "format_elapsed", "(", "dev_start_time", ")", ",", "\n", "format_elapsed", "(", "start_time", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "dev_pred_head", "=", "[", "[", "leaf", ".", "father", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "dev_predicted", "]", "\n", "dev_pred_type", "=", "[", "[", "leaf", ".", "type", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "dev_predicted", "]", "\n", "assert", "len", "(", "dev_pred_head", ")", "==", "len", "(", "dev_pred_type", ")", "\n", "assert", "len", "(", "dev_pred_type", ")", "==", "len", "(", "dep_dev_type", ")", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "num_inst", "=", "dep_eval", ".", "eval", "(", "len", "(", "dev_pred_head", ")", ",", "dep_dev_word", ",", "dep_dev_pos", ",", "\n", "dev_pred_head", ",", "dev_pred_type", ",", "\n", "dep_dev_headid", ",", "dep_dev_type", ",", "\n", "dep_dev_lengs", ",", "punct_set", "=", "punct_set", ",", "\n", "symbolic_root", "=", "False", ")", "\n", "dev_ucorr", ",", "dev_lcorr", ",", "dev_total", ",", "dev_ucomlpete", ",", "dev_lcomplete", "=", "stats", "\n", "dev_ucorr_nopunc", ",", "dev_lcorr_nopunc", ",", "dev_total_nopunc", ",", "dev_ucomlpete_nopunc", ",", "dev_lcomplete_nopunc", "=", "stats_nopunc", "\n", "dev_root_corr", ",", "dev_total_root", "=", "stats_root", "\n", "dev_total_inst", "=", "num_inst", "\n", "print", "(", "\n", "'W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "dev_ucorr", ",", "dev_lcorr", ",", "dev_total", ",", "dev_ucorr", "*", "100", "/", "dev_total", ",", "dev_lcorr", "*", "100", "/", "dev_total", ",", "\n", "dev_ucomlpete", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete", "*", "100", "/", "dev_total_inst", ")", ")", "\n", "print", "(", "\n", "'Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "dev_ucorr_nopunc", ",", "dev_lcorr_nopunc", ",", "dev_total_nopunc", ",", "\n", "dev_ucorr_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_lcorr_nopunc", "*", "100", "/", "dev_total_nopunc", ",", "\n", "dev_ucomlpete_nopunc", "*", "100", "/", "dev_total_inst", ",", "dev_lcomplete_nopunc", "*", "100", "/", "dev_total_inst", ")", ")", "\n", "print", "(", "'Root: corr: %d, total: %d, acc: %.2f%%'", "%", "(", "\n", "dev_root_corr", ",", "dev_total_root", ",", "dev_root_corr", "*", "100", "/", "dev_total_root", ")", ")", "\n", "\n", "dev_uas", "=", "dev_ucorr_nopunc", "*", "100", "/", "dev_total_nopunc", "\n", "dev_las", "=", "dev_lcorr_nopunc", "*", "100", "/", "dev_total_nopunc", "\n", "\n", "if", "dev_fscore", ".", "fscore", "+", "dev_las", ">", "best_dev_score", ":", "\n", "            ", "if", "best_model_path", "is", "not", "None", ":", "\n", "                ", "extensions", "=", "[", "\".pt\"", "]", "\n", "for", "ext", "in", "extensions", ":", "\n", "                    ", "path", "=", "best_model_path", "+", "ext", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "                        ", "print", "(", "\"Removing previous model file {}...\"", ".", "format", "(", "path", ")", ")", "\n", "os", ".", "remove", "(", "path", ")", "\n", "\n", "", "", "", "best_dev_score", "=", "dev_fscore", ".", "fscore", "+", "dev_las", "\n", "best_model_path", "=", "\"{}_best_dev={:.2f}_devuas={:.2f}_devlas={:.2f}\"", ".", "format", "(", "\n", "args", ".", "model_path_base", ",", "dev_fscore", ".", "fscore", ",", "dev_uas", ",", "dev_las", ")", "\n", "print", "(", "\"Saving new best model to {}...\"", ".", "format", "(", "best_model_path", ")", ")", "\n", "torch", ".", "save", "(", "{", "\n", "'spec'", ":", "parser", ".", "spec", ",", "\n", "'state_dict'", ":", "parser", ".", "state_dict", "(", ")", ",", "\n", "'trainer'", ":", "trainer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "best_model_path", "+", "\".pt\"", ")", "\n", "\n", "\n", "", "", "for", "epoch", "in", "itertools", ".", "count", "(", "start", "=", "1", ")", ":", "\n", "        ", "if", "args", ".", "epochs", "is", "not", "None", "and", "epoch", ">", "args", ".", "epochs", ":", "\n", "            ", "break", "\n", "#check_dev(epoch)", "\n", "", "np", ".", "random", ".", "shuffle", "(", "train_parse", ")", "\n", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "start_index", "in", "range", "(", "0", ",", "len", "(", "train_parse", ")", ",", "args", ".", "batch_size", ")", ":", "\n", "            ", "trainer", ".", "zero_grad", "(", ")", "\n", "schedule_lr", "(", "total_processed", "//", "args", ".", "batch_size", ")", "\n", "\n", "parser", ".", "train", "(", ")", "\n", "\n", "batch_loss_value", "=", "0.0", "\n", "batch_trees", "=", "train_parse", "[", "start_index", ":", "start_index", "+", "args", ".", "batch_size", "]", "\n", "\n", "batch_sentences", "=", "[", "[", "(", "leaf", ".", "tag", ",", "leaf", ".", "word", ")", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "batch_trees", "]", "\n", "for", "subbatch_sentences", ",", "subbatch_trees", "in", "parser", ".", "split_batch", "(", "batch_sentences", ",", "batch_trees", ",", "args", ".", "subbatch_max_tokens", ")", ":", "\n", "                ", "_", ",", "loss", "=", "parser", ".", "parse_batch", "(", "subbatch_sentences", ",", "subbatch_trees", ")", "\n", "\n", "loss", "=", "loss", "/", "len", "(", "batch_trees", ")", "\n", "loss_value", "=", "float", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "batch_loss_value", "+=", "loss_value", "\n", "if", "loss_value", ">", "0", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "", "del", "loss", "\n", "total_processed", "+=", "len", "(", "subbatch_trees", ")", "\n", "current_processed", "+=", "len", "(", "subbatch_trees", ")", "\n", "\n", "", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "clippable_parameters", ",", "grad_clip_threshold", ")", "\n", "\n", "trainer", ".", "step", "(", ")", "\n", "\n", "print", "(", "\n", "\"epoch {:,} \"", "\n", "\"batch {:,}/{:,} \"", "\n", "\"processed {:,} \"", "\n", "\"batch-loss {:.4f} \"", "\n", "\"grad-norm {:.4f} \"", "\n", "\"epoch-elapsed {} \"", "\n", "\"total-elapsed {}\"", ".", "format", "(", "\n", "epoch", ",", "\n", "start_index", "//", "args", ".", "batch_size", "+", "1", ",", "\n", "int", "(", "np", ".", "ceil", "(", "len", "(", "train_parse", ")", "/", "args", ".", "batch_size", ")", ")", ",", "\n", "total_processed", ",", "\n", "batch_loss_value", ",", "\n", "grad_norm", ",", "\n", "format_elapsed", "(", "epoch_start_time", ")", ",", "\n", "format_elapsed", "(", "start_time", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "current_processed", ">=", "check_every", ":", "\n", "                ", "current_processed", "-=", "check_every", "\n", "check_dev", "(", "epoch", ")", "\n", "\n", "# adjust learning rate at the end of an epoch", "\n", "", "", "if", "hparams", ".", "step_decay", ":", "\n", "            ", "if", "(", "total_processed", "//", "args", ".", "batch_size", "+", "1", ")", ">", "hparams", ".", "learning_rate_warmup_steps", ":", "\n", "                ", "scheduler", ".", "step", "(", "best_dev_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.run_test": [[534, 639], ["print", "args.model_path_base.endswith", "main.torch_load", "KM_parser.ChartParser.from_spec", "KM_parser.ChartParser.from_spec.eval", "dep_reader.CoNLLXReader", "print", "dep_reader.CoNLLXReader.getNext", "numpy.zeros", "numpy.zeros", "dep_reader.CoNLLXReader.close", "print", "trees.load_trees", "print", "print", "time.time", "KM_parser.ChartParser.from_spec.eval", "range", "evaluate.evalb", "print", "dep_eval.eval", "print", "print", "print", "print", "dep_test_reader.getNext.length", "dep_test_data.append", "range", "dep_test_type.append", "dep_test_word.append", "dep_test_pos.append", "dep_reader.CoNLLXReader.getNext", "len", "KM_parser.ChartParser.from_spec.parse_batch", "test_predicted.extend", "len", "len", "len", "len", "len", "len", "main.format_elapsed", "p.convert", "tree.leaves", "tree.leaves", "tree.leaves"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.torch_load", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.from_spec", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.load_trees", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.evaluate.evalb", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.DependencyInstance.length", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.parse_batch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.format_elapsed", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves"], ["", "", "", "", "def", "run_test", "(", "args", ")", ":", "\n", "\n", "    ", "const_test_path", "=", "args", ".", "consttest_ptb_path", "\n", "\n", "dep_test_path", "=", "args", ".", "deptest_ptb_path", "\n", "\n", "if", "args", ".", "dataset", "==", "'ctb'", ":", "\n", "        ", "const_test_path", "=", "args", ".", "consttest_ctb_path", "\n", "dep_test_path", "=", "args", ".", "deptest_ctb_path", "\n", "\n", "", "print", "(", "\"Loading model from {}...\"", ".", "format", "(", "args", ".", "model_path_base", ")", ")", "\n", "assert", "args", ".", "model_path_base", ".", "endswith", "(", "\".pt\"", ")", ",", "\"Only pytorch savefiles supported\"", "\n", "\n", "info", "=", "torch_load", "(", "args", ".", "model_path_base", ")", "\n", "assert", "'hparams'", "in", "info", "[", "'spec'", "]", ",", "\"Older savefiles not supported\"", "\n", "parser", "=", "KM_parser", ".", "ChartParser", ".", "from_spec", "(", "info", "[", "'spec'", "]", ",", "info", "[", "'state_dict'", "]", ")", "\n", "parser", ".", "eval", "(", ")", "\n", "\n", "dep_test_reader", "=", "CoNLLXReader", "(", "dep_test_path", ",", "parser", ".", "type_vocab", ")", "\n", "print", "(", "'Reading dependency parsing data from %s'", "%", "dep_test_path", ")", "\n", "\n", "dep_test_data", "=", "[", "]", "\n", "test_inst", "=", "dep_test_reader", ".", "getNext", "(", ")", "\n", "dep_test_headid", "=", "np", ".", "zeros", "(", "[", "40000", ",", "300", "]", ",", "dtype", "=", "int", ")", "\n", "dep_test_type", "=", "[", "]", "\n", "dep_test_word", "=", "[", "]", "\n", "dep_test_pos", "=", "[", "]", "\n", "dep_test_lengs", "=", "np", ".", "zeros", "(", "40000", ",", "dtype", "=", "int", ")", "\n", "cun", "=", "0", "\n", "while", "test_inst", "is", "not", "None", ":", "\n", "        ", "inst_size", "=", "test_inst", ".", "length", "(", ")", "\n", "dep_test_lengs", "[", "cun", "]", "=", "inst_size", "\n", "sent", "=", "test_inst", ".", "sentence", "\n", "dep_test_data", ".", "append", "(", "(", "sent", ".", "words", ",", "test_inst", ".", "postags", ",", "test_inst", ".", "heads", ",", "test_inst", ".", "types", ")", ")", "\n", "for", "i", "in", "range", "(", "inst_size", ")", ":", "\n", "            ", "dep_test_headid", "[", "cun", "]", "[", "i", "]", "=", "test_inst", ".", "heads", "[", "i", "]", "\n", "", "dep_test_type", ".", "append", "(", "test_inst", ".", "types", ")", "\n", "dep_test_word", ".", "append", "(", "sent", ".", "words", ")", "\n", "dep_test_pos", ".", "append", "(", "sent", ".", "postags", ")", "\n", "# dep_sentences.append([(tag, word) for i, (word, tag) in enumerate(zip(sent.words, sent.postags))])", "\n", "test_inst", "=", "dep_test_reader", ".", "getNext", "(", ")", "\n", "cun", "=", "cun", "+", "1", "\n", "\n", "", "dep_test_reader", ".", "close", "(", ")", "\n", "\n", "print", "(", "\"Loading test trees from {}...\"", ".", "format", "(", "const_test_path", ")", ")", "\n", "test_treebank", "=", "trees", ".", "load_trees", "(", "const_test_path", ",", "dep_test_headid", ",", "dep_test_type", ",", "dep_test_word", ")", "\n", "print", "(", "\"Loaded {:,} test examples.\"", ".", "format", "(", "len", "(", "test_treebank", ")", ")", ")", "\n", "\n", "print", "(", "\"Parsing test sentences...\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "punct_set", "=", "'.'", "'``'", "\"''\"", "':'", "','", "\n", "\n", "parser", ".", "eval", "(", ")", "\n", "test_predicted", "=", "[", "]", "\n", "for", "start_index", "in", "range", "(", "0", ",", "len", "(", "test_treebank", ")", ",", "args", ".", "eval_batch_size", ")", ":", "\n", "        ", "subbatch_trees", "=", "test_treebank", "[", "start_index", ":", "start_index", "+", "args", ".", "eval_batch_size", "]", "\n", "\n", "subbatch_sentences", "=", "[", "[", "(", "leaf", ".", "tag", ",", "leaf", ".", "word", ")", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "subbatch_trees", "]", "\n", "\n", "predicted", ",", "_", ",", "=", "parser", ".", "parse_batch", "(", "subbatch_sentences", ")", "\n", "del", "_", "\n", "test_predicted", ".", "extend", "(", "[", "p", ".", "convert", "(", ")", "for", "p", "in", "predicted", "]", ")", "\n", "\n", "", "test_fscore", "=", "evaluate", ".", "evalb", "(", "args", ".", "evalb_dir", ",", "test_treebank", ",", "test_predicted", ")", "\n", "print", "(", "\n", "\"test-fscore {} \"", "\n", "\"test-elapsed {}\"", ".", "format", "(", "\n", "test_fscore", ",", "\n", "format_elapsed", "(", "start_time", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "test_pred_head", "=", "[", "[", "leaf", ".", "father", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "test_predicted", "]", "\n", "test_pred_type", "=", "[", "[", "leaf", ".", "type", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "test_predicted", "]", "\n", "assert", "len", "(", "test_pred_head", ")", "==", "len", "(", "test_pred_type", ")", "\n", "assert", "len", "(", "test_pred_type", ")", "==", "len", "(", "dep_test_type", ")", "\n", "stats", ",", "stats_nopunc", ",", "stats_root", ",", "test_total_inst", "=", "dep_eval", ".", "eval", "(", "len", "(", "test_pred_head", ")", ",", "dep_test_word", ",", "dep_test_pos", ",", "\n", "test_pred_head", ",", "\n", "test_pred_type", ",", "dep_test_headid", ",", "dep_test_type", ",", "\n", "dep_test_lengs", ",", "punct_set", "=", "punct_set", ",", "\n", "symbolic_root", "=", "False", ")", "\n", "\n", "test_ucorrect", ",", "test_lcorrect", ",", "test_total", ",", "test_ucomlpete_match", ",", "test_lcomplete_match", "=", "stats", "\n", "test_ucorrect_nopunc", ",", "test_lcorrect_nopunc", ",", "test_total_nopunc", ",", "test_ucomlpete_match_nopunc", ",", "test_lcomplete_match_nopunc", "=", "stats_nopunc", "\n", "test_root_correct", ",", "test_total_root", "=", "stats_root", "\n", "\n", "print", "(", "\n", "'best test W. Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%%'", "%", "(", "\n", "test_ucorrect", ",", "test_lcorrect", ",", "test_total", ",", "test_ucorrect", "*", "100", "/", "test_total", ",", "\n", "test_lcorrect", "*", "100", "/", "test_total", ",", "\n", "test_ucomlpete_match", "*", "100", "/", "test_total_inst", ",", "test_lcomplete_match", "*", "100", "/", "test_total_inst", "\n", ")", ")", "\n", "print", "(", "\n", "'best test Wo Punct: ucorr: %d, lcorr: %d, total: %d, uas: %.2f%%, las: %.2f%%, ucm: %.2f%%, lcm: %.2f%% '", "%", "(", "\n", "test_ucorrect_nopunc", ",", "test_lcorrect_nopunc", ",", "test_total_nopunc", ",", "\n", "test_ucorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "\n", "test_lcorrect_nopunc", "*", "100", "/", "test_total_nopunc", ",", "\n", "test_ucomlpete_match_nopunc", "*", "100", "/", "test_total_inst", ",", "\n", "test_lcomplete_match_nopunc", "*", "100", "/", "test_total_inst", ")", ")", "\n", "print", "(", "'best test Root: corr: %d, total: %d, acc: %.2f%%'", "%", "(", "\n", "test_root_correct", ",", "test_total_root", ",", "test_root_correct", "*", "100", "/", "test_total_root", ")", ")", "\n", "print", "(", "\n", "'============================================================================================================================'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.run_parse": [[640, 720], ["print", "args.model_path_base.endswith", "main.torch_load", "KM_parser.ChartParser.from_spec", "KM_parser.ChartParser.from_spec.eval", "print", "tqdm.tqdm", "open", "input_file.readlines", "sentence.strip", "range", "KM_parser.ChartParser.from_spec.parse_batch", "syntree_pred.extend", "len", "main.run_parse.save_data"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.torch_load", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.from_spec", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.parse_batch"], ["", "def", "run_parse", "(", "args", ")", ":", "\n", "\n", "    ", "print", "(", "\"Loading model from {}...\"", ".", "format", "(", "args", ".", "model_path_base", ")", ")", "\n", "assert", "args", ".", "model_path_base", ".", "endswith", "(", "\".pt\"", ")", ",", "\"Only pytorch savefiles supported\"", "\n", "\n", "info", "=", "torch_load", "(", "args", ".", "model_path_base", ")", "\n", "assert", "'hparams'", "in", "info", "[", "'spec'", "]", ",", "\"Older savefiles not supported\"", "\n", "parser", "=", "KM_parser", ".", "ChartParser", ".", "from_spec", "(", "info", "[", "'spec'", "]", ",", "info", "[", "'state_dict'", "]", ")", "\n", "parser", ".", "contributions", "=", "(", "args", ".", "contributions", "==", "1", ")", "\n", "parser", ".", "eval", "(", ")", "\n", "print", "(", "\"Parsing sentences...\"", ")", "\n", "with", "open", "(", "args", ".", "input_path", ")", "as", "input_file", ":", "\n", "        ", "sentences", "=", "input_file", ".", "readlines", "(", ")", "\n", "\n", "", "sentences", "=", "[", "sentence", ".", "strip", "(", ")", "for", "sentence", "in", "sentences", "if", "len", "(", "sentence", ".", "strip", "(", ")", ")", ">", "0", "]", "\n", "\n", "if", "args", ".", "max_tokens", ">", "0", ":", "\n", "        ", "tmp", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "            ", "sub_sentences", "=", "[", "word_tokenize", "(", "sub_sentence", ")", "for", "sub_sentence", "in", "sent_tokenize", "(", "sentence", ")", "]", "\n", "this_sentence", "=", "sub_sentences", "[", "0", "]", "[", ":", "args", ".", "max_tokens", "]", "\n", "this_idx", "=", "1", "\n", "move_on", "=", "False", "\n", "while", "this_idx", "<", "len", "(", "sub_sentences", ")", "and", "len", "(", "this_sentence", ")", "<", "args", ".", "max_tokens", "and", "not", "move_on", ":", "\n", "                ", "if", "len", "(", "sub_sentences", "[", "this_idx", "]", ")", "<=", "args", ".", "max_tokens", "-", "len", "(", "this_sentence", ")", ":", "\n", "                    ", "this_sentence", "=", "this_sentence", "+", "sub_sentences", "[", "this_idx", "]", "\n", "", "else", ":", "\n", "                    ", "move_on", "=", "True", "\n", "", "this_idx", "+=", "1", "\n", "", "tmp", ".", "append", "(", "' '", ".", "join", "(", "this_sentence", ")", ")", "\n", "", "sentences", "=", "tmp", "\n", "\n", "", "if", "args", ".", "pos_tag", "==", "2", ":", "\n", "# Parser does not do tagging, so use a dummy tag when parsing from raw text", "\n", "        ", "if", "'UNK'", "in", "parser", ".", "tag_vocab", ".", "indices", ":", "\n", "            ", "dummy_tag", "=", "'UNK'", "\n", "", "else", ":", "\n", "            ", "dummy_tag", "=", "parser", ".", "tag_vocab", ".", "value", "(", "0", ")", "\n", "\n", "", "", "def", "save_data", "(", "syntree_pred", ",", "cun", ")", ":", "\n", "        ", "pred_head", "=", "[", "[", "leaf", ".", "father", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "syntree_pred", "]", "\n", "pred_type", "=", "[", "[", "leaf", ".", "type", "for", "leaf", "in", "tree", ".", "leaves", "(", ")", "]", "for", "tree", "in", "syntree_pred", "]", "\n", "appent_string", "=", "\"_\"", "+", "str", "(", "cun", ")", "+", "\".txt\"", "\n", "if", "args", ".", "output_path_synconst", "!=", "'-'", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_path_synconst", "+", "appent_string", ",", "'w'", ")", "as", "output_file", ":", "\n", "                ", "for", "tree", "in", "syntree_pred", ":", "\n", "                    ", "output_file", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "tree", ".", "convert", "(", ")", ".", "linearize", "(", ")", ")", ")", "\n", "", "", "print", "(", "\"Output written to:\"", ",", "args", ".", "output_path_synconst", ")", "\n", "\n", "", "if", "args", ".", "output_path_syndep", "!=", "'-'", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_path_syndep", "+", "appent_string", ",", "'w'", ")", "as", "output_file", ":", "\n", "                ", "for", "heads", "in", "pred_head", ":", "\n", "                    ", "output_file", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "heads", ")", ")", "\n", "", "", "print", "(", "\"Output written to:\"", ",", "args", ".", "output_path_syndep", ")", "\n", "\n", "", "if", "args", ".", "output_path_synlabel", "!=", "'-'", ":", "\n", "            ", "with", "open", "(", "args", ".", "output_path_synlabel", "+", "appent_string", ",", "'w'", ")", "as", "output_file", ":", "\n", "                ", "for", "labels", "in", "pred_type", ":", "\n", "                    ", "output_file", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "labels", ")", ")", "\n", "", "", "print", "(", "\"Output written to:\"", ",", "args", ".", "output_path_synlabel", ")", "\n", "\n", "", "", "syntree_pred", "=", "[", "]", "\n", "cun", "=", "0", "\n", "for", "start_index", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "args", ".", "eval_batch_size", ")", ",", "desc", "=", "'Parsing sentences'", ")", ":", "\n", "        ", "subbatch_sentences", "=", "sentences", "[", "start_index", ":", "start_index", "+", "args", ".", "eval_batch_size", "]", "\n", "if", "args", ".", "pos_tag", "==", "2", ":", "\n", "            ", "tagged_sentences", "=", "[", "[", "(", "dummy_tag", ",", "REVERSE_TOKEN_MAPPING", ".", "get", "(", "word", ",", "word", ")", ")", "for", "word", "in", "word_tokenize", "(", "sentence", ")", "]", "for", "sentence", "in", "subbatch_sentences", "]", "\n", "", "elif", "args", ".", "pos_tag", "==", "1", ":", "\n", "            ", "tagged_sentences", "=", "[", "[", "(", "REVERSE_TOKEN_MAPPING", ".", "get", "(", "tag", ",", "tag", ")", ",", "REVERSE_TOKEN_MAPPING", ".", "get", "(", "word", ",", "word", ")", ")", "for", "word", ",", "tag", "in", "nltk", ".", "pos_tag", "(", "word_tokenize", "(", "sentence", ")", ")", "]", "for", "sentence", "in", "subbatch_sentences", "]", "\n", "", "else", ":", "\n", "            ", "tagged_sentences", "=", "[", "[", "(", "REVERSE_TOKEN_MAPPING", ".", "get", "(", "word", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "word", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ",", "REVERSE_TOKEN_MAPPING", ".", "get", "(", "word", ".", "split", "(", "'_'", ")", "[", "1", "]", ",", "word", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", ")", "for", "word", "in", "sentence", ".", "split", "(", ")", "]", "for", "sentence", "in", "subbatch_sentences", "]", "\n", "", "syntree", ",", "_", "=", "parser", ".", "parse_batch", "(", "tagged_sentences", ")", "\n", "syntree_pred", ".", "extend", "(", "syntree", ")", "\n", "if", "args", ".", "save_per_sentences", "<=", "len", "(", "syntree_pred", ")", "and", "args", ".", "save_per_sentences", ">", "0", ":", "\n", "            ", "save_data", "(", "syntree_pred", ",", "cun", ")", "\n", "syntree_pred", "=", "[", "]", "\n", "cun", "+=", "1", "\n", "\n", "", "", "if", "0", "<", "len", "(", "syntree_pred", ")", ":", "\n", "        ", "save_data", "(", "syntree_pred", ",", "cun", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.main": [[721, 785], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "main.make_hparams", "parser.add_subparsers.add_parser", "subparsers.add_parser.set_defaults", "make_hparams.populate_arguments", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "parser.add_subparsers.add_parser", "subparsers.add_parser.set_defaults", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "parser.add_subparsers.add_parser", "subparsers.add_parser.set_defaults", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.callback", "main.run_train"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.make_hparams", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.populate_arguments", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.main.run_train"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "subparsers", "=", "parser", ".", "add_subparsers", "(", ")", "\n", "\n", "hparams", "=", "make_hparams", "(", ")", "\n", "subparser", "=", "subparsers", ".", "add_parser", "(", "\"train\"", ")", "\n", "subparser", ".", "set_defaults", "(", "callback", "=", "lambda", "args", ":", "run_train", "(", "args", ",", "hparams", ")", ")", "\n", "hparams", ".", "populate_arguments", "(", "subparser", ")", "\n", "subparser", ".", "add_argument", "(", "\"--numpy-seed\"", ",", "type", "=", "int", ")", "\n", "subparser", ".", "add_argument", "(", "\"--model-path-base\"", ",", "required", "=", "True", ")", "\n", "subparser", ".", "add_argument", "(", "\"--embedding-path\"", ",", "required", "=", "True", ")", "\n", "subparser", ".", "add_argument", "(", "\"--embedding-type\"", ",", "default", "=", "\"random\"", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "\"--model-name\"", ",", "default", "=", "\"test\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--evalb-dir\"", ",", "default", "=", "\"EVALB/\"", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"ptb\"", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "\"--train-ptb-path\"", ",", "default", "=", "\"data/02-21.10way.clean\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dev-ptb-path\"", ",", "default", "=", "\"data/22.auto.clean\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dep-train-ptb-path\"", ",", "default", "=", "\"data/ptb_train_3.3.0.sd.clean\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dep-dev-ptb-path\"", ",", "default", "=", "\"data/ptb_dev_3.3.0.sd.clean\"", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "\"--train-ctb-path\"", ",", "default", "=", "\"data/train_ctb.txt\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dev-ctb-path\"", ",", "default", "=", "\"data/dev_ctb.txt\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dep-train-ctb-path\"", ",", "default", "=", "\"data/train_ctb.conll\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dep-dev-ctb-path\"", ",", "default", "=", "\"data/dev_ctb.conll\"", ")", "\n", "\n", "subparser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "250", ")", "\n", "subparser", ".", "add_argument", "(", "\"--subbatch-max-tokens\"", ",", "type", "=", "int", ",", "default", "=", "2000", ")", "\n", "subparser", ".", "add_argument", "(", "\"--eval-batch-size\"", ",", "type", "=", "int", ",", "default", "=", "30", ")", "\n", "subparser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "subparser", ".", "add_argument", "(", "\"--checks-per-epoch\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "subparser", ".", "add_argument", "(", "\"--print-vocabs\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "subparser", "=", "subparsers", ".", "add_parser", "(", "\"test\"", ")", "\n", "subparser", ".", "set_defaults", "(", "callback", "=", "run_test", ")", "\n", "subparser", ".", "add_argument", "(", "\"--model-path-base\"", ",", "required", "=", "True", ")", "\n", "subparser", ".", "add_argument", "(", "\"--evalb-dir\"", ",", "default", "=", "\"EVALB/\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--embedding-path\"", ",", "default", "=", "\"data/glove.6B.100d.txt.gz\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"ptb\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--consttest-ptb-path\"", ",", "default", "=", "\"data/23.auto.clean\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--deptest-ptb-path\"", ",", "default", "=", "\"data/ptb_test_3.3.0.sd.clean\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--consttest-ctb-path\"", ",", "default", "=", "\"data/test_ctb.txt\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--deptest-ctb-path\"", ",", "default", "=", "\"data/test_ctb.conll\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--eval-batch-size\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "\n", "subparser", "=", "subparsers", ".", "add_parser", "(", "\"parse\"", ")", "\n", "subparser", ".", "set_defaults", "(", "callback", "=", "run_parse", ")", "\n", "subparser", ".", "add_argument", "(", "\"--model-path-base\"", ",", "required", "=", "True", ")", "\n", "subparser", ".", "add_argument", "(", "\"--contributions\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "# 1 to print contributions", "\n", "subparser", ".", "add_argument", "(", "\"--pos-tag\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "# 1 to PoS-tag the input sentences, 2 for dummy tag", "\n", "subparser", ".", "add_argument", "(", "\"--embedding-path\"", ",", "default", "=", "\"data/glove.6B.100d.txt.gz\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"ptb\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--max-tokens\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "subparser", ".", "add_argument", "(", "\"--save-per-sentences\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "subparser", ".", "add_argument", "(", "\"--input-path\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "subparser", ".", "add_argument", "(", "\"--output-path-synconst\"", ",", "type", "=", "str", ",", "default", "=", "\"-\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--output-path-syndep\"", ",", "type", "=", "str", ",", "default", "=", "\"-\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--output-path-synlabel\"", ",", "type", "=", "str", ",", "default", "=", "\"-\"", ")", "\n", "subparser", ".", "add_argument", "(", "\"--eval-batch-size\"", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "callback", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.Sentence.__init__": [[7, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "words", ",", "postags", ")", ":", "\n", "        ", "self", ".", "words", "=", "words", "\n", "self", ".", "postags", "=", "postags", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.Sentence.length": [[11, 13], ["len"], "methods", ["None"], ["", "def", "length", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.DependencyInstance.__init__": [[16, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sentence", ",", "postags", ",", "heads", ",", "types", ")", ":", "\n", "        ", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "postags", "=", "postags", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "types", "=", "types", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.DependencyInstance.length": [[22, 24], ["dep_reader.DependencyInstance.sentence.length"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.DependencyInstance.length"], ["", "def", "length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sentence", ".", "length", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.__init__": [[27, 30], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "file_path", ",", "type_vocab", "=", "None", ")", ":", "\n", "        ", "self", ".", "__source_file", "=", "open", "(", "file_path", ",", "'r'", ")", "\n", "self", ".", "type_vocab", "=", "type_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close": [[31, 33], ["dep_reader.CoNLLXReader.__source_file.close"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "__source_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.getNext": [[34, 86], ["dep_reader.CoNLLXReader.__source_file.readline", "len", "dep_reader.DependencyInstance", "dep_reader.CoNLLXReader.__source_file.readline", "len", "len", "dep_reader.CoNLLXReader.strip", "lines.append", "dep_reader.CoNLLXReader.__source_file.readline", "gold_pos.append", "int", "words.append", "postags.append", "types.append", "heads.append", "dep_reader.Sentence", "len", "len", "dep_reader.CoNLLXReader.strip", "dep_reader.CoNLLXReader.split", "dep_reader.CoNLLXReader.strip"], "methods", ["None"], ["", "def", "getNext", "(", "self", ")", ":", "\n", "        ", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "# skip multiple blank lines.", "\n", "while", "len", "(", "line", ")", ">", "0", "and", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "lines", "=", "[", "]", "\n", "while", "len", "(", "line", ".", "strip", "(", ")", ")", ">", "0", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "#line = line.decode('utf-8')", "\n", "lines", ".", "append", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "\n", "line", "=", "self", ".", "__source_file", ".", "readline", "(", ")", "\n", "\n", "", "length", "=", "len", "(", "lines", ")", "\n", "if", "length", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "words", "=", "[", "]", "\n", "postags", "=", "[", "]", "\n", "types", "=", "[", "]", "\n", "heads", "=", "[", "]", "\n", "gold_pos", "=", "[", "]", "\n", "\n", "# words.append(KM_parser.ROOT)", "\n", "# postags.append(KM_parser.ROOT)", "\n", "# types.append(KM_parser.ROOT)", "\n", "# heads.append(0)", "\n", "\n", "for", "tokens", "in", "lines", ":", "\n", "\n", "            ", "word", "=", "tokens", "[", "1", "]", "\n", "pos", "=", "tokens", "[", "4", "]", "\n", "gold_pos", ".", "append", "(", "tokens", "[", "3", "]", ")", "\n", "head", "=", "int", "(", "tokens", "[", "6", "]", ")", "\n", "type", "=", "tokens", "[", "7", "]", "\n", "\n", "words", ".", "append", "(", "word", ")", "\n", "\n", "postags", ".", "append", "(", "pos", ")", "\n", "\n", "types", ".", "append", "(", "type", ")", "\n", "\n", "heads", ".", "append", "(", "head", ")", "\n", "\n", "# words.append(parse_nk.STOP)", "\n", "# postags.append(parse_nk.STOP)", "\n", "# types.append(parse_nk.STOP)", "\n", "# heads.append(0)", "\n", "\n", "", "return", "DependencyInstance", "(", "Sentence", "(", "words", ",", "postags", ")", ",", "gold_pos", ",", "heads", ",", "types", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.evaluate.FScore.__init__": [[10, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "recall", ",", "precision", ",", "fscore", ")", ":", "\n", "        ", "self", ".", "recall", "=", "recall", "\n", "self", ".", "precision", "=", "precision", "\n", "self", ".", "fscore", "=", "fscore", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.evaluate.FScore.__str__": [[15, 18], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"(Recall={:.2f}, Precision={:.2f}, FScore={:.2f})\"", ".", "format", "(", "\n", "self", ".", "recall", ",", "self", ".", "precision", ",", "self", ".", "fscore", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.evaluate.evalb": [[19, 105], ["os.path.exists", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "zip", "tempfile.TemporaryDirectory", "os.path.join", "os.path.join", "os.path.join", "subprocess.run", "evaluate.FScore", "os.path.exists", "os.path.exists", "os.path.join", "os.path.join", "len", "len", "isinstance", "isinstance", "list", "list", "all", "open", "open", "open", "tempfile.TemporaryDirectory.cleanup", "print", "print", "print", "print", "gold_tree.leaves", "predicted_tree.leaves", "len", "len", "outfile.write", "re.match", "re.match", "re.match", "math.isnan", "outfile.write", "open", "outfile.write", "float", "float", "float", "zip", "goldfile.read", "tree.linearize", "re.match.group", "re.match.group", "re.match.group", "tree.linearize"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.linearize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.linearize"], ["", "", "def", "evalb", "(", "evalb_dir", ",", "gold_trees", ",", "predicted_trees", ",", "ref_gold_path", "=", "None", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "exists", "(", "evalb_dir", ")", "\n", "evalb_program_path", "=", "os", ".", "path", ".", "join", "(", "evalb_dir", ",", "\"evalb\"", ")", "\n", "evalb_spmrl_program_path", "=", "os", ".", "path", ".", "join", "(", "evalb_dir", ",", "\"evalb_spmrl\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "evalb_program_path", ")", "or", "os", ".", "path", ".", "exists", "(", "evalb_spmrl_program_path", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "evalb_program_path", ")", ":", "\n", "#evalb_param_path = os.path.join(evalb_dir, \"COLLINS.prm\")", "\n", "        ", "evalb_param_path", "=", "os", ".", "path", ".", "join", "(", "evalb_dir", ",", "\"nk.prm\"", ")", "\n", "", "else", ":", "\n", "        ", "evalb_program_path", "=", "evalb_spmrl_program_path", "\n", "evalb_param_path", "=", "os", ".", "path", ".", "join", "(", "evalb_dir", ",", "\"spmrl.prm\"", ")", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "evalb_program_path", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "evalb_param_path", ")", "\n", "\n", "assert", "len", "(", "gold_trees", ")", "==", "len", "(", "predicted_trees", ")", "\n", "for", "gold_tree", ",", "predicted_tree", "in", "zip", "(", "gold_trees", ",", "predicted_trees", ")", ":", "\n", "        ", "assert", "isinstance", "(", "gold_tree", ",", "trees", ".", "TreebankNode", ")", "\n", "assert", "isinstance", "(", "predicted_tree", ",", "trees", ".", "TreebankNode", ")", "\n", "gold_leaves", "=", "list", "(", "gold_tree", ".", "leaves", "(", ")", ")", "\n", "predicted_leaves", "=", "list", "(", "predicted_tree", ".", "leaves", "(", ")", ")", "\n", "assert", "len", "(", "gold_leaves", ")", "==", "len", "(", "predicted_leaves", ")", "\n", "assert", "all", "(", "\n", "gold_leaf", ".", "word", "==", "predicted_leaf", ".", "word", "\n", "for", "gold_leaf", ",", "predicted_leaf", "in", "zip", "(", "gold_leaves", ",", "predicted_leaves", ")", ")", "\n", "\n", "", "temp_dir", "=", "tempfile", ".", "TemporaryDirectory", "(", "prefix", "=", "\"evalb-\"", ")", "\n", "gold_path", "=", "os", ".", "path", ".", "join", "(", "temp_dir", ".", "name", ",", "\"gold.txt\"", ")", "\n", "predicted_path", "=", "os", ".", "path", ".", "join", "(", "temp_dir", ".", "name", ",", "\"predicted.txt\"", ")", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "temp_dir", ".", "name", ",", "\"output.txt\"", ")", "\n", "\n", "# DELETE", "\n", "predicted_path", "=", "'tmp_predictions.txt'", "\n", "output_path", "=", "'tmp_output.txt'", "\n", "gold_path", "=", "'tmp_gold.txt'", "\n", "\n", "with", "open", "(", "gold_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "if", "ref_gold_path", "is", "None", ":", "\n", "            ", "for", "tree", "in", "gold_trees", ":", "\n", "                ", "outfile", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "tree", ".", "linearize", "(", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "ref_gold_path", ")", "as", "goldfile", ":", "\n", "                ", "outfile", ".", "write", "(", "goldfile", ".", "read", "(", ")", ")", "\n", "\n", "", "", "", "with", "open", "(", "predicted_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "for", "tree", "in", "predicted_trees", ":", "\n", "            ", "outfile", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "tree", ".", "linearize", "(", ")", ")", ")", "\n", "\n", "", "", "command", "=", "\"{} -p {} {} {} > {}\"", ".", "format", "(", "\n", "evalb_program_path", ",", "\n", "evalb_param_path", ",", "\n", "gold_path", ",", "\n", "predicted_path", ",", "\n", "output_path", ",", "\n", ")", "\n", "subprocess", ".", "run", "(", "command", ",", "shell", "=", "True", ")", "\n", "\n", "fscore", "=", "FScore", "(", "math", ".", "nan", ",", "math", ".", "nan", ",", "math", ".", "nan", ")", "\n", "with", "open", "(", "output_path", ")", "as", "infile", ":", "\n", "        ", "for", "line", "in", "infile", ":", "\n", "            ", "match", "=", "re", ".", "match", "(", "r\"Bracketing Recall\\s+=\\s+(\\d+\\.\\d+)\"", ",", "line", ")", "\n", "if", "match", ":", "\n", "                ", "fscore", ".", "recall", "=", "float", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "", "match", "=", "re", ".", "match", "(", "r\"Bracketing Precision\\s+=\\s+(\\d+\\.\\d+)\"", ",", "line", ")", "\n", "if", "match", ":", "\n", "                ", "fscore", ".", "precision", "=", "float", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "", "match", "=", "re", ".", "match", "(", "r\"Bracketing FMeasure\\s+=\\s+(\\d+\\.\\d+)\"", ",", "line", ")", "\n", "if", "match", ":", "\n", "                ", "fscore", ".", "fscore", "=", "float", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "break", "\n", "\n", "", "", "", "success", "=", "(", "\n", "not", "math", ".", "isnan", "(", "fscore", ".", "fscore", ")", "or", "\n", "fscore", ".", "recall", "==", "0.0", "or", "\n", "fscore", ".", "precision", "==", "0.0", ")", "\n", "\n", "if", "success", ":", "\n", "        ", "temp_dir", ".", "cleanup", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Error reading EVALB results.\"", ")", "\n", "print", "(", "\"Gold path: {}\"", ".", "format", "(", "gold_path", ")", ")", "\n", "print", "(", "\"Predicted path: {}\"", ".", "format", "(", "predicted_path", ")", ")", "\n", "print", "(", "\"Output path: {}\"", ".", "format", "(", "output_path", ")", ")", "\n", "\n", "", "return", "fscore", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.transliterate.arabic": [[129, 141], ["BUCKWALTER_MAP.get", "BUCKWALTER_UNESCAPE.get"], "function", ["None"], ["def", "arabic", "(", "inp", ")", ":", "\n", "    ", "\"\"\"\n    Undo Buckwalter transliteration\n\n    See: http://languagelog.ldc.upenn.edu/myl/ldc/morph/buckwalter.html\n\n    This code inspired by:\n    https://github.com/dlwh/epic/blob/master/src/main/scala/epic/util/ArabicNormalization.scala\n    \"\"\"", "\n", "return", "\"\"", ".", "join", "(", "\n", "BUCKWALTER_MAP", ".", "get", "(", "char", ",", "char", ")", "\n", "for", "char", "in", "BUCKWALTER_UNESCAPE", ".", "get", "(", "inp", ",", "inp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.transliterate.hebrew": [[142, 157], ["HEBREW_MAP.get", "HEBREW_UNESCAPE.get"], "function", ["None"], ["", "def", "hebrew", "(", "inp", ")", ":", "\n", "    ", "\"\"\"\n    Undo Hebrew transliteration\n\n    See: http://www.phil.uu.nl/ozsl/articles/simaan02.pdf\n\n    This code inspired by:\n    https://github.com/habeanf/yap/blob/b57502364b73ef78f3510eb890319ae268eeacca/nlp/parser/xliter8/types.go\n    \"\"\"", "\n", "out", "=", "\"\"", ".", "join", "(", "\n", "HEBREW_MAP", ".", "get", "(", "char", ",", "char", ")", "\n", "for", "char", "in", "HEBREW_UNESCAPE", ".", "get", "(", "inp", ",", "inp", ")", ")", "\n", "if", "out", "and", "(", "out", "[", "-", "1", "]", "in", "HEBREW_SUFFIX_MAP", ")", ":", "\n", "        ", "out", "=", "out", "[", ":", "-", "1", "]", "+", "HEBREW_SUFFIX_MAP", "[", "out", "[", "-", "1", "]", "]", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalTreebankNode.__init__": [[12, 37], ["isinstance", "isinstance", "all", "tuple", "isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "label", ",", "children", ")", ":", "\n", "        ", "assert", "isinstance", "(", "label", ",", "str", ")", "\n", "self", ".", "label", "=", "label", "\n", "assert", "isinstance", "(", "children", ",", "collections", ".", "abc", ".", "Sequence", ")", "\n", "assert", "all", "(", "isinstance", "(", "child", ",", "TreebankNode", ")", "for", "child", "in", "children", ")", "\n", "assert", "children", "\n", "self", ".", "children", "=", "tuple", "(", "children", ")", "\n", "self", ".", "father", "=", "self", ".", "children", "[", "0", "]", ".", "father", "\n", "self", ".", "type", "=", "self", ".", "children", "[", "0", "]", ".", "type", "\n", "self", ".", "head", "=", "self", ".", "children", "[", "0", "]", ".", "head", "\n", "self", ".", "left", "=", "self", ".", "children", "[", "0", "]", ".", "left", "\n", "self", ".", "right", "=", "self", ".", "children", "[", "-", "1", "]", ".", "right", "\n", "self", ".", "cun", "=", "0", "\n", "flag", "=", "0", "\n", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "if", "child", ".", "father", "<", "self", ".", "left", "+", "1", "or", "child", ".", "father", ">", "self", ".", "right", ":", "\n", "                ", "self", ".", "father", "=", "child", ".", "father", "\n", "self", ".", "type", "=", "child", ".", "type", "\n", "self", ".", "head", "=", "child", ".", "head", "\n", "flag", "=", "1", "\n", "\n", "", "", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "if", "child", ".", "head", "!=", "self", ".", "head", ":", "\n", "                ", "if", "child", ".", "father", "!=", "self", ".", "head", ":", "\n", "                    ", "self", ".", "cun", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalTreebankNode.linearize": [[39, 42], ["child.linearize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.linearize"], ["", "", "", "", "def", "linearize", "(", "self", ")", ":", "\n", "        ", "return", "\"({} {})\"", ".", "format", "(", "\n", "self", ".", "label", ",", "\" \"", ".", "join", "(", "child", ".", "linearize", "(", ")", "for", "child", "in", "self", ".", "children", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalTreebankNode.leaves": [[43, 46], ["child.leaves"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves"], ["", "def", "leaves", "(", "self", ")", ":", "\n", "        ", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "yield", "from", "child", ".", "leaves", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalTreebankNode.convert": [[47, 97], ["set", "set", "set", "trees.InternalParseNode", "isinstance", "sublabels.append", "set", "set", "tuple", "len", "trees.InternalParseNode", "children.append", "children.append", "set", "len", "tuple", "len", "len", "child.convert", "sub_children.append", "len", "sub_child.convert"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert"], ["", "", "def", "convert", "(", "self", ",", "index", "=", "0", ",", "nocache", "=", "False", ")", ":", "\n", "        ", "tree", "=", "self", "\n", "sublabels", "=", "[", "self", ".", "label", "]", "\n", "\n", "while", "len", "(", "tree", ".", "children", ")", "==", "1", "and", "isinstance", "(", "\n", "tree", ".", "children", "[", "0", "]", ",", "InternalTreebankNode", ")", ":", "\n", "            ", "tree", "=", "tree", ".", "children", "[", "0", "]", "\n", "sublabels", ".", "append", "(", "tree", ".", "label", ")", "\n", "\n", "", "pre_children", "=", "[", "]", "\n", "children", "=", "[", "]", "\n", "sub_father", "=", "set", "(", ")", "\n", "sub_head", "=", "set", "(", ")", "\n", "al_make", "=", "set", "(", ")", "\n", "\n", "for", "child", "in", "tree", ".", "children", ":", "\n", "            ", "sub_head", "|=", "set", "(", "[", "child", ".", "head", "]", ")", "\n", "sub_father", "|=", "set", "(", "[", "child", ".", "father", "]", ")", "\n", "\n", "", "for", "child", "in", "tree", ".", "children", ":", "\n", "#not in sub tree", "\n", "            ", "if", "(", "child", ".", "father", "in", "sub_head", "and", "child", ".", "father", "!=", "self", ".", "head", ")", "or", "(", "child", ".", "head", "in", "sub_father", "and", "child", ".", "head", "!=", "self", ".", "head", ")", ":", "\n", "                ", "sub_r", "=", "child", ".", "father", "\n", "if", "child", ".", "head", "in", "sub_father", ":", "\n", "                    ", "sub_r", "=", "child", ".", "head", "\n", "", "if", "sub_r", "not", "in", "al_make", ":", "\n", "                    ", "al_make", "|=", "set", "(", "[", "sub_r", "]", ")", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "sub_children", "=", "[", "]", "\n", "for", "sub_child", "in", "tree", ".", "children", ":", "\n", "                    ", "if", "sub_child", ".", "father", "==", "sub_r", "or", "sub_child", ".", "head", "==", "sub_r", ":", "\n", "                        ", "if", "len", "(", "sub_children", ")", ">", "0", ":", "\n", "                            ", "assert", "sub_children", "[", "-", "1", "]", ".", "right", "==", "sub_child", ".", "left", "#contiune span", "\n", "", "sub_children", ".", "append", "(", "sub_child", ".", "convert", "(", "index", "=", "index", ")", ")", "\n", "index", "=", "sub_children", "[", "-", "1", "]", ".", "right", "\n", "\n", "", "", "assert", "len", "(", "sub_children", ")", ">", "1", "\n", "\n", "sub_node", "=", "InternalParseNode", "(", "tuple", "(", "[", "Sub_Head", "]", ")", ",", "sub_children", ",", "nocache", "=", "nocache", ")", "\n", "if", "len", "(", "children", ")", ">", "0", ":", "\n", "                    ", "assert", "children", "[", "-", "1", "]", ".", "right", "==", "sub_node", ".", "left", "# contiune span", "\n", "", "children", ".", "append", "(", "sub_node", ")", "\n", "", "else", ":", "\n", "                ", "if", "len", "(", "children", ")", ">", "0", ":", "\n", "                    ", "assert", "children", "[", "-", "1", "]", ".", "right", "==", "child", ".", "left", "# contiune span", "\n", "", "children", ".", "append", "(", "child", ".", "convert", "(", "index", "=", "index", ")", ")", "\n", "index", "=", "children", "[", "-", "1", "]", ".", "right", "\n", "\n", "", "", "return", "InternalParseNode", "(", "tuple", "(", "sublabels", ")", ",", "children", ",", "nocache", "=", "nocache", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.__init__": [[100, 110], ["isinstance", "isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tag", ",", "word", ",", "head", ",", "father", ",", "type", ")", ":", "\n", "        ", "assert", "isinstance", "(", "tag", ",", "str", ")", "\n", "self", ".", "tag", "=", "tag", "\n", "self", ".", "father", "=", "father", "\n", "self", ".", "type", "=", "type", "\n", "self", ".", "head", "=", "head", "\n", "assert", "isinstance", "(", "word", ",", "str", ")", "\n", "self", ".", "word", "=", "word", "\n", "self", ".", "left", "=", "self", ".", "head", "-", "1", "\n", "self", ".", "right", "=", "self", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.linearize": [[111, 113], ["None"], "methods", ["None"], ["", "def", "linearize", "(", "self", ")", ":", "\n", "        ", "return", "\"({} {})\"", ".", "format", "(", "self", ".", "tag", ",", "self", ".", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.leaves": [[114, 116], ["None"], "methods", ["None"], ["", "def", "leaves", "(", "self", ")", ":", "\n", "        ", "yield", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafTreebankNode.convert": [[117, 119], ["trees.LeafParseNode"], "methods", ["None"], ["", "def", "convert", "(", "self", ",", "index", "=", "0", ")", ":", "\n", "        ", "return", "LeafParseNode", "(", "index", ",", "self", ".", "tag", ",", "self", ".", "word", ",", "self", ".", "father", ",", "self", ".", "type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.__init__": [[124, 162], ["isinstance", "all", "isinstance", "all", "all", "tuple", "isinstance", "isinstance", "isinstance", "len", "zip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "label", ",", "children", ",", "nocache", "=", "False", ")", ":", "\n", "        ", "assert", "isinstance", "(", "label", ",", "tuple", ")", "\n", "assert", "all", "(", "isinstance", "(", "sublabel", ",", "str", ")", "for", "sublabel", "in", "label", ")", "\n", "assert", "label", "\n", "self", ".", "label", "=", "label", "\n", "\n", "assert", "isinstance", "(", "children", ",", "collections", ".", "abc", ".", "Sequence", ")", "\n", "assert", "all", "(", "isinstance", "(", "child", ",", "ParseNode", ")", "for", "child", "in", "children", ")", "\n", "assert", "children", "\n", "assert", "len", "(", "children", ")", ">", "1", "or", "isinstance", "(", "children", "[", "0", "]", ",", "LeafParseNode", ")", "\n", "assert", "all", "(", "\n", "left", ".", "right", "==", "right", ".", "left", "\n", "for", "left", ",", "right", "in", "zip", "(", "children", ",", "children", "[", "1", ":", "]", ")", ")", "\n", "self", ".", "children", "=", "tuple", "(", "children", ")", "\n", "\n", "self", ".", "left", "=", "children", "[", "0", "]", ".", "left", "\n", "self", ".", "right", "=", "children", "[", "-", "1", "]", ".", "right", "\n", "\n", "self", ".", "father", "=", "self", ".", "children", "[", "0", "]", ".", "father", "\n", "self", ".", "type", "=", "self", ".", "children", "[", "0", "]", ".", "type", "\n", "self", ".", "head", "=", "self", ".", "children", "[", "0", "]", ".", "head", "\n", "flag", "=", "0", "\n", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "if", "child", ".", "father", "-", "1", "<", "self", ".", "left", "or", "child", ".", "father", ">", "self", ".", "right", ":", "\n", "                ", "self", ".", "father", "=", "child", ".", "father", "\n", "self", ".", "type", "=", "child", ".", "type", "\n", "self", ".", "head", "=", "child", ".", "head", "\n", "flag", "=", "1", "\n", "\n", "\n", "", "", "self", ".", "cun_w", "=", "0", "\n", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "if", "self", ".", "head", "!=", "child", ".", "head", ":", "\n", "                ", "if", "child", ".", "father", "!=", "self", ".", "head", ":", "\n", "#child.father = self.head", "\n", "                    ", "self", ".", "cun_w", "+=", "1", "\n", "\n", "", "", "", "self", ".", "nocache", "=", "nocache", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.leaves": [[163, 166], ["child.leaves"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves"], ["", "def", "leaves", "(", "self", ")", ":", "\n", "        ", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "yield", "from", "child", ".", "leaves", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.convert": [[167, 173], ["trees.InternalTreebankNode", "reversed", "child.convert", "trees.InternalTreebankNode"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert"], ["", "", "def", "convert", "(", "self", ")", ":", "\n", "        ", "children", "=", "[", "child", ".", "convert", "(", ")", "for", "child", "in", "self", ".", "children", "]", "\n", "tree", "=", "InternalTreebankNode", "(", "self", ".", "label", "[", "-", "1", "]", ",", "children", ")", "\n", "for", "sublabel", "in", "reversed", "(", "self", ".", "label", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "tree", "=", "InternalTreebankNode", "(", "sublabel", ",", "[", "tree", "]", ")", "\n", "", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.enclosing": [[174, 182], ["isinstance", "child.enclosing"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.enclosing"], ["", "def", "enclosing", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "assert", "self", ".", "left", "<=", "left", "<", "right", "<=", "self", ".", "right", "\n", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "if", "isinstance", "(", "child", ",", "LeafParseNode", ")", ":", "\n", "                ", "continue", "\n", "", "if", "child", ".", "left", "<=", "left", "<", "right", "<=", "child", ".", "right", ":", "\n", "                ", "return", "child", ".", "enclosing", "(", "left", ",", "right", ")", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.chil_enclosing": [[183, 189], ["child.chil_enclosing"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.chil_enclosing"], ["", "def", "chil_enclosing", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "assert", "self", ".", "left", "<=", "left", "<", "right", "<=", "self", ".", "right", "\n", "for", "child", "in", "self", ".", "children", ":", "\n", "            ", "if", "child", ".", "left", "<=", "left", "<", "right", "<=", "child", ".", "right", ":", "\n", "                ", "return", "child", ".", "chil_enclosing", "(", "left", ",", "right", ")", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.oracle_label": [[190, 195], ["trees.InternalParseNode.enclosing"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.enclosing"], ["", "def", "oracle_label", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "enclosing", "=", "self", ".", "enclosing", "(", "left", ",", "right", ")", "\n", "if", "enclosing", ".", "left", "==", "left", "and", "enclosing", ".", "right", "==", "right", ":", "\n", "            ", "return", "enclosing", ".", "label", "\n", "", "return", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.oracle_type": [[196, 199], ["trees.InternalParseNode.chil_enclosing"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.chil_enclosing"], ["", "def", "oracle_type", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "enclosing", "=", "self", ".", "chil_enclosing", "(", "left", ",", "right", ")", "\n", "return", "enclosing", ".", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.oracle_head": [[200, 203], ["trees.InternalParseNode.chil_enclosing"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.chil_enclosing"], ["", "def", "oracle_head", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "enclosing", "=", "self", ".", "chil_enclosing", "(", "left", ",", "right", ")", "\n", "return", "enclosing", ".", "head", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.oracle_splits": [[204, 209], ["trees.InternalParseNode.enclosing"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.InternalParseNode.enclosing"], ["", "def", "oracle_splits", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "return", "[", "\n", "child", ".", "left", "\n", "for", "child", "in", "self", ".", "enclosing", "(", "left", ",", "right", ")", ".", "children", "\n", "if", "left", "<", "child", ".", "left", "<", "right", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.__init__": [[212, 226], ["isinstance", "isinstance", "isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "index", ",", "tag", ",", "word", ",", "father", ",", "type", ")", ":", "\n", "        ", "assert", "isinstance", "(", "index", ",", "int", ")", "\n", "assert", "index", ">=", "0", "\n", "self", ".", "left", "=", "index", "\n", "self", ".", "right", "=", "index", "+", "1", "\n", "\n", "assert", "isinstance", "(", "tag", ",", "str", ")", "\n", "self", ".", "tag", "=", "tag", "\n", "self", ".", "head", "=", "index", "+", "1", "\n", "self", ".", "father", "=", "father", "\n", "self", ".", "type", "=", "type", "\n", "\n", "assert", "isinstance", "(", "word", ",", "str", ")", "\n", "self", ".", "word", "=", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.leaves": [[227, 229], ["None"], "methods", ["None"], ["", "def", "leaves", "(", "self", ")", ":", "\n", "        ", "yield", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.chil_enclosing": [[230, 233], ["None"], "methods", ["None"], ["", "def", "chil_enclosing", "(", "self", ",", "left", ",", "right", ")", ":", "\n", "        ", "assert", "self", ".", "left", "<=", "left", "<", "right", "<=", "self", ".", "right", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.LeafParseNode.convert": [[234, 236], ["trees.LeafTreebankNode"], "methods", ["None"], ["", "def", "convert", "(", "self", ")", ":", "\n", "        ", "return", "LeafTreebankNode", "(", "self", ".", "tag", ",", "self", ".", "word", ",", "self", ".", "head", ",", "self", ".", "father", ",", "self", ".", "type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.trees.load_trees": [[237, 323], ["infile.read.replace().replace().split", "trees.load_trees.helper"], "function", ["None"], ["", "", "def", "load_trees", "(", "path", ",", "heads", "=", "None", ",", "types", "=", "None", ",", "wordss", "=", "None", ",", "strip_top", "=", "True", ")", ":", "\n", "    ", "with", "open", "(", "path", ")", "as", "infile", ":", "\n", "        ", "treebank", "=", "infile", ".", "read", "(", ")", "\n", "\n", "", "tokens", "=", "treebank", ".", "replace", "(", "\"(\"", ",", "\" ( \"", ")", ".", "replace", "(", "\")\"", ",", "\" ) \"", ")", ".", "split", "(", ")", "\n", "\n", "cun_word", "=", "0", "#without root", "\n", "cun_sent", "=", "0", "\n", "def", "helper", "(", "index", ",", "flag_sent", ")", ":", "\n", "        ", "nonlocal", "cun_sent", "\n", "nonlocal", "cun_word", "\n", "trees", "=", "[", "]", "\n", "\n", "while", "index", "<", "len", "(", "tokens", ")", "and", "tokens", "[", "index", "]", "==", "\"(\"", ":", "\n", "            ", "paren_count", "=", "0", "\n", "while", "tokens", "[", "index", "]", "==", "\"(\"", ":", "\n", "                ", "index", "+=", "1", "\n", "paren_count", "+=", "1", "\n", "\n", "", "label", "=", "tokens", "[", "index", "]", "\n", "\n", "index", "+=", "1", "\n", "\n", "if", "tokens", "[", "index", "]", "==", "\"(\"", ":", "\n", "                ", "children", ",", "index", "=", "helper", "(", "index", ",", "flag_sent", "=", "0", ")", "\n", "if", "len", "(", "children", ")", ">", "0", ":", "\n", "                    ", "tr", "=", "InternalTreebankNode", "(", "label", ",", "children", ")", "\n", "trees", ".", "append", "(", "tr", ")", "\n", "", "", "else", ":", "\n", "                ", "word", "=", "tokens", "[", "index", "]", "\n", "index", "+=", "1", "\n", "if", "label", "!=", "'-NONE-'", ":", "\n", "                    ", "trees", ".", "append", "(", "LeafTreebankNode", "(", "label", ",", "word", ",", "head", "=", "cun_word", "+", "1", ",", "father", "=", "heads", "[", "cun_sent", "]", "[", "cun_word", "]", ",", "type", "=", "types", "[", "cun_sent", "]", "[", "cun_word", "]", ")", ")", "\n", "if", "cun_sent", "<", "0", ":", "\n", "                        ", "print", "(", "cun_sent", ",", "cun_word", "+", "1", ",", "word", ",", "heads", "[", "cun_sent", "]", "[", "cun_word", "]", ",", "types", "[", "cun_sent", "]", "[", "cun_word", "]", ")", "\n", "", "cun_word", "+=", "1", "\n", "\n", "", "", "while", "paren_count", ">", "0", ":", "\n", "                ", "assert", "tokens", "[", "index", "]", "==", "\")\"", "\n", "index", "+=", "1", "\n", "paren_count", "-=", "1", "\n", "\n", "", "if", "flag_sent", "==", "1", ":", "\n", "                ", "cun_sent", "+=", "1", "\n", "cun_word", "=", "0", "\n", "\n", "", "", "return", "trees", ",", "index", "\n", "\n", "", "trees", ",", "index", "=", "helper", "(", "0", ",", "flag_sent", "=", "1", ")", "\n", "assert", "index", "==", "len", "(", "tokens", ")", "\n", "assert", "len", "(", "trees", ")", "==", "cun_sent", "\n", "\n", "if", "strip_top", ":", "\n", "        ", "for", "i", ",", "tree", "in", "enumerate", "(", "trees", ")", ":", "\n", "            ", "if", "tree", ".", "label", "in", "(", "\"TOP\"", ",", "\"ROOT\"", ")", ":", "\n", "                ", "assert", "len", "(", "tree", ".", "children", ")", "==", "1", "\n", "trees", "[", "i", "]", "=", "tree", ".", "children", "[", "0", "]", "\n", "\n", "", "", "", "def", "process_NONE", "(", "tree", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "tree", ",", "LeafTreebankNode", ")", ":", "\n", "            ", "label", "=", "tree", ".", "tag", "\n", "if", "label", "==", "'-NONE-'", ":", "\n", "                ", "return", "None", "\n", "", "else", ":", "\n", "                ", "return", "tree", "\n", "\n", "", "", "tr", "=", "[", "]", "\n", "label", "=", "tree", ".", "label", "\n", "if", "label", "==", "'-NONE-'", ":", "\n", "            ", "return", "None", "\n", "", "for", "node", "in", "tree", ".", "children", ":", "\n", "            ", "new_node", "=", "process_NONE", "(", "node", ")", "\n", "if", "new_node", "is", "not", "None", ":", "\n", "                ", "tr", ".", "append", "(", "new_node", ")", "\n", "", "", "if", "tr", "==", "[", "]", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "InternalTreebankNode", "(", "label", ",", "tr", ")", "\n", "\n", "", "", "new_trees", "=", "[", "]", "\n", "for", "i", ",", "tree", "in", "enumerate", "(", "trees", ")", ":", "\n", "        ", "new_tree", "=", "process_NONE", "(", "tree", ")", "\n", "new_trees", ".", "append", "(", "new_tree", ")", "\n", "\n", "", "return", "new_trees", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.is_uni_punctuation": [[6, 9], ["re.match"], "function", ["None"], ["def", "is_uni_punctuation", "(", "word", ")", ":", "\n", "    ", "match", "=", "re", ".", "match", "(", "\"^[^\\w\\s]+$]\"", ",", "word", ",", "flags", "=", "re", ".", "UNICODE", ")", "\n", "return", "match", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.is_punctuation": [[11, 16], ["dep_eval.is_uni_punctuation"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.is_uni_punctuation"], ["", "def", "is_punctuation", "(", "word", ",", "pos", ",", "punct_set", "=", "None", ")", ":", "\n", "    ", "if", "punct_set", "is", "None", ":", "\n", "        ", "return", "is_uni_punctuation", "(", "word", ")", "\n", "", "else", ":", "\n", "        ", "return", "pos", "in", "punct_set", "or", "pos", "==", "'PU'", "# for chinese", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval": [[18, 82], ["range", "range", "dep_eval.is_punctuation", "int"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.is_punctuation"], ["", "", "def", "eval", "(", "batch_size", ",", "words", ",", "postags", ",", "heads_pred", ",", "types_pred", ",", "heads", ",", "types", ",", "lengths", ",", "\n", "punct_set", "=", "None", ",", "symbolic_root", "=", "False", ",", "symbolic_end", "=", "False", ")", ":", "\n", "    ", "ucorr", "=", "0.", "\n", "lcorr", "=", "0.", "\n", "total", "=", "0.", "\n", "ucomplete_match", "=", "0.", "\n", "lcomplete_match", "=", "0.", "\n", "\n", "ucorr_nopunc", "=", "0.", "\n", "lcorr_nopunc", "=", "0.", "\n", "total_nopunc", "=", "0.", "\n", "ucomplete_match_nopunc", "=", "0.", "\n", "lcomplete_match_nopunc", "=", "0.", "\n", "\n", "corr_root", "=", "0.", "\n", "total_root", "=", "0.", "\n", "start", "=", "1", "if", "symbolic_root", "else", "0", "\n", "end", "=", "1", "if", "symbolic_end", "else", "0", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "ucm", "=", "1.", "\n", "lcm", "=", "1.", "\n", "ucm_nopunc", "=", "1.", "\n", "lcm_nopunc", "=", "1.", "\n", "#assert len(heads[i]) == len(heads_pred[i])", "\n", "for", "j", "in", "range", "(", "start", ",", "lengths", "[", "i", "]", "-", "end", ")", ":", "\n", "            ", "word", "=", "words", "[", "i", "]", "[", "j", "]", "\n", "\n", "pos", "=", "postags", "[", "i", "]", "[", "j", "]", "\n", "\n", "total", "+=", "1", "\n", "if", "heads", "[", "i", "]", "[", "j", "]", "==", "heads_pred", "[", "i", "]", "[", "j", "]", ":", "\n", "                ", "ucorr", "+=", "1", "\n", "if", "types", "[", "i", "]", "[", "j", "]", "==", "types_pred", "[", "i", "]", "[", "j", "]", ":", "\n", "                    ", "lcorr", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "lcm", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "ucm", "=", "0", "\n", "lcm", "=", "0", "\n", "\n", "", "if", "not", "is_punctuation", "(", "word", ",", "pos", ",", "punct_set", ")", ":", "\n", "                ", "total_nopunc", "+=", "1", "\n", "if", "heads", "[", "i", "]", "[", "j", "]", "==", "heads_pred", "[", "i", "]", "[", "j", "]", ":", "\n", "                    ", "ucorr_nopunc", "+=", "1", "\n", "if", "types", "[", "i", "]", "[", "j", "]", "==", "types_pred", "[", "i", "]", "[", "j", "]", ":", "\n", "                        ", "lcorr_nopunc", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "lcm_nopunc", "=", "0", "\n", "", "", "else", ":", "\n", "                    ", "ucm_nopunc", "=", "0", "\n", "lcm_nopunc", "=", "0", "\n", "\n", "", "", "if", "heads_pred", "[", "i", "]", "[", "j", "]", "==", "0", ":", "\n", "                ", "total_root", "+=", "1", "\n", "corr_root", "+=", "1", "if", "int", "(", "heads", "[", "i", "]", "[", "j", "]", ")", "==", "0", "else", "0", "\n", "\n", "", "", "ucomplete_match", "+=", "ucm", "\n", "lcomplete_match", "+=", "lcm", "\n", "ucomplete_match_nopunc", "+=", "ucm_nopunc", "\n", "lcomplete_match_nopunc", "+=", "lcm_nopunc", "\n", "\n", "", "return", "(", "ucorr", ",", "lcorr", ",", "total", ",", "ucomplete_match", ",", "lcomplete_match", ")", ",", "(", "ucorr_nopunc", ",", "lcorr_nopunc", ",", "total_nopunc", ",", "ucomplete_match_nopunc", ",", "lcomplete_match_nopunc", ")", ",", "(", "corr_root", ",", "total_root", ")", ",", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.__init__": [[3, 6], ["kwargs.items", "setattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.__getitem__": [[7, 9], ["getattr"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.__setitem__": [[10, 14], ["setattr", "hasattr", "KeyError"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "item", ",", "value", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "item", ")", ":", "\n", "            ", "raise", "KeyError", "(", "f\"Hyperparameter {item} has not been declared yet\"", ")", "\n", "", "setattr", "(", "self", ",", "item", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.to_dict": [[15, 22], ["dir", "k.startswith"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "}", "\n", "for", "k", "in", "dir", "(", "self", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'_'", ")", "or", "k", "in", "self", ".", "_skip_keys", ":", "\n", "                ", "continue", "\n", "", "res", "[", "k", "]", "=", "self", "[", "k", "]", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.populate_arguments": [[23, 36], ["dir", "k.replace.replace.replace", "k.replace.replace.startswith", "type", "parser.add_argument", "isinstance", "type", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "def", "populate_arguments", "(", "self", ",", "parser", ")", ":", "\n", "        ", "for", "k", "in", "dir", "(", "self", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'_'", ")", "or", "k", "in", "self", ".", "_skip_keys", ":", "\n", "                ", "continue", "\n", "", "v", "=", "self", "[", "k", "]", "\n", "k", "=", "k", ".", "replace", "(", "'_'", ",", "'-'", ")", "\n", "if", "type", "(", "v", ")", "in", "(", "int", ",", "float", ")", ":", "\n", "                ", "parser", ".", "add_argument", "(", "f'--{k}'", ",", "type", "=", "type", "(", "v", ")", ",", "default", "=", "v", ")", "\n", "", "elif", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "                ", "if", "not", "v", ":", "\n", "                    ", "parser", ".", "add_argument", "(", "f'--{k}'", ",", "action", "=", "'store_true'", ")", "\n", "", "else", ":", "\n", "                    ", "parser", ".", "add_argument", "(", "f'--no-{k}'", ",", "action", "=", "'store_false'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.set_from_args": [[37, 45], ["dir", "hasattr", "k.startswith", "getattr", "hasattr", "getattr"], "methods", ["None"], ["", "", "", "", "def", "set_from_args", "(", "self", ",", "args", ")", ":", "\n", "        ", "for", "k", "in", "dir", "(", "self", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'_'", ")", "or", "k", "in", "self", ".", "_skip_keys", ":", "\n", "                ", "continue", "\n", "", "if", "hasattr", "(", "args", ",", "k", ")", ":", "\n", "                ", "self", "[", "k", "]", "=", "getattr", "(", "args", ",", "k", ")", "\n", "", "elif", "hasattr", "(", "args", ",", "f'no_{k}'", ")", ":", "\n", "                ", "self", "[", "k", "]", "=", "getattr", "(", "args", ",", "f'no_{k}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print": [[46, 51], ["dir", "makehp.HParams.print"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["", "", "", "def", "print", "(", "self", ")", ":", "\n", "        ", "for", "k", "in", "dir", "(", "self", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'_'", ")", "or", "k", "in", "self", ".", "_skip_keys", ":", "\n", "                ", "continue", "\n", "", "print", "(", "k", ",", "repr", "(", "self", "[", "k", "]", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.utils.load_embedding_dict": [[10, 70], ["print", "dict", "gzip.open", "dict", "ValueError", "line.decode.strip", "line.decode.decode", "line.decode.split", "numpy.empty", "gzip.open", "file.readline", "len", "utils_io.DIGIT_RE.sub", "line.decode.strip", "len", "len", "line.decode.decode", "line.decode.split", "numpy.empty", "len", "len", "len", "utils_io.DIGIT_RE.sub", "len"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "load_embedding_dict", "(", "embedding", ",", "embedding_path", ",", "normalize_digits", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    load word embeddings from file\n    :param embedding:\n    :param embedding_path:\n    :return: embedding dict, embedding dimention, caseless\n    \"\"\"", "\n", "print", "(", "\"loading embedding: %s from %s\"", "%", "(", "embedding", ",", "embedding_path", ")", ")", "\n", "if", "embedding", "==", "'glove'", ":", "\n", "# loading GloVe", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "embedd_dim", "<", "0", ":", "\n", "                    ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "", "else", ":", "\n", "                    ", "assert", "(", "embedd_dim", "+", "1", "==", "len", "(", "tokens", ")", ")", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "1", ":", "]", "\n", "word", "=", "utils_io", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "tokens", "[", "0", "]", ")", "if", "normalize_digits", "else", "tokens", "[", "0", "]", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "elif", "embedding", "==", "'sskip'", ":", "\n", "        ", "embedd_dim", "=", "-", "1", "\n", "embedd_dict", "=", "dict", "(", ")", "\n", "with", "gzip", ".", "open", "(", "embedding_path", ",", "'r'", ")", "as", "file", ":", "\n", "# skip the first line", "\n", "            ", "file", ".", "readline", "(", ")", "\n", "for", "line", "in", "file", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "try", ":", "\n", "                    ", "line", "=", "line", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "tokens", ")", "<", "embedd_dim", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "embedd_dim", "<", "0", ":", "\n", "                        ", "embedd_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "\n", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedd_dim", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "start", "=", "len", "(", "tokens", ")", "-", "embedd_dim", "\n", "word", "=", "' '", ".", "join", "(", "tokens", "[", "0", ":", "start", "]", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "start", ":", "]", "\n", "word", "=", "utils_io", ".", "DIGIT_RE", ".", "sub", "(", "b\"0\"", ",", "word", ")", "if", "normalize_digits", "else", "word", "\n", "embedd_dict", "[", "word", "]", "=", "embedd", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "                    ", "continue", "\n", "", "", "", "return", "embedd_dict", ",", "embedd_dim", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"embedding should choose from [glove, sskip]\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.__init__": [[69, 98], ["tokenization_utils.PreTrainedTokenizer.__init__", "collections.Counter", "torch.load", "torch.load.items", "tokenization_transfo_xl.TransfoXLTokenizer.build_vocab"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab"], ["def", "__init__", "(", "self", ",", "special", "=", "None", ",", "min_freq", "=", "0", ",", "max_size", "=", "None", ",", "lower_case", "=", "False", ",", "\n", "delimiter", "=", "None", ",", "vocab_file", "=", "None", ",", "pretrained_vocab_file", "=", "None", ",", "\n", "never_split", "=", "None", ",", "unk_token", "=", "\"<unk>\"", ",", "eos_token", "=", "\"<eos>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<formula>\"", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TransfoXLTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "eos_token", "=", "eos_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", ")", "\n", "if", "never_split", "is", "None", ":", "\n", "            ", "never_split", "=", "self", ".", "all_special_tokens", "\n", "", "if", "special", "is", "None", ":", "\n", "            ", "special", "=", "[", "]", "\n", "", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "special", "=", "special", "\n", "self", ".", "min_freq", "=", "min_freq", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "lower_case", "=", "lower_case", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n", "if", "pretrained_vocab_file", "is", "not", "None", ":", "\n", "# Hack because, honestly this tokenizer was not made to be used", "\n", "# in a library like ours, at all.", "\n", "            ", "vocab_dict", "=", "torch", ".", "load", "(", "pretrained_vocab_file", ")", "\n", "for", "key", ",", "value", "in", "vocab_dict", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "\n", "", "", "if", "vocab_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "build_vocab", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file": [[99, 113], ["os.path.exists", "logger.info", "io.open", "enumerate", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "sents.append", "logger.info"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "", "def", "count_file", "(", "self", ",", "path", ",", "verbose", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "logger", ".", "info", "(", "'counting file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ")", "\n", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "sents", ".", "append", "(", "symbols", ")", "\n", "\n", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_sents": [[114, 123], ["enumerate", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "logger.info", "len"], "methods", ["None"], ["", "def", "count_sents", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            sents : a list of sentences, each a list of tokenized symbols\n        \"\"\"", "\n", "if", "verbose", ":", "logger", ".", "info", "(", "'counting {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file": [[124, 138], ["collections.OrderedDict", "io.open", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "ValueError", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "_build_from_file", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "symb", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "self", ".", "add_symbol", "(", "symb", ")", "\n", "", "", "if", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'No <unkown> token in vocabulary'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.save_vocabulary": [[139, 145], ["os.path.isdir", "torch.save", "os.path.join"], "methods", ["None"], ["", "", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "'pretrained_vocab_file'", "]", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "__dict__", ",", "vocab_file", ")", "\n", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab": [[146, 166], ["logger.info", "tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "logger.info", "logger.info", "collections.OrderedDict", "tokenization_transfo_xl.TransfoXLTokenizer.counter.most_common", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.add_special", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_special", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "def", "build_vocab", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "'building vocab from {}'", ".", "format", "(", "self", ".", "vocab_file", ")", ")", "\n", "self", ".", "_build_from_file", "(", "self", ".", "vocab_file", ")", "\n", "logger", ".", "info", "(", "'final vocab size {}'", ".", "format", "(", "len", "(", "self", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'building vocab with min_freq={}, max_size={}'", ".", "format", "(", "\n", "self", ".", "min_freq", ",", "self", ".", "max_size", ")", ")", "\n", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "sym", "in", "self", ".", "special", ":", "\n", "                ", "self", ".", "add_special", "(", "sym", ")", "\n", "\n", "", "for", "sym", ",", "cnt", "in", "self", ".", "counter", ".", "most_common", "(", "self", ".", "max_size", ")", ":", "\n", "                ", "if", "cnt", "<", "self", ".", "min_freq", ":", "break", "\n", "self", ".", "add_symbol", "(", "sym", ")", "\n", "\n", "", "logger", ".", "info", "(", "'final vocab size {} from {} unique tokens'", ".", "format", "(", "\n", "len", "(", "self", ")", ",", "len", "(", "self", ".", "counter", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file": [[167, 184], ["os.path.exists", "logger.info", "io.open", "enumerate", "torch.cat", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "torch.cat.append", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "", "def", "encode_file", "(", "self", ",", "path", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ",", "add_eos", "=", "True", ",", "\n", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "logger", ".", "info", "(", "'encoding file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "encoded", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ",", "\n", "add_double_eos", "=", "add_double_eos", ")", "\n", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_sents": [[185, 197], ["enumerate", "logger.info", "torch.cat.append", "torch.cat", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "def", "encode_sents", "(", "self", ",", "sents", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "logger", ".", "info", "(", "'encoding {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "encoded", "=", "[", "]", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_special": [[198, 203], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "setattr", "len", "sym.strip"], "methods", ["None"], ["", "def", "add_special", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "setattr", "(", "self", ",", "'{}_idx'", ".", "format", "(", "sym", ".", "strip", "(", "'<>'", ")", ")", ",", "self", ".", "sym2idx", "[", "sym", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol": [[204, 208], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "len"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer._convert_id_to_token": [[209, 213], ["len"], "methods", ["None"], ["", "", "def", "_convert_id_to_token", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "assert", "0", "<=", "idx", "<", "len", "(", "self", ")", ",", "'Index {} out of vocabulary range'", ".", "format", "(", "idx", ")", "\n", "return", "self", ".", "idx2sym", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer._convert_token_to_id": [[214, 230], ["hasattr", "tokenization_transfo_xl.TransfoXLTokenizer.sym2idx.get", "ValueError"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "sym", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "if", "sym", "in", "self", ".", "sym2idx", ":", "\n", "            ", "return", "self", ".", "sym2idx", "[", "sym", "]", "\n", "", "else", ":", "\n", "# logger.info('encounter unk {}'.format(sym))", "\n", "# assert '<eos>' not in sym", "\n", "            ", "if", "hasattr", "(", "self", ",", "'unk_idx'", ")", ":", "\n", "                ", "return", "self", ".", "sym2idx", ".", "get", "(", "sym", ",", "self", ".", "unk_idx", ")", "\n", "# Backward compatibility with pre-trained models", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "elif", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Token not in vocabulary and no <unk> token in vocabulary for replacement'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_string": [[231, 235], ["None"], "methods", ["None"], ["", "", "", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor": [[236, 238], ["torch.LongTensor", "tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "convert_to_tensor", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "self", ".", "convert_tokens_to_ids", "(", "symbols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.vocab_size": [[239, 242], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2sym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer._tokenize": [[243, 261], ["line.lower.lower.strip", "line.lower.lower.lower", "line.lower.lower.split"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "line", ",", "add_eos", "=", "False", ",", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "# convert to lower case", "\n", "if", "self", ".", "lower_case", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "\n", "# empty delimiter '' will evaluate False", "\n", "", "if", "self", ".", "delimiter", "==", "''", ":", "\n", "            ", "symbols", "=", "line", "\n", "", "else", ":", "\n", "            ", "symbols", "=", "line", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "\n", "", "if", "add_double_eos", ":", "# lm1b", "\n", "            ", "return", "[", "'<S>'", "]", "+", "symbols", "+", "[", "'<S>'", "]", "\n", "", "elif", "add_eos", ":", "\n", "            ", "return", "symbols", "+", "[", "'<eos>'", "]", "\n", "", "else", ":", "\n", "            ", "return", "symbols", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.__init__": [[264, 285], ["data.narrow.narrow.narrow", "data.narrow.narrow.view().t().contiguous().to", "data.narrow.narrow.size", "data.narrow.narrow.view().t().contiguous", "data.narrow.narrow.view().t", "data.narrow.narrow.view"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            data -- LongTensor -- the LongTensor is strictly ordered\n        \"\"\"", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "self", ".", "n_step", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "self", ".", "n_step", "*", "bsz", ")", "\n", "\n", "# Evenly divide the data across the bsz batches.", "\n", "self", ".", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Number of mini-batches", "\n", "self", ".", "n_batch", "=", "(", "self", ".", "n_step", "+", "self", ".", "bptt", "-", "1", ")", "//", "self", ".", "bptt", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch": [[286, 300], ["min", "max", "data.transpose().contiguous().to", "target.transpose().contiguous().to", "data.transpose().contiguous", "target.transpose().contiguous", "tokenization_transfo_xl.LMOrderedIterator.data.size", "data.transpose", "target.transpose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "get_batch", "(", "self", ",", "i", ",", "bptt", "=", "None", ")", ":", "\n", "        ", "if", "bptt", "is", "None", ":", "bptt", "=", "self", ".", "bptt", "\n", "seq_len", "=", "min", "(", "bptt", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", "-", "i", ")", "\n", "\n", "end_idx", "=", "i", "+", "seq_len", "\n", "beg_idx", "=", "max", "(", "0", ",", "i", "-", "self", ".", "ext_len", ")", "\n", "\n", "data", "=", "self", ".", "data", "[", "beg_idx", ":", "end_idx", "]", "\n", "target", "=", "self", ".", "data", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", "\n", "\n", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "data_out", ",", "target_out", ",", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter": [[301, 304], ["range", "tokenization_transfo_xl.LMOrderedIterator.data.size", "tokenization_transfo_xl.LMOrderedIterator.get_batch"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "def", "get_fixlen_iter", "(", "self", ",", "start", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "start", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "self", ".", "bptt", ")", ":", "\n", "            ", "yield", "self", ".", "get_batch", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.get_varlen_iter": [[305, 316], ["min", "tokenization_transfo_xl.LMOrderedIterator.get_batch", "max", "numpy.random.random", "int", "tokenization_transfo_xl.LMOrderedIterator.data.size", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "get_varlen_iter", "(", "self", ",", "start", "=", "0", ",", "std", "=", "5", ",", "min_len", "=", "5", ",", "max_deviation", "=", "3", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "bptt", "+", "max_deviation", "*", "std", "\n", "i", "=", "start", "\n", "while", "True", ":", "\n", "            ", "bptt", "=", "self", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "self", ".", "bptt", "/", "2.", "\n", "bptt", "=", "min", "(", "max_len", ",", "max", "(", "min_len", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "std", ")", ")", ")", ")", "\n", "data", ",", "target", ",", "seq_len", "=", "self", ".", "get_batch", "(", "i", ",", "bptt", ")", "\n", "i", "+=", "seq_len", "\n", "yield", "data", ",", "target", ",", "seq_len", "\n", "if", "i", ">=", "self", ".", "data", ".", "size", "(", "0", ")", "-", "2", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.__iter__": [[317, 319], ["tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_fixlen_iter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMShuffledIterator.__init__": [[322, 334], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            data -- list[LongTensor] -- there is no order among the LongTensors\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMShuffledIterator.get_sent_stream": [[335, 343], ["numpy.random.permutation", "numpy.array", "len", "range", "len"], "methods", ["None"], ["", "def", "get_sent_stream", "(", "self", ")", ":", "\n", "# index iterator", "\n", "        ", "epoch_indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "data", ")", ")", "if", "self", ".", "shuffle", "else", "np", ".", "array", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "# sentence iterator", "\n", "for", "idx", "in", "epoch_indices", ":", "\n", "            ", "yield", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator": [[344, 392], ["torch.LongTensor", "torch.LongTensor", "data[].fill_", "torch.LongTensor.fill_", "range", "torch.LongTensor.transpose().contiguous().to", "torch.LongTensor.transpose().contiguous().to", "min", "torch.LongTensor.resize_", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.transpose().contiguous", "torch.LongTensor.transpose().contiguous", "min", "next", "torch.LongTensor.transpose", "torch.LongTensor.transpose", "len", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "# streams for each data in the batch", "\n", "        ", "streams", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "\n", "n_retain", "=", "0", "\n", "\n", "while", "True", ":", "\n", "# data   : [n_retain+bptt x bsz]", "\n", "# target : [bptt x bsz]", "\n", "            ", "data", "[", "n_retain", ":", "]", ".", "fill_", "(", "-", "1", ")", "\n", "target", ".", "fill_", "(", "-", "1", ")", "\n", "\n", "valid_batch", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "bsz", ")", ":", "\n", "                ", "n_filled", "=", "0", "\n", "try", ":", "\n", "                    ", "while", "n_filled", "<", "self", ".", "bptt", ":", "\n", "                        ", "if", "streams", "[", "i", "]", "is", "None", "or", "len", "(", "streams", "[", "i", "]", ")", "<=", "1", ":", "\n", "                            ", "streams", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "# number of new tokens to fill in", "\n", "", "n_new", "=", "min", "(", "len", "(", "streams", "[", "i", "]", ")", "-", "1", ",", "self", ".", "bptt", "-", "n_filled", ")", "\n", "# first n_retain tokens are retained from last batch", "\n", "data", "[", "n_retain", "+", "n_filled", ":", "n_retain", "+", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", ":", "n_new", "]", "\n", "target", "[", "n_filled", ":", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", "1", ":", "n_new", "+", "1", "]", "\n", "streams", "[", "i", "]", "=", "streams", "[", "i", "]", "[", "n_new", ":", "]", "\n", "n_filled", "+=", "n_new", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "not", "valid_batch", ":", "\n", "                ", "return", "\n", "\n", "", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "yield", "data_out", ",", "target_out", ",", "self", ".", "bptt", "\n", "\n", "n_retain", "=", "min", "(", "data", ".", "size", "(", "0", ")", ",", "self", ".", "ext_len", ")", "\n", "if", "n_retain", ">", "0", ":", "\n", "                ", "data", "[", ":", "n_retain", "]", "=", "data", "[", "-", "n_retain", ":", "]", "\n", "", "data", ".", "resize_", "(", "n_retain", "+", "self", ".", "bptt", ",", "data", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMShuffledIterator.__iter__": [[393, 399], ["tokenization_transfo_xl.LMShuffledIterator.get_sent_stream", "tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMMultiFileIterator.__init__": [[402, 414], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "paths", ",", "vocab", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "\n", "shuffle", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "paths", "=", "paths", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream": [[415, 422], ["tokenization_transfo_xl.LMMultiFileIterator.vocab.encode_file", "iter", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "get_sent_stream", "(", "self", ",", "path", ")", ":", "\n", "        ", "sents", "=", "self", ".", "vocab", ".", "encode_file", "(", "path", ",", "add_double_eos", "=", "True", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "sents", ")", "\n", "", "sent_stream", "=", "iter", "(", "sents", ")", "\n", "\n", "return", "sent_stream", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMMultiFileIterator.__iter__": [[423, 432], ["numpy.random.shuffle", "tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "tokenization_transfo_xl.LMMultiFileIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "paths", ")", "\n", "\n", "", "for", "path", "in", "self", ".", "paths", ":", "\n", "# sent_stream is an iterator", "\n", "            ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", "path", ")", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "                ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": [[435, 477], ["TransfoXLTokenizer.from_pretrained", "cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "logger.error", "PRETRAINED_CORPUS_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.cached_path"], ["    ", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a pre-processed corpus.\n        \"\"\"", "\n", "vocab", "=", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_CORPUS_ARCHIVE_MAP", ":", "\n", "            ", "corpus_file", "=", "PRETRAINED_CORPUS_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "corpus_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CORPUS_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_corpus_file", "=", "cached_path", "(", "corpus_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Corpus '{}' was not found in corpus list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_CORPUS_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "corpus_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_corpus_file", "==", "corpus_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {}\"", ".", "format", "(", "corpus_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {} from cache at {}\"", ".", "format", "(", "\n", "corpus_file", ",", "resolved_corpus_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "corpus", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "corpus_dict", "=", "torch", ".", "load", "(", "resolved_corpus_file", ")", "\n", "for", "key", ",", "value", "in", "corpus_dict", ".", "items", "(", ")", ":", "\n", "            ", "corpus", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "corpus", ".", "vocab", "=", "vocab", "\n", "if", "corpus", ".", "train", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "train", "=", "torch", ".", "tensor", "(", "corpus", ".", "train", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "valid", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "valid", "=", "torch", ".", "tensor", "(", "corpus", ".", "valid", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "test", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "test", "=", "torch", ".", "tensor", "(", "corpus", ".", "test", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLCorpus.__init__": [[478, 484], ["tokenization_transfo_xl.TransfoXLTokenizer"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "TransfoXLTokenizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "train", "=", "None", "\n", "self", ".", "valid", "=", "None", "\n", "self", ".", "test", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLCorpus.build_corpus": [[485, 523], ["tokenization_transfo_xl.TransfoXLCorpus.vocab.build_vocab", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "glob.glob", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "build_corpus", "(", "self", ",", "path", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'wt103'", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "train_path_pattern", "=", "os", ".", "path", ".", "join", "(", "\n", "path", ",", "'1-billion-word-language-modeling-benchmark-r13output'", ",", "\n", "'training-monolingual.tokenized.shuffled'", ",", "'news.en-*'", ")", "\n", "train_paths", "=", "glob", ".", "glob", "(", "train_path_pattern", ")", "\n", "# the vocab will load from file when build_vocab() is called", "\n", "\n", "", "self", ".", "vocab", ".", "build_vocab", "(", ")", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "self", ".", "train", "=", "train_paths", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": [[524, 539], ["tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMMultiFileIterator", "tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMShuffledIterator"], "methods", ["None"], ["", "", "def", "get_iterator", "(", "self", ",", "split", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "self", ".", "train", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "kwargs", "[", "'shuffle'", "]", "=", "True", "\n", "data_iter", "=", "LMMultiFileIterator", "(", "self", ".", "train", ",", "self", ".", "vocab", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "elif", "split", "in", "[", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "data", "=", "self", ".", "valid", "if", "split", "==", "'valid'", "else", "self", ".", "test", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "data_iter", "=", "LMShuffledIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_transfo_xl.get_lm_corpus": [[541, 571], ["os.path.join", "os.path.join", "os.path.exists", "logger.info", "torch.load", "os.path.exists", "logger.info", "logger.info", "tokenization_transfo_xl.TransfoXLCorpus", "torch.save", "io.open", "pickle.load", "os.path.join"], "function", ["None"], ["", "", "def", "get_lm_corpus", "(", "datadir", ",", "dataset", ")", ":", "\n", "    ", "fn", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pt'", ")", "\n", "fn_pickle", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading cached dataset...'", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn_pickle", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading cached dataset from pickle...'", ")", "\n", "with", "open", "(", "fn", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'Producing dataset {}...'", ".", "format", "(", "dataset", ")", ")", "\n", "kwargs", "=", "{", "}", "\n", "if", "dataset", "in", "[", "'wt103'", ",", "'wt2'", "]", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "", "elif", "dataset", "==", "'ptb'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "True", "\n", "", "elif", "dataset", "==", "'lm1b'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "kwargs", "[", "'vocab_file'", "]", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'1b_word_vocab.txt'", ")", "\n", "", "elif", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "pass", "\n", "\n", "", "corpus", "=", "TransfoXLCorpus", "(", "datadir", ",", "dataset", ",", "**", "kwargs", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "\n", "", "return", "corpus", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_pytorch_checkpoint_to_tf.convert_pytorch_checkpoint_to_tf": [[26, 93], ["model.state_dict", "tensorflow.reset_default_graph", "os.path.isdir", "os.makedirs", "iter", "tensorflow.dtypes.as_dtype", "tensorflow.get_variable", "session.run", "session.run", "tensorflow.Session", "tensorflow.train.Saver", "tf.train.Saver.save", "name.replace.replace", "tensorflow.variables_initializer", "convert_pytorch_checkpoint_to_tf.convert_pytorch_checkpoint_to_tf.to_tf_var_name"], "function", ["None"], ["def", "convert_pytorch_checkpoint_to_tf", "(", "model", ":", "BertModel", ",", "ckpt_dir", ":", "str", ",", "model_name", ":", "str", ")", ":", "\n", "\n", "    ", "\"\"\"\n    :param model:BertModel Pytorch model instance to be converted\n    :param ckpt_dir: Tensorflow model directory\n    :param model_name: model name\n    :return:\n\n    Currently supported HF models:\n        Y BertModel\n        N BertForMaskedLM\n        N BertForPreTraining\n        N BertForMultipleChoice\n        N BertForNextSentencePrediction\n        N BertForSequenceClassification\n        N BertForQuestionAnswering\n    \"\"\"", "\n", "\n", "tensors_to_transpose", "=", "(", "\n", "\"dense.weight\"", ",", "\n", "\"attention.self.query\"", ",", "\n", "\"attention.self.key\"", ",", "\n", "\"attention.self.value\"", "\n", ")", "\n", "\n", "var_map", "=", "(", "\n", "(", "'layer.'", ",", "'layer_'", ")", ",", "\n", "(", "'word_embeddings.weight'", ",", "'word_embeddings'", ")", ",", "\n", "(", "'position_embeddings.weight'", ",", "'position_embeddings'", ")", ",", "\n", "(", "'token_type_embeddings.weight'", ",", "'token_type_embeddings'", ")", ",", "\n", "(", "'.'", ",", "'/'", ")", ",", "\n", "(", "'LayerNorm/weight'", ",", "'LayerNorm/gamma'", ")", ",", "\n", "(", "'LayerNorm/bias'", ",", "'LayerNorm/beta'", ")", ",", "\n", "(", "'weight'", ",", "'kernel'", ")", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "ckpt_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "ckpt_dir", ")", "\n", "\n", "", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "def", "to_tf_var_name", "(", "name", ":", "str", ")", ":", "\n", "        ", "for", "patt", ",", "repl", "in", "iter", "(", "var_map", ")", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "patt", ",", "repl", ")", "\n", "", "return", "'bert/{}'", ".", "format", "(", "name", ")", "\n", "\n", "", "def", "create_tf_var", "(", "tensor", ":", "np", ".", "ndarray", ",", "name", ":", "str", ",", "session", ":", "tf", ".", "Session", ")", ":", "\n", "        ", "tf_dtype", "=", "tf", ".", "dtypes", ".", "as_dtype", "(", "tensor", ".", "dtype", ")", "\n", "tf_var", "=", "tf", ".", "get_variable", "(", "dtype", "=", "tf_dtype", ",", "shape", "=", "tensor", ".", "shape", ",", "name", "=", "name", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "session", ".", "run", "(", "tf", ".", "variables_initializer", "(", "[", "tf_var", "]", ")", ")", "\n", "session", ".", "run", "(", "tf_var", ")", "\n", "return", "tf_var", "\n", "\n", "", "tf", ".", "reset_default_graph", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "for", "var_name", "in", "state_dict", ":", "\n", "            ", "tf_name", "=", "to_tf_var_name", "(", "var_name", ")", "\n", "torch_tensor", "=", "state_dict", "[", "var_name", "]", ".", "numpy", "(", ")", "\n", "if", "any", "(", "[", "x", "in", "var_name", "for", "x", "in", "tensors_to_transpose", "]", ")", ":", "\n", "                ", "torch_tensor", "=", "torch_tensor", ".", "T", "\n", "", "tf_var", "=", "create_tf_var", "(", "tensor", "=", "torch_tensor", ",", "name", "=", "tf_name", ",", "session", "=", "session", ")", "\n", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "tf_var", ",", "torch_tensor", ")", "\n", "tf_weight", "=", "session", ".", "run", "(", "tf_var", ")", "\n", "print", "(", "\"Successfully created {}: {}\"", ".", "format", "(", "tf_name", ",", "np", ".", "allclose", "(", "tf_weight", ",", "torch_tensor", ")", ")", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "model_name", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "+", "\".ckpt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_pytorch_checkpoint_to_tf.main": [[95, 126], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pytorch_transformers.modeling.BertModel.from_pretrained", "convert_pytorch_checkpoint_to_tf.convert_pytorch_checkpoint_to_tf", "torch.load"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_pytorch_checkpoint_to_tf.convert_pytorch_checkpoint_to_tf"], ["", "", "def", "main", "(", "raw_args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"model name e.g. bert-base-uncased\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"Directory containing pytorch model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pytorch_model_path\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"/path/to/<pytorch-model-name>.bin\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tf_cache_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Directory in which to save tensorflow model\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "raw_args", ")", "\n", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", "=", "args", ".", "model_name", ",", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "pytorch_model_path", ")", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "\n", ")", "\n", "\n", "convert_pytorch_checkpoint_to_tf", "(", "\n", "model", "=", "model", ",", "\n", "ckpt_dir", "=", "args", ".", "tf_cache_dir", ",", "\n", "model_name", "=", "args", ".", "model_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.__init__": [[64, 87], ["tokenization_utils.PreTrainedTokenizer.__init__", "spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "max_len", "=", "None", ",", "\n", "do_lower_case", "=", "False", ",", "remove_space", "=", "True", ",", "keep_accents", "=", "False", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "sep_token", "=", "\"<sep>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "cls_token", "=", "\"<cls>\"", ",", "mask_token", "=", "\"<mask>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<eop>\"", ",", "\"<eod>\"", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "additional_special_tokens", "=", "\n", "additional_special_tokens", ",", "**", "kwargs", ")", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", ")", "\n", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "remove_space", "=", "remove_space", "\n", "self", ".", "keep_accents", "=", "keep_accents", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.vocab_size": [[88, 91], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.__getstate__": [[92, 96], ["tokenization_xlnet.XLNetTokenizer.__dict__.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "state", "[", "\"sp_model\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.__setstate__": [[97, 106], ["spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "d", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", ")", "\n", "", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "self", ".", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.preprocess_text": [[107, 124], ["outputs.lower.lower.replace().replace", "isinstance", "outputs.lower.lower.decode", "unicodedata.normalize", "outputs.lower.lower.lower", "inputs.strip().split", "outputs.lower.lower.replace", "inputs.strip", "unicodedata.combining"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "preprocess_text", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "remove_space", ":", "\n", "            ", "outputs", "=", "' '", ".", "join", "(", "inputs", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "inputs", "\n", "", "outputs", "=", "outputs", ".", "replace", "(", "\"``\"", ",", "'\"'", ")", ".", "replace", "(", "\"''\"", ",", "'\"'", ")", "\n", "\n", "if", "six", ".", "PY2", "and", "isinstance", "(", "outputs", ",", "str", ")", ":", "\n", "            ", "outputs", "=", "outputs", ".", "decode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "self", ".", "keep_accents", ":", "\n", "            ", "outputs", "=", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "outputs", ")", "\n", "outputs", "=", "''", ".", "join", "(", "[", "c", "for", "c", "in", "outputs", "if", "not", "unicodedata", ".", "combining", "(", "c", ")", "]", ")", "\n", "", "if", "self", ".", "do_lower_case", ":", "\n", "            ", "outputs", "=", "outputs", ".", "lower", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer._tokenize": [[125, 163], ["tokenization_xlnet.XLNetTokenizer.preprocess_text", "isinstance", "text.encode.encode.encode", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.sp_model.SampleEncodeAsPieces", "piece[].isdigit", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.append", "new_pieces.extend", "new_pieces.append", "isinstance", "ret_pieces.append", "len", "piece[].replace", "piece.decode.decode.decode", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.preprocess_text", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "return_unicode", "=", "True", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n            return_unicode is used only for py2\n        \"\"\"", "\n", "text", "=", "self", ".", "preprocess_text", "(", "text", ")", "\n", "# note(zhiliny): in some systems, sentencepiece only accepts str for py2", "\n", "if", "six", ".", "PY2", "and", "isinstance", "(", "text", ",", "unicode", ")", ":", "\n", "            ", "text", "=", "text", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "sample", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "new_pieces", "=", "[", "]", "\n", "for", "piece", "in", "pieces", ":", "\n", "            ", "if", "len", "(", "piece", ")", ">", "1", "and", "piece", "[", "-", "1", "]", "==", "','", "and", "piece", "[", "-", "2", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "cur_pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "\n", "piece", "[", ":", "-", "1", "]", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "''", ")", ")", "\n", "if", "piece", "[", "0", "]", "!=", "SPIECE_UNDERLINE", "and", "cur_pieces", "[", "0", "]", "[", "0", "]", "==", "SPIECE_UNDERLINE", ":", "\n", "                    ", "if", "len", "(", "cur_pieces", "[", "0", "]", ")", "==", "1", ":", "\n", "                        ", "cur_pieces", "=", "cur_pieces", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                        ", "cur_pieces", "[", "0", "]", "=", "cur_pieces", "[", "0", "]", "[", "1", ":", "]", "\n", "", "", "cur_pieces", ".", "append", "(", "piece", "[", "-", "1", "]", ")", "\n", "new_pieces", ".", "extend", "(", "cur_pieces", ")", "\n", "", "else", ":", "\n", "                ", "new_pieces", ".", "append", "(", "piece", ")", "\n", "\n", "# note(zhiliny): convert back to unicode for py2", "\n", "", "", "if", "six", ".", "PY2", "and", "return_unicode", ":", "\n", "            ", "ret_pieces", "=", "[", "]", "\n", "for", "piece", "in", "new_pieces", ":", "\n", "                ", "if", "isinstance", "(", "piece", ",", "str", ")", ":", "\n", "                    ", "piece", "=", "piece", ".", "decode", "(", "'utf-8'", ")", "\n", "", "ret_pieces", ".", "append", "(", "piece", ")", "\n", "", "new_pieces", "=", "ret_pieces", "\n", "\n", "", "return", "new_pieces", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer._convert_token_to_id": [[164, 167], ["tokenization_xlnet.XLNetTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer._convert_id_to_token": [[168, 174], ["tokenization_xlnet.XLNetTokenizer.sp_model.IdToPiece", "isinstance", "token.decode.decode.decode"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ",", "return_unicode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "token", "=", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "if", "six", ".", "PY2", "and", "return_unicode", "and", "isinstance", "(", "token", ",", "str", ")", ":", "\n", "            ", "token", "=", "token", ".", "decode", "(", "'utf-8'", ")", "\n", "", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_string": [[175, 179], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "' '", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.add_special_tokens_single_sentence": [[180, 188], ["tokenization_xlnet.XLNetTokenizer._convert_token_to_id", "tokenization_xlnet.XLNetTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence pair for sequence classification tasks.\n        An XLNet sequence pair has the following format: A [SEP] B [SEP][CLS]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "cls", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "\n", "return", "token_ids", "+", "sep", "+", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.add_special_tokens_sentences_pair": [[189, 197], ["tokenization_xlnet.XLNetTokenizer._convert_token_to_id", "tokenization_xlnet.XLNetTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence for sequence classification tasks.\n        An XLNet sequence has the following format: X [SEP][CLS]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "cls", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "\n", "return", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "+", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlnet.XLNetTokenizer.save_vocabulary": [[198, 211], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_roberta_checkpoint_to_pytorch.convert_roberta_checkpoint_to_pytorch": [[42, 157], ["fairseq.models.roberta.RobertaModel.from_pretrained", "FairseqRobertaModel.from_pretrained.eval", "pytorch_transformers.modeling_bert.BertConfig", "print", "model.eval", "torch.zeros_like", "range", "FairseqRobertaModel.from_pretrained.encode().unsqueeze", "print", "torch.allclose", "print", "print", "model.save_pretrained", "pytorch_transformers.modeling_roberta.RobertaForSequenceClassification", "pytorch_transformers.modeling_roberta.RobertaForMaskedLM", "model", "Exception", "torch.Size", "FairseqRobertaModel.from_pretrained.encode", "FairseqRobertaModel.from_pretrained.extract_features", "FairseqRobertaModel.from_pretrained.model"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_eval.eval", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.save_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.model", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.ChartParser.model"], ["def", "convert_roberta_checkpoint_to_pytorch", "(", "roberta_checkpoint_path", ",", "pytorch_dump_folder_path", ",", "classification_head", ")", ":", "\n", "    ", "\"\"\"\n    Copy/paste/tweak roberta's weights to our BERT structure.\n    \"\"\"", "\n", "roberta", "=", "FairseqRobertaModel", ".", "from_pretrained", "(", "roberta_checkpoint_path", ")", "\n", "roberta", ".", "eval", "(", ")", "# disable dropout", "\n", "config", "=", "BertConfig", "(", "\n", "vocab_size_or_config_json_file", "=", "50265", ",", "\n", "hidden_size", "=", "roberta", ".", "args", ".", "encoder_embed_dim", ",", "\n", "num_hidden_layers", "=", "roberta", ".", "args", ".", "encoder_layers", ",", "\n", "num_attention_heads", "=", "roberta", ".", "args", ".", "encoder_attention_heads", ",", "\n", "intermediate_size", "=", "roberta", ".", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "max_position_embeddings", "=", "514", ",", "\n", "type_vocab_size", "=", "1", ",", "\n", ")", "\n", "if", "classification_head", ":", "\n", "        ", "config", ".", "num_labels", "=", "roberta", ".", "args", ".", "num_classes", "\n", "", "print", "(", "\"Our BERT config:\"", ",", "config", ")", "\n", "\n", "model", "=", "RobertaForSequenceClassification", "(", "config", ")", "if", "classification_head", "else", "RobertaForMaskedLM", "(", "config", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Now let's copy all the weights.", "\n", "# Embeddings", "\n", "roberta_sent_encoder", "=", "roberta", ".", "model", ".", "decoder", ".", "sentence_encoder", "\n", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", "=", "roberta_sent_encoder", ".", "embed_tokens", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "position_embeddings", ".", "weight", "=", "roberta_sent_encoder", ".", "embed_positions", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "=", "torch", ".", "zeros_like", "(", "model", ".", "roberta", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ")", "# just zero them out b/c RoBERTa doesn't use them.", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "weight", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "bias", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "bias", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "variance_epsilon", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "eps", "\n", "\n", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", ":", "\n", "# Encoder: start of layer", "\n", "        ", "layer", ":", "BertLayer", "=", "model", ".", "roberta", ".", "encoder", ".", "layer", "[", "i", "]", "\n", "roberta_layer", ":", "TransformerSentenceEncoderLayer", "=", "roberta_sent_encoder", ".", "layers", "[", "i", "]", "\n", "\n", "### self attention", "\n", "self_attn", ":", "BertSelfAttention", "=", "layer", ".", "attention", ".", "self", "\n", "assert", "(", "\n", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", ".", "shape", "==", "torch", ".", "Size", "(", "(", "3", "*", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ")", "\n", ")", "\n", "# we use three distinct linear layers so we split the source layer here.", "\n", "self_attn", ".", "query", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", "[", ":", "config", ".", "hidden_size", ",", ":", "]", "\n", "self_attn", ".", "query", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_bias", "[", ":", "config", ".", "hidden_size", "]", "\n", "self_attn", ".", "key", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", "[", "config", ".", "hidden_size", ":", "2", "*", "config", ".", "hidden_size", ",", ":", "]", "\n", "self_attn", ".", "key", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_bias", "[", "config", ".", "hidden_size", ":", "2", "*", "config", ".", "hidden_size", "]", "\n", "self_attn", ".", "value", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_weight", "[", "2", "*", "config", ".", "hidden_size", ":", ",", ":", "]", "\n", "self_attn", ".", "value", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "in_proj_bias", "[", "2", "*", "config", ".", "hidden_size", ":", "]", "\n", "\n", "### self-attention output", "\n", "self_output", ":", "BertSelfOutput", "=", "layer", ".", "attention", ".", "output", "\n", "assert", "(", "\n", "self_output", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "weight", ".", "shape", "\n", ")", "\n", "self_output", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "weight", "\n", "self_output", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "bias", "\n", "self_output", ".", "LayerNorm", ".", "weight", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "weight", "\n", "self_output", ".", "LayerNorm", ".", "bias", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "bias", "\n", "self_output", ".", "LayerNorm", ".", "variance_epsilon", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "eps", "\n", "\n", "### intermediate", "\n", "intermediate", ":", "BertIntermediate", "=", "layer", ".", "intermediate", "\n", "assert", "(", "\n", "intermediate", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "fc1", ".", "weight", ".", "shape", "\n", ")", "\n", "intermediate", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "fc1", ".", "weight", "\n", "intermediate", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "fc1", ".", "bias", "\n", "\n", "### output", "\n", "bert_output", ":", "BertOutput", "=", "layer", ".", "output", "\n", "assert", "(", "\n", "bert_output", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "fc2", ".", "weight", ".", "shape", "\n", ")", "\n", "bert_output", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "fc2", ".", "weight", "\n", "bert_output", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "fc2", ".", "bias", "\n", "bert_output", ".", "LayerNorm", ".", "weight", "=", "roberta_layer", ".", "final_layer_norm", ".", "weight", "\n", "bert_output", ".", "LayerNorm", ".", "bias", "=", "roberta_layer", ".", "final_layer_norm", ".", "bias", "\n", "bert_output", ".", "LayerNorm", ".", "variance_epsilon", "=", "roberta_layer", ".", "final_layer_norm", ".", "eps", "\n", "#### end of layer", "\n", "\n", "", "if", "classification_head", ":", "\n", "        ", "model", ".", "classifier", ".", "dense", ".", "weight", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "dense", ".", "weight", "\n", "model", ".", "classifier", ".", "dense", ".", "bias", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "dense", ".", "bias", "\n", "model", ".", "classifier", ".", "out_proj", ".", "weight", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "out_proj", ".", "weight", "\n", "model", ".", "classifier", ".", "out_proj", ".", "bias", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", ".", "out_proj", ".", "bias", "\n", "", "else", ":", "\n", "# LM Head", "\n", "        ", "model", ".", "lm_head", ".", "dense", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "dense", ".", "weight", "\n", "model", ".", "lm_head", ".", "dense", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "dense", ".", "bias", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "weight", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "bias", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "variance_epsilon", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "eps", "\n", "model", ".", "lm_head", ".", "decoder", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "weight", "\n", "model", ".", "lm_head", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "bias", "\n", "\n", "# Let's check that we get the same results.", "\n", "", "input_ids", ":", "torch", ".", "Tensor", "=", "roberta", ".", "encode", "(", "SAMPLE_TEXT", ")", ".", "unsqueeze", "(", "0", ")", "# batch of size 1", "\n", "\n", "our_output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "if", "classification_head", ":", "\n", "        ", "their_output", "=", "roberta", ".", "model", ".", "classification_heads", "[", "'mnli'", "]", "(", "roberta", ".", "extract_features", "(", "input_ids", ")", ")", "\n", "", "else", ":", "\n", "        ", "their_output", "=", "roberta", ".", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "", "print", "(", "our_output", ".", "shape", ",", "their_output", ".", "shape", ")", "\n", "success", "=", "torch", ".", "allclose", "(", "our_output", ",", "their_output", ",", "atol", "=", "1e-3", ")", "\n", "print", "(", "\n", "\"Do both models output the same tensors?\"", ",", "\n", "\"\ud83d\udd25\"", "if", "success", "else", "\"\ud83d\udca9\"", "\n", ")", "\n", "if", "not", "success", ":", "\n", "        ", "raise", "Exception", "(", "\"Something went wRoNg\"", ")", "\n", "\n", "", "print", "(", "f\"Saving model to {pytorch_dump_folder_path}\"", ")", "\n", "model", ".", "save_pretrained", "(", "pytorch_dump_folder_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Config.__init__": [[125, 196], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "\n", "num_labels", "=", "1", ",", "\n", "summary_type", "=", "'cls_index'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs GPT2Config.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `GPT2Model` or a configuration json file.\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "super", "(", "GPT2Config", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Config.max_position_embeddings": [[199, 202], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Config.hidden_size": [[203, 206], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Config.num_attention_heads": [[207, 210], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Config.num_hidden_layers": [[211, 214], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Attention.__init__": [[218, 234], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Attention.prune_heads": [[235, 250], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "len", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Attention._attn": [[251, 270], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_gpt2.Attention.attn_dropout", "modeling_gpt2.Attention.size", "modeling_gpt2.Attention.size", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Attention.merge_heads": [[271, 275], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Attention.split_heads": [[276, 283], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Attention.forward": [[284, 305], ["modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.split", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "modeling_gpt2.Attention.resid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.MLP.__init__": [[308, 315], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.MLP.forward": [[316, 320], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.dropout", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Block.__init__": [[323, 330], ["torch.Module.__init__", "modeling_bert.BertLayerNorm", "modeling_gpt2.Attention", "modeling_bert.BertLayerNorm", "modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.Block.forward": [[331, 341], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "modeling_gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "output_attn", "=", "self", ".", "attn", "(", "self", ".", "ln_1", "(", "x", ")", ",", "layer_past", "=", "layer_past", ",", "head_mask", "=", "head_mask", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2PreTrainedModel.__init__": [[352, 354], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPT2PreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2PreTrainedModel.init_weights": [[355, 367], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Model.__init__": [[443, 455], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "modeling_bert.BertLayerNorm", "modeling_gpt2.GPT2Model.apply", "modeling_gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2Model", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Model._resize_token_embeddings": [[456, 459], ["modeling_gpt2.GPT2Model._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "wte", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "wte", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Model._prune_heads": [[460, 466], ["heads_to_prune.items", "modeling_gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2Model.forward": [[467, 537], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wpe", "modeling_gpt2.GPT2Model.drop", "enumerate", "modeling_gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "modeling_gpt2.GPT2Model.wte", "zip", "block", "tuple", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "token_type_ids.view.view.size", "hidden_states.view.view.size", "tuple.append", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "t.view", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "past", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_ids", ".", "size", "(", "-", "1", ")", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "hidden_states", ",", "layer_past", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", "presents", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2LMHeadModel.__init__": [[576, 583], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_gpt2.GPT2LMHeadModel.apply", "modeling_gpt2.GPT2LMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2LMHeadModel.tie_weights": [[584, 590], ["modeling_gpt2.GPT2LMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "wte", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2LMHeadModel.forward": [[591, 610], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "labels", "=", "None", ",", "past", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "past", "=", "past", ",", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[694, 701], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_gpt2.GPT2DoubleHeadsModel.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2DoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2DoubleHeadsModel.tie_weights": [[702, 708], ["modeling_gpt2.GPT2DoubleHeadsModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "wte", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[709, 733], ["modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_gpt2.GPT2DoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mc_token_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "past", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "past", "=", "past", ",", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.load_tf_weights_in_gpt2": [[45, 97], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'w'", "or", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'wpe'", "or", "l", "[", "0", "]", "==", "'wte'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.gelu": [[99, 101], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[29, 41], ["pytorch_transformers.modeling_bert.BertConfig.from_json_file", "print", "pytorch_transformers.modeling_bert.BertForPreTraining", "pytorch_transformers.modeling_bert.load_tf_weights_in_bert", "print", "torch.save", "pytorch_transformers.modeling_bert.BertForPreTraining.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.load_tf_weights_in_bert", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_openai_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch": [[33, 52], ["pytorch_transformers.modeling_openai.OpenAIGPTModel", "pytorch_transformers.modeling_openai.load_tf_weights_in_openai_gpt", "print", "torch.save", "print", "pytorch_transformers.modeling_openai.OpenAIGPTConfig", "pytorch_transformers.modeling_openai.OpenAIGPTConfig", "pytorch_transformers.modeling_openai.OpenAIGPTModel.state_dict", "io.open", "f.write", "pytorch_transformers.modeling_openai.OpenAIGPTConfig.to_json_string"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.load_tf_weights_in_openai_gpt", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["def", "convert_openai_checkpoint_to_pytorch", "(", "openai_checkpoint_folder_path", ",", "openai_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "openai_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", "openai_config_file", ")", "\n", "", "model", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_openai_gpt", "(", "model", ",", "config", ",", "openai_checkpoint_folder_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetConfig.__init__": [[238, 309], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "32000", ",", "\n", "d_model", "=", "1024", ",", "\n", "n_layer", "=", "24", ",", "\n", "n_head", "=", "16", ",", "\n", "d_inner", "=", "4096", ",", "\n", "ff_activation", "=", "\"gelu\"", ",", "\n", "untie_r", "=", "True", ",", "\n", "attn_type", "=", "\"bi\"", ",", "\n", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "\n", "dropout", "=", "0.1", ",", "\n", "mem_len", "=", "None", ",", "\n", "reuse_len", "=", "None", ",", "\n", "bi_data", "=", "False", ",", "\n", "clamp_len", "=", "-", "1", ",", "\n", "same_length", "=", "False", ",", "\n", "\n", "finetuning_task", "=", "None", ",", "\n", "num_labels", "=", "2", ",", "\n", "summary_type", "=", "'last'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "'tanh'", ",", "\n", "summary_last_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs XLNetConfig.\n        \"\"\"", "\n", "super", "(", "XLNetConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "assert", "d_model", "%", "n_head", "==", "0", "\n", "self", ".", "d_head", "=", "d_model", "//", "n_head", "\n", "self", ".", "ff_activation", "=", "ff_activation", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "reuse_len", "=", "reuse_len", "\n", "self", ".", "bi_data", "=", "bi_data", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "\n", "self", ".", "finetuning_task", "=", "finetuning_task", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_last_dropout", "=", "summary_last_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetConfig.max_position_embeddings": [[311, 314], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetConfig.vocab_size": [[319, 322], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetConfig.hidden_size": [[323, 326], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetConfig.num_attention_heads": [[327, 330], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetConfig.num_hidden_layers": [[331, 334], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.__init__": [[356, 383], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "XLNetLayerNorm", "torch.nn.Dropout", "ValueError", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "k", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "o", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_s_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "seg_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.prune_heads": [[384, 386], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift": [[387, 399], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "# x = x[:, 0:klen, :, :]", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core": [[400, 438], ["torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_shift", "torch.nn.functional.softmax", "modeling_xlnet.XLNetRelativeAttention.dropout", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift"], ["", "def", "rel_attn_core", "(", "self", ",", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "None", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "# content based attention score", "\n", "ac", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift", "(", "bd", ",", "klen", "=", "ac", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "torch", ".", "einsum", "(", "'ibnd,snd->ibns'", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "torch", ".", "einsum", "(", "'ijbs,ibns->ijbn'", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "attn_score", "=", "attn_score", "-", "1e30", "*", "attn_mask", "\n", "\n", "# attention probability", "\n", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "attn_prob", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.post_attention": [[439, 450], ["torch.einsum", "modeling_xlnet.XLNetRelativeAttention.dropout", "modeling_xlnet.XLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "h", ",", "attn_vec", ",", "residual", "=", "True", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "attn_out", "=", "torch", ".", "einsum", "(", "'ibnd,hnd->ibh'", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ")", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.forward": [[451, 543], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.cat", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.cat", "mems.dim", "mems.dim"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core"], ["", "def", "forward", "(", "self", ",", "h", ",", "g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "\n", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "###### Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "##### h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec_h", ")", "\n", "\n", "##### g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "torch", ".", "einsum", "(", "'mbnd,mlb->lbnd'", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "torch", ".", "einsum", "(", "'lbnd,mlb->mbnd'", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "g", ",", "attn_vec_g", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "###### Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetFeedForward.__init__": [[545, 556], ["torch.nn.Module.__init__", "XLNetLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "layer_1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_inner", ")", "\n", "self", ".", "layer_2", "=", "nn", ".", "Linear", "(", "config", ".", "d_inner", ",", "config", ".", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "ff_activation", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetFeedForward.forward": [[557, 566], ["modeling_xlnet.XLNetFeedForward.layer_1", "modeling_xlnet.XLNetFeedForward.activation_function", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_2", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetLayer.__init__": [[568, 573], ["torch.nn.Module.__init__", "modeling_xlnet.XLNetRelativeAttention", "modeling_xlnet.XLNetFeedForward", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rel_attn", "=", "XLNetRelativeAttention", "(", "config", ")", "\n", "self", ".", "ff", "=", "XLNetFeedForward", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetLayer.forward": [[574, 588], ["modeling_xlnet.XLNetLayer.rel_attn", "modeling_xlnet.XLNetLayer.ff", "modeling_xlnet.XLNetLayer.ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output_h", ",", "output_g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "output_h", ",", "output_g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "mems", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetPreTrainedModel.__init__": [[599, 601], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLNetPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetPreTrainedModel.init_weights": [[602, 621], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "param.data.normal_", "module.mask_emb.data.normal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XLNetRelativeAttention", ")", ":", "\n", "            ", "for", "param", "in", "[", "module", ".", "q", ",", "module", ".", "k", ",", "module", ".", "v", ",", "module", ".", "o", ",", "module", ".", "r", ",", "\n", "module", ".", "r_r_bias", ",", "module", ".", "r_s_bias", ",", "module", ".", "r_w_bias", ",", "\n", "module", ".", "seg_embed", "]", ":", "\n", "                ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetModel", ")", ":", "\n", "                ", "module", ".", "mask_emb", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.__init__": [[722, 742], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.Dropout", "modeling_xlnet.XLNetModel.apply", "torch.FloatTensor", "modeling_xlnet.XLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "config", ".", "d_model", ")", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "XLNetLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel._resize_token_embeddings": [[743, 746], ["modeling_xlnet.XLNetModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "word_embedding", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "word_embedding", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel._prune_heads": [[747, 749], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.create_mask": [[750, 779], ["torch.ones", "torch.triu", "torch.zeros", "torch.cat", "torch.cat.to", "torch.tril", "torch.cat", "next", "modeling_xlnet.XLNetModel.parameters"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "torch", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_up", "=", "torch", ".", "triu", "(", "attn_mask", ",", "diagonal", "=", "1", ")", "\n", "attn_mask_pad", "=", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "attn_mask_pad", ",", "mask_up", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_lo", "=", "torch", ".", "tril", "(", "attn_mask", ",", "diagonal", "=", "-", "1", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_lo", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "ret", "=", "ret", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.cache_mem": [[780, 794], ["new_mem.detach", "torch.cat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "mem_len", "is", "None", "or", "self", ".", "mem_len", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "                ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "                ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "                ", "new_mem", "=", "torch", ".", "cat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "dim", "=", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "", "return", "new_mem", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.positional_embedding": [[795, 805], ["torch.einsum", "torch.cat", "pos_emb.expand.expand.expand", "torch.sin", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "einsum", "(", "'i,d->id'", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "sinusoid_inp", ")", ",", "torch", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "pos_emb", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.relative_positional_encoding": [[806, 844], ["torch.arange", "modeling_xlnet.XLNetModel.to", "torch.pow", "torch.arange", "torch.arange", "torch.cat", "torch.arange", "modeling_xlnet.XLNetModel.positional_embedding", "next", "ValueError", "fwd_pos_seq.clamp.clamp.clamp", "bwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "fwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.parameters"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "inv_freq", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown `attn_type` {}.'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bwd_pos_seq", "=", "torch", ".", "arange", "(", "-", "beg", ",", "-", "end", ",", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "bwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "torch", ".", "cat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "pos_emb", "=", "pos_emb", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.forward": [[845, 988], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_xlnet.XLNetModel.word_embedding", "modeling_xlnet.XLNetModel.dropout", "modeling_xlnet.XLNetModel.relative_positional_encoding", "modeling_xlnet.XLNetModel.dropout", "enumerate", "modeling_xlnet.XLNetModel.dropout", "token_type_ids.transpose().contiguous", "input_mask.transpose().contiguous", "attention_mask.transpose().contiguous", "perm_mask.permute().contiguous", "target_mapping.permute().contiguous", "next", "next", "modeling_xlnet.XLNetModel.create_mask", "torch.zeros().to", "torch.cat", "torch.cat", "modeling_xlnet.XLNetModel.mask_emb.expand", "modeling_xlnet.XLNetModel.dropout", "torch.zeros", "torch.cat", "torch.nn.functional.one_hot().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "modeling_xlnet.XLNetModel.permute().contiguous", "tuple", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "modeling_xlnet.XLNetModel.parameters", "modeling_xlnet.XLNetModel.parameters", "ValueError", "torch.eye().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "token_type_ids.transpose", "input_mask.transpose", "attention_mask.transpose", "perm_mask.permute", "target_mapping.permute", "torch.zeros", "torch.zeros().to", "torch.nn.functional.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.cache_mem", "modeling_xlnet.XLNetModel.permute", "t.permute().contiguous", "torch.eye", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "h.permute().contiguous", "hs.permute().contiguous", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.parameters", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "h.permute", "hs.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.relative_positional_encoding", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.create_mask", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetModel.cache_mem"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "        ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "token_type_ids", "=", "token_type_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "input_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "attention_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "perm_mask", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "target_mapping", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "qlen", ",", "bsz", "=", "input_ids", ".", "shape", "[", "0", "]", ",", "input_ids", ".", "shape", "[", "1", "]", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "shape", "[", "0", "]", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "##### Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported attention type: {}'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "\"You can only use one of input_mask (uses 1 for padding) \"", "\n", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "attention_mask", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "mems_mask", "=", "torch", ".", "zeros", "(", "[", "data_mask", ".", "shape", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ")", ".", "to", "(", "data_mask", ")", "\n", "data_mask", "=", "torch", ".", "cat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "(", "attn_mask", ">", "0", ")", ".", "to", "(", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "torch", ".", "eye", "(", "qlen", ")", ".", "to", "(", "attn_mask", ")", "\n", "non_tgt_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", ".", "to", "(", "attn_mask", ")", ",", "non_tgt_mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "non_tgt_mask", "=", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ")", ".", "to", "(", "attn_mask", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "##### Word embeddings and prepare h & g hidden states", "\n", "", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "self", ".", "mask_emb", ".", "expand", "(", "target_mapping", ".", "shape", "[", "0", "]", ",", "bsz", ",", "-", "1", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "##### Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "mem_pad", "=", "torch", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "cat_ids", "=", "torch", ".", "cat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "seg_mat", "=", "(", "token_type_ids", "[", ":", ",", "None", "]", "!=", "cat_ids", "[", "None", ",", ":", "]", ")", ".", "long", "(", ")", "\n", "seg_mat", "=", "F", ".", "one_hot", "(", "seg_mat", ",", "num_classes", "=", "2", ")", ".", "to", "(", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "##### Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "# cache new mems", "\n", "            ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "output_h", ",", "output_g", ",", "attn_mask_h", "=", "non_tgt_mask", ",", "attn_mask_g", "=", "attn_mask", ",", "\n", "r", "=", "pos_emb", ",", "seg_mat", "=", "seg_mat", ",", "mems", "=", "mems", "[", "i", "]", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "output", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ",", "new_mems", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "h", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "hs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "attentions", "=", "tuple", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, new_mems, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetLMHeadModel.__init__": [[1033, 1043], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetLMHeadModel.apply", "modeling_xlnet.XLNetLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "lm_loss", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetLMHeadModel.tie_weights": [[1044, 1048], ["modeling_xlnet.XLNetLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_loss", ",", "self", ".", "transformer", ".", "word_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetLMHeadModel.forward": [[1049, 1069], ["modeling_xlnet.XLNetLMHeadModel.transformer", "modeling_xlnet.XLNetLMHeadModel.lm_loss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetLMHeadModel.view", "labels.view", "modeling_xlnet.XLNetLMHeadModel.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "\n", "logits", "=", "self", ".", "lm_loss", "(", "transformer_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Flatten the tokens", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, mems, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetForSequenceClassification.__init__": [[1109, 1118], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetForSequenceClassification.forward": [[1119, 1144], ["modeling_xlnet.XLNetForSequenceClassification.transformer", "modeling_xlnet.XLNetForSequenceClassification.sequence_summary", "modeling_xlnet.XLNetForSequenceClassification.logits_proj", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, mems, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetForQuestionAnswering.__init__": [[1208, 1219], ["modeling_xlnet.XLNetPreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass", "modeling_xlnet.XLNetForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.XLNetForQuestionAnswering.forward": [[1220, 1285], ["modeling_xlnet.XLNetForQuestionAnswering.transformer", "modeling_xlnet.XLNetForQuestionAnswering.start_logits", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "# get the representation of START as weighted sum of hidden states", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "# Shape (batch size,): one single `cls_logits` for each sample", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.build_tf_xlnet_to_pytorch_map": [[49, 118], ["hasattr", "tf_to_pt_map.update", "enumerate", "tf_to_pt_map.update", "hasattr", "tf_to_pt_map.update", "hasattr", "hasattr", "r_r_list.append", "r_w_list.append", "r_s_list.append", "seg_embed_list.append"], "function", ["None"], ["def", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", "=", "None", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        I use a map to keep the PyTorch model as\n        identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "'lm_loss'", ")", ":", "\n", "# We will load also the output bias", "\n", "            ", "tf_to_pt_map", "[", "'model/lm_loss/bias'", "]", "=", "model", ".", "lm_loss", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'sequence_summary'", ")", "and", "'model/sequnece_summary/summary/kernel'", "in", "tf_weights", ":", "\n", "# We will load also the sequence summary", "\n", "            ", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/kernel'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/bias'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'logits_proj'", ")", "and", "config", ".", "finetuning_task", "is", "not", "None", "and", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "in", "tf_weights", ":", "\n", "            ", "tf_to_pt_map", "[", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/regression_{}/logit/bias'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "bias", "\n", "\n", "# Now load the rest of the transformer", "\n", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings and output", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "'model/transformer/word_embedding/lookup_table'", ":", "model", ".", "word_embedding", ".", "weight", ",", "\n", "'model/transformer/mask_emb/mask_emb'", ":", "model", ".", "mask_emb", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layer", ")", ":", "\n", "        ", "layer_str", "=", "\"model/transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "rel_attn", ".", "o", ",", "\n", "layer_str", "+", "\"rel_attn/q/kernel\"", ":", "b", ".", "rel_attn", ".", "q", ",", "\n", "layer_str", "+", "\"rel_attn/k/kernel\"", ":", "b", ".", "rel_attn", ".", "k", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "rel_attn", ".", "r", ",", "\n", "layer_str", "+", "\"rel_attn/v/kernel\"", ":", "b", ".", "rel_attn", ".", "v", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "ff", ".", "layer_1", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "ff", ".", "layer_1", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "ff", ".", "layer_2", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "ff", ".", "layer_2", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "r_s_list", "=", "[", "]", "\n", "seg_embed_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layer", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_w_bias", ")", "\n", "r_s_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_s_bias", ")", "\n", "seg_embed_list", ".", "append", "(", "b", ".", "rel_attn", ".", "seg_embed", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "r_s_list", "=", "[", "model", ".", "r_s_bias", "]", "\n", "seg_embed_list", "=", "[", "model", ".", "seg_embed", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'model/transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'model/transformer/r_w_bias'", ":", "r_w_list", ",", "\n", "'model/transformer/r_s_bias'", ":", "r_s_list", ",", "\n", "'model/transformer/seg_embed'", ":", "seg_embed_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.load_tf_weights_in_xlnet": [[119, 177], ["tf.train.list_variables", "modeling_xlnet.build_tf_xlnet_to_pytorch_map", "build_tf_xlnet_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "logger.info", "isinstance", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "logger.info", "logger.info", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "len", "logger.info", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.build_tf_xlnet_to_pytorch_map"], ["", "def", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Load weights from TF model", "\n", "", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", ")", "\n", "\n", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Importing {}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "not", "in", "tf_weights", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} not in tf pre-trained weights, skipping\"", ".", "format", "(", "name", ")", ")", "\n", "continue", "\n", "", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "and", "(", "'ff'", "in", "name", "or", "'summary'", "in", "name", "or", "'logit'", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing\"", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "isinstance", "(", "pointer", ",", "list", ")", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.gelu": [[179, 186], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu (not exactly the same as BERT)\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.swish": [[188, 190], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.ConstantLRSchedule.__init__": [[29, 31], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "ConstantLRSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "lambda", "_", ":", "1.0", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupConstantSchedule.__init__": [[38, 41], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "super", "(", "WarmupConstantSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupConstantSchedule.lr_lambda": [[42, 46], ["float", "float", "max"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "warmup_steps", ")", ")", "\n", "", "return", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupLinearSchedule.__init__": [[53, 57], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "super", "(", "WarmupLinearSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupLinearSchedule.lr_lambda": [[58, 62], ["max", "float", "float", "float", "float", "max", "max"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", ")", "\n", "", "return", "max", "(", "0.0", ",", "float", "(", "self", ".", "t_total", "-", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupCosineSchedule.__init__": [[70, 75], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "cycles", "=", ".5", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "cycles", "=", "cycles", "\n", "super", "(", "WarmupCosineSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupCosineSchedule.lr_lambda": [[76, 82], ["max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "warmup_steps", ")", ")", "\n", "# progress after warmup", "\n", "", "progress", "=", "float", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", "\n", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "float", "(", "self", ".", "cycles", ")", "*", "2.0", "*", "progress", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupCosineWithHardRestartsSchedule.__init__": [[90, 95], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "cycles", "=", "1.", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "cycles", "=", "cycles", "\n", "super", "(", "WarmupCosineWithHardRestartsSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.WarmupCosineWithHardRestartsSchedule.lr_lambda": [[96, 104], ["max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "methods", ["None"], ["", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", ")", "\n", "# progress after warmup", "\n", "", "progress", "=", "float", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", "\n", "if", "progress", ">=", "1.0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "(", "(", "float", "(", "self", ".", "cycles", ")", "*", "progress", ")", "%", "1.0", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.AdamW.__init__": [[117, 129], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "weight_decay", "=", "0.0", ",", "correct_bias", "=", "True", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "correct_bias", "=", "correct_bias", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.optimization.AdamW.step": [[130, 190], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1.0", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1.0", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "step_size", "=", "group", "[", "'lr'", "]", "\n", "if", "group", "[", "'correct_bias'", "]", ":", "# No bias correction for Bert", "\n", "                    ", "bias_correction1", "=", "1.0", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1.0", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "step_size", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", "*", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.__init__": [[105, 121], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_gpt2.GPT2Tokenizer.encoder.items", "tokenization_gpt2.GPT2Tokenizer.byte_encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.bytes_to_unicode"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "unk_token", "=", "\"<|endoftext|>\"", ",", "\n", "bos_token", "=", "\"<|endoftext|>\"", ",", "eos_token", "=", "\"<|endoftext|>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPT2Tokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "bpe_data", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_data", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.vocab_size": [[122, 125], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.bpe": [[126, 166], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer._tokenize": [[167, 177], ["regex.findall", "bpe_tokens.extend", "tokenization_gpt2.GPT2Tokenizer.bpe().split", "token.encode", "ord", "tokenization_gpt2.GPT2Tokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "ord", "(", "b", ")", "]", "for", "b", "in", "token", ")", "\n", "", "else", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer._convert_token_to_id": [[178, 181], ["tokenization_gpt2.GPT2Tokenizer.encoder.get", "tokenization_gpt2.GPT2Tokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer._convert_id_to_token": [[182, 185], ["tokenization_gpt2.GPT2Tokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_string": [[186, 191], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "text", "=", "''", ".", "join", "(", "tokens", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.save_vocabulary": [[192, 215], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.bytes_to_unicode": [[61, 83], ["lru_cache", "range", "dict", "list", "_chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "_chr", "=", "unichr", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "else", "chr", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "_chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.get_pairs": [[84, 95], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.__init__": [[215, 288], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "modeling_transfo_xl.TransfoXLConfig.cutoffs.extend", "ValueError", "reader.read", "len", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "267735", ",", "\n", "cutoffs", "=", "[", "20000", ",", "40000", ",", "200000", "]", ",", "\n", "d_model", "=", "1024", ",", "\n", "d_embed", "=", "1024", ",", "\n", "n_head", "=", "16", ",", "\n", "d_head", "=", "64", ",", "\n", "d_inner", "=", "4096", ",", "\n", "div_val", "=", "4", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "n_layer", "=", "18", ",", "\n", "tgt_len", "=", "128", ",", "\n", "ext_len", "=", "0", ",", "\n", "mem_len", "=", "1600", ",", "\n", "clamp_len", "=", "1000", ",", "\n", "same_length", "=", "True", ",", "\n", "proj_share_all_but_first", "=", "True", ",", "\n", "attn_type", "=", "0", ",", "\n", "sample_softmax", "=", "-", "1", ",", "\n", "adaptive", "=", "True", ",", "\n", "tie_weight", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "dropatt", "=", "0.0", ",", "\n", "untie_r", "=", "True", ",", "\n", "init", "=", "\"normal\"", ",", "\n", "init_range", "=", "0.01", ",", "\n", "proj_init_std", "=", "0.01", ",", "\n", "init_std", "=", "0.02", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs TransfoXLConfig.\n        \"\"\"", "\n", "super", "(", "TransfoXLConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "cutoffs", "=", "[", "]", "\n", "self", ".", "cutoffs", ".", "extend", "(", "cutoffs", ")", "\n", "self", ".", "tie_weight", "=", "tie_weight", "\n", "if", "proj_share_all_but_first", ":", "\n", "                ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "True", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "False", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "sample_softmax", "=", "sample_softmax", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropatt", "=", "dropatt", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "init", "=", "init", "\n", "self", ".", "init_range", "=", "init_range", "\n", "self", ".", "proj_init_std", "=", "proj_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.max_position_embeddings": [[290, 293], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tgt_len", "+", "self", ".", "ext_len", "+", "self", ".", "mem_len", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.vocab_size": [[298, 301], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.hidden_size": [[302, 305], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.num_attention_heads": [[306, 309], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.num_hidden_layers": [[310, 313], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.PositionalEmbedding.__init__": [[316, 323], ["torch.Module.__init__", "modeling_transfo_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.PositionalEmbedding.forward": [[324, 332], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.PositionwiseFF.__init__": [[336, 353], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modeling_bert.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.PositionwiseFF.forward": [[354, 369], ["modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.layer_norm", "modeling_transfo_xl.PositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "self", ".", "layer_norm", "(", "inp", ")", ")", "\n", "\n", "##### residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "##### positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.MultiHeadAttn.__init__": [[373, 402], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "modeling_bert.BertLayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "pre_lnorm", "=", "False", ",", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "q_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "self", ".", "kv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "2", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.MultiHeadAttn.forward": [[403, 460], ["modeling_transfo_xl.MultiHeadAttn.q_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "head_q.view.view.view", "head_k.view.view.view", "head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum.mul_", "torch.einsum.mul_", "torch.einsum.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.MultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.MultiHeadAttn.o_net", "modeling_transfo_xl.MultiHeadAttn.drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.MultiHeadAttn.layer_norm", "modeling_transfo_xl.MultiHeadAttn.kv_net", "h.size", "h.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "outputs.append", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.MultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "float", "float"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "forward", "(", "self", ",", "h", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "##### multihead attention", "\n", "# [hlen x bsz x n_head x d_head]", "\n", "\n", "        ", "if", "mems", "is", "not", "None", ":", "\n", "            ", "c", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "h", "\n", "\n", "", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization", "\n", "            ", "c", "=", "self", ".", "layer_norm", "(", "c", ")", "\n", "\n", "", "head_q", "=", "self", ".", "q_net", "(", "h", ")", "\n", "head_k", ",", "head_v", "=", "torch", ".", "chunk", "(", "self", ".", "kv_net", "(", "c", ")", ",", "2", ",", "-", "1", ")", "\n", "\n", "head_q", "=", "head_q", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_k", "=", "head_k", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_v", "=", "head_v", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "head_q", ",", "head_k", ")", ")", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# [qlen x klen x bsz x n_head] + [klen x bsz x n_head x d_head] -> [qlen x bsz x n_head x d_head]", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "head_v", ")", ")", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "outputs", "=", "[", "h", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "h", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn.__init__": [[462, 491], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "modeling_bert.BertLayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", "RelMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn._parallelogram_mask": [[492, 502], ["torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "min", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "", "def", "_parallelogram_mask", "(", "self", ",", "h", ",", "w", ",", "left", "=", "False", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "(", "h", ",", "w", ")", ")", ".", "byte", "(", ")", "\n", "m", "=", "min", "(", "h", ",", "w", ")", "\n", "mask", "[", ":", "m", ",", ":", "m", "]", "=", "torch", ".", "triu", "(", "mask", "[", ":", "m", ",", ":", "m", "]", ")", "\n", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", "=", "torch", ".", "tril", "(", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", ")", "\n", "\n", "if", "left", ":", "\n", "            ", "return", "mask", "\n", "", "else", ":", "\n", "            ", "return", "mask", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn._shift": [[503, 520], ["torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask.flip.flip.flip", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "_shift", "(", "self", ",", "x", ",", "qlen", ",", "klen", ",", "mask", ",", "left", "=", "False", ")", ":", "\n", "        ", "if", "qlen", ">", "1", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "qlen", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "0", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "", "if", "left", ":", "\n", "            ", "mask", "=", "mask", ".", "flip", "(", "1", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_padded", "=", "torch", ".", "cat", "(", "[", "x", ",", "zero_pad", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "x", "=", "x_padded", ".", "masked_select", "(", "mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ".", "view", "(", "qlen", ",", "klen", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn._rel_shift": [[521, 536], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "_rel_shift", "(", "self", ",", "x", ",", "zero_triu", "=", "False", ")", ":", "\n", "        ", "zero_pad_shape", "=", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "zero_pad", "=", "torch", ".", "zeros", "(", "zero_pad_shape", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded_shape", "=", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "*", "x_padded_shape", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "if", "zero_triu", ":", "\n", "            ", "ones", "=", "torch", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ")", "\n", "x", "=", "x", "*", "torch", ".", "tril", "(", "ones", ",", "x", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "0", ")", ")", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn.forward": [[537, 539], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.__init__": [[541, 545], ["modeling_transfo_xl.RelMultiHeadAttn.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.forward": [[546, 627], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "outputs.append", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "#### compute attention vector", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "outputs", "=", "[", "w", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelLearnableMultiHeadAttn.__init__": [[629, 631], ["modeling_transfo_xl.RelMultiHeadAttn.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelLearnableMultiHeadAttn.forward": [[632, 718], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelLearnableMultiHeadAttn._rel_shift", "attn_score.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.drop", "w.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat.size", "torch.cat.size", "torch.cat.size", "r_emb[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "r_bias[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "outputs.append", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "attn_mask.any", "attn_mask.dim", "attn_score.masked_fill_", "float", "float"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "w", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# r_emb: [klen, n_head, d_head], used for term B", "\n", "# r_w_bias: [n_head, d_head], used for term C", "\n", "# r_bias: [klen, n_head], used for term D", "\n", "\n", "        ", "qlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "if", "klen", ">", "r_emb", ".", "size", "(", "0", ")", ":", "\n", "            ", "r_emb_pad", "=", "r_emb", "[", "0", ":", "1", "]", ".", "expand", "(", "klen", "-", "r_emb", ".", "size", "(", "0", ")", ",", "-", "1", ",", "-", "1", ")", "\n", "r_emb", "=", "torch", ".", "cat", "(", "[", "r_emb_pad", ",", "r_emb", "]", ",", "0", ")", "\n", "r_bias_pad", "=", "r_bias", "[", "0", ":", "1", "]", ".", "expand", "(", "klen", "-", "r_bias", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "r_bias", "=", "torch", ".", "cat", "(", "[", "r_bias_pad", ",", "r_bias", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "r_emb", "=", "r_emb", "[", "-", "klen", ":", "]", "\n", "r_bias", "=", "r_bias", "[", "-", "klen", ":", "]", "\n", "\n", "#### compute attention score", "\n", "", "rw_head_q", "=", "w_head_q", "+", "r_w_bias", "[", "None", "]", "# qlen x bsz x n_head x d_head", "\n", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "B_", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "w_head_q", ",", "r_emb", ")", ")", "# qlen x klen x bsz x n_head", "\n", "D_", "=", "r_bias", "[", "None", ",", ":", ",", "None", "]", "# 1    x klen x 1   x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "B_", "+", "D_", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "#### compute attention vector", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "outputs", "=", "[", "w", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.DecoderLayer.__init__": [[722, 728], ["torch.Module.__init__", "modeling_transfo_xl.MultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "MultiHeadAttn", "(", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.DecoderLayer.forward": [[729, 738], ["modeling_transfo_xl.DecoderLayer.dec_attn", "modeling_transfo_xl.DecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "\n", "        ", "attn_outputs", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelLearnableDecoderLayer.__init__": [[740, 748], ["torch.Module.__init__", "modeling_transfo_xl.RelLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelLearnableDecoderLayer.forward": [[749, 759], ["modeling_transfo_xl.RelLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "\n", "        ", "attn_outputs", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": [[761, 769], ["torch.Module.__init__", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.RelPartialLearnableDecoderLayer.forward": [[770, 780], ["modeling_transfo_xl.RelPartialLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "\n", "        ", "attn_outputs", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.AdaptiveEmbedding.__init__": [[784, 813], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "range", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "len", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "sample_softmax", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "self", ".", "emb_layers", ".", "append", "(", "\n", "nn", ".", "Embedding", "(", "n_token", ",", "d_embed", ",", "sparse", "=", "sample_softmax", ">", "0", ")", "\n", ")", "\n", "if", "d_proj", "!=", "d_embed", ":", "\n", "                ", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_emb_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.AdaptiveEmbedding.forward": [[814, 845], ["torch.linear.mul_", "next", "inp.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view", "torch.zeros.view", "torch.linear", "torch.linear", "torch.linear", "modeling_transfo_xl.AdaptiveEmbedding.parameters", "len", "mask_i.nonzero().squeeze", "torch.linear", "torch.linear", "torch.linear", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "inp.size", "inp.view.size", "mask_i.nonzero().squeeze.numel", "inp.view.index_select", "mask_i.nonzero"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "embed", "=", "self", ".", "emb_layers", "[", "0", "]", "(", "inp", ")", "\n", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                ", "embed", "=", "F", ".", "linear", "(", "embed", ",", "self", ".", "emb_projs", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "inp_flat", "=", "inp", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "inp_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "inp_i", "=", "inp_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "", "embed_shape", "=", "inp", ".", "size", "(", ")", "+", "(", "self", ".", "d_proj", ",", ")", "\n", "embed", "=", "emb_flat", ".", "view", "(", "embed_shape", ")", "\n", "\n", "", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel.__init__": [[856, 858], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TransfoXLPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight": [[859, 864], ["torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["None"], ["", "def", "_init_weight", "(", "self", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "init", "==", "'uniform'", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "self", ".", "config", ".", "init_range", ",", "self", ".", "config", ".", "init_range", ")", "\n", "", "elif", "self", ".", "config", ".", "init", "==", "'normal'", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias": [[865, 867], ["torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "def", "_init_bias", "(", "self", ",", "bias", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weights": [[868, 908], ["classname.find", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "classname.find", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "range", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "len", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias"], ["", "def", "init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLPreTrainedModel.set_num_special_tokens": [[909, 911], ["None"], "methods", ["None"], ["", "", "", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel.__init__": [[978, 1059], ["modeling_transfo_xl.TransfoXLPreTrainedModel.__init__", "modeling_transfo_xl.AdaptiveEmbedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "modeling_transfo_xl.TransfoXLModel.apply", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl.PositionalEmbedding", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "modeling_transfo_xl.TransfoXLModel.layers.append", "range", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.RelPartialLearnableDecoderLayer", "modeling_transfo_xl.TransfoXLModel.layers.append", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "modeling_transfo_xl.PositionalEmbedding", "modeling_transfo_xl.RelLearnableDecoderLayer", "modeling_transfo_xl.TransfoXLModel.layers.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.DecoderLayer", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "n_token", "=", "config", ".", "n_token", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "\n", "self", ".", "word_emb", "=", "AdaptiveEmbedding", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "\n", "div_val", "=", "config", ".", "div_val", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "if", "not", "config", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "attn_type", "==", "1", ":", "# learnable embeddings", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "attn_type", "in", "[", "2", ",", "3", "]", ":", "# absolute embeddings", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "DecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "1", ":", "# learnable", "\n", "            ", "self", ".", "r_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ")", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "2", ":", "# absolute standard", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "3", ":", "# absolute deeper SA", "\n", "            ", "self", ".", "r_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel._resize_token_embeddings": [[1060, 1062], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "return", "self", ".", "word_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel.backward_compatible": [[1063, 1065], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel.reset_length": [[1066, 1070], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel._prune_heads": [[1071, 1074], ["logger.info"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Head pruning is not implemented for Transformer-XL model\"", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel.init_mems": [[1075, 1087], ["next", "range", "modeling_transfo_xl.TransfoXLModel.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mems.append", "data.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "zeros", "(", "self", ".", "mem_len", ",", "data", ".", "size", "(", "1", ")", ",", "self", ".", "config", ".", "d_model", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel._update_mems": [[1088, 1110], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel._forward": [[1111, 1241], ["dec_inp.size", "modeling_transfo_xl.TransfoXLModel.word_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel._update_mems", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "mems[].size", "modeling_transfo_xl.TransfoXLModel.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "modeling_transfo_xl.TransfoXLModel.transpose().contiguous", "list.append", "list", "outputs.append", "list", "outputs.append", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "list.append", "layer", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "list.append", "list.append", "layer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "modeling_transfo_xl.TransfoXLModel.transpose", "t.transpose().contiguous", "t.permute().contiguous", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "list.append", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "list.append", "layer", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_transfo_xl.TransfoXLModel.parameters", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "modeling_transfo_xl.TransfoXLModel.new_ones", "list.append", "list.append", "[].view", "layer", "t.transpose", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.view", "torch.cat.view", "torch.cat.view", "list.append", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "cur_emb[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel._update_mems", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "_forward", "(", "self", ",", "dec_inp", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "bsz", "=", "dec_inp", ".", "size", "(", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "word_emb", "=", "self", ".", "word_emb", "(", "dec_inp", ")", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "all_ones", "=", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", "\n", "mask_len", "=", "klen", "-", "self", ".", "mem_len", "\n", "if", "mask_len", ">", "0", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "-", "mask_len", "\n", "", "else", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "\n", "", "dec_attn_mask", "=", "(", "torch", ".", "triu", "(", "all_ones", ",", "1", "+", "mlen", ")", "\n", "+", "torch", ".", "tril", "(", "all_ones", ",", "-", "mask_shift_len", ")", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "# -1", "\n", "", "else", ":", "\n", "            ", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "attentions", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "layer_outputs", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "elif", "self", ".", "attn_type", "==", "1", ":", "# learnable", "\n", "            ", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                    ", "r_emb", "=", "self", ".", "r_emb", "[", "i", "]", "[", "-", "self", ".", "clamp_len", ":", "]", "\n", "r_bias", "=", "self", ".", "r_bias", "[", "i", "]", "[", "-", "self", ".", "clamp_len", ":", "]", "\n", "", "else", ":", "\n", "                    ", "r_emb", ",", "r_bias", "=", "self", ".", "r_emb", "[", "i", "]", ",", "self", ".", "r_bias", "[", "i", "]", "\n", "\n", "", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "layer_outputs", "=", "layer", "(", "core_out", ",", "r_emb", ",", "self", ".", "r_w_bias", "[", "i", "]", ",", "\n", "r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "elif", "self", ".", "attn_type", "==", "2", ":", "# absolute", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", "+", "pos_emb", "[", "-", "qlen", ":", "]", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "if", "mems_i", "is", "not", "None", "and", "i", "==", "0", ":", "\n", "                    ", "mems_i", "+=", "pos_emb", "[", ":", "mlen", "]", "\n", "", "layer_outputs", "=", "layer", "(", "core_out", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "elif", "self", ".", "attn_type", "==", "3", ":", "\n", "            ", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "if", "mems_i", "is", "not", "None", "and", "mlen", ">", "0", ":", "\n", "                    ", "cur_emb", "=", "self", ".", "r_emb", "[", "i", "]", "[", ":", "-", "qlen", "]", "\n", "cur_size", "=", "cur_emb", ".", "size", "(", "0", ")", "\n", "if", "cur_size", "<", "mlen", ":", "\n", "                        ", "cur_emb_pad", "=", "cur_emb", "[", "0", ":", "1", "]", ".", "expand", "(", "mlen", "-", "cur_size", ",", "-", "1", ",", "-", "1", ")", "\n", "cur_emb", "=", "torch", ".", "cat", "(", "[", "cur_emb_pad", ",", "cur_emb", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "cur_emb", "=", "cur_emb", "[", "-", "mlen", ":", "]", "\n", "", "mems_i", "+=", "cur_emb", ".", "view", "(", "mlen", ",", "1", ",", "-", "1", ")", "\n", "", "core_out", "+=", "self", ".", "r_emb", "[", "i", "]", "[", "-", "qlen", ":", "]", ".", "view", "(", "qlen", ",", "1", ",", "-", "1", ")", "\n", "\n", "layer_outputs", "=", "layer", "(", "core_out", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "\n", "", "", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "outputs", "=", "[", "core_out", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "new_mems", "]", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "# Add last layer and transpose to library standard shape [bsz, len, hidden_dim]", "\n", "            ", "hids", ".", "append", "(", "core_out", ")", "\n", "hids", "=", "list", "(", "t", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "hids", ")", "\n", "outputs", ".", "append", "(", "hids", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# Transpose to library standard shape [bsz, n_heads, query_seq_len, key_seq_len]", "\n", "            ", "attentions", "=", "list", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", ".", "append", "(", "attentions", ")", "\n", "", "return", "outputs", "# last hidden state, new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel.forward": [[1242, 1252], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_transfo_xl.TransfoXLModel._forward", "modeling_transfo_xl.TransfoXLModel.init_mems", "input_ids.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLModel._forward", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "        ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "input_ids", ")", "\n", "", "outputs", "=", "self", ".", "_forward", "(", "input_ids", ",", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "return", "outputs", "# last hidden state, new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.__init__": [[1293, 1307], ["modeling_transfo_xl.TransfoXLPreTrainedModel.__init__", "modeling_transfo_xl.TransfoXLModel", "modeling_transfo_xl.TransfoXLLMHeadModel.apply", "modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights", "torch.Linear", "torch.Linear", "torch.Linear", "LogUniformSampler", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TransfoXLModel", "(", "config", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "n_token", ")", "\n", "self", ".", "sampler", "=", "LogUniformSampler", "(", "config", ".", "n_token", ",", "config", ".", "sample_softmax", ")", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "ProjectedAdaptiveLogSoftmax", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "\n", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", ")", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights": [[1308, 1334], ["range", "enumerate", "len", "modeling_transfo_xl.TransfoXLLMHeadModel._tie_or_clone_weights", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer.word_emb.emb_projs[].clone", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer.word_emb.emb_projs[].clone"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run this to be sure output and input (adaptive) softmax weights are tied\n        \"\"\"", "\n", "# sampled softmax", "\n", "if", "self", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "self", ".", "out_layer", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "weight", "\n", "# adaptive softmax (including standard softmax)", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "crit", ".", "out_layers", ")", ")", ":", "\n", "                    ", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "crit", ".", "out_layers", "[", "i", "]", ",", "\n", "self", ".", "transformer", ".", "word_emb", ".", "emb_layers", "[", "i", "]", ")", "\n", "", "", "if", "self", ".", "config", ".", "tie_projs", ":", "\n", "                ", "for", "i", ",", "tie_proj", "in", "enumerate", "(", "self", ".", "config", ".", "tie_projs", ")", ":", "\n", "                    ", "if", "tie_proj", "and", "self", ".", "config", ".", "div_val", "==", "1", "and", "self", ".", "config", ".", "d_model", "!=", "self", ".", "config", ".", "d_embed", ":", "\n", "                        ", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "nn", ".", "Parameter", "(", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", "\n", "", "", "elif", "tie_proj", "and", "self", ".", "config", ".", "div_val", "!=", "1", ":", "\n", "                        ", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "nn", ".", "Parameter", "(", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length": [[1335, 1337], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "", "", "", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems": [[1338, 1340], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel.forward": [[1341, 1368], ["input_ids.size", "input_ids.size", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer", "modeling_transfo_xl_utilities.sample_logits", "modeling_transfo_xl.TransfoXLLMHeadModel.crit", "pred_hid.view", "softmax_output.view.view.view", "softmax_output.view.view.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "pred_hid.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.sample_logits", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "labels", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "bsz", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "tgt_len", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "last_hidden", "=", "transformer_outputs", "[", "0", "]", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "self", ".", "training", ":", "\n", "            ", "assert", "self", ".", "config", ".", "tie_weight", "\n", "logit", "=", "sample_logits", "(", "self", ".", "transformer", ".", "word_emb", ",", "self", ".", "out_layer", ".", "bias", ",", "labels", ",", "pred_hid", ",", "self", ".", "sampler", ")", "\n", "softmax_output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# TODO: This is not implemented", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "pred_hid", ".", "view", "(", "-", "1", ",", "pred_hid", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ")", "\n", "if", "labels", "is", "None", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ",", "-", "1", ")", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "", "else", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ")", "\n", "outputs", "=", "[", "softmax_output", ",", "None", "]", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "# (loss), logits or None if labels is not None (speed up adaptive softmax), new_mems, (all hidden states), (all attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.build_tf_to_pytorch_map": [[50, 121], ["hasattr", "enumerate", "enumerate", "tf_to_pt_map.update", "tf_to_pt_map.update", "enumerate", "zip", "tf_to_pt_map.update", "tf_to_pt_map.update", "zip", "r_r_list.append", "r_w_list.append", "tf_to_pt_map.update", "tf_to_pt_map.update", "tf_to_pt_map.update"], "function", ["None"], ["def", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        This time I use a map to keep the PyTorch model as identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "# We are loading in a TransfoXLLMHeadModel => we will load also the Adaptive Softmax", "\n", "        ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_W\"", ":", "model", ".", "crit", ".", "cluster_weight", ",", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_b\"", ":", "model", ".", "crit", ".", "cluster_bias", "}", ")", "\n", "for", "i", ",", "(", "out_l", ",", "proj_l", ",", "tie_proj", ")", "in", "enumerate", "(", "zip", "(", "\n", "model", ".", "crit", ".", "out_layers", ",", "\n", "model", ".", "crit", ".", "out_projs", ",", "\n", "config", ".", "tie_projs", ")", ")", ":", "\n", "            ", "layer_str", "=", "\"transformer/adaptive_softmax/cutoff_%d/\"", "%", "i", "\n", "if", "config", ".", "tie_weight", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "# I don't think this is implemented in the TF code", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "out_l", ".", "weight", ",", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "if", "not", "tie_proj", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'proj'", ":", "proj_l", "\n", "}", ")", "\n", "# Now load the rest of the transformer", "\n", "", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings", "\n", "", "for", "i", ",", "(", "embed_l", ",", "proj_l", ")", "in", "enumerate", "(", "zip", "(", "model", ".", "word_emb", ".", "emb_layers", ",", "model", ".", "word_emb", ".", "emb_projs", ")", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/adaptive_embed/cutoff_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "embed_l", ".", "weight", ",", "\n", "layer_str", "+", "'proj_W'", ":", "proj_l", "\n", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layers", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "dec_attn", ".", "o_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/qkv/kernel\"", ":", "b", ".", "dec_attn", ".", "qkv_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "dec_attn", ".", "r_net", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layers", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_w_bias", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'transformer/r_w_bias'", ":", "r_w_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl": [[122, 176], ["modeling_transfo_xl.build_tf_to_pytorch_map", "tf.train.list_variables", "build_tf_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.build_tf_to_pytorch_map"], ["", "def", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", "\n", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "assert", "name", "in", "tf_weights", "\n", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "or", "'proj'", "in", "name", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "(", "'r_r_bias'", "in", "name", "or", "'r_w_bias'", "in", "name", ")", "and", "len", "(", "pointer", ")", ">", "1", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.__init__": [[115, 141], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "dict", "spacy.load", "io.open", "io.open().read().split", "tuple", "zip", "logger.warning", "tokenization_bert.BasicTokenizer", "tokenization_xlm.XLMTokenizer.encoder.items", "range", "io.open().read", "merge.split", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "bos_token", "=", "\"<s>\"", ",", "\n", "sep_token", "=", "\"</s>\"", ",", "pad_token", "=", "\"<pad>\"", ",", "cls_token", "=", "\"</s>\"", ",", "\n", "mask_token", "=", "\"<special1>\"", ",", "additional_special_tokens", "=", "[", "\"<special0>\"", ",", "\n", "\"<special1>\"", ",", "\"<special2>\"", ",", "\"<special3>\"", ",", "\"<special4>\"", ",", "\"<special5>\"", ",", "\n", "\"<special6>\"", ",", "\"<special7>\"", ",", "\"<special8>\"", ",", "\"<special9>\"", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLMTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "bos_token", "=", "bos_token", ",", "\n", "sep_token", "=", "sep_token", ",", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "mask_token", "=", "mask_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", ")", "\n", "try", ":", "\n", "            ", "import", "ftfy", "\n", "import", "spacy", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en'", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", ",", "'ner'", ",", "'textcat'", "]", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", "[", ":", "2", "]", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.vocab_size": [[142, 145], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.bpe": [[146, 188], ["tokenization_xlm.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_xlm.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_xlm.XLMTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer._tokenize": [[189, 203], ["tokenization_xlm.XLMTokenizer.nlp.tokenize", "tokenization_xlm.XLMTokenizer.nlp", "split_tokens.extend", "tokenization_xlm.text_standardize", "split_tokens.extend", "tokenization_xlm.XLMTokenizer.fix_text", "tokenization_xlm.XLMTokenizer.bpe().split", "tokenization_xlm.XLMTokenizer.bpe().split", "tokenization_xlm.XLMTokenizer.bpe", "tokenization_xlm.XLMTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.text_standardize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer", "\n", "            ", "text", "=", "self", ".", "nlp", ".", "tokenize", "(", "text", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "else", ":", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "            ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer._convert_token_to_id": [[204, 207], ["tokenization_xlm.XLMTokenizer.encoder.get", "tokenization_xlm.XLMTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer._convert_id_to_token": [[208, 211], ["tokenization_xlm.XLMTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.convert_tokens_to_string": [[212, 216], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.add_special_tokens_single_sentence": [[217, 223], ["tokenization_xlm.XLMTokenizer._convert_token_to_id", "tokenization_xlm.XLMTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence for sequence classification tasks.\n        An XLM sequence has the following format: [CLS] X [SEP]\n        \"\"\"", "\n", "return", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "+", "token_ids", "+", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.add_special_tokens_sentences_pair": [[224, 232], ["tokenization_xlm.XLMTokenizer._convert_token_to_id", "tokenization_xlm.XLMTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence pair for sequence classification tasks.\n        An XLM sequence pair has the following format: [CLS] A [SEP] B [SEP]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "cls", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.XLMTokenizer.save_vocabulary": [[233, 255], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "sorted", "json.dumps", "tokenization_xlm.XLMTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.get_pairs": [[71, 82], ["set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_xlm.text_standardize": [[83, 97], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.__init__": [[105, 141], ["tokenization_utils.PreTrainedTokenizer.__init__", "tokenization_bert.load_vocab", "collections.OrderedDict", "tokenization_bert.WordpieceTokenizer", "os.path.isfile", "ValueError", "tokenization_bert.BasicTokenizer", "tokenization_bert.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "do_basic_tokenize", "=", "True", ",", "never_split", "=", "None", ",", "\n", "unk_token", "=", "\"[UNK]\"", ",", "sep_token", "=", "\"[SEP]\"", ",", "pad_token", "=", "\"[PAD]\"", ",", "cls_token", "=", "\"[CLS]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "tokenize_chinese_chars", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs a BertTokenizer.\n\n        Args:\n            **vocab_file**: Path to a one-wordpiece-per-line vocabulary file\n            **do_lower_case**: (`optional`) boolean (default True)\n                Whether to lower case the input\n                Only has an effect when do_basic_tokenize=True\n            **do_basic_tokenize**: (`optional`) boolean (default True)\n                Whether to do basic tokenization before wordpiece.\n            **never_split**: (`optional`) list of string\n                List of tokens which will never be split during tokenization.\n                Only has an effect when do_basic_tokenize=True\n            **tokenize_chinese_chars**: (`optional`) boolean (default True)\n                Whether to tokenize Chinese characters.\n                This should likely be deactivated for Japanese:\n                see: https://github.com/huggingface/pytorch-pretrained-BERT/issues/328\n        \"\"\"", "\n", "super", "(", "BertTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "**", "kwargs", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "do_basic_tokenize", "=", "do_basic_tokenize", "\n", "if", "do_basic_tokenize", ":", "\n", "            ", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "\n", "never_split", "=", "never_split", ",", "\n", "tokenize_chinese_chars", "=", "tokenize_chinese_chars", ")", "\n", "", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ",", "unk_token", "=", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.vocab_size": [[142, 145], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer._tokenize": [[146, 155], ["tokenization_bert.BertTokenizer.basic_tokenizer.tokenize", "tokenization_bert.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization_bert.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization_bert.BertTokenizer.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "do_basic_tokenize", ":", "\n", "            ", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ",", "never_split", "=", "self", ".", "all_special_tokens", ")", ":", "\n", "                ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                    ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "else", ":", "\n", "            ", "split_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer._convert_token_to_id": [[156, 159], ["tokenization_bert.BertTokenizer.vocab.get", "tokenization_bert.BertTokenizer.vocab.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "vocab", ".", "get", "(", "token", ",", "self", ".", "vocab", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer._convert_id_to_token": [[160, 163], ["tokenization_bert.BertTokenizer.ids_to_tokens.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "ids_to_tokens", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.convert_tokens_to_string": [[164, 168], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "' '", ".", "join", "(", "tokens", ")", ".", "replace", "(", "' ##'", ",", "''", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.add_special_tokens_single_sentence": [[169, 175], ["tokenization_bert.BertTokenizer._convert_token_to_id", "tokenization_bert.BertTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to the a sequence for sequence classification tasks.\n        A BERT sequence has the following format: [CLS] X [SEP]\n        \"\"\"", "\n", "return", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "+", "token_ids", "+", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.add_special_tokens_sentences_pair": [[176, 184], ["tokenization_bert.BertTokenizer._convert_token_to_id", "tokenization_bert.BertTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence pair for sequence classification tasks.\n        A BERT sequence pair has the following format: [CLS] A [SEP] B [SEP]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "cls", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.save_vocabulary": [[185, 199], ["os.path.isdir", "os.path.join", "io.open", "sorted", "tokenization_bert.BertTokenizer.vocab.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "index", "=", "0", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "token", ",", "token_index", "in", "sorted", "(", "self", ".", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained": [[200, 217], ["super()._from_pretrained", "kwargs.get", "logger.warning", "logger.warning", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Instantiate a BertTokenizer from pre-trained vocabulary files.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES", ":", "\n", "            ", "if", "'-cased'", "in", "pretrained_model_name_or_path", "and", "kwargs", ".", "get", "(", "'do_lower_case'", ",", "True", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"The pre-trained model you are loading is a cased model but you have not set \"", "\n", "\"`do_lower_case` to False. We are setting `do_lower_case=False` for you but \"", "\n", "\"you may want to check this behavior.\"", ")", "\n", "kwargs", "[", "'do_lower_case'", "]", "=", "False", "\n", "", "elif", "'-cased'", "not", "in", "pretrained_model_name_or_path", "and", "not", "kwargs", ".", "get", "(", "'do_lower_case'", ",", "True", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"The pre-trained model you are loading is an uncased model but you have set \"", "\n", "\"`do_lower_case` to False. We are setting `do_lower_case=True` for you \"", "\n", "\"but you may want to check this behavior.\"", ")", "\n", "kwargs", "[", "'do_lower_case'", "]", "=", "True", "\n", "\n", "", "", "return", "super", "(", "BertTokenizer", ",", "cls", ")", ".", "_from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer.__init__": [[222, 241], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "True", ",", "never_split", "=", "None", ",", "tokenize_chinese_chars", "=", "True", ")", ":", "\n", "        ", "\"\"\" Constructs a BasicTokenizer.\n\n        Args:\n            **do_lower_case**: Whether to lower case the input.\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n            **tokenize_chinese_chars**: (`optional`) boolean (default True)\n                Whether to tokenize Chinese characters.\n                This should likely be deactivated for Japanese:\n                see: https://github.com/huggingface/pytorch-pretrained-BERT/issues/328\n        \"\"\"", "\n", "if", "never_split", "is", "None", ":", "\n", "            ", "never_split", "=", "[", "]", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "self", ".", "tokenize_chinese_chars", "=", "tokenize_chinese_chars", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer.tokenize": [[242, 272], ["tokenization_bert.BasicTokenizer._clean_text", "tokenization_bert.whitespace_tokenize", "tokenization_bert.whitespace_tokenize", "tokenization_bert.BasicTokenizer._tokenize_chinese_chars", "split_tokens.extend", "tokenization_bert.BasicTokenizer.lower", "tokenization_bert.BasicTokenizer._run_strip_accents", "tokenization_bert.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "never_split", "=", "None", ")", ":", "\n", "        ", "\"\"\" Basic Tokenization of a piece of text.\n            Split on \"white spaces\" only, for sub-word tokenization, see WordPieceTokenizer.\n\n        Args:\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n        \"\"\"", "\n", "never_split", "=", "self", ".", "never_split", "+", "(", "never_split", "if", "never_split", "is", "not", "None", "else", "[", "]", ")", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "if", "self", ".", "tokenize_chinese_chars", ":", "\n", "            ", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer._run_strip_accents": [[273, 283], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer._run_split_on_punc": [[284, 305], ["list", "len", "tokenization_bert._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ",", "never_split", "=", "None", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "never_split", "is", "not", "None", "and", "text", "in", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer._tokenize_chinese_chars": [[306, 318], ["ord", "tokenization_bert.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer._is_chinese_char": [[319, 340], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.BasicTokenizer._clean_text": [[341, 353], ["ord", "tokenization_bert._is_whitespace", "tokenization_bert._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.WordpieceTokenizer.__init__": [[358, 362], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.WordpieceTokenizer.tokenize": [[363, 413], ["tokenization_bert.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.load_vocab": [[66, 75], ["collections.OrderedDict", "enumerate", "io.open", "reader.readlines", "token.rstrip.rstrip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "tokens", "=", "reader", ".", "readlines", "(", ")", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token", "=", "token", ".", "rstrip", "(", "'\\n'", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert.whitespace_tokenize": [[77, 84], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert._is_whitespace": [[415, 425], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert._is_control": [[427, 437], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_bert._is_punctuation": [[439, 453], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.__init__": [[32, 77], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.Linear", "torch.Linear", "torch.Linear", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "keep_order", "=", "False", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ")", "\n", "self", ".", "cluster_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ")", ")", "\n", "\n", "", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "d_proj", "!=", "d_embed", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_embed", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "\n", "", "", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_embed", ",", "n_token", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "\n", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_emb_i", ")", ")", "\n", ")", "\n", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n", "", "", "self", ".", "keep_order", "=", "keep_order", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit": [[78, 91], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "if", "proj", "is", "None", ":", "\n", "            ", "logit", "=", "F", ".", "linear", "(", "hidden", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# if CUDA_MAJOR <= 9 and CUDA_MINOR <= 1:", "\n", "            ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "#     logit = torch.einsum('bd,de,ev->bv', (hidden, proj, weight.t()))", "\n", "#     if bias is not None:", "\n", "#         logit = logit + bias", "\n", "\n", "", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.forward": [[92, 196], ["labels.view.view.view", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "hidden.size", "labels.view.view.size", "RuntimeError", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "len", "weights.append", "biases.append", "hidden.new_empty", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze", "torch.log_softmax.index_select", "hidden.index_select", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "head_logprob.index_select.gather().squeeze.size", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "mask_i.nonzero().squeeze.numel", "labels.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "out[].copy_", "torch.log_softmax().gather", "torch.log_softmax().gather", "torch.log_softmax().gather", "mask_i.nonzero", "torch.log_softmax.gather().squeeze", "hasattr", "labels.view.view.unsqueeze", "F.log_softmax.index_select.gather", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.gather", "head_logprob.index_select.gather().squeeze.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "labels", "=", "None", ",", "keep_order", "=", "False", ")", ":", "\n", "        ", "'''\n            Params:\n                hidden :: [len*bsz x d_proj]\n                labels :: [len*bsz]\n            Return:\n                if labels is None:\n                    out :: [len*bsz] Negative log likelihood\n                else:\n                    out :: [len*bsz x n_tokens] log probabilities of tokens over the vocabulary\n            We could replace this implementation by the native PyTorch one\n            if their's had an option to set bias on all clusters in the native one.\n            here: https://github.com/pytorch/pytorch/blob/dbe6a7a9ff1a364a8706bf5df58a1ca96d2fd9da/torch/nn/modules/adaptive.py#L138\n        '''", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "if", "hidden", ".", "size", "(", "0", ")", "!=", "labels", ".", "size", "(", "0", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Input and labels should have the same size '", "\n", "'in the batch dimension.'", ")", "\n", "\n", "", "", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                ", "out", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ".", "gather", "(", "1", ",", "labels", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "                ", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "zeros_like", "(", "labels", ",", "dtype", "=", "hidden", ".", "dtype", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "mask_i", "=", "(", "labels", ">=", "l_idx", ")", "&", "(", "labels", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "target_i", "=", "labels", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "", "else", ":", "\n", "                    ", "hidden_i", "=", "hidden", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "cluster_prob_idx", "]", "+", "tail_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "logprob_i", "=", "head_logprob", "[", ":", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "l_idx", ":", "r_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "if", "(", "hasattr", "(", "self", ",", "'keep_order'", ")", "and", "self", ".", "keep_order", ")", "or", "keep_order", ":", "\n", "                        ", "out", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", "offset", ":", "offset", "+", "logprob_i", ".", "size", "(", "0", ")", "]", ".", "copy_", "(", "-", "logprob_i", ")", "\n", "", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob": [[198, 258], ["modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "hidden.new_empty", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "len", "weights.append", "biases.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "log_prob", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "r\"\"\" Computes log probabilities for all :math:`n\\_classes`\n        From: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/adaptive.py\n        Args:\n            hidden (Tensor): a minibatch of examples\n        Returns:\n            log-probabilities of for each class :math:`c`\n            in range :math:`0 <= c <= n\\_classes`, where :math:`n\\_classes` is a\n            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n        Shape:\n            - Input: :math:`(N, in\\_features)`\n            - Output: :math:`(N, n\\_classes)`\n        \"\"\"", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "return", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "\n", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "start_idx", ",", "stop_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "\n", "logprob_i", "=", "head_logprob", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "start_idx", ",", "stop_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.LogUniformSampler.__init__": [[261, 279], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double().log1p_", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "range_max", ",", "n_sample", ")", ":", "\n", "        ", "\"\"\"\n        Reference : https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/ops/candidate_sampling_ops.py\n            `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)`\n\n        expected count can be approximated by 1 - (1 - p)^n\n        and we use a numerically stable version -expm1(num_tries * log1p(-p))\n\n        Our implementation fixes num_tries at 2 * n_sample, and the actual #samples will vary from run to run\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "range_max", "=", "range_max", "\n", "log_indices", "=", "torch", ".", "arange", "(", "1.", ",", "range_max", "+", "2.", ",", "1.", ")", ".", "log_", "(", ")", "\n", "self", ".", "dist", "=", "(", "log_indices", "[", "1", ":", "]", "-", "log_indices", "[", ":", "-", "1", "]", ")", "/", "log_indices", "[", "-", "1", "]", "\n", "\n", "self", ".", "log_q", "=", "(", "-", "(", "-", "self", ".", "dist", ".", "double", "(", ")", ".", "log1p_", "(", ")", "*", "2", "*", "n_sample", ")", ".", "expm1_", "(", ")", ")", ".", "log_", "(", ")", ".", "float", "(", ")", "\n", "\n", "", "self", ".", "n_sample", "=", "n_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample": [[280, 300], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "neg_samples.to.to.to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n            labels: [b1, b2]\n        Return\n            true_log_probs: [b1, b2]\n            samp_log_probs: [n_sample]\n            neg_samples: [n_sample]\n        \"\"\"", "\n", "\n", "# neg_samples = torch.empty(0).long()", "\n", "n_sample", "=", "self", ".", "n_sample", "\n", "n_tries", "=", "2", "*", "n_sample", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "neg_samples", "=", "torch", ".", "multinomial", "(", "self", ".", "dist", ",", "n_tries", ",", "replacement", "=", "True", ")", ".", "unique", "(", ")", "\n", "device", "=", "labels", ".", "device", "\n", "neg_samples", "=", "neg_samples", ".", "to", "(", "device", ")", "\n", "true_log_probs", "=", "self", ".", "log_q", "[", "labels", "]", ".", "to", "(", "device", ")", "\n", "samp_log_probs", "=", "self", ".", "log_q", "[", "neg_samples", "]", ".", "to", "(", "device", ")", "\n", "return", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.sample_logits": [[301, 333], ["sampler.sample", "neg_samples.size", "torch.cat", "torch.cat", "torch.cat", "embedding", "all_w[].view", "all_w[].view", "all_b[].view", "sample_logits.masked_fill_", "torch.cat", "torch.cat", "torch.cat", "labels.size", "labels.size", "labels.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "", "def", "sample_logits", "(", "embedding", ",", "bias", ",", "labels", ",", "inputs", ",", "sampler", ")", ":", "\n", "    ", "\"\"\"\n        embedding: an nn.Embedding layer\n        bias: [n_vocab]\n        labels: [b1, b2]\n        inputs: [b1, b2, n_emb]\n        sampler: you may use a LogUniformSampler\n    Return\n        logits: [b1, b2, 1 + n_sample]\n    \"\"\"", "\n", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "=", "sampler", ".", "sample", "(", "labels", ")", "\n", "n_sample", "=", "neg_samples", ".", "size", "(", "0", ")", "\n", "b1", ",", "b2", "=", "labels", ".", "size", "(", "0", ")", ",", "labels", ".", "size", "(", "1", ")", "\n", "all_ids", "=", "torch", ".", "cat", "(", "[", "labels", ".", "view", "(", "-", "1", ")", ",", "neg_samples", "]", ")", "\n", "all_w", "=", "embedding", "(", "all_ids", ")", "\n", "true_w", "=", "all_w", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ",", "-", "1", ")", "\n", "sample_w", "=", "all_w", "[", "-", "n_sample", ":", "]", ".", "view", "(", "n_sample", ",", "-", "1", ")", "\n", "\n", "all_b", "=", "bias", "[", "all_ids", "]", "\n", "true_b", "=", "all_b", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ")", "\n", "sample_b", "=", "all_b", "[", "-", "n_sample", ":", "]", "\n", "\n", "hit", "=", "(", "labels", "[", ":", ",", ":", ",", "None", "]", "==", "neg_samples", ")", ".", "detach", "(", ")", "\n", "\n", "true_logits", "=", "torch", ".", "einsum", "(", "'ijk,ijk->ij'", ",", "\n", "[", "true_w", ",", "inputs", "]", ")", "+", "true_b", "-", "true_log_probs", "\n", "sample_logits", "=", "torch", ".", "einsum", "(", "'lk,ijk->ijl'", ",", "\n", "[", "sample_w", ",", "inputs", "]", ")", "+", "sample_b", "-", "samp_log_probs", "\n", "sample_logits", ".", "masked_fill_", "(", "hit", ",", "-", "1e30", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "true_logits", "[", ":", ",", ":", ",", "None", "]", ",", "sample_logits", "]", ",", "-", "1", ")", "\n", "\n", "return", "logits", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.url_to_filename": [[52, 68], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.filename_to_url": [[70, 94], ["os.path.join", "isinstance", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.cached_path": [[96, 124], ["urlparse", "isinstance", "str", "isinstance", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.split_s3_path": [[126, 137], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.s3_request": [[139, 156], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.s3_etag": [[158, 165], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.s3_get": [[167, 173], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.http_get": [[175, 185], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.file_utils.get_from_cache": [[187, 263], ["url.startswith", "file_utils.url_to_filename", "os.path.join", "isinstance", "str", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "response.headers.get.decode", "fnmatch.filter", "list", "os.path.exists", "isinstance", "requests.head", "os.path.exists", "os.listdir", "filter", "os.path.join", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "requests.head.headers.get", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "isinstance", "unicode", "s.endswith"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.url_to_filename", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_etag", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_get", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "not", "isinstance", "(", "cache_dir", ",", "str", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "EnvironmentError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "etag", "is", "not", "None", ":", "\n", "        ", "etag", "=", "etag", ".", "decode", "(", "'utf-8'", ")", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "'.*'", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "'.json'", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "output_string", ",", "str", ")", ":", "\n", "                    ", "output_string", "=", "unicode", "(", "output_string", ",", "'utf-8'", ")", "# The beauty of python 2", "\n", "", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_auto.AutoConfig.__init__": [[59, 61], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoConfig is designed to be instantiated \"", "\n", "\"using the `AutoConfig.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_auto.AutoConfig.from_pretrained": [[63, 131], ["ValueError", "modeling_roberta.RobertaConfig.from_pretrained", "modeling_bert.BertConfig.from_pretrained", "modeling_openai.OpenAIGPTConfig.from_pretrained", "modeling_gpt2.GPT2Config.from_pretrained", "modeling_transfo_xl.TransfoXLConfig.from_pretrained", "modeling_xlnet.XLNetConfig.from_pretrained", "modeling_xlm.XLMConfig.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the configuration classes of the library\n        from a pre-trained model configuration.\n\n        The configuration class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `bert`: BertConfig (Bert model)\n            - contains `openai-gpt`: OpenAIGPTConfig (OpenAI GPT model)\n            - contains `gpt2`: GPT2Config (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLConfig (Transformer-XL model)\n            - contains `xlnet`: XLNetConfig (XLNet model)\n            - contains `xlm`: XLMConfig (XLM model)\n            - contains `roberta`: RobertaConfig (RoBERTa model)\n\n        Params:\n            **pretrained_model_name_or_path**: either:\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache\n                    or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n                - a path to a `directory` containing a configuration file saved\n                    using the `save_pretrained(save_directory)` method.\n                - a path or url to a saved configuration `file`.\n            **cache_dir**: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n            **return_unused_kwargs**: (`optional`) bool:\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs`\n                is a dictionary consisting of the key/value pairs whose keys are not configuration attributes:\n                ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n            **kwargs**: (`optional`) dict:\n                Dictionary of key/value pairs with which to update the configuration object after loading.\n                - The values in kwargs of any keys which are configuration attributes will be used\n                to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled\n                by the `return_unused_kwargs` keyword parameter.\n\n        Examples::\n\n            config = AutoConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = AutoConfig.from_pretrained('./test/bert_saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = AutoConfig.from_pretrained('./test/bert_saved_model/my_configuration.json')\n            config = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "if", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Config", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_auto.AutoModel.__init__": [[155, 157], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoModel is designed to be instantiated \"", "\n", "\"using the `AutoModel.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_auto.AutoModel.from_pretrained": [[159, 246], ["ValueError", "modeling_roberta.RobertaModel.from_pretrained", "modeling_bert.BertModel.from_pretrained", "modeling_openai.OpenAIGPTModel.from_pretrained", "modeling_gpt2.GPT2Model.from_pretrained", "modeling_transfo_xl.TransfoXLModel.from_pretrained", "modeling_xlnet.XLNetModel.from_pretrained", "modeling_xlm.XLMModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the base model classes of the library\n        from a pre-trained model configuration.\n\n        The base model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `bert`: BertModel (Bert model)\n            - contains `openai-gpt`: OpenAIGPTModel (OpenAI GPT model)\n            - contains `gpt2`: GPT2Model (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLModel (Transformer-XL model)\n            - contains `xlnet`: XLNetModel (XLNet model)\n            - contains `xlm`: XLMModel (XLM model)\n            - contains `roberta`: RobertaModel (RoBERTa model)\n\n            The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n            To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            **pretrained_model_name_or_path**: either:\n                - a string with the `shortcut name` of a pre-trained model to load from cache\n                    or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n                - a path to a `directory` containing a configuration file saved\n                    using the `save_pretrained(save_directory)` method.\n                - a path or url to a tensorflow index checkpoint `file` (e.g. `./tf_model/model.ckpt.index`).\n                    In this case, ``from_tf`` should be set to True and a configuration object should be\n                    provided as `config` argument. This loading option is slower than converting the TensorFlow\n                    checkpoint in a PyTorch model using the provided conversion scripts and loading\n                    the PyTorch model afterwards.\n            **model_args**: (`optional`) Sequence:\n                All remaning positional arguments will be passed to the underlying model's __init__ function\n            **config**: an optional configuration for the model to use instead of an automatically loaded configuation.\n                Configuration can be automatically loaded when:\n                - the model is a model provided by the library (loaded with a `shortcut name` of a pre-trained model), or\n                - the model was saved using the `save_pretrained(save_directory)` (loaded by suppling the save directory).\n            **state_dict**: an optional state dictionnary for the model to use instead of a state dictionary loaded\n                from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using `save_pretrained(dir)` and `from_pretrained(save_directory)` is not\n                a simpler option.\n            **cache_dir**: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n            **output_loading_info**: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n            **kwargs**: (`optional`) dict:\n                Dictionary of key, values to update the configuration object after loading.\n                Can be used to override selected configuration parameters. E.g. ``output_attention=True``.\n\n               - If a configuration is provided with `config`, **kwargs will be directly passed\n                 to the underlying model's __init__ method.\n               - If a configuration is not provided, **kwargs will be first passed to the pretrained\n                 model configuration class loading function (`PretrainedConfig.from_pretrained`).\n                 Each key of **kwargs that corresponds to a configuration attribute\n                 will be used to override said attribute with the supplied **kwargs value.\n                 Remaining keys that do not correspond to any configuration attribute will\n                 be passed to the underlying model's __init__ function.\n\n        Examples::\n\n            model = AutoModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModel.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModel.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_xlnet_checkpoint_to_pytorch.convert_xlnet_checkpoint_to_pytorch": [[46, 73], ["pytorch_transformers.modeling_xlnet.XLNetConfig.from_json_file", "pytorch_transformers.modeling_xlnet.load_tf_weights_in_xlnet", "os.path.join", "os.path.join", "print", "torch.save", "print", "finetuning_task.lower", "print", "pytorch_transformers.modeling_xlnet.XLNetForSequenceClassification", "pytorch_transformers.modeling_xlnet.XLNetLMHeadModel.state_dict", "open", "f.write", "pytorch_transformers.modeling_xlnet.XLNetForQuestionAnswering", "pytorch_transformers.modeling_xlnet.XLNetLMHeadModel", "os.path.abspath", "os.path.abspath", "XLNetConfig.from_json_file.to_json_string", "str"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlnet.load_tf_weights_in_xlnet", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["def", "convert_xlnet_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_folder_path", ",", "finetuning_task", "=", "None", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "XLNetConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "\n", "finetuning_task", "=", "finetuning_task", ".", "lower", "(", ")", "if", "finetuning_task", "is", "not", "None", "else", "\"\"", "\n", "if", "finetuning_task", "in", "GLUE_TASKS_NUM_LABELS", ":", "\n", "        ", "print", "(", "\"Building PyTorch XLNetForSequenceClassification model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "config", ".", "finetuning_task", "=", "finetuning_task", "\n", "config", ".", "num_labels", "=", "GLUE_TASKS_NUM_LABELS", "[", "finetuning_task", "]", "\n", "model", "=", "XLNetForSequenceClassification", "(", "config", ")", "\n", "", "elif", "'squad'", "in", "finetuning_task", ":", "\n", "        ", "config", ".", "finetuning_task", "=", "finetuning_task", "\n", "model", "=", "XLNetForQuestionAnswering", "(", "config", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "XLNetLMHeadModel", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaEmbeddings.__init__": [[53, 56], ["pytorch_transformers.modeling_bert.BertEmbeddings.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaEmbeddings.forward": [[57, 65], ["input_ids.size", "super().forward", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForQuestionAnswering.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "# Position numbers begin at padding_idx+1. Padding symbols are ignored.", "\n", "# cf. fairseq's `utils.make_positions`", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "", "return", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "position_ids", "=", "position_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaModel.__init__": [[162, 167], ["pytorch_transformers.modeling_bert.BertModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaModel.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaModel.forward": [[168, 174], ["super().forward", "input_ids[].sum().item", "logger.warning", "input_ids[].sum"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForQuestionAnswering.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "[", ":", ",", "0", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"A sequence with no special tokens has been passed to the RoBERTa model. \"", "\n", "\"This model requires special tokens in order to work. \"", "\n", "\"Please specify add_special_tokens=True in your encoding.\"", ")", "\n", "", "return", "super", "(", "RobertaModel", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "position_ids", ",", "head_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaForMaskedLM.__init__": [[212, 220], ["pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.apply", "modeling_roberta.RobertaForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaForMaskedLM.tie_weights": [[221, 226], ["modeling_roberta.RobertaForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ".", "decoder", ",", "self", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaForMaskedLM.forward": [[227, 242], ["modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaLMHead.__init__": [[247, 254], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "pytorch_transformers.modeling_bert.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaLMHead.forward": [[255, 264], ["modeling_roberta.RobertaLMHead.dense", "pytorch_transformers.modeling_bert.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.gelu"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaForSequenceClassification.__init__": [[304, 310], ["pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaForSequenceClassification.forward": [[311, 330], ["modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaClassificationHead.__init__": [[336, 341], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_roberta.RobertaClassificationHead.forward": [[342, 350], ["modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.bos_token": [[126, 129], ["None"], "methods", ["None"], ["", "@", "bos_token", ".", "setter", "\n", "def", "bos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.eos_token": [[130, 133], ["None"], "methods", ["None"], ["", "@", "eos_token", ".", "setter", "\n", "def", "eos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_eos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.unk_token": [[134, 137], ["None"], "methods", ["None"], ["", "@", "unk_token", ".", "setter", "\n", "def", "unk_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_unk_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.sep_token": [[138, 141], ["None"], "methods", ["None"], ["", "@", "sep_token", ".", "setter", "\n", "def", "sep_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_sep_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.pad_token": [[142, 145], ["None"], "methods", ["None"], ["", "@", "pad_token", ".", "setter", "\n", "def", "pad_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.cls_token": [[146, 149], ["None"], "methods", ["None"], ["", "@", "cls_token", ".", "setter", "\n", "def", "cls_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_cls_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.mask_token": [[150, 153], ["None"], "methods", ["None"], ["", "@", "mask_token", ".", "setter", "\n", "def", "mask_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_mask_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.additional_special_tokens": [[154, 157], ["None"], "methods", ["None"], ["", "@", "additional_special_tokens", ".", "setter", "\n", "def", "additional_special_tokens", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_additional_special_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.__init__": [[158, 179], ["kwargs.items", "int", "setattr", "isinstance", "all", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "max_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "None", "\n", "self", ".", "_eos_token", "=", "None", "\n", "self", ".", "_unk_token", "=", "None", "\n", "self", ".", "_sep_token", "=", "None", "\n", "self", ".", "_pad_token", "=", "None", "\n", "self", ".", "_cls_token", "=", "None", "\n", "self", ".", "_mask_token", "=", "None", "\n", "self", ".", "_additional_special_tokens", "=", "[", "]", "\n", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "added_tokens_encoder", "=", "{", "}", "\n", "self", ".", "added_tokens_decoder", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "                ", "if", "key", "==", "'additional_special_tokens'", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "isinstance", "(", "t", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "t", ",", "unicode", ")", ")", "for", "t", "in", "value", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "value", ",", "unicode", ")", ")", "\n", "", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.from_pretrained": [[181, 221], ["cls._from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained"], ["", "", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"\n        Instantiate a :class:`~pytorch_transformers.PreTrainedTokenizer` (or a derived class) from a predefined tokenizer.\n\n        Args:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a predefined tokenizer to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing vocabulary files required by the tokenizer, for instance saved using the :func:`~pytorch_transformers.PreTrainedTokenizer.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - (not applicable to all derived classes) a path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (e.g. Bert, XLNet), e.g.: ``./my_model_directory/vocab.txt``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the standard cache should not be used.\n\n            inputs: (`optional`) positional arguments: will be passed to the Tokenizer ``__init__`` method.\n\n            kwargs: (`optional`) keyword arguments: will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``, ``additional_special_tokens``. See parameters in the doc string of :class:`~pytorch_transformers.PreTrainedTokenizer` for details.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PreTrainedTokenizer` so let's show our examples on a derived class: BertTokenizer\n\n            # Download vocabulary from S3 and cache.\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n            # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/')\n\n            # If the tokenizer uses a single vocabulary file, you can point directly to this file\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/my_vocab.txt')\n\n            # You can link tokens to special vocabulary when instantiating\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', unk_token='<unk>')\n            # You should be sure '<unk>' is in the vocabulary when doing that.\n            # Otherwise use tokenizer.add_special_tokens({'unk_token': '<unk>'}) instead)\n            assert tokenizer.unk_token == '<unk>'\n\n        \"\"\"", "\n", "return", "cls", ".", "_from_pretrained", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained": [[223, 337], ["kwargs.pop", "list", "vocab_files.items", "resolved_vocab_files.pop", "resolved_vocab_files.pop", "resolved_vocab_files.items", "cls", "cls.max_model_input_sizes.keys", "cls.pretrained_vocab_files_map.items", "logger.info", "cls.vocab_files_names.items", "all_vocab_files_names.items", "all", "vocab_files.items", "json.load", "json.load.items", "json.load", "cls.added_tokens_encoder.update", "cls.added_tokens_decoder.update", "os.path.isdir", "os.path.exists", "os.path.dirname", "os.path.join", "logger.error", "logger.info", "logger.info", "isinstance", "min", "io.open", "io.open", "os.path.join", "os.path.exists", "logger.info", "os.path.isdir", "os.path.exists", "logger.info", "file_utils.cached_path", "logger.error", "logger.error", "kwargs.get", "json.load.items", "vocab_files.values", "int", "str", "vocab_files.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "_from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "\n", "s3_models", "=", "list", "(", "cls", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "vocab_files", "=", "{", "}", "\n", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "# Get the vocabulary from AWS S3 bucket", "\n", "            ", "for", "file_id", ",", "map_list", "in", "cls", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "                ", "vocab_files", "[", "file_id", "]", "=", "map_list", "[", "pretrained_model_name_or_path", "]", "\n", "", "", "else", ":", "\n", "# Get the vocabulary from local files", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Model name '{}' not found in model shortcut name list ({}). \"", "\n", "\"Assuming '{}' is a path or url to a directory containing tokenizer files.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "\n", "# Look for the tokenizer main vocabulary files", "\n", "for", "file_id", ",", "file_name", "in", "cls", ".", "vocab_files_names", ".", "items", "(", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "# If a directory is provided we look for the standard filenames", "\n", "                    ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "file_name", ")", "\n", "", "else", ":", "\n", "# If a path to a file is provided we use it (will only work for non-BPE tokenizer using a single vocabulary file)", "\n", "                    ", "full_file_name", "=", "pretrained_model_name_or_path", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "# Look for the additional tokens files", "\n", "", "all_vocab_files_names", "=", "{", "'added_tokens_file'", ":", "ADDED_TOKENS_FILE", ",", "\n", "'special_tokens_map_file'", ":", "SPECIAL_TOKENS_MAP_FILE", "}", "\n", "\n", "# If a path to a file was provided, get the parent directory", "\n", "saved_directory", "=", "pretrained_model_name_or_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "saved_directory", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "saved_directory", ")", ":", "\n", "                ", "saved_directory", "=", "os", ".", "path", ".", "dirname", "(", "saved_directory", ")", "\n", "\n", "", "for", "file_id", ",", "file_name", "in", "all_vocab_files_names", ".", "items", "(", ")", ":", "\n", "                ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "saved_directory", ",", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "", "if", "all", "(", "full_file_name", "is", "None", "for", "full_file_name", "in", "vocab_files", ".", "values", "(", ")", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find tokenizer files\"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", ")", ")", "\n", "return", "None", "\n", "\n", "# Get files from url, cache, or disk depending on the case", "\n", "", "", "try", ":", "\n", "            ", "resolved_vocab_files", "=", "{", "}", "\n", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "                ", "if", "file_path", "is", "None", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "cached_path", "(", "file_path", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "                ", "logger", ".", "error", "(", "\"Couldn't reach server to download vocabulary.\"", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "str", "(", "vocab_files", ".", "keys", "(", ")", ")", ")", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "file_path", "==", "resolved_vocab_files", "[", "file_id", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {} from cache at {}\"", ".", "format", "(", "\n", "file_path", ",", "resolved_vocab_files", "[", "file_id", "]", ")", ")", "\n", "\n", "# Set max length if needed", "\n", "", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "max_model_input_sizes", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer", "\n", "# wont index sequences longer than the number of positional embeddings", "\n", "            ", "max_len", "=", "cls", ".", "max_model_input_sizes", "[", "pretrained_model_name_or_path", "]", "\n", "if", "max_len", "is", "not", "None", "and", "isinstance", "(", "max_len", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "\n", "# Merge resolved_vocab_files arguments in kwargs.", "\n", "", "", "added_tokens_file", "=", "resolved_vocab_files", ".", "pop", "(", "'added_tokens_file'", ",", "None", ")", "\n", "special_tokens_map_file", "=", "resolved_vocab_files", ".", "pop", "(", "'special_tokens_map_file'", ",", "None", ")", "\n", "for", "args_name", ",", "file_path", "in", "resolved_vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "args_name", "not", "in", "kwargs", ":", "\n", "                ", "kwargs", "[", "args_name", "]", "=", "file_path", "\n", "", "", "if", "special_tokens_map_file", "is", "not", "None", ":", "\n", "            ", "special_tokens_map", "=", "json", ".", "load", "(", "open", "(", "special_tokens_map_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "for", "key", ",", "value", "in", "special_tokens_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "kwargs", ":", "\n", "                    ", "kwargs", "[", "key", "]", "=", "value", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "", "", "tokenizer", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "# Add supplementary tokens.", "\n", "if", "added_tokens_file", "is", "not", "None", ":", "\n", "            ", "added_tok_encoder", "=", "json", ".", "load", "(", "open", "(", "added_tokens_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "tokenizer", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "tokenizer", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.save_pretrained": [[339, 365], ["os.path.join", "os.path.join", "tokenization_utils.PreTrainedTokenizer.save_vocabulary", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "f.write", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.save_vocabulary"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary files (with added tokens) and the\n            special-tokens-to-class-attributes-mapping to a directory.\n\n            This method make sure the full tokenizer can then be re-loaded using the :func:`~pytorch_transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Saving directory ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "\n", "", "special_tokens_map_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "SPECIAL_TOKENS_MAP_FILE", ")", "\n", "added_tokens_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "ADDED_TOKENS_FILE", ")", "\n", "\n", "with", "open", "(", "special_tokens_map_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "special_tokens_map", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "added_tokens_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "if", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "out_str", "=", "json", ".", "dumps", "(", "self", ".", "added_tokens_encoder", ",", "ensure_ascii", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "out_str", "=", "u\"{}\"", "\n", "", "f", ".", "write", "(", "out_str", ")", "\n", "\n", "", "vocab_files", "=", "self", ".", "save_vocabulary", "(", "save_directory", ")", "\n", "\n", "return", "vocab_files", "+", "(", "special_tokens_map_file", ",", "added_tokens_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.save_vocabulary": [[367, 374], ["None"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary to a directory. This method does *NOT* save added tokens\n            and special token mappings.\n\n            Please use :func:`~pytorch_transformers.PreTrainedTokenizer.save_pretrained` `()` to save the full Tokenizer state if you want to reload it using the :func:`~pytorch_transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.vocab_size": [[376, 379], ["None"], "methods", ["None"], ["", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the base vocabulary (without the added tokens) \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.__len__": [[381, 384], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the full vocabulary with the added tokens \"\"\"", "\n", "return", "self", ".", "vocab_size", "+", "len", "(", "self", ".", "added_tokens_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.add_tokens": [[386, 424], ["dict", "tokenization_utils.PreTrainedTokenizer.added_tokens_encoder.update", "tokenization_utils.PreTrainedTokenizer.added_tokens_decoder.update", "len", "isinstance", "to_add_tokens.append", "logger.info", "dict.items", "isinstance", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "add_tokens", "(", "self", ",", "new_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Add a list of new tokens to the tokenizer class. If the new tokens are not in the\n        vocabulary, they are added to it with indices starting from length of the current vocabulary.\n\n        Args:\n            new_tokens: list of string. Each string is a token to add. Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n\n        Returns:\n            Number of tokens added to the vocabulary.\n\n        Examples::\n\n            # Let's see how to increase the vocabulary of Bert model and tokenizer\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            model = BertModel.from_pretrained('bert-base-uncased')\n\n            num_added_toks = tokenizer.add_tokens(['new_tok1', 'my_new-tok2'])\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n        \"\"\"", "\n", "if", "not", "new_tokens", ":", "\n", "            ", "return", "0", "\n", "\n", "", "to_add_tokens", "=", "[", "]", "\n", "for", "token", "in", "new_tokens", ":", "\n", "            ", "assert", "isinstance", "(", "token", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "token", ",", "unicode", ")", ")", "\n", "if", "token", "!=", "self", ".", "unk_token", "and", "self", ".", "convert_tokens_to_ids", "(", "token", ")", "==", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", ":", "\n", "                ", "to_add_tokens", ".", "append", "(", "token", ")", "\n", "logger", ".", "info", "(", "\"Adding %s to the vocabulary\"", ",", "token", ")", "\n", "\n", "", "", "added_tok_encoder", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "to_add_tokens", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "self", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "return", "len", "(", "to_add_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens": [[426, 472], ["special_tokens_dict.items", "logger.info", "setattr", "tokenization_utils.PreTrainedTokenizer.add_tokens", "tokenization_utils.PreTrainedTokenizer.add_tokens", "isinstance", "all", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.add_tokens"], ["", "def", "add_special_tokens", "(", "self", ",", "special_tokens_dict", ")", ":", "\n", "        ", "\"\"\"\n        Add a dictionary of special tokens (eos, pad, cls...) to the encoder and link them\n        to class attributes. If special tokens are NOT in the vocabulary, they are added\n        to it (indexed starting from the last index of the current vocabulary).\n\n        Args:\n            special_tokens_dict: dict of string. Keys should be in the list of predefined special attributes:\n                [``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``,\n                ``additional_special_tokens``].\n\n                Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n\n        Returns:\n            Number of tokens added to the vocabulary.\n\n        Examples::\n\n            # Let's see how to add a new classification token to GPT-2\n            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n            model = GPT2Model.from_pretrained('gpt2')\n\n            special_tokens_dict = {'cls_token': '<CLS>'}\n\n            num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n\n            assert tokenizer.cls_token == '<CLS>'\n        \"\"\"", "\n", "if", "not", "special_tokens_dict", ":", "\n", "            ", "return", "0", "\n", "\n", "", "added_tokens", "=", "0", "\n", "for", "key", ",", "value", "in", "special_tokens_dict", ".", "items", "(", ")", ":", "\n", "            ", "assert", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", "\n", "if", "key", "==", "'additional_special_tokens'", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "isinstance", "(", "t", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "t", ",", "unicode", ")", ")", "for", "t", "in", "value", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "value", ",", "unicode", ")", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "[", "value", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Assigning %s to the %s key of the tokenizer\"", ",", "value", ",", "key", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n", "", "return", "added_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.tokenize": [[473, 493], ["tokenization_utils.PreTrainedTokenizer.tokenize.split_on_tokens"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Take care of added tokens.\n        \"\"\"", "\n", "def", "split_on_tokens", "(", "tok_list", ",", "text", ")", ":", "\n", "            ", "if", "not", "text", ":", "\n", "                ", "return", "[", "]", "\n", "", "if", "not", "tok_list", ":", "\n", "                ", "return", "self", ".", "_tokenize", "(", "text", ",", "**", "kwargs", ")", "\n", "", "tok", "=", "tok_list", "[", "0", "]", "\n", "split_text", "=", "text", ".", "split", "(", "tok", ")", "\n", "return", "sum", "(", "(", "split_on_tokens", "(", "tok_list", "[", "1", ":", "]", ",", "sub_text", ".", "strip", "(", ")", ")", "+", "[", "tok", "]", "for", "sub_text", "in", "split_text", ")", ",", "[", "]", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "added_tokens", "=", "list", "(", "self", ".", "added_tokens_encoder", ".", "keys", "(", ")", ")", "+", "self", ".", "all_special_tokens", "\n", "tokenized_text", "=", "split_on_tokens", "(", "added_tokens", ",", "text", ")", "\n", "return", "tokenized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._tokenize": [[494, 502], ["None"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Do NOT take care of added tokens.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids": [[503, 518], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "ids.append", "len", "logger.warning", "isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a single token, or a sequence of tokens, (str/unicode) in a single integer id\n            (resp. a sequence of ids), using the vocabulary.\n        \"\"\"", "\n", "if", "isinstance", "(", "tokens", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "tokens", ",", "unicode", ")", ")", ":", "\n", "            ", "return", "self", ".", "_convert_token_to_id_with_added_voc", "(", "tokens", ")", "\n", "\n", "", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "_convert_token_to_id_with_added_voc", "(", "token", ")", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Token indices sequence length is longer than the specified maximum sequence length \"", "\n", "\"for this model ({} > {}). Running this sequence through the model will result in \"", "\n", "\"indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc": [[519, 523], ["tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "_convert_token_to_id_with_added_voc", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "            ", "return", "self", ".", "added_tokens_encoder", "[", "token", "]", "\n", "", "return", "self", ".", "_convert_token_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id": [[524, 526], ["None"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode": [[527, 552], ["tokenization_utils.PreTrainedTokenizer._convert_token_to_id", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id", "tokenization_utils.PreTrainedTokenizer.add_special_tokens_sentences_pair", "tokenization_utils.PreTrainedTokenizer.add_special_tokens_single_sentence", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.tokenize", "tokenization_utils.PreTrainedTokenizer.tokenize", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.tokenize", "tokenization_utils.PreTrainedTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "encode", "(", "self", ",", "text", ",", "text_pair", "=", "None", ",", "add_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Converts a string in a sequence of ids (integer), using the tokenizer and vocabulary.\n        \n        Same as doing ``self.convert_tokens_to_ids(self.tokenize(text))``.\n\n        Args:\n            text: The first sequence to be encoded.\n            text_pair: Optional second sequence to be encoded.\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n        \"\"\"", "\n", "if", "text_pair", "is", "None", ":", "\n", "            ", "if", "add_special_tokens", ":", "\n", "                ", "return", "self", ".", "add_special_tokens_single_sentence", "(", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ")", ")", "\n", "\n", "", "", "first_sentence_tokens", "=", "[", "self", ".", "_convert_token_to_id", "(", "token", ")", "for", "token", "in", "self", ".", "tokenize", "(", "text", ")", "]", "\n", "second_sentence_tokens", "=", "[", "self", ".", "_convert_token_to_id", "(", "token", ")", "for", "token", "in", "self", ".", "tokenize", "(", "text_pair", ")", "]", "\n", "\n", "if", "add_special_tokens", ":", "\n", "            ", "return", "self", ".", "add_special_tokens_sentences_pair", "(", "first_sentence_tokens", ",", "second_sentence_tokens", ")", "\n", "", "else", ":", "\n", "            ", "return", "first_sentence_tokens", ",", "second_sentence_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens_single_sentence": [[553, 555], ["None"], "methods", ["None"], ["", "", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens_sentences_pair": [[556, 558], ["None"], "methods", ["None"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens": [[559, 580], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token", "tokens.append", "tokens.append", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\" Converts a single index or a sequence of indices (integers) in a token \"\n            (resp.) a sequence of tokens (str/unicode), using the vocabulary and added tokens.\n\n            Args:\n                skip_special_tokens: Don't decode special tokens (self.all_special_tokens). Default: False\n        \"\"\"", "\n", "if", "isinstance", "(", "ids", ",", "int", ")", ":", "\n", "            ", "if", "ids", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "return", "self", ".", "added_tokens_decoder", "[", "ids", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_convert_id_to_token", "(", "ids", ")", "\n", "", "", "tokens", "=", "[", "]", "\n", "for", "index", "in", "ids", ":", "\n", "            ", "if", "index", "in", "self", ".", "all_special_ids", "and", "skip_special_tokens", ":", "\n", "                ", "continue", "\n", "", "if", "index", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "added_tokens_decoder", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "_convert_id_to_token", "(", "index", ")", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer._convert_id_to_token": [[581, 583], ["None"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string": [[584, 590], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string.\n            The most simple way to do it is ' '.join(self.convert_ids_to_tokens(token_ids))\n            but we often want to remove sub-word tokenization artifacts at the same time.\n        \"\"\"", "\n", "return", "' '", ".", "join", "(", "self", ".", "convert_ids_to_tokens", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode": [[591, 614], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "text.replace.replace.replace", "list", "filter", "tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "text.replace.replace.split", "tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization"], ["", "def", "decode", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Converts a sequence of ids (integer) in a string, using the tokenizer and vocabulary\n        with options to remove special tokens and clean up tokenization spaces.\n        Similar to doing ``self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))``.\n        \"\"\"", "\n", "filtered_tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "token_ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "text", "=", "self", ".", "convert_tokens_to_string", "(", "filtered_tokens", ")", "\n", "\n", "if", "self", ".", "sep_token", "is", "not", "None", "and", "self", ".", "sep_token", "in", "text", ":", "\n", "            ", "text", "=", "text", ".", "replace", "(", "self", ".", "cls_token", ",", "self", ".", "sep_token", ")", "\n", "split_text", "=", "list", "(", "filter", "(", "lambda", "sentence", ":", "len", "(", "sentence", ")", ">", "0", ",", "text", ".", "split", "(", "self", ".", "sep_token", ")", ")", ")", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "                ", "clean_text", "=", "[", "self", ".", "clean_up_tokenization", "(", "text", ")", "for", "text", "in", "split_text", "]", "\n", "return", "clean_text", "\n", "", "else", ":", "\n", "                ", "return", "split_text", "\n", "", "", "else", ":", "\n", "            ", "if", "clean_up_tokenization_spaces", ":", "\n", "                ", "clean_text", "=", "self", ".", "clean_up_tokenization", "(", "text", ")", "\n", "return", "clean_text", "\n", "", "else", ":", "\n", "                ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.special_tokens_map": [[615, 626], ["getattr"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "special_tokens_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" A dictionary mapping special token class attribute (cls_token, unk_token...) to their\n            values ('<unk>', '<cls>'...)\n        \"\"\"", "\n", "set_attr", "=", "{", "}", "\n", "for", "attr", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "            ", "attr_value", "=", "getattr", "(", "self", ",", "\"_\"", "+", "attr", ")", "\n", "if", "attr_value", ":", "\n", "                ", "set_attr", "[", "attr", "]", "=", "attr_value", "\n", "", "", "return", "set_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.all_special_tokens": [[627, 638], ["set_attr.values", "list", "set", "isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_special_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\" List all the special tokens ('<unk>', '<cls>'...) mapped to class attributes\n            (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "[", "]", "\n", "set_attr", "=", "self", ".", "special_tokens_map", "\n", "for", "attr_value", "in", "set_attr", ".", "values", "(", ")", ":", "\n", "            ", "all_toks", "=", "all_toks", "+", "(", "attr_value", "if", "isinstance", "(", "attr_value", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "attr_value", "]", ")", "\n", "", "all_toks", "=", "list", "(", "set", "(", "all_toks", ")", ")", "\n", "return", "all_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.all_special_ids": [[639, 647], ["list", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "@", "property", "\n", "def", "all_special_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" List the vocabulary indices of the special tokens ('<unk>', '<cls>'...) mapped to\n            class attributes (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "self", ".", "all_special_tokens", "\n", "all_ids", "=", "list", "(", "self", ".", "_convert_token_to_id", "(", "t", ")", "for", "t", "in", "all_toks", ")", "\n", "return", "all_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization": [[648, 656], ["out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "clean_up_tokenization", "(", "out_string", ")", ":", "\n", "        ", "\"\"\" Clean up a list of simple English tokenization artifacts like spaces before punctuations and abreviated forms.\n        \"\"\"", "\n", "out_string", "=", "out_string", ".", "replace", "(", "' .'", ",", "'.'", ")", ".", "replace", "(", "' ?'", ",", "'?'", ")", ".", "replace", "(", "' !'", ",", "'!'", ")", ".", "replace", "(", "' ,'", ",", "','", "\n", ")", ".", "replace", "(", "\" ' \"", ",", "\"'\"", ")", ".", "replace", "(", "\" n't\"", ",", "\"n't\"", ")", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", "\n", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", ".", "replace", "(", "\" 're\"", ",", "\"'re\"", ")", "\n", "return", "out_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.__init__": [[86, 92], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "'finetuning_task'", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "'num_labels'", ",", "2", ")", "\n", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "'output_attentions'", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "'output_hidden_states'", ",", "False", ")", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "'torchscript'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.save_pretrained": [[93, 103], ["os.path.isdir", "os.path.join", "modeling_utils.PretrainedConfig.to_json_file"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.to_json_file"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to the directory `save_directory`, so that it\n            can be re-loaded using the :func:`~pytorch_transformers.PretrainedConfig.from_pretrained` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.from_pretrained": [[104, 193], ["kwargs.pop", "kwargs.pop", "cls.from_json_file", "kwargs.items", "logger.info", "os.path.isdir", "file_utils.cached_path", "logger.info", "logger.info", "hasattr", "kwargs.pop", "os.path.join", "setattr", "to_remove.append", "logger.error", "logger.error", "cls.pretrained_config_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a :class:`~pytorch_transformers.PretrainedConfig` (or a derived class) from a pre-trained model configuration.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~pytorch_transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n            # derived class: BertConfig\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "'return_unused_kwargs'", ",", "False", ")", "\n", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "cls", ".", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_config_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "config_file", ")", ")", "\n", "", "return", "None", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "# Load config", "\n", "", "config", "=", "cls", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "config", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "config", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.from_dict": [[194, 201], ["cls", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "cls", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.from_json_file": [[202, 208], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.__eq__": [[209, 211], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.__repr__": [[212, 214], ["str", "modeling_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.to_dict": [[215, 219], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.to_json_string": [[220, 223], ["json.dumps", "modeling_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.to_json_file": [[224, 228], ["io.open", "writer.write", "modeling_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.__init__": [[252, 263], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._get_resized_embeddings": [[264, 297], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel.init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTPreTrainedModel.init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy word embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[298, 305], ["torch.nn.Parameter", "second_module.weight.clone"], "methods", ["None"], ["", "def", "_tie_or_clone_weights", "(", "self", ",", "first_module", ",", "second_module", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "first_module", ".", "weight", "=", "nn", ".", "Parameter", "(", "second_module", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "first_module", ".", "weight", "=", "second_module", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.resize_token_embeddings": [[306, 333], ["getattr", "getattr._resize_token_embeddings", "hasattr", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTModel._resize_token_embeddings", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end. \n                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "if", "hasattr", "(", "self", ",", "'tie_weights'", ")", ":", "\n", "            ", "self", ".", "tie_weights", "(", ")", "\n", "\n", "", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.prune_heads": [[334, 343], ["getattr", "getattr._prune_heads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTModel._prune_heads"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.save_pretrained": [[344, 360], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~pytorch_transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model it-self if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "'module'", ")", "else", "self", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.from_pretrained": [[361, 545], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~pytorch_transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~pytorch_transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~pytorch_transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~pytorch_transformers.PreTrainedModel.save_pretrained` and :func:`~pytorch_transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~pytorch_transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "            ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "return", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# Load from a PyTorch state_dict", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "'.'", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.Conv1D.__init__": [[548, 558], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.Conv1D.forward": [[559, 564], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PoolerStartLogits.__init__": [[568, 571], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerStartLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PoolerStartLogits.forward": [[572, 584], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PoolerEndLogits.__init__": [[589, 595], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerEndLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PoolerEndLogits.forward": [[596, 625], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PoolerAnswerClass.__init__": [[629, 634], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerAnswerClass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PoolerAnswerClass.forward": [[635, 669], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.SQuADHead.__init__": [[711, 719], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SQuADHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.SQuADHead.forward": [[720, 778], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.SequenceSummary.__init__": [[795, 824], ["torch.nn.Module.__init__", "Identity", "Identity", "Identity", "Identity", "hasattr", "hasattr", "torch.nn.Linear", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "else", "'last'", "\n", "if", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "'summary_proj_to_labels'", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "self", ".", "activation", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_activation'", ")", "and", "config", ".", "summary_activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_first_dropout'", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_last_dropout'", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.SequenceSummary.forward": [[825, 855], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "'last'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'first'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'mean'", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "'cls_index'", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer": [[857, 880], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_conv1d_layer": [[882, 904], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_layer": [[906, 917], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertConfig.__init__": [[183, 219], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "30522", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertEmbeddings.__init__": [[245, 255], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertEmbeddings.forward": [[256, 272], ["input_ids.size", "modeling_bert.BertEmbeddings.word_embeddings", "modeling_bert.BertEmbeddings.position_embeddings", "modeling_bert.BertEmbeddings.token_type_embeddings", "modeling_bert.BertEmbeddings.LayerNorm", "modeling_bert.BertEmbeddings.dropout", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertSelfAttention.__init__": [[275, 292], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertSelfAttention.transpose_for_scores": [[293, 297], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertSelfAttention.forward": [[298, 332], ["modeling_bert.BertSelfAttention.query", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_bert.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_bert.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.value", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertSelfOutput.__init__": [[335, 340], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertSelfOutput.forward": [[341, 346], ["modeling_bert.BertSelfOutput.dense", "modeling_bert.BertSelfOutput.dropout", "modeling_bert.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertAttention.__init__": [[349, 353], ["torch.nn.Module.__init__", "modeling_bert.BertSelfAttention", "modeling_bert.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertAttention.prune_heads": [[354, 370], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "len", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ")", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertAttention.forward": [[371, 376], ["modeling_bert.BertAttention.self", "modeling_bert.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "input_tensor", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertIntermediate.__init__": [[379, 386], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertIntermediate.forward": [[387, 391], ["modeling_bert.BertIntermediate.dense", "modeling_bert.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertOutput.__init__": [[394, 399], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertOutput.forward": [[400, 405], ["modeling_bert.BertOutput.dense", "modeling_bert.BertOutput.dropout", "modeling_bert.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertLayer.__init__": [[408, 413], ["torch.nn.Module.__init__", "modeling_bert.BertAttention", "modeling_bert.BertIntermediate", "modeling_bert.BertOutput"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertLayer.forward": [[414, 421], ["modeling_bert.BertLayer.attention", "modeling_bert.BertLayer.intermediate", "modeling_bert.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertEncoder.__init__": [[424, 429], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "modeling_bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertEncoder.forward": [[430, 453], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPooler.__init__": [[456, 460], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPooler.forward": [[461, 468], ["modeling_bert.BertPooler.dense", "modeling_bert.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPredictionHeadTransform.__init__": [[471, 479], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPredictionHeadTransform.forward": [[480, 485], ["modeling_bert.BertPredictionHeadTransform.dense", "modeling_bert.BertPredictionHeadTransform.transform_act_fn", "modeling_bert.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertLMPredictionHead.__init__": [[488, 499], ["torch.nn.Module.__init__", "modeling_bert.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "\n", "config", ".", "vocab_size", ",", "\n", "bias", "=", "False", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertLMPredictionHead.forward": [[500, 504], ["modeling_bert.BertLMPredictionHead.transform", "modeling_bert.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertOnlyMLMHead.__init__": [[507, 510], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertOnlyMLMHead.forward": [[511, 514], ["modeling_bert.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertOnlyNSPHead.__init__": [[517, 520], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertOnlyNSPHead.forward": [[521, 524], ["modeling_bert.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPreTrainingHeads.__init__": [[527, 531], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPreTrainingHeads.forward": [[532, 536], ["modeling_bert.BertPreTrainingHeads.predictions", "modeling_bert.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__": [[547, 549], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertPreTrainedModel.init_weights": [[550, 562], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertModel.__init__": [[653, 661], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertEmbeddings", "modeling_bert.BertEncoder", "modeling_bert.BertPooler", "modeling_bert.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertModel._resize_token_embeddings": [[662, 667], ["modeling_bert.BertModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "embeddings", ".", "word_embeddings", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertModel._prune_heads": [[668, 675], ["heads_to_prune.items", "modeling_bert.BertModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertModel.forward": [[676, 721], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling_bert.BertModel.embeddings", "modeling_bert.BertModel.encoder", "modeling_bert.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "torch.ones_like.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForPreTraining.__init__": [[763, 771], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertPreTrainingHeads", "modeling_bert.BertForPreTraining.apply", "modeling_bert.BertForPreTraining.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForPreTraining.tie_weights": [[772, 778], ["modeling_bert.BertForPreTraining._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForPreTraining.forward": [[779, 797], ["modeling_bert.BertForPreTraining.bert", "modeling_bert.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForMaskedLM.__init__": [[831, 839], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyMLMHead", "modeling_bert.BertForMaskedLM.apply", "modeling_bert.BertForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForMaskedLM.tie_weights": [[840, 846], ["modeling_bert.BertForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "cls", ".", "predictions", ".", "decoder", ",", "\n", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForMaskedLM.forward": [[847, 862], ["modeling_bert.BertForMaskedLM.bert", "modeling_bert.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForNextSentencePrediction.__init__": [[896, 903], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyNSPHead", "modeling_bert.BertForNextSentencePrediction.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForNextSentencePrediction.forward": [[904, 919], ["modeling_bert.BertForNextSentencePrediction.bert", "modeling_bert.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "next_sentence_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (next_sentence_loss), seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForSequenceClassification.__init__": [[955, 964], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForSequenceClassification.forward": [[965, 987], ["modeling_bert.BertForSequenceClassification.bert", "modeling_bert.BertForSequenceClassification.dropout", "modeling_bert.BertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForSequenceClassification.view", "labels.view", "modeling_bert.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForMultipleChoice.__init__": [[1060, 1068], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForMultipleChoice.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForMultipleChoice.forward": [[1069, 1093], ["input_ids.view", "modeling_bert.BertForMultipleChoice.bert", "modeling_bert.BertForMultipleChoice.dropout", "modeling_bert.BertForMultipleChoice.classifier", "modeling_bert.BertForMultipleChoice.view", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "position_ids.size", "token_type_ids.size", "attention_mask.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "outputs", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForTokenClassification.__init__": [[1127, 1136], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForTokenClassification.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForTokenClassification.forward": [[1137, 1160], ["modeling_bert.BertForTokenClassification.bert", "modeling_bert.BertForTokenClassification.dropout", "modeling_bert.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_bert.BertForTokenClassification.view", "labels.view", "modeling_bert.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForQuestionAnswering.__init__": [[1202, 1210], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Linear", "modeling_bert.BertForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.BertForQuestionAnswering.forward": [[1211, 1241], ["modeling_bert.BertForQuestionAnswering.bert", "modeling_bert.BertForQuestionAnswering.qa_outputs", "modeling_bert.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.load_tf_weights_in_bert": [[69, 134], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'squad'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'classifier'", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.gelu": [[136, 143], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_bert.swish": [[145, 147], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.__main__.main": [[2, 126], ["print", "len", "len", "len", "print", "sys.argv.pop", "sys.argv.pop", "sys.argv.pop", "convert_tf_checkpoint_to_pytorch", "print", "print", "convert_openai_checkpoint_to_pytorch", "len", "len", "len", "print", "convert_transfo_xl_checkpoint_to_pytorch", "print", "len", "len", "sys.argv[].lower", "len", "print", "convert_gpt2_checkpoint_to_pytorch", "print", "len", "len", "len", "print", "convert_xlnet_checkpoint_to_pytorch", "print", "len", "len", "len", "len", "print", "convert_xlm_checkpoint_to_pytorch"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_openai_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_transfo_xl_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_gpt2_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_xlnet_checkpoint_to_pytorch.convert_xlnet_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_xlm_checkpoint_to_pytorch.convert_xlm_checkpoint_to_pytorch"], ["def", "main", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "if", "(", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "6", ")", "or", "sys", ".", "argv", "[", "1", "]", "not", "in", "[", "\"bert\"", ",", "\"gpt\"", ",", "\"transfo_xl\"", ",", "\"gpt2\"", ",", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "        ", "print", "(", "\n", "\"Should be used as one of: \\n\"", "\n", "\">> pytorch_transformers bert TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT, \\n\"", "\n", "\">> pytorch_transformers gpt OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG], \\n\"", "\n", "\">> pytorch_transformers transfo_xl TF_CHECKPOINT_OR_DATASET PYTORCH_DUMP_OUTPUT [TF_CONFIG] or \\n\"", "\n", "\">> pytorch_transformers gpt2 TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [GPT2_CONFIG] or \\n\"", "\n", "\">> pytorch_transformers xlnet TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT [FINETUNING_TASK_NAME] or \\n\"", "\n", "\">> pytorch_transformers xlm XLM_CHECKPOINT_PATH PYTORCH_DUMP_OUTPUT\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "sys", ".", "argv", "[", "1", "]", "==", "\"bert\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_tf_checkpoint_to_pytorch", "import", "convert_tf_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "!=", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_transformers bert TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT`\"", ")", "\n", "", "else", ":", "\n", "                ", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CONFIG", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CHECKPOINT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "convert_tf_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"gpt\"", ":", "\n", "            ", "from", ".", "convert_openai_checkpoint_to_pytorch", "import", "convert_openai_checkpoint_to_pytorch", "\n", "if", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_transformers gpt OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "                ", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                    ", "OPENAI_GPT_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "OPENAI_GPT_CONFIG", "=", "\"\"", "\n", "", "convert_openai_checkpoint_to_pytorch", "(", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", ",", "\n", "OPENAI_GPT_CONFIG", ",", "\n", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"transfo_xl\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_transfo_xl_checkpoint_to_pytorch", "import", "convert_transfo_xl_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_transformers transfo_xl TF_CHECKPOINT/TF_DATASET_FILE PYTORCH_DUMP_OUTPUT [TF_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "                ", "if", "'ckpt'", "in", "sys", ".", "argv", "[", "2", "]", ".", "lower", "(", ")", ":", "\n", "                    ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_DATASET_FILE", "=", "\"\"", "\n", "", "else", ":", "\n", "                    ", "TF_DATASET_FILE", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_CHECKPOINT", "=", "\"\"", "\n", "", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                    ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_transfo_xl_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ",", "TF_DATASET_FILE", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"gpt2\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_gpt2_checkpoint_to_pytorch", "import", "convert_gpt2_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_transformers gpt2 TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [TF_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "                ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                    ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_gpt2_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"xlnet\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_xlnet_checkpoint_to_pytorch", "import", "convert_xlnet_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "<", "5", "or", "len", "(", "sys", ".", "argv", ")", ">", "6", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_transformers xlnet TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT [FINETUNING_TASK_NAME]`\"", ")", "\n", "", "else", ":", "\n", "                ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_CONFIG", "=", "sys", ".", "argv", "[", "3", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "4", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "6", ":", "\n", "                    ", "FINETUNING_TASK", "=", "sys", ".", "argv", "[", "5", "]", "\n", "", "else", ":", "\n", "                    ", "FINETUNING_TASK", "=", "None", "\n", "\n", "", "convert_xlnet_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "\n", "TF_CONFIG", ",", "\n", "PYTORCH_DUMP_OUTPUT", ",", "\n", "FINETUNING_TASK", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"xlm\"", ":", "\n", "            ", "from", ".", "convert_xlm_checkpoint_to_pytorch", "import", "convert_xlm_checkpoint_to_pytorch", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "!=", "4", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_transformers xlm XLM_CHECKPOINT_PATH PYTORCH_DUMP_OUTPUT`\"", ")", "\n", "", "else", ":", "\n", "                ", "XLM_CHECKPOINT_PATH", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "\n", "convert_xlm_checkpoint_to_pytorch", "(", "XLM_CHECKPOINT_PATH", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMConfig.__init__": [[105, 181], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "30145", ",", "\n", "emb_dim", "=", "2048", ",", "\n", "n_layers", "=", "12", ",", "\n", "n_heads", "=", "16", ",", "\n", "dropout", "=", "0.1", ",", "\n", "attention_dropout", "=", "0.1", ",", "\n", "gelu_activation", "=", "True", ",", "\n", "sinusoidal_embeddings", "=", "False", ",", "\n", "causal", "=", "False", ",", "\n", "asm", "=", "False", ",", "\n", "n_langs", "=", "1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "embed_init_std", "=", "2048", "**", "-", "0.5", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "init_std", "=", "0.02", ",", "\n", "bos_index", "=", "0", ",", "\n", "eos_index", "=", "1", ",", "\n", "pad_index", "=", "2", ",", "\n", "unk_index", "=", "3", ",", "\n", "mask_index", "=", "5", ",", "\n", "is_encoder", "=", "True", ",", "\n", "\n", "finetuning_task", "=", "None", ",", "\n", "num_labels", "=", "2", ",", "\n", "summary_type", "=", "'first'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs XLMConfig.\n        \"\"\"", "\n", "super", "(", "XLMConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_words", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "emb_dim", "=", "emb_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "attention_dropout", "=", "attention_dropout", "\n", "self", ".", "gelu_activation", "=", "gelu_activation", "\n", "self", ".", "sinusoidal_embeddings", "=", "sinusoidal_embeddings", "\n", "self", ".", "causal", "=", "causal", "\n", "self", ".", "asm", "=", "asm", "\n", "self", ".", "n_langs", "=", "n_langs", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "self", ".", "bos_index", "=", "bos_index", "\n", "self", ".", "eos_index", "=", "eos_index", "\n", "self", ".", "pad_index", "=", "pad_index", "\n", "self", ".", "unk_index", "=", "unk_index", "\n", "self", ".", "mask_index", "=", "mask_index", "\n", "self", ".", "is_encoder", "=", "is_encoder", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "embed_init_std", "=", "embed_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "self", ".", "finetuning_task", "=", "finetuning_task", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMConfig.vocab_size": [[187, 190], ["None"], "methods", ["None"], ["", "@", "vocab_size", ".", "setter", "\n", "def", "vocab_size", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "n_words", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMConfig.hidden_size": [[191, 194], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "emb_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMConfig.num_attention_heads": [[195, 198], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMConfig.num_hidden_layers": [[199, 202], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.MultiHeadAttention.__init__": [[255, 268], ["torch.nn.Module.__init__", "next", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "n_heads", ",", "dim", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "MultiHeadAttention", ".", "NEW_ID", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dropout", "=", "config", ".", "attention_dropout", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "k_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "v_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "out_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.MultiHeadAttention.prune_heads": [[269, 286], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "len", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "attention_head_size", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_heads", ",", "attention_head_size", ")", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q_lin", "=", "prune_linear_layer", "(", "self", ".", "q_lin", ",", "index", ")", "\n", "self", ".", "k_lin", "=", "prune_linear_layer", "(", "self", ".", "k_lin", ",", "index", ")", "\n", "self", ".", "v_lin", "=", "prune_linear_layer", "(", "self", ".", "v_lin", ",", "index", ")", "\n", "self", ".", "out_lin", "=", "prune_linear_layer", "(", "self", ".", "out_lin", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "dim", "=", "attention_head_size", "*", "self", ".", "n_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.MultiHeadAttention.forward": [[287, 349], ["input.size", "modeling_xlm.MultiHeadAttention.forward.shape"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "mask", ",", "kv", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "'slen'", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "kv", ".", "size", "(", "1", ")", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "", "n_heads", "=", "self", ".", "n_heads", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "n_heads", "\n", "mask_reshape", "=", "(", "bs", ",", "1", ",", "qlen", ",", "klen", ")", "if", "mask", ".", "dim", "(", ")", "==", "3", "else", "(", "bs", ",", "1", ",", "1", ",", "klen", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k_", ",", "k", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v_", ",", "v", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "scores", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "# (bs, n_heads, qlen, klen)", "\n", "mask", "=", "(", "mask", "==", "0", ")", ".", "view", "(", "mask_reshape", ")", ".", "expand_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "scores", ".", "masked_fill_", "(", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "weights", "=", "F", ".", "softmax", "(", "scores", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "F", ".", "dropout", "(", "weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "outputs", "=", "(", "self", ".", "out_lin", "(", "context", ")", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.TransformerFFN.__init__": [[353, 359], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "dim_hidden", ",", "out_dim", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransformerFFN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "lin1", "=", "nn", ".", "Linear", "(", "in_dim", ",", "dim_hidden", ")", "\n", "self", ".", "lin2", "=", "nn", ".", "Linear", "(", "dim_hidden", ",", "out_dim", ")", "\n", "self", ".", "act", "=", "gelu", "if", "config", ".", "gelu_activation", "else", "F", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.TransformerFFN.forward": [[360, 366], ["modeling_xlm.TransformerFFN.lin1", "modeling_xlm.TransformerFFN.act", "modeling_xlm.TransformerFFN.lin2", "torch.nn.functional.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMPreTrainedModel.__init__": [[377, 379], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLMPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMPreTrainedModel.init_weights": [[380, 393], ["isinstance", "isinstance", "isinstance", "module.bias.data.zero_", "module.weight.data.fill_", "torch.nn.init.normal_", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights. \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "if", "self", ".", "config", "is", "not", "None", "and", "self", ".", "config", ".", "embed_init_std", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "config", ".", "embed_init_std", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "if", "self", ".", "config", "is", "not", "None", "and", "self", ".", "config", ".", "init_std", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "config", ".", "init_std", ")", "\n", "if", "hasattr", "(", "module", ",", "'bias'", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0.", ")", "\n", "", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMModel.__init__": [[487, 548], ["modeling_xlm.XLMPreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "modeling_xlm.XLMModel.apply", "NotImplementedError", "modeling_xlm.create_sinusoidal_embeddings", "torch.nn.Embedding", "modeling_xlm.XLMModel.attentions.append", "modeling_xlm.XLMModel.layer_norm1.append", "modeling_xlm.XLMModel.ffns.append", "modeling_xlm.XLMModel.layer_norm2.append", "modeling_xlm.MultiHeadAttention", "torch.nn.LayerNorm", "modeling_xlm.TransformerFFN", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.create_sinusoidal_embeddings"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "#, dico, is_encoder, with_output):", "\n", "        ", "super", "(", "XLMModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "# encoder / decoder, output layer", "\n", "self", ".", "is_encoder", "=", "config", ".", "is_encoder", "\n", "self", ".", "is_decoder", "=", "not", "config", ".", "is_encoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Currently XLM can only be used as an encoder\"", ")", "\n", "# self.with_output = with_output", "\n", "", "self", ".", "causal", "=", "config", ".", "causal", "\n", "\n", "# dictionary / languages", "\n", "self", ".", "n_langs", "=", "config", ".", "n_langs", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "eos_index", "=", "config", ".", "eos_index", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "# self.dico = dico", "\n", "# self.id2lang = config.id2lang", "\n", "# self.lang2id = config.lang2id", "\n", "# assert len(self.dico) == self.n_words", "\n", "# assert len(self.id2lang) == len(self.lang2id) == self.n_langs", "\n", "\n", "# model parameters", "\n", "self", ".", "dim", "=", "config", ".", "emb_dim", "# 512 by default", "\n", "self", ".", "hidden_dim", "=", "self", ".", "dim", "*", "4", "# 2048 by default", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "# 8 by default", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "attention_dropout", "=", "config", ".", "attention_dropout", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", ",", "'transformer dim must be a multiple of n_heads'", "\n", "\n", "# embeddings", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "self", ".", "dim", ")", "\n", "if", "config", ".", "sinusoidal_embeddings", ":", "\n", "            ", "create_sinusoidal_embeddings", "(", "config", ".", "max_position_embeddings", ",", "self", ".", "dim", ",", "out", "=", "self", ".", "position_embeddings", ".", "weight", ")", "\n", "", "if", "config", ".", "n_langs", ">", "1", ":", "\n", "            ", "self", ".", "lang_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "n_langs", ",", "self", ".", "dim", ")", "\n", "", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "n_words", ",", "self", ".", "dim", ",", "padding_idx", "=", "self", ".", "pad_index", ")", "\n", "self", ".", "layer_norm_emb", "=", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# transformer layers", "\n", "self", ".", "attentions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "ffns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15 = nn.ModuleList()", "\n", "#     self.encoder_attn = nn.ModuleList()", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "self", ".", "attentions", ".", "append", "(", "MultiHeadAttention", "(", "self", ".", "n_heads", ",", "self", ".", "dim", ",", "config", "=", "config", ")", ")", "\n", "self", ".", "layer_norm1", ".", "append", "(", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15.append(nn.LayerNorm(self.dim, eps=config.layer_norm_eps))", "\n", "#     self.encoder_attn.append(MultiHeadAttention(self.n_heads, self.dim, dropout=self.attention_dropout))", "\n", "self", ".", "ffns", ".", "append", "(", "TransformerFFN", "(", "self", ".", "dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "dim", ",", "config", "=", "config", ")", ")", "\n", "self", ".", "layer_norm2", ".", "append", "(", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ")", "\n", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMModel._resize_token_embeddings": [[549, 552], ["modeling_xlm.XLMModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "embeddings", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMModel._prune_heads": [[553, 560], ["heads_to_prune.items", "modeling_xlm.XLMModel.attentions[].prune_heads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "attentions", "[", "layer", "]", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMModel.forward": [[561, 676], ["input_ids.size", "modeling_xlm.get_masks", "modeling_xlm.XLMModel.embeddings", "modeling_xlm.XLMModel.layer_norm_emb", "torch.nn.functional.dropout", "mask.unsqueeze().to", "range", "lengths.size", "lengths.max().item", "input_ids.new().long", "torch.arange().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_xlm.XLMModel.position_embeddings().expand_as", "torch.nn.functional.dropout", "mask.unsqueeze().to", "torch.nn.functional.dropout.size", "torch.arange().unsqueeze.size", "langs.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "modeling_xlm.XLMModel.lang_embeddings", "modeling_xlm.XLMModel.embeddings", "mask.unsqueeze", "lengths.max", "input_ids.new", "torch.arange", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlm.XLMModel.position_embeddings", "mask.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlm.XLMModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.get_masks", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "lengths", "=", "None", ",", "position_ids", "=", "None", ",", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ")", ":", "# src_enc=None, src_len=None, ", "\n", "        ", "if", "lengths", "is", "None", ":", "\n", "            ", "lengths", "=", "(", "input_ids", "!=", "self", ".", "pad_index", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "# mask = input_ids != self.pad_index", "\n", "\n", "# check inputs", "\n", "", "bs", ",", "slen", "=", "input_ids", ".", "size", "(", ")", "\n", "assert", "lengths", ".", "size", "(", "0", ")", "==", "bs", "\n", "assert", "lengths", ".", "max", "(", ")", ".", "item", "(", ")", "<=", "slen", "\n", "# input_ids = input_ids.transpose(0, 1)  # batch size as dimension 0", "\n", "# assert (src_enc is None) == (src_len is None)", "\n", "# if src_enc is not None:", "\n", "#     assert self.is_decoder", "\n", "#     assert src_enc.size(0) == bs", "\n", "\n", "# generate masks", "\n", "mask", ",", "attn_mask", "=", "get_masks", "(", "slen", ",", "lengths", ",", "self", ".", "causal", ",", "padding_mask", "=", "attention_mask", ")", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     src_mask = torch.arange(src_len.max(), dtype=torch.long, device=lengths.device) < src_len[:, None]", "\n", "\n", "# position_ids", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "input_ids", ".", "new", "(", "(", "slen", ",", ")", ")", ".", "long", "(", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "slen", ",", "out", "=", "position_ids", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "assert", "position_ids", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "# (slen, bs)", "\n", "# position_ids = position_ids.transpose(0, 1)", "\n", "\n", "# langs", "\n", "", "if", "langs", "is", "not", "None", ":", "\n", "            ", "assert", "langs", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "# (slen, bs)", "\n", "# langs = langs.transpose(0, 1)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x qlen x klen]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layers", "\n", "\n", "# do not recompute cached elements", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "_slen", "=", "slen", "-", "cache", "[", "'slen'", "]", "\n", "input_ids", "=", "input_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "position_ids", "=", "position_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "if", "langs", "is", "not", "None", ":", "\n", "                ", "langs", "=", "langs", "[", ":", ",", "-", "_slen", ":", "]", "\n", "", "mask", "=", "mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "\n", "# embeddings", "\n", "", "tensor", "=", "self", ".", "embeddings", "(", "input_ids", ")", "\n", "tensor", "=", "tensor", "+", "self", ".", "position_embeddings", "(", "position_ids", ")", ".", "expand_as", "(", "tensor", ")", "\n", "if", "langs", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "lang_embeddings", "(", "langs", ")", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "embeddings", "(", "token_type_ids", ")", "\n", "", "tensor", "=", "self", ".", "layer_norm_emb", "(", "tensor", ")", "\n", "tensor", "=", "F", ".", "dropout", "(", "tensor", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "tensor", "*=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "tensor", ".", "dtype", ")", "\n", "\n", "# transformer layers", "\n", "hidden_states", "=", "(", ")", "\n", "attentions", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# self attention", "\n", "", "attn_outputs", "=", "self", ".", "attentions", "[", "i", "]", "(", "tensor", ",", "attn_mask", ",", "cache", "=", "cache", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "attn", "=", "attn_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", "=", "attentions", "+", "(", "attn_outputs", "[", "1", "]", ",", ")", "\n", "", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "tensor", "=", "tensor", "+", "attn", "\n", "tensor", "=", "self", ".", "layer_norm1", "[", "i", "]", "(", "tensor", ")", "\n", "\n", "# encoder attention (for decoder only)", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     attn = self.encoder_attn[i](tensor, src_mask, kv=src_enc, cache=cache)", "\n", "#     attn = F.dropout(attn, p=self.dropout, training=self.training)", "\n", "#     tensor = tensor + attn", "\n", "#     tensor = self.layer_norm15[i](tensor)", "\n", "\n", "# FFN", "\n", "tensor", "=", "tensor", "+", "self", ".", "ffns", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "layer_norm2", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "*=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "tensor", ".", "dtype", ")", "\n", "\n", "# Add last hidden state", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# update cache length", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "cache", "[", "'slen'", "]", "+=", "tensor", ".", "size", "(", "1", ")", "\n", "\n", "# move back sequence length to dimension 0", "\n", "# tensor = tensor.transpose(0, 1)", "\n", "\n", "", "outputs", "=", "(", "tensor", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMPredLayer.__init__": [[682, 698], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.AdaptiveLogSoftmaxWithLoss"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMPredLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "asm", "=", "config", ".", "asm", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "dim", "=", "config", ".", "emb_dim", "\n", "\n", "if", "config", ".", "asm", "is", "False", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "config", ".", "n_words", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "AdaptiveLogSoftmaxWithLoss", "(", "\n", "in_features", "=", "dim", ",", "\n", "n_classes", "=", "config", ".", "n_words", ",", "\n", "cutoffs", "=", "config", ".", "asm_cutoffs", ",", "\n", "div_value", "=", "config", ".", "asm_div_value", ",", "\n", "head_bias", "=", "True", ",", "# default is False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMPredLayer.forward": [[700, 718], ["modeling_xlm.XLMPredLayer.proj().view", "modeling_xlm.XLMPredLayer.proj.log_prob", "torch.nn.functional.cross_entropy", "modeling_xlm.XLMPredLayer.proj", "modeling_xlm.XLMPredLayer.proj"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "        ", "\"\"\" Compute the loss, and optionally the scores.\n        \"\"\"", "\n", "outputs", "=", "(", ")", "\n", "if", "self", ".", "asm", "is", "False", ":", "\n", "            ", "scores", "=", "self", ".", "proj", "(", "x", ")", ".", "view", "(", "-", "1", ",", "self", ".", "n_words", ")", "\n", "outputs", "=", "(", "scores", ",", ")", "+", "outputs", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "y", ",", "reduction", "=", "'elementwise_mean'", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "", "else", ":", "\n", "            ", "scores", "=", "self", ".", "proj", ".", "log_prob", "(", "x", ")", "\n", "outputs", "=", "(", "scores", ",", ")", "+", "outputs", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "_", ",", "loss", "=", "self", ".", "proj", "(", "x", ",", "y", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMWithLMHeadModel.__init__": [[754, 761], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_xlm.XLMPredLayer", "modeling_xlm.XLMWithLMHeadModel.apply", "modeling_xlm.XLMWithLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMWithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "pred_layer", "=", "XLMPredLayer", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMWithLMHeadModel.tie_weights": [[762, 766], ["modeling_xlm.XLMWithLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "pred_layer", ".", "proj", ",", "self", ".", "transformer", ".", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMWithLMHeadModel.forward": [[767, 778], ["modeling_xlm.XLMWithLMHeadModel.transformer", "modeling_xlm.XLMWithLMHeadModel.pred_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "lengths", "=", "None", ",", "position_ids", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "cache", "=", "None", ",", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "lengths", "=", "lengths", ",", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "langs", "=", "langs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "cache", "=", "cache", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "outputs", "=", "self", ".", "pred_layer", "(", "output", ",", "labels", ")", "\n", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMForSequenceClassification.__init__": [[814, 822], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_utils.SequenceSummary", "modeling_xlm.XLMForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMForSequenceClassification.forward": [[823, 845], ["modeling_xlm.XLMForSequenceClassification.transformer", "modeling_xlm.XLMForSequenceClassification.sequence_summary", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlm.XLMForSequenceClassification.view", "labels.view", "modeling_xlm.XLMForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "lengths", "=", "None", ",", "position_ids", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "cache", "=", "None", ",", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "lengths", "=", "lengths", ",", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "langs", "=", "langs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "cache", "=", "cache", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMForQuestionAnswering.__init__": [[893, 900], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_utils.SQuADHead", "modeling_xlm.XLMForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "SQuADHead", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.XLMForQuestionAnswering.forward": [[901, 916], ["modeling_xlm.XLMForQuestionAnswering.transformer", "modeling_xlm.XLMForQuestionAnswering.qa_outputs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "lengths", "=", "None", ",", "position_ids", "=", "None", ",", "langs", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "cache", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "lengths", "=", "lengths", ",", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "langs", "=", "langs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "cache", "=", "cache", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "outputs", "=", "self", ".", "qa_outputs", "(", "output", ",", "start_positions", "=", "start_positions", ",", "end_positions", "=", "end_positions", ",", "\n", "cls_index", "=", "cls_index", ",", "is_impossible", "=", "is_impossible", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.create_sinusoidal_embeddings": [[204, 213], ["numpy.array", "torch.FloatTensor", "torch.FloatTensor", "out.detach_", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["", "", "def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "\n", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "\n", "for", "pos", "in", "range", "(", "n_pos", ")", "\n", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "out", ".", "detach_", "(", ")", "\n", "out", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.gelu": [[215, 224], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    GELU activation\n    https://arxiv.org/abs/1606.08415\n    https://github.com/huggingface/pytorch-openai-transformer-lm/blob/master/model_pytorch.py#L14\n    https://github.com/huggingface/pytorch-transformers/blob/master/modeling.py\n    \"\"\"", "\n", "# return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))", "\n", "return", "0.5", "*", "x", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_xlm.get_masks": [[226, 249], ["lengths.size", "torch.arange", "mask.size", "lengths.max().item", "alen[].repeat", "attn_mask.size", "lengths.max"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "get_masks", "(", "slen", ",", "lengths", ",", "causal", ",", "padding_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Generate hidden states mask, and optionally an attention mask.\n    \"\"\"", "\n", "bs", "=", "lengths", ".", "size", "(", "0", ")", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "padding_mask", "\n", "", "else", ":", "\n", "        ", "assert", "lengths", ".", "max", "(", ")", ".", "item", "(", ")", "<=", "slen", "\n", "alen", "=", "torch", ".", "arange", "(", "slen", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "lengths", ".", "device", ")", "\n", "mask", "=", "alen", "<", "lengths", "[", ":", ",", "None", "]", "\n", "\n", "# attention mask is the same as mask, or triangular inferior attention (causal)", "\n", "", "if", "causal", ":", "\n", "        ", "attn_mask", "=", "alen", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "bs", ",", "slen", ",", "1", ")", "<=", "alen", "[", "None", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "        ", "attn_mask", "=", "mask", "\n", "\n", "# sanity check", "\n", "", "assert", "mask", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "\n", "assert", "causal", "is", "False", "or", "attn_mask", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ",", "slen", ")", "\n", "\n", "return", "mask", ",", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_gpt2_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch": [[33, 52], ["pytorch_transformers.modeling_gpt2.GPT2Model", "pytorch_transformers.modeling_gpt2.load_tf_weights_in_gpt2", "print", "torch.save", "print", "pytorch_transformers.modeling_gpt2.GPT2Config", "pytorch_transformers.modeling_gpt2.GPT2Config", "pytorch_transformers.modeling_gpt2.GPT2Model.state_dict", "io.open", "f.write", "pytorch_transformers.modeling_gpt2.GPT2Config.to_json_string"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_gpt2.load_tf_weights_in_gpt2", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["def", "convert_gpt2_checkpoint_to_pytorch", "(", "gpt2_checkpoint_path", ",", "gpt2_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "gpt2_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "GPT2Config", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "GPT2Config", "(", "gpt2_config_file", ")", "\n", "", "model", "=", "GPT2Model", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_transfo_xl_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch": [[48, 91], ["print", "torch.save", "corpus_dict_no_vocab.pop", "print", "torch.save", "os.path.abspath", "os.path.abspath", "print", "print", "pytorch_transformers.modeling_transfo_xl.TransfoXLLMHeadModel", "pytorch_transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "os.path.join", "os.path.join", "print", "torch.save", "print", "io.open", "pickle.load", "pytorch_transformers.modeling_transfo_xl.TransfoXLConfig", "pytorch_transformers.modeling_transfo_xl.TransfoXLConfig", "pytorch_transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl.state_dict", "io.open", "f.write", "str", "os.path.abspath", "os.path.abspath", "pytorch_transformers.modeling_transfo_xl.TransfoXLConfig.to_json_string"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["def", "convert_transfo_xl_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "\n", "transfo_xl_config_file", ",", "\n", "pytorch_dump_folder_path", ",", "\n", "transfo_xl_dataset_file", ")", ":", "\n", "    ", "if", "transfo_xl_dataset_file", ":", "\n", "# Convert a pre-processed corpus (see original TensorFlow repo)", "\n", "        ", "with", "open", "(", "transfo_xl_dataset_file", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ",", "encoding", "=", "\"latin1\"", ")", "\n", "# Save vocabulary and dataset cache as Dictionaries (should be better than pickles for the long-term)", "\n", "", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_FILES_NAMES", "[", "'pretrained_vocab_file'", "]", "\n", "print", "(", "\"Save vocabulary to {}\"", ".", "format", "(", "pytorch_vocab_dump_path", ")", ")", "\n", "corpus_vocab_dict", "=", "corpus", ".", "vocab", ".", "__dict__", "\n", "torch", ".", "save", "(", "corpus_vocab_dict", ",", "pytorch_vocab_dump_path", ")", "\n", "\n", "corpus_dict_no_vocab", "=", "corpus", ".", "__dict__", "\n", "corpus_dict_no_vocab", ".", "pop", "(", "'vocab'", ",", "None", ")", "\n", "pytorch_dataset_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CORPUS_NAME", "\n", "print", "(", "\"Save dataset to {}\"", ".", "format", "(", "pytorch_dataset_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "corpus_dict_no_vocab", ",", "pytorch_dataset_dump_path", ")", "\n", "\n", "", "if", "tf_checkpoint_path", ":", "\n", "# Convert a pre-trained TensorFlow model", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "abspath", "(", "transfo_xl_config_file", ")", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "\n", "print", "(", "\"Converting Transformer XL checkpoint from {} with config at {}\"", ".", "format", "(", "tf_path", ",", "config_path", ")", ")", "\n", "# Initialise PyTorch model", "\n", "if", "transfo_xl_config_file", "==", "\"\"", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", "transfo_xl_config_file", ")", "\n", "", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "TransfoXLLMHeadModel", "(", "config", ")", "\n", "\n", "model", "=", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.__init__": [[74, 92], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_roberta.RobertaTokenizer.encoder.items", "tokenization_roberta.RobertaTokenizer.byte_encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_gpt2.bytes_to_unicode"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "bos_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "sep_token", "=", "\"</s>\"", ",", "\n", "cls_token", "=", "\"<s>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "pad_token", "=", "'<pad>'", ",", "mask_token", "=", "'<mask>'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "cls_token", "=", "cls_token", ",", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "bpe_data", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_data", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.vocab_size": [[93, 96], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.bpe": [[97, 137], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_roberta.RobertaTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer._tokenize": [[138, 148], ["regex.findall", "bpe_tokens.extend", "tokenization_roberta.RobertaTokenizer.bpe().split", "token.encode", "ord", "tokenization_roberta.RobertaTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "ord", "(", "b", ")", "]", "for", "b", "in", "token", ")", "\n", "", "else", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer._convert_token_to_id": [[149, 152], ["tokenization_roberta.RobertaTokenizer.encoder.get", "tokenization_roberta.RobertaTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer._convert_id_to_token": [[153, 156], ["tokenization_roberta.RobertaTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.convert_tokens_to_string": [[157, 162], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "text", "=", "''", ".", "join", "(", "tokens", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence": [[163, 169], ["tokenization_roberta.RobertaTokenizer._convert_token_to_id", "tokenization_roberta.RobertaTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence for sequence classification tasks.\n        A RoBERTa sequence has the following format: [CLS] X [SEP]\n        \"\"\"", "\n", "return", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "+", "token_ids", "+", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair": [[170, 178], ["tokenization_roberta.RobertaTokenizer._convert_token_to_id", "tokenization_roberta.RobertaTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence pair for sequence classification tasks.\n        A RoBERTa sequence pair has the following format: [CLS] A [SEP][SEP] B [SEP]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "cls", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.save_vocabulary": [[179, 202], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_roberta.RobertaTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTConfig.__init__": [[157, 215], ["modeling_utils.PretrainedConfig.__init__", "isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "40478", ",", "\n", "n_positions", "=", "512", ",", "\n", "n_ctx", "=", "512", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "afn", "=", "\"gelu\"", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "predict_special_tokens", "=", "True", ",", "\n", "\n", "num_labels", "=", "1", ",", "\n", "summary_type", "=", "'cls_index'", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs OpenAIGPTConfig.\n        \"\"\"", "\n", "super", "(", "OpenAIGPTConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "afn", "=", "afn", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "predict_special_tokens", "=", "predict_special_tokens", "\n", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTConfig.max_position_embeddings": [[218, 221], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTConfig.hidden_size": [[222, 225], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTConfig.num_attention_heads": [[226, 229], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTConfig.num_hidden_layers": [[230, 233], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.__init__": [[236, 252], ["torch.Module.__init__", "modeling_openai.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.prune_heads": [[253, 268], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "len", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention._attn": [[269, 289], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_openai.Attention.attn_dropout", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size", "modeling_openai.Attention.size", "modeling_openai.Attention.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "# w = w * self.bias + -1e9 * (1 - self.bias)  # TF implem method: mask_attn_weights", "\n", "# XD: self.b may be larger than w, so we need to crop it", "\n", "", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", ":", "w", ".", "size", "(", "-", "2", ")", ",", ":", "w", ".", "size", "(", "-", "1", ")", "]", "\n", "w", "=", "w", "*", "b", "+", "-", "1e9", "*", "(", "1", "-", "b", ")", "\n", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.merge_heads": [[290, 294], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads": [[295, 302], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.forward": [[303, 319], ["modeling_openai.Attention.c_attn", "modeling_openai.Attention.split", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention._attn", "modeling_openai.Attention.merge_heads", "modeling_openai.Attention.c_proj", "modeling_openai.Attention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.MLP.__init__": [[322, 329], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT_FNS", "[", "config", ".", "afn", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.MLP.forward": [[330, 334], ["modeling_openai.MLP.act", "modeling_openai.MLP.c_proj", "modeling_openai.MLP.dropout", "modeling_openai.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Block.__init__": [[337, 344], ["torch.Module.__init__", "modeling_openai.Attention", "modeling_bert.BertLayerNorm", "modeling_openai.MLP", "modeling_bert.BertLayerNorm"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Block.forward": [[345, 355], ["modeling_openai.Block.attn", "modeling_openai.Block.ln_1", "modeling_openai.Block.mlp", "modeling_openai.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attn_outputs", "=", "self", ".", "attn", "(", "x", ",", "head_mask", "=", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "\n", "outputs", "=", "[", "h", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTPreTrainedModel.__init__": [[366, 368], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTPreTrainedModel.init_weights": [[369, 381], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTModel.__init__": [[449, 460], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "modeling_openai.OpenAIGPTModel.apply", "modeling_openai.Block", "range"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "positions_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTModel._resize_token_embeddings": [[461, 464], ["modeling_openai.OpenAIGPTModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "self", ".", "tokens_embed", "=", "self", ".", "_get_resized_embeddings", "(", "self", ".", "tokens_embed", ",", "new_num_tokens", ")", "\n", "return", "self", ".", "tokens_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTModel._prune_heads": [[465, 471], ["heads_to_prune.items", "modeling_openai.OpenAIGPTModel.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTModel.forward": [[472, 532], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "modeling_openai.OpenAIGPTModel.positions_embed", "modeling_openai.OpenAIGPTModel.drop", "enumerate", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "block", "modeling_openai.OpenAIGPTModel.view", "input_ids.view.view.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "token_type_ids.view.view.size", "modeling_openai.OpenAIGPTModel.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_openai.OpenAIGPTModel.view", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_openai.OpenAIGPTModel.view", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_openai.OpenAIGPTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "# This was used when we had a single embedding matrice from position and token embeddings", "\n", "# start = self.config.vocab_size + self.config.n_special", "\n", "# end = start + input_ids.size(-1)", "\n", "# position_ids = torch.arange(start, end, dtype=torch.long, device=input_ids.device)", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "input_ids", ".", "size", "(", "-", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "all_attentions", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "h", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "hidden_states", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", "=", "outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTLMHeadModel.__init__": [[567, 574], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "torch.Linear", "torch.Linear", "modeling_openai.OpenAIGPTLMHeadModel.apply", "modeling_openai.OpenAIGPTLMHeadModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTLMHeadModel.tie_weights": [[575, 581], ["modeling_openai.OpenAIGPTLMHeadModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "tokens_embed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTLMHeadModel.forward": [[582, 600], ["modeling_openai.OpenAIGPTLMHeadModel.transformer", "modeling_openai.OpenAIGPTLMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "labels", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.__init__": [[676, 685], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_openai.OpenAIGPTDoubleHeadsModel.apply", "modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.tie_weights": [[686, 692], ["modeling_openai.OpenAIGPTDoubleHeadsModel._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ",", "\n", "self", ".", "transformer", ".", "tokens_embed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.forward": [[693, 717], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mc_token_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.load_tf_weights_in_openai_gpt": [[44, 117], ["logger.info", "json.load", "json.load", "np.cumsum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "json.load.pop", "init_params.pop", "init_params.pop", "zip", "os.path.dirname", "io.open", "io.open", "np.load", "np.split", "param.reshape", "arr.squeeze", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "np.prod", "range", "np.concatenate", "zip", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_openai_gpt", "(", "model", ",", "config", ",", "openai_checkpoint_folder_path", ")", ":", "\n", "    ", "\"\"\" Load tf pre-trained weights in a pytorch model (from NumPy arrays here)\n    \"\"\"", "\n", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "\n", "if", "'.ckpt'", "in", "openai_checkpoint_folder_path", ":", "\n", "        ", "openai_checkpoint_folder_path", "=", "os", ".", "path", ".", "dirname", "(", "openai_checkpoint_folder_path", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Loading weights from {}\"", ".", "format", "(", "openai_checkpoint_folder_path", ")", ")", "\n", "\n", "names", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/parameters_names.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "shapes", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/params_shapes.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "offsets", "=", "np", ".", "cumsum", "(", "[", "np", ".", "prod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "init_params", "=", "[", "np", ".", "load", "(", "openai_checkpoint_folder_path", "+", "'/params_{}.npy'", ".", "format", "(", "n", ")", ")", "for", "n", "in", "range", "(", "10", ")", "]", "\n", "init_params", "=", "np", ".", "split", "(", "np", ".", "concatenate", "(", "init_params", ",", "0", ")", ",", "offsets", ")", "[", ":", "-", "1", "]", "\n", "init_params", "=", "[", "param", ".", "reshape", "(", "shape", ")", "for", "param", ",", "shape", "in", "zip", "(", "init_params", ",", "shapes", ")", "]", "\n", "\n", "# This was used when we had a single embedding matrix for positions and tokens", "\n", "# init_params[0] = np.concatenate([init_params[1], init_params[0]], 0)", "\n", "# del init_params[1]", "\n", "init_params", "=", "[", "arr", ".", "squeeze", "(", ")", "for", "arr", "in", "init_params", "]", "\n", "\n", "try", ":", "\n", "        ", "assert", "model", ".", "tokens_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "1", "]", ".", "shape", "\n", "assert", "model", ".", "positions_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "0", "]", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "e", ".", "args", "+=", "(", "model", ".", "tokens_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "1", "]", ".", "shape", ")", "\n", "e", ".", "args", "+=", "(", "model", ".", "positions_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "0", "]", ".", "shape", ")", "\n", "raise", "\n", "\n", "", "model", ".", "tokens_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "1", "]", ")", "\n", "model", ".", "positions_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "0", "]", ")", "\n", "names", ".", "pop", "(", "0", ")", "\n", "# Pop position and token embedding arrays", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "\n", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "init_params", ")", ":", "# names[1:n_transfer], init_params[1:n_transfer]):", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "assert", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "name", "[", ":", "-", "2", "]", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'w'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.gelu": [[119, 121], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_openai.swish": [[123, 125], ["torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_auto.AutoTokenizer.__init__": [[52, 54], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"AutoTokenizer is designed to be instantiated \"", "\n", "\"using the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method.\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_auto.AutoTokenizer.from_pretrained": [[56, 106], ["ValueError", "tokenization_roberta.RobertaTokenizer.from_pretrained", "tokenization_bert.BertTokenizer.from_pretrained", "tokenization_openai.OpenAIGPTTokenizer.from_pretrained", "tokenization_gpt2.GPT2Tokenizer.from_pretrained", "tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained", "tokenization_xlnet.XLNetTokenizer.from_pretrained", "tokenization_xlm.XLMTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the tokenizer classes of the library\n        from a pre-trained model vocabulary.\n\n        The tokenizer class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `bert`: BertTokenizer (Bert model)\n            - contains `openai-gpt`: OpenAIGPTTokenizer (OpenAI GPT model)\n            - contains `gpt2`: GPT2Tokenizer (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLTokenizer (Transformer-XL model)\n            - contains `xlnet`: XLNetTokenizer (XLNet model)\n            - contains `xlm`: XLMTokenizer (XLM model)\n            - contains `roberta`: RobertaTokenizer (XLM model)\n\n        Params:\n            **pretrained_model_name_or_path**: either:\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache\n                    or download and cache if not already stored in cache (e.g. 'bert-base-uncased').\n                - a path to a `directory` containing a configuration file saved\n                    using the `save_pretrained(save_directory)` method.\n                - a path or url to a saved configuration `file`.\n            **cache_dir**: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n        Examples::\n\n            config = AutoTokenizer.from_pretrained('bert-base-uncased')    # Download vocabulary from S3 and cache.\n            config = AutoTokenizer.from_pretrained('./test/bert_saved_model/')  # E.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`\n\n        \"\"\"", "\n", "if", "'roberta'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'bert'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'openai-gpt'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'gpt2'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Tokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'transfo-xl'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlnet'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "'xlm'", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.convert_xlm_checkpoint_to_pytorch.convert_xlm_checkpoint_to_pytorch": [[32, 59], ["torch.load", "dict", "dict", "print", "torch.save", "print", "print", "io.open", "f.write", "io.open", "f.write", "dict.items", "dict.items", "json.dumps", "json.dumps", "isinstance", "s.replace", "s.find"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["def", "convert_xlm_checkpoint_to_pytorch", "(", "xlm_checkpoint_path", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Load checkpoint", "\n", "    ", "chkpt", "=", "torch", ".", "load", "(", "xlm_checkpoint_path", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "model", "=", "chkpt", "[", "'model'", "]", "\n", "\n", "config", "=", "chkpt", "[", "'params'", "]", "\n", "config", "=", "dict", "(", "(", "n", ",", "v", ")", "for", "n", ",", "v", "in", "config", ".", "items", "(", ")", "if", "not", "isinstance", "(", "v", ",", "(", "torch", ".", "FloatTensor", ",", "numpy", ".", "ndarray", ")", ")", ")", "\n", "\n", "vocab", "=", "chkpt", "[", "'dico_word2id'", "]", "\n", "vocab", "=", "dict", "(", "(", "s", "+", "'</w>'", "if", "s", ".", "find", "(", "'@@'", ")", "==", "-", "1", "and", "i", ">", "13", "else", "s", ".", "replace", "(", "'@@'", ",", "''", ")", ",", "i", ")", "for", "s", ",", "i", "in", "vocab", ".", "items", "(", ")", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", "\n", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ",", "pytorch_weights_dump_path", ")", "\n", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "config", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "print", "(", "\"Save vocab file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_vocab_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vocab", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.__init__": [[87, 106], ["tokenization_utils.PreTrainedTokenizer.__init__", "json.load", "dict", "spacy.load", "io.open", "io.open().read().split", "tuple", "zip", "logger.warning", "tokenization_bert.BasicTokenizer", "tokenization_openai.OpenAIGPTTokenizer.encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "\n", "try", ":", "\n", "            ", "import", "ftfy", "\n", "import", "spacy", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en'", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", ",", "'ner'", ",", "'textcat'", "]", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.vocab_size": [[107, 110], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe": [[111, 153], ["tokenization_openai.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_openai.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.index"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._tokenize": [[154, 168], ["tokenization_openai.OpenAIGPTTokenizer.nlp.tokenize", "tokenization_openai.OpenAIGPTTokenizer.nlp", "split_tokens.extend", "tokenization_openai.text_standardize", "split_tokens.extend", "tokenization_openai.OpenAIGPTTokenizer.fix_text", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe", "tokenization_openai.OpenAIGPTTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.text_standardize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer", "\n", "            ", "text", "=", "self", ".", "nlp", ".", "tokenize", "(", "text", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "else", ":", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "            ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id": [[169, 172], ["tokenization_openai.OpenAIGPTTokenizer.encoder.get", "tokenization_openai.OpenAIGPTTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token": [[173, 176], ["tokenization_openai.OpenAIGPTTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string": [[177, 181], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.save_vocabulary": [[182, 205], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.get_pairs": [[50, 61], ["set", "set.add"], "function", ["None"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_openai.text_standardize": [[62, 76], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_gpt2_test.GPT2ModelTest.test_config": [[30, 33], ["modeling_common_test.ConfigTester", "modeling_common_test.ConfigTester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["    ", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "n_embd", "=", "37", ")", "\n", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_gpt2_test.GPT2ModelTest.test_model": [[34, 39], ["modeling_common_test.CommonTestCases.GPTModelTester", "modeling_common_test.CommonTestCases.GPTModelTester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_model", "(", "self", ")", ":", "\n", "        ", "model_tester", "=", "CommonTestCases", ".", "GPTModelTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "base_model_class", "=", "GPT2Model", ",", "\n", "lm_head_model_class", "=", "GPT2LMHeadModel", ",", "\n", "double_head_model_class", "=", "GPT2DoubleHeadsModel", ")", "\n", "model_tester", ".", "run_common_tests", "(", "test_presents", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_gpt2_test.GPT2ModelTest.test_pretrained": [[40, 46], ["modeling_common_test.CommonTestCases.GPTModelTester", "modeling_common_test.CommonTestCases.GPTModelTester.run_slow_tests"], "methods", ["None"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_pretrained", "(", "self", ")", ":", "\n", "        ", "model_tester", "=", "CommonTestCases", ".", "GPTModelTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "base_model_class", "=", "GPT2Model", ",", "\n", "lm_head_model_class", "=", "GPT2LMHeadModel", ",", "\n", "double_head_model_class", "=", "GPT2DoubleHeadsModel", ")", "\n", "model_tester", ".", "run_slow_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_openai_test.OpenAIModelTest.test_config": [[30, 33], ["modeling_common_test.ConfigTester", "modeling_common_test.ConfigTester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["    ", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "n_embd", "=", "37", ")", "\n", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_openai_test.OpenAIModelTest.test_model": [[34, 39], ["modeling_common_test.CommonTestCases.GPTModelTester", "modeling_common_test.CommonTestCases.GPTModelTester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_model", "(", "self", ")", ":", "\n", "        ", "model_tester", "=", "CommonTestCases", ".", "GPTModelTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "base_model_class", "=", "OpenAIGPTModel", ",", "\n", "lm_head_model_class", "=", "OpenAIGPTLMHeadModel", ",", "\n", "double_head_model_class", "=", "OpenAIGPTDoubleHeadsModel", ")", "\n", "model_tester", ".", "run_common_tests", "(", "test_presents", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_openai_test.OpenAIModelTest.test_pretrained": [[40, 46], ["modeling_common_test.CommonTestCases.GPTModelTester", "modeling_common_test.CommonTestCases.GPTModelTester.run_slow_tests"], "methods", ["None"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_pretrained", "(", "self", ")", ":", "\n", "        ", "model_tester", "=", "CommonTestCases", ".", "GPTModelTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "base_model_class", "=", "OpenAIGPTModel", ",", "\n", "lm_head_model_class", "=", "OpenAIGPTLMHeadModel", ",", "\n", "double_head_model_class", "=", "OpenAIGPTDoubleHeadsModel", ")", "\n", "model_tester", ".", "run_slow_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.__init__": [[510, 514], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parent", ",", "config_class", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "parent", "=", "parent", "\n", "self", ".", "config_class", "=", "config_class", "\n", "self", ".", "inputs_dict", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.create_and_test_config_common_properties": [[515, 521], ["modeling_common_test.ConfigTester.config_class", "modeling_common_test.ConfigTester.parent.assertTrue", "modeling_common_test.ConfigTester.parent.assertTrue", "modeling_common_test.ConfigTester.parent.assertTrue", "modeling_common_test.ConfigTester.parent.assertTrue", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "create_and_test_config_common_properties", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'vocab_size'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'hidden_size'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'num_attention_heads'", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "'num_hidden_layers'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.create_and_test_config_to_json_string": [[522, 527], ["modeling_common_test.ConfigTester.config_class", "json.loads", "modeling_common_test.ConfigTester.inputs_dict.items", "modeling_common_test.ConfigTester.to_json_string", "modeling_common_test.ConfigTester.parent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "create_and_test_config_to_json_string", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "obj", "=", "json", ".", "loads", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inputs_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "parent", ".", "assertEqual", "(", "obj", "[", "key", "]", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.create_and_test_config_to_json_file": [[528, 535], ["modeling_common_test.ConfigTester.config_class", "modeling_common_test.ConfigTester.to_json_file", "modeling_common_test.ConfigTester.config_class.from_json_file", "os.remove", "modeling_common_test.ConfigTester.parent.assertEqual", "modeling_common_test.ConfigTester.to_dict", "modeling_common_test.ConfigTester.to_dict"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_dict", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_dict"], ["", "", "def", "create_and_test_config_to_json_file", "(", "self", ")", ":", "\n", "        ", "config_first", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "json_file_path", "=", "\"/tmp/config.json\"", "\n", "config_first", ".", "to_json_file", "(", "json_file_path", ")", "\n", "config_second", "=", "self", ".", "config_class", ".", "from_json_file", "(", "json_file_path", ")", "\n", "os", ".", "remove", "(", "json_file_path", ")", "\n", "self", ".", "parent", ".", "assertEqual", "(", "config_second", ".", "to_dict", "(", ")", ",", "config_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests": [[536, 540], ["modeling_common_test.ConfigTester.create_and_test_config_common_properties", "modeling_common_test.ConfigTester.create_and_test_config_to_json_string", "modeling_common_test.ConfigTester.create_and_test_config_to_json_file"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.create_and_test_config_common_properties", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.create_and_test_config_to_json_string", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.create_and_test_config_to_json_file"], ["", "def", "run_common_tests", "(", "self", ")", ":", "\n", "        ", "self", ".", "create_and_test_config_common_properties", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_string", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_file", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ModelUtilsTest.test_model_from_pretrained": [[561, 580], ["logging.basicConfig", "list", "pytorch_transformers.modeling_bert.BertConfig.from_pretrained", "modeling_common_test.ModelUtilsTest.assertIsNotNone", "modeling_common_test.ModelUtilsTest.assertIsInstance", "pytorch_transformers.modeling_bert.BertModel.from_pretrained", "pytorch_transformers.modeling_bert.BertModel.from_pretrained", "modeling_common_test.ModelUtilsTest.assertIsNotNone", "modeling_common_test.ModelUtilsTest.assertIsInstance", "loading_info.values", "pytorch_transformers.modeling_bert.BertConfig.from_pretrained", "pytorch_transformers.modeling_bert.BertModel.from_pretrained", "modeling_common_test.ModelUtilsTest.assertEqual", "modeling_common_test.ModelUtilsTest.assertEqual", "modeling_common_test.ModelUtilsTest.assertEqual", "pytorch_transformers.modeling_bert.BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "modeling_common_test.ModelUtilsTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["    ", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "PretrainedConfig", ")", "\n", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "PreTrainedModel", ")", "\n", "for", "value", "in", "loading_info", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "len", "(", "value", ")", ",", "0", ")", "\n", "\n", "", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_name", ",", "output_attentions", "=", "True", ",", "output_hidden_states", "=", "True", ")", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "output_attentions", "=", "True", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test._config_zero_init": [[35, 41], ["copy.deepcopy", "copy.deepcopy.__dict__.keys", "setattr"], "function", ["None"], ["def", "_config_zero_init", "(", "config", ")", ":", "\n", "    ", "configs_no_init", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "for", "key", "in", "configs_no_init", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "        ", "if", "'_range'", "in", "key", "or", "'_std'", "in", "key", ":", "\n", "            ", "setattr", "(", "configs_no_init", ",", "key", ",", "0.0", ")", "\n", "", "", "return", "configs_no_init", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ids_tensor": [[544, 558], ["range", "torch.tensor().view().contiguous", "random.Random", "values.append", "random.Random.randint", "torch.tensor().view", "torch.tensor"], "function", ["None"], ["", "", "def", "ids_tensor", "(", "shape", ",", "vocab_size", ",", "rng", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a random int32 tensor of the shape within the vocab size.\"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "random", ".", "Random", "(", ")", "\n", "\n", "", "total_dims", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "        ", "total_dims", "*=", "dim", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "total_dims", ")", ":", "\n", "        ", "values", ".", "append", "(", "rng", ".", "randint", "(", "0", ",", "vocab_size", "-", "1", ")", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "data", "=", "values", ",", "dtype", "=", "torch", ".", "long", ")", ".", "view", "(", "shape", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlm_test.XLMModelTest.setUp": [[257, 260], ["XLMModelTest.XLMModelTester", "modeling_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XLMModelTest", ".", "XLMModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLMConfig", ",", "emb_dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlm_test.XLMModelTest.test_config": [[261, 263], ["modeling_xlm_test.XLMModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlm_test.XLMModelTest.test_xlm_model": [[264, 267], ["modeling_xlm_test.XLMModelTest.model_tester.prepare_config_and_inputs", "modeling_xlm_test.XLMModelTest.model_tester.create_and_check_xlm_model"], "methods", ["None"], ["", "def", "test_xlm_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlm_test.XLMModelTest.test_model_from_pretrained": [[283, 290], ["list", "pytorch_transformers.XLMModel.from_pretrained", "shutil.rmtree", "modeling_xlm_test.XLMModelTest.assertIsNotNone", "pytorch_transformers.modeling_xlm.XLM_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/pytorch_transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "XLM_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLMModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.setUp": [[264, 267], ["BertModelTest.BertModelTester", "modeling_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "BertModelTest", ".", "BertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "BertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_config": [[268, 270], ["modeling_bert_test.BertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_bert_model": [[271, 274], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_model"], "methods", ["None"], ["", "def", "test_bert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_masked_lm": [[275, 278], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_multiple_choice": [[279, 282], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_multiple_choice"], "methods", ["None"], ["", "def", "test_for_multiple_choice", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_multiple_choice", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_next_sequence_prediction": [[283, 286], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_next_sequence_prediction"], "methods", ["None"], ["", "def", "test_for_next_sequence_prediction", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_next_sequence_prediction", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_pretraining": [[287, 290], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_pretraining"], "methods", ["None"], ["", "def", "test_for_pretraining", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_pretraining", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_question_answering": [[291, 294], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_sequence_classification": [[295, 298], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_for_token_classification": [[299, 302], ["modeling_bert_test.BertModelTest.model_tester.prepare_config_and_inputs", "modeling_bert_test.BertModelTest.model_tester.create_and_check_bert_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_bert_test.BertModelTest.test_model_from_pretrained": [[303, 310], ["list", "pytorch_transformers.BertModel.from_pretrained", "shutil.rmtree", "modeling_bert_test.BertModelTest.assertIsNotNone", "pytorch_transformers.modeling_bert.BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/pytorch_transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.setUp": [[31, 37], ["super().setUp", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.modeling_utils.PreTrainedModel.save_pretrained"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# We have a SentencePiece fixture for testing", "\n", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.get_tokenizer": [[38, 40], ["pytorch_transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "XLNetTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.get_input_output_texts": [[41, 45], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"This is a test\"", "\n", "output_text", "=", "u\"This is a test\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_full_tokenizer": [[47, 74], ["pytorch_transformers.tokenization_xlnet.XLNetTokenizer", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_ids", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.convert_ids_to_tokens", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u'This is a test'", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "u'\u2581This'", ",", "u'\u2581is'", ",", "u'\u2581a'", ",", "u'\u2581t'", ",", "u'est'", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "285", ",", "46", ",", "10", ",", "170", ",", "382", "]", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u'I'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "\n", "u'or'", ",", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "SPIECE_UNDERLINE", "+", "u''", ",", "\n", "u'9'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u's'", ",", "u'\u00e9'", ",", "u'.'", "]", ")", "\n", "ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "ids", ",", "[", "8", ",", "21", ",", "84", ",", "55", ",", "24", ",", "19", ",", "7", ",", "0", ",", "\n", "602", ",", "347", ",", "347", ",", "347", ",", "3", ",", "12", ",", "66", ",", "\n", "46", ",", "72", ",", "80", ",", "6", ",", "0", ",", "4", "]", ")", "\n", "\n", "back_tokens", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "\n", "self", ".", "assertListEqual", "(", "back_tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u'I'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "\n", "u'or'", ",", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "\n", "SPIECE_UNDERLINE", "+", "u''", ",", "u'<unk>'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "\n", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u's'", ",", "\n", "u'<unk>'", ",", "u'.'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_tokenizer_lower": [[75, 83], ["pytorch_transformers.tokenization_xlnet.XLNetTokenizer", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "do_lower_case", "=", "True", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u''", ",", "u'i'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "\n", "u'or'", ",", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "SPIECE_UNDERLINE", "+", "u''", ",", "\n", "u'9'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u'se'", ",", "u'.'", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "u\"H\\u00E9llo\"", ")", ",", "[", "u\"\u2581he\"", ",", "u\"ll\"", ",", "u\"o\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_tokenizer_no_lower": [[84, 91], ["pytorch_transformers.tokenization_xlnet.XLNetTokenizer", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "tokenization_xlnet_test.XLNetTokenizationTest.assertListEqual"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "do_lower_case", "=", "False", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "SPIECE_UNDERLINE", "+", "u'I'", ",", "SPIECE_UNDERLINE", "+", "u'was'", ",", "SPIECE_UNDERLINE", "+", "u'b'", ",", "u'or'", ",", "\n", "u'n'", ",", "SPIECE_UNDERLINE", "+", "u'in'", ",", "SPIECE_UNDERLINE", "+", "u''", ",", "\n", "u'9'", ",", "u'2'", ",", "u'0'", ",", "u'0'", ",", "u'0'", ",", "u','", ",", "SPIECE_UNDERLINE", "+", "u'and'", ",", "SPIECE_UNDERLINE", "+", "u'this'", ",", "\n", "SPIECE_UNDERLINE", "+", "u'is'", ",", "SPIECE_UNDERLINE", "+", "u'f'", ",", "u'al'", ",", "u'se'", ",", "u'.'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlnet_test.XLNetTokenizationTest.test_sequence_builders": [[92, 103], ["pytorch_transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.add_special_tokens_single_sentence", "pytorch_transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.add_special_tokens_sentences_pair"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", ".", "from_pretrained", "(", "\"xlnet-base-cased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "add_special_tokens_single_sentence", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "add_special_tokens_sentences_pair", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "text", "+", "[", "4", ",", "3", "]", "\n", "assert", "encoded_pair", "==", "text", "+", "[", "4", "]", "+", "text_2", "+", "[", "4", ",", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_transfo_xl_test.TransfoXLModelTest.setUp": [[185, 188], ["TransfoXLModelTest.TransfoXLModelTester", "modeling_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TransfoXLModelTest", ".", "TransfoXLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "TransfoXLConfig", ",", "d_embed", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_config": [[189, 191], ["modeling_transfo_xl_test.TransfoXLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_transfo_xl_model": [[192, 197], ["modeling_transfo_xl_test.TransfoXLModelTest.model_tester.set_seed", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.prepare_config_and_inputs", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.create_transfo_xl_model", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.check_transfo_xl_model_output"], "methods", ["None"], ["", "def", "test_transfo_xl_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "output_result", "=", "self", ".", "model_tester", ".", "create_transfo_xl_model", "(", "*", "config_and_inputs", ")", "\n", "self", ".", "model_tester", ".", "check_transfo_xl_model_output", "(", "output_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_transfo_xl_lm_head": [[198, 203], ["modeling_transfo_xl_test.TransfoXLModelTest.model_tester.set_seed", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.prepare_config_and_inputs", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.create_transfo_xl_lm_head", "modeling_transfo_xl_test.TransfoXLModelTest.model_tester.check_transfo_xl_lm_head_output"], "methods", ["None"], ["", "def", "test_transfo_xl_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "output_result", "=", "self", ".", "model_tester", ".", "create_transfo_xl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "self", ".", "model_tester", ".", "check_transfo_xl_lm_head_output", "(", "output_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_transfo_xl_test.TransfoXLModelTest.test_model_from_pretrained": [[204, 211], ["list", "pytorch_transformers.TransfoXLModel.from_pretrained", "shutil.rmtree", "modeling_transfo_xl_test.TransfoXLModelTest.assertIsNotNone", "pytorch_transformers.modeling_transfo_xl.TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/pytorch_transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TransfoXLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_utils_test.TokenizerUtilsTest.check_tokenizer_from_pretrained": [[26, 41], ["list", "tokenizer_class.max_model_input_sizes.keys", "tokenizer_class.from_pretrained", "tokenization_utils_test.TokenizerUtilsTest.assertIsNotNone", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenizer_class.from_pretrained.convert_tokens_to_ids", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance", "tokenization_utils_test.TokenizerUtilsTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["    ", "def", "check_tokenizer_from_pretrained", "(", "self", ",", "tokenizer_class", ")", ":", "\n", "        ", "s3_models", "=", "list", "(", "tokenizer_class", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "for", "model_name", "in", "s3_models", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "tokenizer_class", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "PreTrainedTokenizer", ")", "\n", "\n", "for", "special_tok", "in", "tokenizer", ".", "all_special_tokens", ":", "\n", "                ", "if", "six", ".", "PY2", ":", "\n", "                    ", "self", ".", "assertIsInstance", "(", "special_tok", ",", "unicode", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "assertIsInstance", "(", "special_tok", ",", "str", ")", "\n", "", "special_tok_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "special_tok", ")", "\n", "self", ".", "assertIsInstance", "(", "special_tok_id", ",", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_utils_test.TokenizerUtilsTest.test_pretrained_tokenizers": [[42, 44], ["tokenization_utils_test.TokenizerUtilsTest.check_tokenizer_from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_utils_test.TokenizerUtilsTest.check_tokenizer_from_pretrained"], ["", "", "", "def", "test_pretrained_tokenizers", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_tokenizer_from_pretrained", "(", "GPT2Tokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.setUp": [[30, 47], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"w</w>\"", ",", "\"r</w>\"", ",", "\"t</w>\"", ",", "\n", "\"lo\"", ",", "\"low\"", ",", "\"er</w>\"", ",", "\n", "\"low</w>\"", ",", "\"lowest</w>\"", ",", "\"newer</w>\"", ",", "\"wider</w>\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"l o\"", ",", "\"lo w\"", ",", "\"e r</w>\"", ",", "\"\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.get_tokenizer": [[48, 50], ["pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.get_input_output_texts": [[51, 55], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_openai_test.OpenAIGPTTokenizationTest.test_full_tokenizer": [[57, 69], ["pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer", "pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.tokenize", "tokenization_openai_test.OpenAIGPTTokenizationTest.assertListEqual", "tokenization_openai_test.OpenAIGPTTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "OpenAIGPTTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ")", "\n", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er</w>\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "\"<unk>\"", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "20", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_gpt2_test.GPT2TokenizationTest.setUp": [[29, 46], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "GPT2TokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"lo\"", ",", "\"low\"", ",", "\"er\"", ",", "\n", "\"low\"", ",", "\"lowest\"", ",", "\"newer\"", ",", "\"wider\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"l o\"", ",", "\"lo w\"", ",", "\"e r\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_gpt2_test.GPT2TokenizationTest.get_tokenizer": [[47, 49], ["pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "GPT2Tokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_gpt2_test.GPT2TokenizationTest.get_input_output_texts": [[50, 54], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower<unk>newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_gpt2_test.GPT2TokenizationTest.test_full_tokenizer": [[55, 66], ["pytorch_transformers.tokenization_gpt2.GPT2Tokenizer", "pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.tokenize", "tokenization_gpt2_test.GPT2TokenizationTest.assertListEqual", "tokenization_gpt2_test.GPT2TokenizationTest.assertListEqual", "pytorch_transformers.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "GPT2Tokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "input_bpe_tokens", "=", "[", "13", ",", "12", ",", "17", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelTest.setUp": [[160, 163], ["RobertaModelTest.RobertaModelTester", "modeling_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "RobertaModelTest", ".", "RobertaModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "RobertaConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelTest.test_config": [[164, 166], ["modeling_roberta_test.RobertaModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelTest.test_roberta_model": [[167, 170], ["modeling_roberta_test.RobertaModelTest.model_tester.prepare_config_and_inputs", "modeling_roberta_test.RobertaModelTest.model_tester.create_and_check_roberta_model"], "methods", ["None"], ["", "def", "test_roberta_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelTest.test_for_masked_lm": [[171, 174], ["modeling_roberta_test.RobertaModelTest.model_tester.prepare_config_and_inputs", "modeling_roberta_test.RobertaModelTest.model_tester.create_and_check_roberta_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelTest.test_model_from_pretrained": [[175, 182], ["list", "pytorch_transformers.RobertaModel.from_pretrained", "shutil.rmtree", "modeling_roberta_test.RobertaModelTest.assertIsNotNone", "pytorch_transformers.modeling_roberta.ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/pytorch_transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelIntegrationTest.test_inference_masked_lm": [[187, 206], ["pytorch_transformers.RobertaForMaskedLM.from_pretrained", "torch.tensor", "torch.Size", "modeling_roberta_test.RobertaModelIntegrationTest.assertEqual", "torch.Tensor", "modeling_roberta_test.RobertaModelIntegrationTest.assertTrue", "pytorch_transformers.RobertaForMaskedLM.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["    ", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_masked_lm", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaForMaskedLM", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "torch", ".", "Size", "(", "(", "1", ",", "11", ",", "50265", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "output", ".", "shape", ",", "\n", "expected_shape", "\n", ")", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "33.8843", ",", "-", "4.3107", ",", "22.7779", "]", ",", "\n", "[", "4.6533", ",", "-", "2.8099", ",", "13.6252", "]", ",", "\n", "[", "1.8222", ",", "-", "3.6898", ",", "8.8600", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ",", "expected_slice", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelIntegrationTest.test_inference_no_head": [[208, 222], ["pytorch_transformers.RobertaModel.from_pretrained", "torch.tensor", "torch.Tensor", "modeling_roberta_test.RobertaModelIntegrationTest.assertTrue", "pytorch_transformers.RobertaModel.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_no_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "'roberta-base'", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "-", "0.0231", ",", "0.0782", ",", "0.0074", "]", ",", "\n", "[", "-", "0.1854", ",", "0.0539", ",", "-", "0.0174", "]", ",", "\n", "[", "0.0548", ",", "0.0799", ",", "0.1687", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ",", "expected_slice", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_roberta_test.RobertaModelIntegrationTest.test_inference_classification_head": [[224, 238], ["pytorch_transformers.RobertaForSequenceClassification.from_pretrained", "torch.tensor", "torch.Size", "modeling_roberta_test.RobertaModelIntegrationTest.assertEqual", "torch.Tensor", "modeling_roberta_test.RobertaModelIntegrationTest.assertTrue", "pytorch_transformers.RobertaForSequenceClassification.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_inference_classification_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaForSequenceClassification", ".", "from_pretrained", "(", "'roberta-large-mnli'", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "torch", ".", "Size", "(", "(", "1", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "output", ".", "shape", ",", "\n", "expected_shape", "\n", ")", "\n", "expected_tensor", "=", "torch", ".", "Tensor", "(", "[", "[", "-", "0.9469", ",", "0.3913", ",", "0.5118", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "\n", "torch", ".", "allclose", "(", "output", ",", "expected_tensor", ",", "atol", "=", "1e-3", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.setUp": [[285, 288], ["XLNetModelTest.XLNetModelTester", "modeling_common_test.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XLNetModelTest", ".", "XLNetModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLNetConfig", ",", "d_inner", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.test_config": [[289, 291], ["modeling_xlnet_test.XLNetModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_common_test.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_base_model": [[292, 296], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_base_model"], "methods", ["None"], ["", "def", "test_xlnet_base_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_base_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_lm_head": [[297, 301], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_lm_head"], "methods", ["None"], ["", "def", "test_xlnet_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_sequence_classif": [[302, 306], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_sequence_classif"], "methods", ["None"], ["", "def", "test_xlnet_sequence_classif", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.test_xlnet_qa": [[307, 311], ["modeling_xlnet_test.XLNetModelTest.model_tester.set_seed", "modeling_xlnet_test.XLNetModelTest.model_tester.prepare_config_and_inputs", "modeling_xlnet_test.XLNetModelTest.model_tester.create_and_check_xlnet_qa"], "methods", ["None"], ["", "def", "test_xlnet_qa", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_xlnet_test.XLNetModelTest.test_model_from_pretrained": [[312, 319], ["list", "pytorch_transformers.XLNetModel.from_pretrained", "shutil.rmtree", "modeling_xlnet_test.XLNetModelTest.assertIsNotNone", "pytorch_transformers.modeling_xlnet.XLNET_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "cache_dir", "=", "\"/tmp/pytorch_transformers_test/\"", "\n", "for", "model_name", "in", "list", "(", "XLNET_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLNetModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "cache_dir", ")", "\n", "shutil", ".", "rmtree", "(", "cache_dir", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.OptimizationTest.assertListAlmostEqual": [[53, 57], ["optimization_test.OptimizationTest.assertEqual", "zip", "len", "len", "optimization_test.OptimizationTest.assertAlmostEqual"], "methods", ["None"], ["    ", "def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.OptimizationTest.test_adam_w": [[58, 71], ["torch.tensor", "torch.tensor", "torch.nn.MSELoss", "pytorch_transformers.AdamW", "range", "optimization_test.OptimizationTest.assertListAlmostEqual", "torch.nn.MSELoss.", "torch.nn.MSELoss.backward", "pytorch_transformers.AdamW.step", "torch.tensor.grad.detach_", "torch.tensor.grad.zero_", "torch.tensor.tolist"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.KM_parser.FeatureDropoutFunction.backward", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.step"], ["", "", "def", "test_adam_w", "(", "self", ")", ":", "\n", "        ", "w", "=", "torch", ".", "tensor", "(", "[", "0.1", ",", "-", "0.2", ",", "-", "0.1", "]", ",", "requires_grad", "=", "True", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "0.4", ",", "0.2", ",", "-", "0.5", "]", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "# No warmup, constant schedule, no gradient clipping", "\n", "optimizer", "=", "AdamW", "(", "params", "=", "[", "w", "]", ",", "lr", "=", "2e-1", ",", "weight_decay", "=", "0.0", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "            ", "loss", "=", "criterion", "(", "w", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "w", ".", "grad", ".", "detach_", "(", ")", "# No zero_grad() function on simple tensors. we do it ourselves.", "\n", "w", ".", "grad", ".", "zero_", "(", ")", "\n", "", "self", ".", "assertListAlmostEqual", "(", "w", ".", "tolist", "(", ")", ",", "[", "0.4", ",", "0.2", ",", "-", "0.5", "]", ",", "tol", "=", "1e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual": [[78, 82], ["optimization_test.ScheduleInitTest.assertEqual", "zip", "len", "len", "optimization_test.ScheduleInitTest.assertAlmostEqual"], "methods", ["None"], ["def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.test_constant_scheduler": [[83, 93], ["pytorch_transformers.ConstantLRSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListEqual", "pytorch_transformers.ConstantLRSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "", "def", "test_constant_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "ConstantLRSchedule", "(", "self", ".", "optimizer", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "10.", "]", "*", "self", ".", "num_steps", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "ConstantLRSchedule", "(", "self", ".", "optimizer", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.test_warmup_constant_scheduler": [[94, 104], ["pytorch_transformers.WarmupConstantSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListEqual", "pytorch_transformers.WarmupConstantSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_constant_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupConstantSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "4", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "2.5", ",", "5.0", ",", "7.5", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "WarmupConstantSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "4", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.test_warmup_linear_scheduler": [[105, 115], ["pytorch_transformers.WarmupLinearSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListEqual", "pytorch_transformers.WarmupLinearSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_linear_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupLinearSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "8.75", ",", "7.5", ",", "6.25", ",", "5.0", ",", "3.75", ",", "2.5", ",", "1.25", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.test_warmup_cosine_scheduler": [[116, 126], ["pytorch_transformers.WarmupCosineSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListAlmostEqual", "pytorch_transformers.WarmupCosineSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_cosine_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupCosineSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "9.61", ",", "8.53", ",", "6.91", ",", "5.0", ",", "3.08", ",", "1.46", ",", "0.38", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ",", "tol", "=", "1e-2", ")", "\n", "\n", "scheduler", "=", "WarmupCosineSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.test_warmup_cosine_hard_restart_scheduler": [[127, 137], ["pytorch_transformers.WarmupCosineWithHardRestartsSchedule", "optimization_test.unwrap_schedule", "optimization_test.ScheduleInitTest.assertEqual", "optimization_test.ScheduleInitTest.assertListAlmostEqual", "pytorch_transformers.WarmupCosineWithHardRestartsSchedule", "optimization_test.unwrap_and_save_reload_schedule", "optimization_test.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_schedule", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.ScheduleInitTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_cosine_hard_restart_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "WarmupCosineWithHardRestartsSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "cycles", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "8.53", ",", "5.0", ",", "1.46", ",", "10.0", ",", "8.53", ",", "5.0", ",", "1.46", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ",", "tol", "=", "1e-2", ")", "\n", "\n", "scheduler", "=", "WarmupCosineWithHardRestartsSchedule", "(", "self", ".", "optimizer", ",", "warmup_steps", "=", "2", ",", "cycles", "=", "2", ",", "t_total", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_schedule": [[30, 36], ["range", "scheduler.step", "lrs.append", "scheduler.get_lr"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.step", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.get_lr"], ["def", "unwrap_schedule", "(", "scheduler", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "lrs", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "lrs", ".", "append", "(", "scheduler", ".", "get_lr", "(", ")", ")", "\n", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.optimization_test.unwrap_and_save_reload_schedule": [[37, 50], ["range", "scheduler.step", "lrs.append", "scheduler.get_lr", "tokenization_tests_commons.TemporaryDirectory", "os.path.join", "torch.save", "torch.load", "scheduler.load_state_dict", "scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.step", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.get_lr"], ["", "def", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "lrs", "=", "[", "]", "\n", "for", "step", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "lrs", ".", "append", "(", "scheduler", ".", "get_lr", "(", ")", ")", "\n", "if", "step", "==", "num_steps", "//", "2", ":", "\n", "            ", "with", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "file_name", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "'schedule.bin'", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "file_name", ")", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "file_name", ")", "\n", "scheduler", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_roberta_test.RobertaTokenizationTest.setUp": [[28, 45], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"lo\"", ",", "\"low\"", ",", "\"er\"", ",", "\n", "\"low\"", ",", "\"lowest\"", ",", "\"newer\"", ",", "\"wider\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"l o\"", ",", "\"lo w\"", ",", "\"e r\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_roberta_test.RobertaTokenizationTest.get_tokenizer": [[46, 48], ["pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_roberta_test.RobertaTokenizationTest.get_input_output_texts": [[49, 53], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower<unk>newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_roberta_test.RobertaTokenizationTest.test_full_tokenizer": [[54, 65], ["pytorch_transformers.tokenization_roberta.RobertaTokenizer", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.tokenize", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "input_bpe_tokens", "=", "[", "13", ",", "12", ",", "17", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_roberta_test.RobertaTokenizationTest.roberta_dict_integration_testing": [[66, 76], ["tokenization_roberta_test.RobertaTokenizationTest.get_tokenizer", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "tokenization_roberta_test.RobertaTokenizationTest.assertListEqual", "tokenization_roberta_test.RobertaTokenizationTest.encode", "tokenization_roberta_test.RobertaTokenizationTest.encode"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "def", "roberta_dict_integration_testing", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "encode", "(", "'Hello world!'", ")", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "2", "]", "\n", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "encode", "(", "'Hello world! c\u00e9c\u00e9 herlolip 418'", ")", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_roberta_test.RobertaTokenizationTest.test_sequence_builders": [[78, 92], ["pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.add_special_tokens_single_sentence", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.add_special_tokens_sentences_pair"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_text_from_decode", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "True", ")", "\n", "encoded_pair_from_decode", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "True", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "add_special_tokens_single_sentence", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "add_special_tokens_sentences_pair", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "encoded_text_from_decode", "\n", "assert", "encoded_pair", "==", "encoded_pair_from_decode", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.modeling_auto_test.AutoModelTest.test_model_from_pretrained": [[31, 44], ["logging.basicConfig", "list", "pytorch_transformers.AutoConfig.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "pytorch_transformers.AutoModel.from_pretrained", "pytorch_transformers.AutoModel.from_pretrained", "modeling_auto_test.AutoModelTest.assertIsNotNone", "modeling_auto_test.AutoModelTest.assertIsInstance", "loading_info.values", "pytorch_transformers.modeling_bert.BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "modeling_auto_test.AutoModelTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["    ", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertModel", ")", "\n", "for", "value", "in", "loading_info", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "len", "(", "value", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.setUp": [[29, 39], ["super().setUp", "os.path.join", "io.open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "TransfoXLTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"<unk>\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"unwanted\"", ",", "\"wa\"", ",", "\"un\"", ",", "\n", "\"running\"", ",", "\",\"", ",", "\"low\"", ",", "\"l\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.get_tokenizer": [[40, 42], ["pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "TransfoXLTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "lower_case", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.get_input_output_texts": [[43, 47], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"<unk> UNwanted , running\"", "\n", "output_text", "=", "u\"<unk> unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.test_full_tokenizer": [[48, 56], ["pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer", "pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "vocab_file", "=", "self", ".", "vocab_file", ",", "lower_case", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"<unk> UNwanted , running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"<unk>\"", ",", "\"unwanted\"", ",", "\",\"", ",", "\"running\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "0", ",", "4", ",", "8", ",", "7", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.test_full_tokenizer_lower": [[57, 63], ["pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_full_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo ! how  \\n Are yoU ?  \"", ")", ",", "\n", "[", "\"hello\"", ",", "\"!\"", ",", "\"how\"", ",", "\"are\"", ",", "\"you\"", ",", "\"?\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_transfo_xl_test.TransfoXLTokenizationTest.test_full_tokenizer_no_lower": [[64, 70], ["pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer", "tokenization_transfo_xl_test.TransfoXLTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_transfo_xl.TransfoXLTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_full_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "lower_case", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo ! how  \\n Are yoU ?  \"", ")", ",", "\n", "[", "\"HeLLo\"", ",", "\"!\"", ",", "\"how\"", ",", "\"Are\"", ",", "\"yoU\"", ",", "\"?\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_auto_test.AutoTokenizerTest.test_tokenizer_from_pretrained": [[30, 43], ["logging.basicConfig", "list", "pytorch_transformers.AutoTokenizer.from_pretrained", "tokenization_auto_test.AutoTokenizerTest.assertIsNotNone", "tokenization_auto_test.AutoTokenizerTest.assertIsInstance", "tokenization_auto_test.AutoTokenizerTest.assertGreater", "list", "pytorch_transformers.AutoTokenizer.from_pretrained", "tokenization_auto_test.AutoTokenizerTest.assertIsNotNone", "tokenization_auto_test.AutoTokenizerTest.assertIsInstance", "tokenization_auto_test.AutoTokenizerTest.assertGreater", "pytorch_transformers.modeling_bert.BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "len", "pytorch_transformers.modeling_gpt2.GPT2_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["    ", "def", "test_tokenizer_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "BertTokenizer", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "tokenizer", ")", ",", "0", ")", "\n", "\n", "", "for", "model_name", "in", "list", "(", "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "GPT2Tokenizer", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "tokenizer", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.conftest.pytest_addoption": [[6, 9], ["parser.addoption"], "function", ["None"], ["def", "pytest_addoption", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "addoption", "(", "\n", "\"--runslow\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ",", "help", "=", "\"run slow tests\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.conftest.pytest_collection_modifyitems": [[12, 20], ["config.getoption", "pytest.mark.skip", "item.add_marker"], "function", ["None"], ["", "def", "pytest_collection_modifyitems", "(", "config", ",", "items", ")", ":", "\n", "    ", "if", "config", ".", "getoption", "(", "\"--runslow\"", ")", ":", "\n", "# --runslow given in cli: do not skip slow tests", "\n", "        ", "return", "\n", "", "skip_slow", "=", "pytest", ".", "mark", ".", "skip", "(", "reason", "=", "\"need --runslow option to run\"", ")", "\n", "for", "item", "in", "items", ":", "\n", "        ", "if", "\"slow\"", "in", "item", ".", "keywords", ":", "\n", "            ", "item", ".", "add_marker", "(", "skip_slow", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlm_test.XLMTokenizationTest.setUp": [[29, 46], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XLMTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"l\"", ",", "\"o\"", ",", "\"w\"", ",", "\"e\"", ",", "\"r\"", ",", "\"s\"", ",", "\"t\"", ",", "\"i\"", ",", "\"d\"", ",", "\"n\"", ",", "\n", "\"w</w>\"", ",", "\"r</w>\"", ",", "\"t</w>\"", ",", "\n", "\"lo\"", ",", "\"low\"", ",", "\"er</w>\"", ",", "\n", "\"low</w>\"", ",", "\"lowest</w>\"", ",", "\"newer</w>\"", ",", "\"wider</w>\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"l o 123\"", ",", "\"lo w 1456\"", ",", "\"e r</w> 1789\"", ",", "\"\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlm_test.XLMTokenizationTest.get_tokenizer": [[47, 49], ["pytorch_transformers.tokenization_xlm.XLMTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "XLMTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlm_test.XLMTokenizationTest.get_input_output_texts": [[50, 54], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"lower newer\"", "\n", "output_text", "=", "u\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlm_test.XLMTokenizationTest.test_full_tokenizer": [[55, 68], ["pytorch_transformers.tokenization_xlm.XLMTokenizer", "pytorch_transformers.tokenization_xlm.XLMTokenizer.tokenize", "tokenization_xlm_test.XLMTokenizationTest.assertListEqual", "tokenization_xlm_test.XLMTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_xlm.XLMTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "\"\"\" Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt \"\"\"", "\n", "tokenizer", "=", "XLMTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ")", "\n", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er</w>\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "\"<unk>\"", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "20", "]", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_xlm_test.XLMTokenizationTest.test_sequence_builders": [[69, 80], ["pytorch_transformers.tokenization_xlm.XLMTokenizer.from_pretrained", "pytorch_transformers.tokenization_xlm.XLMTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_xlm.XLMTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_xlm.XLMTokenizer.from_pretrained.add_special_tokens_single_sentence", "pytorch_transformers.tokenization_xlm.XLMTokenizer.from_pretrained.add_special_tokens_sentences_pair"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLMTokenizer", ".", "from_pretrained", "(", "\"xlm-mlm-en-2048\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "add_special_tokens_single_sentence", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "add_special_tokens_sentences_pair", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "1", "]", "+", "text", "+", "[", "1", "]", "\n", "assert", "encoded_pair", "==", "[", "1", "]", "+", "text", "+", "[", "1", "]", "+", "text_2", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp": [[33, 43], ["super().setUp", "os.path.join", "io.open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "BertTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"wa\"", ",", "\"un\"", ",", "\"runn\"", ",", "\n", "\"##ing\"", ",", "\",\"", ",", "\"low\"", ",", "\"lowest\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.get_tokenizer": [[44, 46], ["pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "        ", "return", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.get_input_output_texts": [[47, 51], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "u\"UNwant\\u00E9d,running\"", "\n", "output_text", "=", "u\"unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_full_tokenizer": [[52, 58], ["pytorch_transformers.tokenization_bert.BertTokenizer", "pytorch_transformers.tokenization_bert.BertTokenizer.tokenize", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_bert.BertTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", "(", "self", ".", "vocab_file", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "u\"UNwant\\u00E9d,running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\",\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "7", ",", "4", ",", "5", ",", "10", ",", "8", ",", "9", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_chinese": [[59, 65], ["pytorch_transformers.tokenization_bert.BasicTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_chinese", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\"ah\\u535A\\u63A8zz\"", ")", ",", "\n", "[", "u\"ah\"", ",", "u\"\\u535A\"", ",", "u\"\\u63A8\"", ",", "u\"zz\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_basic_tokenizer_lower": [[66, 73], ["pytorch_transformers.tokenization_bert.BasicTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_bert.BasicTokenizer.tokenize", "pytorch_transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_basic_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo!how  \\n Are yoU?  \"", ")", ",", "\n", "[", "\"hello\"", ",", "\"!\"", ",", "\"how\"", ",", "\"are\"", ",", "\"you\"", ",", "\"?\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "u\"H\\u00E9llo\"", ")", ",", "[", "\"hello\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_basic_tokenizer_no_lower": [[74, 80], ["pytorch_transformers.tokenization_bert.BasicTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_basic_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "u\" \\tHeLLo!how  \\n Are yoU?  \"", ")", ",", "\n", "[", "\"HeLLo\"", ",", "\"!\"", ",", "\"how\"", ",", "\"Are\"", ",", "\"yoU\"", ",", "\"?\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_wordpiece_tokenizer": [[81, 100], ["enumerate", "pytorch_transformers.tokenization_bert.WordpieceTokenizer", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "tokenization_bert_test.BertTokenizationTest.assertListEqual", "pytorch_transformers.tokenization_bert.WordpieceTokenizer.tokenize", "pytorch_transformers.tokenization_bert.WordpieceTokenizer.tokenize", "pytorch_transformers.tokenization_bert.WordpieceTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "test_wordpiece_tokenizer", "(", "self", ")", ":", "\n", "        ", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"wa\"", ",", "\"un\"", ",", "\"runn\"", ",", "\n", "\"##ing\"", "\n", "]", "\n", "\n", "vocab", "=", "{", "}", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "vocab_tokens", ")", ":", "\n", "            ", "vocab", "[", "token", "]", "=", "i", "\n", "", "tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\"", ")", ",", "[", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\"unwanted running\"", ")", ",", "\n", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\"unwantedX running\"", ")", ",", "[", "\"[UNK]\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_is_whitespace": [[101, 110], ["tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "pytorch_transformers.tokenization_bert._is_whitespace", "pytorch_transformers.tokenization_bert._is_whitespace", "pytorch_transformers.tokenization_bert._is_whitespace", "pytorch_transformers.tokenization_bert._is_whitespace", "pytorch_transformers.tokenization_bert._is_whitespace", "pytorch_transformers.tokenization_bert._is_whitespace", "pytorch_transformers.tokenization_bert._is_whitespace"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace"], ["", "def", "test_is_whitespace", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\" \"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\t\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\r\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\n\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "u\"\\u00A0\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_whitespace", "(", "u\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_whitespace", "(", "u\"-\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_is_control": [[111, 118], ["tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "pytorch_transformers.tokenization_bert._is_control", "pytorch_transformers.tokenization_bert._is_control", "pytorch_transformers.tokenization_bert._is_control", "pytorch_transformers.tokenization_bert._is_control", "pytorch_transformers.tokenization_bert._is_control"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control"], ["", "def", "test_is_control", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_control", "(", "u\"\\u0005\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\" \"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\"\\t\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "u\"\\r\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_is_punctuation": [[119, 127], ["tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertTrue", "tokenization_bert_test.BertTokenizationTest.assertFalse", "tokenization_bert_test.BertTokenizationTest.assertFalse", "pytorch_transformers.tokenization_bert._is_punctuation", "pytorch_transformers.tokenization_bert._is_punctuation", "pytorch_transformers.tokenization_bert._is_punctuation", "pytorch_transformers.tokenization_bert._is_punctuation", "pytorch_transformers.tokenization_bert._is_punctuation", "pytorch_transformers.tokenization_bert._is_punctuation"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation"], ["", "def", "test_is_punctuation", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\"-\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\"$\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\"`\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "u\".\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_punctuation", "(", "u\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_punctuation", "(", "u\" \"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.tests.tokenization_bert_test.BertTokenizationTest.test_sequence_builders": [[128, 139], ["pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained.encode", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained.add_special_tokens_single_sentence", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained.add_special_tokens_sentences_pair"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\"bert-base-uncased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "add_special_tokens_single_sentence", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "add_special_tokens_sentences_pair", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "101", "]", "+", "text", "+", "[", "102", "]", "\n", "assert", "encoded_pair", "==", "[", "101", "]", "+", "text", "+", "[", "102", "]", "+", "text_2", "+", "[", "102", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.__init__": [[69, 124], ["isinstance", "json.loads.items", "isinstance", "open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_dict": [[126, 133], ["modeling.BertConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file": [[134, 140], ["cls.from_dict", "open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.__repr__": [[141, 143], ["str", "modeling.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_dict": [[144, 148], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_json_string": [[149, 152], ["json.dumps", "modeling.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertEmbeddings.__init__": [[175, 185], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertEmbeddings.forward": [[186, 201], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling.BertEmbeddings.word_embeddings", "modeling.BertEmbeddings.position_embeddings", "modeling.BertEmbeddings.token_type_embeddings", "modeling.BertEmbeddings.LayerNorm", "modeling.BertEmbeddings.dropout", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.__init__": [[204, 219], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores": [[220, 224], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.forward": [[225, 252], ["modeling.BertSelfAttention.query", "modeling.BertSelfAttention.key", "modeling.BertSelfAttention.value", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.value", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfOutput.__init__": [[255, 260], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertSelfOutput.forward": [[261, 266], ["modeling.BertSelfOutput.dense", "modeling.BertSelfOutput.dropout", "modeling.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertAttention.__init__": [[269, 273], ["torch.nn.Module.__init__", "modeling.BertSelfAttention", "modeling.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertAttention.forward": [[274, 278], ["modeling.BertAttention.self", "modeling.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertIntermediate.__init__": [[281, 286], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "else", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertIntermediate.forward": [[287, 291], ["modeling.BertIntermediate.dense", "modeling.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertOutput.__init__": [[294, 299], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertOutput.forward": [[300, 305], ["modeling.BertOutput.dense", "modeling.BertOutput.dropout", "modeling.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertLayer.__init__": [[308, 313], ["torch.nn.Module.__init__", "modeling.BertAttention", "modeling.BertIntermediate", "modeling.BertOutput"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertLayer.forward": [[314, 319], ["modeling.BertLayer.attention", "modeling.BertLayer.intermediate", "modeling.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertEncoder.__init__": [[322, 326], ["torch.nn.Module.__init__", "modeling.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertEncoder.forward": [[327, 336], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ")", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertPooler.__init__": [[339, 343], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertPooler.forward": [[344, 351], ["modeling.BertPooler.dense", "modeling.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertPredictionHeadTransform.__init__": [[354, 360], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "else", "config", ".", "hidden_act", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertPredictionHeadTransform.forward": [[361, 366], ["modeling.BertPredictionHeadTransform.dense", "modeling.BertPredictionHeadTransform.transform_act_fn", "modeling.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertLMPredictionHead.__init__": [[369, 380], ["torch.nn.Module.__init__", "modeling.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertLMPredictionHead.forward": [[381, 385], ["modeling.BertLMPredictionHead.transform", "modeling.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertOnlyMLMHead.__init__": [[388, 391], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertOnlyMLMHead.forward": [[392, 395], ["modeling.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertOnlyNSPHead.__init__": [[398, 401], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertOnlyNSPHead.forward": [[402, 405], ["modeling.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertPreTrainingHeads.__init__": [[408, 412], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertPreTrainingHeads.forward": [[413, 417], ["modeling.BertPreTrainingHeads.predictions", "modeling.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.PreTrainedBertModel.__init__": [[423, 433], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedBertModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"", "\n", "\"To create a model from a Google pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.PreTrainedBertModel.init_bert_weights": [[434, 446], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.normal_", "module.weight.data.normal_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.PreTrainedBertModel.from_pretrained": [[447, 552], ["os.path.isdir", "os.path.join", "modeling.BertConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling.PreTrainedBertModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `bert-base-uncased`\n                    . `bert-large-uncased`\n                    . `bert-base-cased`\n                    . `bert-base-multilingual`\n                    . `bert-base-chinese`\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "pretrained_model_name", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "tempdir", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", ":", "\n", "            ", "serialization_dir", "=", "resolved_archive_file", "\n", "", "else", ":", "\n", "# Extract archive to temp dir", "\n", "            ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", ")", ")", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:gz'", ")", "as", "archive", ":", "\n", "                ", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "serialization_dir", "=", "tempdir", "\n", "# Load config", "\n", "", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", "\n", "config", "=", "BertConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", ":", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "WEIGHTS_NAME", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "weights_path", ")", "\n", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "", "", "", "load", "(", "model", ",", "prefix", "=", "''", "if", "hasattr", "(", "model", ",", "'bert'", ")", "else", "'bert.'", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "tempdir", ":", "\n", "# Clean up temp dir", "\n", "            ", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertModel.__init__": [[598, 604], ["modeling.PreTrainedBertModel.__init__", "modeling.BertEmbeddings", "modeling.BertEncoder", "modeling.BertPooler", "modeling.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertModel.forward": [[605, 635], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling.BertModel.embeddings", "modeling.BertModel.encoder", "modeling.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "torch.ones_like.unsqueeze", "next", "modeling.BertModel.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "token_type_ids", ")", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForPreTraining.__init__": [[687, 692], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "modeling.BertPreTrainingHeads", "modeling.BertForPreTraining.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForPreTraining.forward": [[693, 706], ["modeling.BertForPreTraining.bert", "modeling.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForMaskedLM.__init__": [[750, 755], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "modeling.BertOnlyMLMHead", "modeling.BertForMaskedLM.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForMaskedLM.forward": [[756, 767], ["modeling.BertForMaskedLM.bert", "modeling.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "masked_lm_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForNextSentencePrediction.__init__": [[812, 817], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "modeling.BertOnlyNSPHead", "modeling.BertForNextSentencePrediction.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForNextSentencePrediction.forward": [[818, 829], ["modeling.BertForNextSentencePrediction.bert", "modeling.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "next_sentence_loss", "\n", "", "else", ":", "\n", "            ", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForSequenceClassification.__init__": [[876, 883], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", "=", "2", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForSequenceClassification.forward": [[884, 895], ["modeling.BertForSequenceClassification.bert", "modeling.BertForSequenceClassification.dropout", "modeling.BertForSequenceClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForMultipleChoice.__init__": [[941, 948], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForMultipleChoice.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_choices", "=", "2", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_choices", "=", "num_choices", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForMultipleChoice.forward": [[949, 964], ["input_ids.view", "token_type_ids.view", "attention_mask.view", "modeling.BertForMultipleChoice.bert", "modeling.BertForMultipleChoice.dropout", "modeling.BertForMultipleChoice.classifier", "modeling.BertForMultipleChoice.view", "input_ids.size", "token_type_ids.size", "attention_mask.size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss."], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "flat_token_type_ids", ",", "flat_attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_choices", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "reshaped_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForTokenClassification.__init__": [[1011, 1018], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForTokenClassification.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", "=", "2", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForTokenClassification.forward": [[1019, 1030], ["modeling.BertForTokenClassification.bert", "modeling.BertForTokenClassification.dropout", "modeling.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForQuestionAnswering.__init__": [[1087, 1094], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Linear", "modeling.BertForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "# TODO check with Google if it's normal there is no dropout on the token classifier of SQuAD in the TF version", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertForQuestionAnswering.forward": [[1095, 1120], ["modeling.BertForQuestionAnswering.bert", "modeling.BertForQuestionAnswering.qa_outputs", "modeling.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.vocabulary.Vocabulary.size"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "start_logits", ",", "end_logits", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.gelu": [[51, 57], ["torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.swish": [[59, 61], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[30, 88], ["os.path.abspath", "os.path.abspath", "print", "tensorflow.train.list_variables", "modeling.BertConfig.from_json_file", "print", "modeling.BertForPreTraining", "zip", "print", "torch.save", "print", "tensorflow.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "print", "torch.from_numpy", "modeling.BertForPreTraining.state_dict", "str", "print", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "numpy.transpose", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.modeling.BertConfig.from_json_file", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["# Initialise PyTorch model", "\n", "    ", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--tf_checkpoint_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the TensorFlow checkpoint path.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_config_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The config json file corresponding to the pre-trained BERT model. \\n\"", "\n", "\"This specifies the model architecture.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pytorch_dump_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the output PyTorch model.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "convert_tf_checkpoint_to_pytorch", "(", "args", ".", "tf_checkpoint_path", ",", "\n", "args", ".", "bert_config_file", ",", "\n", "args", ".", "pytorch_dump_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.__init__": [[59, 78], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", ")", "\n", "", "return", "max", "(", "0.0", ",", "float", "(", "self", ".", "t_total", "-", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", ")", "\n", "\n", "\n", "", "", "class", "WarmupCosineSchedule", "(", "LambdaLR", ")", ":", "\n", "    ", "\"\"\" Linear warmup and then cosine decay.\n        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n        Decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps following a cosine curve.\n        If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "cycles", "=", ".5", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "cycles", "=", "cycles", "\n", "super", "(", "WarmupCosineSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n", "", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1.0", ",", "self", ".", "warmup_steps", ")", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.get_lr": [[79, 93], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["# progress after warmup", "\n", "", "progress", "=", "float", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", "\n", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "float", "(", "self", ".", "cycles", ")", "*", "2.0", "*", "progress", ")", ")", ")", "\n", "\n", "\n", "", "", "class", "WarmupCosineWithHardRestartsSchedule", "(", "LambdaLR", ")", ":", "\n", "    ", "\"\"\" Linear warmup and then cosine cycles with hard restarts.\n        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n        If `cycles` (default=1.) is different from default, learning rate follows `cycles` times a cosine decaying\n        learning rate (with hard restarts).\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "optimizer", ",", "warmup_steps", ",", "t_total", ",", "cycles", "=", "1.", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "t_total", "=", "t_total", "\n", "self", ".", "cycles", "=", "cycles", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.BertAdam.step": [[94, 163], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct"], "methods", ["None"], ["super", "(", "WarmupCosineWithHardRestartsSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "self", ".", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n", "", "def", "lr_lambda", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "float", "(", "step", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "warmup_steps", ")", ")", "\n", "# progress after warmup", "\n", "", "progress", "=", "float", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "self", ".", "t_total", "-", "self", ".", "warmup_steps", ")", ")", "\n", "if", "progress", ">=", "1.0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "(", "(", "float", "(", "self", ".", "cycles", ")", "*", "progress", ")", "%", "1.0", ")", ")", ")", ")", "\n", "\n", "\n", "\n", "", "", "class", "AdamW", "(", "Optimizer", ")", ":", "\n", "    ", "\"\"\" Implements Adam algorithm with weight decay fix.\n\n    Parameters:\n        lr (float): learning rate. Default 1e-3.\n        betas (tuple of 2 floats): Adams beta parameters (b1, b2). Default: (0.9, 0.999)\n        eps (float): Adams epsilon. Default: 1e-6\n        weight_decay (float): Weight decay. Default: 0.0\n        correct_bias (bool): can be set to False to avoid correcting bias in Adam (e.g. like in Bert TF repository). Default True.\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "weight_decay", "=", "0.0", ",", "correct_bias", "=", "True", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "correct_bias", "=", "correct_bias", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.warmup_cosine": [[23, 27], ["torch.cos"], "function", ["None"], ["\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "class", "ConstantLRSchedule", "(", "LambdaLR", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.warmup_constant": [[28, 32], ["None"], "function", ["None"], ["\n", "def", "__init__", "(", "self", ",", "optimizer", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "ConstantLRSchedule", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "lambda", "_", ":", "1.0", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.optimization.warmup_linear": [[33, 37], ["None"], "function", ["None"], ["", "", "class", "WarmupConstantSchedule", "(", "LambdaLR", ")", ":", "\n", "    ", "\"\"\" Linear warmup and then constant.\n        Linearly increases learning rate schedule from 0 to 1 over `warmup_steps` training steps.\n        Keeps learning rate schedule equal to 1. after warmup_steps.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.url_to_filename": [[30, 46], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pytorch_transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["os", ".", "getenv", "(", "'XDG_CACHE_HOME'", ",", "'~/.cache'", ")", ",", "'torch'", ")", ")", ")", "\n", "", "default_cache_path", "=", "os", ".", "path", ".", "join", "(", "torch_cache_home", ",", "'pytorch_transformers'", ")", "\n", "\n", "try", ":", "\n", "    ", "from", "urllib", ".", "parse", "import", "urlparse", "\n", "", "except", "ImportError", ":", "\n", "    ", "from", "urlparse", "import", "urlparse", "\n", "\n", "", "try", ":", "\n", "    ", "from", "pathlib", "import", "Path", "\n", "PYTORCH_PRETRAINED_BERT_CACHE", "=", "Path", "(", "\n", "os", ".", "getenv", "(", "'PYTORCH_TRANSFORMERS_CACHE'", ",", "os", ".", "getenv", "(", "'PYTORCH_PRETRAINED_BERT_CACHE'", ",", "default_cache_path", ")", ")", ")", "\n", "", "except", "(", "AttributeError", ",", "ImportError", ")", ":", "\n", "    ", "PYTORCH_PRETRAINED_BERT_CACHE", "=", "os", ".", "getenv", "(", "'PYTORCH_TRANSFORMERS_CACHE'", ",", "\n", "os", ".", "getenv", "(", "'PYTORCH_PRETRAINED_BERT_CACHE'", ",", "\n", "default_cache_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.filename_to_url": [[48, 72], ["isinstance", "os.path.join", "str", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "open", "json.load"], "function", ["None"], ["\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "# pylint: disable=invalid-name", "\n", "\n", "\n", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n", "\n", "", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.cached_path": [[74, 102], ["isinstance", "isinstance", "urllib.parse.urlparse", "str", "str", "file_utils.get_from_cache", "os.path.exists", "FileNotFoundError", "ValueError"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.get_from_cache"], ["\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n", "\n", "", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.split_s3_path": [[104, 115], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_request": [[117, 134], ["functools.wraps", "func", "int", "FileNotFoundError"], "function", ["None"], ["        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n", "\n", "", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_etag": [[136, 143], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.split_s3_path"], ["", "return", "bucket_name", ",", "s3_path", "\n", "\n", "\n", "", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_get": [[145, 151], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.split_s3_path"], ["@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.http_get": [[153, 163], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.dep_reader.CoNLLXReader.close"], ["                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n", "\n", "", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.get_from_cache": [[165, 222], ["isinstance", "os.makedirs", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "file_utils.s3_etag", "requests.head", "requests.head.headers.get", "os.path.exists", "IOError", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "file_utils.s3_get", "file_utils.http_get", "open", "shutil.copyfileobj", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.url_to_filename", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_etag", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.s3_get", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.http_get"], ["\n", "\n", "", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n", "\n", "", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n", "\n", "", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "not", "isinstance", "(", "cache_dir", ",", "str", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "EnvironmentError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "etag", "is", "not", "None", ":", "\n", "        ", "etag", "=", "etag", ".", "decode", "(", "'utf-8'", ")", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.read_set_from_file": [[224, 234], ["set", "open", "set.add", "line.rstrip"], "function", ["None"], ["if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "'.*'", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "'.json'", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.get_file_extension": [[236, 240], ["os.path.splitext", "ext.lower"], "function", ["None"], ["# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.__init__": [[78, 89], ["tokenization.load_vocab", "collections.OrderedDict", "tokenization.BasicTokenizer", "tokenization.WordpieceTokenizer", "os.path.isfile", "ValueError", "int", "tokenization.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.tokenize": [[90, 96], ["tokenization.BertTokenizer.basic_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "split_tokens.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", ":", "\n", "            ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids": [[97, 109], ["ids.append", "len", "ValueError", "len"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"", "\n", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "token", "]", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this BERT model ({} > {}). Running this\"", "\n", "\" sequence through BERT will result in indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens": [[110, 116], ["tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "ids_to_tokens", "[", "i", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BertTokenizer.from_pretrained": [[117, 154], ["os.path.isdir", "cls", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "pretrained_model_name", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "vocab_file", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_file", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "", "if", "pretrained_model_name", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer.__init__": [[159, 166], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "True", ")", ":", "\n", "        ", "\"\"\"Constructs a BasicTokenizer.\n\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer.tokenize": [[167, 187], ["tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "tokenization.whitespace_tokenize", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._run_strip_accents": [[188, 198], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc": [[199, 218], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars": [[219, 231], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._is_chinese_char": [[232, 253], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.BasicTokenizer._clean_text": [[254, 266], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.__init__": [[271, 275], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.WordpieceTokenizer.tokenize": [[276, 326], ["tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.load_vocab": [[51, 64], ["collections.OrderedDict", "open", "reader.readline", "token.strip.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "token", "=", "reader", ".", "readline", "(", ")", "\n", "if", "not", "token", ":", "\n", "                ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization.whitespace_tokenize": [[66, 73], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_whitespace": [[328, 338], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_control": [[340, 350], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.tokenization._is_punctuation": [[352, 366], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.__main__.main": [[2, 20], ["len", "print", "sys.argv.pop", "sys.argv.pop", "sys.argv.pop", "convert_tf_checkpoint_to_pytorch", "print"], "function", ["home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.KhalilMrini_LAL-Parser.src_joint.makehp.HParams.print"], ["def", "main", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "if", "(", "len", "(", "sys", ".", "argv", ")", "<", "4", "or", "len", "(", "sys", ".", "argv", ")", ">", "6", ")", "or", "sys", ".", "argv", "[", "1", "]", "not", "in", "[", "\"bert\"", ",", "\"gpt\"", ",", "\"transfo_xl\"", ",", "\"gpt2\"", ",", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "        ", "print", "(", "\n", "\"Should be used as one of: \\n\"", "\n", "\">> pytorch_transformers bert TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT, \\n\"", "\n", "\">> pytorch_transformers gpt OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG], \\n\"", "\n", "\">> pytorch_transformers transfo_xl TF_CHECKPOINT_OR_DATASET PYTORCH_DUMP_OUTPUT [TF_CONFIG] or \\n\"", "\n", "\">> pytorch_transformers gpt2 TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [GPT2_CONFIG] or \\n\"", "\n", "\">> pytorch_transformers xlnet TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT [FINETUNING_TASK_NAME] or \\n\"", "\n", "\">> pytorch_transformers xlm XLM_CHECKPOINT_PATH PYTORCH_DUMP_OUTPUT\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "sys", ".", "argv", "[", "1", "]", "==", "\"bert\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_tf_checkpoint_to_pytorch", "import", "convert_tf_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n"]]}