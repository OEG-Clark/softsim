{"home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.standarization": [[17, 23], ["tensorflow.name_scope", "tensorflow.reshape", "tensorflow.map_fn", "tensorflow.reshape", "tensorflow.image.per_image_standardization"], "function", ["None"], ["def", "standarization", "(", "x_images", ")", ":", "\n", "  ", "with", "tf", ".", "name_scope", "(", "'standarization'", ")", ":", "\n", "    ", "x_images", "=", "tf", ".", "reshape", "(", "x_images", ",", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "x_images", "=", "tf", ".", "map_fn", "(", "lambda", "image", ":", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", ",", "x_images", ")", "\n", "x_images", "=", "tf", ".", "reshape", "(", "x_images", ",", "[", "-", "1", ",", "784", "]", ")", "\n", "", "return", "x_images", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.image_processing": [[24, 34], ["tensorflow.name_scope", "tensorflow.random_normal", "tensorflow.name_scope", "tensorflow.reshape", "tensorflow.random_crop", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.reshape", "tensorflow.shape"], "function", ["None"], ["", "def", "image_processing", "(", "x_images", ")", ":", "\n", "  ", "with", "tf", ".", "name_scope", "(", "'gaussian_noise'", ")", ":", "\n", "    ", "noise", "=", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "x_images", ")", ",", "mean", "=", "0.0", ",", "stddev", "=", "0.3", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "x_images", "=", "x_images", "+", "noise", "\n", "", "with", "tf", ".", "name_scope", "(", "'crop'", ")", ":", "\n", "    ", "x_images", "=", "tf", ".", "reshape", "(", "x_images", ",", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "x_images", "=", "tf", ".", "random_crop", "(", "x_images", ",", "[", "FLAGS", ".", "batch_size", ",", "25", ",", "25", ",", "1", "]", ")", "\n", "x_images", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "x_images", ",", "28", ",", "28", ")", "\n", "x_images", "=", "tf", ".", "reshape", "(", "x_images", ",", "[", "-", "1", ",", "784", "]", ")", "\n", "", "return", "x_images", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.deepnn": [[35, 76], ["tensorflow.placeholder", "semantic.standarization", "tensorflow.cond", "tensorflow.name_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.name_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.name_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.name_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.name_scope", "tensorflow.layers.batch_normalization", "tensorflow.name_scope", "tensorflow.nn.dropout", "tensorflow.name_scope", "tensorflow.contrib.layers.fully_connected", "semantic.image_processing", "tensorflow.contrib.layers.fully_connected"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.standarization", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.image_processing"], ["", "def", "deepnn", "(", "x_images", ")", ":", "\n", "  ", "\"\"\"deepnn builds the graph for a deep net for classifying digits.\n  Args:\n    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n    number of pixels in a standard MNIST image.\n  Returns:\n    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n    equal to the logits of classifying the digit into one of 10 classes (the\n    digits 0-9). keep_prob is a scalar placeholder for the probability of\n    dropout.\n  \"\"\"", "\n", "keep_prob", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "\n", "x_images", "=", "standarization", "(", "x_images", ")", "\n", "x_images", "=", "tf", ".", "cond", "(", "keep_prob", "<", "1.0", ",", "lambda", ":", "image_processing", "(", "x_images", ")", ",", "lambda", ":", "x_images", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'fc1'", ")", ":", "\n", "    ", "h_fc1", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "x_images", ",", "1000", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'fc2'", ")", ":", "\n", "    ", "h_fc2", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "h_fc1", ",", "500", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'fc3'", ")", ":", "\n", "    ", "h_fc3", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "h_fc2", ",", "250", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'fc4'", ")", ":", "\n", "    ", "h_fc4", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "h_fc3", ",", "250", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'fc5'", ")", ":", "\n", "    ", "h_fc5", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "h_fc4", ",", "250", ")", ")", "\n", "\n", "# Dropout - controls the complexity of the model, prevents co-adaptation of", "\n", "# features.", "\n", "", "with", "tf", ".", "name_scope", "(", "'dropout'", ")", ":", "\n", "    ", "h_fc5_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "h_fc5", ",", "keep_prob", ")", "\n", "\n", "# Map the 1024 features to 10 classes, one for each digit", "\n", "", "with", "tf", ".", "name_scope", "(", "'fc6'", ")", ":", "\n", "    ", "y_mlp", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "h_fc5_drop", ",", "10", ",", "activation_fn", "=", "None", ")", "\n", "\n", "", "return", "y_mlp", ",", "keep_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.conv2d": [[78, 81], ["tensorflow.nn.conv2d"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.conv2d"], ["", "def", "conv2d", "(", "x", ",", "W", ")", ":", "\n", "  ", "\"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.max_pool_2x2": [[83, 87], ["tensorflow.nn.max_pool"], "function", ["None"], ["", "def", "max_pool_2x2", "(", "x", ")", ":", "\n", "  ", "\"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"", "\n", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.weight_variable": [[89, 93], ["tensorflow.truncated_normal", "tensorflow.Variable"], "function", ["None"], ["", "def", "weight_variable", "(", "shape", ")", ":", "\n", "  ", "\"\"\"weight_variable generates a weight variable of a given shape.\"\"\"", "\n", "initial", "=", "tf", ".", "truncated_normal", "(", "shape", ",", "stddev", "=", "0.1", ")", "\n", "return", "tf", ".", "Variable", "(", "initial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.bias_variable": [[95, 99], ["tensorflow.constant", "tensorflow.Variable"], "function", ["None"], ["", "def", "bias_variable", "(", "shape", ")", ":", "\n", "  ", "\"\"\"bias_variable generates a bias variable of a given shape.\"\"\"", "\n", "initial", "=", "tf", ".", "constant", "(", "0.1", ",", "shape", "=", "shape", ")", "\n", "return", "tf", ".", "Variable", "(", "initial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.leakyRelu": [[100, 102], ["tensorflow.maximum"], "function", ["None"], ["", "def", "leakyRelu", "(", "value", ",", "alpha", "=", "0.01", ")", ":", "\n", "  ", "return", "tf", ".", "maximum", "(", "value", ",", "alpha", "*", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.main": [[103, 180], ["mnist_input.read_data_sets", "tensorflow.placeholder", "tensorflow.placeholder", "semantic.deepnn", "tensorflow.greater", "tensorflow.cast", "tensorflow.abs", "tensorflow.reduce_mean", "tempfile.mkdtemp", "print", "tensorflow.summary.FileWriter", "tf.summary.FileWriter.add_graph", "tensorflow.shape", "tensorflow.reduce_max", "tensorflow.zeros", "tensorflow.name_scope", "tensorflow.reduce_sum", "tensorflow.name_scope", "tensorflow.nn.sigmoid", "tensorflow.zeros", "range", "tensorflow.name_scope", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.name_scope", "tensorflow.equal", "tensorflow.cast", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.get_default_graph", "tensorflow.Session", "sess.run", "range", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.concat", "tensorflow.reduce_prod", "tensorflow.ones", "tensorflow.multiply", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.global_variables_initializer", "mnist_input.read_data_sets.train.next_batch", "sess.run", "tensorflow.train.AdamOptimizer", "accuracy.eval", "tensorflow.concat", "tensorflow.ones", "tensorflow.multiply", "tensorflow.multiply", "open", "print", "outFile.write", "open", "print", "outFile.write", "tensorflow.ones", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.read_data_sets", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.semantic.deepnn", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.SemiDataSet.next_batch"], ["", "def", "main", "(", "_", ")", ":", "\n", "# Import data", "\n", "  ", "mnist", "=", "read_data_sets", "(", "FLAGS", ".", "data_path", ",", "n_labeled", "=", "FLAGS", ".", "num_labeled", ",", "one_hot", "=", "True", ")", "\n", "\n", "# Create the model", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "784", "]", ")", "\n", "\n", "# Define loss and optimizer", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "10", "]", ")", "\n", "\n", "# Build the graph for the deep net", "\n", "y_mlp", ",", "keep_prob", "=", "deepnn", "(", "x", ")", "\n", "\n", "batch_number", "=", "tf", ".", "shape", "(", "y_mlp", ")", "[", "0", "]", "\n", "label_examples", "=", "tf", ".", "greater", "(", "tf", ".", "reduce_max", "(", "y_", ",", "axis", "=", "1", ")", ",", "tf", ".", "zeros", "(", "[", "batch_number", ",", "]", ")", ")", "\n", "label_examples", "=", "tf", ".", "cast", "(", "label_examples", ",", "tf", ".", "float32", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'cross_entropy'", ")", ":", "\n", "#cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_mlp)", "\n", "    ", "cross_entropy", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "y_", ",", "logits", "=", "y_mlp", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'wmc'", ")", ":", "\n", "    ", "normalized_logits", "=", "tf", ".", "nn", ".", "sigmoid", "(", "y_mlp", ")", "\n", "wmc_tmp", "=", "tf", ".", "zeros", "(", "[", "batch_number", ",", "]", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "one_situation", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "concat", "(", "[", "tf", ".", "ones", "(", "[", "batch_number", ",", "i", "]", ")", ",", "tf", ".", "zeros", "(", "[", "batch_number", ",", "1", "]", ")", "]", ",", "axis", "=", "1", ")", ",", "\n", "tf", ".", "ones", "(", "[", "batch_number", ",", "10", "-", "i", "-", "1", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "wmc_tmp", "+=", "tf", ".", "reduce_prod", "(", "one_situation", "-", "normalized_logits", ",", "axis", "=", "1", ")", "\n", "", "", "wmc_tmp", "=", "tf", ".", "abs", "(", "wmc_tmp", ")", "\n", "wmc", "=", "tf", ".", "reduce_mean", "(", "wmc_tmp", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'loss'", ")", ":", "\n", "    ", "unlabel_examples", "=", "tf", ".", "ones", "(", "[", "batch_number", ",", "]", ")", "-", "label_examples", "\n", "log_wmc", "=", "tf", ".", "log", "(", "wmc_tmp", ")", "\n", "loss", "=", "-", "0.0005", "*", "tf", ".", "multiply", "(", "unlabel_examples", ",", "log_wmc", ")", "-", "0.0005", "*", "tf", ".", "multiply", "(", "label_examples", ",", "log_wmc", ")", "+", "tf", ".", "multiply", "(", "label_examples", ",", "cross_entropy", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'adam_optimizer'", ")", ":", "\n", "    ", "train_step", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "1e-4", ")", ".", "minimize", "(", "loss", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'accuracy'", ")", ":", "\n", "    ", "correct_prediction", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "y_mlp", ",", "1", ")", ",", "tf", ".", "argmax", "(", "y_", ",", "1", ")", ")", "\n", "correct_prediction", "=", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", "\n", "correct_prediction", "=", "tf", ".", "multiply", "(", "correct_prediction", ",", "label_examples", ")", "\n", "", "accuracy", "=", "tf", ".", "reduce_sum", "(", "correct_prediction", ")", "/", "tf", ".", "reduce_sum", "(", "label_examples", ")", "\n", "\n", "graph_location", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "print", "(", "'Saving graph to: %s'", "%", "graph_location", ")", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "graph_location", ")", "\n", "train_writer", ".", "add_graph", "(", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "train_average_accuracy", ",", "train_average_wmc", ",", "train_average_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "for", "i", "in", "range", "(", "50000", ")", ":", "\n", "      ", "images", ",", "labels", "=", "mnist", ".", "train", ".", "next_batch", "(", "FLAGS", ".", "batch_size", ")", "\n", "_", ",", "train_accuracy", ",", "train_wmc", ",", "train_loss", "=", "sess", ".", "run", "(", "[", "train_step", ",", "accuracy", ",", "wmc", ",", "loss", "]", ",", "feed_dict", "=", "{", "x", ":", "images", ",", "y_", ":", "labels", ",", "keep_prob", ":", "0.5", "}", ")", "\n", "train_average_accuracy", "+=", "train_accuracy", "\n", "train_average_wmc", "+=", "train_wmc", "\n", "train_average_loss", "+=", "train_loss", "\n", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "        ", "train_average_accuracy", "/=", "100", "\n", "train_average_wmc", "/=", "100", "\n", "train_average_loss", "/=", "100", "\n", "with", "open", "(", "\"log.txt\"", ",", "'a'", ")", "as", "outFile", ":", "\n", "          ", "print", "(", "'step %d, training_accuracy %g, train_loss %g, wmc %g'", "%", "(", "i", ",", "train_average_accuracy", ",", "train_average_loss", ",", "train_average_wmc", ")", ")", "\n", "outFile", ".", "write", "(", "'step %d, training_accuracy %g, train_loss %g, wmc %g\\n'", "%", "(", "i", ",", "train_average_accuracy", ",", "train_average_loss", ",", "train_average_wmc", ")", ")", "\n", "train_average_accuracy", ",", "train_average_wmc", ",", "train_average_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "", "", "if", "i", "%", "500", "==", "0", ":", "\n", "\n", "          ", "test_accuracy", "=", "accuracy", ".", "eval", "(", "feed_dict", "=", "{", "\n", "x", ":", "mnist", ".", "test", ".", "images", ",", "y_", ":", "mnist", ".", "test", ".", "labels", ",", "keep_prob", ":", "1.0", "}", ")", "\n", "with", "open", "(", "\"log.txt\"", ",", "'a'", ")", "as", "outFile", ":", "\n", "            ", "print", "(", "'test accuracy %g'", "%", "(", "test_accuracy", ")", ")", "\n", "outFile", ".", "write", "(", "'test accuracy %g\\n'", "%", "(", "test_accuracy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.DataSet.__init__": [[75, 96], ["numpy.multiply.reshape", "numpy.multiply.astype", "numpy.multiply"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "images", ",", "labels", ",", "fake_data", "=", "False", ")", ":", "\n", "    ", "if", "fake_data", ":", "\n", "      ", "self", ".", "_num_examples", "=", "10000", "\n", "", "else", ":", "\n", "      ", "assert", "images", ".", "shape", "[", "0", "]", "==", "labels", ".", "shape", "[", "0", "]", ",", "(", "\n", "\"images.shape: %s labels.shape: %s\"", "%", "(", "images", ".", "shape", ",", "\n", "labels", ".", "shape", ")", ")", "\n", "self", ".", "_num_examples", "=", "images", ".", "shape", "[", "0", "]", "\n", "\n", "# Convert shape from [num examples, rows, columns, depth]", "\n", "# to [num examples, rows*columns] (assuming depth == 1)", "\n", "assert", "images", ".", "shape", "[", "3", "]", "==", "1", "\n", "images", "=", "images", ".", "reshape", "(", "images", ".", "shape", "[", "0", "]", ",", "\n", "images", ".", "shape", "[", "1", "]", "*", "images", ".", "shape", "[", "2", "]", ")", "\n", "# Convert from [0, 255] -> [0.0, 1.0].", "\n", "images", "=", "images", ".", "astype", "(", "numpy", ".", "float32", ")", "\n", "images", "=", "numpy", ".", "multiply", "(", "images", ",", "1.0", "/", "255.0", ")", "\n", "", "self", ".", "_images", "=", "images", "\n", "self", ".", "_labels", "=", "labels", "\n", "self", ".", "_epochs_completed", "=", "0", "\n", "self", ".", "_index_in_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.DataSet.images": [[97, 100], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "images", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_images", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.DataSet.labels": [[101, 104], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.DataSet.num_examples": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_examples", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.DataSet.epochs_completed": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "epochs_completed", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_epochs_completed", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.DataSet.next_batch": [[113, 136], ["numpy.arange", "numpy.random.shuffle", "xrange", "xrange", "xrange"], "methods", ["None"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ",", "fake_data", "=", "False", ")", ":", "\n", "    ", "\"\"\"Return the next `batch_size` examples from this data set.\"\"\"", "\n", "if", "fake_data", ":", "\n", "      ", "fake_image", "=", "[", "1.0", "for", "_", "in", "xrange", "(", "784", ")", "]", "\n", "fake_label", "=", "0", "\n", "return", "[", "fake_image", "for", "_", "in", "xrange", "(", "batch_size", ")", "]", ",", "[", "\n", "fake_label", "for", "_", "in", "xrange", "(", "batch_size", ")", "]", "\n", "", "start", "=", "self", ".", "_index_in_epoch", "\n", "self", ".", "_index_in_epoch", "+=", "batch_size", "\n", "if", "self", ".", "_index_in_epoch", ">", "self", ".", "_num_examples", ":", "\n", "# Finished epoch", "\n", "      ", "self", ".", "_epochs_completed", "+=", "1", "\n", "# Shuffle the data", "\n", "perm", "=", "numpy", ".", "arange", "(", "self", ".", "_num_examples", ")", "\n", "numpy", ".", "random", ".", "shuffle", "(", "perm", ")", "\n", "self", ".", "_images", "=", "self", ".", "_images", "[", "perm", "]", "\n", "self", ".", "_labels", "=", "self", ".", "_labels", "[", "perm", "]", "\n", "# Start next epoch", "\n", "start", "=", "0", "\n", "self", ".", "_index_in_epoch", "=", "batch_size", "\n", "assert", "batch_size", "<=", "self", ".", "_num_examples", "\n", "", "end", "=", "self", ".", "_index_in_epoch", "\n", "return", "self", ".", "_images", "[", "start", ":", "end", "]", ",", "self", ".", "_labels", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.SemiDataSet.__init__": [[138, 161], ["mnist_input.DataSet", "numpy.arange", "numpy.random.permutation", "numpy.array", "range", "mnist_input.DataSet", "numpy.zeros", "numpy.array.max", "list", "numpy.shape", "numpy.arange"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "images", ",", "labels", ",", "n_labeled", ")", ":", "\n", "        ", "self", ".", "n_labeled", "=", "n_labeled", "\n", "\n", "# Unlabled DataSet", "\n", "self", ".", "unlabeled_ds", "=", "DataSet", "(", "images", ",", "numpy", ".", "zeros", "(", "numpy", ".", "shape", "(", "labels", ")", ")", ")", "\n", "\n", "# Labeled DataSet", "\n", "self", ".", "num_examples", "=", "self", ".", "unlabeled_ds", ".", "num_examples", "\n", "indices", "=", "numpy", ".", "arange", "(", "self", ".", "num_examples", ")", "\n", "shuffled_indices", "=", "numpy", ".", "random", ".", "permutation", "(", "indices", ")", "\n", "images", "=", "images", "[", "shuffled_indices", "]", "\n", "labels", "=", "labels", "[", "shuffled_indices", "]", "\n", "y", "=", "numpy", ".", "array", "(", "[", "numpy", ".", "arange", "(", "10", ")", "[", "l", "==", "1", "]", "[", "0", "]", "for", "l", "in", "labels", "]", ")", "\n", "idx", "=", "indices", "[", "y", "==", "0", "]", "[", ":", "5", "]", "\n", "n_classes", "=", "y", ".", "max", "(", ")", "+", "1", "\n", "n_from_each_class", "=", "n_labeled", "//", "n_classes", "\n", "i_labeled", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "n_classes", ")", ":", "\n", "            ", "i", "=", "indices", "[", "y", "==", "c", "]", "[", ":", "n_from_each_class", "]", "\n", "i_labeled", "+=", "list", "(", "i", ")", "\n", "", "l_images", "=", "images", "[", "i_labeled", "]", "\n", "l_labels", "=", "labels", "[", "i_labeled", "]", "\n", "self", ".", "labeled_ds", "=", "DataSet", "(", "l_images", ",", "l_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.SemiDataSet.next_batch": [[162, 171], ["mnist_input.SemiDataSet.unlabeled_ds.next_batch", "numpy.vstack", "numpy.vstack", "int", "mnist_input.SemiDataSet.labeled_ds.next_batch", "mnist_input.SemiDataSet.labeled_ds.next_batch", "int"], "methods", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.SemiDataSet.next_batch", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.SemiDataSet.next_batch", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.SemiDataSet.next_batch"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "unlabeled_images", ",", "unlabeled_labels", "=", "self", ".", "unlabeled_ds", ".", "next_batch", "(", "int", "(", "0.5", "*", "batch_size", ")", ")", "\n", "if", "0.5", "*", "batch_size", ">", "self", ".", "n_labeled", ":", "\n", "            ", "labeled_images", ",", "labeled_labels", "=", "self", ".", "labeled_ds", ".", "next_batch", "(", "self", ".", "n_labeled", ")", "\n", "", "else", ":", "\n", "            ", "labeled_images", ",", "labeled_labels", "=", "self", ".", "labeled_ds", ".", "next_batch", "(", "int", "(", "0.5", "*", "batch_size", ")", ")", "\n", "", "images", "=", "numpy", ".", "vstack", "(", "[", "labeled_images", ",", "unlabeled_images", "]", ")", "\n", "labels", "=", "numpy", ".", "vstack", "(", "[", "labeled_labels", ",", "unlabeled_labels", "]", ")", "\n", "return", "images", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.maybe_download": [[12, 22], ["os.path.join", "os.path.exists", "os.mkdir", "os.path.exists", "urllib.urlretrieve", "os.stat", "print"], "function", ["None"], ["def", "maybe_download", "(", "filename", ",", "work_directory", ")", ":", "\n", "  ", "\"\"\"Download the data from Yann's website, unless it's already here.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "work_directory", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "work_directory", ")", "\n", "", "filepath", "=", "os", ".", "path", ".", "join", "(", "work_directory", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "    ", "filepath", ",", "_", "=", "urllib", ".", "urlretrieve", "(", "SOURCE_URL", "+", "filename", ",", "filepath", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Succesfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32": [[24, 27], ["numpy.dtype().newbyteorder", "numpy.frombuffer", "numpy.dtype", "bytestream.read"], "function", ["None"], ["", "def", "_read32", "(", "bytestream", ")", ":", "\n", "  ", "dt", "=", "numpy", ".", "dtype", "(", "numpy", ".", "uint32", ")", ".", "newbyteorder", "(", "'>'", ")", "\n", "return", "numpy", ".", "frombuffer", "(", "bytestream", ".", "read", "(", "4", ")", ",", "dtype", "=", "dt", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.extract_images": [[29, 45], ["print", "gzip.open", "mnist_input._read32", "mnist_input._read32", "mnist_input._read32", "mnist_input._read32", "bytestream.read", "numpy.frombuffer", "data.reshape.reshape", "ValueError"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32"], ["", "def", "extract_images", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Extract the images into a 4D uint8 numpy array [index, y, x, depth].\"\"\"", "\n", "print", "(", "'Extracting'", ",", "filename", ")", "\n", "with", "gzip", ".", "open", "(", "filename", ")", "as", "bytestream", ":", "\n", "    ", "magic", "=", "_read32", "(", "bytestream", ")", "\n", "if", "magic", "!=", "2051", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'Invalid magic number %d in MNIST image file: %s'", "%", "\n", "(", "magic", ",", "filename", ")", ")", "\n", "", "num_images", "=", "_read32", "(", "bytestream", ")", "\n", "rows", "=", "_read32", "(", "bytestream", ")", "\n", "cols", "=", "_read32", "(", "bytestream", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "rows", "*", "cols", "*", "num_images", ")", "\n", "data", "=", "numpy", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "numpy", ".", "uint8", ")", "\n", "data", "=", "data", ".", "reshape", "(", "num_images", ",", "rows", ",", "cols", ",", "1", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.dense_to_one_hot": [[47, 54], ["numpy.zeros", "numpy.arange", "labels_dense.ravel"], "function", ["None"], ["", "", "def", "dense_to_one_hot", "(", "labels_dense", ",", "num_classes", "=", "10", ")", ":", "\n", "  ", "\"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"", "\n", "num_labels", "=", "labels_dense", ".", "shape", "[", "0", "]", "\n", "index_offset", "=", "numpy", ".", "arange", "(", "num_labels", ")", "*", "num_classes", "\n", "labels_one_hot", "=", "numpy", ".", "zeros", "(", "(", "num_labels", ",", "num_classes", ")", ")", "\n", "labels_one_hot", ".", "flat", "[", "index_offset", "+", "labels_dense", ".", "ravel", "(", ")", "]", "=", "1", "\n", "return", "labels_one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.extract_labels": [[56, 71], ["print", "gzip.open", "mnist_input._read32", "mnist_input._read32", "bytestream.read", "numpy.frombuffer", "ValueError", "mnist_input.dense_to_one_hot"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input._read32", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.dense_to_one_hot"], ["", "def", "extract_labels", "(", "filename", ",", "one_hot", "=", "False", ")", ":", "\n", "  ", "\"\"\"Extract the labels into a 1D uint8 numpy array [index].\"\"\"", "\n", "print", "(", "'Extracting'", ",", "filename", ")", "\n", "with", "gzip", ".", "open", "(", "filename", ")", "as", "bytestream", ":", "\n", "    ", "magic", "=", "_read32", "(", "bytestream", ")", "\n", "if", "magic", "!=", "2049", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'Invalid magic number %d in MNIST label file: %s'", "%", "\n", "(", "magic", ",", "filename", ")", ")", "\n", "", "num_items", "=", "_read32", "(", "bytestream", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "num_items", ")", "\n", "labels", "=", "numpy", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "numpy", ".", "uint8", ")", "\n", "if", "one_hot", ":", "\n", "      ", "return", "dense_to_one_hot", "(", "labels", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.read_data_sets": [[172, 211], ["DataSets", "mnist_input.maybe_download", "mnist_input.extract_images", "mnist_input.maybe_download", "mnist_input.extract_labels", "mnist_input.maybe_download", "mnist_input.extract_images", "mnist_input.maybe_download", "mnist_input.extract_labels", "mnist_input.SemiDataSet", "mnist_input.DataSet", "mnist_input.DataSet", "mnist_input.DataSet", "mnist_input.DataSet", "mnist_input.DataSet"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.maybe_download", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.extract_images", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.maybe_download", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.extract_labels", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.maybe_download", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.extract_images", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.maybe_download", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.semi_supervised.mnist_input.extract_labels"], ["", "", "def", "read_data_sets", "(", "train_dir", ",", "n_labeled", "=", "100", ",", "fake_data", "=", "False", ",", "one_hot", "=", "False", ")", ":", "\n", "  ", "class", "DataSets", "(", "object", ")", ":", "\n", "    ", "pass", "\n", "", "data_sets", "=", "DataSets", "(", ")", "\n", "\n", "if", "fake_data", ":", "\n", "    ", "data_sets", ".", "train", "=", "DataSet", "(", "[", "]", ",", "[", "]", ",", "fake_data", "=", "True", ")", "\n", "data_sets", ".", "validation", "=", "DataSet", "(", "[", "]", ",", "[", "]", ",", "fake_data", "=", "True", ")", "\n", "data_sets", ".", "test", "=", "DataSet", "(", "[", "]", ",", "[", "]", ",", "fake_data", "=", "True", ")", "\n", "return", "data_sets", "\n", "\n", "", "TRAIN_IMAGES", "=", "'train-images-idx3-ubyte.gz'", "\n", "TRAIN_LABELS", "=", "'train-labels-idx1-ubyte.gz'", "\n", "TEST_IMAGES", "=", "'t10k-images-idx3-ubyte.gz'", "\n", "TEST_LABELS", "=", "'t10k-labels-idx1-ubyte.gz'", "\n", "VALIDATION_SIZE", "=", "0", "\n", "\n", "local_file", "=", "maybe_download", "(", "TRAIN_IMAGES", ",", "train_dir", ")", "\n", "train_images", "=", "extract_images", "(", "local_file", ")", "\n", "\n", "local_file", "=", "maybe_download", "(", "TRAIN_LABELS", ",", "train_dir", ")", "\n", "train_labels", "=", "extract_labels", "(", "local_file", ",", "one_hot", "=", "one_hot", ")", "\n", "\n", "local_file", "=", "maybe_download", "(", "TEST_IMAGES", ",", "train_dir", ")", "\n", "test_images", "=", "extract_images", "(", "local_file", ")", "\n", "\n", "local_file", "=", "maybe_download", "(", "TEST_LABELS", ",", "train_dir", ")", "\n", "test_labels", "=", "extract_labels", "(", "local_file", ",", "one_hot", "=", "one_hot", ")", "\n", "\n", "validation_images", "=", "train_images", "[", ":", "VALIDATION_SIZE", "]", "\n", "validation_labels", "=", "train_labels", "[", ":", "VALIDATION_SIZE", "]", "\n", "train_images", "=", "train_images", "[", "VALIDATION_SIZE", ":", "]", "\n", "train_labels", "=", "train_labels", "[", "VALIDATION_SIZE", ":", "]", "\n", "\n", "data_sets", ".", "train", "=", "SemiDataSet", "(", "train_images", ",", "train_labels", ",", "n_labeled", ")", "\n", "data_sets", ".", "validation", "=", "DataSet", "(", "validation_images", ",", "validation_labels", ")", "\n", "data_sets", ".", "test", "=", "DataSet", "(", "test_images", ",", "test_labels", ")", "\n", "\n", "return", "data_sets", "\n", "", ""]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.weight_variable": [[21, 23], ["tensorflow.Variable", "tensorflow.truncated_normal"], "function", ["None"], ["def", "weight_variable", "(", "shape", ")", ":", "\n", "  ", "return", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "shape", ",", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.bias_variable": [[24, 26], ["tensorflow.Variable", "tensorflow.truncated_normal"], "function", ["None"], ["", "def", "bias_variable", "(", "shape", ")", ":", "\n", "  ", "return", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "shape", ",", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.main": [[27, 164], ["grid_data.GridData", "tensorflow.placeholder", "W.append", "b.append", "range", "W.append", "b.append", "tensorflow.placeholder", "tensorflow.unstack", "tensorflow.unstack", "compute_mpe.CircuitMPE", "compute_mpe.CircuitMPE.get_tf_ac", "numpy.random.permutation", "numpy.zeros", "tensorflow.losses.sigmoid_cross_entropy", "sum", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.global_variables_initializer().run", "range", "tensorflow.equal", "tensorflow.reduce_mean", "tf.InteractiveSession.run", "print", "print", "print", "print", "grid_net.weight_variable", "grid_net.bias_variable", "ys.append", "ys.append", "W.append", "b.append", "grid_net.weight_variable", "grid_net.bias_variable", "tensorflow.nn.sigmoid", "tensorflow.losses.sigmoid_cross_entropy", "tf.InteractiveSession.run", "tensorflow.cast", "tensorflow.nn.sigmoid", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "sum", "tensorflow.nn.relu", "tensorflow.nn.sigmoid", "grid_net.weight_variable", "grid_net.bias_variable", "ys.append", "ys.append", "tensorflow.matmul", "int", "int", "tensorflow.nn.l2_loss", "tensorflow.train.AdamOptimizer", "tensorflow.log", "tensorflow.global_variables_initializer", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "print", "print", "print", "print", "numpy.array", "print", "numpy.array", "print", "print", "print", "tf.InteractiveSession.run", "print", "print", "print", "print", "tensorflow.reduce_mean", "tensorflow.nn.relu", "tensorflow.nn.sigmoid", "numpy.finfo", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "print", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.log", "tensorflow.log", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "print", "tf.InteractiveSession.run", "print", "print", "numpy.array", "print", "sys.exit", "numpy.sum", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "sum", "float", "sum", "float", "compute_mpe.CircuitMPE.compute_mpe_inst", "zip", "float", "float", "compute_mpe.CircuitMPE.compute_mpe_inst", "zip", "float", "float", "tensorflow.log", "tf.InteractiveSession.run", "tensorflow.reduce_mean", "float", "float", "tensorflow.nn.sigmoid", "numpy.abs", "numpy.sum", "float", "numpy.sum", "float", "numpy.sum", "numpy.sum", "tensorflow.reduce_mean", "tensorflow.log", "numpy.sum", "numpy.abs", "numpy.abs", "numpy.equal", "numpy.equal", "tensorflow.reduce_mean", "sum", "float", "compute_mpe.CircuitMPE.compute_mpe_inst", "zip", "float", "float", "numpy.array", "numpy.sum", "numpy.sum", "numpy.concatenate", "numpy.sum", "numpy.concatenate", "numpy.sum", "compute_mpe.CircuitMPE.weighted_model_count", "numpy.sum", "float", "numpy.sum", "numpy.abs", "numpy.abs", "numpy.array", "numpy.array", "numpy.abs", "numpy.abs", "zip", "numpy.abs", "numpy.equal", "numpy.array", "numpy.sum", "numpy.concatenate", "numpy.sum", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.abs", "numpy.array", "numpy.abs", "numpy.array"], "function", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.weight_variable", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.bias_variable", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.weight_variable", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.bias_variable", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.weight_variable", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_net.bias_variable"], ["", "def", "main", "(", "_", ")", ":", "\n", "# Import data", "\n", "# mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)", "\n", "  ", "grid_data", "=", "GridData", "(", "FLAGS", ".", "data", ")", "\n", "\n", "# Create the model", "\n", "# Input(16) - Layer 1(units)", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "40", "]", ")", "\n", "W", "=", "[", "]", "\n", "b", "=", "[", "]", "\n", "ys", "=", "[", "]", "\n", "W", ".", "append", "(", "weight_variable", "(", "[", "40", ",", "FLAGS", ".", "units", "]", ")", ")", "\n", "b", ".", "append", "(", "bias_variable", "(", "[", "FLAGS", ".", "units", "]", ")", ")", "\n", "if", "FLAGS", ".", "relu", ":", "\n", "    ", "ys", ".", "append", "(", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "x", ",", "W", "[", "0", "]", ")", "+", "b", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "    ", "ys", ".", "append", "(", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "x", ",", "W", "[", "0", "]", ")", "+", "b", "[", "0", "]", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "FLAGS", ".", "layers", ")", ":", "\n", "# Layer i(units) - Layer i+1(units)", "\n", "    ", "W", ".", "append", "(", "weight_variable", "(", "[", "FLAGS", ".", "units", ",", "FLAGS", ".", "units", "]", ")", ")", "\n", "b", ".", "append", "(", "bias_variable", "(", "[", "FLAGS", ".", "units", "]", ")", ")", "\n", "if", "FLAGS", ".", "relu", ":", "\n", "      ", "ys", ".", "append", "(", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "ys", "[", "i", "-", "1", "]", ",", "W", "[", "i", "]", ")", "+", "b", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "ys", ".", "append", "(", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "ys", "[", "i", "-", "1", "]", ",", "W", "[", "i", "]", ")", "+", "b", "[", "i", "]", ")", ")", "\n", "\n", "# Layer n(units) - Output(24)", "\n", "", "", "W", ".", "append", "(", "weight_variable", "(", "[", "FLAGS", ".", "units", ",", "24", "]", ")", ")", "\n", "b", ".", "append", "(", "bias_variable", "(", "[", "24", "]", ")", ")", "\n", "y", "=", "tf", ".", "matmul", "(", "ys", "[", "-", "1", "]", ",", "W", "[", "-", "1", "]", ")", "+", "b", "[", "-", "1", "]", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", "*", "10", "\n", "\n", "\n", "# Define loss and optimizer", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "24", "]", ")", "\n", "yu", "=", "tf", ".", "unstack", "(", "tf", ".", "nn", ".", "sigmoid", "(", "y", ")", ",", "axis", "=", "1", ")", "\n", "xu", "=", "tf", ".", "unstack", "(", "x", ",", "axis", "=", "1", ")", "\n", "\n", "# Create CircuitMPE instance for predictions", "\n", "cmpe", "=", "CircuitMPE", "(", "'4-grid-out.vtree.sd'", ",", "'4-grid-all-pairs-sd.sdd'", ")", "\n", "wmc", "=", "cmpe", ".", "get_tf_ac", "(", "[", "[", "1.0", "-", "ny", ",", "ny", "]", "for", "ny", "in", "yu", "+", "xu", "[", "24", ":", "]", "]", ")", "\n", "\n", "# Get supervised part (rest is unsupervised)", "\n", "perm", "=", "permutation", "(", "grid_data", ".", "train_data", ".", "shape", "[", "0", "]", ")", "\n", "sup_train_inds", "=", "perm", "[", ":", "int", "(", "grid_data", ".", "train_data", ".", "shape", "[", "0", "]", "*", "FLAGS", ".", "give_labels", ")", "]", "\n", "unsup_train_inds", "=", "perm", "[", "int", "(", "grid_data", ".", "train_data", ".", "shape", "[", "0", "]", "*", "FLAGS", ".", "give_labels", ")", ":", "]", "\n", "ce_weights", "=", "np", ".", "zeros", "(", "[", "grid_data", ".", "train_data", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "ce_weights", "[", "sup_train_inds", ",", ":", "]", "=", "1", "\n", "# cross_entropy = tf.reduce_mean(", "\n", "#     tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y))", "\n", "cross_entropy", "=", "tf", ".", "losses", ".", "sigmoid_cross_entropy", "(", "y_", ",", "y", ",", "weights", "=", "ce_weights", ")", "\n", "regularizers", "=", "sum", "(", "tf", ".", "nn", ".", "l2_loss", "(", "weights", ")", "for", "weights", "in", "W", ")", "\n", "if", "FLAGS", ".", "use_unlabeled", ":", "\n", "    ", "loss", "=", "cross_entropy", "-", "FLAGS", ".", "wmc", "*", "tf", ".", "log", "(", "tf", ".", "reduce_mean", "(", "wmc", ")", ")", "+", "FLAGS", ".", "l2_decay", "*", "regularizers", "\n", "", "else", ":", "\n", "    ", "loss", "=", "cross_entropy", "-", "FLAGS", ".", "wmc", "*", "tf", ".", "log", "(", "tf", ".", "reduce_mean", "(", "wmc", "*", "ce_weights", ")", ")", "+", "FLAGS", ".", "l2_decay", "*", "regularizers", "\n", "# train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)", "\n", "", "train_step", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", ")", ".", "minimize", "(", "loss", ")", "\n", "\n", "full_loss", "=", "tf", ".", "losses", ".", "sigmoid_cross_entropy", "(", "y_", ",", "y", ")", "-", "FLAGS", ".", "wmc", "*", "tf", ".", "log", "(", "tf", ".", "reduce_mean", "(", "wmc", ")", ")", "\n", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "\n", "# For early stopping", "\n", "prev_loss", "=", "1e15", "\n", "# Train", "\n", "for", "i", "in", "range", "(", "FLAGS", ".", "iters", ")", ":", "\n", "# batch_xs, batch_ys = grid_data.get_batch(32)", "\n", "    ", "batch_xs", ",", "batch_ys", "=", "grid_data", ".", "train_data", ",", "grid_data", ".", "train_labels", "\n", "# batch_xs, batch_ys = mnist.train.next_batch(100)", "\n", "sess", ".", "run", "(", "train_step", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "# Every 1k iterations check accuracy", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "      ", "print", "(", "\"After %d iterations\"", "%", "i", ")", "\n", "# Get outputs", "\n", "train_out", "=", "sess", ".", "run", "(", "tf", ".", "nn", ".", "sigmoid", "(", "y", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "train_data", "[", "sup_train_inds", ",", ":", "]", ",", "\n", "y_", ":", "grid_data", ".", "train_labels", "[", "sup_train_inds", ",", ":", "]", "}", ")", "\n", "valid_out", "=", "sess", ".", "run", "(", "tf", ".", "nn", ".", "sigmoid", "(", "y", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "valid_data", ",", "\n", "y_", ":", "grid_data", ".", "valid_labels", "}", ")", "\n", "# Percentage that are exactly right", "\n", "print", "(", "\"Percentage of training that are exactly right: %f\"", "%", "(", "sum", "(", "1", "for", "z", "in", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "train_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "train_labels", "[", "sup_train_inds", ",", ":", "]", ")", ",", "axis", "=", "1", ")", "if", "z", "==", "0", ")", "/", "float", "(", "sup_train_inds", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "print", "(", "\"Percentage of validation that are exactly right: %f\"", "%", "(", "sum", "(", "1", "for", "z", "in", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "valid_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "valid_labels", ")", ",", "axis", "=", "1", ")", "if", "z", "==", "0", ")", "/", "float", "(", "grid_data", ".", "valid_labels", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "\n", "# Percentage of individual labels that are right", "\n", "print", "(", "\"Percentage of individual labels in training that are right: %f\"", "%", "(", "1.", "-", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "train_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "train_labels", "[", "sup_train_inds", ",", ":", "]", ")", ")", "/", "float", "(", "sup_train_inds", ".", "shape", "[", "0", "]", "*", "grid_data", ".", "train_labels", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "print", "(", "\"Percentage of individual labels in validation that are right: %f\"", "%", "(", "1.", "-", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "valid_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "valid_labels", ")", ")", "/", "float", "(", "grid_data", ".", "valid_labels", ".", "shape", "[", "0", "]", "*", "grid_data", ".", "valid_labels", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "\n", "# MPE instatiation accuracy", "\n", "mpe_pred", "=", "np", ".", "array", "(", "[", "cmpe", ".", "compute_mpe_inst", "(", "[", "(", "1", "-", "p", ",", "p", ")", "for", "p", "in", "np", ".", "concatenate", "(", "(", "o", ",", "inp", "[", "24", ":", "]", ")", ")", "]", ")", "[", ":", "24", "]", "for", "o", ",", "inp", "in", "zip", "(", "train_out", ",", "grid_data", ".", "train_data", "[", "sup_train_inds", ",", ":", "]", ")", "]", ")", "\n", "print", "(", "\"Train MPE accuracy %f\"", "%", "(", "float", "(", "np", ".", "sum", "(", "np", ".", "equal", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "mpe_pred", "-", "grid_data", ".", "train_labels", "[", "sup_train_inds", ",", ":", "]", ")", ",", "axis", "=", "1", ")", ",", "0", ")", ")", ")", "/", "float", "(", "sup_train_inds", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "valid_mpe_pred", "=", "np", ".", "array", "(", "[", "cmpe", ".", "compute_mpe_inst", "(", "[", "(", "1", "-", "p", ",", "p", ")", "for", "p", "in", "np", ".", "concatenate", "(", "(", "o", ",", "inp", "[", "24", ":", "]", ")", ")", "]", ")", "[", ":", "24", "]", "for", "o", ",", "inp", "in", "zip", "(", "valid_out", ",", "grid_data", ".", "valid_data", ")", "]", ")", "\n", "print", "(", "\"Validation MPE accuracy %f\"", "%", "(", "float", "(", "np", ".", "sum", "(", "np", ".", "equal", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "valid_mpe_pred", "-", "grid_data", ".", "valid_labels", ")", ",", "axis", "=", "1", ")", ",", "0", ")", ")", ")", "/", "float", "(", "grid_data", ".", "valid_data", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "\n", "# Print Losses and WMC", "\n", "print", "(", "\"Supervised train loss: %f\"", "%", "sess", ".", "run", "(", "full_loss", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "train_data", "[", "sup_train_inds", ",", ":", "]", ",", "y_", ":", "grid_data", ".", "train_labels", "[", "sup_train_inds", ",", ":", "]", "}", ")", ")", "\n", "print", "(", "\"Train loss: %f\"", "%", "sess", ".", "run", "(", "full_loss", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "train_data", ",", "y_", ":", "grid_data", ".", "train_labels", "}", ")", ")", "\n", "valid_loss", "=", "sess", ".", "run", "(", "full_loss", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "valid_data", ",", "y_", ":", "grid_data", ".", "valid_labels", "}", ")", "\n", "print", "(", "\"Validation loss: %f\"", "%", "valid_loss", ")", "\n", "print", "(", "\"Train WMC: %f\"", "%", "sess", ".", "run", "(", "tf", ".", "log", "(", "tf", ".", "reduce_mean", "(", "wmc", ")", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "train_data", "[", "sup_train_inds", ",", ":", "]", ",", "y_", ":", "grid_data", ".", "train_labels", "[", "sup_train_inds", ",", ":", "]", "}", ")", ")", "\n", "if", "FLAGS", ".", "use_unlabeled", ":", "\n", "        ", "print", "(", "\"Unlabeled train WMC: %f\"", "%", "sess", ".", "run", "(", "tf", ".", "log", "(", "tf", ".", "reduce_mean", "(", "wmc", ")", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "train_data", "[", "unsup_train_inds", ",", ":", "]", ",", "y_", ":", "grid_data", ".", "train_labels", "[", "unsup_train_inds", ",", ":", "]", "}", ")", ")", "\n", "", "print", "(", "\"Validation WMC: %f\"", "%", "sess", ".", "run", "(", "tf", ".", "reduce_mean", "(", "wmc", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "valid_data", ",", "y_", ":", "grid_data", ".", "valid_labels", "}", ")", ")", "\n", "\n", "print", "(", "\"Percentage of predictions that follow constraint: %f\"", "%", "(", "float", "(", "np", ".", "sum", "(", "[", "cmpe", ".", "weighted_model_count", "(", "[", "(", "1", "-", "p", ",", "p", ")", "for", "p", "in", "np", ".", "concatenate", "(", "(", "o", ",", "inp", "[", "24", ":", "]", ")", ")", "]", ")", "for", "o", ",", "inp", "in", "zip", "(", "np", ".", "array", "(", "valid_out", "+", "0.5", ",", "int", ")", ",", "grid_data", ".", "valid_data", ")", "]", ")", ")", "/", "float", "(", "grid_data", ".", "valid_data", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "\n", "# Early stopping", "\n", "if", "FLAGS", ".", "early_stopping", ":", "\n", "        ", "if", "prev_loss", "<", "valid_loss", ":", "\n", "          ", "print", "(", "\"Stopping early\"", ")", "\n", "test_out", "=", "sess", ".", "run", "(", "tf", ".", "nn", ".", "sigmoid", "(", "y", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "test_data", ",", "y_", ":", "grid_data", ".", "test_labels", "}", ")", "\n", "print", "(", "\"Percentage of test that are exactly right: %f\"", "%", "(", "sum", "(", "1", "for", "z", "in", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "test_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "test_labels", ")", ",", "axis", "=", "1", ")", "if", "z", "==", "0", ")", "/", "float", "(", "grid_data", ".", "test_labels", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "print", "(", "\"Percentage of individual labels in test that are right: %f\"", "%", "(", "1.", "-", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "test_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "test_labels", ")", ")", "/", "float", "(", "grid_data", ".", "test_labels", ".", "shape", "[", "0", "]", "*", "grid_data", ".", "test_labels", ".", "shape", "[", "1", "]", ")", ")", ")", "\n", "test_mpe_pred", "=", "np", ".", "array", "(", "[", "cmpe", ".", "compute_mpe_inst", "(", "[", "(", "1", "-", "p", ",", "p", ")", "for", "p", "in", "np", ".", "concatenate", "(", "(", "o", ",", "inp", "[", "24", ":", "]", ")", ")", "]", ")", "[", ":", "24", "]", "for", "o", ",", "inp", "in", "zip", "(", "test_out", ",", "grid_data", ".", "test_data", ")", "]", ")", "\n", "print", "(", "\"Test MPE accuracy %f\"", "%", "(", "float", "(", "np", ".", "sum", "(", "np", ".", "equal", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "test_mpe_pred", "-", "grid_data", ".", "test_labels", ")", ",", "axis", "=", "1", ")", ",", "0", ")", ")", ")", "/", "float", "(", "grid_data", ".", "test_labels", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "else", ":", "\n", "          ", "prev_loss", "=", "valid_loss", "\n", "\n", "# Test trained model", "\n", "", "", "", "", "correct_prediction", "=", "tf", ".", "equal", "(", "y", ",", "y_", ")", "\n", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "# print(sess.run(W_1, feed_dict={x: mnist.test.images,", "\n", "# y_: mnist.test.labels}))", "\n", "\n", "\n", "train_out", "=", "sess", ".", "run", "(", "tf", ".", "nn", ".", "sigmoid", "(", "y", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "train_data", ",", "\n", "y_", ":", "grid_data", ".", "train_labels", "}", ")", "\n", "\n", "print", "(", "sess", ".", "run", "(", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "valid_data", ",", "\n", "y_", ":", "grid_data", ".", "valid_labels", "}", ")", ")", "\n", "print", "(", "sess", ".", "run", "(", "cross_entropy", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "valid_data", ",", "\n", "y_", ":", "grid_data", ".", "valid_labels", "}", ")", ")", "\n", "print", "(", "sess", ".", "run", "(", "tf", ".", "reduce_mean", "(", "wmc", ")", ",", "feed_dict", "=", "{", "x", ":", "grid_data", ".", "valid_data", ",", "\n", "y_", ":", "grid_data", ".", "valid_labels", "}", ")", ")", "\n", "\n", "print", "(", "sum", "(", "1", "for", "x", "in", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "train_out", "+", "0.5", ",", "int", ")", "-", "grid_data", ".", "train_labels", ")", ",", "axis", "=", "1", ")", "if", "x", "==", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.GridData.__init__": [[5, 54], ["numpy.random.seed", "numpy.random.permutation", "numpy.array", "numpy.array", "len", "numpy.random.seed", "open", "len", "line.strip().split", "data.append", "labels.append", "int", "int", "int", "int", "int", "numpy.concatenate", "len", "random.randrange", "int", "grid_data.to_one_hot", "line.strip", "int", "tokens[].split", "len", "paths[].split", "len", "len", "len", "len", "tokens[].split", "grid_data.to_one_hot", "grid_data.to_one_hot"], "methods", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.to_one_hot", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.to_one_hot", "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.to_one_hot"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "data", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "with", "open", "(", "data_path", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "if", "(", "tokens", "[", "0", "]", "!=", "''", ")", ":", "\n", "                    ", "removed", "=", "[", "int", "(", "x", ")", "for", "x", "in", "tokens", "[", "0", "]", ".", "split", "(", "'-'", ")", "]", "\n", "", "else", ":", "\n", "                    ", "removed", "=", "[", "]", "\n", "\n", "", "inp", "=", "[", "int", "(", "x", ")", "for", "x", "in", "tokens", "[", "1", "]", ".", "split", "(", "'-'", ")", "]", "\n", "paths", "=", "tokens", "[", "2", ":", "]", "\n", "data", ".", "append", "(", "np", ".", "concatenate", "(", "(", "to_one_hot", "(", "removed", ",", "24", ",", "True", ")", ",", "to_one_hot", "(", "inp", ",", "16", ")", ")", ")", ")", "\n", "pathind", "=", "0", "\n", "if", "len", "(", "paths", ")", ">", "1", ":", "\n", "                    ", "pathind", "=", "random", ".", "randrange", "(", "len", "(", "paths", ")", ")", "\n", "", "path", "=", "[", "int", "(", "x", ")", "for", "x", "in", "paths", "[", "0", "]", ".", "split", "(", "'-'", ")", "]", "\n", "labels", ".", "append", "(", "to_one_hot", "(", "path", ",", "24", ")", ")", "\n", "\n", "\n", "# We're going to split 60/20/20 train/test/validation", "\n", "", "", "perm", "=", "permutation", "(", "len", "(", "data", ")", ")", "\n", "train_inds", "=", "perm", "[", ":", "int", "(", "len", "(", "data", ")", "*", "0.6", ")", "]", "\n", "valid_inds", "=", "perm", "[", "int", "(", "len", "(", "data", ")", "*", "0.6", ")", ":", "int", "(", "len", "(", "data", ")", "*", "0.8", ")", "]", "\n", "test_inds", "=", "perm", "[", "int", "(", "len", "(", "data", ")", "*", "0.8", ")", ":", "]", "\n", "self", ".", "data", "=", "np", ".", "array", "(", "data", ")", "\n", "self", ".", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "self", ".", "train_data", "=", "self", ".", "data", "[", "train_inds", ",", ":", "]", "\n", "self", ".", "valid_data", "=", "self", ".", "data", "[", "valid_inds", ",", ":", "]", "\n", "self", ".", "test_data", "=", "self", ".", "data", "[", "test_inds", ",", ":", "]", "\n", "self", ".", "train_labels", "=", "self", ".", "labels", "[", "train_inds", ",", ":", "]", "\n", "self", ".", "valid_labels", "=", "self", ".", "labels", "[", "valid_inds", ",", ":", "]", "\n", "self", ".", "test_labels", "=", "self", ".", "labels", "[", "test_inds", ",", ":", "]", "\n", "\n", "# Count what part of the batch we're attempt", "\n", "self", ".", "batch_ind", "=", "len", "(", "train_inds", ")", "\n", "self", ".", "batch_perm", "=", "None", "\n", "\n", "# print self.data.shape", "\n", "# print self.labels.shape", "\n", "# print self.valid_data.shape", "\n", "# print self.valid_labels.shape", "\n", "# print self.train_data.shape", "\n", "# print self.train_labels.shape", "\n", "# print self.test_data.shape", "\n", "# print self.test_labels.shape", "\n", "np", ".", "random", ".", "seed", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.GridData.get_batch": [[55, 76], ["numpy.random.permutation", "len", "grid_data.GridData.get_batch", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.GridData.get_batch"], ["", "def", "get_batch", "(", "self", ",", "size", ")", ":", "\n", "# If we're out:", "\n", "        ", "if", "self", ".", "batch_ind", ">=", "self", ".", "train_data", ".", "shape", "[", "0", "]", ":", "\n", "# Rerandomize ordering", "\n", "            ", "self", ".", "batch_perm", "=", "permutation", "(", "self", ".", "train_data", ".", "shape", "[", "0", "]", ")", "\n", "# Reset counter", "\n", "self", ".", "batch_ind", "=", "0", "\n", "\n", "# If there's not enough", "\n", "", "if", "self", ".", "train_data", ".", "shape", "[", "0", "]", "-", "self", ".", "batch_ind", "<", "size", ":", "\n", "# Get what there is, append whatever else you need", "\n", "            ", "ret_ind", "=", "self", ".", "batch_perm", "[", "self", ".", "batch_ind", ":", "]", "\n", "d", ",", "l", "=", "self", ".", "train_data", "[", "ret_ind", ",", ":", "]", ",", "self", ".", "train_labels", "[", "ret_ind", ",", ":", "]", "\n", "size", "-=", "len", "(", "ret_ind", ")", "\n", "self", ".", "batch_ind", "=", "self", ".", "train_data", ".", "shape", "[", "0", "]", "\n", "nd", ",", "nl", "=", "self", ".", "get_batch", "(", "size", ")", "\n", "return", "np", ".", "concatenate", "(", "d", ",", "nd", ")", ",", "np", ".", "concatenate", "(", "l", ",", "nl", ")", "\n", "\n", "# Normal case", "\n", "", "ret_ind", "=", "self", ".", "batch_perm", "[", "self", ".", "batch_ind", ":", "self", ".", "batch_ind", "+", "size", "]", "\n", "return", "self", ".", "train_data", "[", "ret_ind", ",", ":", "]", ",", "self", ".", "train_labels", "[", "ret_ind", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.UCLA-StarAI_Semantic-Loss.complex_constraints.grid_data.to_one_hot": [[77, 83], ["numpy.zeros"], "function", ["None"], ["", "", "def", "to_one_hot", "(", "dense", ",", "n", ",", "inv", "=", "False", ")", ":", "\n", "    ", "one_hot", "=", "np", ".", "zeros", "(", "n", ")", "\n", "one_hot", "[", "dense", "]", "=", "1", "\n", "if", "inv", ":", "\n", "        ", "one_hot", "=", "(", "one_hot", "+", "1", ")", "%", "2", "\n", "", "return", "one_hot", "\n", "\n"]]}