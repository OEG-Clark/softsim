{"home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.print_arguments": [[8, 14], ["print", "print", "vars", "print", "print", "getattr"], "function", ["None"], ["def", "print_arguments", "(", "args", ")", ":", "\n", "    ", "print", "(", "'='", "*", "100", ")", "\n", "print", "(", "'Arguments ='", ")", "\n", "for", "arg", "in", "vars", "(", "args", ")", ":", "\n", "        ", "print", "(", "'\\t'", "+", "arg", "+", "':'", ",", "getattr", "(", "args", ",", "arg", ")", ")", "\n", "", "print", "(", "'='", "*", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.print_model_report": [[16, 29], ["print", "print", "print", "model.parameters", "print", "print", "print", "print", "numpy.prod", "utils.human_format", "p.size", "p.size", "utils.human_format", "sum", "p.numel", "model.parameters"], "function", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.human_format", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.human_format"], ["", "def", "print_model_report", "(", "model", ")", ":", "\n", "    ", "print", "(", "'-'", "*", "100", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "'Dimensions ='", ",", "end", "=", "' '", ")", "\n", "count", "=", "0", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "print", "(", "p", ".", "size", "(", ")", ",", "end", "=", "' '", ")", "\n", "count", "+=", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "\n", "\n", "", "print", "(", ")", "\n", "print", "(", "'Num parameters = %s'", "%", "(", "human_format", "(", "count", ")", ")", ",", "human_format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", ")", ")", "\n", "print", "(", "'-'", "*", "100", ")", "\n", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.human_format": [[30, 36], ["abs"], "function", ["None"], ["", "def", "human_format", "(", "num", ")", ":", "\n", "    ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "        ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.1f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.is_number": [[39, 53], ["float", "unicodedata.numeric"], "function", ["None"], ["", "def", "is_number", "(", "s", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "float", "(", "s", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "pass", "\n", "", "try", ":", "\n", "        ", "import", "unicodedata", "\n", "unicodedata", ".", "numeric", "(", "s", ")", "\n", "return", "True", "\n", "", "except", "(", "TypeError", ",", "ValueError", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "False", "\n", "########################################################################################################################", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.save_log": [[56, 71], ["print", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "gzip.open", "pickle.dump", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "save_log", "(", "taskcla", ",", "acc", ",", "lss", ",", "data", ",", "output_path", ")", ":", "\n", "    ", "logs", "=", "{", "}", "\n", "# save task names", "\n", "logs", "[", "'task_name'", "]", "=", "{", "}", "\n", "logs", "[", "'test_acc'", "]", "=", "{", "}", "\n", "logs", "[", "'test_loss'", "]", "=", "{", "}", "\n", "for", "t", ",", "ncla", "in", "taskcla", ":", "\n", "        ", "logs", "[", "'task_name'", "]", "[", "t", "]", "=", "deepcopy", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "logs", "[", "'test_acc'", "]", "[", "t", "]", "=", "deepcopy", "(", "acc", "[", "t", ",", ":", "]", ")", "\n", "logs", "[", "'test_loss'", "]", "[", "t", "]", "=", "deepcopy", "(", "lss", "[", "t", ",", ":", "]", ")", "\n", "# pickle", "\n", "", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "'logs.p'", ")", ",", "'wb'", ")", "as", "output", ":", "\n", "        ", "pickle", ".", "dump", "(", "logs", ",", "output", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "print", "(", "\"Log file saved in \"", ",", "os", ".", "path", ".", "join", "(", "output_path", ",", "'logs.p'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.make_directories": [[72, 83], ["os.path.join", "print", "print", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir"], "function", ["None"], ["", "def", "make_directories", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "output", "==", "''", ":", "\n", "        ", "args", ".", "output", "=", "'{}_{}'", ".", "format", "(", "args", ".", "experiment", ",", "args", ".", "approach", ")", "\n", "print", "(", "args", ".", "output", ")", "\n", "", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "args", ".", "output", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "checkpoint_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "checkpoint_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint", ")", ":", "os", ".", "mkdir", "(", "checkpoint", ")", "\n", "print", "(", "\"Results will be saved in \"", ",", "checkpoint", ")", "\n", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.src.utils.print_log_acc_bwt": [[85, 123], ["print", "print", "range", "numpy.mean", "print", "print", "print", "print", "print", "print", "numpy.diag", "os.path.join", "print", "print", "range", "print", "open", "pickle.dump", "print", "numpy.diag"], "function", ["None"], ["", "def", "print_log_acc_bwt", "(", "args", ",", "acc", ",", "lss", ")", ":", "\n", "\n", "    ", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "'Accuracies ='", ")", "\n", "for", "i", "in", "range", "(", "acc", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "print", "(", "'\\t'", ",", "end", "=", "','", ")", "\n", "for", "j", "in", "range", "(", "acc", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "print", "(", "'{:5.4f}% '", ".", "format", "(", "acc", "[", "i", ",", "j", "]", ")", ",", "end", "=", "','", ")", "\n", "", "print", "(", ")", "\n", "\n", "", "avg_acc", "=", "np", ".", "mean", "(", "acc", "[", "acc", ".", "shape", "[", "0", "]", "-", "1", ",", ":", "]", ")", "\n", "print", "(", "'ACC: {:5.4f}%'", ".", "format", "(", "avg_acc", ")", ")", "\n", "print", "(", ")", "\n", "print", "(", ")", "\n", "\n", "ucb_bwt", "=", "(", "acc", "[", "-", "1", "]", "-", "np", ".", "diag", "(", "acc", ")", ")", ".", "mean", "(", ")", "\n", "print", "(", "'BWT : {:5.2f}%'", ".", "format", "(", "ucb_bwt", ")", ")", "\n", "\n", "print", "(", "'*'", "*", "100", ")", "\n", "print", "(", "'Done!'", ")", "\n", "\n", "logs", "=", "{", "}", "\n", "# save results", "\n", "logs", "[", "'name'", "]", "=", "args", ".", "experiment", "\n", "logs", "[", "'taskcla'", "]", "=", "args", ".", "taskcla", "\n", "logs", "[", "'acc'", "]", "=", "acc", "\n", "logs", "[", "'loss'", "]", "=", "lss", "\n", "logs", "[", "'bwt'", "]", "=", "ucb_bwt", "\n", "logs", "[", "'rii'", "]", "=", "np", ".", "diag", "(", "acc", ")", "\n", "logs", "[", "'rij'", "]", "=", "acc", "[", "-", "1", "]", "\n", "\n", "# pickle", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint", ",", "'{}_{}_seed_{}.p'", ".", "format", "(", "args", ".", "experiment", ",", "args", ".", "approach", ",", "args", ".", "seed", ")", ")", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "output", ":", "\n", "        ", "pickle", ".", "dump", "(", "logs", ",", "output", ")", "\n", "\n", "", "print", "(", "\"Log file saved in \"", ",", "path", ")", "\n", "return", "avg_acc", ",", "ucb_bwt", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BayesianConvs._ConvNd.__init__": [[12, 78], ["torch.Module.__init__", "distributions.VariationalPosterior().to", "distributions.Prior().to", "ValueError", "ValueError", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "distributions.VariationalPosterior().to", "BayesianConvs._ConvNd.register_parameter", "distributions.Prior().to", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.Tensor().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "distributions.VariationalPosterior", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "distributions.Prior", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "distributions.VariationalPosterior", "distributions.Prior", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "transposed", ",", "output_padding", ",", "groups", ",", "use_bias", ",", "args", ")", ":", "\n", "        ", "super", "(", "_ConvNd", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "in_channels", "%", "groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'in_channels must be divisible by groups'", ")", "\n", "", "if", "out_channels", "%", "groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'out_channels must be divisible by groups'", ")", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "transposed", "=", "transposed", "\n", "self", ".", "output_padding", "=", "output_padding", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "sig1", "=", "args", ".", "sig1", "\n", "self", ".", "sig2", "=", "args", ".", "sig2", "\n", "self", ".", "pi", "=", "args", ".", "pi", "\n", "self", ".", "rho", "=", "args", ".", "rho", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "\n", "\n", "if", "transposed", ":", "\n", "            ", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "in_channels", ",", "out_channels", "//", "groups", ",", "*", "kernel_size", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ")", "\n", "# self.weight_mu = nn.Parameter(torch.normal(mean=0., std=0.1, size=(in_channels, out_channels//groups, *kernel_size)))", "\n", "self", ".", "weight_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "torch", ".", "zeros", "(", "in_channels", ",", "out_channels", "//", "groups", ",", "*", "kernel_size", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ")", "\n", "\n", "", "else", ":", "\n", "# self.weight_mu = nn.Parameter(torch.Tensor(out_channels, in_channels//groups, *kernel_size).normal_(0., 0.1))", "\n", "\n", "            ", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "kernel_size", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "weight_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "torch", ".", "empty", "(", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "kernel_size", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "# self.weight_mu = nn.Parameter(torch.normal(mean=0., std=0.1, size=(out_channels, in_channels//groups, *kernel_size)))", "\n", "# self.weight_rho = nn.Parameter(self.rho + torch.zeros(out_channels, in_channels//groups,*kernel_size).normal_(0., 0.1))", "\n", "\n", "", "self", ".", "weight", "=", "VariationalPosterior", "(", "self", ".", "weight_mu", ",", "self", ".", "weight_rho", ",", "self", ".", "device", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "# Bias parameters [out_channel]", "\n", "if", "self", ".", "use_bias", ":", "\n", "# self.bias_mu = nn.Parameter(torch.Tensor(self.out_channels).normal_(0., 0.1))", "\n", "# self.bias_mu = nn.Parameter(torch.zeros(self.out_channels).normal_(0., 0.1))", "\n", "# self.bias_rho = nn.Parameter(self.rho + torch.zeros(self.out_channels).normal_(0., 0.1))", "\n", "            ", "self", ".", "bias_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "(", "self", ".", "out_channels", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bias_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "self", ".", "out_channels", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "bias", "=", "VariationalPosterior", "(", "self", ".", "bias_mu", ",", "self", ".", "bias_rho", ",", "self", ".", "device", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "# Prior distributions", "\n", "", "self", ".", "weight_prior", "=", "Prior", "(", "args", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "use_bias", ":", "\n", "            ", "self", ".", "bias_prior", "=", "Prior", "(", "args", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "log_prior", "=", "0", "\n", "self", ".", "log_variational_posterior", "=", "0", "\n", "\n", "self", ".", "mask_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BayesianConvs.BayesianConv2D.__init__": [[82, 89], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "BayesianConvs._ConvNd.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "args", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "use_bias", "=", "True", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "BayesianConv2D", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "False", ",", "_pair", "(", "0", ")", ",", "groups", ",", "use_bias", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BayesianConvs.BayesianConv2D.prune_module": [[92, 95], ["BayesianConvs.BayesianConv2D.weight_mu.data.mul_"], "methods", ["None"], ["", "def", "prune_module", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask_flag", "=", "True", "\n", "self", ".", "pruned_weight_mu", "=", "self", ".", "weight_mu", ".", "data", ".", "mul_", "(", "mask", ")", "\n", "# self.pruned_weight_rho=self.weight_rho.data.mul_(mask)", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BayesianConvs.BayesianConv2D.forward": [[99, 125], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "distributions.VariationalPosterior", "BayesianConvs.BayesianConv2D.weight.sample", "BayesianConvs.BayesianConv2D.bias.sample", "BayesianConvs.BayesianConv2D.weight_prior.log_prob", "BayesianConvs.BayesianConv2D.weight.log_prob", "BayesianConvs.BayesianConv2D.weight_prior.log_prob", "BayesianConvs.BayesianConv2D.bias_prior.log_prob", "BayesianConvs.BayesianConv2D.weight.log_prob", "BayesianConvs.BayesianConv2D.bias.log_prob"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob"], ["", "def", "forward", "(", "self", ",", "input", ",", "sample", "=", "False", ",", "calculate_log_probs", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "mask_flag", ":", "\n", "            ", "self", ".", "weight", "=", "VariationalPosterior", "(", "self", ".", "pruned_weight_mu", ",", "self", ".", "weight_rho", ",", "self", ".", "device", ")", "\n", "# if self.use_bias:", "\n", "#     self.bias = VariationalPosterior(self.bias_mu, self.bias_rho)", "\n", "\n", "", "if", "self", ".", "training", "or", "sample", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "sample", "(", ")", "\n", "bias", "=", "self", ".", "bias", ".", "sample", "(", ")", "if", "self", ".", "use_bias", "else", "None", "\n", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "mu", "\n", "bias", "=", "self", ".", "bias", ".", "mu", "if", "self", ".", "use_bias", "else", "None", "\n", "\n", "", "if", "self", ".", "training", "or", "calculate_log_probs", ":", "\n", "            ", "if", "self", ".", "use_bias", ":", "\n", "                ", "self", ".", "log_prior", "=", "self", ".", "weight_prior", ".", "log_prob", "(", "weight", ")", "+", "self", ".", "bias_prior", ".", "log_prob", "(", "bias", ")", "\n", "self", ".", "log_variational_posterior", "=", "self", ".", "weight", ".", "log_prob", "(", "weight", ")", "+", "self", ".", "bias", ".", "log_prob", "(", "bias", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "log_prior", "=", "self", ".", "weight_prior", ".", "log_prob", "(", "weight", ")", "\n", "self", ".", "log_variational_posterior", "=", "self", ".", "weight", ".", "log_prob", "(", "weight", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "log_prior", ",", "self", ".", "log_variational_posterior", "=", "0", ",", "0", "\n", "\n", "", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "bias", ",", "self", ".", "stride", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.FC.BayesianLinear.__init__": [[13, 47], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "distributions.VariationalPosterior", "distributions.Prior", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "distributions.VariationalPosterior", "FC.BayesianLinear.register_parameter", "distributions.Prior", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "args", ",", "use_bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "BayesianLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "self", ".", "rho", "=", "args", ".", "rho", "\n", "\n", "# Variational Posterior Distributions", "\n", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "(", "out_features", ",", "in_features", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "weight_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "torch", ".", "empty", "(", "(", "out_features", ",", "in_features", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "weight", "=", "VariationalPosterior", "(", "self", ".", "weight_mu", ",", "self", ".", "weight_rho", ",", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "use_bias", ":", "\n", "            ", "self", ".", "bias_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "(", "out_features", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bias_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "out_features", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "bias", "=", "VariationalPosterior", "(", "self", ".", "bias_mu", ",", "self", ".", "bias_rho", ",", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "# Prior Distributions", "\n", "", "self", ".", "weight_prior", "=", "Prior", "(", "args", ")", "\n", "if", "self", ".", "use_bias", ":", "\n", "            ", "self", ".", "bias_prior", "=", "Prior", "(", "args", ")", "\n", "\n", "# Initialize log prior and log posterior", "\n", "", "self", ".", "log_prior", "=", "0", "\n", "self", ".", "log_variational_posterior", "=", "0", "\n", "\n", "self", ".", "mask_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.FC.BayesianLinear.prune_module": [[49, 53], ["FC.BayesianLinear.weight_mu.data.clone().mul_().to", "FC.BayesianLinear.weight_rho.data.clone().mul_().to", "FC.BayesianLinear.weight_mu.data.clone().mul_", "FC.BayesianLinear.weight_rho.data.clone().mul_", "FC.BayesianLinear.weight_mu.data.clone", "FC.BayesianLinear.weight_rho.data.clone"], "methods", ["None"], ["", "def", "prune_module", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask_flag", "=", "True", "\n", "self", ".", "pruned_weight_mu", "=", "self", ".", "weight_mu", ".", "data", ".", "clone", "(", ")", ".", "mul_", "(", "mask", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "pruned_weight_rho", "=", "self", ".", "weight_rho", ".", "data", ".", "clone", "(", ")", ".", "mul_", "(", "mask", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.FC.BayesianLinear.forward": [[55, 81], ["torch.linear", "torch.linear", "torch.linear", "distributions.VariationalPosterior", "FC.BayesianLinear.weight.sample", "FC.BayesianLinear.bias.sample", "FC.BayesianLinear.weight_prior.log_prob", "FC.BayesianLinear.weight.log_prob", "FC.BayesianLinear.weight_prior.log_prob", "FC.BayesianLinear.bias_prior.log_prob", "FC.BayesianLinear.weight.log_prob", "FC.BayesianLinear.bias.log_prob"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob"], ["", "def", "forward", "(", "self", ",", "input", ",", "sample", "=", "False", ",", "calculate_log_probs", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "mask_flag", ":", "\n", "            ", "self", ".", "weight", "=", "VariationalPosterior", "(", "self", ".", "pruned_weight_mu", ",", "self", ".", "pruned_weight_rho", ",", "self", ".", "device", ")", "\n", "# if self.use_bias:", "\n", "#     self.bias = VariationalPosterior(self.pruned_bias_mu, self.pruned_bias_rho)", "\n", "\n", "", "if", "self", ".", "training", "or", "sample", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "sample", "(", ")", "\n", "bias", "=", "self", ".", "bias", ".", "sample", "(", ")", "if", "self", ".", "use_bias", "else", "None", "\n", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "mu", "\n", "bias", "=", "self", ".", "bias", ".", "mu", "if", "self", ".", "use_bias", "else", "None", "\n", "\n", "", "if", "self", ".", "training", "or", "calculate_log_probs", ":", "\n", "            ", "if", "self", ".", "use_bias", ":", "\n", "                ", "self", ".", "log_prior", "=", "self", ".", "weight_prior", ".", "log_prob", "(", "weight", ")", "+", "self", ".", "bias_prior", ".", "log_prob", "(", "bias", ")", "\n", "self", ".", "log_variational_posterior", "=", "self", ".", "weight", ".", "log_prob", "(", "weight", ")", "+", "self", ".", "bias", ".", "log_prob", "(", "bias", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "log_prior", "=", "self", ".", "weight_prior", ".", "log_prob", "(", "weight", ")", "\n", "self", ".", "log_variational_posterior", "=", "self", ".", "weight", ".", "log_prob", "(", "weight", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "log_prior", ",", "self", ".", "log_variational_posterior", "=", "0", ",", "0", "\n", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BasicBlock.__init__": [[18, 27], ["torch.Module.__init__", "resnet_ucb.conv3x3", "BatchNorm.BayesianBatchNorm2d", "resnet_ucb.conv3x3", "BatchNorm.BayesianBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.conv3x3", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "args", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "args", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "BayesianBatchNorm2d", "(", "planes", ",", "args", ")", "\n", "# self.relu = nn.ReLU(inplace=True)", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "args", ")", "\n", "self", ".", "bn2", "=", "BayesianBatchNorm2d", "(", "planes", ",", "args", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BasicBlock.forward": [[28, 45], ["resnet_ucb.BasicBlock.conv1", "resnet_ucb.BasicBlock.bn1", "torch.relu", "torch.relu", "torch.relu", "resnet_ucb.BasicBlock.conv2", "resnet_ucb.BasicBlock.bn2", "torch.relu", "torch.relu", "torch.relu", "resnet_ucb.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ",", "sample", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ",", "sample", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ",", "sample", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ",", "sample", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.Bottleneck.__init__": [[50, 60], ["torch.Module.__init__", "BayesianConvs.BayesianConv2D", "BatchNorm.BayesianBatchNorm2d", "BayesianConvs.BayesianConv2D", "BatchNorm.BayesianBatchNorm2d", "BayesianConvs.BayesianConv2D", "BatchNorm.BayesianBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "args", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "BayesianConv2D", "(", "inplanes", ",", "planes", ",", "1", ",", "args", ",", "use_bias", "=", "True", ")", "\n", "self", ".", "bn1", "=", "BayesianBatchNorm2d", "(", "planes", ",", "args", ")", "\n", "self", ".", "conv2", "=", "BayesianConv2D", "(", "planes", ",", "planes", ",", "3", ",", "args", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "use_bias", "=", "True", ")", "\n", "self", ".", "bn2", "=", "BayesianBatchNorm2d", "(", "planes", ",", "args", ")", "\n", "self", ".", "conv3", "=", "BayesianConv2D", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "args", ",", "kernel_size", "=", "1", ",", "use_bias", "=", "True", ")", "\n", "self", ".", "bn3", "=", "BayesianBatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ",", "args", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.Bottleneck.forward": [[61, 82], ["resnet_ucb.Bottleneck.conv1", "resnet_ucb.Bottleneck.bn1", "torch.relu", "torch.relu", "torch.relu", "resnet_ucb.Bottleneck.conv2", "resnet_ucb.Bottleneck.bn2", "torch.relu", "torch.relu", "torch.relu", "resnet_ucb.Bottleneck.conv3", "resnet_ucb.Bottleneck.bn3", "torch.relu", "torch.relu", "torch.relu", "resnet_ucb.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ",", "sample", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ",", "sample", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ",", "inplace", "=", "True", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ",", "sample", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ",", "sample", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ",", "inplace", "=", "True", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ",", "sample", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ",", "sample", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "F", ".", "relu", "(", "out", ",", "inplace", "=", "True", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet.__init__": [[86, 113], ["torch.Module.__init__", "BayesianConvs.BayesianConv2D", "BatchNorm.BayesianBatchNorm2d", "resnet_ucb.BayesianResNet._make_layer", "resnet_ucb.BayesianResNet._make_layer", "resnet_ucb.BayesianResNet._make_layer", "resnet_ucb.BayesianResNet._make_layer", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "resnet_ucb.BayesianResNet.classifier.append", "FC.BayesianLinear"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet._make_layer", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet._make_layer", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet._make_layer", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "args", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "32", "\n", "super", "(", "BayesianResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "sig1", "=", "args", ".", "sig1", "\n", "self", ".", "sig2", "=", "args", ".", "sig2", "\n", "self", ".", "pi", "=", "args", ".", "pi", "\n", "self", ".", "rho", "=", "args", ".", "rho", "\n", "\n", "ncha", ",", "size", ",", "_", "=", "args", ".", "inputsize", "\n", "self", ".", "taskcla", "=", "args", ".", "taskcla", "\n", "\n", "self", ".", "num_ftrs", "=", "256", "*", "block", ".", "expansion", "\n", "\n", "self", ".", "conv1", "=", "BayesianConv2D", "(", "ncha", ",", "32", ",", "7", ",", "args", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "use_bias", "=", "True", ")", "\n", "self", ".", "bn1", "=", "BayesianBatchNorm2d", "(", "32", ",", "args", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "32", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "# self.fc = None", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "            ", "self", ".", "classifier", ".", "append", "(", "BayesianLinear", "(", "self", ".", "num_ftrs", ",", "n", ",", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet._make_layer": [[115, 131], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "BayesianConvs.BayesianConv2D", "BatchNorm.BayesianBatchNorm2d", "block"], "methods", ["None"], ["", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "BayesianConv2D", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "1", ",", "self", ".", "args", ",", "\n", "stride", "=", "stride", ",", "use_bias", "=", "True", ")", ",", "\n", "BayesianBatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ",", "self", ".", "args", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "self", ".", "args", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "self", ".", "args", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet.add_task": [[132, 134], ["FC.BayesianLinear"], "methods", ["None"], ["", "def", "add_task", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "classifier", "=", "BayesianLinear", "(", "self", ".", "num_ftrs", ",", "num_classes", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet.prune": [[135, 138], ["mask_modules.items", "module.prune_module"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm.prune_module"], ["", "def", "prune", "(", "self", ",", "mask_modules", ")", ":", "\n", "        ", "for", "module", ",", "mask", "in", "mask_modules", ".", "items", "(", ")", ":", "\n", "            ", "module", ".", "prune_module", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.BayesianResNet.forward": [[139, 156], ["resnet_ucb.BayesianResNet.conv1", "resnet_ucb.BayesianResNet.bn1", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "resnet_ucb.BayesianResNet.layer1", "resnet_ucb.BayesianResNet.layer2", "resnet_ucb.BayesianResNet.layer3", "resnet_ucb.BayesianResNet.layer4", "x.view.view.view", "x.view.view.size", "y.append", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ",", "sample", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ",", "sample", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ",", "inplace", "=", "True", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "3", ",", "2", ",", "1", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "            ", "y", ".", "append", "(", "self", ".", "classifier", "[", "t", "]", "(", "x", ",", "sample", ")", ")", "\n", "", "return", "[", "F", ".", "log_softmax", "(", "yy", ",", "dim", "=", "1", ")", "for", "yy", "in", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.conv3x3": [[11, 13], ["BayesianConvs.BayesianConv2D"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "args", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "BayesianConv2D", "(", "in_planes", ",", "out_planes", ",", "3", ",", "args", "=", "args", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "use_bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.resnet_ucb.Net": [[189, 191], ["resnet_ucb.BayesianResNet"], "function", ["None"], ["", "", "def", "Net", "(", "args", ")", ":", "\n", "    ", "return", "BayesianResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "args", ")", "", "", ""]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm.__init__": [[11, 69], ["torch.Module.__init__", "distributions.Prior", "distributions.Prior", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "distributions.VariationalPosterior", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "distributions.VariationalPosterior", "BatchNorm._BatchNorm.register_parameter", "BatchNorm._BatchNorm.register_parameter", "BatchNorm._BatchNorm.register_buffer", "BatchNorm._BatchNorm.register_buffer", "BatchNorm._BatchNorm.register_parameter", "BatchNorm._BatchNorm.register_parameter", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.zeros().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.empty().normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "args", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "\n", "track_running_stats", "=", "True", ",", "use_bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "_BatchNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "track_running_stats", "=", "track_running_stats", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "sig1", "=", "args", ".", "sig1", "\n", "self", ".", "sig2", "=", "args", ".", "sig2", "\n", "self", ".", "pi", "=", "args", ".", "pi", "\n", "self", ".", "rho", "=", "args", ".", "rho", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "\n", "if", "self", ".", "affine", ":", "\n", "# Weight parameters", "\n", "# self.weight_mu = nn.Parameter(torch.zeros(self.num_features).normal_(0., 0.1))", "\n", "# self.weight_rho = nn.Parameter(self.rho  + torch.zeros(self.num_features).normal_(0., 0.1))", "\n", "            ", "self", ".", "weight_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "(", "self", ".", "num_features", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "weight_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "torch", ".", "empty", "(", "(", "self", ".", "num_features", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "\n", "0.1", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "\n", "self", ".", "weight", "=", "VariationalPosterior", "(", "self", ".", "weight_mu", ",", "self", ".", "weight_rho", ",", "self", ".", "device", ")", "\n", "\n", "# Bias parameters [out_channel]", "\n", "# self.bias_mu = nn.Parameter(torch.zeros(self.num_features).normal_(0., 0.1))", "\n", "# self.bias_rho = nn.Parameter(self.rho  + torch.zeros(self.num_features).normal_(0., 0.1))", "\n", "self", ".", "bias_mu", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "(", "self", ".", "num_features", ")", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bias_rho", "=", "nn", ".", "Parameter", "(", "self", ".", "rho", "+", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "self", ".", "num_features", ",", "\n", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "normal_", "(", "0.", ",", "0.1", ")", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "bias", "=", "VariationalPosterior", "(", "self", ".", "bias_mu", ",", "self", ".", "bias_rho", ",", "self", ".", "device", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'weight'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "if", "self", ".", "track_running_stats", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "self", ".", "num_features", ")", ".", "normal_", "(", "0.", ",", "1.", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "zeros", "(", "self", ".", "num_features", ")", ".", "normal_", "(", "0.", ",", "1.", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'running_mean'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'running_var'", ",", "None", ")", "\n", "\n", "# Prior distributions", "\n", "", "self", ".", "weight_prior", "=", "Prior", "(", "args", ")", "\n", "self", ".", "bias_prior", "=", "Prior", "(", "args", ")", "\n", "\n", "self", ".", "log_prior", "=", "0", "\n", "self", ".", "log_variational_posterior", "=", "0", "\n", "\n", "self", ".", "mask_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm.prune_module": [[73, 76], ["BatchNorm._BatchNorm.weight_mu.data.mul_"], "methods", ["None"], ["", "def", "prune_module", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask_flag", "=", "True", "\n", "self", ".", "pruned_weight_mu", "=", "self", ".", "weight_mu", ".", "data", ".", "mul_", "(", "mask", ")", "\n", "# self.pruned_weight_rho=self.weight_rho.data.mul_(mask)", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm._check_input_dim": [[79, 81], ["None"], "methods", ["None"], ["", "def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm.forward": [[83, 107], ["BatchNorm._BatchNorm._check_input_dim", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "distributions.VariationalPosterior", "BatchNorm._BatchNorm.weight.sample", "BatchNorm._BatchNorm.bias.sample", "BatchNorm._BatchNorm.weight_prior.log_prob", "BatchNorm._BatchNorm.bias_prior.log_prob", "BatchNorm._BatchNorm.weight.log_prob", "BatchNorm._BatchNorm.bias.log_prob"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm.BayesianBatchNorm2d._check_input_dim", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob"], ["", "def", "forward", "(", "self", ",", "input", ",", "sample", "=", "False", ",", "calculate_log_probs", "=", "False", ")", ":", "\n", "        ", "self", ".", "_check_input_dim", "(", "input", ")", "\n", "if", "self", ".", "mask_flag", ":", "\n", "            ", "self", ".", "weight", "=", "VariationalPosterior", "(", "self", ".", "pruned_weight_mu", ",", "self", ".", "weight_rho", ",", "self", ".", "device", ")", "\n", "# if self.use_bias:", "\n", "#     self.bias = VariationalPosterior(self.bias_mu, self.bias_rho)", "\n", "\n", "\n", "\n", "", "if", "self", ".", "training", "or", "sample", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "sample", "(", ")", "\n", "bias", "=", "self", ".", "bias", ".", "sample", "(", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight", ".", "mu", "\n", "bias", "=", "self", ".", "bias", ".", "mu", "\n", "\n", "", "if", "self", ".", "training", "or", "calculate_log_probs", ":", "\n", "            ", "self", ".", "log_prior", "=", "self", ".", "weight_prior", ".", "log_prob", "(", "weight", ")", "+", "self", ".", "bias_prior", ".", "log_prob", "(", "bias", ")", "\n", "self", ".", "log_variational_posterior", "=", "self", ".", "weight", ".", "log_prob", "(", "weight", ")", "+", "self", ".", "bias", ".", "log_prob", "(", "bias", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "log_prior", ",", "self", ".", "log_variational_posterior", "=", "0", ",", "0", "\n", "\n", "", "return", "F", ".", "batch_norm", "(", "input", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "weight", ",", "bias", ",", "\n", "self", ".", "training", "or", "not", "self", ".", "track_running_stats", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm.extra_repr": [[109, 112], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'{num_features}, eps={eps}, momentum={momentum}, affine={affine}, '", "'track_running_stats={track_running_stats}'", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm.BayesianBatchNorm2d._check_input_dim": [[116, 120], ["input.dim", "ValueError", "input.dim"], "methods", ["None"], ["    ", "def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 4D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.mlp_ucb.BayesianMLP.__init__": [[8, 29], ["super().__init__", "FC.BayesianLinear", "torch.nn.ModuleList", "FC.BayesianLinear", "mlp_ucb.BayesianMLP.classifier.append", "FC.BayesianLinear"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "BayesianMLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "ncha", ",", "size", ",", "_", "=", "args", ".", "inputsize", "\n", "self", ".", "taskcla", "=", "args", ".", "taskcla", "\n", "self", ".", "samples", "=", "args", ".", "samples", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "self", ".", "sbatch", "=", "args", ".", "sbatch", "\n", "self", ".", "init_lr", "=", "args", ".", "lr", "\n", "# dim=60  #100k", "\n", "# dim=1200", "\n", "dim", "=", "args", ".", "nhid", "\n", "nlayers", "=", "args", ".", "nlayers", "\n", "\n", "self", ".", "fc1", "=", "BayesianLinear", "(", "ncha", "*", "size", "*", "size", ",", "dim", ",", "args", ")", "\n", "if", "nlayers", "==", "2", ":", "\n", "            ", "self", ".", "fc2", "=", "BayesianLinear", "(", "dim", ",", "dim", ",", "args", ")", "\n", "\n", "", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "t", ",", "n", "in", "self", ".", "taskcla", ":", "\n", "            ", "self", ".", "classifier", ".", "append", "(", "BayesianLinear", "(", "dim", ",", "n", ",", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.mlp_ucb.BayesianMLP.prune": [[31, 34], ["mask_modules.items", "module.prune_module"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.BatchNorm._BatchNorm.prune_module"], ["", "", "def", "prune", "(", "self", ",", "mask_modules", ")", ":", "\n", "        ", "for", "module", ",", "mask", "in", "mask_modules", ".", "items", "(", ")", ":", "\n", "            ", "module", ".", "prune_module", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.mlp_ucb.BayesianMLP.forward": [[36, 43], ["torch.nn.functional.relu.view", "torch.nn.functional.relu", "torch.nn.functional.relu.size", "mlp_ucb.BayesianMLP.fc1", "y.append", "torch.nn.functional.log_softmax"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "sample", "=", "False", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "self", ".", "fc1", "(", "x", ",", "sample", ")", ")", "\n", "y", "=", "[", "]", "\n", "for", "t", ",", "i", "in", "self", ".", "taskcla", ":", "\n", "            ", "y", ".", "append", "(", "self", ".", "classifier", "[", "t", "]", "(", "x", ",", "sample", ")", ")", "\n", "", "return", "[", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "yy", ",", "dim", "=", "1", ")", "for", "yy", "in", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.mlp_ucb.Net": [[45, 47], ["mlp_ucb.BayesianMLP"], "function", ["None"], ["", "", "def", "Net", "(", "args", ")", ":", "\n", "    ", "return", "BayesianMLP", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.__init__": [[6, 14], ["super().__init__", "mu.to", "rho.to", "torch.distributions.Normal", "torch.log1p().to", "torch.log1p", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mu", ",", "rho", ",", "device", ")", ":", "\n", "        ", "super", "(", "VariationalPosterior", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mu", "=", "mu", ".", "to", "(", "device", ")", "\n", "self", ".", "rho", "=", "rho", ".", "to", "(", "device", ")", "\n", "self", ".", "device", "=", "device", "\n", "# gaussian distribution to sample epsilon from", "\n", "self", ".", "normal", "=", "torch", ".", "distributions", ".", "Normal", "(", "0", ",", "1", ")", "\n", "self", ".", "sigma", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "self", ".", "rho", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample": [[15, 20], ["distributions.VariationalPosterior.normal.sample().to", "distributions.VariationalPosterior.normal.sample", "distributions.VariationalPosterior.rho.size"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "epsilon", "=", "self", ".", "normal", ".", "sample", "(", "self", ".", "rho", ".", "size", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# reparametrizarion trick for sampling from posterior", "\n", "posterior_sample", "=", "(", "self", ".", "mu", "+", "self", ".", "sigma", "*", "epsilon", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "posterior_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.VariationalPosterior.log_prob": [[21, 25], ["torch.log", "math.log", "math.sqrt"], "methods", ["None"], ["", "def", "log_prob", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "(", "-", "math", ".", "log", "(", "math", ".", "sqrt", "(", "2", "*", "math", ".", "pi", ")", ")", "\n", "-", "torch", ".", "log", "(", "self", ".", "sigma", ")", "\n", "-", "(", "(", "input", "-", "self", ".", "mu", ")", "**", "2", ")", "/", "(", "2", "*", "self", ".", "sigma", "**", "2", ")", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.__init__": [[33, 45], ["super().__init__", "torch.tensor", "torch.tensor", "torch.distributions.Normal", "torch.distributions.Normal", "math.exp", "math.exp"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "Prior", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sig1", "=", "args", ".", "sig1", "\n", "self", ".", "sig2", "=", "args", ".", "sig2", "\n", "self", ".", "pi", "=", "args", ".", "pi", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "\n", "self", ".", "s1", "=", "torch", ".", "tensor", "(", "[", "math", ".", "exp", "(", "-", "1.", "*", "self", ".", "sig1", ")", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "s2", "=", "torch", ".", "tensor", "(", "[", "math", ".", "exp", "(", "-", "1.", "*", "self", ".", "sig2", ")", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "self", ".", "gaussian1", "=", "torch", ".", "distributions", ".", "Normal", "(", "0", ",", "self", ".", "s1", ")", "\n", "self", ".", "gaussian2", "=", "torch", ".", "distributions", ".", "Normal", "(", "0", ",", "self", ".", "s2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob": [[47, 52], ["input.to.to.to", "torch.exp", "torch.exp", "torch.log().sum", "distributions.Prior.gaussian1.log_prob", "distributions.Prior.gaussian2.log_prob", "torch.log"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.networks.distributions.Prior.log_prob"], ["", "def", "log_prob", "(", "self", ",", "input", ")", ":", "\n", "        ", "input", "=", "input", ".", "to", "(", "self", ".", "device", ")", "\n", "prob1", "=", "torch", ".", "exp", "(", "self", ".", "gaussian1", ".", "log_prob", "(", "input", ")", ")", "\n", "prob2", "=", "torch", ".", "exp", "(", "self", ".", "gaussian2", ".", "log_prob", "(", "input", ")", ")", "\n", "return", "(", "torch", ".", "log", "(", "self", ".", "pi", "*", "prob1", "+", "(", "1.", "-", "self", ".", "pi", ")", "*", "prob2", ")", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.cifar.get": [[8, 101], ["os.path.join", "list", "print", "range", "data.keys", "data.keys", "os.path.isdir", "os.makedirs", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "range", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "range", "data.keys", "sklearn.utils.shuffle", "dict.fromkeys", "len", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "taskcla.append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "numpy.arange", "torch.load", "torch.load", "numpy.unique", "[].size", "sklearn.utils.shuffle", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "torch.stack().view", "torch.LongTensor().view", "torch.save", "torch.save", "os.path.join", "os.path.join", "[].numpy", "str", "str", "len", "target.cpu().numpy", "target.cpu().numpy", "os.path.join", "os.path.join", "os.path.expanduser", "os.path.expanduser", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.stack", "torch.LongTensor", "os.path.expanduser", "os.path.expanduser", "target.cpu", "target.cpu", "numpy.array", "str", "str", "str", "str"], "function", ["None"], ["def", "get", "(", "data_path", ",", "seed", "=", "0", ",", "pc_valid", "=", "0.10", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "size", "=", "[", "3", ",", "32", ",", "32", "]", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'binary_cifar'", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "\n", "# CIFAR10", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "CIFAR10", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "CIFAR10", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "for", "n", "in", "range", "(", "5", ")", ":", "\n", "            ", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar10'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "2", "\n", "data", "[", "n", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                ", "n", "=", "target", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "nn", "=", "n", "//", "2", "\n", "data", "[", "nn", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "nn", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "n", "%", "2", ")", "\n", "\n", "# CIFAR100", "\n", "", "", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "CIFAR100", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "CIFAR100", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "for", "n", "in", "range", "(", "5", ",", "10", ")", ":", "\n", "            ", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar100'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "20", "\n", "data", "[", "n", "]", "[", "'train'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "'test'", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                ", "n", "=", "target", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "nn", "=", "(", "n", "//", "20", ")", "+", "5", "\n", "data", "[", "nn", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "nn", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "n", "%", "20", ")", "\n", "\n", "# \"Unify\" and save", "\n", "", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "            ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "data", "[", "t", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "t", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", "\n", "data", "[", "t", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "t", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "torch", ".", "save", "(", "data", "[", "t", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "t", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "t", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "t", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "# Load binary files", "\n", "", "", "", "data", "=", "{", "}", "\n", "ids", "=", "list", "(", "shuffle", "(", "np", ".", "arange", "(", "10", ")", ",", "random_state", "=", "seed", ")", ")", "\n", "print", "(", "'Task order ='", ",", "ids", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "data", "[", "i", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "i", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "ids", "[", "i", "]", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "ids", "[", "i", "]", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "", "data", "[", "i", "]", "[", "'ncla'", "]", "=", "len", "(", "np", ".", "unique", "(", "data", "[", "i", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "numpy", "(", ")", ")", ")", "\n", "if", "data", "[", "i", "]", "[", "'ncla'", "]", "==", "2", ":", "\n", "            ", "data", "[", "i", "]", "[", "'name'", "]", "=", "'cifar10-'", "+", "str", "(", "ids", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "data", "[", "i", "]", "[", "'name'", "]", "=", "'cifar100-'", "+", "str", "(", "ids", "[", "i", "]", "-", "5", ")", "\n", "\n", "# Validation", "\n", "", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "seed", ")", ",", "dtype", "=", "int", ")", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "size", "\n", "", ""]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mnist5.get": [[8, 99], ["torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "range", "data.keys", "data.keys", "torch.utils.data.DataLoader", "[].clone", "[].clone", "taskcla.append", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "target.numpy", "torch.stack().view", "torch.LongTensor().view", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "[].append", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.stack", "torch.LongTensor", "numpy.array"], "function", ["None"], ["def", "get", "(", "data_path", ",", "seed", ",", "fixed_order", "=", "False", ",", "pc_valid", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "size", "=", "[", "1", ",", "28", ",", "28", "]", "\n", "\n", "# MNIST", "\n", "mean", "=", "(", "0.1307", ",", ")", "\n", "std", "=", "(", "0.3081", ",", ")", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "0", "]", "=", "{", "}", "\n", "data", "[", "0", "]", "[", "'name'", "]", "=", "'mnist-0-1'", "\n", "data", "[", "0", "]", "[", "'ncla'", "]", "=", "2", "\n", "data", "[", "1", "]", "=", "{", "}", "\n", "data", "[", "1", "]", "[", "'name'", "]", "=", "'mnist-2-3'", "\n", "data", "[", "1", "]", "[", "'ncla'", "]", "=", "2", "\n", "data", "[", "2", "]", "=", "{", "}", "\n", "data", "[", "2", "]", "[", "'name'", "]", "=", "'mnist-4-5'", "\n", "data", "[", "2", "]", "[", "'ncla'", "]", "=", "2", "\n", "data", "[", "3", "]", "=", "{", "}", "\n", "data", "[", "3", "]", "[", "'name'", "]", "=", "'mnist-6-7'", "\n", "data", "[", "3", "]", "[", "'ncla'", "]", "=", "2", "\n", "data", "[", "4", "]", "=", "{", "}", "\n", "data", "[", "4", "]", "[", "'name'", "]", "=", "'mnist-8-9'", "\n", "data", "[", "4", "]", "[", "'ncla'", "]", "=", "2", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "0", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "1", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "2", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "3", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "4", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "label", "=", "target", ".", "numpy", "(", ")", "\n", "if", "label", "==", "0", ":", "\n", "                ", "data", "[", "0", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "0", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "0", ")", "\n", "", "if", "label", "==", "1", ":", "\n", "                ", "data", "[", "0", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "0", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "1", ")", "\n", "\n", "", "if", "label", "==", "2", ":", "\n", "                ", "data", "[", "1", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "1", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "0", ")", "\n", "", "if", "label", "==", "3", ":", "\n", "                ", "data", "[", "1", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "1", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "1", ")", "\n", "\n", "", "if", "label", "==", "4", ":", "\n", "                ", "data", "[", "2", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "2", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "0", ")", "\n", "", "if", "label", "==", "5", ":", "\n", "                ", "data", "[", "2", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "2", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "1", ")", "\n", "\n", "", "if", "label", "==", "6", ":", "\n", "                ", "data", "[", "3", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "3", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "0", ")", "\n", "", "if", "label", "==", "7", ":", "\n", "                ", "data", "[", "3", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "3", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "1", ")", "\n", "\n", "", "if", "label", "==", "8", ":", "\n", "                ", "data", "[", "4", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "4", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "0", ")", "\n", "", "if", "label", "==", "9", ":", "\n", "                ", "data", "[", "4", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "4", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "1", ")", "\n", "\n", "\n", "# \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "range", "(", "5", ")", ":", "\n", "        ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Validation", "\n", "", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "clone", "(", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.pmnist.get": [[10, 83], ["numpy.array", "data.keys", "data.keys", "list", "sklearn.utils.shuffle", "os.path.isdir", "os.makedirs", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "enumerate", "print", "enumerate", "[].clone", "[].clone", "taskcla.append", "range", "print", "sys.stdout.flush", "dict.fromkeys", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torch.utils.data.DataLoader", "torch.stack().view", "torch.LongTensor().view", "torch.save", "torch.save", "torch.load", "torch.load", "torch.FloatTensor().view.view().numpy", "sklearn.utils.shuffle", "torch.FloatTensor().view", "[].append", "[].append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.stack", "torch.LongTensor", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "torch.FloatTensor().view.view", "torch.FloatTensor", "target.numpy", "numpy.array", "str", "str", "str", "str"], "function", ["None"], ["def", "get", "(", "seed", "=", "0", ",", "fixed_order", "=", "False", ",", "pc_valid", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "size", "=", "[", "1", ",", "28", ",", "28", "]", "\n", "\n", "nperm", "=", "10", "\n", "seeds", "=", "np", ".", "array", "(", "list", "(", "range", "(", "nperm", ")", ")", ",", "dtype", "=", "int", ")", "\n", "if", "not", "fixed_order", ":", "\n", "        ", "seeds", "=", "shuffle", "(", "seeds", ",", "random_state", "=", "seed", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'/home/sayna/scratch/sayna/data/binary_pmnist/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'/home/sayna/scratch/sayna/data/binary_pmnist'", ")", "\n", "# Pre-load", "\n", "# MNIST", "\n", "mean", "=", "(", "0.1307", ",", ")", "\n", "std", "=", "(", "0.3081", ",", ")", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "MNIST", "(", "'/scratch/sayna/data/'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "MNIST", "(", "'/scratch/sayna/data/'", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "for", "i", ",", "r", "in", "enumerate", "(", "seeds", ")", ":", "\n", "            ", "print", "(", "i", ",", "end", "=", "','", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "data", "[", "i", "]", "=", "{", "}", "\n", "data", "[", "i", "]", "[", "'name'", "]", "=", "'pmnist-{:d}'", ".", "format", "(", "i", ")", "\n", "data", "[", "i", "]", "[", "'ncla'", "]", "=", "10", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "i", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                    ", "aux", "=", "image", ".", "view", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "aux", "=", "shuffle", "(", "aux", ",", "random_state", "=", "r", "*", "100", "+", "i", ")", "\n", "image", "=", "torch", ".", "FloatTensor", "(", "aux", ")", ".", "view", "(", "size", ")", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "\n", "# \"Unify\" and save", "\n", "", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "data", "[", "i", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "i", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "i", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "torch", ".", "save", "(", "data", "[", "i", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'/scratch/sayna/data/binary_pmnist'", ")", ",", "'data'", "+", "str", "(", "r", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "i", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'/scratch/sayna/data/binary_pmnist'", ")", ",", "'data'", "+", "str", "(", "r", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "", "", "print", "(", ")", "\n", "\n", "", "else", ":", "\n", "\n", "# Load binary files", "\n", "        ", "for", "i", ",", "r", "in", "enumerate", "(", "seeds", ")", ":", "\n", "            ", "data", "[", "i", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "data", "[", "i", "]", "[", "'ncla'", "]", "=", "10", "\n", "data", "[", "i", "]", "[", "'name'", "]", "=", "'pmnist-{:d}'", ".", "format", "(", "i", ")", "\n", "\n", "# Load", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "data", "[", "i", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'/scratch/sayna/data/binary_pmnist'", ")", ",", "'data'", "+", "str", "(", "r", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "i", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "'/scratch/sayna/data/binary_pmnist'", ")", ",", "'data'", "+", "str", "(", "r", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "# Validation", "\n", "", "", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "clone", "(", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.TrafficSigns.__init__": [[277, 309], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.transpose", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "RuntimeError", "print", "mixture.TrafficSigns.download", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.download"], ["def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "        ", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "filename", "=", "\"traffic_signs_dataset.zip\"", "\n", "self", ".", "url", "=", "\"https://d17h27t6h515a5.cloudfront.net/topher/2016/October/580d53ce_traffic-sign-data/traffic-sign-data.zip\"", "\n", "# Other options for the same 32x32 pickled dataset", "\n", "# url=\"https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581faac4_traffic-signs-data/traffic-signs-data.zip\"", "\n", "# url_train=\"https://drive.google.com/open?id=0B5WIzrIVeL0WR1dsTC1FdWEtWFE\"", "\n", "# url_test=\"https://drive.google.com/open?id=0B5WIzrIVeL0WLTlPNlR2RG95S3c\"", "\n", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "            ", "if", "not", "download", ":", "\n", "               ", "raise", "RuntimeError", "(", "'Dataset not found. You can use download=True to download it'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Downloading from '", "+", "self", ".", "url", ")", "\n", "self", ".", "download", "(", ")", "\n", "\n", "", "", "training_file", "=", "'lab 2 data/train.p'", "\n", "testing_file", "=", "'lab 2 data/test.p'", "\n", "if", "train", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "training_file", ")", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "                ", "train", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "data", "=", "train", "[", "'features'", "]", "\n", "self", ".", "labels", "=", "train", "[", "'labels'", "]", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "testing_file", ")", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "                ", "test", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "data", "=", "test", "[", "'features'", "]", "\n", "self", ".", "labels", "=", "test", "[", "'labels'", "]", "\n", "\n", "", "self", ".", "data", "=", "np", ".", "transpose", "(", "self", ".", "data", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "#print(self.data.shape); sys.exit()", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.TrafficSigns.__getitem__": [[311, 326], ["PIL.Image.fromarray", "numpy.transpose", "mixture.TrafficSigns.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args: index (int): Index\n        Returns: tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "np", ".", "transpose", "(", "img", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.TrafficSigns.__len__": [[327, 329], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.TrafficSigns.download": [[330, 347], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "urllib.request.urlretrieve", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs"], "methods", ["None"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "import", "errno", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "root", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "\n", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "            ", "if", "e", ".", "errno", "==", "errno", ".", "EEXIST", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "", "", "urllib", ".", "request", ".", "urlretrieve", "(", "self", ".", "url", ",", "fpath", ")", "\n", "import", "zipfile", "\n", "zip_ref", "=", "zipfile", ".", "ZipFile", "(", "fpath", ",", "'r'", ")", "\n", "zip_ref", ".", "extractall", "(", "root", ")", "\n", "zip_ref", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.Facescrub.__init__": [[366, 405], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "train[].astype", "train[].astype", "test[].astype", "test[].astype", "RuntimeError", "print", "mixture.Facescrub.download", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.download"], ["def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "        ", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "filename", "=", "\"facescrub_100.zip\"", "\n", "self", ".", "url", "=", "\"https://github.com/nkundiushuti/facescrub_subset/blob/master/data/facescrub_100.zip?raw=true\"", "\n", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "            ", "if", "not", "download", ":", "\n", "               ", "raise", "RuntimeError", "(", "'Dataset not found. You can use download=True to download it'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Downloading from '", "+", "self", ".", "url", ")", "\n", "self", ".", "download", "(", ")", "\n", "\n", "", "", "training_file", "=", "'facescrub_train_100.pkl'", "\n", "testing_file", "=", "'facescrub_test_100.pkl'", "\n", "if", "train", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "training_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "# u = pickle._Unpickler(f)", "\n", "# u.encoding = 'latin1'", "\n", "# train  = u.load()", "\n", "                ", "train", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "data", "=", "train", "[", "'features'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "self", ".", "labels", "=", "train", "[", "'labels'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\"\"\"\n            print(self.data.shape)\n            print(self.data.mean())\n            print(self.data.std())\n            print(self.labels.max())\n            #\"\"\"", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "testing_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "# u = pickle._Unpickler(f)", "\n", "# u.encoding = 'latin1'", "\n", "# test  = u.load()", "\n", "                ", "test", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "data", "=", "test", "[", "'features'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "self", ".", "labels", "=", "test", "[", "'labels'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.Facescrub.__getitem__": [[406, 421], ["PIL.Image.fromarray", "numpy.transpose", "mixture.Facescrub.transform"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args: index (int): Index\n        Returns: tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "np", ".", "transpose", "(", "img", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.Facescrub.__len__": [[422, 424], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.Facescrub.download": [[425, 444], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "urllib.request.urlretrieve", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs"], "methods", ["None"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "import", "errno", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "root", ")", "\n", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "\n", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "            ", "if", "e", ".", "errno", "==", "errno", ".", "EEXIST", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "", "", "urllib", ".", "request", ".", "urlretrieve", "(", "self", ".", "url", ",", "fpath", ")", "\n", "\n", "import", "zipfile", "\n", "zip_ref", "=", "zipfile", ".", "ZipFile", "(", "fpath", ",", "'r'", ")", "\n", "zip_ref", ".", "extractall", "(", "root", ")", "\n", "zip_ref", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.__init__": [[463, 496], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "train[].astype", "train[].astype", "test[].astype", "test[].astype", "RuntimeError", "print", "mixture.notMNIST.download", "open", "pickle.load", "open", "pickle.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.download"], ["def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "        ", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "filename", "=", "\"notmnist.zip\"", "\n", "self", ".", "url", "=", "\"https://github.com/nkundiushuti/notmnist_convert/blob/master/notmnist.zip?raw=true\"", "\n", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "            ", "if", "not", "download", ":", "\n", "               ", "raise", "RuntimeError", "(", "'Dataset not found. You can use download=True to download it'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Downloading from '", "+", "self", ".", "url", ")", "\n", "self", ".", "download", "(", ")", "\n", "\n", "", "", "training_file", "=", "'notmnist_train.pkl'", "\n", "testing_file", "=", "'notmnist_test.pkl'", "\n", "if", "train", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "training_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "# u = pickle._Unpickler(f)", "\n", "# u.encoding = 'latin1'", "\n", "# train  = u.load()", "\n", "                ", "train", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "data", "=", "train", "[", "'features'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "self", ".", "labels", "=", "train", "[", "'labels'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "testing_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "# u = pickle._Unpickler(f)", "\n", "# u.encoding = 'latin1'", "\n", "# test  = u.load()", "\n", "                ", "test", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "data", "=", "test", "[", "'features'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "self", ".", "labels", "=", "test", "[", "'labels'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.__getitem__": [[498, 512], ["PIL.Image.fromarray", "mixture.notMNIST.transform"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args: index (int): Index\n        Returns: tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", "[", "0", "]", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.__len__": [[513, 515], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.notMNIST.download": [[516, 535], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "urllib.request.urlretrieve", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs"], "methods", ["None"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "import", "errno", "\n", "root", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "root", ")", "\n", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "filename", ")", "\n", "\n", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "root", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "            ", "if", "e", ".", "errno", "==", "errno", ".", "EEXIST", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "", "", "urllib", ".", "request", ".", "urlretrieve", "(", "self", ".", "url", ",", "fpath", ")", "\n", "\n", "import", "zipfile", "\n", "zip_ref", "=", "zipfile", ".", "ZipFile", "(", "fpath", ",", "'r'", ")", "\n", "zip_ref", ".", "extractall", "(", "root", ")", "\n", "zip_ref", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mixture.get": [[15, 247], ["numpy.arange", "print", "os.path.join", "os.path.join", "data.keys", "data.keys", "list", "os.path.isdir", "os.path.isdir", "os.makedirs", "os.makedirs", "enumerate", "enumerate", "numpy.arange", "numpy.array", "int", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "[].clone", "[].clone", "[].clone", "[].clone", "taskcla.append", "sklearn.utils.shuffle", "dict.fromkeys", "[].size", "sklearn.utils.shuffle", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.stack().view", "torch.stack().view", "torch.LongTensor().view", "torch.LongTensor().view", "torch.save", "torch.save", "torch.save", "torch.save", "torch.load", "torch.load", "torch.load", "torch.load", "len", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.SVHN", "torchvision.datasets.SVHN", "numpy.array", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "image.expand.expand", "[].append", "[].append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "mixture.FashionMNIST", "mixture.FashionMNIST", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy", "image.expand.size", "image.expand.size", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "mixture.TrafficSigns", "mixture.TrafficSigns", "str", "str", "str", "str", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "image.expand.expand", "[].append", "[].append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "mixture.Facescrub", "mixture.Facescrub", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "image.expand.size", "image.expand.size", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "mixture.notMNIST", "mixture.notMNIST", "print", "sys.exit", "print", "sys.exit", "target.numpy", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "[].append", "[].append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "image.expand.expand", "[].append", "[].append", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy", "image.expand.size", "image.expand.size", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "target.numpy"], "function", ["None"], ["def", "get", "(", "data_path", ",", "seed", "=", "0", ",", "pc_valid", "=", "0.15", ",", "fixed_order", "=", "True", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "size", "=", "[", "3", ",", "32", ",", "32", "]", "\n", "\n", "idata", "=", "np", ".", "arange", "(", "8", ")", "\n", "if", "not", "fixed_order", ":", "\n", "        ", "idata", "=", "list", "(", "shuffle", "(", "idata", ",", "random_state", "=", "seed", ")", ")", "\n", "", "print", "(", "'Task order ='", ",", "idata", ")", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "'binary_mixture'", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "# Pre-load", "\n", "for", "n", ",", "idx", "in", "enumerate", "(", "idata", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "# CIFAR10", "\n", "                ", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "CIFAR10", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "CIFAR10", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar10'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "elif", "idx", "==", "1", ":", "\n", "# CIFAR100", "\n", "                ", "mean", "=", "[", "x", "/", "255", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", "\n", "std", "=", "[", "x", "/", "255", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "CIFAR100", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "CIFAR100", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar100'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "100", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "elif", "idx", "==", "2", ":", "\n", "# MNIST", "\n", "#mean=(0.1307,) # Mean and std without including the padding", "\n", "#std=(0.3081,)", "\n", "                ", "mean", "=", "(", "0.1", ",", ")", "# Mean and std including the padding", "\n", "std", "=", "(", "0.2752", ",", ")", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "padding", "=", "2", ",", "fill", "=", "0", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "padding", "=", "2", ",", "fill", "=", "0", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'mnist'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "image", "=", "image", ".", "expand", "(", "1", ",", "3", ",", "image", ".", "size", "(", "2", ")", ",", "image", ".", "size", "(", "3", ")", ")", "# Create 3 equal channels", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "elif", "idx", "==", "3", ":", "\n", "# SVHN", "\n", "                ", "mean", "=", "[", "0.4377", ",", "0.4438", ",", "0.4728", "]", "\n", "std", "=", "[", "0.198", ",", "0.201", ",", "0.197", "]", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "SVHN", "(", "data_path", ",", "split", "=", "'train'", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "SVHN", "(", "data_path", ",", "split", "=", "'test'", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'svhn'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", "-", "1", ")", "\n", "\n", "", "", "", "elif", "idx", "==", "4", ":", "\n", "# FashionMNIST", "\n", "                ", "mean", "=", "(", "0.2190", ",", ")", "# Mean and std including the padding", "\n", "std", "=", "(", "0.3318", ",", ")", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "FashionMNIST", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/fashion_mnist'", ")", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "padding", "=", "2", ",", "fill", "=", "0", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "FashionMNIST", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/fashion_mnist'", ")", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "padding", "=", "2", ",", "fill", "=", "0", ")", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'fashion-mnist'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "image", "=", "image", ".", "expand", "(", "1", ",", "3", ",", "image", ".", "size", "(", "2", ")", ",", "image", ".", "size", "(", "3", ")", ")", "# Create 3 equal channels", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "elif", "idx", "==", "5", ":", "\n", "# Traffic signs", "\n", "                ", "mean", "=", "[", "0.3398", ",", "0.3117", ",", "0.3210", "]", "\n", "std", "=", "[", "0.2755", ",", "0.2647", ",", "0.2712", "]", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "TrafficSigns", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/traffic_signs'", ")", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "TrafficSigns", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/traffic_signs'", ")", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "# mean, var = utils.compute_mean_std_dataset(dat['train'])", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'traffic-signs'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "43", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "", "", "", "elif", "idx", "==", "6", ":", "\n", "# Facescrub 100 faces", "\n", "                ", "mean", "=", "[", "0.5163", ",", "0.5569", ",", "0.4695", "]", "\n", "std", "=", "[", "0.2307", ",", "0.2272", ",", "0.2479", "]", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "Facescrub", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/facescrub'", ")", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "Facescrub", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/facescrub'", ")", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "#mean, std = utils.compute_mean_std_dataset(dat['train']); print(mean,std); sys.exit()", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'facescrub'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "100", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "", "", "", "elif", "idx", "==", "7", ":", "\n", "# notMNIST A-J letters", "\n", "                ", "mean", "=", "(", "0.4254", ",", ")", "\n", "std", "=", "(", "0.4501", ",", ")", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "notMNIST", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/notmnist'", ")", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "notMNIST", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "'../data/traffic_signs'", ")", ",", "train", "=", "False", ",", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "#mean, std = utils.compute_mean_std_dataset(dat['train']); print(mean,std); sys.exit()", "\n", "data", "[", "n", "]", "=", "{", "}", "\n", "data", "[", "n", "]", "[", "'name'", "]", "=", "'notmnist'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                    ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "                        ", "image", "=", "image", ".", "expand", "(", "1", ",", "3", ",", "image", ".", "size", "(", "2", ")", ",", "image", ".", "size", "(", "3", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "target", ".", "numpy", "(", ")", "[", "0", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "print", "(", "'ERROR: Undefined data set'", ",", "n", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "#print(n,data[n]['name'],data[n]['ncla'],len(data[n]['train']['x']))", "\n", "\n", "# \"Unify\" and save", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "idx", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "torch", ".", "save", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "idx", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "\n", "# Load binary files", "\n", "        ", "for", "n", ",", "idx", "in", "enumerate", "(", "idata", ")", ":", "\n", "            ", "data", "[", "n", "]", "=", "dict", ".", "fromkeys", "(", "[", "'name'", ",", "'ncla'", ",", "'train'", ",", "'test'", "]", ")", "\n", "if", "idx", "==", "0", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar10'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "", "elif", "idx", "==", "1", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'cifar100'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "100", "\n", "", "elif", "idx", "==", "2", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'mnist'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "", "elif", "idx", "==", "3", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'svhn'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "", "elif", "idx", "==", "4", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'fashion-mnist'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "", "elif", "idx", "==", "5", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'traffic-signs'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "43", "\n", "", "elif", "idx", "==", "6", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'facescrub'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "100", "\n", "", "elif", "idx", "==", "7", ":", "\n", "                ", "data", "[", "n", "]", "[", "'name'", "]", "=", "'notmnist'", "\n", "data", "[", "n", "]", "[", "'ncla'", "]", "=", "10", "\n", "", "else", ":", "\n", "                ", "print", "(", "'ERROR: Undefined data set'", ",", "n", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "# Load", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "                ", "data", "[", "n", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "idx", ")", "+", "s", "+", "'x.bin'", ")", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "expanduser", "(", "path", ")", ",", "'data'", "+", "str", "(", "idx", ")", "+", "s", "+", "'y.bin'", ")", ")", "\n", "\n", "# Validation", "\n", "", "", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "r", "=", "np", ".", "arange", "(", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "np", ".", "array", "(", "shuffle", "(", "r", ",", "random_state", "=", "seed", ")", ",", "dtype", "=", "int", ")", "\n", "nvalid", "=", "int", "(", "pc_valid", "*", "len", "(", "r", ")", ")", "\n", "ivalid", "=", "torch", ".", "LongTensor", "(", "r", "[", ":", "nvalid", "]", ")", "\n", "itrain", "=", "torch", ".", "LongTensor", "(", "r", "[", "nvalid", ":", "]", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "ivalid", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", "[", "itrain", "]", ".", "clone", "(", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.dataloaders.mnist2.get": [[8, 62], ["torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "data.keys", "data.keys", "torch.utils.data.DataLoader", "[].clone", "[].clone", "taskcla.append", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torch.stack().view", "torch.LongTensor().view", "target.numpy", "[].append", "[].append", "[].append", "[].append", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.stack", "torch.LongTensor", "numpy.array"], "function", ["None"], ["def", "get", "(", "data_path", ",", "seed", ",", "fixed_order", "=", "False", ",", "pc_valid", "=", "0", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "taskcla", "=", "[", "]", "\n", "size", "=", "[", "1", ",", "28", ",", "28", "]", "\n", "\n", "# MNIST", "\n", "mean", "=", "(", "0.1307", ",", ")", "\n", "std", "=", "(", "0.3081", ",", ")", "\n", "dat", "=", "{", "}", "\n", "dat", "[", "'train'", "]", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "dat", "[", "'test'", "]", "=", "datasets", ".", "MNIST", "(", "data_path", ",", "train", "=", "False", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "mean", ",", "std", ")", "]", ")", ")", "\n", "data", "[", "0", "]", "=", "{", "}", "\n", "data", "[", "0", "]", "[", "'name'", "]", "=", "'mnist-0-4'", "\n", "data", "[", "0", "]", "[", "'ncla'", "]", "=", "5", "\n", "data", "[", "1", "]", "=", "{", "}", "\n", "data", "[", "1", "]", "[", "'name'", "]", "=", "'mnist-5-9'", "\n", "data", "[", "1", "]", "[", "'ncla'", "]", "=", "5", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dat", "[", "s", "]", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "drop_last", "=", "True", ")", "\n", "data", "[", "0", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "data", "[", "1", "]", "[", "s", "]", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "for", "image", ",", "target", "in", "loader", ":", "\n", "            ", "label", "=", "target", ".", "numpy", "(", ")", "[", "0", "]", "\n", "if", "label", "<", "5", ":", "\n", "                ", "data", "[", "0", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "0", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "label", ")", "\n", "", "else", ":", "\n", "                ", "data", "[", "1", "]", "[", "s", "]", "[", "'x'", "]", ".", "append", "(", "image", ")", "\n", "data", "[", "1", "]", "[", "s", "]", "[", "'y'", "]", ".", "append", "(", "label", "-", "5", ")", "\n", "\n", "\n", "\n", "# \"Unify\" and save", "\n", "", "", "", "for", "n", "in", "[", "0", ",", "1", "]", ":", "\n", "        ", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", "=", "torch", ".", "stack", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'x'", "]", ")", ".", "view", "(", "-", "1", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "size", "[", "2", "]", ")", "\n", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "data", "[", "n", "]", "[", "s", "]", "[", "'y'", "]", ",", "dtype", "=", "int", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Validation", "\n", "", "", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "data", "[", "t", "]", "[", "'valid'", "]", "=", "{", "}", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'x'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'x'", "]", ".", "clone", "(", ")", "\n", "data", "[", "t", "]", "[", "'valid'", "]", "[", "'y'", "]", "=", "data", "[", "t", "]", "[", "'train'", "]", "[", "'y'", "]", ".", "clone", "(", ")", "\n", "\n", "# Others", "\n", "", "n", "=", "0", "\n", "for", "t", "in", "data", ".", "keys", "(", ")", ":", "\n", "        ", "taskcla", ".", "append", "(", "(", "t", ",", "data", "[", "t", "]", "[", "'ncla'", "]", ")", ")", "\n", "n", "+=", "data", "[", "t", "]", "[", "'ncla'", "]", "\n", "", "data", "[", "'ncla'", "]", "=", "n", "\n", "\n", "return", "data", ",", "taskcla", ",", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.__init__": [[12, 35], ["ucb.Appr.find_modules_names", "ucb.Appr.find_modules_names"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.find_modules_names", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.find_modules_names"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "args", ",", "lr_min", "=", "1e-6", ",", "lr_factor", "=", "3", ",", "lr_patience", "=", "5", ",", "clipgrad", "=", "1000", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "self", ".", "lr_min", "=", "lr_min", "\n", "self", ".", "lr_factor", "=", "lr_factor", "\n", "self", ".", "lr_patience", "=", "lr_patience", "\n", "self", ".", "clipgrad", "=", "clipgrad", "\n", "\n", "self", ".", "init_lr", "=", "args", ".", "lr", "\n", "self", ".", "sbatch", "=", "args", ".", "sbatch", "\n", "self", ".", "nepochs", "=", "args", ".", "nepochs", "\n", "\n", "self", ".", "arch", "=", "args", ".", "arch", "\n", "self", ".", "samples", "=", "args", ".", "samples", "\n", "self", ".", "lambda_", "=", "1.", "\n", "\n", "self", ".", "output", "=", "args", ".", "output", "\n", "self", ".", "checkpoint", "=", "args", ".", "checkpoint", "\n", "self", ".", "experiment", "=", "args", ".", "experiment", "\n", "self", ".", "num_tasks", "=", "args", ".", "num_tasks", "\n", "\n", "self", ".", "modules_names_with_cls", "=", "self", ".", "find_modules_names", "(", "with_classifier", "=", "True", ")", "\n", "self", ".", "modules_names_without_cls", "=", "self", ".", "find_modules_names", "(", "with_classifier", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.train": [[38, 99], ["ucb.Appr.update_lr", "utils.BayesianSGD", "copy.deepcopy", "ucb.Appr.model.load_state_dict", "ucb.Appr.save_model", "ucb.Appr.model.state_dict", "range", "copy.deepcopy", "time.time", "ucb.Appr.train_epoch", "time.time", "ucb.Appr.eval", "time.time", "print", "ucb.Appr.eval", "print", "print", "print", "math.isnan", "math.isnan", "print", "copy.deepcopy", "print", "ucb.Appr.model.state_dict", "print", "ucb.Appr.update_lr", "utils.BayesianSGD", "xtrain.size", "xtrain.size", "print"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.update_lr", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.save_model", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.train_epoch", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.eval", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.eval", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.update_lr"], ["", "def", "train", "(", "self", ",", "t", ",", "xtrain", ",", "ytrain", ",", "xvalid", ",", "yvalid", ")", ":", "\n", "\n", "# Update the next learning rate for each parameter based on their uncertainty", "\n", "        ", "params_dict", "=", "self", ".", "update_lr", "(", "t", ")", "\n", "self", ".", "optimizer", "=", "BayesianSGD", "(", "params", "=", "params_dict", ")", "\n", "\n", "best_loss", "=", "np", ".", "inf", "\n", "\n", "# best_model=copy.deepcopy(self.model)", "\n", "best_model", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "lr", "=", "self", ".", "init_lr", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "\n", "\n", "# Loop epochs", "\n", "try", ":", "\n", "            ", "for", "e", "in", "range", "(", "self", ".", "nepochs", ")", ":", "\n", "# Train", "\n", "                ", "clock0", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "train_epoch", "(", "t", ",", "xtrain", ",", "ytrain", ")", "\n", "clock1", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_acc", "=", "self", ".", "eval", "(", "t", ",", "xtrain", ",", "ytrain", ")", "\n", "clock2", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'| Epoch {:3d}, time={:5.1f}ms/{:5.1f}ms | Train: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "e", "+", "1", ",", "\n", "1000", "*", "self", ".", "sbatch", "*", "(", "clock1", "-", "clock0", ")", "/", "xtrain", ".", "size", "(", "0", ")", ",", "1000", "*", "self", ".", "sbatch", "*", "(", "clock2", "-", "clock1", ")", "/", "xtrain", ".", "size", "(", "0", ")", ",", "\n", "train_loss", ",", "100", "*", "train_acc", ")", ",", "end", "=", "''", ")", "\n", "# Valid", "\n", "valid_loss", ",", "valid_acc", "=", "self", ".", "eval", "(", "t", ",", "xvalid", ",", "yvalid", ")", "\n", "print", "(", "' Valid: loss={:.3f}, acc={:5.1f}% |'", ".", "format", "(", "valid_loss", ",", "100", "*", "valid_acc", ")", ",", "end", "=", "''", ")", "\n", "\n", "if", "math", ".", "isnan", "(", "valid_loss", ")", "or", "math", ".", "isnan", "(", "train_loss", ")", ":", "\n", "                    ", "print", "(", "\"saved best model and quit because loss became nan\"", ")", "\n", "break", "\n", "\n", "# Adapt lr", "\n", "", "if", "valid_loss", "<", "best_loss", ":", "\n", "                    ", "best_loss", "=", "valid_loss", "\n", "best_model", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "patience", "=", "self", ".", "lr_patience", "\n", "print", "(", "' *'", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "                    ", "patience", "-=", "1", "\n", "if", "patience", "<=", "0", ":", "\n", "                        ", "lr", "/=", "self", ".", "lr_factor", "\n", "print", "(", "' lr={:.1e}'", ".", "format", "(", "lr", ")", ",", "end", "=", "''", ")", "\n", "if", "lr", "<", "self", ".", "lr_min", ":", "\n", "                            ", "print", "(", ")", "\n", "break", "\n", "", "patience", "=", "self", ".", "lr_patience", "\n", "\n", "params_dict", "=", "self", ".", "update_lr", "(", "t", ",", "adaptive_lr", "=", "True", ",", "lr", "=", "lr", ")", "\n", "self", ".", "optimizer", "=", "BayesianSGD", "(", "params", "=", "params_dict", ")", "\n", "\n", "", "", "print", "(", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# Restore best", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "copy", ".", "deepcopy", "(", "best_model", ")", ")", "\n", "self", ".", "save_model", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.update_lr": [[103, 133], ["params_dict.append", "name.split", "ucb.Appr.model.parameters", "len", "params_dict.append", "params_dict.append", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "torch.log1p", "params_dict.append", "params_dict.append", "params_dict.append", "params_dict.append", "len", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "len", "print", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "update_lr", "(", "self", ",", "t", ",", "lr", "=", "None", ",", "adaptive_lr", "=", "False", ")", ":", "\n", "        ", "params_dict", "=", "[", "]", "\n", "if", "t", "==", "0", ":", "\n", "            ", "params_dict", ".", "append", "(", "{", "'params'", ":", "self", ".", "model", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "init_lr", "}", ")", "\n", "", "else", ":", "\n", "            ", "for", "name", "in", "self", ".", "modules_names_without_cls", ":", "\n", "                ", "n", "=", "name", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "n", ")", "==", "1", ":", "\n", "                    ", "m", "=", "self", ".", "model", ".", "_modules", "[", "n", "[", "0", "]", "]", "\n", "", "elif", "len", "(", "n", ")", "==", "3", ":", "\n", "                    ", "m", "=", "self", ".", "model", ".", "_modules", "[", "n", "[", "0", "]", "]", ".", "_modules", "[", "n", "[", "1", "]", "]", ".", "_modules", "[", "n", "[", "2", "]", "]", "\n", "", "elif", "len", "(", "n", ")", "==", "4", ":", "\n", "                    ", "m", "=", "self", ".", "model", ".", "_modules", "[", "n", "[", "0", "]", "]", ".", "_modules", "[", "n", "[", "1", "]", "]", ".", "_modules", "[", "n", "[", "2", "]", "]", ".", "_modules", "[", "n", "[", "3", "]", "]", "\n", "", "else", ":", "\n", "                    ", "print", "(", "name", ")", "\n", "\n", "", "if", "adaptive_lr", "is", "True", ":", "\n", "                    ", "params_dict", ".", "append", "(", "{", "'params'", ":", "m", ".", "weight_rho", ",", "'lr'", ":", "lr", "}", ")", "\n", "params_dict", ".", "append", "(", "{", "'params'", ":", "m", ".", "bias_rho", ",", "'lr'", ":", "lr", "}", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "w_unc", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "m", ".", "weight_rho", ".", "data", ")", ")", "\n", "b_unc", "=", "torch", ".", "log1p", "(", "torch", ".", "exp", "(", "m", ".", "bias_rho", ".", "data", ")", ")", "\n", "\n", "params_dict", ".", "append", "(", "{", "'params'", ":", "m", ".", "weight_mu", ",", "'lr'", ":", "torch", ".", "mul", "(", "w_unc", ",", "self", ".", "init_lr", ")", "}", ")", "\n", "params_dict", ".", "append", "(", "{", "'params'", ":", "m", ".", "bias_mu", ",", "'lr'", ":", "torch", ".", "mul", "(", "b_unc", ",", "self", ".", "init_lr", ")", "}", ")", "\n", "params_dict", ".", "append", "(", "{", "'params'", ":", "m", ".", "weight_rho", ",", "'lr'", ":", "self", ".", "init_lr", "}", ")", "\n", "params_dict", ".", "append", "(", "{", "'params'", ":", "m", ".", "bias_rho", ",", "'lr'", ":", "self", ".", "init_lr", "}", ")", "\n", "\n", "", "", "", "return", "params_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.find_modules_names": [[135, 149], ["ucb.Appr.model.named_parameters", "set", "set.append", "name.startswith", "set.append", "name.split", "name.split"], "methods", ["None"], ["", "def", "find_modules_names", "(", "self", ",", "with_classifier", "=", "False", ")", ":", "\n", "        ", "modules_names", "=", "[", "]", "\n", "for", "name", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "with_classifier", "is", "False", ":", "\n", "                ", "if", "not", "name", ".", "startswith", "(", "'classifier'", ")", ":", "\n", "                    ", "n", "=", "name", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", "\n", "modules_names", ".", "append", "(", "'.'", ".", "join", "(", "n", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "n", "=", "name", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", "\n", "modules_names", ".", "append", "(", "'.'", ".", "join", "(", "n", ")", ")", "\n", "\n", "", "", "modules_names", "=", "set", "(", "modules_names", ")", "\n", "\n", "return", "modules_names", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.logs": [[150, 169], ["name.split", "len", "len", "len"], "methods", ["None"], ["", "def", "logs", "(", "self", ",", "t", ")", ":", "\n", "\n", "        ", "lp", ",", "lvp", "=", "0.0", ",", "0.0", "\n", "for", "name", "in", "self", ".", "modules_names_without_cls", ":", "\n", "            ", "n", "=", "name", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "n", ")", "==", "1", ":", "\n", "                ", "m", "=", "self", ".", "model", ".", "_modules", "[", "n", "[", "0", "]", "]", "\n", "", "elif", "len", "(", "n", ")", "==", "3", ":", "\n", "                ", "m", "=", "self", ".", "model", ".", "_modules", "[", "n", "[", "0", "]", "]", ".", "_modules", "[", "n", "[", "1", "]", "]", ".", "_modules", "[", "n", "[", "2", "]", "]", "\n", "", "elif", "len", "(", "n", ")", "==", "4", ":", "\n", "                ", "m", "=", "self", ".", "model", ".", "_modules", "[", "n", "[", "0", "]", "]", ".", "_modules", "[", "n", "[", "1", "]", "]", ".", "_modules", "[", "n", "[", "2", "]", "]", ".", "_modules", "[", "n", "[", "3", "]", "]", "\n", "\n", "", "lp", "+=", "m", ".", "log_prior", "\n", "lvp", "+=", "m", ".", "log_variational_posterior", "\n", "\n", "", "lp", "+=", "self", ".", "model", ".", "classifier", "[", "t", "]", ".", "log_prior", "\n", "lvp", "+=", "self", ".", "model", ".", "classifier", "[", "t", "]", ".", "log_variational_posterior", "\n", "\n", "return", "lp", ",", "lvp", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.train_epoch": [[171, 200], ["ucb.Appr.model.train", "numpy.arange", "numpy.random.shuffle", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "x.size", "len", "len", "ucb.Appr.elbo_loss().to", "ucb.Appr.model.cuda", "ucb.Appr.optimizer.zero_grad", "ucb.Appr.backward", "ucb.Appr.model.cuda", "ucb.Appr.optimizer.step", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "x[].to", "y[].to", "ucb.Appr.elbo_loss"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.train", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.step", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.elbo_loss"], ["", "def", "train_epoch", "(", "self", ",", "t", ",", "x", ",", "y", ")", ":", "\n", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "x", ".", "size", "(", "0", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "r", ")", "\n", "r", "=", "torch", ".", "LongTensor", "(", "r", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "num_batches", "=", "len", "(", "x", ")", "//", "self", ".", "sbatch", "\n", "j", "=", "0", "\n", "# Loop batches", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "r", ")", ",", "self", ".", "sbatch", ")", ":", "\n", "\n", "            ", "if", "i", "+", "self", ".", "sbatch", "<=", "len", "(", "r", ")", ":", "b", "=", "r", "[", "i", ":", "i", "+", "self", ".", "sbatch", "]", "\n", "else", ":", "b", "=", "r", "[", "i", ":", "]", "\n", "images", ",", "targets", "=", "x", "[", "b", "]", ".", "to", "(", "self", ".", "device", ")", ",", "y", "[", "b", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Forward", "\n", "loss", "=", "self", ".", "elbo_loss", "(", "images", ",", "targets", ",", "t", ",", "num_batches", ",", "sample", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Backward", "\n", "self", ".", "model", ".", "cuda", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "self", ".", "model", ".", "cuda", "(", ")", "\n", "\n", "# Update parameters", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.eval": [[202, 231], ["ucb.Appr.model.eval", "numpy.arange", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "x.size", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "len", "ucb.Appr.model", "ucb.Appr.elbo_loss", "output.max", "pred.eq().sum().item", "len", "len", "x[].to", "y[].to", "ucb.Appr.detach", "len", "pred.eq().sum", "pred.eq", "targets.view_as"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.eval", "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.elbo_loss"], ["", "def", "eval", "(", "self", ",", "t", ",", "x", ",", "y", ",", "debug", "=", "False", ")", ":", "\n", "        ", "total_loss", "=", "0", "\n", "total_acc", "=", "0", "\n", "total_num", "=", "0", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "r", "=", "np", ".", "arange", "(", "x", ".", "size", "(", "0", ")", ")", "\n", "r", "=", "torch", ".", "as_tensor", "(", "r", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "num_batches", "=", "len", "(", "x", ")", "//", "self", ".", "sbatch", "\n", "# Loop batches", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "r", ")", ",", "self", ".", "sbatch", ")", ":", "\n", "                ", "if", "i", "+", "self", ".", "sbatch", "<=", "len", "(", "r", ")", ":", "b", "=", "r", "[", "i", ":", "i", "+", "self", ".", "sbatch", "]", "\n", "else", ":", "b", "=", "r", "[", "i", ":", "]", "\n", "images", ",", "targets", "=", "x", "[", "b", "]", ".", "to", "(", "self", ".", "device", ")", ",", "y", "[", "b", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Forward", "\n", "outputs", "=", "self", ".", "model", "(", "images", ",", "sample", "=", "False", ")", "\n", "output", "=", "outputs", "[", "t", "]", "\n", "loss", "=", "self", ".", "elbo_loss", "(", "images", ",", "targets", ",", "t", ",", "num_batches", ",", "sample", "=", "False", ",", "debug", "=", "debug", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "total_loss", "+=", "loss", ".", "detach", "(", ")", "*", "len", "(", "b", ")", "\n", "total_acc", "+=", "pred", ".", "eq", "(", "targets", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "total_num", "+=", "len", "(", "b", ")", "\n", "\n", "", "", "return", "total_loss", "/", "total_num", ",", "total_acc", "/", "total_num", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.set_model_": [[233, 235], ["model.model.load_state_dict", "copy.deepcopy"], "methods", ["None"], ["", "def", "set_model_", "(", "model", ",", "state_dict", ")", ":", "\n", "        ", "model", ".", "model", ".", "load_state_dict", "(", "copy", ".", "deepcopy", "(", "state_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.elbo_loss": [[237, 274], ["range", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "range", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "predictions.append", "ucb.Appr.logs", "lps.append", "lvps.append", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.as_tensor().mean", "torch.nn.functional.nll_loss().to", "torch.nn.functional.nll_loss().to", "torch.nn.functional.nll_loss().to", "torch.nn.functional.nll_loss().to", "predictions.append", "torch.nn.functional.nll_loss().to", "torch.nn.functional.nll_loss().to", "torch.nn.functional.nll_loss().to", "torch.nn.functional.nll_loss().to", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "ucb.Appr.model", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "ucb.Appr.model", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.stack().to.mean", "torch.stack().to.mean", "torch.stack().to.mean", "torch.stack().to.mean"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.logs"], ["", "def", "elbo_loss", "(", "self", ",", "input", ",", "target", ",", "t", ",", "num_batches", ",", "sample", ",", "debug", "=", "False", ")", ":", "\n", "        ", "if", "sample", ":", "\n", "            ", "lps", ",", "lvps", ",", "predictions", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "samples", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "self", ".", "model", "(", "input", ",", "sample", "=", "sample", ")", "[", "t", "]", ")", "\n", "lp", ",", "lv", "=", "self", ".", "logs", "(", "t", ")", "\n", "lps", ".", "append", "(", "lp", ")", "\n", "lvps", ".", "append", "(", "lv", ")", "\n", "\n", "# hack", "\n", "", "w1", "=", "1.e-3", "\n", "w2", "=", "1.e-3", "\n", "w3", "=", "5.e-2", "\n", "\n", "outputs", "=", "torch", ".", "stack", "(", "predictions", ",", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "log_var", "=", "w1", "*", "torch", ".", "as_tensor", "(", "lvps", ",", "device", "=", "self", ".", "device", ")", ".", "mean", "(", ")", "\n", "log_p", "=", "w2", "*", "torch", ".", "as_tensor", "(", "lps", ",", "device", "=", "self", ".", "device", ")", ".", "mean", "(", ")", "\n", "nll", "=", "w3", "*", "torch", ".", "nn", ".", "functional", ".", "nll_loss", "(", "outputs", ".", "mean", "(", "0", ")", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "(", "log_var", "-", "log_p", ")", "/", "num_batches", "+", "nll", "\n", "\n", "", "else", ":", "\n", "            ", "predictions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "samples", ")", ":", "\n", "                ", "pred", "=", "self", ".", "model", "(", "input", ",", "sample", "=", "False", ")", "[", "t", "]", "\n", "predictions", ".", "append", "(", "pred", ")", "\n", "\n", "\n", "# hack", "\n", "# w1 = 1.e-3", "\n", "# w2 = 1.e-3", "\n", "", "w3", "=", "5.e-6", "\n", "\n", "outputs", "=", "torch", ".", "stack", "(", "predictions", ",", "dim", "=", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "nll", "=", "w3", "*", "torch", ".", "nn", ".", "functional", ".", "nll_loss", "(", "outputs", ".", "mean", "(", "0", ")", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "nll", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.ucb.Appr.save_model": [[286, 289], ["torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "ucb.Appr.model.state_dict"], "methods", ["None"], ["", "", "def", "save_model", "(", "self", ",", "t", ")", ":", "\n", "        ", "torch", ".", "save", "(", "{", "'model_state_dict'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint", ",", "'model_{}.pth.tar'", ".", "format", "(", "t", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__": [[7, 19], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__init__"], ["########################################################################################################################", "\n", "def", "print_arguments", "(", "args", ")", ":", "\n", "    ", "print", "(", "'='", "*", "100", ")", "\n", "print", "(", "'Arguments ='", ")", "\n", "for", "arg", "in", "vars", "(", "args", ")", ":", "\n", "        ", "print", "(", "'\\t'", "+", "arg", "+", "':'", ",", "getattr", "(", "args", ",", "arg", ")", ")", "\n", "", "print", "(", "'='", "*", "100", ")", "\n", "\n", "\n", "", "def", "print_model_report", "(", "model", ")", ":", "\n", "    ", "print", "(", "'-'", "*", "100", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "'Dimensions ='", ",", "end", "=", "' '", ")", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__setstate__": [[21, 26], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.__setstate__"], ["for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "print", "(", "p", ".", "size", "(", ")", ",", "end", "=", "' '", ")", "\n", "count", "+=", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "\n", "\n", "", "print", "(", ")", "\n", "print", "(", "'Num parameters = %s'", "%", "(", "human_format", "(", "count", ")", ")", ",", "human_format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.SaynaEbrahimi_UCB.approaches.utils.BayesianSGD.step": [[27, 71], ["closure", "isinstance", "d_p.add.add.add_", "p.data.add_", "torch.clone().detach", "torch.clone().detach.mul_().add_", "d_p.add.add.add", "torch.mul", "torch.clone", "torch.clone().detach.mul_"], "methods", ["None"], ["print", "(", "'-'", "*", "100", ")", "\n", "return", "count", "\n", "\n", "", "def", "human_format", "(", "num", ")", ":", "\n", "    ", "magnitude", "=", "0", "\n", "while", "abs", "(", "num", ")", ">=", "1000", ":", "\n", "        ", "magnitude", "+=", "1", "\n", "num", "/=", "1000.0", "\n", "", "return", "'%.1f%s'", "%", "(", "num", ",", "[", "''", ",", "'K'", ",", "'M'", ",", "'G'", ",", "'T'", ",", "'P'", "]", "[", "magnitude", "]", ")", "\n", "\n", "########################################################################################################################", "\n", "\n", "", "def", "is_number", "(", "s", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "float", "(", "s", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "pass", "\n", "", "try", ":", "\n", "        ", "import", "unicodedata", "\n", "unicodedata", ".", "numeric", "(", "s", ")", "\n", "return", "True", "\n", "", "except", "(", "TypeError", ",", "ValueError", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "False", "\n", "########################################################################################################################", "\n", "\n", "\n", "", "def", "save_log", "(", "taskcla", ",", "acc", ",", "lss", ",", "data", ",", "output_path", ")", ":", "\n", "    ", "logs", "=", "{", "}", "\n", "# save task names", "\n", "logs", "[", "'task_name'", "]", "=", "{", "}", "\n", "logs", "[", "'test_acc'", "]", "=", "{", "}", "\n", "logs", "[", "'test_loss'", "]", "=", "{", "}", "\n", "for", "t", ",", "ncla", "in", "taskcla", ":", "\n", "        ", "logs", "[", "'task_name'", "]", "[", "t", "]", "=", "deepcopy", "(", "data", "[", "t", "]", "[", "'name'", "]", ")", "\n", "logs", "[", "'test_acc'", "]", "[", "t", "]", "=", "deepcopy", "(", "acc", "[", "t", ",", ":", "]", ")", "\n", "logs", "[", "'test_loss'", "]", "[", "t", "]", "=", "deepcopy", "(", "lss", "[", "t", ",", ":", "]", ")", "\n", "# pickle", "\n", "", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "'logs.p'", ")", ",", "'wb'", ")", "as", "output", ":", "\n", "        ", "pickle", ".", "dump", "(", "logs", ",", "output", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "print", "(", "\"Log file saved in \"", ",", "os", ".", "path", ".", "join", "(", "output_path", ",", "'logs.p'", ")", ")", "\n", "\n"]]}