{"home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.main.parse_arguments": [[10, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "parse_arguments", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Argument parser for Fake News Detection'", ")", "\n", "\n", "# Data Related", "\n", "parser", ".", "add_argument", "(", "\"--train\"", ",", "dest", "=", "\"train\"", ",", "type", "=", "str", ",", "default", "=", "'data/fulltrain.csv'", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev\"", ",", "dest", "=", "\"dev\"", ",", "type", "=", "str", ",", "default", "=", "'data/balancedtest.csv'", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "dest", "=", "\"test\"", ",", "type", "=", "str", ",", "default", "=", "'data/test.xlsx'", ",", "help", "=", "'Out of domain test set'", ")", "\n", "parser", ".", "add_argument", "(", "\"--pte\"", ",", "dest", "=", "\"pte\"", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'Pre-trained embeds'", ")", "\n", "\n", "# Hyper-parameters", "\n", "parser", ".", "add_argument", "(", "\"--freq_cutoff\"", ",", "dest", "=", "\"freq_cutoff\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\"--emb_dim\"", ",", "dest", "=", "\"emb_dim\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "dest", "=", "\"hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--node_emb_dim\"", ",", "dest", "=", "\"node_emb_dim\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\"--filters\"", ",", "dest", "=", "\"filters\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--kernel_size\"", ",", "dest", "=", "\"kernel_size\"", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_epochs\"", ",", "dest", "=", "\"max_epochs\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sent_len\"", ",", "dest", "=", "\"max_sent_len\"", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sents_in_a_doc\"", ",", "dest", "=", "\"max_sents_in_a_doc\"", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "dest", "=", "\"batch_size\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "dest", "=", "\"lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-3", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "dest", "=", "\"dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "\"--ntags\"", ",", "dest", "=", "\"ntags\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "dest", "=", "\"weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--encoder\"", ",", "dest", "=", "\"encoder\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'0: LSTM encoder for text,'", "\n", "'1: CNN encoder for text'", "\n", "'2: GCN encoder for text'", "\n", "'3: GCN + attention'", "\n", "'4: GAT'", "\n", "'5: GAT with 2 attn heads'", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "dest", "=", "\"config\"", ",", "type", "=", "str", ",", "default", "=", "'lstm_no_pte'", ",", "help", "=", "'Name for saving plots'", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_file\"", ",", "dest", "=", "\"model_file\"", ",", "type", "=", "str", ",", "default", "=", "'model_gat_adj_latest.t7'", ",", "help", "=", "'For '", "\n", "'evaluating a saved model'", ")", "\n", "parser", ".", "add_argument", "(", "\"--plot\"", ",", "dest", "=", "\"plot\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'set to plot attn'", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_ss\"", ",", "dest", "=", "\"use_ss\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'use ss model'", ")", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "dest", "=", "\"mode\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'0: train, 1:test'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "\"models/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"models/\"", ")", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.main.main": [[51, 73], ["main.parse_arguments", "timeit.default_timer", "data_loader.DataLoader", "util.Utils", "trainer.Trainer", "trainer.Trainer.train", "print", "print", "timeit.default_timer", "evaluator.Evaluator", "evaluator.Evaluator.evaluate", "timeit.default_timer"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.main.parse_arguments", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.train", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "params", "=", "parse_arguments", "(", ")", "\n", "s_t", "=", "timer", "(", ")", "\n", "dl", "=", "DataLoader", "(", "params", ")", "\n", "u", "=", "Utils", "(", "params", ",", "dl", ")", "\n", "\n", "if", "params", ".", "mode", "==", "0", ":", "\n", "# Start training", "\n", "        ", "trainer", "=", "Trainer", "(", "params", ",", "u", ")", "\n", "trainer", ".", "log_time", "[", "'data_loading'", "]", "=", "timer", "(", ")", "-", "s_t", "\n", "trainer", ".", "train", "(", ")", "\n", "print", "(", "trainer", ".", "log_time", ")", "\n", "print", "(", "\"Total time taken (in seconds): {}\"", ".", "format", "(", "timer", "(", ")", "-", "s_t", ")", ")", "\n", "\n", "", "elif", "params", ".", "mode", "==", "1", ":", "\n", "# Evaluate on the test set", "\n", "        ", "evaluator", "=", "Evaluator", "(", "params", ",", "u", ",", "dl", ")", "\n", "evaluator", ".", "evaluate", "(", ")", "\n", "\n", "", "else", ":", "\n", "# Nothing implemented yet", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.BertForClassification.__init__": [[25, 32], ["super().__init__", "torch.nn.LSTM", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForClassification", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "768", ",", "params", ".", "hidden_dim", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "params", ".", "dropout", ")", "\n", "# Hidden size of bert base model = 768", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "params", ".", "hidden_dim", ",", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.BertForClassification.forward": [[33, 39], ["input_features.permute", "bert_classifier.BertForClassification.lstm", "bert_classifier.BertForClassification.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_features", ")", ":", "\n", "        ", "embeds", "=", "input_features", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# seq_len * batch_size * embedding_dim", "\n", "_", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "embeds", ")", "\n", "output", "=", "hn", "[", "-", "1", "]", "# bs * hidden_dim", "\n", "logits", "=", "self", ".", "classifier", "(", "output", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.InputExample.__init__": [[43, 47], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "unique_id", ",", "text_a", ",", "text_b", ")", ":", "\n", "        ", "self", ".", "unique_id", "=", "unique_id", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.InputFeatures.__init__": [[52, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokens", ",", "input_ids", ",", "input_mask", ",", "input_type_ids", ")", ":", "\n", "        ", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "input_type_ids", "=", "input_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.ClassificationDataSet.__init__": [[181, 190], ["super().__init__", "len"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "labels", ",", "params", ",", "bert_model", ",", "device", ")", ":", "\n", "        ", "super", "(", "ClassificationDataSet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "# data is a list of tuples (sent, label)", "\n", "self", ".", "features", "=", "features", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "bert", "=", "bert_model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "num_of_samples", "=", "len", "(", "self", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.ClassificationDataSet.__len__": [[191, 193], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_of_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.ClassificationDataSet.__getitem__": [[194, 201], ["torch.tensor().to", "torch.tensor().to", "bert_classifier.ClassificationDataSet.bert", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "input_features", "=", "self", ".", "features", "[", "idx", "]", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "input_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "input_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "None", ",", "input_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "# Picking the output corresponding to [CLS]", "\n", "return", "output", "[", ":", ",", "0", ",", ":", "]", ",", "torch", ".", "tensor", "(", "self", ".", "labels", "[", "idx", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.ClassificationDataSet.collate": [[202, 212], ["max", "torch.zeros().to", "enumerate", "torch.stack", "f.size", "torch.zeros", "len", "f.size"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ")", ":", "\n", "        ", "features", "=", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", "\n", "labels", "=", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", "\n", "# Find the longest sentence length in the batch", "\n", "max_length", "=", "max", "(", "[", "f", ".", "size", "(", "0", ")", "for", "f", "in", "features", "]", ")", "\n", "padded_tensor", "=", "torch", ".", "zeros", "(", "len", "(", "features", ")", ",", "max_length", ",", "768", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "padded_tensor", "[", "i", ",", ":", "f", ".", "size", "(", "0", ")", ",", ":", "]", "=", "f", "\n", "\n", "", "return", "padded_tensor", ",", "torch", ".", "stack", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.convert_examples_to_features": [[59, 119], ["tokenizer.tokenize", "tokens.append", "input_type_ids.append", "tokens.append", "input_type_ids.append", "tokenizer.convert_tokens_to_ids", "features.append", "len", "tokens.append", "input_type_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "input_type_ids.append", "len", "len", "len", "bert_classifier.InputFeatures"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "examples", ",", "seq_length", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "features", "=", "[", "]", "\n", "for", "example", "in", "examples", ":", "\n", "        ", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ")", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "if", "len", "(", "tokens_a", ")", ">", "seq_length", "-", "2", ":", "\n", "            ", "tokens_a", "=", "tokens_a", "[", "0", ":", "(", "seq_length", "-", "2", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0      0   0    1  1  1   1  1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambigiously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "tokens", "=", "[", "]", "\n", "input_type_ids", "=", "[", "]", "\n", "tokens", ".", "append", "(", "\"[CLS]\"", ")", "\n", "input_type_ids", ".", "append", "(", "0", ")", "\n", "for", "token", "in", "tokens_a", ":", "\n", "            ", "tokens", ".", "append", "(", "token", ")", "\n", "input_type_ids", ".", "append", "(", "0", ")", "\n", "", "tokens", ".", "append", "(", "\"[SEP]\"", ")", "\n", "input_type_ids", ".", "append", "(", "0", ")", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "seq_length", ":", "\n", "            ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "input_type_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "seq_length", "\n", "assert", "len", "(", "input_type_ids", ")", "==", "seq_length", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "tokens", "=", "tokens", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "input_type_ids", "=", "input_type_ids", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier._truncate_seq_pair": [[121, 136], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.read_examples": [[138, 153], ["open", "csv.reader", "csv.field_size_limit", "int", "examples.append", "examples.append", "words.lower", "words.lower"], "function", ["None"], ["", "", "", "def", "read_examples", "(", "filename", ",", "max_seq_length", ",", "ntags", ")", ":", "\n", "    ", "\"\"\"Read a list of `InputExample`s from an input file.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "readCSV", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "csv", ".", "field_size_limit", "(", "100000000", ")", "\n", "for", "tag", ",", "words", "in", "readCSV", ":", "\n", "            ", "tag", "=", "int", "(", "tag", ")", "\n", "if", "ntags", "==", "2", ":", "\n", "                ", "if", "tag", "in", "[", "1", ",", "4", "]", ":", "\n", "# Adjust the tag to {0: Satire, 1: Trusted}", "\n", "                    ", "examples", ".", "append", "(", "(", "words", ".", "lower", "(", ")", "[", ":", "max_seq_length", "]", ",", "tag", "-", "1", "if", "tag", "==", "1", "else", "tag", "-", "3", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "examples", ".", "append", "(", "(", "words", ".", "lower", "(", ")", "[", ":", "max_seq_length", "]", ",", "tag", "-", "1", ")", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.read_testset": [[155, 163], ["pandas.read_excel", "int", "data.append", "row[].lower"], "function", ["None"], ["", "def", "read_testset", "(", "filename", ",", "max_seq_length", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_excel", "(", "filename", ")", "\n", "data", "=", "[", "]", "\n", "for", "row", "in", "df", ".", "values", ":", "\n", "        ", "tag", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "# Tag id is reversed in this dataset", "\n", "data", ".", "append", "(", "(", "row", "[", "2", "]", ".", "lower", "(", ")", "[", ":", "max_seq_length", "]", ",", "tag", "+", "1", "if", "tag", "==", "0", "else", "tag", "-", "1", ")", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.get_dev_loss_and_acc": [[165, 178], ["model.eval", "model", "loss_fn", "torch.sum().item", "len", "losses.append", "numpy.asscalar", "loss_fn.item", "numpy.mean", "torch.sum", "torch.argmax"], "function", ["None"], ["", "def", "get_dev_loss_and_acc", "(", "model", ",", "loss_fn", ",", "dev_data_loader", ",", "device", ")", ":", "\n", "    ", "losses", "=", "[", "]", "\n", "hits", "=", "0", "\n", "total", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "for", "input_features", ",", "input_labels", "in", "dev_data_loader", ":", "\n", "        ", "logits", "=", "model", "(", "input_features", ")", "\n", "loss", "=", "loss_fn", "(", "logits", ",", "input_labels", ")", "\n", "hits", "+=", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "==", "input_labels", ")", ".", "item", "(", ")", "\n", "total", "+=", "len", "(", "input_features", ")", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "np", ".", "asscalar", "(", "np", ".", "mean", "(", "losses", ")", ")", ",", "hits", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.get_data_loader": [[214, 229], ["bert_classifier.ClassificationDataSet", "torch.utils.data.DataLoader", "bert_classifier.convert_examples_to_features", "all_features.append", "all_labels.append", "example.split"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.convert_examples_to_features"], ["", "", "def", "get_data_loader", "(", "args", ",", "examples", ",", "tokenizer", ",", "bert_model", ",", "device", ",", "max_sents_in_a_doc", ")", ":", "\n", "    ", "all_features", "=", "[", "]", "\n", "all_labels", "=", "[", "]", "\n", "for", "example", ",", "tag", "in", "examples", ":", "\n", "        ", "sents", "=", "example", ".", "split", "(", "\".\"", ")", "[", ":", "max_sents_in_a_doc", "]", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", "=", "sents", ",", "seq_length", "=", "args", ".", "max_sent_length", ",", "tokenizer", "=", "tokenizer", ")", "\n", "all_features", ".", "append", "(", "features", ")", "\n", "all_labels", ".", "append", "(", "tag", ")", "\n", "\n", "", "dataset_train", "=", "ClassificationDataSet", "(", "all_features", ",", "all_labels", ",", "args", ",", "bert_model", ",", "device", ")", "\n", "kwargs", "=", "{", "}", "\n", "train_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_train", ",", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "collate_fn", "=", "dataset_train", ".", "collate", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "return", "train_data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier._evaluate_aux": [[231, 249], ["model.eval", "tqdm.tqdm", "model", "torch.argmax", "torch.sum().item", "len", "input_labels.cpu().data.numpy", "torch.argmax.cpu().data.numpy", "numpy.concatenate", "numpy.concatenate", "torch.sum", "torch.argmax.cpu().data.numpy", "input_labels.cpu", "torch.argmax.cpu", "torch.argmax.cpu"], "function", ["None"], ["", "def", "_evaluate_aux", "(", "model", ",", "data_loader", ")", ":", "\n", "    ", "hits", "=", "0", "\n", "total", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "all_actual", "=", "None", "\n", "all_predicted", "=", "None", "\n", "for", "input_features", ",", "input_labels", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "        ", "logits", "=", "model", "(", "input_features", ")", "\n", "predicted", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "hits", "+=", "torch", ".", "sum", "(", "predicted", "==", "input_labels", ")", ".", "item", "(", ")", "\n", "total", "+=", "len", "(", "input_features", ")", "\n", "all_predicted", "=", "predicted", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "if", "all_predicted", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_predicted", ",", "\n", "predicted", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", ")", "\n", "labels", "=", "input_labels", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "all_actual", "=", "labels", "if", "all_actual", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_actual", ",", "labels", ")", ")", "\n", "\n", "", "accuracy", "=", "hits", "/", "total", "\n", "return", "accuracy", ",", "all_actual", ",", "all_predicted", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.main": [[251, 420], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "pytorch_pretrained_bert.modeling.BertModel.from_pretrained", "BertModel.from_pretrained.to", "print", "bert_classifier.read_examples", "sklearn.model_selection.train_test_split", "bert_classifier.get_data_loader", "bert_classifier.get_data_loader", "print", "bert_classifier.BertForClassification", "model.cuda.to", "torch.nn.CrossEntropyLoss", "torch.optim.Adam", "range", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.legend", "matplotlib.xticks", "plt.figure.savefig", "torch.cuda.is_available", "model.cuda.parameters", "model.cuda.train", "tqdm.tqdm", "bert_classifier.get_dev_loss_and_acc", "train_losses.append", "dev_losses.append", "train_accs.append", "dev_accs.append", "tqdm.tqdm.write", "range", "range", "numpy.arange", "bert_classifier.BertForClassification", "model.cuda.to", "torch.cuda.is_available", "model.cuda.load_state_dict", "model.cuda.eval", "bert_classifier.read_examples", "bert_classifier.get_data_loader", "bert_classifier._evaluate_aux", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "print", "bert_classifier._evaluate_aux", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "model.cuda.", "torch.nn.CrossEntropyLoss.", "loss_fn.item", "torch.sum().item", "len", "torch.optim.Adam.zero_grad", "loss_fn.backward", "torch.optim.Adam.step", "torch.save", "print", "bert_classifier.read_testset", "bert_classifier.get_data_loader", "print", "model.cuda.cuda", "torch.load", "bert_classifier._evaluate_aux", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "print", "len", "torch.optim.Adam.state_dict", "torch.optim.Adam.load_state_dict", "tqdm.tqdm.write", "model.cuda.state_dict", "torch.sum", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.read_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.get_data_loader", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.get_data_loader", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.train", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_dev_loss_and_acc", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.read_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.get_data_loader", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_testset", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.bert_classifier.get_data_loader", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train\"", ",", "dest", "=", "\"train\"", ",", "type", "=", "str", ",", "default", "=", "'data/fulltrain.csv'", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev\"", ",", "dest", "=", "\"dev\"", ",", "type", "=", "str", ",", "default", "=", "'data/balancedtest.csv'", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "dest", "=", "\"test\"", ",", "type", "=", "str", ",", "default", "=", "'data/test.xlsx'", ",", "help", "=", "'Out of domain test set'", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "default", "=", "\"bert-base-uncased\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "default", "=", "\"-1,-2,-3,-4\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "dest", "=", "\"dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_epochs\"", ",", "dest", "=", "\"max_epochs\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "dest", "=", "\"hidden_dim\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "dest", "=", "\"lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-3", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "dest", "=", "\"config\"", ",", "type", "=", "str", ",", "default", "=", "'bert'", ",", "help", "=", "'Name for saving plots'", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sents_in_a_doc\"", ",", "dest", "=", "\"max_sents_in_a_doc\"", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "500", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. Sequences longer \"", "\n", "\"than this will be truncated, and sequences shorter than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sent_length\"", ",", "default", "=", "70", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--ntags\"", ",", "dest", "=", "\"ntags\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "dest", "=", "\"weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"Batch size for predictions.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "dest", "=", "\"mode\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'0: train, 1:test'", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_file\"", ",", "dest", "=", "\"model_file\"", ",", "type", "=", "str", ",", "default", "=", "'model_bert.t7'", ",", "help", "=", "'For evaluating a '", "\n", "'saved model'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "# Create bert model", "\n", "bert_model", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "bert_model", ".", "to", "(", "device", ")", "\n", "\n", "print", "(", "\"Preparing data...\"", ")", "\n", "train_examples", "=", "read_examples", "(", "args", ".", "train", ",", "args", ".", "max_seq_length", ",", "args", ".", "ntags", ")", "\n", "train_examples", ",", "dev_examples", "=", "train_test_split", "(", "train_examples", ",", "test_size", "=", "0.2", ",", "random_state", "=", "42", ")", "\n", "train_dataloader", "=", "get_data_loader", "(", "args", ",", "train_examples", ",", "tokenizer", ",", "bert_model", ",", "device", ",", "args", ".", "max_sents_in_a_doc", ")", "\n", "\n", "# dev_examples = read_examples(args.dev, args.max_seq_length)", "\n", "dev_dataloader", "=", "get_data_loader", "(", "args", ",", "dev_examples", ",", "tokenizer", ",", "bert_model", ",", "device", ",", "args", ".", "max_sents_in_a_doc", ")", "\n", "print", "(", "\"Preparing data...[OK]\"", ")", "\n", "\n", "if", "args", ".", "mode", "==", "0", ":", "\n", "\n", "        ", "model", "=", "BertForClassification", "(", "args", ",", "args", ".", "ntags", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "# Variables for plotting", "\n", "train_losses", "=", "[", "]", "\n", "dev_losses", "=", "[", "]", "\n", "train_accs", "=", "[", "]", "\n", "dev_accs", "=", "[", "]", "\n", "prev_best", "=", "0", "\n", "patience", "=", "0", "\n", "\n", "# Training epoch", "\n", "# Start the training loop", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "max_epochs", "+", "1", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "hits", "=", "0", "\n", "total", "=", "0", "\n", "for", "input_features", ",", "input_labels", "in", "tqdm", "(", "train_dataloader", ")", ":", "\n", "\n", "                ", "logits", "=", "model", "(", "input_features", ")", "\n", "loss", "=", "loss_fn", "(", "logits", ",", "input_labels", ")", "\n", "\n", "# Book keeping", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "hits", "+=", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "==", "input_labels", ")", ".", "item", "(", ")", "\n", "# One can alternatively do this accuracy computation on cpu by,", "\n", "# moving the logits to cpu: logits.data.cpu().numpy(), and then using numpy argmax.", "\n", "# However, we should always avoid moving tensors between devices if possible for faster computation", "\n", "total", "+=", "len", "(", "input_features", ")", "\n", "\n", "# Back-prop", "\n", "optimizer", ".", "zero_grad", "(", ")", "# Reset the gradients", "\n", "loss", ".", "backward", "(", ")", "# Back propagate the gradients", "\n", "optimizer", ".", "step", "(", ")", "# Update the network", "\n", "\n", "# Compute loss and acc for dev set", "\n", "", "dev_loss", ",", "dev_acc", "=", "get_dev_loss_and_acc", "(", "model", ",", "loss_fn", ",", "dev_dataloader", ",", "device", ")", "\n", "train_losses", ".", "append", "(", "train_loss", "/", "len", "(", "train_dataloader", ")", ")", "\n", "dev_losses", ".", "append", "(", "dev_loss", ")", "\n", "train_accs", ".", "append", "(", "hits", "/", "total", ")", "\n", "dev_accs", ".", "append", "(", "dev_acc", ")", "\n", "tqdm", ".", "write", "(", "\"Epoch: {}, Train loss: {}, Train acc: {}, Dev loss: {}, Dev acc: {}\"", ".", "format", "(", "\n", "epoch", ",", "train_loss", ",", "hits", "/", "total", ",", "dev_loss", ",", "dev_acc", ")", ")", "\n", "if", "dev_acc", "<", "prev_best", ":", "\n", "                ", "patience", "+=", "1", "\n", "if", "patience", "==", "3", ":", "\n", "# Reduce the learning rate by a factor of 2 if dev acc doesn't increase for 3 epochs", "\n", "# Learning rate annealing", "\n", "                    ", "optim_state", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "optim_state", "[", "'param_groups'", "]", "[", "0", "]", "[", "'lr'", "]", "=", "optim_state", "[", "'param_groups'", "]", "[", "0", "]", "[", "'lr'", "]", "/", "2", "\n", "optimizer", ".", "load_state_dict", "(", "optim_state", ")", "\n", "tqdm", ".", "write", "(", "'Dev accuracy did not increase, reducing the learning rate by 2 !!!'", ")", "\n", "patience", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "prev_best", "=", "dev_acc", "\n", "# Save the model", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "\"models/model_{}.t7\"", ".", "format", "(", "args", ".", "config", ")", ")", "\n", "\n", "# Acc vs time plot", "\n", "", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "range", "(", "1", ",", "args", ".", "max_epochs", "+", "1", ")", ",", "train_accs", ",", "color", "=", "'b'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "range", "(", "1", ",", "args", ".", "max_epochs", "+", "1", ")", ",", "dev_accs", ",", "color", "=", "'r'", ",", "label", "=", "'dev'", ")", "\n", "plt", ".", "ylabel", "(", "'accuracy'", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "1", ",", "args", ".", "max_epochs", "+", "1", ",", "step", "=", "4", ")", ")", "\n", "fig", ".", "savefig", "(", "'data/'", "+", "'{}_accuracy.png'", ".", "format", "(", "args", ".", "config", ")", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "1", ":", "\n", "\n", "        ", "if", "args", ".", "ntags", "==", "2", ":", "\n", "            ", "print", "(", "\"Preparing data...\"", ")", "\n", "test_examples", "=", "read_testset", "(", "args", ".", "test", ",", "args", ".", "max_seq_length", ")", "\n", "test_data_loader", "=", "get_data_loader", "(", "args", ",", "test_examples", ",", "tokenizer", ",", "bert_model", ",", "device", ")", "\n", "print", "(", "\"Preparing data...[OK]\"", ")", "\n", "\n", "", "model", "=", "BertForClassification", "(", "args", ",", "args", ".", "ntags", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# Load the model weights", "\n", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"models/\"", "+", "args", ".", "model_file", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "args", ".", "ntags", "==", "2", ":", "\n", "            ", "accuracy", ",", "all_actual", ",", "all_predicted", "=", "_evaluate_aux", "(", "model", ",", "test_data_loader", ")", "\n", "prec_mac", ",", "recall_mac", ",", "f1_mac", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'macro'", ")", "\n", "prec_mic", ",", "recall_mic", ",", "f1_mic", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'micro'", ")", "\n", "print", "(", "\"Accuracy on the OOD test set 1: {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "print", "(", "\"Precision on the OOD test set 1 macro / micro: {}, {}\"", ".", "format", "(", "prec_mac", ",", "prec_mic", ")", ")", "\n", "print", "(", "\"Recall on the OOD test set 1 macro / micro: {}, {}\"", ".", "format", "(", "recall_mac", ",", "recall_mic", ")", ")", "\n", "print", "(", "\"F1 on the OOD test set 1 macro / micro: {}, {}\"", ".", "format", "(", "f1_mac", ",", "f1_mic", ")", ")", "\n", "\n", "print", "(", "\"----------------------------------------------------------------------\"", ")", "\n", "\n", "", "test_2_examples", "=", "read_examples", "(", "args", ".", "dev", ",", "args", ".", "max_seq_length", ",", "args", ".", "ntags", ")", "\n", "test_2_dataloader", "=", "get_data_loader", "(", "args", ",", "test_2_examples", ",", "tokenizer", ",", "bert_model", ",", "device", ",", "args", ".", "max_sents_in_a_doc", ")", "\n", "\n", "accuracy", ",", "all_actual", ",", "all_predicted", "=", "_evaluate_aux", "(", "model", ",", "test_2_dataloader", ")", "\n", "prec_mac", ",", "recall_mac", ",", "f1_mac", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'macro'", ")", "\n", "prec_mic", ",", "recall_mic", ",", "f1_mic", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'micro'", ")", "\n", "print", "(", "\"Accuracy on the OOD test set 2: {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "print", "(", "\"Precision on the OOD test set 2 macro / micro: {}, {}\"", ".", "format", "(", "prec_mac", ",", "prec_mic", ")", ")", "\n", "print", "(", "\"Recall on the OOD test set 2 macro / micro: {}, {}\"", ".", "format", "(", "recall_mac", ",", "recall_mic", ")", ")", "\n", "print", "(", "\"F1 on the OOD test set 2 macro / micro: {}, {}\"", ".", "format", "(", "f1_mac", ",", "f1_mic", ")", ")", "\n", "\n", "print", "(", "\"----------------------------------------------------------------------\"", ")", "\n", "\n", "accuracy", ",", "all_actual", ",", "all_predicted", "=", "_evaluate_aux", "(", "model", ",", "dev_dataloader", ")", "\n", "prec_mac", ",", "recall_mac", ",", "f1_mac", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'macro'", ")", "\n", "prec_mic", ",", "recall_mic", ",", "f1_mic", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'micro'", ")", "\n", "print", "(", "\"Accuracy on the dev set: {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "print", "(", "\"Precision on the dev set macro / micro: {}, {}\"", ".", "format", "(", "prec_mac", ",", "prec_mic", ")", ")", "\n", "print", "(", "\"Recall on the dev set macro / micro: {}, {}\"", ".", "format", "(", "recall_mac", ",", "recall_mic", ")", ")", "\n", "print", "(", "\"F1 on the dev set macro / micro: {}, {}\"", ".", "format", "(", "f1_mac", ",", "f1_mic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.__init__": [[11, 83], ["data_loader.freezable_defaultdict", "print", "print", "data_loader.freezable_defaultdict", "data_loader.freezable_defaultdict.freeze", "dict", "len", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_loader.DataLoader.read_dataset_sentence_wise", "list", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "map", "data_loader.DataLoader.read_testset_sentence_wise", "data_loader.DataLoader.read_testset", "data_loader.DataLoader.read_dataset_sentence_wise", "list", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "data_loader.ClassificationGraphDataSet", "data_loader.ClassificationDataSet", "data_loader.ClassificationGraphDataSet", "data_loader.ClassificationDataSet", "data_loader.ClassificationGraphDataSet", "data_loader.ClassificationDataSet", "data_loader.ClassificationGraphDataSet", "data_loader.ClassificationDataSet", "len", "data_loader.DataLoader.load_adj_matrix", "data_loader.DataLoader.read_dataset", "numpy.mean", "max", "data_loader.DataLoader.w2i.items", "data_loader.DataLoader.load_adj_matrix", "data_loader.DataLoader.load_adj_matrix", "data_loader.DataLoader.read_dataset", "len", "len"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.freezable_defaultdict.freeze", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_dataset_sentence_wise", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_testset_sentence_wise", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_testset", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_dataset_sentence_wise", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.load_adj_matrix", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_dataset", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.load_adj_matrix", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.load_adj_matrix", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_dataset"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "ntags", "=", "params", ".", "ntags", "\n", "# Dictionaries for word to index and vice versa", "\n", "w2i", "=", "freezable_defaultdict", "(", "lambda", ":", "len", "(", "w2i", ")", ")", "\n", "# Adding unk token", "\n", "UNK", "=", "w2i", "[", "\"<unk>\"", "]", "\n", "\n", "# Read in the data and store the dicts", "\n", "if", "self", ".", "params", ".", "encoder", ">=", "2", ":", "\n", "            ", "self", ".", "adj_train", "=", "self", ".", "load_adj_matrix", "(", "'lib_semscore/logs/STS-B/train-parts'", ",", "'train-adj_matrix-'", ")", "if", "self", ".", "params", ".", "use_ss", "==", "1", "else", "None", "\n", "self", ".", "train", ",", "self", ".", "adj_train", "=", "self", ".", "read_dataset_sentence_wise", "(", "params", ".", "train", ",", "w2i", ",", "self", ".", "adj_train", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train", "=", "list", "(", "self", ".", "read_dataset", "(", "params", ".", "train", ",", "w2i", ")", ")", "\n", "", "print", "(", "\"Average train document length: {}\"", ".", "format", "(", "np", ".", "mean", "(", "[", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "self", ".", "train", "]", ")", ")", ")", "\n", "print", "(", "\"Maximum train document length: {}\"", ".", "format", "(", "max", "(", "[", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "self", ".", "train", "]", ")", ")", ")", "\n", "w2i", "=", "freezable_defaultdict", "(", "lambda", ":", "UNK", ",", "w2i", ")", "\n", "w2i", ".", "freeze", "(", ")", "\n", "# Split the training set into two", "\n", "if", "self", ".", "params", ".", "use_ss", "==", "0", ":", "\n", "            ", "self", ".", "adj_dev", "=", "None", "\n", "self", ".", "train", ",", "self", ".", "dev", "=", "train_test_split", "(", "self", ".", "train", ",", "test_size", "=", "0.2", ",", "random_state", "=", "42", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train", ",", "self", ".", "dev", ",", "self", ".", "adj_train", ",", "self", ".", "adj_dev", "=", "train_test_split", "(", "self", ".", "train", ",", "self", ".", "adj_train", ",", "\n", "test_size", "=", "0.2", ",", "\n", "random_state", "=", "42", ")", "\n", "", "self", ".", "w2i", "=", "w2i", "\n", "self", ".", "i2w", "=", "dict", "(", "map", "(", "reversed", ",", "self", ".", "w2i", ".", "items", "(", ")", ")", ")", "\n", "self", ".", "nwords", "=", "len", "(", "w2i", ")", "\n", "# Treating this as a binary classification problem for now \"1: Satire, 4: Trusted\"", "\n", "if", "self", ".", "params", ".", "encoder", ">=", "2", ":", "\n", "            ", "self", ".", "adj_test", "=", "self", ".", "load_adj_matrix", "(", "'lib_semscore/logs/STS-B/test-parts'", ",", "\n", "'test-adj_matrix-'", ")", "if", "self", ".", "params", ".", "use_ss", "==", "1", "else", "None", "\n", "self", ".", "test", ",", "self", ".", "adj_test", "=", "self", ".", "read_testset_sentence_wise", "(", "params", ".", "test", ",", "w2i", ",", "self", ".", "adj_test", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "test", "=", "self", ".", "read_testset", "(", "params", ".", "test", ",", "w2i", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "encoder", ">=", "2", ":", "\n", "            ", "self", ".", "adj_test_2", "=", "self", ".", "load_adj_matrix", "(", "'lib_semscore/logs/STS-B/dev-parts'", ",", "\n", "'dev-adj_matrix-'", ")", "if", "self", ".", "params", ".", "use_ss", "==", "1", "else", "None", "\n", "self", ".", "test_2", ",", "self", ".", "adj_test_2", "=", "self", ".", "read_dataset_sentence_wise", "(", "params", ".", "dev", ",", "w2i", ",", "self", ".", "adj_test_2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "test_2", "=", "list", "(", "self", ".", "read_dataset", "(", "params", ".", "dev", ",", "w2i", ")", ")", "\n", "# Setting pin memory and number of workers", "\n", "", "kwargs", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "\n", "dataset_train", "=", "ClassificationGraphDataSet", "(", "self", ".", "train", ",", "self", ".", "adj_train", ",", "\n", "self", ".", "params", ")", "if", "self", ".", "params", ".", "encoder", ">=", "2", "else", "ClassificationDataSet", "(", "self", ".", "train", ",", "self", ".", "params", ")", "\n", "self", ".", "train_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_train", ",", "batch_size", "=", "params", ".", "batch_size", ",", "\n", "collate_fn", "=", "dataset_train", ".", "collate", ",", "shuffle", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n", "dataset_dev", "=", "ClassificationGraphDataSet", "(", "self", ".", "dev", ",", "self", ".", "adj_dev", ",", "self", ".", "params", ")", "if", "self", ".", "params", ".", "encoder", ">=", "2", "else", "ClassificationDataSet", "(", "self", ".", "dev", ",", "self", ".", "params", ")", "\n", "self", ".", "dev_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_dev", ",", "batch_size", "=", "params", ".", "batch_size", ",", "\n", "collate_fn", "=", "dataset_dev", ".", "collate", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "dataset_test", "=", "ClassificationGraphDataSet", "(", "self", ".", "test", ",", "self", ".", "adj_test", ",", "\n", "self", ".", "params", ")", "if", "self", ".", "params", ".", "encoder", ">=", "2", "else", "ClassificationDataSet", "(", "self", ".", "test", ",", "self", ".", "params", ")", "\n", "self", ".", "test_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_test", ",", "batch_size", "=", "params", ".", "batch_size", ",", "\n", "collate_fn", "=", "dataset_test", ".", "collate", ",", "shuffle", "=", "False", ",", "\n", "**", "kwargs", ")", "\n", "\n", "dataset_test_2", "=", "ClassificationGraphDataSet", "(", "self", ".", "test_2", ",", "self", ".", "adj_test_2", ",", "\n", "self", ".", "params", ")", "if", "self", ".", "params", ".", "encoder", ">=", "2", "else", "ClassificationDataSet", "(", "self", ".", "test_2", ",", "self", ".", "params", ")", "\n", "self", ".", "test_data_loader_2", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_test_2", ",", "batch_size", "=", "params", ".", "batch_size", ",", "\n", "collate_fn", "=", "dataset_test_2", ".", "collate", ",", "shuffle", "=", "False", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_dataset": [[84, 97], ["open", "csv.reader", "csv.field_size_limit", "int", "words.lower().split", "words.lower().split", "words.lower", "words.lower"], "methods", ["None"], ["", "def", "read_dataset", "(", "self", ",", "filename", ",", "w2i", ")", ":", "\n", "        ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "readCSV", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "csv", ".", "field_size_limit", "(", "100000000", ")", "\n", "for", "tag", ",", "words", "in", "readCSV", ":", "\n", "                ", "tag", "=", "int", "(", "tag", ")", "\n", "if", "self", ".", "ntags", "==", "2", ":", "\n", "                    ", "if", "tag", "in", "[", "1", ",", "4", "]", ":", "\n", "# Adjust the tag to {0: Satire, 1: Trusted}", "\n", "                        ", "yield", "(", "[", "w2i", "[", "x", "]", "for", "x", "in", "words", ".", "lower", "(", ")", ".", "split", "(", "\" \"", ")", "]", ",", "tag", "-", "1", "if", "tag", "==", "1", "else", "tag", "-", "3", ")", "\n", "", "", "else", ":", "\n", "# {0: Satire, 1: Hoax, 2: Propaganda, 3: Trusted}", "\n", "                    ", "yield", "(", "[", "w2i", "[", "x", "]", "for", "x", "in", "words", ".", "lower", "(", ")", ".", "split", "(", "\" \"", ")", "]", ",", "tag", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_testset": [[98, 107], ["pandas.read_excel", "int", "data.append", "row[].lower().split", "row[].lower"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "read_testset", "(", "filename", ",", "w2i", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_excel", "(", "filename", ")", "\n", "data", "=", "[", "]", "\n", "for", "row", "in", "df", ".", "values", ":", "\n", "            ", "tag", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "# Tag id is reversed in this dataset", "\n", "data", ".", "append", "(", "(", "[", "w2i", "[", "x", "]", "for", "x", "in", "row", "[", "2", "]", ".", "lower", "(", ")", ".", "split", "(", "\" \"", ")", "]", ",", "tag", "+", "1", "if", "tag", "==", "0", "else", "tag", "-", "1", ")", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_dataset_sentence_wise": [[108, 137], ["open", "csv.reader", "csv.field_size_limit", "doc.split", "int", "sentence.lower().strip().split.lower().strip().split.lower().strip().split", "sentences_idx.append", "len", "data.append", "new_adj.append", "sentence.lower().strip().split.lower().strip().split.lower().strip", "len", "sentence.lower().strip().split.lower().strip().split.lower"], "methods", ["None"], ["", "def", "read_dataset_sentence_wise", "(", "self", ",", "filename", ",", "w2i", ",", "adj", ")", ":", "\n", "        ", "data", "=", "[", "]", "\n", "new_adj", "=", "[", "]", "\n", "count", "=", "0", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "readCSV", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "csv", ".", "field_size_limit", "(", "100000000", ")", "\n", "for", "tag", ",", "doc", "in", "readCSV", ":", "\n", "                ", "sentences", "=", "doc", ".", "split", "(", "'.'", ")", "\n", "tag", "=", "int", "(", "tag", ")", "\n", "allowed_tags", "=", "[", "1", ",", "4", "]", "if", "self", ".", "ntags", "==", "2", "else", "[", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "if", "tag", "in", "allowed_tags", ":", "\n", "                    ", "if", "self", ".", "ntags", "==", "2", ":", "\n", "# Adjust the tag to {0: Satire, 1: Trusted}", "\n", "                        ", "tag", "=", "tag", "-", "1", "if", "tag", "==", "1", "else", "tag", "-", "3", "\n", "", "else", ":", "\n", "# {0: Satire, 1: Hoax, 2: Propaganda, 3: Trusted}", "\n", "                        ", "tag", "-=", "1", "\n", "", "sentences_idx", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "                        ", "sentence", "=", "sentence", ".", "lower", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "curr_sentence_idx", "=", "[", "w2i", "[", "x", "]", "for", "x", "in", "sentence", "]", "\n", "sentences_idx", ".", "append", "(", "curr_sentence_idx", "if", "len", "(", "curr_sentence_idx", ")", ">", "0", "else", "[", "w2i", "[", "'<unk>'", "]", "]", ")", "\n", "", "if", "len", "(", "sentences_idx", ")", ">", "1", ":", "\n", "                        ", "data", ".", "append", "(", "(", "sentences_idx", "[", ":", "self", ".", "params", ".", "max_sents_in_a_doc", "]", ",", "tag", ")", ")", "\n", "if", "adj", "is", "not", "None", ":", "\n", "                            ", "new_adj", ".", "append", "(", "adj", "[", "count", "]", ")", "\n", "", "", "count", "+=", "1", "\n", "", "", "", "return", "data", ",", "new_adj", "if", "adj", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.load_adj_matrix": [[138, 144], ["range", "numpy.concatenate", "len", "adjs.append", "os.listdir", "numpy.load", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_adj_matrix", "(", "path", ",", "file_prefix", ")", ":", "\n", "        ", "adjs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "os", ".", "listdir", "(", "path", ")", ")", ")", ":", "\n", "            ", "adjs", ".", "append", "(", "np", ".", "load", "(", "path", "+", "\"/\"", "+", "file_prefix", "+", "str", "(", "i", ")", "+", "'.npy'", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "adjs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.DataLoader.read_testset_sentence_wise": [[145, 167], ["pandas.read_excel", "row[].split", "int", "sentence.lower().replace().strip().split.lower().replace().strip().split.lower().replace().strip().split", "sentences_idx.append", "len", "data.append", "new_adj.append", "sentence.lower().replace().strip().split.lower().replace().strip().split.lower().replace().strip", "len", "sentence.lower().replace().strip().split.lower().replace().strip().split.lower().replace", "sentence.lower().replace().strip().split.lower().replace().strip().split.lower"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "read_testset_sentence_wise", "(", "filename", ",", "w2i", ",", "adj", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_excel", "(", "filename", ")", "\n", "data", "=", "[", "]", "\n", "new_adj", "=", "[", "]", "\n", "count", "=", "0", "\n", "for", "row", "in", "df", ".", "values", ":", "\n", "            ", "sentences", "=", "row", "[", "2", "]", ".", "split", "(", "'.'", ")", "\n", "tag", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "# Tag id is reversed in this dataset", "\n", "tag", "=", "tag", "+", "1", "if", "tag", "==", "0", "else", "tag", "-", "1", "\n", "sentences_idx", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "                ", "sentence", "=", "sentence", ".", "lower", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "curr_sentence_idx", "=", "[", "w2i", "[", "x", "]", "for", "x", "in", "sentence", "]", "\n", "sentences_idx", ".", "append", "(", "curr_sentence_idx", "if", "len", "(", "curr_sentence_idx", ")", ">", "0", "else", "[", "w2i", "[", "'<unk>'", "]", "]", ")", "\n", "", "if", "len", "(", "sentences_idx", ")", ">", "1", ":", "\n", "                ", "data", ".", "append", "(", "(", "sentences_idx", ",", "tag", ")", ")", "\n", "if", "adj", "is", "not", "None", ":", "\n", "                    ", "new_adj", ".", "append", "(", "adj", "[", "count", "]", ")", "\n", "", "", "count", "+=", "1", "\n", "", "return", "data", ",", "new_adj", "if", "adj", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationDataSet.__init__": [[170, 177], ["super().__init__", "len"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "params", ")", ":", "\n", "        ", "super", "(", "ClassificationDataSet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "# data is a list of tuples (sent, label)", "\n", "self", ".", "sents", "=", "[", "x", "[", "0", "]", "for", "x", "in", "data", "]", "\n", "self", ".", "labels", "=", "[", "x", "[", "1", "]", "for", "x", "in", "data", "]", "\n", "self", ".", "num_of_samples", "=", "len", "(", "self", ".", "sents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationDataSet.__len__": [[178, 180], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_of_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationDataSet.__getitem__": [[181, 183], ["len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "sents", "[", "idx", "]", ",", "len", "(", "self", ".", "sents", "[", "idx", "]", ")", ",", "self", ".", "labels", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationDataSet.collate": [[184, 203], ["numpy.array", "numpy.array", "numpy.array", "numpy.flipud", "min", "numpy.zeros", "enumerate", "numpy.argsort", "min", "len", "len"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ")", ":", "\n", "        ", "sents", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", ")", "\n", "sent_lens", "=", "np", ".", "array", "(", "[", "min", "(", "self", ".", "params", ".", "max_sent_len", ",", "x", "[", "1", "]", ")", "for", "x", "in", "batch", "]", ")", "\n", "labels", "=", "np", ".", "array", "(", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", ")", "\n", "\n", "# List of indices according to decreasing order of sentence lengths", "\n", "sorted_input_seq_len", "=", "np", ".", "flipud", "(", "np", ".", "argsort", "(", "sent_lens", ")", ")", "\n", "# Sorting the elements od the batch in decreasing length order", "\n", "input_lens", "=", "sent_lens", "[", "sorted_input_seq_len", "]", "\n", "sents", "=", "sents", "[", "sorted_input_seq_len", "]", "\n", "labels", "=", "labels", "[", "sorted_input_seq_len", "]", "\n", "\n", "# Creating padded sentences", "\n", "sent_max_len", "=", "min", "(", "input_lens", "[", "0", "]", ",", "self", ".", "params", ".", "max_sent_len", ")", "\n", "padded_sents", "=", "np", ".", "zeros", "(", "(", "len", "(", "batch", ")", ",", "sent_max_len", ")", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "padded_sents", "[", "i", ",", ":", "len", "(", "sent", ")", "]", "=", "sent", "[", ":", "sent_max_len", "]", "\n", "\n", "", "return", "padded_sents", ",", "input_lens", ",", "labels", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationGraphDataSet.__init__": [[206, 217], ["super().__init__", "len", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "adj", ",", "params", ")", ":", "\n", "        ", "super", "(", "ClassificationGraphDataSet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "# data is a list of tuples (sent, label)", "\n", "self", ".", "sents", "=", "[", "x", "[", "0", "]", "for", "x", "in", "data", "]", "\n", "self", ".", "labels", "=", "[", "x", "[", "1", "]", "for", "x", "in", "data", "]", "\n", "self", ".", "adjs", "=", "adj", "\n", "self", ".", "num_of_samples", "=", "len", "(", "self", ".", "sents", ")", "\n", "if", "adj", "is", "not", "None", ":", "\n", "            ", "for", "i", ",", "adj", "in", "enumerate", "(", "self", ".", "adjs", ")", ":", "\n", "                ", "assert", "adj", ".", "shape", "[", "0", "]", "==", "len", "(", "self", ".", "sents", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationGraphDataSet.__len__": [[218, 220], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_of_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationGraphDataSet.__getitem__": [[221, 224], ["len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "sents", "[", "idx", "]", ",", "len", "(", "self", ".", "sents", "[", "idx", "]", ")", ",", "self", ".", "labels", "[", "idx", "]", ",", "self", ".", "adjs", "[", "\n", "idx", "]", "if", "self", ".", "adjs", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.ClassificationGraphDataSet.collate": [[225, 254], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "zip", "numpy.array", "numpy.array", "numpy.flipud", "numpy.zeros", "enumerate", "documents.append", "numpy.argsort", "numpy.zeros", "range", "new_adjs.append", "min", "len", "range", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ")", ":", "\n", "        ", "sents", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", ")", "\n", "doc_lens", "=", "np", ".", "array", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", ")", "\n", "labels", "=", "np", ".", "array", "(", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", ")", "\n", "adjs", "=", "np", ".", "array", "(", "[", "x", "[", "3", "]", "for", "x", "in", "batch", "]", ")", "\n", "# Sort sentences within each document by length", "\n", "documents", "=", "[", "]", "\n", "\n", "new_adjs", "=", "[", "]", "\n", "for", "doc", ",", "adj", "in", "zip", "(", "sents", ",", "adjs", ")", ":", "\n", "            ", "curr_lens", "=", "np", ".", "array", "(", "[", "min", "(", "self", ".", "params", ".", "max_sent_len", ",", "len", "(", "x", ")", ")", "for", "x", "in", "doc", "]", ")", "\n", "curr_sents", "=", "np", ".", "array", "(", "doc", ")", "\n", "sorted_input_seq_len", "=", "np", ".", "flipud", "(", "np", ".", "argsort", "(", "curr_lens", ")", ")", "\n", "curr_sents", "=", "curr_sents", "[", "sorted_input_seq_len", "]", "\n", "curr_lens", "=", "curr_lens", "[", "sorted_input_seq_len", "]", "\n", "\n", "if", "self", ".", "adjs", "is", "not", "None", ":", "\n", "                ", "new_adj", "=", "np", ".", "zeros", "(", "adj", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "adj", ")", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "len", "(", "adj", ")", ")", ":", "\n", "                        ", "new_adj", "[", "i", "]", "[", "j", "]", "=", "adj", "[", "sorted_input_seq_len", "[", "i", "]", "]", "[", "sorted_input_seq_len", "[", "j", "]", "]", "\n", "", "", "new_adjs", ".", "append", "(", "new_adj", ")", "\n", "\n", "", "padded_sents", "=", "np", ".", "zeros", "(", "(", "len", "(", "curr_sents", ")", ",", "curr_lens", "[", "0", "]", ")", ")", "\n", "for", "i", ",", "sen", "in", "enumerate", "(", "curr_sents", ")", ":", "\n", "                ", "padded_sents", "[", "i", ",", ":", "len", "(", "sen", ")", "]", "=", "sen", "[", ":", "curr_lens", "[", "0", "]", "]", "\n", "", "documents", ".", "append", "(", "(", "padded_sents", ",", "curr_lens", ")", ")", "\n", "\n", "", "return", "documents", ",", "doc_lens", ",", "labels", ",", "new_adjs", "if", "self", ".", "adjs", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.freezable_defaultdict.__init__": [[257, 261], ["dict.__init__"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "default_factory", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "frozen", "=", "False", "\n", "self", ".", "default_factory", "=", "default_factory", "\n", "super", "(", "freezable_defaultdict", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.freezable_defaultdict.__missing__": [[262, 268], ["data_loader.freezable_defaultdict.default_factory", "data_loader.freezable_defaultdict.default_factory"], "methods", ["None"], ["", "def", "__missing__", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "self", ".", "frozen", ":", "\n", "            ", "return", "self", ".", "default_factory", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", "[", "key", "]", "=", "value", "=", "self", ".", "default_factory", "(", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.data_loader.freezable_defaultdict.freeze": [[269, 271], ["None"], "methods", ["None"], ["", "", "def", "freeze", "(", "self", ")", ":", "\n", "        ", "self", ".", "frozen", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.trainer.Trainer.__init__": [[2, 6], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "utils", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "utils", "=", "utils", "\n", "self", ".", "log_time", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.trainer.Trainer.train": [[7, 12], ["print", "trainer.Trainer.utils.train", "print"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "print", "(", "'-----------{}-------------'", ".", "format", "(", "self", ".", "params", ".", "config", ")", ")", "\n", "training_time", "=", "self", ".", "utils", ".", "train", "(", "pretrained_emb", "=", "None", ",", "save_plots_as", "=", "self", ".", "params", ".", "config", ")", "\n", "self", ".", "log_time", "[", "self", ".", "params", ".", "config", "]", "=", "training_time", "\n", "print", "(", "'-----------------------------------------'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphConvolution.__init__": [[13, 21], ["torch.nn.modules.module.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "layers.GraphConvolution.reset_parameters", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphConvolution.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "dropout", "=", "0.", ",", "act", "=", "F", ".", "relu", ")", ":", "\n", "        ", "super", "(", "GraphConvolution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "act", "=", "act", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "in_features", ",", "out_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphConvolution.reset_parameters": [[22, 24], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphConvolution.forward": [[25, 31], ["torch.dropout", "torch.dropout", "torch.dropout", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "torch.spmm", "layers.GraphConvolution.act"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "adj", ")", ":", "\n", "        ", "input", "=", "F", ".", "dropout", "(", "input", ",", "self", ".", "dropout", ",", "self", ".", "training", ")", "\n", "support", "=", "torch", ".", "mm", "(", "input", ",", "self", ".", "weight", ")", "\n", "output", "=", "torch", ".", "spmm", "(", "adj", ",", "support", ")", "\n", "output", "=", "self", ".", "act", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphConvolution.__repr__": [[32, 36], ["str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "' ('", "+", "str", "(", "self", ".", "in_features", ")", "+", "' -> '", "+", "str", "(", "self", ".", "out_features", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphAttentionLayer.__init__": [[43, 57], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "dropout", ",", "alpha", ",", "concat", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphAttentionLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "concat", "=", "concat", "\n", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "size", "=", "(", "in_features", ",", "out_features", ")", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W", ".", "data", ",", "gain", "=", "1.414", ")", "\n", "self", ".", "a", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "size", "=", "(", "2", "*", "out_features", ",", "1", ")", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "a", ".", "data", ",", "gain", "=", "1.414", ")", "\n", "\n", "self", ".", "leakyrelu", "=", "nn", ".", "LeakyReLU", "(", "self", ".", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphAttentionLayer.forward": [[58, 75], ["torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "layers.GraphAttentionLayer.leakyrelu", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mm.size", "torch.mm.size", "torch.mm.size", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.elu", "torch.elu", "torch.elu", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mm.repeat().view", "torch.mm.repeat().view", "torch.mm.repeat().view", "torch.mm.repeat", "torch.mm.repeat", "torch.mm.repeat", "torch.mm.repeat", "torch.mm.repeat", "torch.mm.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "adj", ")", ":", "\n", "        ", "h", "=", "torch", ".", "mm", "(", "input", ",", "self", ".", "W", ")", "\n", "N", "=", "h", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "a_input", "=", "torch", ".", "cat", "(", "[", "h", ".", "repeat", "(", "1", ",", "N", ")", ".", "view", "(", "N", "*", "N", ",", "-", "1", ")", ",", "h", ".", "repeat", "(", "N", ",", "1", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "N", ",", "-", "1", ",", "2", "*", "self", ".", "out_features", ")", "\n", "e", "=", "self", ".", "leakyrelu", "(", "torch", ".", "matmul", "(", "a_input", ",", "self", ".", "a", ")", ".", "squeeze", "(", "2", ")", ")", "\n", "\n", "zero_vec", "=", "-", "9e15", "*", "torch", ".", "ones_like", "(", "e", ")", "\n", "attention", "=", "torch", ".", "where", "(", "adj", ">", "0", ",", "e", ",", "zero_vec", ")", "\n", "attention", "=", "F", ".", "softmax", "(", "attention", ",", "dim", "=", "1", ")", "\n", "attention", "=", "F", ".", "dropout", "(", "attention", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "h_prime", "=", "torch", ".", "matmul", "(", "attention", ",", "h", ")", "\n", "\n", "if", "self", ".", "concat", ":", "\n", "            ", "return", "F", ".", "elu", "(", "h_prime", ")", ",", "attention", "\n", "", "else", ":", "\n", "            ", "return", "h_prime", ",", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.layers.GraphAttentionLayer.__repr__": [[76, 78], ["str", "str"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "' ('", "+", "str", "(", "self", ".", "in_features", ")", "+", "' -> '", "+", "str", "(", "self", ".", "out_features", ")", "+", "')'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.Classify.__init__": [[14, 62], ["super().__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "model.Classify.word_embeddings.weight.data.copy_", "model.CnnEncoder", "model.LstmEncoder", "layers.GraphConvolution", "torch.Linear", "torch.Linear", "torch.Linear", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "layers.GraphConvolution", "torch.Linear", "torch.Linear", "torch.Linear", "layers.GraphAttentionLayer", "enumerate", "layers.GraphAttentionLayer", "torch.Linear", "torch.Linear", "torch.Linear", "layers.GraphAttentionLayer", "model.Classify.add_module", "layers.GraphAttentionLayer", "enumerate", "layers.GraphAttentionLayer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "layers.GraphAttentionLayer", "model.Classify.add_module", "range"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "vocab_size", ",", "ntags", ",", "pte", "=", "None", ")", ":", "\n", "        ", "super", "(", "Classify", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "params", ".", "emb_dim", ")", "\n", "if", "pte", "is", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "word_embeddings", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "pte", ")", ")", "\n", "", "self", ".", "text_encoder", "=", "CnnEncoder", "(", "\n", "params", ".", "filters", ",", "params", ".", "emb_dim", ",", "params", ".", "kernel_size", ")", "if", "params", ".", "encoder", "==", "1", "else", "LstmEncoder", "(", "\n", "params", ".", "hidden_dim", ",", "params", ".", "emb_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "params", ".", "dropout", ")", "\n", "if", "params", ".", "encoder", "==", "2", ":", "\n", "            ", "self", ".", "gcn1", "=", "GraphConvolution", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "params", ".", "dropout", ",", "act", "=", "F", ".", "relu", ")", "\n", "self", ".", "linear_transform", "=", "nn", ".", "Linear", "(", "in_features", "=", "params", ".", "node_emb_dim", ",", "\n", "out_features", "=", "ntags", ")", "\n", "", "elif", "params", ".", "encoder", "==", "3", ":", "\n", "            ", "self", ".", "gcn1", "=", "GraphConvolution", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "params", ".", "dropout", ",", "act", "=", "F", ".", "relu", ")", "\n", "# Add the attention thingy", "\n", "self", ".", "linear_transform", "=", "nn", ".", "Linear", "(", "in_features", "=", "params", ".", "node_emb_dim", ",", "\n", "out_features", "=", "ntags", ")", "\n", "", "elif", "params", ".", "encoder", "==", "4", ":", "\n", "            ", "self", ".", "gcn1", "=", "GraphAttentionLayer", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "params", ".", "dropout", ",", "0.2", ")", "\n", "self", ".", "attentions", "=", "[", "GraphAttentionLayer", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "dropout", "=", "params", ".", "dropout", ",", "\n", "alpha", "=", "0.2", ",", "concat", "=", "True", ")", "for", "_", "in", "range", "(", "0", ")", "]", "\n", "for", "i", ",", "attention", "in", "enumerate", "(", "self", ".", "attentions", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "'attention_{}'", ".", "format", "(", "i", ")", ",", "attention", ")", "\n", "\n", "", "self", ".", "out_att", "=", "GraphAttentionLayer", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "dropout", "=", "params", ".", "dropout", ",", "\n", "alpha", "=", "0.2", ",", "concat", "=", "False", ")", "\n", "# Add the attention thingy", "\n", "self", ".", "linear_transform", "=", "nn", ".", "Linear", "(", "in_features", "=", "params", ".", "node_emb_dim", ",", "\n", "out_features", "=", "ntags", ")", "\n", "", "elif", "params", ".", "encoder", "==", "5", ":", "\n", "            ", "self", ".", "gcn1", "=", "GraphAttentionLayer", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "params", ".", "dropout", ",", "0.2", ")", "\n", "self", ".", "attentions", "=", "[", "GraphAttentionLayer", "(", "params", ".", "hidden_dim", ",", "params", ".", "node_emb_dim", ",", "dropout", "=", "params", ".", "dropout", ",", "\n", "alpha", "=", "0.2", ",", "concat", "=", "True", ")", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "attention", "in", "enumerate", "(", "self", ".", "attentions", ")", ":", "\n", "                ", "self", ".", "add_module", "(", "'attention_{}'", ".", "format", "(", "i", ")", ",", "attention", ")", "\n", "\n", "", "self", ".", "out_att", "=", "GraphAttentionLayer", "(", "params", ".", "node_emb_dim", "*", "2", ",", "params", ".", "node_emb_dim", ",", "dropout", "=", "params", ".", "dropout", ",", "\n", "alpha", "=", "0.2", ",", "concat", "=", "False", ")", "\n", "# Add the attention thingy", "\n", "self", ".", "linear_transform", "=", "nn", ".", "Linear", "(", "in_features", "=", "params", ".", "node_emb_dim", ",", "\n", "out_features", "=", "ntags", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear_transform", "=", "nn", ".", "Linear", "(", "in_features", "=", "params", ".", "hidden_dim", ",", "\n", "out_features", "=", "ntags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.Classify.forward": [[63, 208], ["model.Classify.word_embeddings", "model.Classify.text_encoder", "model.Classify.dropout", "model.Classify.linear_transform", "torch.relu", "torch.relu", "torch.relu", "numpy.fill_diagonal", "model.Classify.to_tensor", "model.Classify.gcn1", "torch.elu.max", "numpy.ones", "numpy.fill_diagonal", "model.Classify.to_tensor", "model.Classify.gcn1", "torch.softmax", "torch.softmax", "torch.softmax", "torch.elu.max", "numpy.ones", "numpy.matrix", "matplotlib.figure", "matplotlib.figure", "matplotlib.imshow", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.figure.colorbar", "matplotlib.figure.savefig", "numpy.fill_diagonal", "model.Classify.to_tensor", "torch.dropout", "torch.dropout", "torch.dropout", "model.Classify.out_att", "torch.elu", "torch.elu", "torch.elu", "torch.elu.max", "torch.elu.size", "torch.elu.size", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "numpy.sqrt", "torch.softmax.data.numpy", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "numpy.ones", "numpy.matrix", "matplotlib.figure", "matplotlib.figure", "matplotlib.imshow", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.figure.colorbar", "matplotlib.figure.savefig", "numpy.matrix", "matplotlib.figure", "matplotlib.figure", "matplotlib.imshow", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.figure.colorbar", "matplotlib.figure.savefig", "numpy.fill_diagonal", "model.Classify.to_tensor", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.dropout", "torch.dropout", "torch.dropout", "model.Classify.out_att", "torch.elu", "torch.elu", "torch.elu", "torch.elu.max", "torch.elu.size", "torch.elu.size", "torch.elu.transpose", "range", "range", "model.Classify.cpu().data.numpy", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "attn.cpu().data.numpy", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "open", "open.close", "numpy.ones", "torch.softmax.", "hs.append", "numpy.matrix", "matplotlib.figure", "matplotlib.figure", "matplotlib.imshow", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.figure.colorbar", "matplotlib.figure.savefig", "numpy.matrix", "matplotlib.figure", "matplotlib.figure", "matplotlib.imshow", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.figure.colorbar", "matplotlib.figure.savefig", "torch.elu.size", "torch.elu.size", "range", "range", "range", "range", "open.write", "numpy.matrix", "matplotlib.figure", "matplotlib.figure", "matplotlib.imshow", "matplotlib.imshow", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.figure.colorbar", "matplotlib.figure.savefig", "model.Classify.cpu().data.numpy", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "attn.cpu().data.numpy", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "open", "open.close", "torch.elu.size", "torch.elu.size", "att_i.cpu().data.numpy", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "range", "range", "range", "range", "open.write", "model.Classify.cpu", "attn.cpu", "range", "range", "model.Classify.cpu", "attn.cpu", "att_i.cpu"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor"], ["", "", "def", "forward", "(", "self", ",", "input_sents", ",", "input_lens", ",", "adj", "=", "None", ",", "actual_sentence", "=", "None", ")", ":", "\n", "        ", "embeds", "=", "self", ".", "word_embeddings", "(", "input_sents", ")", "# bs * max_seq_len * emb", "\n", "h", "=", "self", ".", "text_encoder", "(", "embeds", ",", "input_lens", ")", "# bs * 100 * hidden", "\n", "h", "=", "self", ".", "dropout", "(", "F", ".", "relu", "(", "h", ")", ")", "# Relu activation and dropout", "\n", "if", "self", ".", "params", ".", "encoder", "==", "2", ":", "\n", "# Currently it's a dummy matrix with all edge weights one", "\n", "            ", "adj_matrix", "=", "np", ".", "ones", "(", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "0", ")", ")", ")", "if", "adj", "is", "None", "else", "adj", "\n", "np", ".", "fill_diagonal", "(", "adj_matrix", ",", "0", ")", "\n", "adj_matrix", "=", "self", ".", "to_tensor", "(", "adj_matrix", ")", "\n", "h", "=", "self", ".", "gcn1", "(", "h", ",", "adj_matrix", ")", "\n", "# Simple max pool on all node representations", "\n", "h", ",", "_", "=", "h", ".", "max", "(", "dim", "=", "0", ")", "\n", "", "elif", "self", ".", "params", ".", "encoder", "==", "3", ":", "\n", "# Currently it's a dummy matrix with all edge weights one", "\n", "            ", "adj_matrix", "=", "np", ".", "ones", "(", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "0", ")", ")", ")", "if", "adj", "is", "None", "else", "adj", "\n", "# Setting link between same sentences to 0", "\n", "np", ".", "fill_diagonal", "(", "adj_matrix", ",", "0", ")", "\n", "adj_matrix", "=", "self", ".", "to_tensor", "(", "adj_matrix", ")", "\n", "h", "=", "self", ".", "gcn1", "(", "h", ",", "adj_matrix", ")", "# num_sentences * node_emb_dim", "\n", "# Adding self attention layer on the representations", "\n", "att", "=", "F", ".", "softmax", "(", "torch", ".", "mm", "(", "h", ",", "h", ".", "transpose", "(", "0", ",", "1", ")", ")", "/", "np", ".", "sqrt", "(", "self", ".", "params", ".", "node_emb_dim", ")", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "params", ".", "plot", "==", "1", ":", "\n", "                ", "mat", "=", "np", ".", "matrix", "(", "att", ".", "data", ".", "numpy", "(", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "mat", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cm", ".", "hot", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "xlabel", "(", "'Sentence Number'", ")", "\n", "plt", ".", "ylabel", "(", "'Sentence Number'", ")", "\n", "fig", ".", "colorbar", "(", "im", ")", "\n", "if", "mat", ".", "shape", "[", "0", "]", "<", "10", ":", "\n", "                    ", "plt", ".", "xticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "plt", ".", "yticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "", "fig", ".", "savefig", "(", "'plots/sample_attn_{}.png'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "# Simple max pool on all node representations", "\n", "", "h", ",", "_", "=", "h", ".", "max", "(", "dim", "=", "0", ")", "\n", "", "elif", "self", ".", "params", ".", "encoder", "==", "4", ":", "\n", "# Currently it's a dummy matrix with all edge weights one", "\n", "            ", "adj_matrix", "=", "np", ".", "ones", "(", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "0", ")", ")", ")", "if", "adj", "is", "None", "else", "adj", "\n", "# Setting link between same sentences to 0", "\n", "np", ".", "fill_diagonal", "(", "adj_matrix", ",", "0", ")", "\n", "adj_matrix", "=", "self", ".", "to_tensor", "(", "adj_matrix", ")", "\n", "\n", "h", "=", "F", ".", "dropout", "(", "h", ",", "self", ".", "params", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "h", ",", "attn", "=", "self", ".", "out_att", "(", "h", ",", "adj_matrix", ")", "\n", "h", "=", "F", ".", "elu", "(", "h", ")", "\n", "if", "self", ".", "params", ".", "plot", "==", "1", ":", "\n", "\n", "                ", "mat", "=", "np", ".", "matrix", "(", "adj_matrix", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "mat", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cm", ".", "hot", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "xlabel", "(", "'Sentence Number'", ")", "\n", "# for j, actual_sent in enumerate(actual_sentence):", "\n", "#    plt.text(10, 2 + j, actual_sent, ha='right', wrap=True, size=2)", "\n", "plt", ".", "ylabel", "(", "'Sentence Number'", ")", "\n", "if", "mat", ".", "shape", "[", "0", "]", "<", "10", ":", "\n", "                    ", "plt", ".", "xticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "plt", ".", "yticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "", "fig", ".", "colorbar", "(", "im", ")", "\n", "fig", ".", "savefig", "(", "'plots/adj/sample_adj_matrix_{}.png'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "mat", "=", "np", ".", "matrix", "(", "attn", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "mat", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cm", ".", "hot", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "xlabel", "(", "'Sentence Number'", ")", "\n", "#for j, actual_sent in enumerate(actual_sentence):", "\n", "#    plt.text(10, 2 + j, actual_sent, ha='right', wrap=True, size=2)", "\n", "plt", ".", "ylabel", "(", "'Sentence Number'", ")", "\n", "if", "mat", ".", "shape", "[", "0", "]", "<", "10", ":", "\n", "                    ", "plt", ".", "xticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "plt", ".", "yticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "", "fig", ".", "colorbar", "(", "im", ")", "\n", "fig", ".", "savefig", "(", "'plots/adj/sample_attn_gat_{}.png'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "if", "actual_sentence", "is", "not", "None", ":", "\n", "                    ", "file", "=", "open", "(", "'plots/adj/{}.txt'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ",", "'w'", ")", "\n", "for", "actual_sent", "in", "actual_sentence", ":", "\n", "                        ", "file", ".", "write", "(", "actual_sent", "+", "\"\\n\"", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "\n", "# Simple max pool on all node representations", "\n", "", "", "h", ",", "_", "=", "h", ".", "max", "(", "dim", "=", "0", ")", "\n", "", "elif", "self", ".", "params", ".", "encoder", "==", "5", ":", "\n", "# Currently it's a dummy matrix with all edge weights one", "\n", "            ", "adj_matrix", "=", "np", ".", "ones", "(", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "0", ")", ")", ")", "if", "adj", "is", "None", "else", "adj", "\n", "# Setting link between same sentences to 0", "\n", "np", ".", "fill_diagonal", "(", "adj_matrix", ",", "0", ")", "\n", "adj_matrix", "=", "self", ".", "to_tensor", "(", "adj_matrix", ")", "\n", "\n", "hs", "=", "[", "]", "\n", "for", "i", ",", "att", "in", "enumerate", "(", "self", ".", "attentions", ")", ":", "\n", "                ", "h_i", ",", "att_i", "=", "att", "(", "h", ",", "adj_matrix", ")", "\n", "if", "self", ".", "params", ".", "plot", "==", "1", ":", "\n", "                    ", "mat", "=", "np", ".", "matrix", "(", "att_i", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "mat", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cm", ".", "hot", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "xlabel", "(", "'Sentence Number'", ")", "\n", "if", "mat", ".", "shape", "[", "0", "]", "<", "10", ":", "\n", "                        ", "plt", ".", "xticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "plt", ".", "yticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "#for j, actual_sent in enumerate(actual_sentence):", "\n", "#    plt.text(10, 2 + j, actual_sent, ha='right', wrap=True, size=2)", "\n", "", "plt", ".", "ylabel", "(", "'Sentence Number'", ")", "\n", "fig", ".", "colorbar", "(", "im", ")", "\n", "fig", ".", "savefig", "(", "'plots/sample_attn_gat_{}_{}.png'", ".", "format", "(", "i", ",", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "hs", ".", "append", "(", "h_i", ")", "\n", "", "h", "=", "torch", ".", "cat", "(", "hs", ",", "dim", "=", "1", ")", "\n", "h", "=", "F", ".", "dropout", "(", "h", ",", "self", ".", "params", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "h", ",", "attn", "=", "self", ".", "out_att", "(", "h", ",", "adj_matrix", ")", "\n", "h", "=", "F", ".", "elu", "(", "h", ")", "\n", "if", "self", ".", "params", ".", "plot", "==", "1", ":", "\n", "\n", "                ", "mat", "=", "np", ".", "matrix", "(", "adj_matrix", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "mat", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cm", ".", "hot", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "xlabel", "(", "'Sentence Number'", ")", "\n", "# for j, actual_sent in enumerate(actual_sentence):", "\n", "#    plt.text(10, 2 + j, actual_sent, ha='right', wrap=True, size=2)", "\n", "plt", ".", "ylabel", "(", "'Sentence Number'", ")", "\n", "if", "mat", ".", "shape", "[", "0", "]", "<", "10", ":", "\n", "                    ", "plt", ".", "xticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "plt", ".", "yticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "", "fig", ".", "colorbar", "(", "im", ")", "\n", "fig", ".", "savefig", "(", "'plots/adj/sample_adj_matrix_{}.png'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "mat", "=", "np", ".", "matrix", "(", "attn", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "mat", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cm", ".", "hot", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "xlabel", "(", "'Sentence Number'", ")", "\n", "#for j, actual_sent in enumerate(actual_sentence):", "\n", "#    plt.text(10, 2 + j, actual_sent, ha='right', wrap=True, size=2)", "\n", "plt", ".", "ylabel", "(", "'Sentence Number'", ")", "\n", "if", "mat", ".", "shape", "[", "0", "]", "<", "10", ":", "\n", "                    ", "plt", ".", "xticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "plt", ".", "yticks", "(", "range", "(", "0", ",", "mat", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "", "fig", ".", "colorbar", "(", "im", ")", "\n", "fig", ".", "savefig", "(", "'plots/adj/sample_attn_gat_{}.png'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "if", "actual_sentence", "is", "not", "None", ":", "\n", "                    ", "file", "=", "open", "(", "'plots/adj/{}.txt'", ".", "format", "(", "mat", ".", "shape", "[", "0", "]", ")", ",", "'w'", ")", "\n", "for", "actual_sent", "in", "actual_sentence", ":", "\n", "                        ", "file", ".", "write", "(", "actual_sent", "+", "\"\\n\"", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "\n", "# Simple max pool on all node representations", "\n", "", "", "h", ",", "_", "=", "h", ".", "max", "(", "dim", "=", "0", ")", "\n", "", "h", "=", "self", ".", "linear_transform", "(", "h", ")", "# bs * ntags", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.Classify.to_tensor": [[209, 217], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "to_tensor", "(", "arr", ")", ":", "\n", "# list -> Tensor (on GPU if possible)", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "tensor", "=", "torch", ".", "tensor", "(", "arr", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "torch", ".", "tensor", "(", "arr", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.LstmEncoder.__init__": [[220, 224], ["super().__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_dimension", ",", "embedding_dimension", ")", ":", "\n", "        ", "super", "(", "LstmEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dimension", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "embedding_dimension", ",", "hidden_dimension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.LstmEncoder.forward": [[225, 238], ["embeds.permute.permute.permute", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.LstmEncoder.lstm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "embeds", ",", "seq_lens", ")", ":", "\n", "# By default a LSTM requires the batch_size as the second dimension", "\n", "# You could also use batch_first=True while declaring the LSTM module, then this permute won't be required", "\n", "        ", "embeds", "=", "embeds", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# seq_len * batch_size * embedding_dim", "\n", "\n", "packed_input", "=", "pack_padded_sequence", "(", "embeds", ",", "seq_lens", ")", "\n", "_", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "packed_input", ")", "\n", "# two outputs are returned. _ stores all the hidden representation at each time_step", "\n", "# (hn, cn) is just for convenience, and is hidden representation and context after the last time_step", "\n", "# _ : will be of PackedSequence type, once unpacked, you will get a tensor of size: seq_len x bs x hidden_dim", "\n", "# hn : 1 x bs x hidden_dim", "\n", "\n", "return", "hn", "[", "-", "1", "]", "# bs * hidden_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.CnnEncoder.__init__": [[241, 244], ["super().__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__"], ["    ", "def", "__init__", "(", "self", ",", "filters", ",", "emb_dim", ",", "kernel_size", ")", ":", "\n", "        ", "super", "(", "CnnEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_tri", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "emb_dim", ",", "out_channels", "=", "filters", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.model.CnnEncoder.forward": [[245, 252], ["embeds.permute.permute.permute", "model.CnnEncoder.conv_tri", "torch.relu", "torch.relu", "torch.relu", "torch.relu.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "embeds", ",", "seq_lens", ")", ":", "\n", "        ", "embeds", "=", "embeds", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# bs * ed * seq", "\n", "h", "=", "self", ".", "conv_tri", "(", "embeds", ")", "# bs * hd * seq", "\n", "# Max pooling", "\n", "h", "=", "h", ".", "max", "(", "dim", "=", "2", ")", "[", "0", "]", "# bs * hd", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "return", "h", "# bs * hidden_dim", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.__init__": [[14, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "dl", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "data_loader", "=", "dl", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor": [[18, 26], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor().type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "to_tensor", "(", "arr", ")", ":", "\n", "# list -> Tensor (on GPU if possible)", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "tensor", "=", "torch", ".", "tensor", "(", "arr", ")", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "torch", ".", "tensor", "(", "arr", ")", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_dev_loss_and_acc": [[27, 47], ["model.eval", "util.Utils.to_tensor", "loss_fn", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "len", "losses.append", "numpy.asscalar", "util.Utils.get_gcn_logits", "util.Utils.to_tensor", "model", "loss_fn.item", "numpy.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_gcn_logits", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor"], ["", "def", "get_dev_loss_and_acc", "(", "self", ",", "model", ",", "loss_fn", ")", ":", "\n", "        ", "losses", "=", "[", "]", "\n", "hits", "=", "0", "\n", "total", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "for", "sents", ",", "lens", ",", "labels", ",", "adjs", "in", "self", ".", "data_loader", ".", "dev_data_loader", ":", "\n", "            ", "y_batch", "=", "self", ".", "to_tensor", "(", "labels", ")", "\n", "if", "self", ".", "params", ".", "encoder", ">=", "2", ":", "\n", "# This is currently unbatched", "\n", "                ", "logits", "=", "self", ".", "get_gcn_logits", "(", "model", ",", "sents", ",", "adjs", ")", "\n", "", "else", ":", "\n", "                ", "x_batch", "=", "self", ".", "to_tensor", "(", "sents", ")", "\n", "logits", "=", "model", "(", "x_batch", ",", "lens", ")", "\n", "\n", "", "loss", "=", "loss_fn", "(", "logits", ",", "y_batch", ")", "\n", "hits", "+=", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "==", "y_batch", ")", ".", "item", "(", ")", "\n", "total", "+=", "len", "(", "sents", ")", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "np", ".", "asscalar", "(", "np", ".", "mean", "(", "losses", ")", ")", ",", "hits", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_gcn_logits": [[48, 58], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "util.Utils.to_tensor", "logits.append", "model", "model"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor"], ["", "def", "get_gcn_logits", "(", "self", ",", "model", ",", "docs", ",", "adjs", ",", "actual_sentences", "=", "None", ")", ":", "\n", "        ", "logits", "=", "[", "]", "\n", "for", "i", ",", "(", "sents", ",", "sent_lens", ")", "in", "enumerate", "(", "docs", ")", ":", "\n", "            ", "x_batch", "=", "self", ".", "to_tensor", "(", "sents", ")", "\n", "if", "actual_sentences", "is", "not", "None", ":", "\n", "                ", "logit", "=", "model", "(", "x_batch", ",", "sent_lens", ",", "adjs", "[", "i", "]", "if", "adjs", "is", "not", "None", "else", "None", ",", "actual_sentences", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "logit", "=", "model", "(", "x_batch", ",", "sent_lens", ",", "adjs", "[", "i", "]", "if", "adjs", "is", "not", "None", "else", "None", ")", "\n", "", "logits", ".", "append", "(", "logit", ")", "\n", "", "return", "torch", ".", "stack", "(", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.train": [[59, 144], ["model.cuda.Classify", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Adam", "torch.Adam", "timeit.default_timer", "range", "matplotlib.figure", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.legend", "matplotlib.legend", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.figure.savefig", "model.cuda.cuda.cuda", "model.cuda.cuda.parameters", "model.cuda.cuda.train", "tqdm.tqdm.tqdm", "util.Utils.get_dev_loss_and_acc", "train_losses.append", "dev_losses.append", "train_accs.append", "dev_accs.append", "tqdm.tqdm.tqdm.write", "range", "range", "numpy.arange", "timeit.default_timer", "len", "util.Utils.to_tensor", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "len", "torch.Adam.zero_grad", "torch.nn.CrossEntropyLoss.backward", "torch.Adam.step", "torch.save", "torch.save", "torch.save", "torch.save", "util.Utils.get_gcn_logits", "util.Utils.to_tensor", "model.cuda.cuda.", "len", "torch.Adam.state_dict", "torch.Adam.load_state_dict", "tqdm.tqdm.tqdm.write", "model.cuda.cuda.state_dict", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.train", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_dev_loss_and_acc", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_gcn_logits", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor"], ["", "def", "train", "(", "self", ",", "pretrained_emb", ",", "save_plots_as", ")", ":", "\n", "        ", "model", "=", "Classify", "(", "self", ".", "params", ",", "vocab_size", "=", "len", "(", "self", ".", "data_loader", ".", "w2i", ")", ",", "\n", "ntags", "=", "self", ".", "data_loader", ".", "ntags", ",", "pte", "=", "pretrained_emb", ")", "\n", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "params", ".", "lr", ",", "weight_decay", "=", "self", ".", "params", ".", "weight_decay", ")", "\n", "\n", "# Variables for plotting", "\n", "train_losses", "=", "[", "]", "\n", "dev_losses", "=", "[", "]", "\n", "train_accs", "=", "[", "]", "\n", "dev_accs", "=", "[", "]", "\n", "s_t", "=", "timer", "(", ")", "\n", "prev_best", "=", "0", "\n", "patience", "=", "0", "\n", "\n", "# Start the training loop", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "params", ".", "max_epochs", "+", "1", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "hits", "=", "0", "\n", "total", "=", "0", "\n", "for", "sents", ",", "lens", ",", "labels", ",", "adjs", "in", "tqdm", "(", "self", ".", "data_loader", ".", "train_data_loader", ")", ":", "\n", "                ", "y_batch", "=", "self", ".", "to_tensor", "(", "labels", ")", "\n", "\n", "if", "self", ".", "params", ".", "encoder", ">=", "2", ":", "\n", "# This is currently unbatched", "\n", "                    ", "logits", "=", "self", ".", "get_gcn_logits", "(", "model", ",", "sents", ",", "adjs", ")", "\n", "", "else", ":", "\n", "# Converting data to tensors", "\n", "                    ", "x_batch", "=", "self", ".", "to_tensor", "(", "sents", ")", "\n", "\n", "# Forward pass", "\n", "logits", "=", "model", "(", "x_batch", ",", "lens", ")", "\n", "\n", "", "loss", "=", "loss_fn", "(", "logits", ",", "y_batch", ")", "\n", "\n", "# Book keeping", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "hits", "+=", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "==", "y_batch", ")", ".", "item", "(", ")", "\n", "# One can alternatively do this accuracy computation on cpu by,", "\n", "# moving the logits to cpu: logits.data.cpu().numpy(), and then using numpy argmax.", "\n", "# However, we should always avoid moving tensors between devices if possible for faster computation", "\n", "total", "+=", "len", "(", "sents", ")", "\n", "\n", "# Back-prop", "\n", "optimizer", ".", "zero_grad", "(", ")", "# Reset the gradients", "\n", "loss", ".", "backward", "(", ")", "# Back propagate the gradients", "\n", "optimizer", ".", "step", "(", ")", "# Update the network", "\n", "\n", "# Compute loss and acc for dev set", "\n", "", "dev_loss", ",", "dev_acc", "=", "self", ".", "get_dev_loss_and_acc", "(", "model", ",", "loss_fn", ")", "\n", "train_losses", ".", "append", "(", "train_loss", "/", "len", "(", "self", ".", "data_loader", ".", "train_data_loader", ")", ")", "\n", "dev_losses", ".", "append", "(", "dev_loss", ")", "\n", "train_accs", ".", "append", "(", "hits", "/", "total", ")", "\n", "dev_accs", ".", "append", "(", "dev_acc", ")", "\n", "tqdm", ".", "write", "(", "\"Epoch: {}, Train loss: {}, Train acc: {}, Dev loss: {}, Dev acc: {}\"", ".", "format", "(", "\n", "epoch", ",", "train_loss", ",", "hits", "/", "total", ",", "dev_loss", ",", "dev_acc", ")", ")", "\n", "if", "dev_acc", "<", "prev_best", ":", "\n", "                ", "patience", "+=", "1", "\n", "if", "patience", "==", "3", ":", "\n", "# Reduce the learning rate by a factor of 2 if dev acc doesn't increase for 3 epochs", "\n", "# Learning rate annealing", "\n", "                    ", "optim_state", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "optim_state", "[", "'param_groups'", "]", "[", "0", "]", "[", "'lr'", "]", "=", "optim_state", "[", "'param_groups'", "]", "[", "0", "]", "[", "'lr'", "]", "/", "2", "\n", "optimizer", ".", "load_state_dict", "(", "optim_state", ")", "\n", "tqdm", ".", "write", "(", "'Dev accuracy did not increase, reducing the learning rate by 2 !!!'", ")", "\n", "patience", "=", "0", "\n", "", "", "else", ":", "\n", "                ", "prev_best", "=", "dev_acc", "\n", "# Save the model", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "\"models/model_{}.t7\"", ".", "format", "(", "save_plots_as", ")", ")", "\n", "\n", "# Acc vs time plot", "\n", "", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "range", "(", "1", ",", "self", ".", "params", ".", "max_epochs", "+", "1", ")", ",", "train_accs", ",", "color", "=", "'b'", ",", "label", "=", "'train'", ")", "\n", "plt", ".", "plot", "(", "range", "(", "1", ",", "self", ".", "params", ".", "max_epochs", "+", "1", ")", ",", "dev_accs", ",", "color", "=", "'r'", ",", "label", "=", "'dev'", ")", "\n", "plt", ".", "ylabel", "(", "'accuracy'", ")", "\n", "plt", ".", "xlabel", "(", "'epochs'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "1", ",", "self", ".", "params", ".", "max_epochs", "+", "1", ",", "step", "=", "4", ")", ")", "\n", "fig", ".", "savefig", "(", "'data/'", "+", "'{}_accuracy.png'", ".", "format", "(", "save_plots_as", ")", ")", "\n", "\n", "return", "timer", "(", ")", "-", "s_t", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_pre_trained_embeddings": [[145, 162], ["print", "numpy.random.uniform", "print", "numpy.array", "open", "f.readlines", "len", "row.split", "numpy.array().astype", "len", "numpy.array", "len"], "methods", ["None"], ["", "def", "get_pre_trained_embeddings", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Reading pre-trained embeddings...\"", ")", "\n", "embeddings", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ",", "(", "len", "(", "self", ".", "data_loader", ".", "w2i", ")", ",", "self", ".", "params", ".", "emb_dim", ")", ")", "\n", "count", "=", "0", "\n", "with", "open", "(", "self", ".", "params", ".", "pte", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "ignore_first_row", "=", "True", "\n", "for", "row", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "if", "ignore_first_row", ":", "\n", "                    ", "ignore_first_row", "=", "False", "\n", "continue", "\n", "", "split_row", "=", "row", ".", "split", "(", "\" \"", ")", "\n", "vec", "=", "np", ".", "array", "(", "split_row", "[", "1", ":", "-", "1", "]", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "if", "split_row", "[", "0", "]", "in", "self", ".", "data_loader", ".", "w2i", "and", "len", "(", "vec", ")", "==", "self", ".", "params", ".", "emb_dim", ":", "\n", "                    ", "embeddings", "[", "self", ".", "data_loader", ".", "w2i", "[", "split_row", "[", "0", "]", "]", "]", "=", "vec", "\n", "count", "+=", "1", "\n", "", "", "", "print", "(", "\"Successfully loaded {} embeddings out of {}\"", ".", "format", "(", "count", ",", "len", "(", "self", ".", "data_loader", ".", "w2i", ")", ")", ")", "\n", "return", "np", ".", "array", "(", "embeddings", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "utils", ",", "data_loader", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "utils", "=", "utils", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator.get_sentences_from_indices": [[18, 26], ["enumerate", "actual_sentences.append", "sentences.append", "int"], "methods", ["None"], ["", "def", "get_sentences_from_indices", "(", "self", ",", "docs", ")", ":", "\n", "        ", "actual_sentences", "=", "[", "]", "\n", "for", "doc", ",", "sent_lens", "in", "docs", ":", "\n", "            ", "sentences", "=", "[", "]", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "                ", "sentences", ".", "append", "(", "' '", ".", "join", "(", "[", "self", ".", "data_loader", ".", "i2w", "[", "int", "(", "wid", ")", "]", "for", "wid", "in", "sent", "[", ":", "sent_lens", "[", "i", "]", "]", "]", ")", ")", "\n", "", "actual_sentences", ".", "append", "(", "sentences", ")", "\n", "", "return", "actual_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux": [[27, 52], ["tqdm.tqdm.tqdm", "evaluator.Evaluator.utils.to_tensor", "torch.argmax", "torch.sum().item", "len", "evaluator.Evaluator.utils.get_gcn_logits", "evaluator.Evaluator.utils.to_tensor", "model", "torch.argmax.cpu().data.numpy", "numpy.concatenate", "numpy.concatenate", "torch.sum", "torch.argmax.cpu().data.numpy", "torch.argmax.cpu", "torch.argmax.cpu"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.get_gcn_logits", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.to_tensor"], ["", "def", "_evaluate_aux", "(", "self", ",", "model", ",", "data_loader", ")", ":", "\n", "        ", "hits", "=", "0", "\n", "total", "=", "0", "\n", "all_actual", "=", "None", "\n", "all_predicted", "=", "None", "\n", "for", "sents", ",", "lens", ",", "labels", ",", "adjs", "in", "tqdm", "(", "data_loader", ")", ":", "\n", "            ", "y_batch", "=", "self", ".", "utils", ".", "to_tensor", "(", "labels", ")", "\n", "actual_sentences", "=", "None", "\n", "if", "self", ".", "params", ".", "plot", "==", "1", ":", "\n", "                ", "actual_sentences", "=", "None", "# self.get_sentences_from_indices(sents)", "\n", "\n", "", "if", "self", ".", "params", ".", "encoder", ">=", "2", ":", "\n", "# This is currently unbatched", "\n", "                ", "logits", "=", "self", ".", "utils", ".", "get_gcn_logits", "(", "model", ",", "sents", ",", "adjs", ",", "actual_sentences", ")", "\n", "", "else", ":", "\n", "                ", "x_batch", "=", "self", ".", "utils", ".", "to_tensor", "(", "sents", ")", "\n", "logits", "=", "model", "(", "x_batch", ",", "lens", ")", "\n", "", "predicted", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "hits", "+=", "torch", ".", "sum", "(", "predicted", "==", "y_batch", ")", ".", "item", "(", ")", "\n", "total", "+=", "len", "(", "sents", ")", "\n", "all_predicted", "=", "predicted", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "if", "all_predicted", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_predicted", ",", "\n", "predicted", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", ")", "\n", "all_actual", "=", "labels", "if", "all_actual", "is", "None", "else", "np", ".", "concatenate", "(", "(", "all_actual", ",", "labels", ")", ")", "\n", "", "accuracy", "=", "hits", "/", "total", "\n", "return", "accuracy", ",", "all_actual", ",", "all_predicted", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator.evaluate": [[53, 100], ["model.cuda.Classify", "torch.cuda.is_available", "model.cuda.cuda.load_state_dict", "model.cuda.cuda.eval", "evaluator.Evaluator._evaluate_aux", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "print", "evaluator.Evaluator._evaluate_aux", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "model.cuda.cuda.cuda", "torch.load", "evaluator.Evaluator._evaluate_aux", "sklearn.metrics.precision_recall_fscore_support", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "print", "sklearn.metrics.confusion_matrix", "pandas.DataFrame", "seaborn.heatmap", "matplotlib.yticks", "seaborn.heatmap.get_figure().savefig", "len", "seaborn.heatmap.get_figure"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.evaluator.Evaluator._evaluate_aux"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "model", "=", "Classify", "(", "self", ".", "params", ",", "vocab_size", "=", "len", "(", "self", ".", "data_loader", ".", "w2i", ")", ",", "\n", "ntags", "=", "self", ".", "data_loader", ".", "ntags", ",", "pte", "=", "None", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# Load the model weights", "\n", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"models/\"", "+", "self", ".", "params", ".", "model_file", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# This dataset is only available for the binary classifier", "\n", "if", "self", ".", "params", ".", "ntags", "==", "2", ":", "\n", "            ", "accuracy", ",", "all_actual", ",", "all_predicted", "=", "self", ".", "_evaluate_aux", "(", "model", ",", "self", ".", "data_loader", ".", "test_data_loader", ")", "\n", "prec_mac", ",", "recall_mac", ",", "f1_mac", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'macro'", ")", "\n", "prec_mic", ",", "recall_mic", ",", "f1_mic", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'micro'", ")", "\n", "print", "(", "\"Accuracy on the OOD test set 1: {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "print", "(", "\"Precision on the OOD test set 1 macro / micro: {}, {}\"", ".", "format", "(", "prec_mac", ",", "prec_mic", ")", ")", "\n", "print", "(", "\"Recall on the OOD test set 1 macro / micro: {}, {}\"", ".", "format", "(", "recall_mac", ",", "recall_mic", ")", ")", "\n", "print", "(", "\"F1 on the OOD test set 1 macro / micro: {}, {}\"", ".", "format", "(", "f1_mac", ",", "f1_mic", ")", ")", "\n", "\n", "print", "(", "\"----------------------------------------------------------------------\"", ")", "\n", "\n", "", "accuracy", ",", "all_actual", ",", "all_predicted", "=", "self", ".", "_evaluate_aux", "(", "model", ",", "self", ".", "data_loader", ".", "test_data_loader_2", ")", "\n", "prec_mac", ",", "recall_mac", ",", "f1_mac", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'macro'", ")", "\n", "prec_mic", ",", "recall_mic", ",", "f1_mic", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'micro'", ")", "\n", "print", "(", "\"Accuracy on the OOD test set 2: {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "print", "(", "\"Precision on the OOD test set 2 macro / micro: {}, {}\"", ".", "format", "(", "prec_mac", ",", "prec_mic", ")", ")", "\n", "print", "(", "\"Recall on the OOD test set 2 macro / micro: {}, {}\"", ".", "format", "(", "recall_mac", ",", "recall_mic", ")", ")", "\n", "print", "(", "\"F1 on the OOD test set 2 macro / micro: {}, {}\"", ".", "format", "(", "f1_mac", ",", "f1_mic", ")", ")", "\n", "\n", "if", "self", ".", "params", ".", "ntags", "==", "4", ":", "\n", "            ", "results", "=", "confusion_matrix", "(", "all_actual", ",", "all_predicted", ")", "\n", "df_cm", "=", "pd", ".", "DataFrame", "(", "results", ",", "index", "=", "[", "i", "for", "i", "in", "[", "\"Satire\"", ",", "\"Hoax\"", ",", "\"Propaganda\"", ",", "\"Trusted\"", "]", "]", ",", "\n", "columns", "=", "[", "i", "for", "i", "in", "[", "\"Satire\"", ",", "\"Hoax\"", ",", "\"Propaganda\"", ",", "\"Trusted\"", "]", "]", ")", "\n", "sns_plot", "=", "sn", ".", "heatmap", "(", "df_cm", ",", "annot", "=", "True", ",", "fmt", "=", "'g'", ")", "\n", "plt", ".", "yticks", "(", "rotation", "=", "45", ")", "\n", "sns_plot", ".", "get_figure", "(", ")", ".", "savefig", "(", "'plots/cm.png'", ")", "\n", "\n", "", "print", "(", "\"----------------------------------------------------------------------\"", ")", "\n", "\n", "accuracy", ",", "all_actual", ",", "all_predicted", "=", "self", ".", "_evaluate_aux", "(", "model", ",", "self", ".", "data_loader", ".", "dev_data_loader", ")", "\n", "prec_mac", ",", "recall_mac", ",", "f1_mac", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'macro'", ")", "\n", "prec_mic", ",", "recall_mic", ",", "f1_mic", ",", "_", "=", "precision_recall_fscore_support", "(", "all_actual", ",", "all_predicted", ",", "average", "=", "'micro'", ")", "\n", "print", "(", "\"Accuracy on the dev set: {}\"", ".", "format", "(", "accuracy", ")", ")", "\n", "print", "(", "\"Precision on the dev set macro / micro: {}, {}\"", ".", "format", "(", "prec_mac", ",", "prec_mic", ")", ")", "\n", "print", "(", "\"Recall on the dev macro / micro: {}, {}\"", ".", "format", "(", "recall_mac", ",", "recall_mic", ")", ")", "\n", "print", "(", "\"F1 on the dev macro / micro: {}, {}\"", ".", "format", "(", "f1_mac", ",", "f1_mic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AgNews.__init__": [[127, 142], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/ag_news.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "4", "\n", "self", ".", "epoch_size", "=", "5000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"classes.txt\"", ",", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AgNews._generator": [[143, 151], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "def", "_generator", "(", "self", ",", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AgNews.load_train_data": [[152, 154], ["datasets.AgNews._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AgNews.load_test_data": [[155, 157], ["datasets.AgNews._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.DbPedia.__init__": [[165, 181], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/db_pedia.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "14", "\n", "\n", "self", ".", "epoch_size", "=", "5000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"classes.txt\"", ",", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.DbPedia._generator": [[182, 191], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.DbPedia.load_train_data": [[192, 194], ["datasets.DbPedia._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.DbPedia.load_test_data": [[195, 197], ["datasets.DbPedia._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpReview.__init__": [[205, 220], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/yelp_review_full.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "5", "\n", "self", ".", "epoch_size", "=", "5000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpReview._generator": [[221, 230], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpReview.load_train_data": [[231, 233], ["datasets.YelpReview._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpReview.load_test_data": [[234, 236], ["datasets.YelpReview._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpPolarity.__init__": [[244, 259], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/yelp_review_polarity.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "2", "\n", "self", ".", "epoch_size", "=", "5000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpPolarity._generator": [[260, 269], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpPolarity.load_train_data": [[270, 272], ["datasets.YelpPolarity._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YelpPolarity.load_test_data": [[273, 275], ["datasets.YelpPolarity._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonReview.__init__": [[283, 298], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/amazon_review_full.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "5", "\n", "self", ".", "epoch_size", "=", "30000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonReview._generator": [[299, 308], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonReview.load_train_data": [[309, 311], ["datasets.AmazonReview._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonReview.load_test_data": [[312, 314], ["datasets.AmazonReview._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonPolarity.__init__": [[322, 337], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/amazon_review_polarity.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "2", "\n", "self", ".", "epoch_size", "=", "30000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonPolarity._generator": [[338, 347], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonPolarity.load_train_data": [[348, 350], ["datasets.AmazonPolarity._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.AmazonPolarity.load_test_data": [[351, 353], ["datasets.AmazonPolarity._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.SoguNews.__init__": [[361, 376], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/sogou_news.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "5", "\n", "self", ".", "epoch_size", "=", "5000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.SoguNews._generator": [[377, 386], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.SoguNews.load_train_data": [[387, 389], ["datasets.SoguNews._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.SoguNews.load_test_data": [[390, 392], ["datasets.SoguNews._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YahooAnswer.__init__": [[400, 415], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/yahoo_answers.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "10", "\n", "self", ".", "epoch_size", "=", "10000", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YahooAnswer._generator": [[416, 425], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "fieldnames", "=", "[", "'label'", ",", "'title'", ",", "'description'", "]", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "\"{} {}\"", ".", "format", "(", "line", "[", "'title'", "]", ",", "line", "[", "'description'", "]", ")", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "-", "1", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YahooAnswer.load_train_data": [[426, 428], ["datasets.YahooAnswer._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.YahooAnswer.load_test_data": [[429, 431], ["datasets.YahooAnswer._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb.__init__": [[438, 452], ["os.path.exists", "os.path.basename().split", "datasets.get_file", "os.path.basename", "os.path.exists", "datasets.get_file", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "url", "=", "\"https://s3.eu-west-2.amazonaws.com/ardalan.mehrani.datasets/imdb.tar.gz\"", "\n", "self", ".", "data_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "url", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "# ag_news", "\n", "self", ".", "data_folder", "=", "\"{}/{}/raw\"", ".", "format", "(", "DATA_FOLDER", ",", "self", ".", "data_name", ")", "\n", "self", ".", "n_classes", "=", "2", "\n", "\n", "# Check if relevant files are in the folder_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "data_folder", ")", ":", "\n", "            ", "for", "f", "in", "[", "\"readme.txt\"", ",", "\"test.csv\"", ",", "\"train.csv\"", "]", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "f", ")", ")", ":", "\n", "                    ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_", "=", "get_file", "(", "self", ".", "data_name", ",", "origin", "=", "self", ".", "url", ",", "untar", "=", "True", ",", "cache_subdir", "=", "self", ".", "data_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator": [[453, 463], ["open", "csv.DictReader", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_generator", "(", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ",", "quotechar", "=", "'\"'", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "sentence", "=", "line", "[", "'sentence'", "]", "\n", "label", "=", "int", "(", "line", "[", "'label'", "]", ")", "\n", "# if sentence and label:", "\n", "yield", "sentence", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb.load_train_data": [[464, 466], ["datasets.Imdb._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "", "", "def", "load_train_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"train.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb.load_test_data": [[467, 469], ["datasets.Imdb._generator", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.Imdb._generator"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_generator", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_folder", ",", "\"test.csv\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets._progress": [[22, 25], ["sys.stdout.write", "float", "float"], "function", ["None"], ["def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "    ", "rate", "=", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", "\n", "sys", ".", "stdout", ".", "write", "(", "\"\\r>> Downloading {:.1f}%\"", ".", "format", "(", "rate", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.get_file": [[27, 101], ["os.path.exists", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "print", "requests.get", "os.path.exists", "print", "tarfile.open", "tarfile.open.close", "datasets.validate_file", "print", "open", "fd.write", "tarfile.open.extractall", "urllib.request.urlretrieve", "sys.stdout.flush", "os.path.exists", "os.path.exists", "Exception", "Exception", "os.remove", "os.path.isfile", "error_msg.format", "error_msg.format", "os.remove", "shutil.rmtree"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.validate_file"], ["", "def", "get_file", "(", "fname", ",", "origin", ",", "untar", "=", "False", ",", "md5_hash", "=", "None", ",", "cache_subdir", "=", "'datasets'", ",", "check_certificate", "=", "True", ")", ":", "\n", "    ", "\"\"\"Downloads a file from a URL if it not already in the cache.\n    Passing the MD5 hash will verify the file after download\n    as well as if it is already present in the cache.\n    # Arguments\n        fname: name of the file\n        origin: original URL of the file\n        untar: boolean, whether the file should be decompressed\n        md5_hash: MD5 hash of the file for verification\n        cache_subdir: directory being used as the cache\n    # Returns\n        Path to the downloaded file\n    \"\"\"", "\n", "datadir", "=", "cache_subdir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "datadir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "datadir", ")", "\n", "\n", "", "if", "untar", ":", "\n", "        ", "untar_fpath", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "fname", ")", "\n", "fpath", "=", "untar_fpath", "+", "'.tar.gz'", "\n", "", "else", ":", "\n", "        ", "fpath", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "fname", ")", "\n", "\n", "", "download", "=", "False", "\n", "if", "os", ".", "path", ".", "exists", "(", "fpath", ")", ":", "\n", "# File found; verify integrity if a hash was provided.", "\n", "        ", "if", "md5_hash", "is", "not", "None", ":", "\n", "            ", "if", "not", "validate_file", "(", "fpath", ",", "md5_hash", ")", ":", "\n", "                ", "print", "(", "'A local file was found, but it seems to be '", "\n", "'incomplete or outdated.'", ")", "\n", "download", "=", "True", "\n", "", "", "", "else", ":", "\n", "        ", "download", "=", "True", "\n", "\n", "", "if", "download", ":", "\n", "        ", "print", "(", "'Downloading data from'", ",", "origin", ")", "\n", "error_msg", "=", "'URL fetch failure on {}: {} -- {}'", "\n", "\n", "if", "not", "check_certificate", ":", "\n", "            ", "import", "requests", "\n", "r", "=", "requests", ".", "get", "(", "origin", ",", "verify", "=", "False", ")", "\n", "with", "open", "(", "fpath", ",", "'wb'", ")", "as", "fd", ":", "\n", "                ", "fd", ".", "write", "(", "r", ".", "content", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "try", ":", "\n", "                    ", "urlretrieve", "(", "origin", ",", "fpath", ",", "_progress", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "except", "URLError", "as", "e", ":", "\n", "                    ", "raise", "Exception", "(", "error_msg", ".", "format", "(", "origin", ",", "e", ".", "errno", ",", "e", ".", "reason", ")", ")", "\n", "", "except", "HTTPError", "as", "e", ":", "\n", "                    ", "raise", "Exception", "(", "error_msg", ".", "format", "(", "origin", ",", "e", ".", "code", ",", "e", ".", "msg", ")", ")", "\n", "", "", "except", "(", "Exception", ",", "KeyboardInterrupt", ")", "as", "e", ":", "\n", "                ", "if", "os", ".", "path", ".", "exists", "(", "fpath", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "fpath", ")", "\n", "", "raise", "\n", "\n", "", "", "", "if", "untar", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "untar_fpath", ")", ":", "\n", "            ", "print", "(", "'Untaring file...'", ")", "\n", "tfile", "=", "tarfile", ".", "open", "(", "fpath", ",", "'r:gz'", ")", "\n", "try", ":", "\n", "                ", "tfile", ".", "extractall", "(", "path", "=", "datadir", ")", "\n", "", "except", "(", "Exception", ",", "KeyboardInterrupt", ")", "as", "e", ":", "\n", "                ", "if", "os", ".", "path", ".", "exists", "(", "untar_fpath", ")", ":", "\n", "                    ", "if", "os", ".", "path", ".", "isfile", "(", "untar_fpath", ")", ":", "\n", "                        ", "os", ".", "remove", "(", "untar_fpath", ")", "\n", "", "else", ":", "\n", "                        ", "shutil", ".", "rmtree", "(", "untar_fpath", ")", "\n", "", "", "raise", "\n", "", "tfile", ".", "close", "(", ")", "\n", "", "return", "untar_fpath", "\n", "\n", "", "return", "fpath", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.validate_file": [[103, 119], ["hashlib.md5", "open", "f.read", "hashlib.md5.update", "str", "str", "hashlib.md5.hexdigest"], "function", ["None"], ["", "def", "validate_file", "(", "fpath", ",", "md5_hash", ")", ":", "\n", "    ", "\"\"\"Validates a file against a MD5 hash.\n    # Arguments\n        fpath: path to the file being validated\n        md5_hash: the MD5 hash being validated against\n    # Returns\n        Whether the file is valid\n    \"\"\"", "\n", "hasher", "=", "hashlib", ".", "md5", "(", ")", "\n", "with", "open", "(", "fpath", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "buf", "=", "f", ".", "read", "(", ")", "\n", "hasher", ".", "update", "(", "buf", ")", "\n", "", "if", "str", "(", "hasher", ".", "hexdigest", "(", ")", ")", "==", "str", "(", "md5_hash", ")", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.datasets.load_datasets": [[471, 499], ["datasets.append", "datasets.append", "datasets.append", "datasets.append", "datasets.append", "datasets.append", "datasets.append", "datasets.append", "datasets.append", "datasets.AgNews", "datasets.DbPedia", "datasets.YelpReview", "datasets.YelpPolarity", "datasets.AmazonReview", "datasets.AmazonPolarity", "datasets.SoguNews", "datasets.YahooAnswer", "datasets.Imdb"], "function", ["None"], ["", "", "def", "load_datasets", "(", "names", "=", "[", "\"ag_news\"", ",", "\"imdb\"", "]", ")", ":", "\n", "    ", "\"\"\"\n    Select datasets based on their names\n    :param names: list of string of dataset names\n    :return: list of dataset object\n    \"\"\"", "\n", "\n", "datasets", "=", "[", "]", "\n", "\n", "if", "'ag_news'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "AgNews", "(", ")", ")", "\n", "", "if", "'db_pedia'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "DbPedia", "(", ")", ")", "\n", "", "if", "'yelp_review'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "YelpReview", "(", ")", ")", "\n", "", "if", "'yelp_polarity'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "YelpPolarity", "(", ")", ")", "\n", "", "if", "'amazon_review'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "AmazonReview", "(", ")", ")", "\n", "", "if", "'amazon_polarity'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "AmazonPolarity", "(", ")", ")", "\n", "", "if", "'sogou_news'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "SoguNews", "(", ")", ")", "\n", "", "if", "'yahoo_answer'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "YahooAnswer", "(", ")", ")", "\n", "", "if", "'imdb'", "in", "names", ":", "\n", "        ", "datasets", ".", "append", "(", "Imdb", "(", ")", ")", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.InputExample.__init__": [[49, 65], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.InputFeatures.__init__": [[70, 75], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor.get_train_examples": [[80, 83], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor.get_dev_examples": [[84, 87], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor.get_labels": [[88, 91], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv": [[92, 103], ["open", "csv.reader", "lines.append", "list", "unicode"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", "\n", "lines", "=", "[", "]", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "line", "=", "list", "(", "unicode", "(", "cell", ",", "'utf-8'", ")", "for", "cell", "in", "line", ")", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MrpcProcessor.get_train_examples": [[108, 113], ["logger.info", "bert_classifier_example.MrpcProcessor._create_examples", "bert_classifier_example.MrpcProcessor._read_tsv", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MrpcProcessor.get_dev_examples": [[114, 118], ["bert_classifier_example.MrpcProcessor._create_examples", "bert_classifier_example.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MrpcProcessor.get_labels": [[119, 122], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MrpcProcessor._create_examples": [[123, 136], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "0", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MnliProcessor.get_train_examples": [[141, 145], ["bert_classifier_example.MnliProcessor._create_examples", "bert_classifier_example.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MnliProcessor.get_dev_examples": [[146, 151], ["bert_classifier_example.MnliProcessor._create_examples", "bert_classifier_example.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_matched.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MnliProcessor.get_labels": [[152, 155], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MnliProcessor._create_examples": [[156, 169], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "8", "]", "\n", "text_b", "=", "line", "[", "9", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.MnliMismatchedProcessor.get_dev_examples": [[174, 179], ["bert_classifier_example.MnliMismatchedProcessor._create_examples", "bert_classifier_example.MnliMismatchedProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.ColaProcessor.get_train_examples": [[184, 188], ["bert_classifier_example.ColaProcessor._create_examples", "bert_classifier_example.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.ColaProcessor.get_dev_examples": [[189, 193], ["bert_classifier_example.ColaProcessor._create_examples", "bert_classifier_example.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.ColaProcessor.get_labels": [[194, 197], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.ColaProcessor._create_examples": [[198, 208], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.Sst2Processor.get_train_examples": [[213, 217], ["bert_classifier_example.Sst2Processor._create_examples", "bert_classifier_example.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.Sst2Processor.get_dev_examples": [[218, 222], ["bert_classifier_example.Sst2Processor._create_examples", "bert_classifier_example.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.Sst2Processor.get_labels": [[223, 226], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.Sst2Processor._create_examples": [[227, 239], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "0", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.StsbProcessor.get_train_examples": [[244, 248], ["bert_classifier_example.StsbProcessor._create_examples", "bert_classifier_example.StsbProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.StsbProcessor.get_dev_examples": [[249, 253], ["bert_classifier_example.StsbProcessor._create_examples", "bert_classifier_example.StsbProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.StsbProcessor.get_labels": [[254, 257], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.StsbProcessor._create_examples": [[258, 271], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "7", "]", "\n", "text_b", "=", "line", "[", "8", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QqpProcessor.get_train_examples": [[276, 280], ["bert_classifier_example.QqpProcessor._create_examples", "bert_classifier_example.QqpProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QqpProcessor.get_dev_examples": [[281, 285], ["bert_classifier_example.QqpProcessor._create_examples", "bert_classifier_example.QqpProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QqpProcessor.get_labels": [[286, 289], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QqpProcessor._create_examples": [[290, 306], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "try", ":", "\n", "                ", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "5", "]", "\n", "", "except", "IndexError", ":", "\n", "                ", "continue", "\n", "", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QnliProcessor.get_train_examples": [[311, 315], ["bert_classifier_example.QnliProcessor._create_examples", "bert_classifier_example.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QnliProcessor.get_dev_examples": [[316, 321], ["bert_classifier_example.QnliProcessor._create_examples", "bert_classifier_example.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\n", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QnliProcessor.get_labels": [[322, 325], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.QnliProcessor._create_examples": [[326, 339], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.RteProcessor.get_train_examples": [[344, 348], ["bert_classifier_example.RteProcessor._create_examples", "bert_classifier_example.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.RteProcessor.get_dev_examples": [[349, 353], ["bert_classifier_example.RteProcessor._create_examples", "bert_classifier_example.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.RteProcessor.get_labels": [[354, 357], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.RteProcessor._create_examples": [[358, 371], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_train_examples": [[376, 380], ["bert_classifier_example.WnliProcessor._create_examples", "bert_classifier_example.WnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_dev_examples": [[381, 385], ["bert_classifier_example.WnliProcessor._create_examples", "bert_classifier_example.WnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_labels": [[386, 389], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor._create_examples": [[390, 403], ["enumerate", "examples.append", "bert_classifier_example.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.convert_examples_to_features": [[405, 495], ["enumerate", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "bert_classifier_example._truncate_seq_pair", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "bert_classifier_example.InputFeatures", "len", "len", "float", "KeyError", "len", "len", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example._truncate_seq_pair"], ["", "", "def", "convert_examples_to_features", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids: 0   0   0   0  0     0 0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens_a", "+", "[", "\"[SEP]\"", "]", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "\"[SEP]\"", "]", "\n", "segment_ids", "+=", "[", "1", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "input_mask", "+=", "padding", "\n", "segment_ids", "+=", "padding", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "\n", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label_id", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example._truncate_seq_pair": [[497, 512], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy": [[514, 516], ["None"], "function", ["None"], ["", "", "", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.acc_and_f1": [[518, 525], ["bert_classifier_example.simple_accuracy", "sklearn.metrics.f1_score"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy"], ["", "def", "acc_and_f1", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "acc", "=", "simple_accuracy", "(", "preds", ",", "labels", ")", "\n", "f1", "=", "f1_score", "(", "y_true", "=", "labels", ",", "y_pred", "=", "preds", ")", "\n", "return", "{", "\n", "\"acc\"", ":", "acc", ",", "\n", "\"f1\"", ":", "f1", ",", "\n", "\"acc_and_f1\"", ":", "(", "acc", "+", "f1", ")", "/", "2", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.pearson_and_spearman": [[528, 535], ["scipy.stats.pearsonr", "scipy.stats.spearmanr"], "function", ["None"], ["", "def", "pearson_and_spearman", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "pearson_corr", "=", "pearsonr", "(", "preds", ",", "labels", ")", "[", "0", "]", "\n", "spearman_corr", "=", "spearmanr", "(", "preds", ",", "labels", ")", "[", "0", "]", "\n", "return", "{", "\n", "\"pearson\"", ":", "pearson_corr", ",", "\n", "\"spearmanr\"", ":", "spearman_corr", ",", "\n", "\"corr\"", ":", "(", "pearson_corr", "+", "spearman_corr", ")", "/", "2", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.compute_metrics": [[538, 562], ["len", "len", "sklearn.metrics.matthews_corrcoef", "bert_classifier_example.simple_accuracy", "bert_classifier_example.acc_and_f1", "bert_classifier_example.pearson_and_spearman", "bert_classifier_example.acc_and_f1", "bert_classifier_example.simple_accuracy", "bert_classifier_example.simple_accuracy", "bert_classifier_example.simple_accuracy", "bert_classifier_example.simple_accuracy", "KeyError", "bert_classifier_example.simple_accuracy"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.acc_and_f1", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.pearson_and_spearman", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.acc_and_f1", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.simple_accuracy"], ["", "def", "compute_metrics", "(", "task_name", ",", "preds", ",", "labels", ")", ":", "\n", "    ", "assert", "len", "(", "preds", ")", "==", "len", "(", "labels", ")", "\n", "if", "task_name", "==", "\"cola\"", ":", "\n", "        ", "return", "{", "\"mcc\"", ":", "matthews_corrcoef", "(", "labels", ",", "preds", ")", "}", "\n", "", "elif", "task_name", "==", "\"sst-2\"", ":", "\n", "        ", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", "elif", "task_name", "==", "\"mrpc\"", ":", "\n", "        ", "return", "acc_and_f1", "(", "preds", ",", "labels", ")", "\n", "", "elif", "task_name", "==", "\"sts-b\"", ":", "\n", "        ", "return", "pearson_and_spearman", "(", "preds", ",", "labels", ")", "\n", "", "elif", "task_name", "==", "\"qqp\"", ":", "\n", "        ", "return", "acc_and_f1", "(", "preds", ",", "labels", ")", "\n", "", "elif", "task_name", "==", "\"mnli\"", ":", "\n", "        ", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", "elif", "task_name", "==", "\"mnli-mm\"", ":", "\n", "        ", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", "elif", "task_name", "==", "\"qnli\"", ":", "\n", "        ", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", "elif", "task_name", "==", "\"rte\"", ":", "\n", "        ", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", "elif", "task_name", "==", "\"wnli\"", ":", "\n", "        ", "return", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "labels", ")", "}", "\n", "", "else", ":", "\n", "        ", "raise", "KeyError", "(", "task_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.main": [[564, 1023], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.info", "random.seed", "numpy.random.seed", "torch.manual_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "pytorch_pretrained_bert.modeling.BertForSequenceClassification.from_pretrained", "torch.nn.DataParallel.to", "list", "torch.nn.DataParallel.to", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "ValueError", "torch.cuda.manual_seed_all", "ValueError", "os.path.exists", "os.listdir", "ValueError", "os.path.exists", "os.makedirs", "ValueError", "processor.get_train_examples", "os.path.join", "torch.nn.DataParallel.half", "DDP", "torch.nn.DataParallel.named_parameters", "FusedAdam", "pytorch_pretrained_bert.optimization.BertAdam", "bert_classifier_example.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.nn.DataParallel.train", "tqdm.trange", "os.path.join", "os.path.join", "torch.save", "model_to_save.config.to_json_file", "BertTokenizer.from_pretrained.save_vocabulary", "pytorch_pretrained_bert.modeling.BertForSequenceClassification.from_pretrained", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "pytorch_pretrained_bert.modeling.BertForSequenceClassification.from_pretrained", "processor.get_dev_examples", "bert_classifier_example.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.nn.DataParallel.eval", "tqdm.tqdm", "bert_classifier_example.compute_metrics", "os.path.join", "bool", "int", "str", "torch.nn.DataParallel", "FP16_Optimizer", "FP16_Optimizer", "len", "torch.tensor", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "int", "enumerate", "hasattr", "model_to_save.state_dict", "len", "torch.tensor", "input_ids.to.to", "input_mask.to.to", "segment_ids.to.to", "label_ids.to.to", "loss_fct.mean().item", "numpy.argmax", "torch.tensor.numpy", "open", "logger.info", "sorted", "processor.get_dev_examples", "bert_classifier_example.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.nn.DataParallel.eval", "tqdm.tqdm", "numpy.argmax", "bert_classifier_example.compute_metrics", "os.path.join", "torch.distributed.get_world_size", "ImportError", "ImportError", "torch.tensor", "tqdm.tqdm", "tuple", "torch.nn.DataParallel.", "loss_fct.item", "input_ids.to.size", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.tensor", "torch.no_grad", "torch.nn.DataParallel.", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss.", "len", "np.squeeze.append", "numpy.append", "numpy.squeeze", "compute_metrics.keys", "logger.info", "writer.write", "os.path.exists", "os.listdir", "ValueError", "os.path.exists", "os.makedirs", "len", "input_ids.to.to", "input_mask.to.to", "segment_ids.to.to", "label_ids.to.to", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss.", "loss_fct.mean().item", "torch.tensor.numpy", "open", "logger.info", "sorted", "torch.cuda.is_available", "any", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss.", "loss_fct.mean", "FP16_Optimizer.backward", "loss_fct.backward", "FP16_Optimizer.step", "FP16_Optimizer.zero_grad", "model.view", "label_ids.to.view", "torch.nn.MSELoss", "torch.nn.MSELoss.", "loss_fct.mean", "model.detach().cpu().numpy", "model.detach().cpu().numpy", "str", "torch.no_grad", "torch.nn.DataParallel.", "model.view", "label_ids.to.view", "len", "np.squeeze.append", "numpy.append", "compute_metrics.keys", "logger.info", "writer.write", "len", "any", "t.to", "model.view", "label_ids.to.view", "torch.nn.MSELoss", "torch.nn.MSELoss.", "model.view", "label_ids.to.view", "loss_fct.mean", "model.detach().cpu().numpy", "model.detach().cpu().numpy", "str", "model.view", "label_ids.to.view", "pytorch_pretrained_bert.optimization.warmup_linear", "model.detach().cpu", "model.detach().cpu", "str", "model.detach().cpu", "model.detach().cpu", "str", "model.detach", "model.detach", "model.detach", "model.detach"], "function", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_labels", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_train_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.convert_examples_to_features", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.None.util.Utils.train", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_dev_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.convert_examples_to_features", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.compute_metrics", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.WnliProcessor.get_dev_examples", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.convert_examples_to_features", "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_classifier_example.compute_metrics"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"", "\n", "\"bert-base-multilingual-cased, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for eval.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "\n", "default", "=", "3.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Proportion of training to perform linear learning rate warmup for. \"", "\n", "\"E.g., 0.1 = 10%% of training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit float precision instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_scale'", ",", "\n", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"", "\n", "\"0 (default value): dynamic loss scaling.\\n\"", "\n", "\"Positive power of 2: static loss scaling value.\\n\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "processors", "=", "{", "\n", "\"cola\"", ":", "ColaProcessor", ",", "\n", "\"mnli\"", ":", "MnliProcessor", ",", "\n", "\"mnli-mm\"", ":", "MnliMismatchedProcessor", ",", "\n", "\"mrpc\"", ":", "MrpcProcessor", ",", "\n", "\"sst-2\"", ":", "Sst2Processor", ",", "\n", "\"sts-b\"", ":", "StsbProcessor", ",", "\n", "\"qqp\"", ":", "QqpProcessor", ",", "\n", "\"qnli\"", ":", "QnliProcessor", ",", "\n", "\"rte\"", ":", "RteProcessor", ",", "\n", "\"wnli\"", ":", "WnliProcessor", ",", "\n", "}", "\n", "\n", "output_modes", "=", "{", "\n", "\"cola\"", ":", "\"classification\"", ",", "\n", "\"mnli\"", ":", "\"classification\"", ",", "\n", "\"mrpc\"", ":", "\"classification\"", ",", "\n", "\"sst-2\"", ":", "\"classification\"", ",", "\n", "\"sts-b\"", ":", "\"regression\"", ",", "\n", "\"qqp\"", ":", "\"classification\"", ",", "\n", "\"qnli\"", ":", "\"classification\"", ",", "\n", "\"rte\"", ":", "\"classification\"", ",", "\n", "\"wnli\"", ":", "\"classification\"", ",", "\n", "}", "\n", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "n_gpu", "=", "1", "\n", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "\n", "", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "\n", "logger", ".", "info", "(", "\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "gradient_accumulation_steps", "\n", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "not", "args", ".", "do_train", "and", "not", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\"At least one of `do_train` or `do_eval` must be True.\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "        ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "\n", "if", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "task_name", ")", ")", "\n", "\n", "", "processor", "=", "processors", "[", "task_name", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task_name", "]", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "train_examples", "=", "None", "\n", "num_train_optimization_steps", "=", "None", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "num_train_optimization_steps", "=", "int", "(", "\n", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", "/", "args", ".", "gradient_accumulation_steps", ")", "*", "args", ".", "num_train_epochs", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "            ", "num_train_optimization_steps", "=", "num_train_optimization_steps", "//", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "\n", "# Prepare model", "\n", "", "", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "os", ".", "path", ".", "join", "(", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", ",", "\n", "'distributed_{}'", ".", "format", "(", "args", ".", "local_rank", ")", ")", "\n", "model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "num_labels", "=", "num_labels", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "model", ".", "half", "(", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "parallel", "import", "DistributedDataParallel", "as", "DDP", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"", ")", "\n", "\n", "", "model", "=", "DDP", "(", "model", ")", "\n", "", "elif", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Prepare optimizer", "\n", "", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "optimizers", "import", "FP16_Optimizer", "\n", "from", "apex", ".", "optimizers", "import", "FusedAdam", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"", ")", "\n", "\n", "", "optimizer", "=", "FusedAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "bias_correction", "=", "False", ",", "\n", "max_grad_norm", "=", "1.0", ")", "\n", "if", "args", ".", "loss_scale", "==", "0", ":", "\n", "            ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "dynamic_loss_scale", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "static_loss_scale", "=", "args", ".", "loss_scale", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "num_train_optimization_steps", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "nb_tr_steps", "=", "0", "\n", "tr_loss", "=", "0", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_features", "=", "convert_examples_to_features", "(", "\n", "train_examples", ",", "label_list", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "output_mode", ")", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_optimization_steps", ")", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "train_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "train_data", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "if", "args", ".", "local_rank", "==", "-", "1", ":", "\n", "            ", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "", "else", ":", "\n", "            ", "train_sampler", "=", "DistributedSampler", "(", "train_data", ")", "\n", "", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "for", "_", "in", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ")", ":", "\n", "            ", "tr_loss", "=", "0", "\n", "nb_tr_examples", ",", "nb_tr_steps", "=", "0", ",", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ")", ")", ":", "\n", "                ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", "=", "batch", "\n", "\n", "# define a new function to compute loss values for both output_modes", "\n", "logits", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "labels", "=", "None", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "                    ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "num_labels", ")", ",", "label_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "                    ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "label_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "n_gpu", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu.", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                    ", "optimizer", ".", "backward", "(", "loss", ")", "\n", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "nb_tr_examples", "+=", "input_ids", ".", "size", "(", "0", ")", "\n", "nb_tr_steps", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                    ", "if", "args", ".", "fp16", ":", "\n", "# modify learning rate with special warm up BERT uses", "\n", "# if args.fp16 is False, BertAdam is used that handles this automatically", "\n", "                        ", "lr_this_step", "=", "args", ".", "learning_rate", "*", "warmup_linear", "(", "global_step", "/", "num_train_optimization_steps", ",", "\n", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                            ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "", "", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Save a trained model, configuration and tokenizer", "\n", "        ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Only save the model it-self", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "CONFIG_NAME", ")", "\n", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "model_to_save", ".", "config", ".", "to_json_file", "(", "output_config_file", ")", "\n", "tokenizer", ".", "save_vocabulary", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "num_labels", "=", "num_labels", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "num_labels", "=", "num_labels", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "args", ".", "do_eval", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "        ", "eval_examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "eval_features", "=", "convert_examples_to_features", "(", "\n", "eval_examples", ",", "label_list", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "output_mode", ")", "\n", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "eval_data", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "# Run prediction for full data", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_data", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_data", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "eval_loss", "=", "0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "[", "]", "\n", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "device", ")", "\n", "label_ids", "=", "label_ids", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "logits", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "labels", "=", "None", ")", "\n", "\n", "# create eval loss and other metric required by the task", "\n", "", "if", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "tmp_eval_loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "num_labels", ")", ",", "label_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "tmp_eval_loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "label_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "nb_eval_steps", "+=", "1", "\n", "if", "len", "(", "preds", ")", "==", "0", ":", "\n", "                ", "preds", ".", "append", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "preds", "[", "0", "]", "=", "np", ".", "append", "(", "\n", "preds", "[", "0", "]", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "preds", "[", "0", "]", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "", "result", "=", "compute_metrics", "(", "task_name", ",", "preds", ",", "all_label_ids", ".", "numpy", "(", ")", ")", "\n", "loss", "=", "tr_loss", "/", "nb_tr_steps", "if", "args", ".", "do_train", "else", "None", "\n", "\n", "result", "[", "'eval_loss'", "]", "=", "eval_loss", "\n", "result", "[", "'global_step'", "]", "=", "global_step", "\n", "result", "[", "'loss'", "]", "=", "loss", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "# hack for MNLI-MM", "\n", "", "", "if", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "task_name", "=", "\"mnli-mm\"", "\n", "processor", "=", "processors", "[", "task_name", "]", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", "+", "'-MM'", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", "+", "'-MM'", ")", "and", "args", ".", "do_train", ":", "\n", "                ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", "+", "'-MM'", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "args", ".", "output_dir", "+", "'-MM'", ")", "\n", "\n", "", "eval_examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "eval_features", "=", "convert_examples_to_features", "(", "\n", "eval_examples", ",", "label_list", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "output_mode", ")", "\n", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_examples", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_id", "for", "f", "in", "eval_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "eval_data", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "# Run prediction for full data", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_data", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_data", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "eval_loss", "=", "0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "[", "]", "\n", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "                ", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "device", ")", "\n", "label_ids", "=", "label_ids", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "logits", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "labels", "=", "None", ")", "\n", "\n", "", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "tmp_eval_loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "num_labels", ")", ",", "label_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "nb_eval_steps", "+=", "1", "\n", "if", "len", "(", "preds", ")", "==", "0", ":", "\n", "                    ", "preds", ".", "append", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "preds", "[", "0", "]", "=", "np", ".", "append", "(", "\n", "preds", "[", "0", "]", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "preds", "[", "0", "]", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "result", "=", "compute_metrics", "(", "task_name", ",", "preds", ",", "all_label_ids", ".", "numpy", "(", ")", ")", "\n", "loss", "=", "tr_loss", "/", "nb_tr_steps", "if", "args", ".", "do_train", "else", "None", "\n", "\n", "result", "[", "'eval_loss'", "]", "=", "eval_loss", "\n", "result", "[", "'global_step'", "]", "=", "global_step", "\n", "result", "[", "'loss'", "]", "=", "loss", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", "+", "'-MM'", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.__init__": [[13, 22], ["pytorch_pretrained_bert.modeling.BertForSequenceClassification.from_pretrained", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "print", "bert_sem_model.ComputeSimilarity.model.cuda", "bert_sem_model.ComputeSimilarity.model.eval"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "num_labels", "=", "args", ".", "num_labels", ")", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "self", ".", "max_sentence_length", "=", "args", ".", "max_sentence_length", "\n", "print", "(", "'Loaded model with fine-tuned weights'", ")", "\n", "\n", "# Set to eval mode", "\n", "self", ".", "model", ".", "cuda", "(", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.get_similarity": [[23, 36], ["bert_sem_model.ComputeSimilarity.tokenizer.convert_tokens_to_ids", "bert_sem_model.ComputeSimilarity.item", "len", "torch.no_grad", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "bert_sem_model.ComputeSimilarity.model", "len", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "get_similarity", "(", "self", ",", "tokens_a", ",", "tokens_b", ")", ":", "\n", "        ", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens_a", "+", "[", "\"[SEP]\"", "]", "+", "tokens_b", "+", "[", "\"[SEP]\"", "]", "\n", "token_segments", "=", "[", "0", "]", "*", "(", "len", "(", "tokens_a", ")", "+", "2", ")", "+", "[", "1", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "token_vector", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "token_vector_mask", "=", "[", "1", "]", "*", "len", "(", "token_vector", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "torch", ".", "LongTensor", "(", "token_vector", ")", ".", "unsqueeze", "(", "0", ")", "\n", "segment_ids", "=", "torch", ".", "LongTensor", "(", "token_segments", ")", ".", "unsqueeze", "(", "0", ")", "\n", "input_mask", "=", "torch", ".", "LongTensor", "(", "token_vector_mask", ")", ".", "unsqueeze", "(", "0", ")", "\n", "out", "=", "self", ".", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "labels", "=", "None", ")", "\n", "\n", "", "return", "out", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.get_similarity_batched": [[37, 62], ["range", "out[].cpu().data.numpy", "bert_sem_model.ComputeSimilarity.tokenizer.convert_tokens_to_ids", "torch.LongTensor().cuda.append", "torch.LongTensor().cuda.append", "torch.LongTensor().cuda.append", "max", "len", "torch.no_grad", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "bert_sem_model.ComputeSimilarity.model", "len", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "out[].cpu", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "get_similarity_batched", "(", "self", ",", "tokens_a", ",", "tokenized_list", ")", ":", "\n", "        ", "input_ids", ",", "segment_ids", ",", "input_mask", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "max_token_len", "=", "0", "\n", "\n", "for", "tokens_b", "in", "tokenized_list", ":", "\n", "            ", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens_a", "+", "[", "\"[SEP]\"", "]", "+", "tokens_b", "+", "[", "\"[SEP]\"", "]", "\n", "token_vector", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "input_ids", ".", "append", "(", "token_vector", ")", "\n", "segment_ids", ".", "append", "(", "[", "0", "]", "*", "(", "len", "(", "tokens_a", ")", "+", "2", ")", "+", "[", "1", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", ")", "\n", "input_mask", ".", "append", "(", "[", "1", "]", "*", "len", "(", "token_vector", ")", ")", "\n", "max_token_len", "=", "max", "(", "max_token_len", ",", "len", "(", "token_vector", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "input_ids", ")", ")", ":", "\n", "            ", "input_ids", "[", "i", "]", "=", "input_ids", "[", "i", "]", "+", "[", "0", "]", "*", "(", "max_token_len", "-", "len", "(", "input_ids", "[", "i", "]", ")", ")", "\n", "segment_ids", "[", "i", "]", "=", "segment_ids", "[", "i", "]", "+", "[", "0", "]", "*", "(", "max_token_len", "-", "len", "(", "segment_ids", "[", "i", "]", ")", ")", "\n", "input_mask", "[", "i", "]", "=", "input_mask", "[", "i", "]", "+", "[", "0", "]", "*", "(", "max_token_len", "-", "len", "(", "input_mask", "[", "i", "]", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", ".", "cuda", "(", ")", "\n", "segment_ids", "=", "torch", ".", "LongTensor", "(", "segment_ids", ")", ".", "cuda", "(", ")", "\n", "input_mask", "=", "torch", ".", "LongTensor", "(", "input_mask", ")", ".", "cuda", "(", ")", "\n", "out", "=", "self", ".", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "labels", "=", "None", ")", "\n", "\n", "", "return", "out", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.get_similarity_scores": [[64, 79], ["len", "tqdm.tqdm.tqdm", "numpy.array", "tokenized_sentences.append", "range", "adj_matrix.append", "bert_sem_model.ComputeSimilarity.get_similarity_batched", "bert_sem_model.ComputeSimilarity.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.ComputeSimilarity.get_similarity_batched"], ["", "def", "get_similarity_scores", "(", "self", ",", "sentences", ")", ":", "\n", "# Compares sentences with themselves as well", "\n", "# ie. non-zero diagonal score", "\n", "\n", "        ", "num_sentences", "=", "len", "(", "sentences", ")", "\n", "adj_matrix", "=", "[", "]", "\n", "\n", "tokenized_sentences", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "            ", "tokenized_sentences", ".", "append", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "sentence", ")", "[", ":", "self", ".", "max_sentence_length", "]", ")", "\n", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "num_sentences", ")", ")", ":", "\n", "            ", "adj_matrix", ".", "append", "(", "self", ".", "get_similarity_batched", "(", "tokenized_sentences", "[", "i", "]", ",", "tokenized_sentences", ")", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "adj_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.doc_to_sentences": [[81, 83], ["x.lower", "doc.strip().split", "doc.strip"], "function", ["None"], ["", "", "def", "doc_to_sentences", "(", "doc", ")", ":", "\n", "    ", "return", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "doc", ".", "strip", "(", ")", ".", "split", "(", "\".\"", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.read_csv_file": [[85, 95], ["open", "csv.reader", "csv.field_size_limit", "int", "examples.append", "words.lower"], "function", ["None"], ["", "def", "read_csv_file", "(", "filename", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "readCSV", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "','", ")", "\n", "csv", ".", "field_size_limit", "(", "100000000", ")", "\n", "for", "tag", ",", "words", "in", "readCSV", ":", "\n", "            ", "tag", "=", "int", "(", "tag", ")", "\n", "if", "tag", "in", "[", "1", ",", "4", "]", ":", "\n", "                ", "examples", ".", "append", "(", "words", ".", "lower", "(", ")", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.MysteryVaibhav_fake_news_semantics.lib_semscore.bert_sem_model.read_xlsx_file": [[97, 104], ["pandas.read_excel", "int", "data.append", "row[].lower"], "function", ["None"], ["", "def", "read_xlsx_file", "(", "filename", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_excel", "(", "filename", ")", "\n", "data", "=", "[", "]", "\n", "for", "row", "in", "df", ".", "values", ":", "\n", "        ", "tag", "=", "int", "(", "row", "[", "0", "]", ")", "\n", "data", ".", "append", "(", "row", "[", "2", "]", ".", "lower", "(", ")", ")", "\n", "", "return", "data", "\n", "\n"]]}