{"home.repos.pwc.inspect_result.mlii_mfrl.None.main_MFQ_Ising.boltzman_explore": [[55, 68], ["range", "numpy.random.choice", "action_probs_numes.append", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "boltzman_explore", "(", "Q", ",", "temper", ",", "state", ",", "agent_index", ")", ":", "\n", "  ", "action_probs_numes", "=", "[", "]", "\n", "denom", "=", "0", "\n", "for", "i", "in", "range", "(", "n_actions", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "val", "=", "np", ".", "exp", "(", "Q", "[", "agent_index", ",", "state", ",", "i", "]", "/", "temper", ")", "\n", "", "except", "OverflowError", ":", "\n", "      ", "return", "i", "\n", "", "action_probs_numes", ".", "append", "(", "val", ")", "\n", "denom", "+=", "val", "\n", "", "action_probs", "=", "[", "x", "/", "denom", "for", "x", "in", "action_probs_numes", "]", "\n", "\n", "return", "np", ".", "random", ".", "choice", "(", "n_actions", ",", "1", ",", "p", "=", "action_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.None.train_battle.linear_decay": [[17, 33], ["enumerate"], "function", ["None"], ["def", "linear_decay", "(", "epoch", ",", "x", ",", "y", ")", ":", "\n", "    ", "min_v", ",", "max_v", "=", "y", "[", "0", "]", ",", "y", "[", "-", "1", "]", "\n", "start", ",", "end", "=", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", "\n", "\n", "if", "epoch", "==", "start", ":", "\n", "        ", "return", "min_v", "\n", "\n", "", "eps", "=", "min_v", "\n", "\n", "for", "i", ",", "x_i", "in", "enumerate", "(", "x", ")", ":", "\n", "        ", "if", "epoch", "<=", "x_i", ":", "\n", "            ", "interval", "=", "(", "y", "[", "i", "]", "-", "y", "[", "i", "-", "1", "]", ")", "/", "(", "x_i", "-", "x", "[", "i", "-", "1", "]", ")", "\n", "eps", "=", "interval", "*", "(", "epoch", "-", "x", "[", "i", "-", "1", "]", ")", "+", "y", "[", "i", "-", "1", "]", "\n", "break", "\n", "\n", "", "", "return", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.battle_model.senario_battle.generate_map": [[6, 32], ["random.randint", "range", "env.add_agents", "range", "env.add_agents", "int", "range", "int", "range", "math.sqrt", "pos.append", "math.sqrt", "pos.append"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["def", "generate_map", "(", "env", ",", "map_size", ",", "handles", ")", ":", "\n", "    ", "\"\"\" generate a map, which consists of two squares of agents\"\"\"", "\n", "width", "=", "height", "=", "map_size", "\n", "init_num", "=", "map_size", "*", "map_size", "*", "0.04", "\n", "gap", "=", "3", "\n", "\n", "leftID", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "rightID", "=", "1", "-", "leftID", "\n", "\n", "# left", "\n", "n", "=", "init_num", "\n", "side", "=", "int", "(", "math", ".", "sqrt", "(", "n", ")", ")", "*", "2", "\n", "pos", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "width", "//", "2", "-", "gap", "-", "side", ",", "width", "//", "2", "-", "gap", "-", "side", "+", "side", ",", "2", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "(", "height", "-", "side", ")", "//", "2", ",", "(", "height", "-", "side", ")", "//", "2", "+", "side", ",", "2", ")", ":", "\n", "            ", "pos", ".", "append", "(", "[", "x", ",", "y", ",", "0", "]", ")", "\n", "", "", "env", ".", "add_agents", "(", "handles", "[", "leftID", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n", "# right", "\n", "n", "=", "init_num", "\n", "side", "=", "int", "(", "math", ".", "sqrt", "(", "n", ")", ")", "*", "2", "\n", "pos", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "width", "//", "2", "+", "gap", ",", "width", "//", "2", "+", "gap", "+", "side", ",", "2", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "(", "height", "-", "side", ")", "//", "2", ",", "(", "height", "-", "side", ")", "//", "2", "+", "side", ",", "2", ")", ":", "\n", "            ", "pos", ".", "append", "(", "[", "x", ",", "y", ",", "0", "]", ")", "\n", "", "", "env", ".", "add_agents", "(", "handles", "[", "rightID", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.battle_model.senario_battle.play": [[34, 125], ["env.reset", "senario_battle.generate_map", "len", "nums.copy", "print", "range", "env.get_num", "numpy.zeros", "numpy.zeros", "range", "range", "range", "env.step", "range", "range", "range", "env.clear_dead", "models[].train", "sum", "range", "range", "range", "range", "range", "range", "range", "env.get_action_space", "env.get_action_space", "range", "range", "list", "env.get_agent_id", "numpy.tile", "models[].act", "env.set_action", "env.get_reward", "env.get_alive", "numpy.mean", "models[].flush_buffer", "env.get_num", "sum", "mean_rewards[].append", "total_rewards[].append", "env.render", "numpy.round", "print", "sum", "len", "env.get_observation", "list", "env.get_action_space", "env.get_action_space", "len", "map", "numpy.eye"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.reset", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.generate_map", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.clear_dead", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.train", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_agent_id", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.act", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.set_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_reward", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_alive", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.flush_buffer", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_observation", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space"], ["", "def", "play", "(", "env", ",", "n_round", ",", "map_size", ",", "max_steps", ",", "handles", ",", "models", ",", "print_every", ",", "eps", "=", "1.0", ",", "render", "=", "False", ",", "train", "=", "False", ")", ":", "\n", "    ", "\"\"\"play a ground and train\"\"\"", "\n", "env", ".", "reset", "(", ")", "\n", "generate_map", "(", "env", ",", "map_size", ",", "handles", ")", "\n", "\n", "step_ct", "=", "0", "\n", "done", "=", "False", "\n", "\n", "n_group", "=", "len", "(", "handles", ")", "\n", "state", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "acts", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "ids", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "\n", "alives", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "rewards", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "nums", "=", "[", "env", ".", "get_num", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "max_nums", "=", "nums", ".", "copy", "(", ")", "\n", "\n", "loss", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "eval_q", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "n_action", "=", "[", "env", ".", "get_action_space", "(", "handles", "[", "0", "]", ")", "[", "0", "]", ",", "env", ".", "get_action_space", "(", "handles", "[", "1", "]", ")", "[", "0", "]", "]", "\n", "\n", "print", "(", "\"\\n\\n[*] ROUND #{0}, EPS: {1:.2f} NUMBER: {2}\"", ".", "format", "(", "n_round", ",", "eps", ",", "nums", ")", ")", "\n", "mean_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "total_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "\n", "former_act_prob", "=", "[", "np", ".", "zeros", "(", "(", "1", ",", "env", ".", "get_action_space", "(", "handles", "[", "0", "]", ")", "[", "0", "]", ")", ")", ",", "np", ".", "zeros", "(", "(", "1", ",", "env", ".", "get_action_space", "(", "handles", "[", "1", "]", ")", "[", "0", "]", ")", ")", "]", "\n", "\n", "while", "not", "done", "and", "step_ct", "<", "max_steps", ":", "\n", "# take actions for every model", "\n", "        ", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "state", "[", "i", "]", "=", "list", "(", "env", ".", "get_observation", "(", "handles", "[", "i", "]", ")", ")", "\n", "ids", "[", "i", "]", "=", "env", ".", "get_agent_id", "(", "handles", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "former_act_prob", "[", "i", "]", "=", "np", ".", "tile", "(", "former_act_prob", "[", "i", "]", ",", "(", "len", "(", "state", "[", "i", "]", "[", "0", "]", ")", ",", "1", ")", ")", "\n", "acts", "[", "i", "]", "=", "models", "[", "i", "]", ".", "act", "(", "state", "=", "state", "[", "i", "]", ",", "prob", "=", "former_act_prob", "[", "i", "]", ",", "eps", "=", "eps", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "env", ".", "set_action", "(", "handles", "[", "i", "]", ",", "acts", "[", "i", "]", ")", "\n", "\n", "# simulate one step", "\n", "", "done", "=", "env", ".", "step", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "rewards", "[", "i", "]", "=", "env", ".", "get_reward", "(", "handles", "[", "i", "]", ")", "\n", "alives", "[", "i", "]", "=", "env", ".", "get_alive", "(", "handles", "[", "i", "]", ")", "\n", "\n", "", "buffer", "=", "{", "\n", "'state'", ":", "state", "[", "0", "]", ",", "'acts'", ":", "acts", "[", "0", "]", ",", "'rewards'", ":", "rewards", "[", "0", "]", ",", "\n", "'alives'", ":", "alives", "[", "0", "]", ",", "'ids'", ":", "ids", "[", "0", "]", "\n", "}", "\n", "\n", "buffer", "[", "'prob'", "]", "=", "former_act_prob", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "former_act_prob", "[", "i", "]", "=", "np", ".", "mean", "(", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "eye", "(", "n_action", "[", "i", "]", ")", "[", "x", "]", ",", "acts", "[", "i", "]", ")", ")", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "if", "train", ":", "\n", "            ", "models", "[", "0", "]", ".", "flush_buffer", "(", "**", "buffer", ")", "\n", "\n", "# stat info", "\n", "", "nums", "=", "[", "env", ".", "get_num", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "sum_reward", "=", "sum", "(", "rewards", "[", "i", "]", ")", "\n", "rewards", "[", "i", "]", "=", "sum_reward", "/", "nums", "[", "i", "]", "\n", "mean_rewards", "[", "i", "]", ".", "append", "(", "rewards", "[", "i", "]", ")", "\n", "total_rewards", "[", "i", "]", ".", "append", "(", "sum_reward", ")", "\n", "\n", "", "if", "render", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "# clear dead agents", "\n", "", "env", ".", "clear_dead", "(", ")", "\n", "\n", "info", "=", "{", "\"Ave-Reward\"", ":", "np", ".", "round", "(", "rewards", ",", "decimals", "=", "6", ")", ",", "\"NUM\"", ":", "nums", "}", "\n", "\n", "step_ct", "+=", "1", "\n", "\n", "if", "step_ct", "%", "print_every", "==", "0", ":", "\n", "            ", "print", "(", "\"> step #{}, info: {}\"", ".", "format", "(", "step_ct", ",", "info", ")", ")", "\n", "\n", "", "", "if", "train", ":", "\n", "        ", "models", "[", "0", "]", ".", "train", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "        ", "mean_rewards", "[", "i", "]", "=", "sum", "(", "mean_rewards", "[", "i", "]", ")", "/", "len", "(", "mean_rewards", "[", "i", "]", ")", "\n", "total_rewards", "[", "i", "]", "=", "sum", "(", "total_rewards", "[", "i", "]", ")", "\n", "\n", "", "return", "max_nums", ",", "nums", ",", "mean_rewards", ",", "total_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.battle_model.senario_battle.battle": [[127, 203], ["env.reset", "senario_battle.generate_map", "len", "nums.copy", "print", "range", "env.get_num", "numpy.zeros", "numpy.zeros", "range", "range", "range", "env.step", "range", "range", "range", "env.clear_dead", "sum", "range", "range", "range", "range", "range", "env.get_action_space", "env.get_action_space", "range", "range", "list", "env.get_agent_id", "numpy.tile", "models[].act", "env.set_action", "env.get_reward", "env.get_alive", "numpy.mean", "env.get_num", "sum", "mean_rewards[].append", "total_rewards[].append", "env.render", "numpy.round", "print", "sum", "len", "env.get_observation", "list", "env.get_action_space", "env.get_action_space", "len", "map", "numpy.eye"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.reset", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.generate_map", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.clear_dead", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_agent_id", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.act", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.set_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_reward", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_alive", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_observation", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space"], ["", "def", "battle", "(", "env", ",", "n_round", ",", "map_size", ",", "max_steps", ",", "handles", ",", "models", ",", "print_every", ",", "eps", "=", "1.0", ",", "render", "=", "False", ",", "train", "=", "False", ")", ":", "\n", "    ", "\"\"\"play a ground and train\"\"\"", "\n", "env", ".", "reset", "(", ")", "\n", "generate_map", "(", "env", ",", "map_size", ",", "handles", ")", "\n", "\n", "step_ct", "=", "0", "\n", "done", "=", "False", "\n", "\n", "n_group", "=", "len", "(", "handles", ")", "\n", "state", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "acts", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "ids", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "\n", "alives", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "rewards", "=", "[", "None", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "nums", "=", "[", "env", ".", "get_num", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "max_nums", "=", "nums", ".", "copy", "(", ")", "\n", "\n", "n_action", "=", "[", "env", ".", "get_action_space", "(", "handles", "[", "0", "]", ")", "[", "0", "]", ",", "env", ".", "get_action_space", "(", "handles", "[", "1", "]", ")", "[", "0", "]", "]", "\n", "\n", "print", "(", "\"\\n\\n[*] ROUND #{0}, EPS: {1:.2f} NUMBER: {2}\"", ".", "format", "(", "n_round", ",", "eps", ",", "nums", ")", ")", "\n", "mean_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "total_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_group", ")", "]", "\n", "\n", "former_act_prob", "=", "[", "np", ".", "zeros", "(", "(", "1", ",", "env", ".", "get_action_space", "(", "handles", "[", "0", "]", ")", "[", "0", "]", ")", ")", ",", "np", ".", "zeros", "(", "(", "1", ",", "env", ".", "get_action_space", "(", "handles", "[", "1", "]", ")", "[", "0", "]", ")", ")", "]", "\n", "\n", "while", "not", "done", "and", "step_ct", "<", "max_steps", ":", "\n", "# take actions for every model", "\n", "        ", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "state", "[", "i", "]", "=", "list", "(", "env", ".", "get_observation", "(", "handles", "[", "i", "]", ")", ")", "\n", "ids", "[", "i", "]", "=", "env", ".", "get_agent_id", "(", "handles", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "former_act_prob", "[", "i", "]", "=", "np", ".", "tile", "(", "former_act_prob", "[", "i", "]", ",", "(", "len", "(", "state", "[", "i", "]", "[", "0", "]", ")", ",", "1", ")", ")", "\n", "acts", "[", "i", "]", "=", "models", "[", "i", "]", ".", "act", "(", "state", "=", "state", "[", "i", "]", ",", "prob", "=", "former_act_prob", "[", "i", "]", ",", "eps", "=", "eps", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "env", ".", "set_action", "(", "handles", "[", "i", "]", ",", "acts", "[", "i", "]", ")", "\n", "\n", "# simulate one step", "\n", "", "done", "=", "env", ".", "step", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "rewards", "[", "i", "]", "=", "env", ".", "get_reward", "(", "handles", "[", "i", "]", ")", "\n", "alives", "[", "i", "]", "=", "env", ".", "get_alive", "(", "handles", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "former_act_prob", "[", "i", "]", "=", "np", ".", "mean", "(", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "eye", "(", "n_action", "[", "i", "]", ")", "[", "x", "]", ",", "acts", "[", "i", "]", ")", ")", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "# stat info", "\n", "", "nums", "=", "[", "env", ".", "get_num", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "            ", "sum_reward", "=", "sum", "(", "rewards", "[", "i", "]", ")", "\n", "rewards", "[", "i", "]", "=", "sum_reward", "/", "nums", "[", "i", "]", "\n", "mean_rewards", "[", "i", "]", ".", "append", "(", "rewards", "[", "i", "]", ")", "\n", "total_rewards", "[", "i", "]", ".", "append", "(", "sum_reward", ")", "\n", "\n", "", "if", "render", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "\n", "# clear dead agents", "\n", "", "env", ".", "clear_dead", "(", ")", "\n", "\n", "info", "=", "{", "\"Ave-Reward\"", ":", "np", ".", "round", "(", "rewards", ",", "decimals", "=", "6", ")", ",", "\"NUM\"", ":", "nums", "}", "\n", "\n", "step_ct", "+=", "1", "\n", "\n", "if", "step_ct", "%", "print_every", "==", "0", ":", "\n", "            ", "print", "(", "\"> step #{}, info: {}\"", ".", "format", "(", "step_ct", ",", "info", ")", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "n_group", ")", ":", "\n", "        ", "mean_rewards", "[", "i", "]", "=", "sum", "(", "mean_rewards", "[", "i", "]", ")", "/", "len", "(", "mean_rewards", "[", "i", "]", ")", "\n", "total_rewards", "[", "i", "]", "=", "sum", "(", "total_rewards", "[", "i", "]", ")", "\n", "\n", "", "return", "max_nums", ",", "nums", ",", "mean_rewards", ",", "total_rewards", "\n", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.__init__": [[20, 63], ["environment.Environment.__init__", "ctypes.c_void_p", "c_lib._LIB.env_new_game", "discrete_snake.DiscreteSnake._init_obs_buf", "numpy.empty", "c_lib._LIB.env_get_info", "c_lib._LIB.env_get_info", "c_lib._LIB.env_get_info", "ctypes.byref", "print", "numpy.empty.ctypes.data_as", "numpy.empty.ctypes.data_as", "numpy.empty.ctypes.data_as", "c_lib._LIB.env_config_game", "ctypes.POINTER", "ctypes.POINTER", "ctypes.POINTER", "ctypes.byref", "c_lib._LIB.env_config_game", "ctypes.c_int", "ctypes.byref", "c_lib._LIB.env_config_game", "ctypes.c_bool", "ctypes.byref", "c_lib._LIB.env_config_game", "ctypes.c_float", "ctypes.c_char_p"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._init_obs_buf"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "Environment", ".", "__init__", "(", "self", ")", "\n", "\n", "# for global settings", "\n", "game", "=", "ctypes", ".", "c_void_p", "(", ")", "\n", "_LIB", ".", "env_new_game", "(", "ctypes", ".", "byref", "(", "game", ")", ",", "b\"DiscreteSnake\"", ")", "\n", "self", ".", "game", "=", "game", "\n", "\n", "config_value_type", "=", "{", "\n", "'map_width'", ":", "int", ",", "'map_height'", ":", "int", ",", "\n", "'view_width'", ":", "int", ",", "'view_height'", ":", "int", ",", "\n", "'max_dead_penalty'", ":", "float", ",", "'corpse_value'", ":", "float", ",", "\n", "'embedding_size'", ":", "int", ",", "'total_resource'", ":", "int", ",", "\n", "'render_dir'", ":", "str", ",", "\n", "}", "\n", "\n", "# config general setting", "\n", "for", "key", "in", "config", ".", "config_dict", ":", "\n", "            ", "print", "(", "\"discrete_snake.py L37 : \"", ",", "key", ",", "config", ".", "config_dict", "[", "key", "]", ")", "\n", "value_type", "=", "config_value_type", "[", "key", "]", "\n", "if", "value_type", "is", "int", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_int", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", ")", "\n", "", "elif", "value_type", "is", "bool", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_bool", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", ")", "\n", "", "elif", "value_type", "is", "float", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_float", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", ")", "\n", "", "elif", "value_type", "is", "str", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ",", "ctypes", ".", "c_char_p", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", "\n", "\n", "# init observation buffer (for acceleration)", "\n", "", "", "self", ".", "_init_obs_buf", "(", ")", "\n", "\n", "# init view size, feature size, action space", "\n", "buf", "=", "np", ".", "empty", "(", "(", "3", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "0", ",", "b\"view_space\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "self", ".", "view_space", "=", "[", "buf", "[", "0", "]", ",", "buf", "[", "1", "]", ",", "buf", "[", "2", "]", "]", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "0", ",", "b\"feature_space\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "self", ".", "feature_space", "=", "buf", "[", "0", "]", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "0", ",", "b\"action_space\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "self", ".", "action_space", "=", "buf", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.reset": [[64, 66], ["c_lib._LIB.env_reset"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "_LIB", ".", "env_reset", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake._add_object": [[67, 73], ["c_lib._LIB.discrete_snake_add_object", "print", "exit", "int"], "methods", ["None"], ["", "def", "_add_object", "(", "self", ",", "obj_id", ",", "method", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "method", "==", "\"random\"", ":", "\n", "            ", "_LIB", ".", "discrete_snake_add_object", "(", "self", ".", "game", ",", "obj_id", ",", "int", "(", "kwargs", "[", "\"n\"", "]", ")", ",", "b\"random\"", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"unsupported type of method\"", ")", "\n", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.add_walls": [[74, 77], ["discrete_snake.DiscreteSnake._add_object"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake._add_object"], ["", "", "def", "add_walls", "(", "self", ",", "method", ",", "**", "kwargs", ")", ":", "\n", "# handle = -1 for walls", "\n", "        ", "self", ".", "_add_object", "(", "-", "1", ",", "method", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.add_food": [[78, 81], ["discrete_snake.DiscreteSnake._add_object"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake._add_object"], ["", "def", "add_food", "(", "self", ",", "method", ",", "**", "kwargs", ")", ":", "\n", "# handles = -2 for food", "\n", "        ", "self", ".", "_add_object", "(", "-", "2", ",", "method", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.add_agent": [[82, 84], ["discrete_snake.DiscreteSnake._add_object"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake._add_object"], ["", "def", "add_agent", "(", "self", ",", "method", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_add_object", "(", "0", ",", "method", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake._get_obs_buf": [[86, 101], ["group_buf.append", "group_buf.append", "numpy.zeros", "numpy.zeros", "ret.resize"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "_get_obs_buf", "(", "self", ",", "key", ",", "shape", ",", "dtype", ")", ":", "\n", "        ", "if", "self", ".", "obs_bufs", "[", "key", "]", "is", "None", ":", "\n", "            ", "group_buf", "=", "self", ".", "obs_bufs", "[", "key", "]", "=", "[", "1", "]", "# (buf_id, buf1, buf2, ...)", "\n", "group_buf", ".", "append", "(", "np", ".", "zeros", "(", "shape", "=", "shape", ",", "dtype", "=", "dtype", ")", ")", "\n", "group_buf", ".", "append", "(", "np", ".", "zeros", "(", "shape", "=", "shape", ",", "dtype", "=", "dtype", ")", ")", "\n", "ret", "=", "group_buf", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "group_buf", "=", "self", ".", "obs_bufs", "[", "key", "]", "\n", "turn", "=", "group_buf", "[", "0", "]", "\n", "ret", "=", "group_buf", "[", "turn", "]", "\n", "if", "shape", "!=", "ret", ".", "shape", ":", "\n", "                ", "ret", ".", "resize", "(", "shape", ",", "refcheck", "=", "False", ")", "\n", "", "group_buf", "[", "0", "]", "=", "(", "turn", "-", "1", "+", "1", ")", "%", "2", "+", "1", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake._init_obs_buf": [[102, 104], ["None"], "methods", ["None"], ["", "def", "_init_obs_buf", "(", "self", ")", ":", "\n", "        ", "self", ".", "obs_bufs", "=", "[", "None", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_observation": [[105, 119], ["discrete_snake.DiscreteSnake.get_num", "discrete_snake.DiscreteSnake._get_obs_buf", "discrete_snake.DiscreteSnake._get_obs_buf", "c_lib.as_float_c_array", "c_lib.as_float_c_array", "c_lib._LIB.env_get_observation", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_obs_buf", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_obs_buf", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array"], ["", "def", "get_observation", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "view_space", "=", "self", ".", "view_space", "\n", "feature_space", "=", "self", ".", "feature_space", "\n", "\n", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "view_buf", "=", "self", ".", "_get_obs_buf", "(", "self", ".", "OBS_VIEW_INDEX", ",", "[", "n", "]", "+", "view_space", ",", "np", ".", "float32", ")", "\n", "feature_buf", "=", "self", ".", "_get_obs_buf", "(", "self", ".", "OBS_FEATURE_INDEX", ",", "(", "n", ",", "feature_space", ")", ",", "np", ".", "float32", ")", "\n", "\n", "bufs", "=", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", "*", "2", ")", "(", ")", "\n", "bufs", "[", "0", "]", "=", "as_float_c_array", "(", "view_buf", ")", "\n", "bufs", "[", "1", "]", "=", "as_float_c_array", "(", "feature_buf", ")", "\n", "_LIB", ".", "env_get_observation", "(", "self", ".", "game", ",", "handle", ",", "bufs", ")", "\n", "\n", "return", "view_buf", ",", "feature_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.set_action": [[120, 124], ["isinstance", "c_lib._LIB.env_set_action", "actions.ctypes.data_as", "ctypes.POINTER"], "methods", ["None"], ["", "def", "set_action", "(", "self", ",", "handle", ",", "actions", ")", ":", "\n", "        ", "assert", "isinstance", "(", "actions", ",", "np", ".", "ndarray", ")", "\n", "assert", "actions", ".", "dtype", "==", "np", ".", "int32", "\n", "_LIB", ".", "env_set_action", "(", "self", ".", "game", ",", "handle", ",", "actions", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.step": [[125, 129], ["ctypes.c_int32", "c_lib._LIB.env_step", "ctypes.byref"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "done", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "env_step", "(", "self", ".", "game", ",", "ctypes", ".", "byref", "(", "done", ")", ")", "\n", "return", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_reward": [[130, 136], ["discrete_snake.DiscreteSnake.get_num", "numpy.empty", "c_lib._LIB.env_get_reward", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_reward", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "_LIB", ".", "env_get_reward", "(", "self", ".", "game", ",", "handle", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.clear_dead": [[137, 139], ["c_lib._LIB.discrete_snake_clear_dead"], "methods", ["None"], ["", "def", "clear_dead", "(", "self", ")", ":", "\n", "        ", "_LIB", ".", "discrete_snake_clear_dead", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_num": [[141, 145], ["ctypes.c_int32", "c_lib._LIB.env_get_info", "ctypes.byref"], "methods", ["None"], ["", "def", "get_num", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "num", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "\"num\"", ",", "ctypes", ".", "byref", "(", "num", ")", ")", "\n", "return", "num", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_action_space": [[146, 148], ["None"], "methods", ["None"], ["", "def", "get_action_space", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "return", "self", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_view_space": [[149, 151], ["None"], "methods", ["None"], ["", "def", "get_view_space", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "return", "self", ".", "view_space", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_feature_space": [[152, 154], ["None"], "methods", ["None"], ["", "def", "get_feature_space", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "return", "self", ".", "feature_space", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_agent_id": [[155, 161], ["discrete_snake.DiscreteSnake.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_agent_id", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"id\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_head": [[162, 168], ["discrete_snake.DiscreteSnake.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_head", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"head\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_alive": [[169, 175], ["discrete_snake.DiscreteSnake.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_alive", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"alive\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_bool", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_length": [[176, 182], ["discrete_snake.DiscreteSnake.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_length", "(", "self", ",", "handle", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"length\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.get_food_num": [[183, 187], ["ctypes.c_int32", "c_lib._LIB.env_get_info", "ctypes.byref"], "methods", ["None"], ["", "def", "get_food_num", "(", "self", ")", ":", "\n", "        ", "num", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "-", "2", ",", "\"num\"", ",", "ctypes", ".", "byref", "(", "num", ")", ")", "# -2 for food", "\n", "return", "num", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.set_render_dir": [[189, 193], ["c_lib._LIB.env_config_game", "os.path.exists", "os.mkdir"], "methods", ["None"], ["", "def", "set_render_dir", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "name", ")", "\n", "", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "b\"render_dir\"", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.render": [[194, 196], ["c_lib._LIB.env_render"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "_LIB", ".", "env_render", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.render_next_file": [[197, 199], ["c_lib._LIB.env_render_next_file"], "methods", ["None"], ["", "def", "render_next_file", "(", "self", ")", ":", "\n", "        ", "_LIB", ".", "env_render_next_file", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.DiscreteSnake.__del__": [[200, 202], ["c_lib._LIB.env_delete_game"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "_LIB", ".", "env_delete_game", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.Config.__init__": [[205, 207], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_dict", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.discrete_snake.Config.set": [[208, 211], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "args", ")", ":", "\n", "        ", "for", "key", "in", "args", ":", "\n", "            ", "self", ".", "config_dict", "[", "key", "]", "=", "args", "[", "key", "]", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBufferEntry.__init__": [[17, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "views", "=", "[", "]", "\n", "self", ".", "features", "=", "[", "]", "\n", "self", ".", "actions", "=", "[", "]", "\n", "self", ".", "rewards", "=", "[", "]", "\n", "self", ".", "terminal", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBufferEntry.append": [[24, 31], ["utility.EpisodesBufferEntry.views.append", "utility.EpisodesBufferEntry.features.append", "utility.EpisodesBufferEntry.actions.append", "utility.EpisodesBufferEntry.rewards.append", "view.copy", "feature.copy"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "append", "(", "self", ",", "view", ",", "feature", ",", "action", ",", "reward", ",", "alive", ")", ":", "\n", "        ", "self", ".", "views", ".", "append", "(", "view", ".", "copy", "(", ")", ")", "\n", "self", ".", "features", ".", "append", "(", "feature", ".", "copy", "(", ")", ")", "\n", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "if", "not", "alive", ":", "\n", "            ", "self", ".", "terminal", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBuffer.__init__": [[37, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "self", ".", "buffer", "=", "{", "}", "\n", "self", ".", "capacity", "=", "capacity", "\n", "self", ".", "is_full", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBuffer.record_step": [[42, 67], ["numpy.random.permutation", "len", "range", "range", "len", "buffer.get", "utility.EpisodesBufferEntry.append", "len", "buffer.get", "utility.EpisodesBufferEntry.append", "utility.EpisodesBufferEntry", "len"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "record_step", "(", "self", ",", "ids", ",", "obs", ",", "acts", ",", "rewards", ",", "alives", ")", ":", "\n", "        ", "\"\"\"record transitions (s, a, r, terminal) in a step\"\"\"", "\n", "buffer", "=", "self", ".", "buffer", "\n", "index", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "ids", ")", ")", "\n", "\n", "if", "self", ".", "is_full", ":", "# extract loop invariant in else part", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "ids", ")", ")", ":", "\n", "                ", "entry", "=", "buffer", ".", "get", "(", "ids", "[", "i", "]", ")", "\n", "if", "entry", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "entry", ".", "append", "(", "obs", "[", "0", "]", "[", "i", "]", ",", "obs", "[", "1", "]", "[", "i", "]", ",", "acts", "[", "i", "]", ",", "rewards", "[", "i", "]", ",", "alives", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "ids", ")", ")", ":", "\n", "                ", "i", "=", "index", "[", "i", "]", "\n", "entry", "=", "buffer", ".", "get", "(", "ids", "[", "i", "]", ")", "\n", "if", "entry", "is", "None", ":", "\n", "                    ", "if", "self", ".", "is_full", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "entry", "=", "EpisodesBufferEntry", "(", ")", "\n", "buffer", "[", "ids", "[", "i", "]", "]", "=", "entry", "\n", "if", "len", "(", "buffer", ")", ">=", "self", ".", "capacity", ":", "\n", "                            ", "self", ".", "is_full", "=", "True", "\n", "\n", "", "", "", "entry", ".", "append", "(", "obs", "[", "0", "]", "[", "i", "]", ",", "obs", "[", "1", "]", "[", "i", "]", ",", "acts", "[", "i", "]", ",", "rewards", "[", "i", "]", ",", "alives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBuffer.reset": [[68, 72], ["None"], "methods", ["None"], ["", "", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\" clear replay buffer \"\"\"", "\n", "self", ".", "buffer", "=", "{", "}", "\n", "self", ".", "is_full", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBuffer.episodes": [[73, 76], ["utility.EpisodesBuffer.buffer.values"], "methods", ["None"], ["", "def", "episodes", "(", "self", ")", ":", "\n", "        ", "\"\"\" get episodes \"\"\"", "\n", "return", "self", ".", "buffer", ".", "values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.FontProvider.__init__": [[273, 300], ["open", "fin.readlines", "range", "expand_data.append", "line.split", "data.append", "range", "char.append", "range", "eval", "range"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "        ", "data", "=", "[", "]", "\n", "# read raw", "\n", "with", "open", "(", "filename", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ".", "readlines", "(", ")", ":", "\n", "                ", "char", "=", "[", "]", "\n", "for", "x", "in", "line", ".", "split", "(", "','", ")", ":", "\n", "                    ", "char", ".", "append", "(", "eval", "(", "x", ")", ")", "\n", "", "data", ".", "append", "(", "char", ")", "\n", "\n", "", "", "height", "=", "8", "\n", "width", "=", "8", "\n", "\n", "# expand bit compress", "\n", "expand_data", "=", "[", "]", "\n", "for", "char", "in", "data", ":", "\n", "            ", "expand_char", "=", "[", "[", "0", "for", "_", "in", "range", "(", "width", ")", "]", "for", "_", "in", "range", "(", "height", ")", "]", "\n", "for", "i", "in", "range", "(", "width", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "height", ")", ":", "\n", "                    ", "set", "=", "char", "[", "i", "]", "&", "(", "1", "<<", "j", ")", "\n", "if", "set", ":", "\n", "                        ", "expand_char", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "", "", "", "expand_data", ".", "append", "(", "expand_char", ")", "\n", "\n", "", "self", ".", "data", "=", "expand_data", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.FontProvider.get": [[301, 306], ["isinstance", "ord"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "isinstance", "(", "i", ",", "int", ")", ":", "\n", "            ", "return", "self", ".", "data", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "data", "[", "ord", "(", "i", ")", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.exponential_decay": [[79, 83], ["math.exp", "max", "math.log"], "function", ["None"], ["", "", "def", "exponential_decay", "(", "now_step", ",", "total_step", ",", "final_value", ",", "rate", ")", ":", "\n", "    ", "\"\"\"exponential decay scheduler\"\"\"", "\n", "decay", "=", "math", ".", "exp", "(", "math", ".", "log", "(", "final_value", ")", "/", "total_step", "**", "rate", ")", "\n", "return", "max", "(", "final_value", ",", "1", "*", "decay", "**", "(", "now_step", "**", "rate", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.linear_decay": [[85, 89], ["max"], "function", ["None"], ["", "def", "linear_decay", "(", "now_step", ",", "total_step", ",", "final_value", ")", ":", "\n", "    ", "\"\"\"linear decay scheduler\"\"\"", "\n", "decay", "=", "(", "1", "-", "final_value", ")", "/", "total_step", "\n", "return", "max", "(", "final_value", ",", "1", "-", "decay", "*", "now_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.piecewise_decay": [[91, 112], ["len", "len"], "function", ["None"], ["", "def", "piecewise_decay", "(", "now_step", ",", "anchor", ",", "anchor_value", ")", ":", "\n", "    ", "\"\"\"piecewise linear decay scheduler\n\n    Parameters\n    ---------\n    now_step : int\n        current step\n    anchor : list of integer\n        step anchor\n    anchor_value: list of float\n        value at corresponding anchor\n    \"\"\"", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "anchor", ")", "and", "now_step", ">=", "anchor", "[", "i", "]", ":", "\n", "        ", "i", "+=", "1", "\n", "\n", "", "if", "i", "==", "len", "(", "anchor", ")", ":", "\n", "        ", "return", "anchor_value", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "return", "anchor_value", "[", "i", "-", "1", "]", "+", "(", "now_step", "-", "anchor", "[", "i", "-", "1", "]", ")", "*", "(", "(", "anchor_value", "[", "i", "]", "-", "anchor_value", "[", "i", "-", "1", "]", ")", "/", "(", "anchor", "[", "i", "]", "-", "anchor", "[", "i", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.sample_observation": [[115, 179], ["len", "range", "magent.builtin.rule_model.RandomActor", "range", "env.step", "env.clear_dead", "range", "numpy.array().reshape", "numpy.array().reshape", "range", "range", "range", "env.get_observation", "env.get_agent_id", "models[].infer_action", "env.set_action", "views[].append", "features[].append", "print", "zip", "numpy.array", "env.get_view_space", "numpy.array", "env.get_feature_space", "numpy.random.choice", "numpy.random.choice", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.clear_dead", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_observation", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_agent_id", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.infer_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.set_action", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space"], ["", "", "def", "sample_observation", "(", "env", ",", "handles", ",", "n_obs", "=", "-", "1", ",", "step", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"Sample observations by random actors.\n    These samples can be used for evaluation\n\n    Parameters\n    ----------\n    env : environment\n    handles: list of handle\n    n_obs : int\n        number of observation\n    step : int\n        maximum step\n\n    Returns\n    -------\n    ret : list of raw observation\n        raw observation for every group\n        the format of raw observation is tuple(view, feature)\n    \"\"\"", "\n", "models", "=", "[", "RandomActor", "(", "env", ",", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "\n", "n", "=", "len", "(", "handles", ")", "\n", "views", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "features", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "done", "=", "False", "\n", "step_ct", "=", "0", "\n", "while", "not", "done", ":", "\n", "        ", "obs", "=", "[", "env", ".", "get_observation", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "ids", "=", "[", "env", ".", "get_agent_id", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "act", "=", "models", "[", "i", "]", ".", "infer_action", "(", "obs", "[", "i", "]", ",", "ids", "[", "i", "]", ")", "\n", "env", ".", "set_action", "(", "handles", "[", "i", "]", ",", "act", ")", "\n", "\n", "", "done", "=", "env", ".", "step", "(", ")", "\n", "env", ".", "clear_dead", "(", ")", "\n", "\n", "# record steps", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "views", "[", "i", "]", ".", "append", "(", "obs", "[", "i", "]", "[", "0", "]", ")", "\n", "features", "[", "i", "]", ".", "append", "(", "features", "[", "i", "]", "[", "1", "]", ")", "\n", "\n", "", "if", "step", "!=", "-", "1", "and", "step_ct", ">", "step", ":", "\n", "            ", "break", "\n", "\n", "", "if", "step_ct", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "\"sample step %d\"", "%", "step_ct", ")", "\n", "\n", "", "step_ct", "+=", "1", "\n", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "views", "[", "i", "]", "=", "np", ".", "array", "(", "views", "[", "i", "]", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "\n", "env", ".", "get_view_space", "(", "handles", "[", "i", "]", ")", ")", "\n", "features", "[", "i", "]", "=", "np", ".", "array", "(", "features", "[", "i", "]", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "\n", "env", ".", "get_feature_space", "(", "handles", "[", "i", "]", ")", ")", "\n", "\n", "", "if", "n_obs", "!=", "-", "1", ":", "\n", "        ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "views", "[", "i", "]", "=", "views", "[", "i", "]", "[", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "views", "[", "i", "]", ".", "shape", "[", "0", "]", ")", ",", "n_obs", ")", "]", "\n", "features", "[", "i", "]", "=", "features", "[", "i", "]", "[", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "features", "[", "i", "]", ".", "shape", "[", "0", "]", ")", ",", "n_obs", ")", "]", "\n", "\n", "", "", "ret", "=", "[", "(", "v", ",", "f", ")", "for", "v", ",", "f", "in", "zip", "(", "views", ",", "features", ")", "]", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.init_logger": [[181, 193], ["logging.basicConfig", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.getLogger().addHandler", "logging.getLogger"], "function", ["None"], ["", "def", "init_logger", "(", "filename", ")", ":", "\n", "    ", "\"\"\" initialize logger config\n\n    Parameters\n    ----------\n    filename : str\n        filename of the log\n    \"\"\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "filename", "+", "\".log\"", ")", "\n", "console", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "logging", ".", "getLogger", "(", "''", ")", ".", "addHandler", "(", "console", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.rec_round": [[195, 208], ["isinstance", "round", "utility.rec_round"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.rec_round"], ["", "def", "rec_round", "(", "x", ",", "ndigits", "=", "2", ")", ":", "\n", "    ", "\"\"\" round x recursively\n\n    Parameters\n    ----------\n    x: float, int, list, list of list, ...\n        variable to round, support many types\n    ndigits: int\n        precision in decimal digits\n    \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "collections", ".", "Iterable", ")", ":", "\n", "        ", "return", "[", "rec_round", "(", "item", ",", "ndigits", ")", "for", "item", "in", "x", "]", "\n", "", "return", "round", "(", "x", ",", "ndigits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.has_gpu": [[210, 214], ["os.popen().read", "os.popen().read.find", "os.popen"], "function", ["None"], ["", "def", "has_gpu", "(", ")", ":", "\n", "    ", "\"\"\" check where has a nvidia gpu \"\"\"", "\n", "ret", "=", "os", ".", "popen", "(", "\"nvidia-smi -L 2>/dev/null\"", ")", ".", "read", "(", ")", "\n", "return", "ret", ".", "find", "(", "\"GPU\"", ")", "!=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.download_file": [[216, 228], ["print", "os.system", "print", "print", "exit", "print"], "function", ["None"], ["", "def", "download_file", "(", "filename", ",", "url", ")", ":", "\n", "    ", "\"\"\"download url to filename\"\"\"", "\n", "print", "(", "\"Download %s from %s...\"", "%", "(", "filename", ",", "url", ")", ")", "\n", "\n", "ret", "=", "os", ".", "system", "(", "\"wget -O %s '%s'\"", "%", "(", "filename", ",", "url", ")", ")", "\n", "\n", "if", "ret", "!=", "0", ":", "\n", "        ", "print", "(", "\"ERROR: wget fails!\"", ")", "\n", "print", "(", "\"If you are an OSX user, you can install wget by 'brew install wget' and retry.\"", ")", "\n", "exit", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"download done!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.download_model": [[230, 240], ["os.path.join", "utility.download_file", "utility.download_model.do_commond"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.download_file"], ["", "", "def", "download_model", "(", "url", ")", ":", "\n", "    ", "\"\"\"download model from url\"\"\"", "\n", "name", "=", "url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "name", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "name", ")", "\n", "download_file", "(", "name", ",", "url", ")", "\n", "def", "do_commond", "(", "cmd", ")", ":", "\n", "        ", "print", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "", "do_commond", "(", "\"tar xzf %s -C data\"", "%", "name", ")", "\n", "do_commond", "(", "\"rm %s\"", "%", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.check_model": [[242, 269], ["RuntimeError", "utility.download_model", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.download_model"], ["", "def", "check_model", "(", "name", ")", ":", "\n", "    ", "\"\"\"check whether a model is downloaded\"\"\"", "\n", "infos", "=", "{", "\n", "'against'", ":", "\n", "(", "(", "'data/battle_model/battle/tfdqn_0.index'", ",", ")", ",", "\n", "'https://raw.githubusercontent.com/merrymercy/merrymercy.github.io/master/_data/magent/against-0.tar.gz'", ")", ",", "\n", "\n", "'battle-game'", ":", "\n", "(", "(", "\"data/battle_model/trusty-battle-game-l/tfdqn_0.index\"", ",", "\n", "\"data/battle_model/trusty-battle-game-r/tfdqn_0.index\"", ")", ",", "\n", "'https://raw.githubusercontent.com/merrymercy/merrymercy.github.io/master/_data/magent/battle_model.tar.gz'", ")", ",", "\n", "\n", "'arrange'", ":", "\n", "(", "(", "'data/arrange_model/arrange/tfdqn_10.index'", ",", ")", ",", "\n", "'https://raw.githubusercontent.com/merrymercy/merrymercy.github.io/master/_data/magent/arrange_game.tar.gz'", ",", ")", "\n", "}", "\n", "\n", "if", "name", "not", "in", "infos", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Unknown model name\"", ")", "\n", "\n", "", "info", "=", "infos", "[", "name", "]", "\n", "missing", "=", "False", "\n", "for", "check", "in", "info", "[", "0", "]", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "check", ")", ":", "\n", "            ", "missing", "=", "True", "\n", "", "", "if", "missing", ":", "\n", "        ", "download_model", "(", "info", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib._load_lib": [[11, 23], ["os.path.dirname", "os.path.join", "ctypes.CDLL", "os.path.abspath", "platform.system", "os.path.join", "os.path.expanduser", "platform.system", "os.path.join", "BaseException", "platform.system"], "function", ["None"], ["def", "_load_lib", "(", ")", ":", "\n", "    ", "\"\"\" Load library in build/lib. \"\"\"", "\n", "cur_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "__file__", ")", ")", ")", "\n", "lib_path", "=", "os", ".", "path", ".", "join", "(", "cur_path", ",", "\"../../build/\"", ")", "\n", "if", "platform", ".", "system", "(", ")", "==", "'Darwin'", ":", "\n", "        ", "path_to_so_file", "=", "os", ".", "path", ".", "join", "(", "lib_path", ",", "\"libmagent.dylib\"", ")", "\n", "", "elif", "platform", ".", "system", "(", ")", "==", "'Linux'", ":", "\n", "        ", "path_to_so_file", "=", "os", ".", "path", ".", "join", "(", "lib_path", ",", "\"libmagent.so\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "BaseException", "(", "\"unsupported system: \"", "+", "platform", ".", "system", "(", ")", ")", "\n", "", "lib", "=", "ctypes", ".", "CDLL", "(", "path_to_so_file", ",", "ctypes", ".", "RTLD_GLOBAL", ")", "\n", "return", "lib", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array": [[25, 28], ["buf.ctypes.data_as", "ctypes.POINTER"], "function", ["None"], ["", "def", "as_float_c_array", "(", "buf", ")", ":", "\n", "    ", "\"\"\"numpy to ctypes array\"\"\"", "\n", "return", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array": [[30, 33], ["buf.ctypes.data_as", "ctypes.POINTER"], "function", ["None"], ["", "def", "as_int32_c_array", "(", "buf", ")", ":", "\n", "    ", "\"\"\"numpy to ctypes array\"\"\"", "\n", "return", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_bool_c_array": [[35, 38], ["buf.ctypes.data_as", "ctypes.POINTER"], "function", ["None"], ["", "def", "as_bool_c_array", "(", "buf", ")", ":", "\n", "    ", "\"\"\"numpy to ctypes array\"\"\"", "\n", "return", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_bool", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.BaseModel.__init__": [[15, 26], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" init\n\n        Parameters\n        ----------\n        env: Environment\n            env\n        handle: GroupHandle\n            handle of this group, handles are returned by env.get_handles()\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.BaseModel.infer_action": [[27, 46], ["None"], "methods", ["None"], ["", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" infer action for a group of agents\n\n        Parameters\n        ----------\n        raw_obs: tuple\n            raw_obs is a tuple of (view, feature)\n            view is a numpy array, its shape is n * view_width * view_height * n_channel\n                                   it contains the spatial local observation for all the agents\n            feature is a numpy array, its shape is n * feature_size\n                                   it contains the non-spatial feature for all the agents\n        ids: numpy array of int32\n            the unique id of every agents\n        args:\n            additional custom args\n        kwargs:\n            additional custom args\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.BaseModel.train": [[47, 60], ["None"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "sample_buffer", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" feed new samples and train\n\n        Parameters\n        ----------\n        sample_buffer: EpisodesBuffer\n            a buffer contains transitions of agents\n\n        Returns\n        -------\n        loss and estimated mean state value\n        \"\"\"", "\n", "return", "0", ",", "0", "# loss, mean value", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.BaseModel.save": [[61, 64], ["None"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" save the model \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.BaseModel.load": [[65, 68], ["None"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" load the model \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.__init__": [[72, 81], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "if", "isinstance", "(", "args", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "self", ".", "data", "=", "args", "\n", "self", ".", "info", "=", "[", "(", "x", ".", "shape", ",", "x", ".", "dtype", ")", "for", "x", "in", "args", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "data", "=", "None", "\n", "self", ".", "info", "=", "args", "[", "0", "]", "\n", "\n", "", "self", ".", "max_len", "=", "(", "1", "<<", "30", ")", "/", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.send_to": [[82, 98], ["thread.start_new_thread", "model.NDArrayPackage.send_to.send_thread"], "methods", ["None"], ["", "def", "send_to", "(", "self", ",", "conn", ",", "use_thread", "=", "False", ")", ":", "\n", "        ", "assert", "self", ".", "data", "is", "not", "None", "\n", "\n", "def", "send_thread", "(", ")", ":", "\n", "            ", "for", "x", "in", "self", ".", "data", ":", "\n", "                ", "if", "np", ".", "prod", "(", "x", ".", "shape", ")", ">", "self", ".", "max_len", ":", "\n", "                    ", "seg", "=", "int", "(", "self", ".", "max_len", "//", "np", ".", "prod", "(", "x", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "for", "pt", "in", "range", "(", "0", ",", "len", "(", "x", ")", ",", "seg", ")", ":", "\n", "                        ", "conn", ".", "send_bytes", "(", "x", "[", "pt", ":", "pt", "+", "seg", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "conn", ".", "send_bytes", "(", "x", ")", "\n", "\n", "", "", "", "if", "use_thread", ":", "\n", "            ", "thread", ".", "start_new_thread", "(", "send_thread", ",", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "send_thread", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.recv_from": [[99, 113], ["numpy.empty", "int", "bufs.append", "numpy.prod", "numpy.prod", "int", "range", "conn.recv_bytes_into", "numpy.empty.reshape", "int", "conn.recv_bytes_into", "int", "numpy.prod", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "", "def", "recv_from", "(", "self", ",", "conn", ")", ":", "\n", "        ", "bufs", "=", "[", "]", "\n", "for", "info", "in", "self", ".", "info", ":", "\n", "            ", "buf", "=", "np", ".", "empty", "(", "shape", "=", "(", "int", "(", "np", ".", "prod", "(", "info", "[", "0", "]", ")", ")", ",", ")", ",", "dtype", "=", "info", "[", "1", "]", ")", "\n", "\n", "item_size", "=", "int", "(", "np", ".", "prod", "(", "info", "[", "0", "]", "[", "1", ":", "]", ")", ")", "\n", "if", "np", ".", "prod", "(", "info", "[", "0", "]", ")", ">", "self", ".", "max_len", ":", "\n", "                ", "seg", "=", "int", "(", "self", ".", "max_len", "//", "item_size", ")", "\n", "for", "pt", "in", "range", "(", "0", ",", "int", "(", "np", ".", "prod", "(", "info", "[", "0", "]", ")", ")", ",", "seg", "*", "item_size", ")", ":", "\n", "                    ", "conn", ".", "recv_bytes_into", "(", "buf", "[", "pt", ":", "pt", "+", "seg", "*", "item_size", "]", ")", "\n", "", "", "else", ":", "\n", "               ", "conn", ".", "recv_bytes_into", "(", "buf", ")", "\n", "", "bufs", ".", "append", "(", "buf", ".", "reshape", "(", "info", "[", "0", "]", ")", ")", "\n", "", "return", "bufs", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.__init__": [[120, 155], ["model.BaseModel.__init__", "multiprocessing.Process", "multiprocessing.Process", "multiprocessing.Process", "multiprocessing.Process", "multiprocessing.Process.start", "multiprocessing.Process.start", "multiprocessing.connection.Listener", "multiprocessing.connection.Listener", "multiprocessing.connection.Listener", "multiprocessing.connection.Listener", "multiprocessing.connection.Listener.accept", "multiprocessing.connection.Listener.accept", "str"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.renderer.pygame_renderer.PyGameRenderer.start", "home.repos.pwc.inspect_result.mlii_mfrl.renderer.pygame_renderer.PyGameRenderer.start"], ["def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "port", ",", "sample_buffer_capacity", "=", "1000", ",", "\n", "RLModel", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        env: environment\n        handle: group handle\n        name: str\n            name of the model (be used when store model)\n        port: int\n            port of socket or suffix of pipe\n        sample_buffer_capacity: int\n            the maximum number of samples (s,r,a,s') to collect in a game round\n        RLModel: BaseModel\n            the RL algorithm class\n        kwargs: dict\n            arguments for RLModel\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "\n", "assert", "RLModel", "is", "not", "None", "\n", "\n", "kwargs", "[", "'env'", "]", "=", "env", "\n", "kwargs", "[", "'handle'", "]", "=", "handle", "\n", "kwargs", "[", "'name'", "]", "=", "name", "\n", "addr", "=", "'magent-pipe-'", "+", "str", "(", "port", ")", "# named pipe", "\n", "# addr = ('localhost', port) # socket", "\n", "proc", "=", "multiprocessing", ".", "Process", "(", "\n", "target", "=", "model_client", ",", "\n", "args", "=", "(", "addr", ",", "sample_buffer_capacity", ",", "RLModel", ",", "kwargs", ")", ",", "\n", ")", "\n", "\n", "proc", ".", "start", "(", ")", "\n", "listener", "=", "multiprocessing", ".", "connection", ".", "Listener", "(", "addr", ")", "\n", "self", ".", "conn", "=", "listener", ".", "accept", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.sample_step": [[156, 172], ["model.NDArrayPackage", "model.ProcessingModel.conn.send", "model.NDArrayPackage.send_to", "model.ProcessingModel.check_done"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.send_to", "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.check_done"], ["", "def", "sample_step", "(", "self", ",", "rewards", ",", "alives", ",", "block", "=", "True", ")", ":", "\n", "        ", "\"\"\"record a step (should be followed by check_done)\n\n        Parameters\n        ----------\n        block: bool\n            if it is True, the function call will block\n            if it is False, the caller must call check_done() afterward\n                            to check/consume the return message\n        \"\"\"", "\n", "package", "=", "NDArrayPackage", "(", "rewards", ",", "alives", ")", "\n", "self", ".", "conn", ".", "send", "(", "[", "\"sample\"", ",", "package", ".", "info", "]", ")", "\n", "package", ".", "send_to", "(", "self", ".", "conn", ")", "\n", "\n", "if", "block", ":", "\n", "            ", "self", ".", "check_done", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.infer_action": [[173, 202], ["model.NDArrayPackage", "model.ProcessingModel.conn.send", "model.NDArrayPackage.send_to", "model.ProcessingModel.conn.recv", "model.NDArrayPackage.recv_from", "model.NDArrayPackage"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.send_to", "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.recv_from"], ["", "", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "policy", "=", "'e_greedy'", ",", "eps", "=", "0", ",", "block", "=", "True", ")", ":", "\n", "        ", "\"\"\" infer action\n\n        Parameters\n        ----------\n        policy: str\n            can be 'e_greedy' or 'greedy'\n        eps: float\n            used when policy is 'e_greedy'\n        block: bool\n            if it is True, the function call will block, and return actions\n            if it is False, the function call won't block, the caller\n                            must call fetch_action() to get actions\n\n        Returns\n        -------\n        actions: numpy array (int32)\n            see above\n        \"\"\"", "\n", "\n", "package", "=", "NDArrayPackage", "(", "raw_obs", "[", "0", "]", ",", "raw_obs", "[", "1", "]", ",", "ids", ")", "\n", "self", ".", "conn", ".", "send", "(", "[", "\"act\"", ",", "policy", ",", "eps", ",", "package", ".", "info", "]", ")", "\n", "package", ".", "send_to", "(", "self", ".", "conn", ",", "use_thread", "=", "True", ")", "\n", "\n", "if", "block", ":", "\n", "            ", "info", "=", "self", ".", "conn", ".", "recv", "(", ")", "\n", "return", "NDArrayPackage", "(", "info", ")", ".", "recv_from", "(", "self", ".", "conn", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.fetch_action": [[203, 212], ["model.ProcessingModel.conn.recv", "model.NDArrayPackage.recv_from", "model.NDArrayPackage"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.recv_from"], ["", "", "def", "fetch_action", "(", "self", ")", ":", "\n", "        ", "\"\"\" fetch actions , fetch action after calling infer_action(block=False)\n\n        Returns\n        -------\n        actions: numpy array (int32)\n        \"\"\"", "\n", "info", "=", "self", ".", "conn", ".", "recv", "(", ")", "\n", "return", "NDArrayPackage", "(", "info", ")", ".", "recv_from", "(", "self", ".", "conn", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.train": [[213, 226], ["model.ProcessingModel.conn.send", "model.ProcessingModel.fetch_train"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.fetch_train"], ["", "def", "train", "(", "self", ",", "print_every", "=", "5000", ",", "block", "=", "True", ")", ":", "\n", "        ", "\"\"\" train new data samples according to the model setting\n\n        Parameters\n        ----------\n        print_every: int\n            print training log info every print_every batches\n\n        \"\"\"", "\n", "self", ".", "conn", ".", "send", "(", "[", "'train'", ",", "print_every", "]", ")", "\n", "\n", "if", "block", ":", "\n", "            ", "return", "self", ".", "fetch_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.fetch_train": [[227, 238], ["model.ProcessingModel.conn.recv"], "methods", ["None"], ["", "", "def", "fetch_train", "(", "self", ")", ":", "\n", "        ", "\"\"\" fetch result of train after calling train(block=False)\n\n        Returns\n        -------\n        loss: float\n            mean loss\n        value: float\n            mean state value\n        \"\"\"", "\n", "return", "self", ".", "conn", ".", "recv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.save": [[239, 253], ["model.ProcessingModel.conn.send", "model.ProcessingModel.check_done"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.check_done"], ["", "def", "save", "(", "self", ",", "save_dir", ",", "epoch", ",", "block", "=", "True", ")", ":", "\n", "        ", "\"\"\" save model\n\n        Parameters\n        ----------\n        block: bool\n            if it is True, the function call will block\n            if it is False, the caller must call check_done() afterward\n                            to check/consume the return message\n        \"\"\"", "\n", "\n", "self", ".", "conn", ".", "send", "(", "[", "\"save\"", ",", "save_dir", ",", "epoch", "]", ")", "\n", "if", "block", ":", "\n", "            ", "self", ".", "check_done", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.load": [[254, 269], ["model.ProcessingModel.conn.send", "model.ProcessingModel.check_done"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.check_done"], ["", "", "def", "load", "(", "self", ",", "save_dir", ",", "epoch", ",", "name", "=", "None", ",", "block", "=", "True", ")", ":", "\n", "        ", "\"\"\" load model\n\n        Parameters\n        ----------\n        name: str\n            name of the model (set when stored name is not the same as self.name)\n        block: bool\n            if it is True, the function call will block\n            if it is False, the caller must call check_done() afterward\n                            to check/consume the return message\n        \"\"\"", "\n", "self", ".", "conn", ".", "send", "(", "[", "\"load\"", ",", "save_dir", ",", "epoch", ",", "name", "]", ")", "\n", "if", "block", ":", "\n", "            ", "self", ".", "check_done", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.check_done": [[270, 273], ["model.ProcessingModel.conn.recv"], "methods", ["None"], ["", "", "def", "check_done", "(", "self", ")", ":", "\n", "        ", "\"\"\" check return message of sub processing \"\"\"", "\n", "assert", "self", ".", "conn", ".", "recv", "(", ")", "==", "'done'", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.quit": [[274, 277], ["model.ProcessingModel.conn.send"], "methods", ["None"], ["", "def", "quit", "(", "self", ")", ":", "\n", "        ", "\"\"\" quit \"\"\"", "\n", "self", ".", "conn", ".", "send", "(", "[", "\"quit\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.model_client": [[279, 339], ["RLModel", "magent.utility.EpisodesBuffer", "multiprocessing.connection.Client", "multiprocessing.connection.Client", "multiprocessing.connection.Client.recv", "model.NDArrayPackage.recv_from", "RLModel.infer_action", "model.NDArrayPackage", "multiprocessing.connection.Client.send", "model.NDArrayPackage.send_to", "RLModel.train", "magent.utility.EpisodesBuffer", "multiprocessing.connection.Client.send", "model.NDArrayPackage", "model.NDArrayPackage.recv_from", "magent.utility.EpisodesBuffer.record_step", "multiprocessing.connection.Client.send", "RLModel.save", "multiprocessing.connection.Client.send", "model.NDArrayPackage", "RLModel.load", "multiprocessing.connection.Client.send", "print"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.recv_from", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.infer_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.send_to", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.train", "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.NDArrayPackage.recv_from", "home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.EpisodesBuffer.record_step", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save", "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.__init__.load"], ["", "", "def", "model_client", "(", "addr", ",", "sample_buffer_capacity", ",", "RLModel", ",", "model_args", ")", ":", "\n", "    ", "\"\"\"target function for sub-processing to host a model\n\n    Parameters\n    ----------\n    addr: socket address\n    sample_buffer_capacity: int\n        the maximum number of samples (s,r,a,s') to collect in a game round\n    RLModel: BaseModel\n        the RL algorithm class\n    args: dict\n        arguments to RLModel\n    \"\"\"", "\n", "import", "magent", ".", "utility", "\n", "\n", "model", "=", "RLModel", "(", "**", "model_args", ")", "\n", "sample_buffer", "=", "magent", ".", "utility", ".", "EpisodesBuffer", "(", "capacity", "=", "sample_buffer_capacity", ")", "\n", "\n", "conn", "=", "multiprocessing", ".", "connection", ".", "Client", "(", "addr", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "cmd", "=", "conn", ".", "recv", "(", ")", "\n", "if", "cmd", "[", "0", "]", "==", "'act'", ":", "\n", "            ", "policy", "=", "cmd", "[", "1", "]", "\n", "eps", "=", "cmd", "[", "2", "]", "\n", "array_info", "=", "cmd", "[", "3", "]", "\n", "\n", "view", ",", "feature", ",", "ids", "=", "NDArrayPackage", "(", "array_info", ")", ".", "recv_from", "(", "conn", ")", "\n", "obs", "=", "(", "view", ",", "feature", ")", "\n", "\n", "acts", "=", "model", ".", "infer_action", "(", "obs", ",", "ids", ",", "policy", "=", "policy", ",", "eps", "=", "eps", ")", "\n", "package", "=", "NDArrayPackage", "(", "acts", ")", "\n", "conn", ".", "send", "(", "package", ".", "info", ")", "\n", "package", ".", "send_to", "(", "conn", ")", "\n", "", "elif", "cmd", "[", "0", "]", "==", "'train'", ":", "\n", "            ", "print_every", "=", "cmd", "[", "1", "]", "\n", "total_loss", ",", "value", "=", "model", ".", "train", "(", "sample_buffer", ",", "print_every", "=", "print_every", ")", "\n", "sample_buffer", "=", "magent", ".", "utility", ".", "EpisodesBuffer", "(", "sample_buffer_capacity", ")", "\n", "conn", ".", "send", "(", "(", "total_loss", ",", "value", ")", ")", "\n", "", "elif", "cmd", "[", "0", "]", "==", "'sample'", ":", "\n", "            ", "array_info", "=", "cmd", "[", "1", "]", "\n", "rewards", ",", "alives", "=", "NDArrayPackage", "(", "array_info", ")", ".", "recv_from", "(", "conn", ")", "\n", "sample_buffer", ".", "record_step", "(", "ids", ",", "obs", ",", "acts", ",", "rewards", ",", "alives", ")", "\n", "conn", ".", "send", "(", "\"done\"", ")", "\n", "", "elif", "cmd", "[", "0", "]", "==", "'save'", ":", "\n", "            ", "savedir", "=", "cmd", "[", "1", "]", "\n", "n_iter", "=", "cmd", "[", "2", "]", "\n", "model", ".", "save", "(", "savedir", ",", "n_iter", ")", "\n", "conn", ".", "send", "(", "\"done\"", ")", "\n", "", "elif", "cmd", "[", "0", "]", "==", "'load'", ":", "\n", "            ", "savedir", "=", "cmd", "[", "1", "]", "\n", "n_iter", "=", "cmd", "[", "2", "]", "\n", "name", "=", "cmd", "[", "3", "]", "\n", "model", ".", "load", "(", "savedir", ",", "n_iter", ",", "name", ")", "\n", "conn", ".", "send", "(", "\"done\"", ")", "\n", "", "elif", "cmd", "[", "0", "]", "==", "'quit'", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Error: Unknown command %s\"", "%", "cmd", "[", "0", "]", ")", "\n", "break", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.__init__": [[19, 116], ["environment.Environment.__init__", "isinstance", "ctypes.c_void_p", "c_lib._LIB.env_new_game", "gridworld.GridWorld._serialize_event_exp", "gridworld.GridWorld._init_obs_buf", "numpy.empty", "ctypes.byref", "len", "c_lib._LIB.gridworld_register_agent_type", "ctypes.c_int32", "c_lib._LIB.gridworld_new_group", "gridworld.GridWorld.group_handles.append", "c_lib._LIB.env_get_info", "c_lib._LIB.env_get_info", "c_lib._LIB.env_get_info", "importlib.import_module", "c_lib._LIB.env_config_game", "name.encode", "item.encode", "ctypes.byref", "numpy.empty.ctypes.data_as", "numpy.empty.ctypes.data_as", "numpy.empty.ctypes.data_as", "getattr", "BaseException", "key.encode", "ctypes.byref", "c_lib._LIB.env_config_game", "type_args.keys", "type_args.values", "ctypes.POINTER", "ctypes.POINTER", "ctypes.POINTER", "ctypes.c_int", "key.encode", "ctypes.byref", "c_lib._LIB.env_config_game", "key.encode", "ctypes.c_bool", "key.encode", "ctypes.byref", "c_lib._LIB.env_config_game", "type_args.keys", "ctypes.c_float", "key.encode", "ctypes.c_char_p"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._serialize_event_exp", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._init_obs_buf", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        config: str or Config Object\n            if config is a string, then it is a name of builtin config,\n                builtin config are stored in python/magent/builtin/config\n                kwargs are the arguments to the config\n            if config is a Config Object, then parameters are stored in that object\n        \"\"\"", "\n", "Environment", ".", "__init__", "(", "self", ")", "\n", "\n", "# if is str, load built in configuration", "\n", "if", "isinstance", "(", "config", ",", "str", ")", ":", "\n", "# built-in config are stored in python/magent/builtin/config", "\n", "            ", "try", ":", "\n", "                ", "demo_game", "=", "importlib", ".", "import_module", "(", "'magent.builtin.config.'", "+", "config", ")", "\n", "config", "=", "getattr", "(", "demo_game", ",", "'get_config'", ")", "(", "**", "kwargs", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "raise", "BaseException", "(", "'unknown built-in game \"'", "+", "config", "+", "'\"'", ")", "\n", "\n", "# create new game", "\n", "", "", "game", "=", "ctypes", ".", "c_void_p", "(", ")", "\n", "_LIB", ".", "env_new_game", "(", "ctypes", ".", "byref", "(", "game", ")", ",", "b\"GridWorld\"", ")", "\n", "self", ".", "game", "=", "game", "\n", "\n", "# set global configuration", "\n", "config_value_type", "=", "{", "\n", "'map_width'", ":", "int", ",", "'map_height'", ":", "int", ",", "\n", "'food_mode'", ":", "bool", ",", "'turn_mode'", ":", "bool", ",", "'minimap_mode'", ":", "bool", ",", "\n", "'revive_mode'", ":", "bool", ",", "'goal_mode'", ":", "bool", ",", "\n", "'embedding_size'", ":", "int", ",", "\n", "'render_dir'", ":", "str", ",", "\n", "}", "\n", "\n", "for", "key", "in", "config", ".", "config_dict", ":", "\n", "            ", "value_type", "=", "config_value_type", "[", "key", "]", "\n", "if", "value_type", "is", "int", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ".", "encode", "(", "\"ascii\"", ")", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_int", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", ")", "\n", "", "elif", "value_type", "is", "bool", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ".", "encode", "(", "\"ascii\"", ")", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_bool", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", ")", "\n", "", "elif", "value_type", "is", "float", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ".", "encode", "(", "\"ascii\"", ")", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_float", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", ")", "\n", "", "elif", "value_type", "is", "str", ":", "\n", "                ", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "key", ".", "encode", "(", "\"ascii\"", ")", ",", "ctypes", ".", "c_char_p", "(", "config", ".", "config_dict", "[", "key", "]", ")", ")", "\n", "\n", "# register agent types", "\n", "", "", "for", "name", "in", "config", ".", "agent_type_dict", ":", "\n", "            ", "type_args", "=", "config", ".", "agent_type_dict", "[", "name", "]", "\n", "\n", "# special pre-process for view range and attack range", "\n", "for", "key", "in", "[", "x", "for", "x", "in", "type_args", ".", "keys", "(", ")", "]", ":", "\n", "                ", "if", "key", "==", "\"view_range\"", ":", "\n", "                    ", "val", "=", "type_args", "[", "key", "]", "\n", "del", "type_args", "[", "key", "]", "\n", "type_args", "[", "\"view_radius\"", "]", "=", "val", ".", "radius", "\n", "type_args", "[", "\"view_angle\"", "]", "=", "val", ".", "angle", "\n", "", "elif", "key", "==", "\"attack_range\"", ":", "\n", "                    ", "val", "=", "type_args", "[", "key", "]", "\n", "del", "type_args", "[", "key", "]", "\n", "type_args", "[", "\"attack_radius\"", "]", "=", "val", ".", "radius", "\n", "type_args", "[", "\"attack_angle\"", "]", "=", "val", ".", "angle", "\n", "\n", "", "", "length", "=", "len", "(", "type_args", ")", "\n", "keys", "=", "(", "ctypes", ".", "c_char_p", "*", "length", ")", "(", "*", "[", "key", ".", "encode", "(", "\"ascii\"", ")", "for", "key", "in", "type_args", ".", "keys", "(", ")", "]", ")", "\n", "values", "=", "(", "ctypes", ".", "c_float", "*", "length", ")", "(", "*", "type_args", ".", "values", "(", ")", ")", "\n", "\n", "_LIB", ".", "gridworld_register_agent_type", "(", "self", ".", "game", ",", "name", ".", "encode", "(", "\"ascii\"", ")", ",", "length", ",", "keys", ",", "values", ")", "\n", "\n", "# serialize event expression, send to C++ engine", "\n", "", "self", ".", "_serialize_event_exp", "(", "config", ")", "\n", "\n", "# init group handles", "\n", "self", ".", "group_handles", "=", "[", "]", "\n", "for", "item", "in", "config", ".", "groups", ":", "\n", "            ", "handle", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "gridworld_new_group", "(", "self", ".", "game", ",", "item", ".", "encode", "(", "\"ascii\"", ")", ",", "ctypes", ".", "byref", "(", "handle", ")", ")", "\n", "self", ".", "group_handles", ".", "append", "(", "handle", ")", "\n", "\n", "# init observation buffer (for acceleration)", "\n", "", "self", ".", "_init_obs_buf", "(", ")", "\n", "\n", "# init view space, feature space, action space", "\n", "self", ".", "view_space", "=", "{", "}", "\n", "self", ".", "feature_space", "=", "{", "}", "\n", "self", ".", "action_space", "=", "{", "}", "\n", "buf", "=", "np", ".", "empty", "(", "(", "3", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "handle", "in", "self", ".", "group_handles", ":", "\n", "            ", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"view_space\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "self", ".", "view_space", "[", "handle", ".", "value", "]", "=", "(", "buf", "[", "0", "]", ",", "buf", "[", "1", "]", ",", "buf", "[", "2", "]", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"feature_space\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "self", ".", "feature_space", "[", "handle", ".", "value", "]", "=", "(", "buf", "[", "0", "]", ",", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"action_space\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "self", ".", "action_space", "[", "handle", ".", "value", "]", "=", "(", "buf", "[", "0", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.reset": [[117, 120], ["c_lib._LIB.env_reset"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"reset environment\"\"\"", "\n", "_LIB", ".", "env_reset", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.add_walls": [[121, 142], ["gridworld.GridWorld.add_agents"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents"], ["", "def", "add_walls", "(", "self", ",", "method", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"add wall to environment\n\n        Parameters\n        ----------\n        method: str\n            can be 'random' or 'custom'\n            if method is 'random', then kwargs[\"n\"] is a int\n            if method is 'custom', then kwargs[\"pos\"] is a list of coordination\n\n        Examples\n        --------\n        # add 1000 walls randomly\n        >>> env.add_walls(method=\"random\", n=1000)\n\n        # add 3 walls to (1,2), (4,5) and (9, 8) in map\n        >>> env.add_walls(method=\"custom\", pos=[(1,2), (4,5), (9,8)])\n        \"\"\"", "\n", "# handle = -1 for walls", "\n", "kwargs", "[", "\"dir\"", "]", "=", "0", "\n", "self", ".", "add_agents", "(", "-", "1", ",", "method", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.new_group": [[144, 149], ["ctypes.c_int32", "c_lib._LIB.gridworld_new_group", "ctypes.c_char_p", "ctypes.byref", "name.encode"], "methods", ["None"], ["", "def", "new_group", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"register a new group into environment\"\"\"", "\n", "handle", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "gridworld_new_group", "(", "self", ".", "game", ",", "ctypes", ".", "c_char_p", "(", "name", ".", "encode", "(", "\"ascii\"", ")", ")", ",", "ctypes", ".", "byref", "(", "handle", ")", ")", "\n", "return", "handle", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.add_agents": [[150, 201], ["c_lib._LIB.gridworld_add_agents", "int", "len", "numpy.array", "c_lib._LIB.gridworld_add_agents", "len", "numpy.array", "numpy.array", "numpy.array", "c_lib.as_int32_c_array", "c_lib.as_int32_c_array", "c_lib.as_int32_c_array", "kwargs.get", "numpy.array", "c_lib._LIB.gridworld_add_agents", "numpy.zeros", "numpy.zeros_like", "c_lib.as_int32_c_array", "numpy.array", "c_lib._LIB.gridworld_add_agents", "print", "exit", "c_lib.as_int32_c_array"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array"], ["", "def", "add_agents", "(", "self", ",", "handle", ",", "method", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"add agents to environment\n\n        Parameters\n        ----------\n        handle: group handle\n        method: str\n            can be 'random' or 'custom'\n            if method is 'random', then kwargs[\"n\"] is a int\n            if method is 'custom', then kwargs[\"pos\"] is a list of coordination\n\n        Examples\n        --------\n        # add 1000 walls randomly\n        >>> env.add_agents(handle, method=\"random\", n=1000)\n\n        # add 3 agents to (1,2), (4,5) and (9, 8) in map\n        >>> env.add_agents(handle, method=\"custom\", pos=[(1,2), (4,5), (9,8)])\n        \"\"\"", "\n", "if", "method", "==", "\"random\"", ":", "\n", "            ", "_LIB", ".", "gridworld_add_agents", "(", "self", ".", "game", ",", "handle", ",", "int", "(", "kwargs", "[", "\"n\"", "]", ")", ",", "b\"random\"", ",", "0", ",", "0", ",", "0", ")", "\n", "", "elif", "method", "==", "\"custom\"", ":", "\n", "            ", "n", "=", "len", "(", "kwargs", "[", "\"pos\"", "]", ")", "\n", "pos", "=", "np", ".", "array", "(", "kwargs", "[", "\"pos\"", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "if", "len", "(", "pos", ")", "<=", "0", ":", "\n", "                ", "return", "\n", "", "if", "pos", ".", "shape", "[", "1", "]", "==", "3", ":", "# if has dir", "\n", "                ", "xs", ",", "ys", ",", "dirs", "=", "pos", "[", ":", ",", "0", "]", ",", "pos", "[", ":", ",", "1", "]", ",", "pos", "[", ":", ",", "2", "]", "\n", "", "else", ":", "# if do not has dir, use zero padding", "\n", "                ", "xs", ",", "ys", ",", "dirs", "=", "pos", "[", ":", ",", "0", "]", ",", "pos", "[", ":", ",", "1", "]", ",", "np", ".", "zeros", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# copy again, to make these arrays continuous in memory", "\n", "", "xs", ",", "ys", ",", "dirs", "=", "np", ".", "array", "(", "xs", ")", ",", "np", ".", "array", "(", "ys", ")", ",", "np", ".", "array", "(", "dirs", ")", "\n", "_LIB", ".", "gridworld_add_agents", "(", "self", ".", "game", ",", "handle", ",", "n", ",", "b\"custom\"", ",", "as_int32_c_array", "(", "xs", ")", ",", "\n", "as_int32_c_array", "(", "ys", ")", ",", "as_int32_c_array", "(", "dirs", ")", ")", "\n", "", "elif", "method", "==", "\"fill\"", ":", "\n", "            ", "x", ",", "y", "=", "kwargs", "[", "\"pos\"", "]", "[", "0", "]", ",", "kwargs", "[", "\"pos\"", "]", "[", "1", "]", "\n", "width", ",", "height", "=", "kwargs", "[", "\"size\"", "]", "[", "0", "]", ",", "kwargs", "[", "\"size\"", "]", "[", "1", "]", "\n", "dir", "=", "kwargs", ".", "get", "(", "\"dir\"", ",", "np", ".", "zeros_like", "(", "x", ")", ")", "\n", "bind", "=", "np", ".", "array", "(", "[", "x", ",", "y", ",", "width", ",", "height", ",", "dir", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "gridworld_add_agents", "(", "self", ".", "game", ",", "handle", ",", "0", ",", "b\"fill\"", ",", "as_int32_c_array", "(", "bind", ")", ",", "\n", "0", ",", "0", ",", "0", ")", "\n", "", "elif", "method", "==", "\"maze\"", ":", "\n", "# TODO: implement maze add", "\n", "            ", "x_start", ",", "y_start", ",", "x_end", ",", "y_end", "=", "kwargs", "[", "\"pos\"", "]", "[", "0", "]", ",", "kwargs", "[", "\"pos\"", "]", "[", "1", "]", ",", "kwargs", "[", "\"pos\"", "]", "[", "2", "]", ",", "kwargs", "[", "\"pos\"", "]", "[", "3", "]", "\n", "thick", "=", "kwargs", "[", "\"pos\"", "]", "[", "4", "]", "\n", "bind", "=", "np", ".", "array", "(", "[", "x_start", ",", "y_start", ",", "x_end", ",", "y_end", ",", "thick", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "gridworld_add_agents", "(", "self", ".", "game", ",", "handle", ",", "0", ",", "b\"maze\"", ",", "as_int32_c_array", "(", "bind", ")", ",", "\n", "0", ",", "0", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Unknown type of position\"", ")", "\n", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_obs_buf": [[203, 214], ["numpy.empty", "numpy.empty.resize"], "methods", ["None"], ["", "", "def", "_get_obs_buf", "(", "self", ",", "group", ",", "key", ",", "shape", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"get buffer to receive observation from c++ engine\"\"\"", "\n", "obs_buf", "=", "self", ".", "obs_bufs", "[", "key", "]", "\n", "if", "group", "in", "obs_buf", ":", "\n", "            ", "ret", "=", "obs_buf", "[", "group", "]", "\n", "if", "shape", "!=", "ret", ".", "shape", ":", "\n", "                ", "ret", ".", "resize", "(", "shape", ",", "refcheck", "=", "False", ")", "\n", "", "", "else", ":", "\n", "            ", "ret", "=", "obs_buf", "[", "group", "]", "=", "np", ".", "empty", "(", "shape", "=", "shape", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._init_obs_buf": [[215, 220], ["gridworld.GridWorld.obs_bufs.append", "gridworld.GridWorld.obs_bufs.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "_init_obs_buf", "(", "self", ")", ":", "\n", "        ", "\"\"\"init observation buffer\"\"\"", "\n", "self", ".", "obs_bufs", "=", "[", "]", "\n", "self", ".", "obs_bufs", ".", "append", "(", "{", "}", ")", "\n", "self", ".", "obs_bufs", ".", "append", "(", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_observation": [[221, 249], ["gridworld.GridWorld.get_num", "gridworld.GridWorld._get_obs_buf", "gridworld.GridWorld._get_obs_buf", "c_lib.as_float_c_array", "c_lib.as_float_c_array", "c_lib._LIB.env_get_observation", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_obs_buf", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_obs_buf", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array"], ["", "def", "get_observation", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get observation of a whole group\n\n        Parameters\n        ----------\n        handle : group handle\n\n        Returns\n        -------\n        obs : tuple (views, features)\n            views is a numpy array, whose shape is n * view_width * view_height * n_channel\n            features is a numpy array, whose shape is n * feature_size\n            for agent i, (views[i], features[i]) is its observation at this step\n        \"\"\"", "\n", "view_space", "=", "self", ".", "view_space", "[", "handle", ".", "value", "]", "\n", "feature_space", "=", "self", ".", "feature_space", "[", "handle", ".", "value", "]", "\n", "no", "=", "handle", ".", "value", "\n", "\n", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "view_buf", "=", "self", ".", "_get_obs_buf", "(", "no", ",", "self", ".", "OBS_INDEX_VIEW", ",", "(", "n", ",", ")", "+", "view_space", ",", "np", ".", "float32", ")", "\n", "feature_buf", "=", "self", ".", "_get_obs_buf", "(", "no", ",", "self", ".", "OBS_INDEX_HP", ",", "(", "n", ",", ")", "+", "feature_space", ",", "np", ".", "float32", ")", "\n", "\n", "bufs", "=", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", "*", "2", ")", "(", ")", "\n", "bufs", "[", "0", "]", "=", "as_float_c_array", "(", "view_buf", ")", "\n", "bufs", "[", "1", "]", "=", "as_float_c_array", "(", "feature_buf", ")", "\n", "_LIB", ".", "env_get_observation", "(", "self", ".", "game", ",", "handle", ",", "bufs", ")", "\n", "\n", "return", "view_buf", ",", "feature_buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.set_action": [[250, 262], ["isinstance", "c_lib._LIB.env_set_action", "actions.ctypes.data_as", "ctypes.POINTER"], "methods", ["None"], ["", "def", "set_action", "(", "self", ",", "handle", ",", "actions", ")", ":", "\n", "        ", "\"\"\" set actions for whole group\n\n        Parameters\n        ----------\n        handle: group handle\n        actions: numpy array\n            the dtype of actions must be int32\n        \"\"\"", "\n", "assert", "isinstance", "(", "actions", ",", "np", ".", "ndarray", ")", "\n", "assert", "actions", ".", "dtype", "==", "np", ".", "int32", "\n", "_LIB", ".", "env_set_action", "(", "self", ".", "game", ",", "handle", ",", "actions", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.step": [[263, 274], ["ctypes.c_int32", "c_lib._LIB.env_step", "bool", "ctypes.byref"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"simulation one step after set actions\n\n        Returns\n        -------\n        done: bool\n            whether the game is done\n        \"\"\"", "\n", "done", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "env_step", "(", "self", ".", "game", ",", "ctypes", ".", "byref", "(", "done", ")", ")", "\n", "return", "bool", "(", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_reward": [[275, 288], ["gridworld.GridWorld.get_num", "numpy.empty", "c_lib._LIB.env_get_reward", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_reward", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get reward for a whole group\n\n        Returns\n        -------\n        rewards: numpy array (float32)\n            reward for all the agents in the group\n        \"\"\"", "\n", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "_LIB", ".", "env_get_reward", "(", "self", ".", "game", ",", "handle", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.clear_dead": [[289, 294], ["c_lib._LIB.gridworld_clear_dead"], "methods", ["None"], ["", "def", "clear_dead", "(", "self", ")", ":", "\n", "        ", "\"\"\" clear dead agents in the engine\n        must be called after step()\n        \"\"\"", "\n", "_LIB", ".", "gridworld_clear_dead", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_handles": [[296, 299], ["None"], "methods", ["None"], ["", "def", "get_handles", "(", "self", ")", ":", "\n", "        ", "\"\"\" get all group handles in the environment \"\"\"", "\n", "return", "self", ".", "group_handles", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_num": [[300, 305], ["ctypes.c_int32", "c_lib._LIB.env_get_info", "ctypes.byref"], "methods", ["None"], ["", "def", "get_num", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get the number of agents in a group\"\"\"", "\n", "num", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b'num'", ",", "ctypes", ".", "byref", "(", "num", ")", ")", "\n", "return", "num", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_action_space": [[306, 314], ["None"], "methods", ["None"], ["", "def", "get_action_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\"get action space\n\n        Returns\n        -------\n        action_space : tuple\n        \"\"\"", "\n", "return", "self", ".", "action_space", "[", "handle", ".", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_view_space": [[315, 323], ["None"], "methods", ["None"], ["", "def", "get_view_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\"get view space\n\n        Returns\n        -------\n        view_space : tuple\n        \"\"\"", "\n", "return", "self", ".", "view_space", "[", "handle", ".", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_feature_space": [[324, 332], ["None"], "methods", ["None"], ["", "def", "get_feature_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get feature space\n\n        Returns\n        -------\n        feature_space : tuple\n        \"\"\"", "\n", "return", "self", ".", "feature_space", "[", "handle", ".", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_agent_id": [[333, 346], ["gridworld.GridWorld.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_agent_id", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get agent id\n\n        Returns\n        -------\n        ids : numpy array (int32)\n            id of all the agents in the group\n        \"\"\"", "\n", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"id\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_alive": [[347, 360], ["gridworld.GridWorld.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_alive", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get alive status of agents in a group\n\n        Returns\n        -------\n        alives: numpy array (bool)\n            whether the agents are alive\n        \"\"\"", "\n", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"alive\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_bool", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_pos": [[361, 374], ["gridworld.GridWorld.get_num", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_pos", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get position of agents in a group\n\n        Returns\n        -------\n        pos: numpy array (int)\n            the shape of pos is (n, 2)\n        \"\"\"", "\n", "n", "=", "self", ".", "get_num", "(", "handle", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"pos\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_mean_info": [[375, 381], ["numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["None"], ["", "def", "get_mean_info", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" deprecated \"\"\"", "\n", "buf", "=", "np", ".", "empty", "(", "2", "+", "self", ".", "action_space", "[", "handle", ".", "value", "]", "[", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"mean_info\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_view2attack": [[382, 400], ["numpy.empty", "ctypes.c_int32", "c_lib._LIB.env_get_info", "c_lib._LIB.env_get_info", "gridworld.GridWorld.get_view_space", "numpy.empty.ctypes.data_as", "ctypes.byref", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space"], ["", "def", "get_view2attack", "(", "self", ",", "handle", ")", ":", "\n", "        ", "\"\"\" get a matrix with the same size of view_range,\n            if element >= 0, then it means it is a attackable point, and the corresponding\n                                    action number is the value of that element\n        Returns\n        -------\n        attack_back: int\n        buf: numpy array\n            map attack action into view\n        \"\"\"", "\n", "size", "=", "self", ".", "get_view_space", "(", "handle", ")", "[", "0", ":", "2", "]", "\n", "buf", "=", "np", ".", "empty", "(", "size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "attack_base", "=", "ctypes", ".", "c_int32", "(", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"view2attack\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "handle", ",", "b\"attack_base\"", ",", "\n", "ctypes", ".", "byref", "(", "attack_base", ")", ")", "\n", "return", "attack_base", ".", "value", ",", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_global_minimap": [[401, 421], ["numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "len", "ctypes.POINTER"], "methods", ["None"], ["", "def", "get_global_minimap", "(", "self", ",", "height", ",", "width", ")", ":", "\n", "        ", "\"\"\" compress global map into a minimap of given size\n        Parameters\n        ----------\n        height: int\n            the height of minimap\n        width:  int\n            the width of minimap\n\n        Returns\n        -------\n        minimap : numpy array\n            the shape (n_group + 1, height, width)\n        \"\"\"", "\n", "buf", "=", "np", ".", "empty", "(", "(", "height", ",", "width", ",", "len", "(", "self", ".", "group_handles", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "buf", "[", "0", ",", "0", ",", "0", "]", "=", "height", "\n", "buf", "[", "0", ",", "0", ",", "1", "]", "=", "width", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "-", "1", ",", "b\"global_minimap\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_float", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.set_seed": [[422, 425], ["c_lib._LIB.env_config_game", "ctypes.byref", "ctypes.c_int"], "methods", ["None"], ["", "def", "set_seed", "(", "self", ",", "seed", ")", ":", "\n", "        ", "\"\"\" set random seed of the engine\"\"\"", "\n", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "b\"seed\"", ",", "ctypes", ".", "byref", "(", "ctypes", ".", "c_int", "(", "seed", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.set_render_dir": [[427, 432], ["c_lib._LIB.env_config_game", "os.path.exists", "os.mkdir", "name.encode"], "methods", ["None"], ["", "def", "set_render_dir", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\" set directory to save render file\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "name", ")", "\n", "", "_LIB", ".", "env_config_game", "(", "self", ".", "game", ",", "b\"render_dir\"", ",", "name", ".", "encode", "(", "\"ascii\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.render": [[433, 436], ["c_lib._LIB.env_render"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "\"\"\" render a step \"\"\"", "\n", "_LIB", ".", "env_render", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_groups_info": [[437, 444], ["len", "numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["None"], ["", "def", "_get_groups_info", "(", "self", ")", ":", "\n", "        ", "\"\"\" private method, for interactive application\"\"\"", "\n", "n", "=", "len", "(", "self", ".", "group_handles", ")", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", "5", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "-", "1", ",", "b\"groups_info\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_walls_info": [[445, 453], ["numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty.ctypes.data_as", "ctypes.POINTER"], "methods", ["None"], ["", "def", "_get_walls_info", "(", "self", ")", ":", "\n", "        ", "\"\"\" private method, for interactive application\"\"\"", "\n", "n", "=", "100", "*", "100", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "-", "1", ",", "b\"walls_info\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "ctypes", ".", "c_int32", ")", ")", ")", "\n", "n", "=", "buf", "[", "0", ",", "0", "]", "# the first line is the number of walls", "\n", "return", "buf", "[", "1", ":", "1", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_render_info": [[454, 480], ["numpy.empty", "c_lib._LIB.env_get_info", "numpy.empty", "c_lib._LIB.env_get_info", "gridworld.GridWorld.get_num", "numpy.empty.ctypes.data_as", "numpy.empty.ctypes.data_as", "ctypes.POINTER", "ctypes.POINTER"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "_get_render_info", "(", "self", ",", "x_range", ",", "y_range", ")", ":", "\n", "        ", "\"\"\" private method, for interactive application\"\"\"", "\n", "n", "=", "0", "\n", "for", "handle", "in", "self", ".", "group_handles", ":", "\n", "            ", "n", "+=", "self", ".", "get_num", "(", "handle", ")", "\n", "\n", "", "buf", "=", "np", ".", "empty", "(", "(", "n", "+", "1", ",", "4", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "buf", "[", "0", "]", "=", "x_range", "[", "0", "]", ",", "y_range", "[", "0", "]", ",", "x_range", "[", "1", "]", ",", "y_range", "[", "1", "]", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "-", "1", ",", "b\"render_window_info\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "(", "ctypes", ".", "c_int32", ")", ")", ")", ")", "\n", "\n", "# the first line is for the number of agents in the window range", "\n", "info_line", "=", "buf", "[", "0", "]", "\n", "agent_ct", ",", "attack_event_ct", "=", "info_line", "[", "0", "]", ",", "info_line", "[", "1", "]", "\n", "buf", "=", "buf", "[", "1", ":", "1", "+", "info_line", "[", "0", "]", "]", "\n", "\n", "agent_info", "=", "{", "}", "\n", "for", "item", "in", "buf", ":", "\n", "            ", "agent_info", "[", "item", "[", "0", "]", "]", "=", "[", "item", "[", "1", "]", ",", "item", "[", "2", "]", ",", "item", "[", "3", "]", "]", "\n", "\n", "", "buf", "=", "np", ".", "empty", "(", "(", "attack_event_ct", ",", "3", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "_LIB", ".", "env_get_info", "(", "self", ".", "game", ",", "-", "1", ",", "b\"attack_event\"", ",", "\n", "buf", ".", "ctypes", ".", "data_as", "(", "ctypes", ".", "POINTER", "(", "(", "ctypes", ".", "c_int32", ")", ")", ")", ")", "\n", "attack_event", "=", "buf", "\n", "\n", "return", "agent_info", ",", "attack_event", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.__del__": [[481, 483], ["c_lib._LIB.env_delete_game"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "_LIB", ".", "env_delete_game", "(", "self", ".", "game", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.set_goal": [[485, 491], ["c_lib._LIB.gridworld_set_goal"], "methods", ["None"], ["", "def", "set_goal", "(", "self", ",", "handle", ",", "method", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" deprecated \"\"\"", "\n", "if", "method", "==", "\"random\"", ":", "\n", "            ", "_LIB", ".", "gridworld_set_goal", "(", "self", ".", "game", ",", "handle", ",", "b\"random\"", ",", "0", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._serialize_event_exp": [[493, 566], ["gridworld.GridWorld._serialize_event_exp.collect_agent_symbol"], "methods", ["None"], ["", "", "def", "_serialize_event_exp", "(", "self", ",", "config", ")", ":", "\n", "        ", "\"\"\"serialize event expression and sent them to game engine\"\"\"", "\n", "game", "=", "self", ".", "game", "\n", "\n", "# collect agent symbol", "\n", "symbol2int", "=", "{", "}", "\n", "config", ".", "symbol_ct", "=", "0", "\n", "\n", "def", "collect_agent_symbol", "(", "node", ",", "config", ")", ":", "\n", "            ", "for", "item", "in", "node", ".", "inputs", ":", "\n", "                ", "if", "isinstance", "(", "item", ",", "EventNode", ")", ":", "\n", "                    ", "collect_agent_symbol", "(", "item", ",", "config", ")", "\n", "", "elif", "isinstance", "(", "item", ",", "AgentSymbol", ")", ":", "\n", "                    ", "if", "item", "not", "in", "symbol2int", ":", "\n", "                        ", "symbol2int", "[", "item", "]", "=", "config", ".", "symbol_ct", "\n", "config", ".", "symbol_ct", "+=", "1", "\n", "\n", "", "", "", "", "for", "rule", "in", "config", ".", "reward_rules", ":", "\n", "            ", "on", "=", "rule", "[", "0", "]", "\n", "receiver", "=", "rule", "[", "1", "]", "\n", "for", "symbol", "in", "receiver", ":", "\n", "                ", "if", "symbol", "not", "in", "symbol2int", ":", "\n", "                    ", "symbol2int", "[", "symbol", "]", "=", "config", ".", "symbol_ct", "\n", "config", ".", "symbol_ct", "+=", "1", "\n", "", "", "collect_agent_symbol", "(", "on", ",", "config", ")", "\n", "\n", "# collect event node", "\n", "", "event2int", "=", "{", "}", "\n", "config", ".", "node_ct", "=", "0", "\n", "\n", "def", "collect_event_node", "(", "node", ",", "config", ")", ":", "\n", "            ", "if", "node", "not", "in", "event2int", ":", "\n", "                ", "event2int", "[", "node", "]", "=", "config", ".", "node_ct", "\n", "config", ".", "node_ct", "+=", "1", "\n", "", "for", "item", "in", "node", ".", "inputs", ":", "\n", "                ", "if", "isinstance", "(", "item", ",", "EventNode", ")", ":", "\n", "                    ", "collect_event_node", "(", "item", ",", "config", ")", "\n", "\n", "", "", "", "for", "rule", "in", "config", ".", "reward_rules", ":", "\n", "            ", "collect_event_node", "(", "rule", "[", "0", "]", ",", "config", ")", "\n", "\n", "# send to C++ engine", "\n", "", "for", "sym", "in", "symbol2int", ":", "\n", "            ", "no", "=", "symbol2int", "[", "sym", "]", "\n", "_LIB", ".", "gridworld_define_agent_symbol", "(", "game", ",", "no", ",", "sym", ".", "group", ",", "sym", ".", "index", ")", "\n", "\n", "", "for", "event", "in", "event2int", ":", "\n", "            ", "no", "=", "event2int", "[", "event", "]", "\n", "inputs", "=", "np", ".", "zeros_like", "(", "event", ".", "inputs", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "event", ".", "inputs", ")", ":", "\n", "                ", "if", "isinstance", "(", "item", ",", "EventNode", ")", ":", "\n", "                    ", "inputs", "[", "i", "]", "=", "event2int", "[", "item", "]", "\n", "", "elif", "isinstance", "(", "item", ",", "AgentSymbol", ")", ":", "\n", "                    ", "inputs", "[", "i", "]", "=", "symbol2int", "[", "item", "]", "\n", "", "else", ":", "\n", "                    ", "inputs", "[", "i", "]", "=", "item", "\n", "", "", "n_inputs", "=", "len", "(", "inputs", ")", "\n", "_LIB", ".", "gridworld_define_event_node", "(", "game", ",", "no", ",", "event", ".", "op", ",", "as_int32_c_array", "(", "inputs", ")", ",", "n_inputs", ")", "\n", "\n", "", "for", "rule", "in", "config", ".", "reward_rules", ":", "\n", "# rule = [on, receiver, value, terminal]", "\n", "            ", "on", "=", "event2int", "[", "rule", "[", "0", "]", "]", "\n", "\n", "receiver", "=", "np", ".", "zeros_like", "(", "rule", "[", "1", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "rule", "[", "1", "]", ")", ":", "\n", "                ", "receiver", "[", "i", "]", "=", "symbol2int", "[", "item", "]", "\n", "", "if", "len", "(", "rule", "[", "2", "]", ")", "==", "1", "and", "rule", "[", "2", "]", "[", "0", "]", "==", "'auto'", ":", "\n", "                ", "value", "=", "np", ".", "zeros", "(", "receiver", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "                ", "value", "=", "np", ".", "array", "(", "rule", "[", "2", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "n_receiver", "=", "len", "(", "receiver", ")", "\n", "_LIB", ".", "gridworld_add_reward_rule", "(", "game", ",", "on", ",", "as_int32_c_array", "(", "receiver", ")", ",", "\n", "as_float_c_array", "(", "value", ")", ",", "n_receiver", ",", "rule", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.EventNode.__init__": [[588, 595], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# for non-leaf node", "\n", "        ", "self", ".", "op", "=", "None", "\n", "# for leaf node", "\n", "self", ".", "predicate", "=", "None", "\n", "\n", "self", ".", "inputs", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.EventNode.__call__": [[596, 633], ["gridworld.EventNode", "min", "min", "max", "max", "Exception"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "subject", ",", "predicate", ",", "*", "args", ")", ":", "\n", "        ", "node", "=", "EventNode", "(", ")", "\n", "node", ".", "predicate", "=", "predicate", "\n", "if", "predicate", "==", "'kill'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_KILL", "\n", "node", ".", "inputs", "=", "[", "subject", ",", "args", "[", "0", "]", "]", "\n", "", "elif", "predicate", "==", "'at'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_AT", "\n", "coor", "=", "args", "[", "0", "]", "\n", "node", ".", "inputs", "=", "[", "subject", ",", "coor", "[", "0", "]", ",", "coor", "[", "1", "]", "]", "\n", "", "elif", "predicate", "==", "'in'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_IN", "\n", "coor", "=", "args", "[", "0", "]", "\n", "x1", ",", "y1", "=", "min", "(", "coor", "[", "0", "]", "[", "0", "]", ",", "coor", "[", "1", "]", "[", "0", "]", ")", ",", "min", "(", "coor", "[", "0", "]", "[", "1", "]", ",", "coor", "[", "1", "]", "[", "1", "]", ")", "\n", "x2", ",", "y2", "=", "max", "(", "coor", "[", "0", "]", "[", "0", "]", ",", "coor", "[", "1", "]", "[", "0", "]", ")", ",", "max", "(", "coor", "[", "0", "]", "[", "1", "]", ",", "coor", "[", "1", "]", "[", "1", "]", ")", "\n", "node", ".", "inputs", "=", "[", "subject", ",", "x1", ",", "y1", ",", "x2", ",", "y2", "]", "\n", "", "elif", "predicate", "==", "'attack'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_ATTACK", "\n", "node", ".", "inputs", "=", "[", "subject", ",", "args", "[", "0", "]", "]", "\n", "", "elif", "predicate", "==", "'kill'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_KILL", "\n", "node", ".", "inputs", "=", "[", "subject", ",", "args", "[", "0", "]", "]", "\n", "", "elif", "predicate", "==", "'collide'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_COLLIDE", "\n", "node", ".", "inputs", "=", "[", "subject", ",", "args", "[", "0", "]", "]", "\n", "", "elif", "predicate", "==", "'die'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_DIE", "\n", "node", ".", "inputs", "=", "[", "subject", "]", "\n", "", "elif", "predicate", "==", "'in_a_line'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_IN_A_LINE", "\n", "node", ".", "inputs", "=", "[", "subject", "]", "\n", "", "elif", "predicate", "==", "'align'", ":", "\n", "            ", "node", ".", "op", "=", "EventNode", ".", "OP_ALIGN", "\n", "node", ".", "inputs", "=", "[", "subject", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid predicate of event \"", "+", "predicate", ")", "\n", "", "return", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.EventNode.__and__": [[634, 639], ["gridworld.EventNode"], "methods", ["None"], ["", "def", "__and__", "(", "self", ",", "other", ")", ":", "\n", "        ", "node", "=", "EventNode", "(", ")", "\n", "node", ".", "op", "=", "EventNode", ".", "OP_AND", "\n", "node", ".", "inputs", "=", "[", "self", ",", "other", "]", "\n", "return", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.EventNode.__or__": [[640, 645], ["gridworld.EventNode"], "methods", ["None"], ["", "def", "__or__", "(", "self", ",", "other", ")", ":", "\n", "        ", "node", "=", "EventNode", "(", ")", "\n", "node", ".", "op", "=", "EventNode", ".", "OP_OR", "\n", "node", ".", "inputs", "=", "[", "self", ",", "other", "]", "\n", "return", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.EventNode.__invert__": [[646, 651], ["gridworld.EventNode"], "methods", ["None"], ["", "def", "__invert__", "(", "self", ")", ":", "\n", "        ", "node", "=", "EventNode", "(", ")", "\n", "node", ".", "op", "=", "EventNode", ".", "OP_NOT", "\n", "node", ".", "inputs", "=", "[", "self", "]", "\n", "return", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.AgentSymbol.__init__": [[656, 673], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "group", ",", "index", ")", ":", "\n", "        ", "\"\"\" define a agent symbol, it can be the object or subject of EventNode\n\n        group: group handle\n            it is the return value of cfg.add_group()\n        index: int or str\n            int: a deterministic integer id\n            str: can be 'all' or 'any', represents all or any agents in a group\n        \"\"\"", "\n", "self", ".", "group", "=", "group", "if", "group", "is", "not", "None", "else", "-", "1", "\n", "if", "index", "==", "'any'", ":", "\n", "            ", "self", ".", "index", "=", "-", "1", "\n", "", "elif", "index", "==", "'all'", ":", "\n", "            ", "self", ".", "index", "=", "-", "2", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "index", ",", "int", ")", ",", "\"index must be a deterministic int\"", "\n", "self", ".", "index", "=", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.AgentSymbol.__str__": [[674, 676], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'agent(%d,%d)'", "%", "(", "self", ".", "group", ",", "self", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.__init__": [[680, 685], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_dict", "=", "{", "}", "\n", "self", ".", "agent_type_dict", "=", "{", "}", "\n", "self", ".", "groups", "=", "[", "]", "\n", "self", ".", "reward_rules", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set": [[686, 696], ["None"], "methods", ["None"], ["", "def", "set", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\" set parameters of global configuration\n\n        Parameters\n        ----------\n        args : dict\n            key value pair of the configuration\n        \"\"\"", "\n", "for", "key", "in", "args", ":", "\n", "            ", "self", ".", "config_dict", "[", "key", "]", "=", "args", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type": [[697, 729], ["Exception"], "methods", ["None"], ["", "", "def", "register_agent_type", "(", "self", ",", "name", ",", "attr", ")", ":", "\n", "        ", "\"\"\" register an agent type\n\n        Parameters\n        ----------\n        name : str\n            name of the type (should be unique)\n        attr: dict\n            key value pair of the agent type\n            see notes below to know the available attributes\n\n        Notes\n        -----\n        height: int, height of agent body\n        width:  int, width of agent body\n        speed:  float, maximum speed, i.e. the radius of move circle of the agent\n        hp:     float, maximum health point of the agent\n        view_range: gw.CircleRange or gw.SectorRange\n\n        damage: float, attack damage\n        step_recover: float, step recover of health point (can be negative)\n        kill_supply: float, the hp gain when kill this type of agents\n\n        step_reward: float, reward get in every step\n        kill_reward: float, reward gain when kill this type of agent\n        dead_penalty: float, reward get when dead\n        attack_penalty: float, reward get when perform an attack (this is used to make agents do not attack blank grid)\n        \"\"\"", "\n", "if", "name", "in", "self", ".", "agent_type_dict", ":", "\n", "            ", "raise", "Exception", "(", "\"type name %s already exists\"", "%", "name", ")", "\n", "", "self", ".", "agent_type_dict", "[", "name", "]", "=", "attr", "\n", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group": [[730, 741], ["len", "gridworld.Config.groups.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "add_group", "(", "self", ",", "agent_type", ")", ":", "\n", "        ", "\"\"\" add a group to the configuration\n\n        Returns\n        -------\n        group_handle : int\n            a handle for the new added group\n        \"\"\"", "\n", "no", "=", "len", "(", "self", ".", "groups", ")", "\n", "self", ".", "groups", ".", "append", "(", "agent_type", ")", "\n", "return", "no", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule": [[742, 767], ["gridworld.Config.reward_rules.append", "len", "len", "Exception", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "add_reward_rule", "(", "self", ",", "on", ",", "receiver", ",", "value", ",", "terminal", "=", "False", ")", ":", "\n", "        ", "\"\"\" add a reward rule\n\n        Some note:\n        1. if the receiver is not a deterministic agent,\n           it must be one of the agents involved in the triggering event\n\n        Parameters\n        ----------\n        on: Expr\n            a bool expression of the trigger event\n        receiver:  (list of) AgentSymbol\n            receiver of this reward rule\n        value: (list of) float\n            value to assign\n        terminal: bool\n            whether this event will terminate the game\n        \"\"\"", "\n", "if", "not", "(", "isinstance", "(", "receiver", ",", "tuple", ")", "or", "isinstance", "(", "receiver", ",", "list", ")", ")", ":", "\n", "            ", "assert", "not", "(", "isinstance", "(", "value", ",", "tuple", ")", "or", "isinstance", "(", "value", ",", "tuple", ")", ")", "\n", "receiver", "=", "[", "receiver", "]", "\n", "value", "=", "[", "value", "]", "\n", "", "if", "len", "(", "receiver", ")", "!=", "len", "(", "value", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"the length of receiver and value should be equal\"", ")", "\n", "", "self", ".", "reward_rules", ".", "append", "(", "[", "on", ",", "receiver", ",", "value", ",", "terminal", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.CircleRange.__init__": [[770, 779], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "radius", ")", ":", "\n", "        ", "\"\"\" define a circle range for attack or view\n\n        Parameters\n        ----------\n        radius : float\n        \"\"\"", "\n", "self", ".", "radius", "=", "radius", "\n", "self", ".", "angle", "=", "360", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.CircleRange.__str__": [[780, 782], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'circle(%g)'", "%", "self", ".", "radius", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.SectorRange.__init__": [[785, 798], ["Exception"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "radius", ",", "angle", ")", ":", "\n", "        ", "\"\"\" define a sector range for attack or view\n\n        Parameters\n        ----------\n        radius : float\n        angle :  float\n            angle should be less than 180\n        \"\"\"", "\n", "self", ".", "radius", "=", "radius", "\n", "self", ".", "angle", "=", "angle", "\n", "if", "self", ".", "angle", ">=", "180", ":", "\n", "            ", "raise", "Exception", "(", "\"the angle of a sector should be smaller than 180 degree\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.SectorRange.__str__": [[799, 801], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'sector(%g, %g)'", "%", "(", "self", ".", "radius", ",", "self", ".", "angle", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.__init__": [[6, 8], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.reset": [[9, 11], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_observation": [[13, 15], ["None"], "methods", ["None"], ["", "def", "get_observation", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.set_action": [[16, 18], ["None"], "methods", ["None"], ["", "def", "set_action", "(", "self", ",", "handle", ",", "actions", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.step": [[19, 21], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render": [[22, 24], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render_next_file": [[25, 27], ["None"], "methods", ["None"], ["", "def", "render_next_file", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_reward": [[28, 30], ["None"], "methods", ["None"], ["", "def", "get_reward", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num": [[32, 34], ["None"], "methods", ["None"], ["", "def", "get_num", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space": [[35, 37], ["None"], "methods", ["None"], ["", "def", "get_action_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space": [[38, 40], ["None"], "methods", ["None"], ["", "def", "get_view_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space": [[41, 43], ["None"], "methods", ["None"], ["", "def", "get_feature_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.renderer.base_renderer.BaseRenderer.__init__": [[7, 9], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.renderer.base_renderer.BaseRenderer.start": [[10, 13], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "start", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.renderer.pygame_renderer.PyGameRenderer.__init__": [[14, 16], ["magent.renderer.base_renderer.BaseRenderer.__init__"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PyGameRenderer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.renderer.pygame_renderer.PyGameRenderer.start": [[17, 385], ["pygame.init", "pygame.display.init", "pygame.time.Clock", "pygame.display.set_caption", "pygame.font.SysFont", "pygame.font.SysFont", "pygame.font.SysFont", "server.get_info", "numpy.zeros", "pygame.Color", "pygame.draw.line", "pygame.draw.rect", "map", "map", "map", "isinstance", "BaseException", "pygame.display.Info", "pygame.display.set_mode", "pygame.display.set_mode", "server.get_status", "pygame.mouse.get_pos", "int", "int", "pygame.event.get", "pygame.key.get_pressed", "pygame.display.set_mode.fill", "pygame.display.update", "pygame.time.Clock.tick", "pygame.Rect", "min", "min", "min", "min", "pygame.quit", "max", "min", "max", "min", "server.get_data", "pygame.pixelcopy.array_to_surface", "min", "pygame.font.SysFont.render", "pygame.font.SysFont.render", "pygame.font.SysFont.render", "pygame.font.SysFont.render", "pygame.display.set_mode.blit", "pygame.display.set_mode.blit", "pygame.display.set_mode.blit", "pygame.display.set_mode.blit", "server.get_banners", "server.get_endscreen", "int", "int", "int", "int", "round", "round", "round", "round", "max", "max", "max", "max", "round", "round", "round", "round", "pygame.quit", "max", "min", "int", "int", "int", "int", "pygame.pixelcopy.surface_to_array", "pygame_renderer.PyGameRenderer.start.draw_rect"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.get_info", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_status", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_pos", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.update", "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.quit", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_data", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.render", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_banners", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_endscreen", "home.repos.pwc.inspect_result.mlii_mfrl.magent.model.ProcessingModel.quit"], ["", "def", "start", "(", "\n", "self", ",", "\n", "server", ",", "\n", "animation_total", "=", "2", ",", "\n", "animation_stop", "=", "0", ",", "\n", "resolution", "=", "None", ",", "\n", "fps_soft_bound", "=", "60", ",", "\n", "background_rgb", "=", "(", "255", ",", "255", ",", "255", ")", ",", "\n", "attack_line_rgb", "=", "(", "0", ",", "0", ",", "0", ")", ",", "\n", "attack_dot_rgb", "=", "(", "0", ",", "0", ",", "0", ")", ",", "\n", "attack_dot_size", "=", "0.3", ",", "\n", "text_rgb", "=", "(", "0", ",", "0", ",", "0", ")", ",", "\n", "text_size", "=", "16", ",", "\n", "text_spacing", "=", "3", ",", "\n", "banner_size", "=", "32", ",", "\n", "banner_spacing", "=", "3", ",", "\n", "bigscreen_size", "=", "72", ",", "\n", "bigscreen_spacing", "=", "0", ",", "\n", "grid_rgba", "=", "(", "pygame", ".", "Color", "(", "0", ",", "0", ",", "0", ")", ",", "30", ")", ",", "\n", "grid_size", "=", "7.5", ",", "\n", "grid_min_size", "=", "2", ",", "\n", "grid_max_size", "=", "100", ",", "\n", "zoom_rate", "=", "1", "/", "30", ",", "\n", "move_rate", "=", "4", ",", "\n", "full_screen", "=", "False", "\n", ")", ":", "\n", "        ", "def", "draw_line", "(", "surface", ",", "color", ",", "a", ",", "b", ")", ":", "\n", "            ", "pygame", ".", "draw", ".", "line", "(", "\n", "surface", ",", "color", ",", "\n", "(", "int", "(", "round", "(", "a", "[", "0", "]", ")", ")", ",", "int", "(", "round", "(", "a", "[", "1", "]", ")", ")", ")", ",", "\n", "(", "int", "(", "round", "(", "b", "[", "0", "]", ")", ")", ",", "int", "(", "round", "(", "b", "[", "1", "]", ")", ")", ")", "\n", ")", "\n", "\n", "", "def", "draw_rect", "(", "surface", ",", "color", ",", "a", ",", "w", ",", "h", ")", ":", "\n", "            ", "pygame", ".", "draw", ".", "rect", "(", "surface", ",", "color", ",", "pygame", ".", "Rect", "(", "*", "map", "(", "int", ",", "(", "\n", "round", "(", "a", "[", "0", "]", ")", ",", "round", "(", "a", "[", "1", "]", ")", ",", "\n", "round", "(", "w", "+", "a", "[", "0", "]", "-", "round", "(", "a", "[", "0", "]", ")", ")", ",", "\n", "round", "(", "h", "+", "a", "[", "1", "]", "-", "round", "(", "a", "[", "1", "]", ")", ")", ")", ")", ")", ")", "\n", "\n", "", "def", "draw_rect_matrix", "(", "matrix", ",", "color", ",", "a", ",", "w", ",", "h", ",", "resolution", ")", ":", "\n", "            ", "x", ",", "y", ",", "w", ",", "h", "=", "map", "(", "int", ",", "(", "round", "(", "a", "[", "0", "]", ")", ",", "round", "(", "a", "[", "1", "]", ")", ",", "round", "(", "w", "+", "a", "[", "0", "]", "-", "round", "(", "a", "[", "0", "]", ")", ")", ",", "round", "(", "h", "+", "a", "[", "1", "]", "-", "round", "(", "a", "[", "1", "]", ")", ")", ")", ")", "\n", "matrix", "[", "max", "(", "x", ",", "0", ")", ":", "min", "(", "x", "+", "w", ",", "resolution", "[", "0", "]", ")", ",", "max", "(", "y", ",", "0", ")", ":", "min", "(", "h", "+", "y", ",", "resolution", "[", "1", "]", ")", ",", ":", "]", "=", "color", "\n", "\n", "", "def", "draw_line_matrix", "(", "matrix", ",", "color", ",", "a", ",", "b", ",", "resolution", ")", ":", "\n", "            ", "a", "=", "(", "min", "(", "max", "(", "0", ",", "a", "[", "0", "]", ")", ",", "resolution", "[", "0", "]", "-", "1", ")", ",", "min", "(", "max", "(", "0", ",", "a", "[", "1", "]", ")", ",", "resolution", "[", "1", "]", "-", "1", ")", ")", "\n", "b", "=", "(", "min", "(", "max", "(", "0", ",", "b", "[", "0", "]", ")", ",", "resolution", "[", "0", "]", "-", "1", ")", ",", "min", "(", "max", "(", "0", ",", "b", "[", "1", "]", ")", ",", "resolution", "[", "1", "]", "-", "1", ")", ")", "\n", "a", "=", "map", "(", "int", ",", "(", "round", "(", "a", "[", "0", "]", ")", ",", "round", "(", "a", "[", "1", "]", ")", ")", ")", "\n", "b", "=", "map", "(", "int", ",", "(", "round", "(", "b", "[", "0", "]", ")", ",", "round", "(", "b", "[", "1", "]", ")", ")", ")", "\n", "if", "a", "[", "0", "]", "==", "b", "[", "0", "]", ":", "\n", "                ", "if", "a", "[", "1", "]", ">", "b", "[", "1", "]", ":", "\n", "                    ", "matrix", "[", "a", "[", "0", "]", ",", "b", "[", "1", "]", ":", "a", "[", "1", "]", "+", "1", "]", "=", "color", "\n", "", "else", ":", "\n", "                    ", "matrix", "[", "a", "[", "0", "]", ",", "a", "[", "1", "]", ":", "b", "[", "1", "]", "+", "1", "]", "=", "color", "\n", "", "", "elif", "a", "[", "1", "]", "==", "b", "[", "1", "]", ":", "\n", "                ", "if", "a", "[", "0", "]", ">", "b", "[", "0", "]", ":", "\n", "                    ", "matrix", "[", "b", "[", "0", "]", ":", "a", "[", "0", "]", "+", "1", ",", "a", "[", "1", "]", "]", "=", "color", "\n", "", "else", ":", "\n", "                    ", "matrix", "[", "a", "[", "0", "]", ":", "b", "[", "0", "]", "+", "1", ",", "a", "[", "1", "]", "]", "=", "color", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "if", "not", "isinstance", "(", "server", ",", "BaseServer", ")", ":", "\n", "            ", "raise", "BaseException", "(", "'property server must be an instance of BaseServer'", ")", "\n", "\n", "", "pygame", ".", "init", "(", ")", "\n", "pygame", ".", "display", ".", "init", "(", ")", "\n", "\n", "if", "resolution", "is", "None", ":", "\n", "            ", "info", "=", "pygame", ".", "display", ".", "Info", "(", ")", "\n", "resolution", "=", "info", ".", "current_w", ",", "info", ".", "current_h", "\n", "\n", "", "clock", "=", "pygame", ".", "time", ".", "Clock", "(", ")", "\n", "\n", "if", "full_screen", ":", "\n", "            ", "canvas", "=", "pygame", ".", "display", ".", "set_mode", "(", "resolution", ",", "pygame", ".", "DOUBLEBUF", "|", "pygame", ".", "FULLSCREEN", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "canvas", "=", "pygame", ".", "display", ".", "set_mode", "(", "resolution", ",", "pygame", ".", "DOUBLEBUF", ",", "0", ")", "\n", "\n", "", "pygame", ".", "display", ".", "set_caption", "(", "'MAgent Renderer Window'", ")", "\n", "text_formatter", "=", "pygame", ".", "font", ".", "SysFont", "(", "None", ",", "text_size", ",", "True", ")", "\n", "banner_formatter", "=", "pygame", ".", "font", ".", "SysFont", "(", "None", ",", "banner_size", ",", "True", ")", "\n", "bigscreen_formatter", "=", "pygame", ".", "font", ".", "SysFont", "(", "None", ",", "bigscreen_size", ",", "True", ")", "\n", "\n", "map_size", ",", "groups", ",", "static_info", "=", "server", ".", "get_info", "(", ")", "\n", "view_position", "=", "[", "map_size", "[", "0", "]", "/", "2", "*", "grid_size", "-", "resolution", "[", "0", "]", "/", "2", ",", "\n", "map_size", "[", "1", "]", "/", "2", "*", "grid_size", "-", "resolution", "[", "1", "]", "/", "2", "]", "\n", "frame_id", "=", "0", "\n", "\n", "walls", "=", "static_info", "[", "'wall'", "]", "\n", "\n", "old_data", "=", "None", "\n", "new_data", "=", "None", "\n", "\n", "need_static_update", "=", "True", "\n", "#show_grid = False", "\n", "animation_progress", "=", "0", "\n", "\n", "grid_map", "=", "np", ".", "zeros", "(", "(", "resolution", "[", "0", "]", ",", "resolution", "[", "1", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "done", "=", "False", "\n", "status", "=", "server", ".", "get_status", "(", "frame_id", ")", "\n", "triggered", "=", "False", "\n", "# calculate the relative moues coordinates in the gridworld", "\n", "mouse_x", ",", "mouse_y", "=", "pygame", ".", "mouse", ".", "get_pos", "(", ")", "\n", "mouse_x", "=", "int", "(", "(", "mouse_x", "+", "view_position", "[", "0", "]", ")", "/", "grid_size", ")", "\n", "mouse_y", "=", "int", "(", "(", "mouse_y", "+", "view_position", "[", "1", "]", ")", "/", "grid_size", ")", "\n", "for", "event", "in", "pygame", ".", "event", ".", "get", "(", ")", ":", "\n", "                ", "if", "event", ".", "type", "==", "pygame", ".", "QUIT", ":", "\n", "                    ", "pygame", ".", "quit", "(", ")", "\n", "done", "=", "True", "\n", "", "elif", "event", ".", "type", "==", "pygame", ".", "KEYDOWN", ":", "\n", "#if event.key == pygame.K_g:", "\n", "#    show_grid = not show_grid", "\n", "#else:", "\n", "#    triggered = server.keydown(frame_id, event.key, mouse_x, mouse_y)", "\n", "                    ", "triggered", "=", "server", ".", "keydown", "(", "frame_id", ",", "event", ".", "key", ",", "mouse_x", ",", "mouse_y", ")", "\n", "", "elif", "event", ".", "type", "==", "pygame", ".", "MOUSEBUTTONDOWN", ":", "\n", "                    ", "if", "event", ".", "button", "==", "4", "or", "event", ".", "button", "==", "5", ":", "\n", "                        ", "center_before", "=", "(", "\n", "(", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", "/", "2", ")", "/", "grid_size", ",", "\n", "(", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", "/", "2", ")", "/", "grid_size", "\n", ")", "\n", "if", "event", ".", "button", "==", "5", ":", "\n", "                            ", "grid_size", "=", "max", "(", "grid_size", "-", "grid_size", "*", "zoom_rate", ",", "grid_min_size", ")", "\n", "need_static_update", "=", "True", "\n", "", "else", ":", "\n", "                            ", "grid_size", "=", "min", "(", "grid_size", "+", "grid_size", "*", "zoom_rate", ",", "grid_max_size", ")", "\n", "need_static_update", "=", "True", "\n", "", "center_after", "=", "(", "\n", "(", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", "/", "2", ")", "/", "grid_size", ",", "\n", "(", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", "/", "2", ")", "/", "grid_size", "\n", ")", "\n", "view_position", "[", "0", "]", "+=", "(", "center_before", "[", "0", "]", "-", "center_after", "[", "0", "]", ")", "*", "grid_size", "\n", "view_position", "[", "1", "]", "+=", "(", "center_before", "[", "1", "]", "-", "center_after", "[", "1", "]", ")", "*", "grid_size", "\n", "", "else", ":", "\n", "                        ", "triggered", "=", "server", ".", "mousedown", "(", "frame_id", ",", "pygame", ".", "mouse", ".", "get_pressed", "(", ")", ",", "mouse_x", ",", "mouse_y", ")", "\n", "\n", "", "", "", "pressed", "=", "pygame", ".", "key", ".", "get_pressed", "(", ")", "\n", "if", "pressed", "[", "pygame", ".", "K_ESCAPE", "]", ":", "\n", "                ", "pygame", ".", "quit", "(", ")", "\n", "done", "=", "True", "\n", "\n", "", "if", "pressed", "[", "pygame", ".", "K_COMMA", "]", "or", "pressed", "[", "pygame", ".", "K_PERIOD", "]", ":", "\n", "# center before means the center before zoom operation", "\n", "# center after means the center after zoom operation", "\n", "# we need to keep that the above two are consistent during zoom operation", "\n", "# and hence we need to adjust view_position simultaneously", "\n", "                ", "center_before", "=", "(", "\n", "(", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", "/", "2", ")", "/", "grid_size", ",", "\n", "(", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", "/", "2", ")", "/", "grid_size", "\n", ")", "\n", "if", "pressed", "[", "pygame", ".", "K_COMMA", "]", ":", "\n", "                    ", "grid_size", "=", "max", "(", "grid_size", "-", "grid_size", "*", "zoom_rate", ",", "grid_min_size", ")", "\n", "need_static_update", "=", "True", "\n", "", "else", ":", "\n", "                    ", "grid_size", "=", "min", "(", "grid_size", "+", "grid_size", "*", "zoom_rate", ",", "grid_max_size", ")", "\n", "need_static_update", "=", "True", "\n", "", "center_after", "=", "(", "\n", "(", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", "/", "2", ")", "/", "grid_size", ",", "\n", "(", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", "/", "2", ")", "/", "grid_size", "\n", ")", "\n", "view_position", "[", "0", "]", "+=", "(", "center_before", "[", "0", "]", "-", "center_after", "[", "0", "]", ")", "*", "grid_size", "\n", "view_position", "[", "1", "]", "+=", "(", "center_before", "[", "1", "]", "-", "center_after", "[", "1", "]", ")", "*", "grid_size", "\n", "\n", "", "if", "pressed", "[", "pygame", ".", "K_LEFT", "]", ":", "\n", "                ", "view_position", "[", "0", "]", "-=", "move_rate", "*", "grid_size", "\n", "need_static_update", "=", "True", "\n", "", "if", "pressed", "[", "pygame", ".", "K_RIGHT", "]", ":", "\n", "                ", "view_position", "[", "0", "]", "+=", "move_rate", "*", "grid_size", "\n", "need_static_update", "=", "True", "\n", "", "if", "pressed", "[", "pygame", ".", "K_UP", "]", ":", "\n", "                ", "view_position", "[", "1", "]", "-=", "move_rate", "*", "grid_size", "\n", "need_static_update", "=", "True", "\n", "", "if", "pressed", "[", "pygame", ".", "K_DOWN", "]", ":", "\n", "                ", "view_position", "[", "1", "]", "+=", "move_rate", "*", "grid_size", "\n", "need_static_update", "=", "True", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "# x_range: which vertical gridlines should be shown on the display", "\n", "# y_range: which horizontal gridlines should be shown on the display", "\n", "", "x_range", "=", "(", "\n", "max", "(", "0", ",", "int", "(", "math", ".", "floor", "(", "max", "(", "0", ",", "view_position", "[", "0", "]", ")", "/", "grid_size", ")", ")", ")", ",", "\n", "min", "(", "map_size", "[", "0", "]", ",", "int", "(", "math", ".", "ceil", "(", "max", "(", "0", ",", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", ")", "/", "grid_size", ")", ")", ")", "\n", ")", "\n", "\n", "y_range", "=", "(", "\n", "max", "(", "0", ",", "int", "(", "math", ".", "floor", "(", "max", "(", "0", ",", "view_position", "[", "1", "]", ")", "/", "grid_size", ")", ")", ")", ",", "\n", "min", "(", "map_size", "[", "1", "]", ",", "int", "(", "math", ".", "ceil", "(", "max", "(", "0", ",", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", ")", "/", "grid_size", ")", ")", ")", "\n", ")", "\n", "\n", "canvas", ".", "fill", "(", "background_rgb", ")", "\n", "\n", "#if show_grid:", "\n", "#    if need_static_update or True:", "\n", "#        grids = pygame.Surface(resolution)", "\n", "#        grids.set_alpha(grid_rgba[1])", "\n", "#        grids.fill(background_rgb)", "\n", "#", "\n", "#        for i in range(x_range[0], x_range[1] + 1):", "\n", "#            draw_line(", "\n", "#                canvas, grid_rgba[0],", "\n", "#                (i * grid_size - view_position[0], max(0, view_position[1]) - view_position[1]),", "\n", "#                (", "\n", "#                    i * grid_size - view_position[0],", "\n", "#                    min(view_position[1] + resolution[1], map_size[1] * grid_size) - view_position[1]", "\n", "#                )", "\n", "#            )", "\n", "#        for i in range(y_range[0], y_range[1] + 1):", "\n", "#            draw_line(", "\n", "#                canvas, grid_rgba[0],", "\n", "#                (max(0, view_position[0]) - view_position[0], i * grid_size - view_position[1]),", "\n", "#                (", "\n", "#                    min(view_position[0] + resolution[0], map_size[0] * grid_size) - view_position[0],", "\n", "#                    i * grid_size - view_position[1]", "\n", "#                )", "\n", "#            )", "\n", "\n", "if", "new_data", "is", "None", "or", "animation_progress", ">", "animation_total", "+", "animation_stop", ":", "\n", "                ", "buffered_new_data", "=", "server", ".", "get_data", "(", "\n", "frame_id", ",", "\n", "(", "view_position", "[", "0", "]", "/", "grid_size", ",", "(", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", ")", "/", "grid_size", ")", ",", "\n", "(", "view_position", "[", "1", "]", "/", "grid_size", ",", "(", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", ")", "/", "grid_size", ")", "\n", ")", "\n", "if", "buffered_new_data", "is", "None", ":", "\n", "                    ", "buffered_new_data", "=", "new_data", "\n", "", "old_data", "=", "new_data", "\n", "new_data", "=", "buffered_new_data", "\n", "frame_id", "+=", "1", "\n", "animation_progress", "=", "0", "\n", "\n", "", "if", "new_data", "is", "not", "None", ":", "\n", "                ", "if", "old_data", "is", "None", "and", "animation_progress", "==", "0", ":", "\n", "                    ", "animation_progress", "=", "animation_total", "\n", "\n", "", "if", "need_static_update", ":", "\n", "                    ", "pygame", ".", "pixelcopy", ".", "surface_to_array", "(", "grid_map", ",", "canvas", ")", "\n", "for", "wall", "in", "walls", ":", "\n", "                        ", "x", ",", "y", "=", "wall", "[", "0", "]", ",", "wall", "[", "1", "]", "\n", "if", "x", ">=", "x_range", "[", "0", "]", "and", "x", "<=", "x_range", "[", "1", "]", "and", "y", ">=", "y_range", "[", "0", "]", "and", "y", "<=", "y_range", "[", "1", "]", ":", "\n", "                            ", "draw_rect_matrix", "(", "grid_map", ",", "(", "127", ",", "127", ",", "127", ")", ",", "\n", "(", "x", "*", "grid_size", "-", "view_position", "[", "0", "]", ",", "y", "*", "grid_size", "-", "view_position", "[", "1", "]", ")", ",", "\n", "grid_size", ",", "grid_size", ",", "resolution", ")", "\n", "", "", "", "pygame", ".", "pixelcopy", ".", "array_to_surface", "(", "canvas", ",", "grid_map", ")", "\n", "\n", "rate", "=", "min", "(", "1.0", ",", "animation_progress", "/", "animation_total", ")", "\n", "for", "key", "in", "new_data", "[", "0", "]", ":", "\n", "                    ", "new_prop", "=", "new_data", "[", "0", "]", "[", "key", "]", "\n", "old_prop", "=", "old_data", "[", "0", "]", "[", "key", "]", "if", "old_data", "is", "not", "None", "and", "key", "in", "old_data", "[", "0", "]", "else", "None", "\n", "new_group", "=", "groups", "[", "new_prop", "[", "2", "]", "]", "\n", "old_group", "=", "groups", "[", "old_prop", "[", "2", "]", "]", "if", "old_prop", "is", "not", "None", "else", "None", "\n", "now_prop", "=", "[", "a", "*", "(", "1", "-", "rate", ")", "+", "b", "*", "rate", "for", "a", ",", "b", "in", "\n", "zip", "(", "old_prop", ",", "new_prop", ")", "]", "if", "old_prop", "is", "not", "None", "else", "new_prop", "\n", "now_group", "=", "[", "a", "*", "(", "1", "-", "rate", ")", "+", "b", "*", "rate", "for", "a", ",", "b", "in", "\n", "zip", "(", "old_group", ",", "new_group", ")", "]", "if", "old_group", "is", "not", "None", "else", "new_group", "\n", "\n", "draw_rect", "(", "\n", "canvas", ",", "(", "int", "(", "now_group", "[", "2", "]", ")", ",", "int", "(", "now_group", "[", "3", "]", ")", ",", "int", "(", "now_group", "[", "4", "]", ")", ")", ",", "\n", "(", "\n", "now_prop", "[", "0", "]", "*", "grid_size", "-", "view_position", "[", "0", "]", ",", "\n", "now_prop", "[", "1", "]", "*", "grid_size", "-", "view_position", "[", "1", "]", "\n", ")", ",", "\n", "now_group", "[", "0", "]", "*", "grid_size", ",", "\n", "now_group", "[", "1", "]", "*", "grid_size", "\n", ")", "\n", "\n", "", "for", "key", ",", "event_x", ",", "event_y", "in", "new_data", "[", "1", "]", ":", "\n", "                    ", "if", "not", "key", "in", "new_data", "[", "0", "]", ":", "\n", "                        ", "continue", "\n", "", "new_prop", "=", "new_data", "[", "0", "]", "[", "key", "]", "\n", "old_prop", "=", "old_data", "[", "0", "]", "[", "key", "]", "if", "old_data", "is", "not", "None", "and", "key", "in", "old_data", "[", "0", "]", "else", "None", "\n", "new_group", "=", "groups", "[", "new_prop", "[", "2", "]", "]", "\n", "old_group", "=", "groups", "[", "old_prop", "[", "2", "]", "]", "if", "old_prop", "is", "not", "None", "else", "None", "\n", "now_prop", "=", "[", "a", "*", "(", "1", "-", "rate", ")", "+", "b", "*", "rate", "for", "a", ",", "b", "in", "\n", "zip", "(", "old_prop", ",", "new_prop", ")", "]", "if", "old_prop", "is", "not", "None", "else", "new_prop", "\n", "now_group", "=", "[", "a", "*", "(", "1", "-", "rate", ")", "+", "b", "*", "rate", "for", "a", ",", "b", "in", "\n", "zip", "(", "old_group", ",", "new_group", ")", "]", "if", "old_group", "is", "not", "None", "else", "new_group", "\n", "draw_line", "(", "\n", "canvas", ",", "attack_line_rgb", ",", "\n", "(", "\n", "now_prop", "[", "0", "]", "*", "grid_size", "-", "view_position", "[", "0", "]", "+", "now_group", "[", "0", "]", "/", "2", "*", "grid_size", ",", "\n", "now_prop", "[", "1", "]", "*", "grid_size", "-", "view_position", "[", "1", "]", "+", "now_group", "[", "1", "]", "/", "2", "*", "grid_size", "\n", ")", ",", "\n", "(", "\n", "event_x", "*", "grid_size", "-", "view_position", "[", "0", "]", "+", "grid_size", "/", "2", ",", "\n", "event_y", "*", "grid_size", "-", "view_position", "[", "1", "]", "+", "grid_size", "/", "2", "\n", ")", "\n", ")", "\n", "draw_rect", "(", "\n", "canvas", ",", "attack_dot_rgb", ",", "\n", "(", "\n", "event_x", "*", "grid_size", "-", "view_position", "[", "0", "]", "+", "grid_size", "/", "2", "-", "attack_dot_size", "*", "grid_size", "/", "2", ",", "\n", "event_y", "*", "grid_size", "-", "view_position", "[", "1", "]", "+", "grid_size", "/", "2", "-", "attack_dot_size", "*", "grid_size", "/", "2", ",", "\n", ")", ",", "\n", "attack_dot_size", "*", "grid_size", ",", "\n", "attack_dot_size", "*", "grid_size", "\n", ")", "\n", "\n", "", "if", "status", "or", "triggered", "or", "animation_progress", "<", "animation_total", "+", "animation_stop", ":", "\n", "                    ", "animation_progress", "+=", "1", "\n", "\n", "", "text_fps", "=", "text_formatter", ".", "render", "(", "'FPS: {}'", ".", "format", "(", "int", "(", "clock", ".", "get_fps", "(", ")", ")", ")", ",", "True", ",", "text_rgb", ")", "\n", "text_window", "=", "text_formatter", ".", "render", "(", "\n", "'Window: (%.1f, %.1f, %.1f, %.1f)'", "%", "(", "\n", "view_position", "[", "0", "]", ",", "view_position", "[", "1", "]", ",", "\n", "view_position", "[", "0", "]", "+", "resolution", "[", "0", "]", ",", "\n", "view_position", "[", "1", "]", "+", "resolution", "[", "1", "]", "\n", ")", ",", "True", ",", "text_rgb", "\n", ")", "\n", "\n", "text_grids", "=", "text_formatter", ".", "render", "(", "'Numbers: %d'", "%", "len", "(", "new_data", "[", "0", "]", ")", ",", "True", ",", "text_rgb", ")", "\n", "text_mouse", "=", "text_formatter", ".", "render", "(", "'Mouse: (%d, %d)'", "%", "(", "mouse_x", ",", "mouse_y", ")", ",", "True", ",", "text_rgb", ")", "\n", "\n", "canvas", ".", "blit", "(", "text_fps", ",", "(", "0", ",", "0", ")", ")", "\n", "canvas", ".", "blit", "(", "text_window", ",", "(", "0", ",", "(", "text_size", "+", "text_spacing", ")", "/", "1.5", ")", ")", "\n", "canvas", ".", "blit", "(", "text_grids", ",", "(", "0", ",", "(", "text_size", "+", "text_spacing", ")", "/", "1.5", "*", "2", ")", ")", "\n", "canvas", ".", "blit", "(", "text_mouse", ",", "(", "0", ",", "(", "text_size", "+", "text_spacing", ")", "/", "1.5", "*", "3", ")", ")", "\n", "\n", "height_now", "=", "0", "\n", "for", "texts", "in", "server", ".", "get_banners", "(", "frame_id", ",", "resolution", ")", ":", "\n", "                    ", "content", "=", "[", "]", "\n", "width", ",", "height", "=", "0", ",", "0", "\n", "for", "text", "in", "texts", ":", "\n", "                         ", "text", "=", "banner_formatter", ".", "render", "(", "text", "[", "0", "]", ",", "True", ",", "pygame", ".", "Color", "(", "*", "text", "[", "1", "]", ")", ")", "\n", "content", ".", "append", "(", "(", "text", ",", "width", ")", ")", "\n", "width", "+=", "text", ".", "get_width", "(", ")", "\n", "height", "=", "max", "(", "height", ",", "text", ".", "get_height", "(", ")", ")", "\n", "", "start", "=", "(", "resolution", "[", "0", "]", "-", "width", ")", "/", "2.0", "\n", "for", "b", "in", "content", ":", "\n", "                        ", "canvas", ".", "blit", "(", "b", "[", "0", "]", ",", "(", "start", "+", "b", "[", "1", "]", ",", "height_now", ")", ")", "\n", "", "height_now", "+=", "height", "+", "banner_spacing", "\n", "\n", "", "endscreen_texts", "=", "server", ".", "get_endscreen", "(", "frame_id", ")", "\n", "if", "endscreen_texts", ":", "\n", "                    ", "total_height", "=", "0", "\n", "endscreen_contents", "=", "[", "]", "\n", "endscreen", "=", "pygame", ".", "Surface", "(", "resolution", ")", "\n", "endscreen", ".", "set_alpha", "(", "230", ")", "\n", "endscreen", ".", "fill", "(", "background_rgb", ")", "\n", "for", "texts", "in", "endscreen_texts", ":", "\n", "                        ", "content", "=", "[", "]", "\n", "height", "=", "0", "\n", "for", "text", "in", "texts", ":", "\n", "                            ", "text", "=", "bigscreen_formatter", ".", "render", "(", "text", "[", "0", "]", ",", "True", ",", "pygame", ".", "Color", "(", "*", "text", "[", "1", "]", ")", ")", "\n", "content", ".", "append", "(", "[", "text", "]", ")", "\n", "height", "=", "max", "(", "height", ",", "text", ".", "get_height", "(", ")", ")", "\n", "", "total_height", "+=", "height", "+", "bigscreen_spacing", "\n", "endscreen_contents", ".", "append", "(", "content", ")", "\n", "\n", "", "total_height", "-=", "bigscreen_spacing", "\n", "for", "content", "in", "endscreen_contents", ":", "\n", "                        ", "height", ",", "total_width", "=", "0", ",", "0", "\n", "for", "b", "in", "content", ":", "\n", "                            ", "b", ".", "append", "(", "total_width", ")", "\n", "total_width", "+=", "b", "[", "0", "]", ".", "get_width", "(", ")", "\n", "height", "=", "max", "(", "height", ",", "b", "[", "0", "]", ".", "get_height", "(", ")", ")", "\n", "", "width_now", "=", "(", "resolution", "[", "0", "]", "-", "total_width", ")", "/", "2.0", "\n", "for", "b", "in", "content", ":", "\n", "                            ", "endscreen", ".", "blit", "(", "b", "[", "0", "]", ",", "(", "width_now", "+", "b", "[", "1", "]", ",", "resolution", "[", "1", "]", "/", "2.0", "-", "total_height", "+", "height", ")", ")", "\n", "", "height_now", "+=", "height", "+", "bigscreen_spacing", "\n", "", "canvas", ".", "blit", "(", "endscreen", ",", "(", "0", ",", "0", ")", ")", "\n", "", "", "if", "need_static_update", ":", "\n", "                ", "need_static_update", "=", "False", "\n", "\n", "", "pygame", ".", "display", ".", "update", "(", ")", "\n", "clock", ".", "tick", "(", "fps_soft_bound", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_banners": [[250, 252], ["None"], "methods", ["None"], ["    ", "def", "get_banners", "(", "self", ",", "frame_id", ",", "resolution", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.keydown": [[253, 255], ["None"], "methods", ["None"], ["", "def", "keydown", "(", "self", ",", "frame_id", ",", "key", ",", "mouse_x", ",", "mouse_y", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_status": [[256, 261], ["None"], "methods", ["None"], ["", "def", "get_status", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "if", "self", ".", "done", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_endscreen": [[262, 264], ["None"], "methods", ["None"], ["", "", "def", "get_endscreen", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.mousedown": [[265, 267], ["None"], "methods", ["None"], ["", "def", "mousedown", "(", "self", ",", "frame_id", ",", "key", ",", "mouse_x", ",", "mouse_y", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_info": [[268, 272], ["arrange_server.ArrangeServer.env._get_groups_info", "arrange_server.ArrangeServer.env._get_walls_info"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_groups_info", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_walls_info"], ["", "def", "get_info", "(", "self", ")", ":", "\n", "        ", "ret", "=", "self", ".", "env", ".", "_get_groups_info", "(", ")", "\n", "ret", "[", "1", "]", "=", "ret", "[", "0", "]", "\n", "return", "(", "self", ".", "map_size", ",", "self", ".", "map_size", ")", ",", "ret", ",", "{", "'wall'", ":", "self", ".", "env", ".", "_get_walls_info", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.__init__": [[273, 307], ["magent.GridWorld", "magent.utility.FontProvider", "magent.GridWorld.get_handles", "models.append", "models[].load", "magent.GridWorld.reset", "arrange_server.generate_map", "set", "arrange_server.load_config", "magent.builtin.tf_model.DeepQNetwork"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_handles", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.__init__.load", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.reset", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.generate_map", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.load_config"], ["", "def", "__init__", "(", "self", ",", "path", "=", "\"data/arrange_model\"", ",", "messages", "=", "None", ",", "mode", "=", "1", ")", ":", "\n", "# some parameter", "\n", "        ", "map_size", "=", "250", "\n", "eps", "=", "0.15", "\n", "\n", "# init the game", "\n", "env", "=", "magent", ".", "GridWorld", "(", "load_config", "(", "map_size", ")", ")", "\n", "font", "=", "FontProvider", "(", "'data/font_8x8/basic.txt'", ")", "\n", "\n", "handles", "=", "env", ".", "get_handles", "(", ")", "\n", "food_handle", ",", "handles", "=", "handles", "[", "0", "]", ",", "handles", "[", "1", ":", "]", "\n", "models", "=", "[", "]", "\n", "models", ".", "append", "(", "DeepQNetwork", "(", "env", ",", "handles", "[", "0", "]", ",", "'arrange'", ",", "use_conv", "=", "True", ")", ")", "\n", "\n", "# load model", "\n", "models", "[", "0", "]", ".", "load", "(", "path", ",", "10", ")", "\n", "\n", "# init environment", "\n", "env", ".", "reset", "(", ")", "\n", "generate_map", "(", "mode", ",", "env", ",", "map_size", ",", "food_handle", ",", "handles", ",", "messages", ",", "font", ")", "\n", "\n", "# save to member variable", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "food_handle", "=", "food_handle", "\n", "self", ".", "handles", "=", "handles", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "done", "=", "False", "\n", "self", ".", "map_size", "=", "map_size", "\n", "self", ".", "new_rule_ct", "=", "0", "\n", "self", ".", "pos_reward_ct", "=", "set", "(", ")", "\n", "self", ".", "num", "=", "None", "\n", "\n", "self", ".", "ct", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.step": [[308, 347], ["range", "range", "env.step", "env.get_num", "env.get_reward", "zip", "env.clear_dead", "env.get_observation", "env.get_agent_id", "len", "models[].infer_action", "env.set_action", "env.get_num", "arrange_server.ArrangeServer.pos_reward_ct.add", "len"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_reward", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.clear_dead", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_observation", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_agent_id", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.infer_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.set_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "handles", "=", "self", ".", "handles", "\n", "models", "=", "self", ".", "models", "\n", "env", "=", "self", ".", "env", "\n", "\n", "center_x", "=", "self", ".", "map_size", "//", "2", "\n", "center_y", "=", "self", ".", "map_size", "\n", "\n", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "            ", "obs", "=", "[", "env", ".", "get_observation", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "ids", "=", "[", "env", ".", "get_agent_id", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "handles", ")", ")", ":", "\n", "                ", "if", "self", ".", "new_rule_ct", ">", "0", ":", "\n", "                    ", "obs", "[", "i", "]", "[", "1", "]", "[", ":", ",", "10", ":", "12", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "obs", "[", "i", "]", "[", "1", "]", "[", ":", ",", "10", ":", "12", "]", "=", "1", "\n", "", "acts", "=", "models", "[", "i", "]", ".", "infer_action", "(", "obs", "[", "i", "]", ",", "ids", "[", "i", "]", ",", "'e_greedy'", ",", "eps", "=", "self", ".", "eps", ")", "\n", "env", ".", "set_action", "(", "handles", "[", "i", "]", ",", "acts", ")", "\n", "\n", "", "done", "=", "env", ".", "step", "(", ")", "\n", "\n", "goal_num", "=", "env", ".", "get_num", "(", "self", ".", "food_handle", ")", "\n", "rewards", "=", "env", ".", "get_reward", "(", "handles", "[", "0", "]", ")", "\n", "\n", "for", "id_", ",", "r", "in", "zip", "(", "ids", "[", "0", "]", ",", "rewards", ")", ":", "\n", "                ", "if", "r", ">", "0.05", "and", "id_", "not", "in", "self", ".", "pos_reward_ct", ":", "\n", "                    ", "self", ".", "pos_reward_ct", ".", "add", "(", "id_", ")", "\n", "\n", "", "", "if", "1.0", "*", "len", "(", "self", ".", "pos_reward_ct", ")", "/", "goal_num", ">=", "0.99", ":", "\n", "                ", "self", ".", "new_rule_ct", "+=", "1", "\n", "\n", "", "self", ".", "num", "=", "[", "env", ".", "get_num", "(", "handle", ")", "for", "handle", "in", "[", "self", ".", "food_handle", "]", "+", "handles", "]", "\n", "env", ".", "clear_dead", "(", ")", "\n", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_data": [[348, 360], ["time.time", "print", "arrange_server.ArrangeServer.env._get_render_info", "print", "arrange_server.ArrangeServer.step", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_render_info", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step"], ["", "def", "get_data", "(", "self", ",", "frame_id", ",", "x_range", ",", "y_range", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "not", "self", ".", "done", ":", "\n", "            ", "self", ".", "done", "=", "self", ".", "step", "(", ")", "\n", "", "print", "(", "self", ".", "done", ")", "\n", "if", "self", ".", "done", ":", "\n", "            ", "print", "(", "\"done!\"", ")", "\n", "\n", "", "pos", ",", "event", "=", "self", ".", "env", ".", "_get_render_info", "(", "x_range", ",", "y_range", ")", "\n", "print", "(", "\" fps \"", ",", "1", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "return", "pos", ",", "event", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.add_agents": [[361, 367], ["range", "arrange_server.ArrangeServer.env.add_agents", "range", "pos.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "add_agents", "(", "self", ",", "x", ",", "y", ",", "g", ")", ":", "\n", "        ", "pos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "-", "3", ",", "3", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "-", "3", ",", "3", ")", ":", "\n", "                ", "pos", ".", "append", "(", "(", "x", "+", "i", ",", "y", "+", "j", ")", ")", "\n", "", "", "self", ".", "env", ".", "add_agents", "(", "self", ".", "handles", "[", "g", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_map_size": [[368, 370], ["None"], "methods", ["None"], ["", "def", "get_map_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "map_size", ",", "self", ".", "map_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.ArrangeServer.get_numbers": [[371, 373], ["None"], "methods", ["None"], ["", "def", "get_numbers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.remove_wall": [[11, 36], ["range", "range", "range", "range", "range", "wall_set.remove", "range", "range", "wall_set.remove", "range", "wall_set.remove", "wall_set.remove"], "function", ["None"], ["def", "remove_wall", "(", "d", ",", "cur_pos", ",", "wall_set", ",", "unit", ")", ":", "\n", "    ", "if", "d", "==", "0", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "                ", "temp", "=", "(", "cur_pos", "[", "0", "]", "+", "i", ",", "cur_pos", "[", "1", "]", "+", "unit", "+", "j", ")", "\n", "if", "temp", "in", "wall_set", ":", "\n", "                    ", "wall_set", ".", "remove", "(", "temp", ")", "\n", "", "", "", "", "elif", "d", "==", "1", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "                ", "temp", "=", "(", "cur_pos", "[", "0", "]", "-", "unit", "+", "i", ",", "cur_pos", "[", "1", "]", "+", "j", ")", "\n", "if", "temp", "in", "wall_set", ":", "\n", "                    ", "wall_set", ".", "remove", "(", "temp", ")", "\n", "", "", "", "", "elif", "d", "==", "2", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "                ", "temp", "=", "(", "cur_pos", "[", "0", "]", "+", "i", ",", "cur_pos", "[", "1", "]", "-", "unit", "+", "j", ")", "\n", "if", "temp", "in", "wall_set", ":", "\n", "                    ", "wall_set", ".", "remove", "(", "temp", ")", "\n", "", "", "", "", "elif", "d", "==", "3", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "unit", ")", ":", "\n", "                ", "temp", "=", "(", "cur_pos", "[", "0", "]", "+", "unit", "+", "i", ",", "cur_pos", "[", "1", "]", "+", "j", ")", "\n", "if", "temp", "in", "wall_set", ":", "\n", "                    ", "wall_set", ".", "remove", "(", "temp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.dfs": [[38, 76], ["set", "list", "set.add", "list.append", "random.choice", "range", "len", "list", "list.pop", "len", "max", "tuple", "arrange_server.remove_wall", "list.append", "set.add", "random.choice", "random.choice", "arrange_server.remove_wall", "min", "tuple", "tuple", "range", "range", "min", "max"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.remove_wall", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.remove_wall"], ["", "", "", "", "", "def", "dfs", "(", "x", ",", "y", ",", "width", ",", "height", ",", "unit", ",", "wall_set", ")", ":", "\n", "    ", "pos", "=", "set", "(", ")", "\n", "trace", "=", "list", "(", ")", "\n", "pos", ".", "add", "(", "(", "x", ",", "y", ")", ")", "\n", "trace", ".", "append", "(", "(", "x", ",", "y", ")", ")", "\n", "\n", "max_x", "=", "x", "+", "width", "\n", "max_y", "=", "y", "+", "height", "\n", "\n", "d", "=", "random", ".", "choice", "(", "range", "(", "4", ")", ")", "\n", "pos_list", "=", "[", "]", "\n", "flag", "=", "0", "\n", "while", "len", "(", "trace", ")", ">", "0", ":", "\n", "        ", "if", "flag", "==", "4", ":", "\n", "            ", "cur_pos", "=", "trace", "[", "-", "1", "]", "\n", "trace", ".", "pop", "(", ")", "\n", "if", "random", ".", "choice", "(", "range", "(", "2", ")", ")", "==", "0", ":", "\n", "                ", "remove_wall", "(", "d", ",", "cur_pos", ",", "wall_set", ",", "unit", ")", "\n", "", "flag", "=", "0", "\n", "", "if", "len", "(", "trace", ")", "==", "0", ":", "\n", "            ", "break", "\n", "", "cur_pos", "=", "list", "(", "trace", "[", "-", "1", "]", ")", "\n", "if", "d", "==", "0", ":", "\n", "            ", "cur_pos", "[", "1", "]", "=", "max", "(", "y", ",", "cur_pos", "[", "1", "]", "-", "2", "*", "unit", ")", "\n", "", "elif", "d", "==", "1", ":", "\n", "            ", "cur_pos", "[", "0", "]", "=", "min", "(", "max_x", ",", "cur_pos", "[", "0", "]", "+", "2", "*", "unit", ")", "\n", "", "elif", "d", "==", "2", ":", "\n", "            ", "cur_pos", "[", "1", "]", "=", "min", "(", "max_y", ",", "cur_pos", "[", "1", "]", "+", "2", "*", "unit", ")", "\n", "", "elif", "d", "==", "3", ":", "\n", "            ", "cur_pos", "[", "0", "]", "=", "max", "(", "x", ",", "cur_pos", "[", "0", "]", "-", "2", "*", "unit", ")", "\n", "", "if", "tuple", "(", "cur_pos", ")", "in", "pos", ":", "\n", "            ", "d", "=", "(", "d", "+", "1", ")", "%", "4", "\n", "flag", "+=", "1", "\n", "", "else", ":", "\n", "            ", "remove_wall", "(", "d", ",", "cur_pos", ",", "wall_set", ",", "unit", ")", "\n", "trace", ".", "append", "(", "tuple", "(", "cur_pos", ")", ")", "\n", "pos", ".", "add", "(", "tuple", "(", "cur_pos", ")", ")", "\n", "d", "=", "random", ".", "choice", "(", "range", "(", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.clean_pos_set_convert_to_list": [[78, 83], ["list", "pos_set.remove"], "function", ["None"], ["", "", "", "def", "clean_pos_set_convert_to_list", "(", "pos_set", ",", "pos_list", ")", ":", "\n", "    ", "for", "v", "in", "pos_list", ":", "\n", "        ", "if", "v", "in", "pos_set", ":", "\n", "            ", "pos_set", ".", "remove", "(", "v", ")", "\n", "", "", "return", "list", "(", "pos_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line": [[85, 91], ["range", "range", "pos_set.append"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "draw_line", "(", "x", ",", "y", ",", "width", ",", "height", ")", ":", "\n", "    ", "pos_set", "=", "[", "]", "\n", "for", "r", "in", "range", "(", "height", ")", ":", "\n", "        ", "for", "c", "in", "range", "(", "width", ")", ":", "\n", "            ", "pos_set", ".", "append", "(", "(", "x", "+", "c", ",", "y", "+", "r", ")", ")", "\n", "", "", "return", "pos_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.open_the_door": [[93, 112], ["pos_list.extend", "pos_list.extend", "pos_list.extend", "pos_list.extend", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice"], "function", ["None"], ["", "def", "open_the_door", "(", "x_s", ",", "y_s", ",", "w", ",", "h", ",", "unit", ")", ":", "\n", "    ", "pos_list", "=", "[", "]", "\n", "n_door", "=", "15", "\n", "random_horizon_list_x", "=", "[", "x_s", "+", "(", "2", "*", "np", ".", "random", ".", "choice", "(", "w", "//", "2", "//", "unit", ",", "n_door", ")", "+", "1", ")", "*", "unit", ",", "x_s", "+", "(", "2", "*", "np", ".", "random", ".", "choice", "(", "w", "//", "2", "//", "unit", ",", "n_door", ")", "-", "1", ")", "*", "unit", "]", "\n", "random_vertical_list_y", "=", "[", "y_s", "+", "(", "2", "*", "np", ".", "random", ".", "choice", "(", "h", "//", "2", "//", "unit", ",", "n_door", ")", "+", "1", ")", "*", "unit", ",", "y_s", "+", "(", "2", "*", "np", ".", "random", ".", "choice", "(", "h", "//", "2", "//", "unit", ",", "n_door", ")", "+", "1", ")", "*", "unit", "]", "\n", "\n", "y_e", "=", "y_s", "+", "h", "-", "unit", "\n", "for", "v", "in", "random_horizon_list_x", "[", "0", "]", ":", "\n", "        ", "pos_list", ".", "extend", "(", "[", "(", "v", ",", "y_s", ")", ",", "(", "v", "+", "1", ",", "y_s", ")", ",", "(", "v", ",", "y_s", "+", "1", ")", ",", "(", "v", "+", "1", ",", "y_s", "+", "1", ")", "]", ")", "\n", "", "for", "v", "in", "random_horizon_list_x", "[", "1", "]", ":", "\n", "        ", "pos_list", ".", "extend", "(", "[", "(", "v", ",", "y_e", ")", ",", "(", "v", "+", "1", ",", "y_e", ")", ",", "(", "v", ",", "y_e", "+", "1", ")", ",", "(", "v", "+", "1", ",", "y_e", "+", "1", ")", "]", ")", "\n", "\n", "", "x_e", "=", "x_s", "+", "w", "-", "unit", "\n", "for", "v", "in", "random_vertical_list_y", "[", "0", "]", ":", "\n", "        ", "pos_list", ".", "extend", "(", "[", "(", "x_s", ",", "v", ")", ",", "(", "x_s", ",", "v", "+", "1", ")", ",", "(", "x_s", "+", "1", ",", "v", ")", ",", "(", "x_s", "+", "1", ",", "v", "+", "1", ")", "]", ")", "\n", "", "for", "v", "in", "random_vertical_list_y", "[", "1", "]", ":", "\n", "        ", "pos_list", ".", "extend", "(", "[", "(", "x_e", ",", "v", ")", ",", "(", "x_e", ",", "v", "+", "1", ")", ",", "(", "x_e", "+", "1", ",", "v", ")", ",", "(", "x_e", "+", "1", ",", "v", "+", "1", ")", "]", ")", "\n", "\n", "", "return", "pos_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.create_maze": [[114, 142], ["range", "range", "set", "arrange_server.dfs", "arrange_server.dfs", "arrange_server.dfs", "arrange_server.dfs", "temp.extend", "arrange_server.clean_pos_set_convert_to_list", "arrange_server.open_the_door", "set.extend", "set.extend", "set.extend", "set.extend", "set.extend", "set.extend", "set.extend", "set.extend", "arrange_server.draw_line", "arrange_server.draw_line", "arrange_server.draw_line", "arrange_server.draw_line", "arrange_server.draw_line", "arrange_server.draw_line", "arrange_server.draw_line", "arrange_server.draw_line"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.dfs", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.dfs", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.dfs", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.dfs", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.clean_pos_set_convert_to_list", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.open_the_door", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line", "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.draw_line"], ["", "def", "create_maze", "(", "pos", ",", "width", ",", "height", ",", "unit", ",", "font_area", ")", ":", "\n", "# draw block: with rect: left(x), top(y), width, height", "\n", "    ", "pos_set", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "height", ")", ":", "\n", "        ", "if", "i", "%", "2", "==", "0", ":", "\n", "            ", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", "+", "i", "*", "unit", ",", "width", "*", "unit", ",", "unit", ")", ")", "\n", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", "+", "font_area", "[", "1", "]", "+", "i", "*", "unit", ",", "width", "*", "unit", ",", "unit", ")", ")", "\n", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", "+", "i", "*", "unit", ",", "pos", "[", "1", "]", "+", "height", "*", "unit", ",", "unit", ",", "font_area", "[", "1", "]", ")", ")", "\n", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", "+", "font_area", "[", "0", "]", "+", "i", "*", "unit", ",", "pos", "[", "1", "]", "+", "height", "*", "unit", ",", "unit", ",", "font_area", "[", "1", "]", ")", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "width", ")", ":", "\n", "        ", "if", "i", "%", "2", "==", "0", ":", "\n", "            ", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", "+", "i", "*", "unit", ",", "pos", "[", "1", "]", ",", "unit", ",", "height", "*", "unit", ")", ")", "\n", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", "+", "i", "*", "unit", ",", "pos", "[", "1", "]", "+", "font_area", "[", "1", "]", ",", "unit", ",", "height", "*", "unit", ")", ")", "\n", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", "+", "i", "*", "unit", ",", "height", "*", "unit", ",", "unit", ")", ")", "\n", "pos_set", ".", "extend", "(", "draw_line", "(", "pos", "[", "0", "]", "+", "font_area", "[", "0", "]", ",", "pos", "[", "1", "]", "+", "i", "*", "unit", ",", "height", "*", "unit", ",", "unit", ")", ")", "\n", "\n", "", "", "pos_set", "=", "set", "(", "pos_set", ")", "\n", "\n", "dfs", "(", "pos", "[", "0", "]", "+", "2", ",", "pos", "[", "1", "]", "+", "2", ",", "(", "width", "-", "1", ")", "*", "unit", ",", "(", "height", "-", "1", ")", "*", "unit", ",", "unit", ",", "pos_set", ")", "# north", "\n", "dfs", "(", "pos", "[", "0", "]", "+", "2", ",", "pos", "[", "1", "]", "+", "(", "height", "-", "2", ")", "*", "unit", ",", "(", "height", "-", "1", ")", "*", "unit", ",", "(", "width", "+", "3", ")", "*", "unit", ",", "unit", ",", "pos_set", ")", "# west", "\n", "dfs", "(", "pos", "[", "0", "]", "+", "height", "*", "unit", ",", "pos", "[", "1", "]", "+", "font_area", "[", "1", "]", "-", "unit", ",", "(", "width", "-", "height", ")", "*", "unit", ",", "(", "height", "-", "1", ")", "*", "unit", ",", "unit", ",", "pos_set", ")", "# south", "\n", "dfs", "(", "pos", "[", "0", "]", "+", "font_area", "[", "0", "]", "-", "unit", ",", "pos", "[", "1", "]", "+", "(", "height", "-", "2", ")", "*", "unit", ",", "(", "height", "-", "1", ")", "*", "unit", ",", "font_area", "[", "1", "]", "-", "(", "height", "+", "1", ")", "*", "unit", ",", "unit", ",", "pos_set", ")", "# east", "\n", "\n", "temp", "=", "[", "]", "\n", "temp", ".", "extend", "(", "open_the_door", "(", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", ",", "font_area", "[", "0", "]", "+", "height", "*", "unit", ",", "font_area", "[", "1", "]", "+", "height", "*", "unit", ",", "unit", ")", ")", "\n", "res", "=", "clean_pos_set_convert_to_list", "(", "pos_set", ",", "temp", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.load_config": [[144, 178], ["gw.Config", "gw.Config.set", "gw.Config.set", "gw.Config.set", "gw.Config.register_agent_type", "gw.Config.register_agent_type", "gw.Config.add_group", "gw.Config.add_group", "gw.AgentSymbol", "gw.AgentSymbol", "gw.Config.add_reward_rule", "gw.Event", "gw.CircleRange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule"], ["", "def", "load_config", "(", "map_size", ")", ":", "\n", "    ", "gw", "=", "magent", ".", "gridworld", "\n", "cfg", "=", "gw", ".", "Config", "(", ")", "\n", "\n", "cfg", ".", "set", "(", "{", "\"map_width\"", ":", "map_size", ",", "\"map_height\"", ":", "map_size", "}", ")", "\n", "cfg", ".", "set", "(", "{", "\"minimap_mode\"", ":", "True", "}", ")", "\n", "cfg", ".", "set", "(", "{", "\"embedding_size\"", ":", "12", "}", ")", "\n", "\n", "goal", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"goal\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "\n", "\n", "'can_absorb'", ":", "True", "\n", "}", "\n", ")", "\n", "\n", "agent", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"agent\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "10", ",", "'speed'", ":", "2", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "6", ")", ",", "\n", "'damage'", ":", "2", ",", "'step_recover'", ":", "-", "10.0", "/", "400", ",", "\n", "\n", "'step_reward'", ":", "0", ",", "\n", "}", ")", "\n", "\n", "g_goal", "=", "cfg", ".", "add_group", "(", "goal", ")", "\n", "g_agent", "=", "cfg", ".", "add_group", "(", "agent", ")", "\n", "\n", "g", "=", "gw", ".", "AgentSymbol", "(", "g_goal", ",", "'any'", ")", "\n", "a", "=", "gw", ".", "AgentSymbol", "(", "g_agent", ",", "'any'", ")", "\n", "\n", "cfg", ".", "add_reward_rule", "(", "gw", ".", "Event", "(", "a", ",", "'collide'", ",", "g", ")", ",", "receiver", "=", "a", ",", "value", "=", "10", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.arrange_server.generate_map": [[180, 247], ["env.get_num", "arrange_server.generate_map.add_square"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "generate_map", "(", "mode", ",", "env", ",", "map_size", ",", "goal_handle", ",", "handles", ",", "messages", ",", "font", ")", ":", "\n", "# pre-process message", "\n", "    ", "max_len", "=", "8", "\n", "new", "=", "[", "]", "\n", "for", "msg", "in", "messages", ":", "\n", "        ", "if", "len", "(", "msg", ")", ">", "max_len", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "msg", ")", ",", "max_len", ")", ":", "\n", "                ", "new", ".", "append", "(", "msg", "[", "i", ":", "i", "+", "max_len", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "new", ".", "append", "(", "msg", ")", "\n", "", "", "messages", "=", "new", "\n", "\n", "center_x", ",", "center_y", "=", "map_size", "//", "2", ",", "map_size", "//", "2", "\n", "\n", "# create maze", "\n", "if", "mode", "==", "1", ":", "\n", "        ", "radius", "=", "90", "\n", "pos_list", "=", "create_maze", "(", "[", "center_x", "-", "radius", ",", "center_y", "-", "radius", "]", ",", "radius", "+", "1", ",", "15", ",", "2", ",", "font_area", "=", "[", "radius", "*", "2", "-", "28", ",", "radius", "*", "2", "-", "28", "]", ")", "\n", "env", ".", "add_walls", "(", "method", "=", "\"custom\"", ",", "pos", "=", "pos_list", ")", "\n", "\n", "", "def", "add_square", "(", "pos", ",", "side", ",", "gap", ")", ":", "\n", "        ", "side", "=", "int", "(", "side", ")", "\n", "for", "x", "in", "range", "(", "center_x", "-", "side", "//", "2", ",", "center_x", "+", "side", "//", "2", "+", "1", ",", "gap", ")", ":", "\n", "            ", "pos", ".", "append", "(", "[", "x", ",", "center_y", "-", "side", "//", "2", "]", ")", "\n", "pos", ".", "append", "(", "[", "x", ",", "center_y", "+", "side", "//", "2", "]", ")", "\n", "", "for", "y", "in", "range", "(", "center_y", "-", "side", "//", "2", ",", "center_y", "+", "side", "//", "2", "+", "1", ",", "gap", ")", ":", "\n", "            ", "pos", ".", "append", "(", "[", "center_x", "-", "side", "//", "2", ",", "y", "]", ")", "\n", "pos", ".", "append", "(", "[", "center_x", "+", "side", "//", "2", ",", "y", "]", ")", "\n", "\n", "", "", "def", "draw", "(", "base_x", ",", "base_y", ",", "scale", ",", "data", ")", ":", "\n", "        ", "w", ",", "h", "=", "len", "(", "data", ")", ",", "len", "(", "data", "[", "0", "]", ")", "\n", "pos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "w", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "h", ")", ":", "\n", "                ", "if", "data", "[", "i", "]", "[", "j", "]", "==", "1", ":", "\n", "                    ", "start_x", "=", "i", "*", "scale", "+", "base_y", "\n", "start_y", "=", "j", "*", "scale", "+", "base_x", "\n", "for", "x", "in", "range", "(", "start_x", ",", "start_x", "+", "scale", ")", ":", "\n", "                        ", "for", "y", "in", "range", "(", "start_y", ",", "start_y", "+", "scale", ")", ":", "\n", "                            ", "pos", ".", "append", "(", "[", "y", ",", "x", "]", ")", "\n", "\n", "", "", "", "", "", "env", ".", "add_agents", "(", "goal_handle", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n", "", "base_y", "=", "(", "map_size", "-", "len", "(", "messages", ")", "*", "font", ".", "height", ")", "//", "2", "\n", "for", "message", "in", "messages", ":", "\n", "        ", "base_x", "=", "(", "map_size", "-", "len", "(", "message", ")", "*", "font", ".", "width", ")", "//", "2", "\n", "scale", "=", "1", "\n", "for", "x", "in", "message", ":", "\n", "            ", "data", "=", "font", ".", "get", "(", "x", ")", "\n", "draw", "(", "base_x", ",", "base_y", ",", "scale", ",", "data", ")", "\n", "base_x", "+=", "font", ".", "width", "\n", "", "base_y", "+=", "font", ".", "height", "+", "1", "\n", "\n", "", "alpha_goal_num", "=", "env", ".", "get_num", "(", "goal_handle", ")", "\n", "\n", "# agent", "\n", "pos", "=", "[", "]", "\n", "\n", "add_square", "(", "pos", ",", "map_size", "*", "0.95", ",", "1", ")", "\n", "add_square", "(", "pos", ",", "map_size", "*", "0.90", ",", "1", ")", "\n", "add_square", "(", "pos", ",", "map_size", "*", "0.85", ",", "1", ")", "\n", "add_square", "(", "pos", ",", "map_size", "*", "0.80", ",", "1", ")", "\n", "\n", "pos", "=", "np", ".", "array", "(", "pos", ")", "\n", "pos", "=", "pos", "[", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "len", "(", "pos", ")", ")", ",", "int", "(", "alpha_goal_num", "*", "1.6", ")", ",", "replace", "=", "False", ")", "]", "\n", "\n", "env", ".", "add_agents", "(", "handles", "[", "0", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.get_info": [[7, 10], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "get_info", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.get_data": [[11, 14], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_data", "(", "self", ",", "frame_id", ",", "x_range", ",", "y_range", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.add_agents": [[15, 18], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "add_agents", "(", "self", ",", "x", ",", "y", ",", "g", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.get_map_size": [[19, 22], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_map_size", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.get_banners": [[23, 26], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_banners", "(", "self", ",", "frame_id", ",", "resolution", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.get_status": [[27, 30], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_status", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.keydown": [[31, 34], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "keydown", "(", "self", ",", "frame_id", ",", "key", ",", "mouse_x", ",", "mouse_y", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.mousedown": [[35, 38], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "mousedown", "(", "self", ",", "frame_id", ",", "key", ",", "mouse_x", ",", "mouse_y", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.base_server.BaseServer.get_endscreen": [[39, 42], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_endscreen", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.server.random_server.RandomServer.__init__": [[7, 29], ["range", "range", "random_server.RandomServer._data.setdefault", "random_server.RandomServer._group.append", "random.randint", "random.randint", "random.randint", "random.randint", "random.randint", "random.randint", "random.randint", "random.randint"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["    ", "def", "__init__", "(", "self", ",", "agent_number", "=", "1000", ",", "group_number", "=", "20", ",", "map_size", "=", "100", ",", "shape_range", "=", "3", ",", "speed", "=", "5", ",", "event_range", "=", "100", ")", ":", "\n", "        ", "self", ".", "_data", "=", "{", "}", "\n", "self", ".", "_map_size", "=", "map_size", "\n", "self", ".", "_number", "=", "agent_number", "\n", "for", "i", "in", "range", "(", "agent_number", ")", ":", "\n", "            ", "self", ".", "_data", ".", "setdefault", "(", "i", ",", "[", "\n", "random", ".", "randint", "(", "0", ",", "map_size", "-", "1", ")", ",", "\n", "random", ".", "randint", "(", "0", ",", "map_size", "-", "1", ")", ",", "\n", "random", ".", "randint", "(", "0", ",", "group_number", "-", "1", ")", "\n", "]", ")", "\n", "", "self", ".", "_group", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "group_number", ")", ":", "\n", "            ", "self", ".", "_group", ".", "append", "(", "[", "\n", "random", ".", "randint", "(", "1", ",", "shape_range", ")", ",", "\n", "random", ".", "randint", "(", "1", ",", "shape_range", ")", ",", "\n", "random", ".", "randint", "(", "0", ",", "255", ")", ",", "\n", "random", ".", "randint", "(", "0", ",", "255", ")", ",", "\n", "random", ".", "randint", "(", "0", ",", "255", ")", "\n", "]", ")", "\n", "", "self", ".", "_speed", "=", "speed", "\n", "self", ".", "_event_range", "=", "event_range", "\n", "self", ".", "_map_size", "=", "map_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.random_server.RandomServer.get_group_info": [[30, 32], ["None"], "methods", ["None"], ["", "def", "get_group_info", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_group", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.random_server.RandomServer.get_static_info": [[33, 35], ["None"], "methods", ["None"], ["", "def", "get_static_info", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"wall\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.random_server.RandomServer.get_data": [[36, 62], ["random.randint", "range", "min", "min", "random.choice", "event.append", "random.randint", "random.randint", "max", "max", "result.setdefault", "random_server.RandomServer._data.items", "random.randint", "random.randint"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "get_data", "(", "self", ",", "frame_id", ",", "x_range", ",", "y_range", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "event", "=", "[", "]", "\n", "for", "i", "in", "self", ".", "_data", ":", "\n", "            ", "olddata", "=", "self", ".", "_data", "[", "i", "]", "\n", "data", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "data", "[", "0", "]", "=", "olddata", "[", "0", "]", "+", "random", ".", "randint", "(", "-", "self", ".", "_speed", ",", "self", ".", "_speed", ")", "\n", "data", "[", "1", "]", "=", "olddata", "[", "1", "]", "+", "random", ".", "randint", "(", "-", "self", ".", "_speed", ",", "self", ".", "_speed", ")", "\n", "data", "[", "0", "]", "=", "min", "(", "max", "(", "data", "[", "0", "]", ",", "0", ")", ",", "self", ".", "_map_size", "-", "1", ")", "\n", "data", "[", "1", "]", "=", "min", "(", "max", "(", "data", "[", "1", "]", ",", "0", ")", ",", "self", ".", "_map_size", "-", "1", ")", "\n", "data", "[", "2", "]", "=", "olddata", "[", "2", "]", "\n", "self", ".", "_data", "[", "i", "]", "=", "data", "\n", "if", "(", "x_range", "[", "0", "]", "<=", "data", "[", "0", "]", "<=", "x_range", "[", "1", "]", "and", "y_range", "[", "0", "]", "<=", "data", "[", "1", "]", "<=", "y_range", "[", "1", "]", ")", "or", "(", "x_range", "[", "0", "]", "<=", "olddata", "[", "0", "]", "<=", "x_range", "[", "1", "]", "and", "y_range", "[", "0", "]", "<=", "olddata", "[", "1", "]", "<=", "y_range", "[", "1", "]", ")", ":", "\n", "                ", "result", ".", "setdefault", "(", "i", ",", "olddata", ")", "\n", "", "", "event_number", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "_event_range", ")", "\n", "for", "i", "in", "range", "(", "event_number", ")", ":", "\n", "            ", "agent_id", ",", "_", "=", "random", ".", "choice", "(", "self", ".", "_data", ".", "items", "(", ")", ")", "\n", "event", ".", "append", "(", "\n", "(", "\n", "agent_id", ",", "\n", "random", ".", "randint", "(", "0", ",", "self", ".", "_map_size", "-", "1", ")", ",", "\n", "random", ".", "randint", "(", "0", ",", "self", ".", "_map_size", "-", "1", ")", "\n", ")", "\n", ")", "\n", "", "return", "result", ",", "event", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.random_server.RandomServer.add_agents": [[63, 66], ["random_server.RandomServer._data.setdefault"], "methods", ["None"], ["", "def", "add_agents", "(", "self", ",", "x", ",", "y", ",", "g", ")", ":", "\n", "        ", "self", ".", "_data", ".", "setdefault", "(", "self", ".", "_number", ",", "(", "x", ",", "y", ",", "g", ")", ")", "\n", "self", ".", "_number", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.random_server.RandomServer.get_map_size": [[67, 69], ["None"], "methods", ["None"], ["", "def", "get_map_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_map_size", ",", "self", ".", "_map_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.sample_server.SampleServer.get_group_info": [[5, 7], ["None"], "methods", ["None"], ["    ", "def", "get_group_info", "(", "self", ")", ":", "\n", "        ", "return", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.sample_server.SampleServer.get_static_info": [[8, 10], ["None"], "methods", ["None"], ["", "def", "get_static_info", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"walls\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.sample_server.SampleServer.get_data": [[11, 22], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ",", "frame_id", ",", "x_range", ",", "y_range", ")", ":", "\n", "        ", "if", "frame_id", "==", "0", ":", "\n", "            ", "return", "{", "1", ":", "[", "10", ",", "10", ",", "0", "]", "}", ",", "[", "(", "1", ",", "0", ",", "0", ")", "]", "\n", "", "elif", "frame_id", "==", "1", ":", "\n", "            ", "return", "{", "1", ":", "[", "9", ",", "10", ",", "0", "]", "}", ",", "[", "(", "1", ",", "0", ",", "0", ")", "]", "\n", "", "elif", "frame_id", "==", "2", ":", "\n", "            ", "return", "{", "1", ":", "[", "8", ",", "10", ",", "0", "]", "}", ",", "[", "(", "1", ",", "0", ",", "0", ")", "]", "\n", "", "elif", "frame_id", "==", "3", ":", "\n", "            ", "return", "{", "1", ":", "[", "14", ",", "12", ",", "0", "]", "}", ",", "[", "(", "1", ",", "0", ",", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "{", "1", ":", "[", "10", ",", "10", ",", "0", "]", "}", ",", "[", "(", "1", ",", "0", ",", "0", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.sample_server.SampleServer.add_agents": [[23, 25], ["None"], "methods", ["None"], ["", "", "def", "add_agents", "(", "self", ",", "x", ",", "y", ",", "g", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.sample_server.SampleServer.get_map_size": [[26, 28], ["None"], "methods", ["None"], ["", "def", "get_map_size", "(", "self", ")", ":", "\n", "        ", "return", "[", "50", ",", "50", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.__init__": [[86, 119], ["magent.GridWorld", "magent.GridWorld.get_handles", "models.append", "models.append", "models[].load", "models[].load", "magent.GridWorld.reset", "battle_server.generate_map", "print", "matplotlib.show", "battle_server.load_config", "magent.builtin.tf_model.DeepQNetwork", "magent.builtin.tf_model.DeepQNetwork", "magent.GridWorld.get_view2attack"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_handles", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.__init__.load", "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.__init__.load", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.reset", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.generate_map", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.load_config", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_view2attack"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "\"data/battle_model\"", ",", "total_step", "=", "1000", ",", "add_counter", "=", "10", ",", "add_interval", "=", "50", ")", ":", "\n", "# some parameter", "\n", "        ", "map_size", "=", "125", "\n", "eps", "=", "0.05", "\n", "\n", "# init the game", "\n", "env", "=", "magent", ".", "GridWorld", "(", "load_config", "(", "map_size", ")", ")", "\n", "\n", "handles", "=", "env", ".", "get_handles", "(", ")", "\n", "models", "=", "[", "]", "\n", "models", ".", "append", "(", "DeepQNetwork", "(", "env", ",", "handles", "[", "0", "]", ",", "'trusty-battle-game-l'", ",", "use_conv", "=", "True", ")", ")", "\n", "models", ".", "append", "(", "DeepQNetwork", "(", "env", ",", "handles", "[", "1", "]", ",", "'trusty-battle-game-r'", ",", "use_conv", "=", "True", ")", ")", "\n", "\n", "# load model", "\n", "models", "[", "0", "]", ".", "load", "(", "path", ",", "0", ",", "'trusty-battle-game-l'", ")", "\n", "models", "[", "1", "]", ".", "load", "(", "path", ",", "0", ",", "'trusty-battle-game-r'", ")", "\n", "\n", "# init environment", "\n", "env", ".", "reset", "(", ")", "\n", "generate_map", "(", "env", ",", "map_size", ",", "handles", ")", "\n", "\n", "# save to member variable", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handles", "=", "handles", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "map_size", "=", "map_size", "\n", "self", ".", "total_step", "=", "total_step", "\n", "self", ".", "add_interval", "=", "add_interval", "\n", "self", ".", "add_counter", "=", "add_counter", "\n", "self", ".", "done", "=", "False", "\n", "print", "(", "env", ".", "get_view2attack", "(", "handles", "[", "0", "]", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_info": [[120, 122], ["battle_server.BattleServer.env._get_groups_info", "battle_server.BattleServer.env._get_walls_info"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_groups_info", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_walls_info"], ["", "def", "get_info", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "map_size", ",", "self", ".", "map_size", ")", ",", "self", ".", "env", ".", "_get_groups_info", "(", ")", ",", "{", "'wall'", ":", "self", ".", "env", ".", "_get_walls_info", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.step": [[123, 156], ["range", "env.step", "env.clear_dead", "env.get_observation", "env.get_agent_id", "len", "models[].infer_action", "env.set_action", "counter.append", "numpy.zeros", "env.get_action_space"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.clear_dead", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_observation", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_agent_id", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.infer_action", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.set_action", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "handles", "=", "self", ".", "handles", "\n", "models", "=", "self", ".", "models", "\n", "env", "=", "self", ".", "env", "\n", "\n", "obs", "=", "[", "env", ".", "get_observation", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "ids", "=", "[", "env", ".", "get_agent_id", "(", "handle", ")", "for", "handle", "in", "handles", "]", "\n", "\n", "counter", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "handles", ")", ")", ":", "\n", "            ", "acts", "=", "models", "[", "i", "]", ".", "infer_action", "(", "obs", "[", "i", "]", ",", "ids", "[", "i", "]", ",", "'e_greedy'", ",", "eps", "=", "self", ".", "eps", ")", "\n", "env", ".", "set_action", "(", "handles", "[", "i", "]", ",", "acts", ")", "\n", "counter", ".", "append", "(", "np", ".", "zeros", "(", "shape", "=", "env", ".", "get_action_space", "(", "handles", "[", "i", "]", ")", ")", ")", "\n", "for", "j", "in", "acts", ":", "\n", "                ", "counter", "[", "-", "1", "]", "[", "j", "]", "+=", "1", "\n", "# plt.clf()", "\n", "# for c in counter:", "\n", "#    plt.bar(range(len(c)), c / np.sum(c))", "\n", "# plt.draw()", "\n", "# plt.pause(1e-8)", "\n", "\n", "# code for checking the correctness of observation", "\n", "# for channel in range(7):", "\n", "#     x = magent.round(list(obs[1][0][0][:,:,channel]), 2)", "\n", "#     for row in x:", "\n", "#         print row", "\n", "#     print(\"-------------\")", "\n", "# input()", "\n", "\n", "", "", "done", "=", "env", ".", "step", "(", ")", "\n", "env", ".", "clear_dead", "(", ")", "\n", "\n", "return", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_data": [[157, 165], ["time.time", "battle_server.BattleServer.step", "battle_server.BattleServer.env._get_render_info", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld._get_render_info"], ["", "def", "get_data", "(", "self", ",", "frame_id", ",", "x_range", ",", "y_range", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "done", ":", "\n", "            ", "return", "None", "\n", "", "self", ".", "done", "=", "self", ".", "step", "(", ")", "\n", "pos", ",", "event", "=", "self", ".", "env", ".", "_get_render_info", "(", "x_range", ",", "y_range", ")", "\n", "print", "(", "\" fps \"", ",", "1", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "return", "pos", ",", "event", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents": [[166, 180], ["range", "battle_server.BattleServer.env.add_agents", "numpy.random.randint", "numpy.random.randint", "range", "battle_server.BattleServer.env.add_agents", "range", "range", "pos.append", "pos.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "add_agents", "(", "self", ",", "x", ",", "y", ",", "g", ")", ":", "\n", "        ", "pos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "-", "5", ",", "5", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "-", "5", ",", "5", ")", ":", "\n", "                ", "pos", ".", "append", "(", "(", "x", "+", "i", ",", "y", "+", "j", ")", ")", "\n", "", "", "self", ".", "env", ".", "add_agents", "(", "self", ".", "handles", "[", "g", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n", "pos", "=", "[", "]", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "map_size", "-", "1", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "map_size", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "-", "5", ",", "5", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "-", "5", ",", "6", ")", ":", "\n", "                ", "pos", ".", "append", "(", "(", "x", "+", "i", ",", "y", "+", "j", ")", ")", "\n", "", "", "self", ".", "env", ".", "add_agents", "(", "self", ".", "handles", "[", "g", "^", "1", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_map_size": [[181, 183], ["None"], "methods", ["None"], ["", "def", "get_map_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "map_size", ",", "self", ".", "map_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_banners": [[184, 200], ["result.append", "result.append", "result.append", "battle_server.BattleServer.env.get_num", "battle_server.BattleServer.env.get_num", "max"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_banners", "(", "self", ",", "frame_id", ",", "resolution", ")", ":", "\n", "        ", "red", "=", "'{}'", ".", "format", "(", "self", ".", "env", ".", "get_num", "(", "self", ".", "handles", "[", "0", "]", ")", ")", ",", "(", "200", ",", "0", ",", "0", ")", "\n", "vs", "=", "' vs '", ",", "(", "0", ",", "0", ",", "0", ")", "\n", "blue", "=", "'{}'", ".", "format", "(", "self", ".", "env", ".", "get_num", "(", "self", ".", "handles", "[", "1", "]", ")", ")", ",", "(", "0", ",", "0", ",", "200", ")", "\n", "result", "=", "[", "(", "red", ",", "vs", ",", "blue", ")", "]", "\n", "\n", "tmp", "=", "'{} chance(s) remained'", ".", "format", "(", "\n", "max", "(", "0", ",", "self", ".", "add_counter", ")", ")", ",", "(", "0", ",", "0", ",", "0", ")", "\n", "result", ".", "append", "(", "(", "tmp", ",", ")", ")", "\n", "\n", "tmp", "=", "'{} / {} steps'", ".", "format", "(", "frame_id", ",", "self", ".", "total_step", ")", ",", "(", "0", ",", "0", ",", "0", ")", "\n", "result", ".", "append", "(", "(", "tmp", ",", ")", ")", "\n", "if", "frame_id", "%", "self", ".", "add_interval", "==", "0", "and", "frame_id", "<", "self", ".", "total_step", "and", "self", ".", "add_counter", ">", "0", ":", "\n", "            ", "tmp", "=", "'Please press your left mouse button to add agents'", ",", "(", "0", ",", "0", ",", "0", ")", "\n", "result", ".", "append", "(", "(", "tmp", ",", ")", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_status": [[201, 208], ["None"], "methods", ["None"], ["", "def", "get_status", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "if", "frame_id", "%", "self", ".", "add_interval", "==", "0", "and", "self", ".", "add_counter", ">", "0", ":", "\n", "            ", "return", "False", "\n", "", "elif", "frame_id", ">=", "self", ".", "total_step", "or", "self", ".", "done", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.keydown": [[209, 211], ["None"], "methods", ["None"], ["", "", "def", "keydown", "(", "self", ",", "frame_id", ",", "key", ",", "mouse_x", ",", "mouse_y", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.mousedown": [[212, 231], ["range", "battle_server.BattleServer.env.add_agents", "numpy.random.randint", "numpy.random.randint", "range", "battle_server.BattleServer.env.add_agents", "range", "range", "pos.append", "pos.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "mousedown", "(", "self", ",", "frame_id", ",", "pressed", ",", "mouse_x", ",", "mouse_y", ")", ":", "\n", "        ", "if", "frame_id", "%", "self", ".", "add_interval", "==", "0", "and", "frame_id", "<", "self", ".", "total_step", "and", "pressed", "[", "0", "]", "and", "self", ".", "add_counter", ">", "0", "and", "not", "self", ".", "done", ":", "\n", "            ", "self", ".", "add_counter", "-=", "1", "\n", "pos", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "-", "5", ",", "5", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "-", "5", ",", "5", ")", ":", "\n", "                    ", "pos", ".", "append", "(", "(", "mouse_x", "+", "i", ",", "mouse_y", "+", "j", ")", ")", "\n", "", "", "self", ".", "env", ".", "add_agents", "(", "self", ".", "handles", "[", "0", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n", "pos", "=", "[", "]", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "map_size", "-", "1", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "map_size", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "-", "5", ",", "6", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "-", "5", ",", "5", ")", ":", "\n", "                    ", "pos", ".", "append", "(", "(", "x", "+", "i", ",", "y", "+", "j", ")", ")", "\n", "", "", "self", ".", "env", ".", "add_agents", "(", "self", ".", "handles", "[", "1", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.get_endscreen": [[232, 240], ["battle_server.BattleServer.env.get_num", "battle_server.BattleServer.env.get_num"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_num"], ["", "def", "get_endscreen", "(", "self", ",", "frame_id", ")", ":", "\n", "        ", "if", "frame_id", "==", "self", ".", "total_step", "or", "self", ".", "done", ":", "\n", "            ", "if", "self", ".", "env", ".", "get_num", "(", "self", ".", "handles", "[", "0", "]", ")", ">", "self", ".", "env", ".", "get_num", "(", "self", ".", "handles", "[", "1", "]", ")", ":", "\n", "                ", "return", "[", "(", "(", "\"You\"", ",", "(", "200", ",", "0", ",", "0", ")", ")", ",", "(", "\" win! :)\"", ",", "(", "0", ",", "0", ",", "0", ")", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "(", "(", "\"You\"", ",", "(", "200", ",", "0", ",", "0", ")", ")", ",", "(", "\" lose. :(\"", ",", "(", "0", ",", "0", ",", "0", ")", ")", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "[", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.load_config": [[12, 39], ["gw.Config", "gw.Config.set", "gw.Config.set", "gw.Config.set", "gw.Config.register_agent_type", "gw.Config.add_group", "gw.Config.add_group", "gw.AgentSymbol", "gw.AgentSymbol", "gw.Config.add_reward_rule", "gw.Config.add_reward_rule", "gw.Event", "gw.Event", "gw.CircleRange", "gw.CircleRange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule"], ["def", "load_config", "(", "map_size", ")", ":", "\n", "    ", "gw", "=", "magent", ".", "gridworld", "\n", "cfg", "=", "gw", ".", "Config", "(", ")", "\n", "\n", "cfg", ".", "set", "(", "{", "\"map_width\"", ":", "map_size", ",", "\"map_height\"", ":", "map_size", "}", ")", "\n", "cfg", ".", "set", "(", "{", "\"minimap_mode\"", ":", "True", "}", ")", "\n", "\n", "cfg", ".", "set", "(", "{", "\"embedding_size\"", ":", "10", "}", ")", "\n", "\n", "small", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"small\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "10", ",", "'speed'", ":", "2", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "6", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "1.5", ")", ",", "\n", "'damage'", ":", "2", ",", "'step_recover'", ":", "0.1", ",", "\n", "'step_reward'", ":", "-", "0.001", ",", "'kill_reward'", ":", "100", ",", "'dead_penalty'", ":", "-", "0.05", ",", "'attack_penalty'", ":", "-", "1", ",", "\n", "}", ")", "\n", "\n", "g0", "=", "cfg", ".", "add_group", "(", "small", ")", "\n", "g1", "=", "cfg", ".", "add_group", "(", "small", ")", "\n", "\n", "a", "=", "gw", ".", "AgentSymbol", "(", "g0", ",", "index", "=", "'any'", ")", "\n", "b", "=", "gw", ".", "AgentSymbol", "(", "g1", ",", "index", "=", "'any'", ")", "\n", "\n", "cfg", ".", "add_reward_rule", "(", "gw", ".", "Event", "(", "a", ",", "'attack'", ",", "b", ")", ",", "receiver", "=", "a", ",", "value", "=", "2", ")", "\n", "cfg", ".", "add_reward_rule", "(", "gw", ".", "Event", "(", "b", ",", "'attack'", ",", "a", ")", ",", "receiver", "=", "b", ",", "value", "=", "2", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.generate_map": [[41, 83], ["range", "range", "range", "range", "env.add_walls", "range", "env.add_agents", "range", "env.add_agents", "pos.append", "pos.append", "pos.append", "pos.append", "pos.append", "pos.append", "pos.append", "pos.append", "int", "range", "int", "range", "math.sqrt", "pos.append", "math.sqrt", "pos.append"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.add_walls", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.server.battle_server.BattleServer.add_agents", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "generate_map", "(", "env", ",", "map_size", ",", "handles", ")", ":", "\n", "    ", "width", "=", "map_size", "\n", "height", "=", "map_size", "\n", "\n", "init_num", "=", "20", "\n", "\n", "gap", "=", "3", "\n", "leftID", ",", "rightID", "=", "0", ",", "1", "\n", "\n", "# left", "\n", "pos", "=", "[", "]", "\n", "for", "y", "in", "range", "(", "10", ",", "45", ")", ":", "\n", "        ", "pos", ".", "append", "(", "(", "width", "/", "2", "-", "5", ",", "y", ")", ")", "\n", "pos", ".", "append", "(", "(", "width", "/", "2", "-", "4", ",", "y", ")", ")", "\n", "", "for", "y", "in", "range", "(", "50", ",", "height", "//", "2", "+", "25", ")", ":", "\n", "        ", "pos", ".", "append", "(", "(", "width", "/", "2", "-", "5", ",", "y", ")", ")", "\n", "pos", ".", "append", "(", "(", "width", "/", "2", "-", "4", ",", "y", ")", ")", "\n", "\n", "", "for", "y", "in", "range", "(", "height", "//", "2", "-", "25", ",", "height", "-", "50", ")", ":", "\n", "        ", "pos", ".", "append", "(", "(", "width", "/", "2", "+", "5", ",", "y", ")", ")", "\n", "pos", ".", "append", "(", "(", "width", "/", "2", "+", "4", ",", "y", ")", ")", "\n", "", "for", "y", "in", "range", "(", "height", "-", "45", ",", "height", "-", "10", ")", ":", "\n", "        ", "pos", ".", "append", "(", "(", "width", "/", "2", "+", "5", ",", "y", ")", ")", "\n", "pos", ".", "append", "(", "(", "width", "/", "2", "+", "4", ",", "y", ")", ")", "\n", "", "env", ".", "add_walls", "(", "pos", "=", "pos", ",", "method", "=", "\"custom\"", ")", "\n", "\n", "n", "=", "init_num", "\n", "side", "=", "int", "(", "math", ".", "sqrt", "(", "n", ")", ")", "*", "2", "\n", "pos", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "width", "//", "2", "-", "gap", "-", "side", ",", "width", "//", "2", "-", "gap", "-", "side", "+", "side", ",", "2", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "(", "height", "-", "side", ")", "//", "2", ",", "(", "height", "-", "side", ")", "//", "2", "+", "side", ",", "2", ")", ":", "\n", "            ", "pos", ".", "append", "(", "[", "x", ",", "y", ",", "0", "]", ")", "\n", "", "", "env", ".", "add_agents", "(", "handles", "[", "leftID", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n", "# right", "\n", "n", "=", "init_num", "\n", "side", "=", "int", "(", "math", ".", "sqrt", "(", "n", ")", ")", "*", "2", "\n", "pos", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "width", "//", "2", "+", "gap", ",", "width", "//", "2", "+", "gap", "+", "side", ",", "2", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "(", "height", "-", "side", ")", "//", "2", ",", "(", "height", "-", "side", ")", "//", "2", "+", "side", ",", "2", ")", ":", "\n", "            ", "pos", ".", "append", "(", "[", "x", ",", "y", ",", "0", "]", ")", "\n", "", "", "env", ".", "add_agents", "(", "handles", "[", "rightID", "]", ",", "method", "=", "\"custom\"", ",", "pos", "=", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.__init__": [[8, 12], ["numpy.empty", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "shape", ",", "dtype", "=", "np", ".", "float32", ")", ":", "\n", "        ", "self", ".", "buffer", "=", "np", ".", "empty", "(", "shape", "=", "shape", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "head", "=", "0", "\n", "self", ".", "capacity", "=", "len", "(", "self", ".", "buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put": [[13, 32], ["len"], "methods", ["None"], ["", "def", "put", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"put data to\n\n        Parameters\n        ----------\n        data: numpy array\n            data to add\n        \"\"\"", "\n", "head", "=", "self", ".", "head", "\n", "n", "=", "len", "(", "data", ")", "\n", "if", "head", "+", "n", "<=", "self", ".", "capacity", ":", "\n", "            ", "self", ".", "buffer", "[", "head", ":", "head", "+", "n", "]", "=", "data", "\n", "self", ".", "head", "=", "(", "self", ".", "head", "+", "n", ")", "%", "self", ".", "capacity", "\n", "", "else", ":", "\n", "            ", "split", "=", "self", ".", "capacity", "-", "head", "\n", "self", ".", "buffer", "[", "head", ":", "]", "=", "data", "[", ":", "split", "]", "\n", "self", ".", "buffer", "[", ":", "n", "-", "split", "]", "=", "data", "[", "split", ":", "]", "\n", "self", ".", "head", "=", "split", "\n", "", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get": [[33, 42], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"get items\n\n        Parameters\n        ----------\n        index: int or numpy array\n            it can be any numpy supported index\n        \"\"\"", "\n", "return", "self", ".", "buffer", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear": [[43, 46], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "\"\"\"clear replay buffer\"\"\"", "\n", "self", ".", "head", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic.__init__": [[11, 79], ["base.TFBaseModel.__init__", "tensorflow.ConfigProto", "tensorflow.Session", "a2c.AdvantageActorCritic.sess.run", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "env.get_view_space", "env.get_feature_space", "env.get_action_space", "tensorflow.name_scope", "a2c.AdvantageActorCritic._create_network", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "learning_rate", "=", "1e-3", ",", "\n", "batch_size", "=", "64", ",", "reward_decay", "=", "0.99", ",", "eval_obs", "=", "None", ",", "\n", "train_freq", "=", "1", ",", "value_coef", "=", "0.1", ",", "ent_coef", "=", "0.08", ",", "use_comm", "=", "False", ",", "\n", "custom_view_space", "=", "None", ",", "custom_feature_space", "=", "None", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: Environment\n            environment\n        handle: Handle (ctypes.c_int32)\n            handle of this group, can be got by env.get_handles\n        name: str\n            name of this model\n        learning_rate: float\n        batch_size: int\n        reward_decay: float\n            reward_decay in TD\n        eval_obs: numpy array\n            evaluation set of observation\n        train_freq: int\n            mean training times of a sample\n        ent_coef: float\n            weight of entropy loss in total loss\n        value_coef: float\n            weight of value loss in total loss\n        use_comm: bool\n            whether use CommNet\n        custom_feature_space: tuple\n            customized feature space\n        custom_view_space: tuple\n            customized feature space\n        \"\"\"", "\n", "TFBaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\"tfa2c\"", ")", "\n", "# ======================== set config  ========================", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "view_space", "=", "custom_view_space", "or", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "custom_feature_space", "or", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "self", ".", "reward_decay", "=", "reward_decay", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "train_freq", "=", "train_freq", "# train time of every sample (s,a,r,s')", "\n", "\n", "self", ".", "value_coef", "=", "value_coef", "# coefficient of value in the total loss", "\n", "self", ".", "ent_coef", "=", "ent_coef", "# coefficient of entropy in the total loss", "\n", "\n", "self", ".", "train_ct", "=", "0", "\n", "self", ".", "use_comm", "=", "use_comm", "\n", "\n", "# ======================= build network =======================", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "self", ".", "_create_network", "(", "self", ".", "view_space", ",", "self", ".", "feature_space", ")", "\n", "\n", "# init tensorflow session", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "False", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# init training buffers", "\n", "self", ".", "view_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "reward_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic._commnet_block": [[80, 103], ["tensorflow.where", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.tanh", "tensorflow.ones", "tensorflow.eye", "tensorflow.cast", "tensorflow.matmul", "tensorflow.matmul"], "methods", ["None"], ["", "def", "_commnet_block", "(", "self", ",", "n", ",", "hidden", ",", "skip", ",", "name", ",", "hidden_size", ")", ":", "\n", "        ", "\"\"\"a block of CommNet\n\n        Parameters\n        ----------\n        n: int\n            number of agent\n        hidden: tf.tensor\n            hidden layer input\n        skip: tf.tensor\n            skip connection\n        name: str\n        hidden_size: int\n        \"\"\"", "\n", "mask", "=", "(", "tf", ".", "ones", "(", "(", "n", ",", "n", ")", ")", "-", "tf", ".", "eye", "(", "n", ")", ")", "\n", "mask", "*=", "tf", ".", "where", "(", "n", ">", "1", ",", "1.0", "/", "(", "tf", ".", "cast", "(", "n", ",", "tf", ".", "float32", ")", "-", "1.0", ")", ",", "0", ")", "\n", "\n", "C", "=", "tf", ".", "get_variable", "(", "name", "+", "\"_C\"", ",", "shape", "=", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "H", "=", "tf", ".", "get_variable", "(", "name", "+", "\"_H\"", ",", "shape", "=", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "\n", "message", "=", "tf", ".", "matmul", "(", "mask", ",", "hidden", ")", "\n", "\n", "return", "tf", ".", "tanh", "(", "tf", ".", "matmul", "(", "message", ",", "C", ")", "+", "tf", ".", "matmul", "(", "hidden", ",", "H", ")", "+", "skip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic._commnet": [[104, 127], ["range", "a2c.AdvantageActorCritic._commnet_block"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic._commnet_block"], ["", "def", "_commnet", "(", "self", ",", "n", ",", "dense", ",", "hidden_size", ",", "n_step", "=", "2", ")", ":", "\n", "        ", "\"\"\" CommNet Learning Multiagent Communication with Backpropagation by S. Sukhbaatar et al. NIPS 2016\n\n        Parameters\n        ----------\n        n: int\n            number of agent\n        hidden_size: int\n        n_step: int\n            communication step\n\n        Returns\n        -------\n        h: tf.tensor\n            hidden units after CommNet\n        \"\"\"", "\n", "skip", "=", "dense", "\n", "\n", "h", "=", "dense", "\n", "for", "i", "in", "range", "(", "n_step", ")", ":", "\n", "            ", "h", "=", "self", ".", "_commnet_block", "(", "n", ",", "h", ",", "skip", ",", "\"step_%d\"", "%", "i", ",", "hidden_size", ")", "\n", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic._create_network": [[128, 192], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.clip_by_value", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.stop_gradient", "tensorflow.one_hot", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.AdamOptimizer().minimize", "a2c.AdvantageActorCritic._commnet", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "zip", "numpy.prod", "tensorflow.square", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic._commnet"], ["", "def", "_create_network", "(", "self", ",", "view_space", ",", "feature_space", ")", ":", "\n", "        ", "\"\"\"define computation graph of network\n\n        Parameters\n        ----------\n        view_space: tuple\n        feature_space: tuple\n            the input shape\n        \"\"\"", "\n", "# input", "\n", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "view_space", ")", "\n", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "feature_space", ")", "\n", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "reward", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "num_agent", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "]", ")", "\n", "\n", "kernel_num", "=", "[", "32", ",", "32", "]", "\n", "hidden_size", "=", "[", "256", "]", "\n", "\n", "# fully connected", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "input_view", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "input_view", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "dense", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "dense", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "hidden_size", "[", "0", "]", "*", "2", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "if", "self", ".", "use_comm", ":", "\n", "            ", "dense", "=", "self", ".", "_commnet", "(", "num_agent", ",", "dense", ",", "dense", ".", "shape", "[", "-", "1", "]", ".", "value", ")", "\n", "\n", "", "policy", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "activation", "=", "tf", ".", "nn", ".", "softmax", ")", "\n", "policy", "=", "tf", ".", "clip_by_value", "(", "policy", ",", "1e-10", ",", "1", "-", "1e-10", ")", "\n", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "value", ",", "(", "-", "1", ",", ")", ")", "\n", "advantage", "=", "tf", ".", "stop_gradient", "(", "reward", "-", "value", ")", "\n", "\n", "action_mask", "=", "tf", ".", "one_hot", "(", "action", ",", "self", ".", "num_actions", ")", "\n", "\n", "log_policy", "=", "tf", ".", "log", "(", "policy", "+", "1e-6", ")", "\n", "log_prob", "=", "tf", ".", "reduce_sum", "(", "log_policy", "*", "action_mask", ",", "axis", "=", "1", ")", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "advantage", "*", "log_prob", ")", "\n", "vf_loss", "=", "self", ".", "value_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "reward", "-", "value", ")", ")", "\n", "neg_entropy", "=", "self", ".", "ent_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "policy", "*", "log_policy", ",", "axis", "=", "1", ")", ")", "\n", "total_loss", "=", "pg_loss", "+", "vf_loss", "+", "neg_entropy", "\n", "\n", "# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "total_loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", ".", "minimize", "(", "total_loss", ")", "\n", "\n", "self", ".", "input_view", "=", "input_view", "\n", "self", ".", "input_feature", "=", "input_feature", "\n", "self", ".", "action", "=", "action", "\n", "self", ".", "reward", "=", "reward", "\n", "self", ".", "num_agent", "=", "num_agent", "\n", "\n", "self", ".", "policy", ",", "self", ".", "value", "=", "policy", ",", "value", "\n", "self", ".", "train_op", "=", "train_op", "\n", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", "=", "pg_loss", ",", "vf_loss", ",", "neg_entropy", "\n", "self", ".", "total_loss", "=", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic.infer_action": [[193, 221], ["len", "a2c.AdvantageActorCritic.sess.run", "numpy.arange", "numpy.empty", "range", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"infer action for a batch of agents\n\n        Parameters\n        ----------\n        raw_obs: tuple(numpy array, numpy array)\n            raw observation of agents tuple(views, features)\n        ids: numpy array\n            ids of agents\n\n        Returns\n        -------\n        acts: numpy array of int32\n            actions for agents\n        \"\"\"", "\n", "view", ",", "feature", "=", "raw_obs", "[", "0", "]", ",", "raw_obs", "[", "1", "]", "\n", "n", "=", "len", "(", "view", ")", "\n", "\n", "policy", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "policy", ",", "{", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "num_agent", ":", "n", "}", ")", "\n", "actions", "=", "np", ".", "arange", "(", "self", ".", "num_actions", ")", "\n", "\n", "ret", "=", "np", ".", "empty", "(", "n", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "ret", "[", "i", "]", "=", "np", ".", "random", ".", "choice", "(", "actions", ",", "p", "=", "policy", "[", "i", "]", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic.train": [[222, 287], ["sample_buffer.episodes", "a2c.AdvantageActorCritic.view_buf.resize", "a2c.AdvantageActorCritic.feature_buf.resize", "a2c.AdvantageActorCritic.action_buf.resize", "a2c.AdvantageActorCritic.reward_buf.resize", "sample_buffer.episodes", "a2c.AdvantageActorCritic.sess.run", "print", "len", "len", "numpy.array", "reversed", "numpy.mean", "a2c.AdvantageActorCritic.sess.run", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "train", "(", "self", ",", "sample_buffer", ",", "print_every", "=", "1000", ")", ":", "\n", "        ", "\"\"\"feed new data sample and train\n\n        Parameters\n        ----------\n        sample_buffer: magent.utility.EpisodesBuffer\n            buffer contains samples\n\n        Returns\n        -------\n        loss: list\n            policy gradient loss, critic loss, entropy loss\n        value: float\n            estimated state value\n        \"\"\"", "\n", "# calc buffer size", "\n", "n", "=", "0", "\n", "for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "n", "+=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "# resize to the new size", "\n", "", "self", ".", "view_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", ".", "resize", "(", "n", ")", "\n", "self", ".", "reward_buf", ".", "resize", "(", "n", ")", "\n", "view", ",", "feature", "=", "self", ".", "view_buf", ",", "self", ".", "feature_buf", "\n", "action", ",", "reward", "=", "self", ".", "action_buf", ",", "self", ".", "reward_buf", "\n", "\n", "ct", "=", "0", "\n", "gamma", "=", "self", ".", "reward_decay", "\n", "# collect episodes from multiple separate buffers to a continuous buffer", "\n", "for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", "\n", "m", "=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "r", ")", "\n", "keep", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "value", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "[", "v", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "input_feature", ":", "[", "f", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "num_agent", ":", "1", "\n", "}", ")", "[", "0", "]", "\n", "for", "i", "in", "reversed", "(", "range", "(", "m", ")", ")", ":", "\n", "                ", "keep", "=", "keep", "*", "gamma", "+", "r", "[", "i", "]", "\n", "r", "[", "i", "]", "=", "keep", "\n", "\n", "", "view", "[", "ct", ":", "ct", "+", "m", "]", "=", "v", "\n", "feature", "[", "ct", ":", "ct", "+", "m", "]", "=", "f", "\n", "action", "[", "ct", ":", "ct", "+", "m", "]", "=", "a", "\n", "reward", "[", "ct", ":", "ct", "+", "m", "]", "=", "r", "\n", "ct", "+=", "m", "\n", "\n", "", "assert", "n", "==", "ct", "\n", "\n", "# train", "\n", "_", ",", "pg_loss", ",", "vf_loss", ",", "ent_loss", ",", "state_value", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_op", ",", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", ",", "self", ".", "value", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "action", ":", "action", ",", "\n", "self", ".", "reward", ":", "reward", ",", "\n", "self", ".", "num_agent", ":", "len", "(", "reward", ")", "\n", "}", ")", "\n", "print", "(", "\"sample\"", ",", "n", ",", "pg_loss", ",", "vf_loss", ",", "ent_loss", ")", "\n", "\n", "return", "[", "pg_loss", ",", "vf_loss", ",", "ent_loss", "]", ",", "np", ".", "mean", "(", "state_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.a2c.AdvantageActorCritic.get_info": [[288, 296], ["None"], "methods", ["None"], ["", "def", "get_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"get information of the model\n\n        Returns\n        -------\n        info: string\n        \"\"\"", "\n", "return", "\"a2c train_time: %d\"", "%", "(", "self", ".", "train_ct", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.base.TFBaseModel.__init__": [[9, 23], ["magent.model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "subclass_name", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: magent.Environment\n        handle: handle (ctypes.c_int32)\n        name: str\n        subclass_name: str\n            name of subclass\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "subclass_name", "=", "subclass_name", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.base.TFBaseModel.save": [[24, 41], ["os.path.join", "tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save"], ["", "def", "save", "(", "self", ",", "dir_name", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"save model to dir\n\n        Parameters\n        ----------\n        dir_name: str\n            name of the directory\n        epoch: int\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_name", ")", "\n", "", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "self", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_name", ")", "\n", "", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.base.TFBaseModel.load": [[42, 77], ["os.path.join", "tensorflow.get_collection", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "tensorflow.get_default_graph", "tensorflow.get_default_graph.as_default", "tensorflow.get_collection", "os.path.join", "tensorflow.Graph().as_default", "tensorflow.Session", "tensorflow.train.import_meta_graph", "os.path.join", "tensorflow.get_collection", "sess.run", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "tensorflow.global_variables", "item.name.replace", "base.TFBaseModel.sess.run", "os.path.join", "tensorflow.global_variables_initializer", "os.path.join", "sess.run", "tensorflow.assign", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "load", "(", "self", ",", "dir_name", ",", "epoch", "=", "0", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"save model to dir\n\n        Parameters\n        ----------\n        dir_name: str\n            name of the directory\n        epoch: int\n        \"\"\"", "\n", "if", "name", "is", "None", "or", "name", "==", "self", ".", "name", ":", "# the name of saved model is the same as ours", "\n", "            ", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "self", ".", "name", ")", "\n", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "", "else", ":", "# load a checkpoint with different name", "\n", "            ", "backup_graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "kv_dict", "=", "{", "}", "\n", "\n", "# load checkpoint from another saved graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "                ", "tf", ".", "train", ".", "import_meta_graph", "(", "os", ".", "path", ".", "join", "(", "dir_name", ",", "name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", "+", "\".meta\"", ")", ")", "\n", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "name", ")", "\n", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "name", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "for", "item", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "                    ", "kv_dict", "[", "item", ".", "name", "]", "=", "sess", ".", "run", "(", "item", ")", "\n", "\n", "# assign to now graph", "\n", "", "", "backup_graph", ".", "as_default", "(", ")", "\n", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "for", "item", "in", "model_vars", ":", "\n", "                ", "old_name", "=", "item", ".", "name", ".", "replace", "(", "self", ".", "name", ",", "name", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "assign", "(", "item", ",", "kv_dict", "[", "old_name", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork.__init__": [[13, 149], ["base.TFBaseModel.__init__", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.square", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "dqn.DeepQNetwork.__init__.out_action"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\n", "batch_size", "=", "64", ",", "learning_rate", "=", "1e-4", ",", "reward_decay", "=", "0.99", ",", "\n", "train_freq", "=", "1", ",", "target_update", "=", "2000", ",", "memory_size", "=", "2", "**", "20", ",", "eval_obs", "=", "None", ",", "\n", "use_dueling", "=", "True", ",", "use_double", "=", "True", ",", "use_conv", "=", "True", ",", "\n", "custom_view_space", "=", "None", ",", "custom_feature_space", "=", "None", ",", "\n", "num_gpu", "=", "1", ",", "infer_batch_size", "=", "8192", ",", "network_type", "=", "0", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: Environment\n            environment\n        handle: Handle (ctypes.c_int32)\n            handle of this group, can be got by env.get_handles\n        name: str\n            name of this model\n        learning_rate: float\n        batch_size: int\n        reward_decay: float\n            reward_decay in TD\n        train_freq: int\n            mean training times of a sample\n        target_update: int\n            target will update every target_update batches\n        memory_size: int\n            weight of entropy loss in total loss\n        eval_obs: numpy array\n            evaluation set of observation\n        use_dueling: bool\n            whether use dueling q network\n        use_double: bool\n            whether use double q network\n        use_conv: bool\n            use convolution or fully connected layer as state encoder\n        num_gpu: int\n            number of gpu\n        infer_batch_size: int\n            batch size while inferring actions\n        custom_feature_space: tuple\n            customized feature space\n        custom_view_space: tuple\n            customized feature space\n        \"\"\"", "\n", "TFBaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\"tfdqn\"", ")", "\n", "# ======================== set config  ========================", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "view_space", "=", "custom_view_space", "or", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "custom_feature_space", "or", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "train_freq", "=", "train_freq", "# train time of every sample (s,a,r,s')", "\n", "self", ".", "target_update", "=", "target_update", "# target network update frequency", "\n", "self", ".", "eval_obs", "=", "eval_obs", "\n", "self", ".", "infer_batch_size", "=", "infer_batch_size", "# maximum batch size when infer actions,", "\n", "# change this to fit your GPU memory if you meet a OOM", "\n", "\n", "self", ".", "use_dueling", "=", "use_dueling", "\n", "self", ".", "use_double", "=", "use_double", "\n", "self", ".", "num_gpu", "=", "num_gpu", "\n", "self", ".", "network_type", "=", "network_type", "\n", "\n", "self", ".", "train_ct", "=", "0", "\n", "\n", "# ======================= build network =======================", "\n", "# input place holder", "\n", "self", ".", "target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "self", ".", "weight", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "\n", "self", ".", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "self", ".", "mask", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "self", ".", "eps", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "# e-greedy", "\n", "\n", "# build graph", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"eval_net_scope\"", ")", ":", "\n", "                ", "self", ".", "eval_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "qvalues", "=", "self", ".", "_create_network", "(", "self", ".", "input_view", ",", "self", ".", "input_feature", ",", "use_conv", ")", "\n", "\n", "", "if", "self", ".", "num_gpu", ">", "1", ":", "# build inference graph for multiple gpus", "\n", "                ", "self", ".", "_build_multi_gpu_infer", "(", "self", ".", "num_gpu", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_net_scope\"", ")", ":", "\n", "                ", "self", ".", "target_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "target_qvalues", "=", "self", ".", "_create_network", "(", "self", ".", "input_view", ",", "self", ".", "input_feature", ",", "use_conv", ")", "\n", "\n", "# loss", "\n", "", "", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "actions_onehot", "=", "tf", ".", "one_hot", "(", "self", ".", "action", ",", "self", ".", "num_actions", ")", "\n", "td_error", "=", "tf", ".", "square", "(", "self", ".", "target", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "self", ".", "actions_onehot", ",", "self", ".", "qvalues", ")", ",", "axis", "=", "1", ")", ")", "\n", "self", ".", "loss", "=", "tf", ".", "reduce_sum", "(", "td_error", "*", "self", ".", "mask", ")", "/", "tf", ".", "reduce_sum", "(", "self", ".", "mask", ")", "\n", "\n", "# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "# output action", "\n", "def", "out_action", "(", "qvalues", ")", ":", "\n", "            ", "best_action", "=", "tf", ".", "argmax", "(", "qvalues", ",", "axis", "=", "1", ")", "\n", "best_action", "=", "tf", ".", "to_int32", "(", "best_action", ")", "\n", "random_action", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "best_action", ")", ",", "0", ",", "self", ".", "num_actions", ",", "tf", ".", "int32", ")", "\n", "should_explore", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "best_action", ")", ",", "0", ",", "1", ")", "<", "self", ".", "eps", "\n", "return", "tf", ".", "where", "(", "should_explore", ",", "random_action", ",", "best_action", ")", "\n", "\n", "", "self", ".", "output_action", "=", "out_action", "(", "self", ".", "qvalues", ")", "\n", "if", "self", ".", "num_gpu", ">", "1", ":", "\n", "            ", "self", ".", "infer_out_action", "=", "[", "out_action", "(", "qvalue", ")", "for", "qvalue", "in", "self", ".", "infer_qvalues", "]", "\n", "\n", "# target network update op", "\n", "", "self", ".", "update_target_op", "=", "[", "]", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "target_scope_name", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "eval_scope_name", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "t_params", ")", ")", ":", "\n", "            ", "self", ".", "update_target_op", ".", "append", "(", "tf", ".", "assign", "(", "t_params", "[", "i", "]", ",", "e_params", "[", "i", "]", ")", ")", "\n", "\n", "# init tensorflow session", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "False", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# init replay buffers", "\n", "self", ".", "replay_buf_len", "=", "0", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "replay_buf_view", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "replay_buf_feature", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "replay_buf_action", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "replay_buf_reward", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ")", "\n", "self", ".", "replay_buf_terminal", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "self", ".", "replay_buf_mask", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ")", "\n", "# if mask[i] == 0, then the item is used for padding, not for training", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._create_network": [[151, 190], ["tensorflow.layers.dense", "tensorflow.concat", "tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reduce_mean", "numpy.prod", "numpy.prod"], "methods", ["None"], ["", "def", "_create_network", "(", "self", ",", "input_view", ",", "input_feature", ",", "use_conv", "=", "True", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "\"\"\"define computation graph of network\n\n        Parameters\n        ----------\n        input_view: tf.tensor\n        input_feature: tf.tensor\n            the input tensor\n        \"\"\"", "\n", "kernel_num", "=", "[", "32", ",", "32", "]", "\n", "hidden_size", "=", "[", "256", "]", "\n", "\n", "if", "use_conv", ":", "# convolution", "\n", "            ", "h_conv1", "=", "tf", ".", "layers", ".", "conv2d", "(", "input_view", ",", "filters", "=", "kernel_num", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"conv1\"", ",", "reuse", "=", "reuse", ")", "\n", "h_conv2", "=", "tf", ".", "layers", ".", "conv2d", "(", "h_conv1", ",", "filters", "=", "kernel_num", "[", "1", "]", ",", "kernel_size", "=", "3", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"conv2\"", ",", "reuse", "=", "reuse", ")", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "h_conv2", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "h_conv2", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"dense_view\"", ",", "reuse", "=", "reuse", ")", "\n", "", "else", ":", "# fully connected", "\n", "            ", "flatten_view", "=", "tf", ".", "reshape", "(", "input_view", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "input_view", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"dense_emb\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "dense", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "use_dueling", ":", "\n", "            ", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ",", "name", "=", "\"value\"", ",", "reuse", "=", "reuse", ")", "\n", "advantage", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "use_bias", "=", "False", ",", "\n", "name", "=", "\"advantage\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "qvalues", "=", "value", "+", "advantage", "-", "tf", ".", "reduce_mean", "(", "advantage", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "qvalues", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "name", "=", "\"value\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "", "return", "qvalues", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork.infer_action": [[191, 232], ["len", "min", "dqn.DeepQNetwork._infer_multi_gpu", "range", "numpy.concatenate", "numpy.concatenate.append", "dqn.DeepQNetwork.sess.run"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._infer_multi_gpu", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "policy", "=", "'e_greedy'", ",", "eps", "=", "0", ")", ":", "\n", "        ", "\"\"\"infer action for a batch of agents\n\n        Parameters\n        ----------\n        raw_obs: tuple(numpy array, numpy array)\n            raw observation of agents tuple(views, features)\n        ids: numpy array\n            ids of agents\n        policy: str\n            can be eps-greedy or greedy\n        eps: float\n            used when policy is eps-greedy\n\n        Returns\n        -------\n        acts: numpy array of int32\n            actions for agents\n        \"\"\"", "\n", "view", ",", "feature", "=", "raw_obs", "[", "0", "]", ",", "raw_obs", "[", "1", "]", "\n", "\n", "if", "policy", "==", "'e_greedy'", ":", "\n", "            ", "eps", "=", "eps", "\n", "", "elif", "policy", "==", "'greedy'", ":", "\n", "            ", "eps", "=", "0", "\n", "\n", "", "n", "=", "len", "(", "view", ")", "\n", "batch_size", "=", "min", "(", "n", ",", "self", ".", "infer_batch_size", ")", "\n", "\n", "if", "self", ".", "num_gpu", ">", "1", "and", "n", ">", "batch_size", ":", "# infer by multi gpu in parallel", "\n", "            ", "ret", "=", "self", ".", "_infer_multi_gpu", "(", "view", ",", "feature", ",", "ids", ",", "eps", ")", "\n", "", "else", ":", "# infer by splitting big batch in serial", "\n", "            ", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "batch_size", ")", ":", "\n", "                ", "beg", ",", "end", "=", "i", ",", "i", "+", "batch_size", "\n", "ret", ".", "append", "(", "self", ".", "sess", ".", "run", "(", "self", ".", "output_action", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", "[", "beg", ":", "end", "]", ",", "\n", "self", ".", "input_feature", ":", "feature", "[", "beg", ":", "end", "]", ",", "\n", "self", ".", "eps", ":", "eps", "}", ")", ")", "\n", "", "ret", "=", "np", ".", "concatenate", "(", "ret", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._calc_target": [[233, 249], ["len", "numpy.where", "dqn.DeepQNetwork.sess.run", "dqn.DeepQNetwork.sess.run", "numpy.max", "numpy.arange", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "_calc_target", "(", "self", ",", "next_view", ",", "next_feature", ",", "rewards", ",", "terminal", ")", ":", "\n", "        ", "\"\"\"calculate target value\"\"\"", "\n", "n", "=", "len", "(", "rewards", ")", "\n", "if", "self", ".", "use_double", ":", "\n", "            ", "t_qvalues", ",", "qvalues", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "target_qvalues", ",", "self", ".", "qvalues", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "input_view", ":", "next_view", ",", "\n", "self", ".", "input_feature", ":", "next_feature", "}", ")", "\n", "next_value", "=", "t_qvalues", "[", "np", ".", "arange", "(", "n", ")", ",", "np", ".", "argmax", "(", "qvalues", ",", "axis", "=", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "t_qvalues", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "target_qvalues", ",", "{", "self", ".", "input_view", ":", "next_view", ",", "\n", "self", ".", "input_feature", ":", "next_feature", "}", ")", "\n", "next_value", "=", "np", ".", "max", "(", "t_qvalues", ",", "axis", "=", "1", ")", "\n", "\n", "", "target", "=", "np", ".", "where", "(", "terminal", ",", "rewards", ",", "rewards", "+", "self", ".", "gamma", "*", "next_value", ")", "\n", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._add_to_replay_buffer": [[250, 276], ["sample_buffer.episodes", "min", "len", "numpy.ones", "numpy.zeros", "dqn.DeepQNetwork.replay_buf_view.put", "dqn.DeepQNetwork.replay_buf_feature.put", "dqn.DeepQNetwork.replay_buf_action.put", "dqn.DeepQNetwork.replay_buf_reward.put", "dqn.DeepQNetwork.replay_buf_terminal.put", "dqn.DeepQNetwork.replay_buf_mask.put"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put"], ["", "def", "_add_to_replay_buffer", "(", "self", ",", "sample_buffer", ")", ":", "\n", "        ", "\"\"\"add samples in sample_buffer to replay buffer\"\"\"", "\n", "n", "=", "0", "\n", "for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", "\n", "\n", "m", "=", "len", "(", "r", ")", "\n", "\n", "mask", "=", "np", ".", "ones", "(", "(", "m", ",", ")", ")", "\n", "terminal", "=", "np", ".", "zeros", "(", "(", "m", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "if", "episode", ".", "terminal", ":", "\n", "                ", "terminal", "[", "-", "1", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "mask", "[", "-", "1", "]", "=", "0", "\n", "\n", "", "self", ".", "replay_buf_view", ".", "put", "(", "v", ")", "\n", "self", ".", "replay_buf_feature", ".", "put", "(", "f", ")", "\n", "self", ".", "replay_buf_action", ".", "put", "(", "a", ")", "\n", "self", ".", "replay_buf_reward", ".", "put", "(", "r", ")", "\n", "self", ".", "replay_buf_terminal", ".", "put", "(", "terminal", ")", "\n", "self", ".", "replay_buf_mask", ".", "put", "(", "mask", ")", "\n", "\n", "n", "+=", "m", "\n", "\n", "", "self", ".", "replay_buf_len", "=", "min", "(", "self", ".", "memory_size", ",", "self", ".", "replay_buf_len", "+", "n", ")", "\n", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork.train": [[277, 347], ["dqn.DeepQNetwork._add_to_replay_buffer", "int", "print", "time.time", "range", "print", "numpy.random.choice", "dqn.DeepQNetwork.replay_buf_view.get", "dqn.DeepQNetwork.replay_buf_feature.get", "dqn.DeepQNetwork.replay_buf_action.get", "dqn.DeepQNetwork.replay_buf_reward.get", "dqn.DeepQNetwork.replay_buf_terminal.get", "dqn.DeepQNetwork.replay_buf_mask.get", "dqn.DeepQNetwork.replay_buf_view.get", "dqn.DeepQNetwork.replay_buf_feature.get", "dqn.DeepQNetwork._calc_target", "dqn.DeepQNetwork.sess.run", "time.time", "max", "dqn.DeepQNetwork._eval", "dqn.DeepQNetwork.sess.run", "print", "dqn.DeepQNetwork._eval"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._add_to_replay_buffer", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._calc_target", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval"], ["", "def", "train", "(", "self", ",", "sample_buffer", ",", "print_every", "=", "1000", ")", ":", "\n", "        ", "\"\"\" add new samples in sample_buffer to replay buffer and train\n\n        Parameters\n        ----------\n        sample_buffer: magent.utility.EpisodesBuffer\n            buffer contains samples\n        print_every: int\n            print log every print_every batches\n\n        Returns\n        -------\n        loss: float\n            bellman residual loss\n        value: float\n            estimated state value\n        \"\"\"", "\n", "add_num", "=", "self", ".", "_add_to_replay_buffer", "(", "sample_buffer", ")", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "total_loss", "=", "0", "\n", "\n", "n_batches", "=", "int", "(", "self", ".", "train_freq", "*", "add_num", "/", "batch_size", ")", "\n", "if", "n_batches", "==", "0", ":", "\n", "            ", "return", "0", ",", "0", "\n", "\n", "", "print", "(", "\"batch number: %d  add: %d  replay_len: %d/%d\"", "%", "\n", "(", "n_batches", ",", "add_num", ",", "self", ".", "replay_buf_len", ",", "self", ".", "memory_size", ")", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ct", "=", "0", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "# fetch a batch", "\n", "            ", "index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "replay_buf_len", "-", "1", ",", "batch_size", ")", "\n", "\n", "batch_view", "=", "self", ".", "replay_buf_view", ".", "get", "(", "index", ")", "\n", "batch_feature", "=", "self", ".", "replay_buf_feature", ".", "get", "(", "index", ")", "\n", "batch_action", "=", "self", ".", "replay_buf_action", ".", "get", "(", "index", ")", "\n", "batch_reward", "=", "self", ".", "replay_buf_reward", ".", "get", "(", "index", ")", "\n", "batch_terminal", "=", "self", ".", "replay_buf_terminal", ".", "get", "(", "index", ")", "\n", "batch_mask", "=", "self", ".", "replay_buf_mask", ".", "get", "(", "index", ")", "\n", "\n", "batch_next_view", "=", "self", ".", "replay_buf_view", ".", "get", "(", "index", "+", "1", ")", "\n", "batch_next_feature", "=", "self", ".", "replay_buf_feature", ".", "get", "(", "index", "+", "1", ")", "\n", "\n", "batch_target", "=", "self", ".", "_calc_target", "(", "batch_next_view", ",", "batch_next_feature", ",", "\n", "batch_reward", ",", "batch_terminal", ")", "\n", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "batch_view", ",", "\n", "self", ".", "input_feature", ":", "batch_feature", ",", "\n", "self", ".", "action", ":", "batch_action", ",", "\n", "self", ".", "target", ":", "batch_target", ",", "\n", "self", ".", "mask", ":", "batch_mask", "\n", "}", ")", "\n", "loss", "=", "ret", "[", "1", "]", "\n", "total_loss", "+=", "loss", "\n", "\n", "if", "ct", "%", "self", ".", "target_update", "==", "0", ":", "\n", "                ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_op", ")", "\n", "\n", "", "if", "ct", "%", "print_every", "==", "0", ":", "\n", "                ", "print", "(", "\"batch %5d,  loss %.6f, eval %.6f\"", "%", "(", "ct", ",", "loss", ",", "self", ".", "_eval", "(", "batch_target", ")", ")", ")", "\n", "", "ct", "+=", "1", "\n", "self", ".", "train_ct", "+=", "1", "\n", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "step_average", "=", "total_time", "/", "max", "(", "1.0", ",", "(", "ct", "/", "1000.0", ")", ")", "\n", "print", "(", "\"batches: %d,  total time: %.2f,  1k average: %.2f\"", "%", "(", "ct", ",", "total_time", ",", "step_average", ")", ")", "\n", "\n", "return", "total_loss", "/", "ct", "if", "ct", "!=", "0", "else", "0", ",", "self", ".", "_eval", "(", "batch_target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._eval": [[348, 356], ["numpy.mean", "numpy.mean", "dqn.DeepQNetwork.sess.run"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "_eval", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\"evaluate estimated q value\"\"\"", "\n", "if", "self", ".", "eval_obs", "is", "None", ":", "\n", "            ", "return", "np", ".", "mean", "(", "target", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "qvalues", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "self", ".", "eval_obs", "[", "0", "]", ",", "\n", "self", ".", "input_feature", ":", "self", ".", "eval_obs", "[", "1", "]", "\n", "}", ")", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork.clear_buffer": [[358, 367], ["dqn.DeepQNetwork.replay_buf_view.clear", "dqn.DeepQNetwork.replay_buf_feature.clear", "dqn.DeepQNetwork.replay_buf_action.clear", "dqn.DeepQNetwork.replay_buf_reward.clear", "dqn.DeepQNetwork.replay_buf_terminal.clear", "dqn.DeepQNetwork.replay_buf_mask.clear"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.clear"], ["", "", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "\"\"\"clear replay buffer\"\"\"", "\n", "self", ".", "replay_buf_len", "=", "0", "\n", "self", ".", "replay_buf_view", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_feature", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_action", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_reward", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_terminal", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_mask", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._build_multi_gpu_infer": [[368, 379], ["range", "dqn.DeepQNetwork.infer_input_view.append", "dqn.DeepQNetwork.infer_input_feature.append", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.device", "dqn.DeepQNetwork.infer_qvalues.append", "dqn.DeepQNetwork._create_network"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network"], ["", "def", "_build_multi_gpu_infer", "(", "self", ",", "num_gpu", ")", ":", "\n", "        ", "\"\"\"build inference graph for multi gpus\"\"\"", "\n", "self", ".", "infer_qvalues", "=", "[", "]", "\n", "self", ".", "infer_input_view", "=", "[", "]", "\n", "self", ".", "infer_input_feature", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_gpu", ")", ":", "\n", "            ", "self", ".", "infer_input_view", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "view_space", ")", ")", "\n", "self", ".", "infer_input_feature", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "feature_space", ")", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"eval_net_scope\"", ")", ",", "tf", ".", "device", "(", "\"/gpu:%d\"", "%", "i", ")", ":", "\n", "                ", "self", ".", "infer_qvalues", ".", "append", "(", "self", ".", "_create_network", "(", "self", ".", "infer_input_view", "[", "i", "]", ",", "\n", "self", ".", "infer_input_feature", "[", "i", "]", ",", "reuse", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.dqn.DeepQNetwork._infer_multi_gpu": [[380, 394], ["numpy.concatenate", "len", "range", "ret.extend", "dqn.DeepQNetwork.sess.run"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "", "", "def", "_infer_multi_gpu", "(", "self", ",", "view", ",", "feature", ",", "ids", ",", "eps", ")", ":", "\n", "        ", "\"\"\"infer action by multi gpu in parallel \"\"\"", "\n", "ret", "=", "[", "]", "\n", "beg", "=", "0", "\n", "while", "beg", "<", "len", "(", "view", ")", ":", "\n", "            ", "feed_dict", "=", "{", "self", ".", "eps", ":", "eps", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_gpu", ")", ":", "\n", "                ", "end", "=", "beg", "+", "self", ".", "infer_batch_size", "\n", "feed_dict", "[", "self", ".", "infer_input_view", "[", "i", "]", "]", "=", "view", "[", "beg", ":", "end", "]", "\n", "feed_dict", "[", "self", ".", "infer_input_feature", "[", "i", "]", "]", "=", "feature", "[", "beg", ":", "end", "]", "\n", "beg", "+=", "self", ".", "infer_batch_size", "\n", "\n", "", "ret", ".", "extend", "(", "self", ".", "sess", ".", "run", "(", "self", ".", "infer_out_action", ",", "feed_dict", "=", "feed_dict", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "ret", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork.__init__": [[14, 139], ["base.TFBaseModel.__init__", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.square", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.get_collection", "tensorflow.get_collection", "range", "tensorflow.ConfigProto", "tensorflow.Session", "drqn.DeepRecurrentQNetwork.sess.run", "collections.deque", "collections.deque", "numpy.empty", "numpy.empty", "numpy.empty", "env.get_view_space", "env.get_feature_space", "env.get_action_space", "tensorflow.variable_scope", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "zip", "len", "drqn.DeepRecurrentQNetwork.update_target_op.append", "tensorflow.global_variables_initializer", "numpy.empty", "numpy.empty", "tensorflow.variable_scope", "drqn.DeepRecurrentQNetwork._create_network", "tensorflow.variable_scope", "drqn.DeepRecurrentQNetwork._create_network", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.assign", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow.multiply"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\n", "batch_size", "=", "32", ",", "unroll_step", "=", "8", ",", "reward_decay", "=", "0.99", ",", "learning_rate", "=", "1e-4", ",", "\n", "train_freq", "=", "1", ",", "memory_size", "=", "20000", ",", "target_update", "=", "2000", ",", "eval_obs", "=", "None", ",", "\n", "use_dueling", "=", "True", ",", "use_double", "=", "True", ",", "use_episode_train", "=", "False", ",", "\n", "custom_view_space", "=", "None", ",", "custom_feature_space", "=", "None", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: Environment\n            environment\n        handle: Handle (ctypes.c_int32)\n            handle of this group, can be got by env.get_handles\n        name: str\n            name of this model\n        learning_rate: float\n        batch_size: int\n        reward_decay: float\n            reward_decay in TD\n        train_freq: int\n            mean training times of a sample\n        target_update: int\n            target will update every target_update batches\n        memory_size: int\n            weight of entropy loss in total loss\n        eval_obs: numpy array\n            evaluation set of observation\n        use_dueling: bool\n            whether use dueling q network\n        use_double: bool\n            whether use double q network\n        custom_feature_space: tuple\n            customized feature space\n        custom_view_space: tuple\n            customized feature space\n        \"\"\"", "\n", "TFBaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\"tfdrqn\"", ")", "\n", "# ======================== set config  ========================", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "view_space", "=", "custom_view_space", "or", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "custom_feature_space", "or", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "unroll_step", "=", "unroll_step", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "train_freq", "=", "train_freq", "# train time of every sample (s,a,r,s')", "\n", "self", ".", "target_update", "=", "target_update", "# target network update frequency", "\n", "self", ".", "eval_obs", "=", "eval_obs", "\n", "\n", "self", ".", "use_dueling", "=", "use_dueling", "\n", "self", ".", "use_double", "=", "use_double", "\n", "self", ".", "use_episode_train", "=", "use_episode_train", "\n", "self", ".", "skip_error", "=", "0", "\n", "self", ".", "pad_before_len", "=", "unroll_step", "-", "1", "\n", "\n", "self", ".", "agent_states", "=", "{", "}", "\n", "self", ".", "train_ct", "=", "0", "\n", "\n", "# ======================= build network =======================", "\n", "# input place holder", "\n", "self", ".", "target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "\n", "self", ".", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "view_space", ",", "name", "=", "\"input_view\"", ")", "\n", "self", ".", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "feature_space", ",", "name", "=", "\"input_feature\"", ")", "\n", "self", ".", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"action\"", ")", "\n", "self", ".", "mask", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"mask\"", ")", "\n", "\n", "self", ".", "batch_size_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "]", ")", "\n", "self", ".", "unroll_step_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "]", ")", "\n", "\n", "# build graph", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"eval_net_scope\"", ")", ":", "\n", "                ", "self", ".", "eval_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "qvalues", ",", "self", ".", "state_in", ",", "self", ".", "rnn_state", "=", "self", ".", "_create_network", "(", "self", ".", "input_view", ",", "self", ".", "input_feature", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_net_scope\"", ")", ":", "\n", "                ", "self", ".", "target_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "target_qvalues", ",", "self", ".", "target_state_in", ",", "self", ".", "target_rnn_state", "=", "self", ".", "_create_network", "(", "self", ".", "input_view", ",", "self", ".", "input_feature", ")", "\n", "\n", "# loss", "\n", "", "", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "actions_onehot", "=", "tf", ".", "one_hot", "(", "self", ".", "action", ",", "self", ".", "num_actions", ")", "\n", "self", ".", "td_error", "=", "tf", ".", "square", "(", "\n", "self", ".", "target", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "self", ".", "actions_onehot", ",", "self", ".", "qvalues", ")", ",", "axis", "=", "1", ")", "\n", ")", "\n", "#self.loss = tf.reduce_mean(self.td_error)", "\n", "self", ".", "loss", "=", "tf", ".", "reduce_sum", "(", "self", ".", "td_error", "*", "self", ".", "mask", ")", "/", "tf", ".", "reduce_sum", "(", "self", ".", "mask", ")", "\n", "\n", "# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "10.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "# target network update op", "\n", "self", ".", "update_target_op", "=", "[", "]", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "target_scope_name", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "eval_scope_name", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "t_params", ")", ")", ":", "\n", "            ", "self", ".", "update_target_op", ".", "append", "(", "tf", ".", "assign", "(", "t_params", "[", "i", "]", ",", "e_params", "[", "i", "]", ")", ")", "\n", "\n", "# init tensorflow session", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "False", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# init memory buffers", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "replay_buffer_lens", "=", "collections", ".", "deque", "(", "maxlen", "=", "memory_size", ")", "\n", "self", ".", "replay_buffer", "=", "collections", ".", "deque", "(", "maxlen", "=", "memory_size", ")", "\n", "# item format [views, features, actions, rewards, terminals, masks, len]", "\n", "\n", "# init training buffers", "\n", "self", ".", "view_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", ",", "self", ".", "reward_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "int32", ")", ",", "np", ".", "empty", "(", "1", ")", "\n", "self", ".", "terminal_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._create_network": [[140, 188], ["tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.contrib.rnn.GRUCell", "tensorflow.reshape", "tensorflow.contrib.rnn.GRUCell.zero_state", "tensorflow.nn.dynamic_rnn", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "numpy.prod", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "_create_network", "(", "self", ",", "input_view", ",", "input_feature", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "\"\"\"define computation graph of network\n\n        Parameters\n        ----------\n        input_view: tf.tensor\n        input_feature: tf.tensor\n            the input tensor\n        \"\"\"", "\n", "kernel_num", "=", "[", "32", ",", "32", "]", "\n", "hidden_size", "=", "[", "256", "]", "\n", "\n", "# conv", "\n", "h_conv1", "=", "tf", ".", "layers", ".", "conv2d", "(", "input_view", ",", "filters", "=", "kernel_num", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"conv1\"", ",", "reuse", "=", "reuse", ")", "\n", "h_conv2", "=", "tf", ".", "layers", ".", "conv2d", "(", "h_conv1", ",", "filters", "=", "kernel_num", "[", "1", "]", ",", "kernel_size", "=", "3", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"conv2\"", ",", "reuse", "=", "reuse", ")", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "h_conv2", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "h_conv2", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"dense_view\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"dense_emb\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "dense", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# RNN", "\n", "state_size", "=", "hidden_size", "[", "0", "]", "*", "2", "\n", "rnn_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "GRUCell", "(", "num_units", "=", "state_size", ")", "\n", "\n", "rnn_in", "=", "tf", ".", "reshape", "(", "dense", ",", "shape", "=", "[", "self", ".", "batch_size_ph", ",", "self", ".", "unroll_step_ph", ",", "state_size", "]", ")", "\n", "state_in", "=", "rnn_cell", ".", "zero_state", "(", "self", ".", "batch_size_ph", ",", "tf", ".", "float32", ")", "\n", "rnn", ",", "rnn_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "rnn_cell", ",", "inputs", "=", "rnn_in", ",", "dtype", "=", "tf", ".", "float32", ",", "initial_state", "=", "state_in", "\n", ")", "\n", "rnn", "=", "tf", ".", "reshape", "(", "rnn", ",", "shape", "=", "[", "-", "1", ",", "state_size", "]", ")", "\n", "\n", "if", "self", ".", "use_dueling", ":", "\n", "            ", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ",", "name", "=", "\"dense_value\"", ",", "reuse", "=", "reuse", ")", "\n", "advantage", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "use_bias", "=", "False", ",", "\n", "name", "=", "\"dense_advantage\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "qvalues", "=", "value", "+", "advantage", "-", "tf", ".", "reduce_mean", "(", "advantage", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "qvalues", "=", "tf", ".", "layers", ".", "dense", "(", "rnn", ",", "units", "=", "self", ".", "num_actions", ")", "\n", "\n", "", "self", ".", "state_size", "=", "state_size", "\n", "return", "qvalues", ",", "state_in", ",", "rnn_state", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._get_agent_states": [[189, 197], ["len", "numpy.empty", "numpy.zeros", "range", "drqn.DeepRecurrentQNetwork.agent_states.get"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get"], ["", "def", "_get_agent_states", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"get hidden state of agents\"\"\"", "\n", "n", "=", "len", "(", "ids", ")", "\n", "states", "=", "np", ".", "empty", "(", "[", "n", ",", "self", ".", "state_size", "]", ")", "\n", "default", "=", "np", ".", "zeros", "(", "[", "self", ".", "state_size", "]", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "states", "[", "i", "]", "=", "self", ".", "agent_states", ".", "get", "(", "ids", "[", "i", "]", ",", "default", ")", "\n", "", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._set_agent_states": [[198, 204], ["range", "len", "len", "len"], "methods", ["None"], ["", "def", "_set_agent_states", "(", "self", ",", "ids", ",", "states", ")", ":", "\n", "        ", "\"\"\"set hidden state for agents\"\"\"", "\n", "if", "len", "(", "ids", ")", "<=", "len", "(", "self", ".", "agent_states", ")", "*", "0.5", ":", "\n", "            ", "self", ".", "agent_states", "=", "{", "}", "\n", "", "for", "i", "in", "range", "(", "len", "(", "ids", ")", ")", ":", "\n", "            ", "self", ".", "agent_states", "[", "ids", "[", "i", "]", "]", "=", "states", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork.infer_action": [[205, 246], ["len", "drqn.DeepRecurrentQNetwork._get_agent_states", "drqn.DeepRecurrentQNetwork.sess.run", "drqn.DeepRecurrentQNetwork._set_agent_states", "numpy.argmax", "numpy.where.astype", "numpy.random.randint", "numpy.where", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._get_agent_states", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._set_agent_states"], ["", "", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "policy", "=", "'e_greedy'", ",", "eps", "=", "0", ")", ":", "\n", "        ", "\"\"\"infer action for a batch of agents\n\n        Parameters\n        ----------\n        raw_obs: tuple(numpy array, numpy array)\n            raw observation of agents tuple(views, features)\n        ids: numpy array\n            ids of agents\n        policy: str\n            can be eps-greedy or greedy\n        eps: float\n            used when policy is eps-greedy\n\n        Returns\n        -------\n        acts: numpy array of int32\n            actions for agents\n        \"\"\"", "\n", "view", ",", "feature", "=", "raw_obs", "[", "0", "]", ",", "raw_obs", "[", "1", "]", "\n", "n", "=", "len", "(", "ids", ")", "\n", "\n", "states", "=", "self", ".", "_get_agent_states", "(", "ids", ")", "\n", "qvalues", ",", "states", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "qvalues", ",", "self", ".", "rnn_state", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "state_in", ":", "states", ",", "\n", "self", ".", "batch_size_ph", ":", "n", ",", "\n", "self", ".", "unroll_step_ph", ":", "1", "\n", "}", ")", "\n", "self", ".", "_set_agent_states", "(", "ids", ",", "states", ")", "\n", "best_actions", "=", "np", ".", "argmax", "(", "qvalues", ",", "axis", "=", "1", ")", "\n", "\n", "if", "policy", "==", "'e_greedy'", ":", "\n", "            ", "random", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_actions", ",", "size", "=", "(", "n", ",", ")", ")", "\n", "cond", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "size", "=", "(", "n", ",", ")", ")", "<", "eps", "\n", "ret", "=", "np", ".", "where", "(", "cond", ",", "random", ",", "best_actions", ")", "\n", "", "elif", "policy", "==", "'greedy'", ":", "\n", "            ", "ret", "=", "best_actions", "\n", "\n", "", "return", "ret", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._calc_target": [[247, 278], ["len", "numpy.where", "drqn.DeepRecurrentQNetwork.sess.run", "drqn.DeepRecurrentQNetwork.sess.run", "numpy.max", "numpy.arange", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "_calc_target", "(", "self", ",", "next_view", ",", "next_feature", ",", "rewards", ",", "terminal", ",", "batch_size", ",", "unroll_step", ")", ":", "\n", "        ", "\"\"\"calculate target value\"\"\"", "\n", "n", "=", "len", "(", "rewards", ")", "\n", "if", "self", ".", "use_double", ":", "\n", "            ", "t_qvalues", ",", "qvalues", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "target_qvalues", ",", "self", ".", "qvalues", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "next_view", ",", "\n", "self", ".", "input_feature", ":", "next_feature", ",", "\n", "# self.state_in:        state_in,", "\n", "# self.target_state_in: state_in,", "\n", "self", ".", "batch_size_ph", ":", "batch_size", ",", "\n", "self", ".", "unroll_step_ph", ":", "unroll_step", "}", ")", "\n", "# ignore the first value (the first value is for computing correct hidden state)", "\n", "# t_qvalues = t_qvalues.reshape([-1, unroll_step, self.num_actions])", "\n", "# t_qvalues = t_qvalues[:, 1:, :].reshape([-1, self.num_actions])", "\n", "# qvalues = qvalues.reshape([-1, unroll_step, self.num_actions])", "\n", "# qvalues = qvalues[:, 1:, :].reshape([-1, self.num_actions])", "\n", "next_value", "=", "t_qvalues", "[", "np", ".", "arange", "(", "n", ")", ",", "np", ".", "argmax", "(", "qvalues", ",", "axis", "=", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "t_qvalues", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "target_qvalues", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "next_view", ",", "\n", "self", ".", "input_feature", ":", "next_feature", ",", "\n", "# self.target_state_in: state_in,", "\n", "self", ".", "batch_size_ph", ":", "batch_size", ",", "\n", "self", ".", "unroll_step_ph", ":", "unroll_step", "}", ")", "\n", "# t_qvalues = t_qvalues.reshape([-1, unroll_step, self.num_actions])", "\n", "# t_qvalues = t_qvalues[:,1:,:].reshape([-1, self.num_actions])", "\n", "next_value", "=", "np", ".", "max", "(", "t_qvalues", ",", "axis", "=", "1", ")", "\n", "\n", "", "target", "=", "np", ".", "where", "(", "terminal", ",", "rewards", ",", "rewards", "+", "self", ".", "gamma", "*", "next_value", ")", "\n", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._add_to_replay_buffer": [[279, 300], ["sample_buffer.episodes", "len", "numpy.ones", "numpy.zeros", "drqn.DeepRecurrentQNetwork.replay_buffer_lens.append", "drqn.DeepRecurrentQNetwork.replay_buffer.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "_add_to_replay_buffer", "(", "self", ",", "sample_buffer", ")", ":", "\n", "        ", "\"\"\"add samples in sample_buffer to replay buffer\"\"\"", "\n", "n", "=", "0", "\n", "for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", "\n", "\n", "m", "=", "len", "(", "r", ")", "\n", "\n", "mask", "=", "np", ".", "ones", "(", "(", "m", ",", ")", ")", "\n", "terminal", "=", "np", ".", "zeros", "(", "(", "m", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "if", "episode", ".", "terminal", ":", "\n", "                ", "terminal", "[", "-", "1", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "mask", "[", "-", "1", "]", "=", "0", "\n", "\n", "", "item", "=", "[", "v", ",", "f", ",", "a", ",", "r", ",", "terminal", ",", "mask", ",", "m", "]", "\n", "self", ".", "replay_buffer_lens", ".", "append", "(", "m", ")", "\n", "self", ".", "replay_buffer", ".", "append", "(", "item", ")", "\n", "\n", "n", "+=", "m", "\n", "", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork.train": [[301, 403], ["drqn.DeepRecurrentQNetwork._add_to_replay_buffer", "numpy.sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "int", "print", "time.time", "range", "print", "numpy.array", "numpy.random.choice", "range", "drqn.DeepRecurrentQNetwork._calc_target", "drqn.DeepRecurrentQNetwork.sess.run", "time.time", "max", "drqn.DeepRecurrentQNetwork._eval", "len", "len", "numpy.random.randint", "min", "drqn.DeepRecurrentQNetwork.sess.run", "print", "len", "drqn.DeepRecurrentQNetwork._eval"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._add_to_replay_buffer", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._calc_target", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval"], ["", "def", "train", "(", "self", ",", "sample_buffer", ",", "print_every", "=", "500", ")", ":", "\n", "        ", "\"\"\" add new samples in sample_buffer to replay buffer and train\n        do not keep hidden state (split episode into short sequences)\n\n        Parameters\n        ----------\n        sample_buffer: magent.utility.EpisodesBuffer\n            buffer contains samples\n        print_every: int\n            print log every print_every batches\n\n        Returns\n        -------\n        loss: float\n            bellman residual loss\n        value: float\n            estimated state value\n        \"\"\"", "\n", "add_num", "=", "self", ".", "_add_to_replay_buffer", "(", "sample_buffer", ")", "\n", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "unroll_step", "=", "self", ".", "unroll_step", "\n", "\n", "# calc sample weight of episodes (i.e. their lengths)", "\n", "replay_buffer", "=", "self", ".", "replay_buffer", "\n", "replay_lens_sum", "=", "np", ".", "sum", "(", "self", ".", "replay_buffer_lens", ")", "\n", "weight", "=", "np", ".", "array", "(", "self", ".", "replay_buffer_lens", ",", "dtype", "=", "np", ".", "float32", ")", "/", "replay_lens_sum", "\n", "\n", "n_batches", "=", "self", ".", "train_freq", "*", "add_num", "/", "(", "batch_size", "*", "(", "unroll_step", "-", "self", ".", "skip_error", ")", ")", "\n", "if", "n_batches", "==", "0", ":", "\n", "            ", "return", "0", ",", "0", "\n", "\n", "", "max_", "=", "batch_size", "*", "unroll_step", "\n", "batch_view", "=", "np", ".", "zeros", "(", "(", "max_", "+", "1", ",", ")", "+", "self", ".", "view_space", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_feature", "=", "np", ".", "zeros", "(", "(", "max_", "+", "1", ",", ")", "+", "self", ".", "feature_space", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_action", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "batch_reward", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_terminal", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "batch_mask", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# calc batch number", "\n", "n_batches", "=", "int", "(", "self", ".", "train_freq", "*", "add_num", "/", "(", "batch_size", "*", "(", "unroll_step", "-", "self", ".", "skip_error", ")", ")", ")", "\n", "print", "(", "\"batches: %d  add: %d  replay_len: %d/%d\"", "%", "\n", "(", "n_batches", ",", "add_num", ",", "len", "(", "self", ".", "replay_buffer", ")", ",", "self", ".", "memory_size", ")", ")", "\n", "\n", "ct", "=", "0", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "# train batches", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "            ", "indexes", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "replay_buffer", ")", ",", "self", ".", "batch_size", ",", "p", "=", "weight", ")", "\n", "\n", "batch_mask", "[", ":", "]", "=", "0", "\n", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "item", "=", "replay_buffer", "[", "indexes", "[", "j", "]", "]", "\n", "v", ",", "f", ",", "a", ",", "r", ",", "t", "=", "item", "[", "0", "]", ",", "item", "[", "1", "]", ",", "item", "[", "2", "]", ",", "item", "[", "3", "]", ",", "item", "[", "4", "]", "\n", "length", "=", "len", "(", "v", ")", "\n", "\n", "start", "=", "np", ".", "random", ".", "randint", "(", "length", ")", "\n", "real_step", "=", "min", "(", "length", "-", "start", ",", "unroll_step", ")", "\n", "\n", "beg", "=", "j", "*", "unroll_step", "\n", "batch_view", "[", "beg", ":", "beg", "+", "real_step", "]", "=", "v", "[", "start", ":", "start", "+", "real_step", "]", "\n", "batch_feature", "[", "beg", ":", "beg", "+", "real_step", "]", "=", "f", "[", "start", ":", "start", "+", "real_step", "]", "\n", "batch_action", "[", "beg", ":", "beg", "+", "real_step", "]", "=", "a", "[", "start", ":", "start", "+", "real_step", "]", "\n", "batch_reward", "[", "beg", ":", "beg", "+", "real_step", "]", "=", "r", "[", "start", ":", "start", "+", "real_step", "]", "\n", "batch_terminal", "[", "beg", ":", "beg", "+", "real_step", "]", "=", "t", "[", "start", ":", "start", "+", "real_step", "]", "\n", "batch_mask", "[", "beg", ":", "beg", "+", "real_step", "]", "=", "1.0", "\n", "\n", "if", "not", "t", "[", "start", "+", "real_step", "-", "1", "]", ":", "\n", "                    ", "batch_mask", "[", "beg", "+", "real_step", "-", "1", "]", "=", "0", "\n", "\n", "# collect trajectories from different IDs to a single buffer", "\n", "", "", "target", "=", "self", ".", "_calc_target", "(", "batch_view", "[", "1", ":", "]", ",", "batch_feature", "[", "1", ":", "]", ",", "\n", "batch_reward", ",", "batch_terminal", ",", "batch_size", ",", "unroll_step", ")", "\n", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "batch_view", "[", ":", "-", "1", "]", ",", "\n", "self", ".", "input_feature", ":", "batch_feature", "[", ":", "-", "1", "]", ",", "\n", "self", ".", "action", ":", "batch_action", ",", "\n", "self", ".", "target", ":", "target", ",", "\n", "self", ".", "mask", ":", "batch_mask", ",", "\n", "self", ".", "batch_size_ph", ":", "batch_size", ",", "\n", "self", ".", "unroll_step_ph", ":", "unroll_step", ",", "\n", "}", ")", "\n", "loss", "=", "ret", "[", "1", "]", "\n", "total_loss", "+=", "loss", "\n", "\n", "if", "ct", "%", "self", ".", "target_update", "==", "0", ":", "\n", "                ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_op", ")", "\n", "\n", "", "if", "ct", "%", "print_every", "==", "0", ":", "\n", "                ", "print", "(", "\"batch %5d, loss %.6f, qvalue %.6f\"", "%", "(", "ct", ",", "loss", ",", "self", ".", "_eval", "(", "target", ")", ")", ")", "\n", "", "ct", "+=", "1", "\n", "self", ".", "train_ct", "+=", "1", "\n", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "step_average", "=", "total_time", "/", "max", "(", "1.0", ",", "(", "ct", "/", "1000.0", ")", ")", "\n", "print", "(", "\"batches: %d,  total time: %.2f,  1k average: %.2f\"", "%", "(", "ct", ",", "total_time", ",", "step_average", ")", ")", "\n", "\n", "return", "total_loss", "/", "ct", "if", "ct", "!=", "0", "else", "0", ",", "self", ".", "_eval", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork.train_keep_hidden": [[404, 561], ["drqn.DeepRecurrentQNetwork._add_to_replay_buffer", "numpy.sum", "drqn.DeepRecurrentQNetwork._div_round", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "print", "time.time", "print", "numpy.array", "numpy.max", "numpy.random.choice", "enumerate", "to_sort.sort", "range", "len", "numpy.zeros", "enumerate", "range", "time.time", "max", "round", "drqn.DeepRecurrentQNetwork._eval", "len", "drqn.DeepRecurrentQNetwork._div_round", "max", "to_sort.append", "len", "pick_buffer[].reshape", "numpy.empty", "pick.reshape.reshape.reshape", "next_pick.reshape.reshape.reshape", "numpy.zeros_like", "drqn.DeepRecurrentQNetwork._calc_target", "drqn.DeepRecurrentQNetwork.sess.run", "len", "range", "range", "rows.append", "drqn.DeepRecurrentQNetwork._div_round", "len", "numpy.sum", "drqn.DeepRecurrentQNetwork.sess.run", "print", "row.append", "numpy.zeros.reshape", "sum", "drqn.DeepRecurrentQNetwork._eval"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._add_to_replay_buffer", "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._div_round", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval", "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._div_round", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._calc_target", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._div_round", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval"], ["", "def", "train_keep_hidden", "(", "self", ",", "sample_buffer", ",", "print_every", "=", "500", ")", ":", "\n", "        ", "\"\"\" add new samples in sample_buffer to replay buffer and train\n            keep hidden state (split episode into small sequence, but keep hidden states)\n            this means must train some episodes continuously not fully random.\n            to use this training scheme, you should also modify self._calc_target\n\n        Parameters\n        ----------\n        sample_buffer: magent.utility.EpisodesBuffer\n            buffer contains samples\n        print_every: int\n            print log every print_every batches\n\n        Returns\n        -------\n        loss: float\n            bellman residual loss\n        value: float\n            estimated state value\n        \"\"\"", "\n", "\n", "add_num", "=", "self", ".", "_add_to_replay_buffer", "(", "sample_buffer", ")", "\n", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "unroll_step", "=", "self", ".", "unroll_step", "\n", "\n", "# calc sample weight of episodes (i.e. their lengths)", "\n", "replay_buffer", "=", "self", ".", "replay_buffer", "\n", "replay_lens_sum", "=", "np", ".", "sum", "(", "self", ".", "replay_buffer_lens", ")", "\n", "weight", "=", "np", ".", "array", "(", "self", ".", "replay_buffer_lens", ",", "dtype", "=", "np", ".", "float32", ")", "/", "replay_lens_sum", "\n", "\n", "max_len", "=", "self", ".", "_div_round", "(", "np", ".", "max", "(", "self", ".", "replay_buffer_lens", ")", ",", "unroll_step", ")", "\n", "n_batches", "=", "self", ".", "train_freq", "*", "add_num", "/", "(", "batch_size", "*", "unroll_step", ")", "\n", "if", "n_batches", "==", "0", ":", "\n", "            ", "return", "0", ",", "0", "\n", "\n", "# allocate buffer", "\n", "", "max_", "=", "batch_size", "*", "max_len", "\n", "batch_view", "=", "np", ".", "zeros", "(", "(", "max_", "+", "1", ",", ")", "+", "self", ".", "view_space", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_feature", "=", "np", ".", "zeros", "(", "(", "max_", "+", "1", ",", ")", "+", "self", ".", "feature_space", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_action", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "batch_reward", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_terminal", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "batch_mask", "=", "np", ".", "zeros", "(", "(", "max_", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_hidden", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "self", ".", "state_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "batch_pick", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "max_len", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "pick_buffer", "=", "np", ".", "arange", "(", "max_", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "print", "(", "\"batches: %d  add: %d  replay_len: %d, %d/%d\"", "%", "\n", "(", "n_batches", ",", "add_num", ",", "replay_lens_sum", ",", "len", "(", "self", ".", "replay_buffer", ")", ",", "self", ".", "memory_size", ")", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "total_loss", "=", "0", "\n", "ct", "=", "0", "\n", "while", "ct", "<", "n_batches", ":", "\n", "# random sample agent episodes (sequence)", "\n", "            ", "indexs", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "replay_buffer", ")", ",", "self", ".", "batch_size", ",", "p", "=", "weight", ")", "\n", "train_length", "=", "0", "\n", "to_sort", "=", "[", "]", "\n", "\n", "# collect length and sort", "\n", "for", "j", ",", "index", "in", "enumerate", "(", "indexs", ")", ":", "\n", "                ", "length", "=", "replay_buffer", "[", "index", "]", "[", "-", "1", "]", "\n", "length", "=", "self", ".", "_div_round", "(", "length", ",", "unroll_step", ")", "\n", "train_length", "=", "max", "(", "train_length", ",", "length", ")", "\n", "to_sort", ".", "append", "(", "[", "index", ",", "length", "]", ")", "\n", "", "to_sort", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "\n", "# merge short episodes to long episodes (use greedy method)", "\n", "merged", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "rows", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "to_sort", ")", ")", ":", "\n", "                ", "if", "merged", "[", "j", "]", ":", "\n", "                    ", "continue", "\n", "", "row", "=", "[", "to_sort", "[", "j", "]", "[", "0", "]", "]", "\n", "now_len", "=", "to_sort", "[", "j", "]", "[", "1", "]", "\n", "if", "True", ":", "# use compress", "\n", "                    ", "for", "k", "in", "range", "(", "j", "+", "1", ",", "batch_size", ")", ":", "\n", "                        ", "if", "now_len", "+", "to_sort", "[", "k", "]", "[", "1", "]", "<=", "train_length", ":", "\n", "                            ", "row", ".", "append", "(", "to_sort", "[", "k", "]", "[", "0", "]", ")", "\n", "now_len", "+=", "to_sort", "[", "k", "]", "[", "1", "]", "\n", "merged", "[", "k", "]", "=", "True", "\n", "", "", "rows", ".", "append", "(", "row", ")", "\n", "", "", "n_rows", "=", "len", "(", "rows", ")", "\n", "\n", "batch_reset", "=", "np", ".", "zeros", "(", "(", "train_length", ",", "batch_size", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "batch_mask", "[", ":", "]", "=", "0", "\n", "\n", "# copy from replay buffer to batch buffer", "\n", "for", "j", ",", "row", "in", "enumerate", "(", "rows", ")", ":", "\n", "                ", "beg", "=", "j", "*", "max_len", "\n", "init_beg", "=", "beg", "\n", "# fill a row", "\n", "for", "index", "in", "row", ":", "\n", "                    ", "v", ",", "f", ",", "a", ",", "r", ",", "terminal", ",", "mask", ",", "x", "=", "replay_buffer", "[", "index", "]", "\n", "\n", "batch_reset", "[", "(", "beg", "-", "init_beg", ")", "/", "unroll_step", ",", "j", "]", "=", "True", "\n", "batch_view", "[", "beg", ":", "beg", "+", "x", "]", "=", "v", "\n", "batch_feature", "[", "beg", ":", "beg", "+", "x", "]", "=", "f", "\n", "batch_action", "[", "beg", ":", "beg", "+", "x", "]", "=", "a", "\n", "batch_reward", "[", "beg", ":", "beg", "+", "x", "]", "=", "r", "\n", "batch_terminal", "[", "beg", ":", "beg", "+", "x", "]", "=", "terminal", "\n", "batch_mask", "[", "beg", ":", "beg", "+", "x", "]", "=", "mask", "\n", "\n", "beg", "+=", "self", ".", "_div_round", "(", "x", ",", "unroll_step", ")", "\n", "\n", "# train steps", "\n", "", "", "for", "j", "in", "range", "(", "(", "train_length", "+", "unroll_step", "-", "1", ")", "/", "unroll_step", ")", ":", "\n", "                ", "batch_pick", "[", ":", "]", "=", "False", "\n", "batch_pick", "[", ":", "n_rows", ",", "j", "*", "unroll_step", ":", "(", "j", "+", "1", ")", "*", "unroll_step", "]", "=", "True", "\n", "\n", "pick", "=", "pick_buffer", "[", "batch_pick", ".", "reshape", "(", "-", "1", ")", "]", ".", "reshape", "(", "n_rows", ",", "unroll_step", ")", "\n", "next_pick", "=", "np", ".", "empty", "(", "(", "n_rows", ",", "unroll_step", "+", "1", ")", ",", "dtype", "=", "np", ".", "int32", ")", "# next pick choose one more state than pick", "\n", "next_pick", "[", ":", ",", ":", "unroll_step", "]", "=", "pick", "\n", "next_pick", "[", ":", ",", "unroll_step", "]", "=", "pick", "[", ":", ",", "-", "1", "]", "+", "1", "\n", "pick", "=", "pick", ".", "reshape", "(", "-", "1", ")", "\n", "next_pick", "=", "next_pick", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "steps", "=", "len", "(", "pick", ")", "/", "n_rows", "\n", "assert", "steps", ">", "0", "\n", "if", "np", ".", "sum", "(", "batch_mask", "[", "pick", "]", ")", "<", "1", ":", "\n", "                    ", "continue", "\n", "\n", "", "batch_hidden", "[", "batch_reset", "[", "j", "]", "]", "=", "np", ".", "zeros_like", "(", "batch_hidden", "[", "0", "]", ")", "\n", "\n", "batch_target", "=", "self", ".", "_calc_target", "(", "batch_view", "[", "next_pick", "]", ",", "batch_feature", "[", "next_pick", "]", ",", "\n", "batch_reward", "[", "pick", "]", ",", "batch_terminal", "[", "pick", "]", ",", "batch_hidden", "[", ":", "n_rows", "]", ",", "\n", "n_rows", ",", "steps", "+", "1", ")", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_op", ",", "self", ".", "loss", ",", "self", ".", "rnn_state", "]", ",", "\n", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "batch_view", "[", "pick", "]", ",", "\n", "self", ".", "input_feature", ":", "batch_feature", "[", "pick", "]", ",", "\n", "self", ".", "action", ":", "batch_action", "[", "pick", "]", ",", "\n", "self", ".", "target", ":", "batch_target", ",", "\n", "self", ".", "mask", ":", "batch_mask", "[", "pick", "]", ",", "\n", "self", ".", "state_in", ":", "batch_hidden", "[", ":", "n_rows", "]", ",", "\n", "self", ".", "batch_size_ph", ":", "n_rows", ",", "\n", "self", ".", "unroll_step_ph", ":", "steps", "\n", "}", ")", "\n", "loss", ",", "batch_hidden", "[", ":", "n_rows", "]", "=", "ret", "[", "1", "]", ",", "ret", "[", "2", "]", "\n", "total_loss", "+=", "loss", "\n", "\n", "if", "ct", "%", "self", ".", "target_update", "==", "0", ":", "\n", "                    ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_op", ")", "\n", "\n", "", "if", "ct", "%", "print_every", "==", "0", ":", "\n", "                    ", "print", "(", "\"batches %5d, mask %d/%d (%d), loss %.6f, qvalue %.6f\"", "%", "\n", "(", "ct", ",", "sum", "(", "batch_mask", ")", ",", "n_rows", "*", "train_length", ",", "n_rows", ",", "loss", ",", "self", ".", "_eval", "(", "batch_target", ")", ")", ")", "\n", "", "ct", "+=", "1", "\n", "self", ".", "train_ct", "+=", "1", "\n", "\n", "", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "step_average", "=", "total_time", "/", "max", "(", "1.0", ",", "(", "ct", "/", "1000.0", ")", ")", "\n", "print", "(", "\"batches: %d,  total time: %.2f,  1k average: %.2f\"", "%", "(", "ct", ",", "total_time", ",", "step_average", ")", ")", "\n", "\n", "return", "round", "(", "total_loss", "/", "ct", "if", "ct", "!=", "0", "else", "0", ",", "6", ")", ",", "self", ".", "_eval", "(", "batch_target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._div_round": [[562, 566], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_div_round", "(", "x", ",", "divisor", ")", ":", "\n", "        ", "\"\"\"round up to nearest integer that are divisible by divisor\"\"\"", "\n", "return", "(", "x", "+", "divisor", "-", "1", ")", "/", "divisor", "*", "divisor", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork._eval": [[567, 577], ["numpy.mean", "numpy.mean", "drqn.DeepRecurrentQNetwork.sess.run"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "_eval", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\"evaluate estimated q value\"\"\"", "\n", "if", "self", ".", "eval_obs", "is", "None", ":", "\n", "            ", "return", "np", ".", "mean", "(", "target", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "self", ".", "target_qvalues", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "self", ".", "eval_obs", "[", "0", "]", ",", "\n", "self", ".", "input_feature", ":", "self", ".", "eval_obs", "[", "1", "]", ",", "\n", "self", ".", "batch_size_ph", ":", "self", ".", "eval_obs", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "\n", "self", ".", "unroll_step_ph", ":", "1", "\n", "}", ")", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.tf_model.drqn.DeepRecurrentQNetwork.get_info": [[579, 582], ["None"], "methods", ["None"], ["", "", "def", "get_info", "(", "self", ")", ":", "\n", "        ", "\"\"\"get information of model\"\"\"", "\n", "return", "\"tfdrqn train_time: %d\"", "%", "(", "self", ".", "train_ct", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.config.forest.get_config": [[6, 35], ["gw.Config", "gw.Config.set", "gw.Config.set", "gw.Config.register_agent_type", "gw.Config.register_agent_type", "gw.Config.add_group", "gw.Config.add_group", "gw.CircleRange", "gw.CircleRange", "gw.CircleRange", "gw.CircleRange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group"], ["def", "get_config", "(", "map_size", ")", ":", "\n", "    ", "gw", "=", "magent", ".", "gridworld", "\n", "\n", "cfg", "=", "gw", ".", "Config", "(", ")", "\n", "\n", "cfg", ".", "set", "(", "{", "\"map_width\"", ":", "map_size", ",", "\"map_height\"", ":", "map_size", "}", ")", "\n", "cfg", ".", "set", "(", "{", "\"embedding_size\"", ":", "10", "}", ")", "\n", "\n", "deer", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"deer\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "5", ",", "'speed'", ":", "1", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "1", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "0", ")", ",", "\n", "'damage'", ":", "0", ",", "'step_recover'", ":", "0.2", ",", "\n", "'food_supply'", ":", "0", ",", "'kill_supply'", ":", "8", ",", "\n", "}", ")", "\n", "\n", "tiger", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"tiger\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "10", ",", "'speed'", ":", "1", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "4", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "1", ")", ",", "\n", "'damage'", ":", "3", ",", "'step_recover'", ":", "-", "0.5", ",", "\n", "'food_supply'", ":", "0", ",", "'kill_supply'", ":", "0", ",", "\n", "'step_reward'", ":", "1", ",", "'attack_penalty'", ":", "-", "0.1", ",", "\n", "}", ")", "\n", "\n", "deer_group", "=", "cfg", ".", "add_group", "(", "deer", ")", "\n", "tiger_group", "=", "cfg", ".", "add_group", "(", "tiger", ")", "\n", "\n", "return", "cfg", "\n", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.config.double_attack.get_config": [[8, 43], ["gw.Config", "gw.Config.set", "gw.Config.set", "gw.Config.register_agent_type", "gw.Config.register_agent_type", "gw.Config.add_group", "gw.Config.add_group", "gw.AgentSymbol", "gw.AgentSymbol", "gw.AgentSymbol", "gw.Event", "gw.Event", "gw.Config.add_reward_rule", "gw.CircleRange", "gw.CircleRange", "gw.CircleRange", "gw.CircleRange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule"], ["def", "get_config", "(", "map_size", ")", ":", "\n", "    ", "gw", "=", "magent", ".", "gridworld", "\n", "cfg", "=", "gw", ".", "Config", "(", ")", "\n", "\n", "cfg", ".", "set", "(", "{", "\"map_width\"", ":", "map_size", ",", "\"map_height\"", ":", "map_size", "}", ")", "\n", "cfg", ".", "set", "(", "{", "\"embedding_size\"", ":", "10", "}", ")", "\n", "\n", "deer", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"deer\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "5", ",", "'speed'", ":", "1", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "1", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "0", ")", ",", "\n", "'step_recover'", ":", "0.2", ",", "\n", "'kill_supply'", ":", "8", ",", "\n", "}", ")", "\n", "\n", "tiger", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"tiger\"", ",", "\n", "{", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "10", ",", "'speed'", ":", "1", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "4", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "1", ")", ",", "\n", "'damage'", ":", "1", ",", "'step_recover'", ":", "-", "0.2", ",", "\n", "}", ")", "\n", "\n", "deer_group", "=", "cfg", ".", "add_group", "(", "deer", ")", "\n", "tiger_group", "=", "cfg", ".", "add_group", "(", "tiger", ")", "\n", "\n", "a", "=", "gw", ".", "AgentSymbol", "(", "tiger_group", ",", "index", "=", "'any'", ")", "\n", "b", "=", "gw", ".", "AgentSymbol", "(", "tiger_group", ",", "index", "=", "'any'", ")", "\n", "c", "=", "gw", ".", "AgentSymbol", "(", "deer_group", ",", "index", "=", "'any'", ")", "\n", "\n", "# tigers get reward when they attack a deer simultaneously", "\n", "e1", "=", "gw", ".", "Event", "(", "a", ",", "'attack'", ",", "c", ")", "\n", "e2", "=", "gw", ".", "Event", "(", "b", ",", "'attack'", ",", "c", ")", "\n", "cfg", ".", "add_reward_rule", "(", "e1", "&", "e2", ",", "receiver", "=", "[", "a", ",", "b", "]", ",", "value", "=", "[", "1", ",", "1", "]", ")", "\n", "\n", "return", "cfg", "\n", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.config.battle.get_config": [[6, 34], ["gw.Config", "gw.Config.set", "gw.Config.set", "gw.Config.set", "gw.Config.register_agent_type", "gw.Config.add_group", "gw.Config.add_group", "gw.AgentSymbol", "gw.AgentSymbol", "gw.Config.add_reward_rule", "gw.Config.add_reward_rule", "gw.Event", "gw.Event", "gw.CircleRange", "gw.CircleRange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule"], ["import", "tensorflow", "as", "tf", "\n", "import", "numpy", "as", "np", "\n", "import", "magent", "\n", "\n", "from", "examples", ".", "battle_model", ".", "algo", "import", "spawn_ai", "\n", "from", "examples", ".", "battle_model", ".", "algo", "import", "tools", "\n", "from", "examples", ".", "battle_model", ".", "senario_battle", "import", "battle", "\n", "\n", "\n", "BASE_DIR", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "\n", "\n", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--algo'", ",", "type", "=", "str", ",", "choices", "=", "{", "'ac'", ",", "'mfac'", ",", "'mfq'", ",", "'il'", "}", ",", "help", "=", "'choose an algorithm from the preset'", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--oppo'", ",", "type", "=", "str", ",", "choices", "=", "{", "'ac'", ",", "'mfac'", ",", "'mfq'", ",", "'il'", "}", ",", "help", "=", "'indicate the opponent model'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_round'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'set the trainning round'", ")", "\n", "parser", ".", "add_argument", "(", "'--render'", ",", "action", "=", "'store_true'", ",", "help", "=", "'render or not (if true, will render every save)'", ")", "\n", "parser", ".", "add_argument", "(", "'--map_size'", ",", "type", "=", "int", ",", "default", "=", "40", ",", "help", "=", "'set the size of map'", ")", "# then the amount of agents is 64", "\n", "parser", ".", "add_argument", "(", "'--max_steps'", ",", "type", "=", "int", ",", "default", "=", "400", ",", "help", "=", "'set the max steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--idx'", ",", "nargs", "=", "'*'", ",", "required", "=", "True", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Initialize the environment", "\n", "env", "=", "magent", ".", "GridWorld", "(", "'battle'", ",", "map_size", "=", "args", ".", "map_size", ")", "\n", "env", ".", "set_render_dir", "(", "os", ".", "path", ".", "join", "(", "BASE_DIR", ",", "'examples/battle_model'", ",", "'build/render'", ")", ")", "\n", "handles", "=", "env", ".", "get_handles", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.config.pursuit.get_config": [[4, 34], ["gw.Config", "gw.Config.set", "gw.Config.register_agent_type", "gw.Config.register_agent_type", "gw.Config.add_group", "gw.Config.add_group", "gw.AgentSymbol", "gw.AgentSymbol", "gw.Config.add_reward_rule", "gw.Event", "gw.CircleRange", "gw.CircleRange", "gw.CircleRange", "gw.CircleRange"], "function", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.register_agent_type", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_group", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.add_reward_rule"], ["def", "get_config", "(", "map_size", ")", ":", "\n", "    ", "gw", "=", "magent", ".", "gridworld", "\n", "cfg", "=", "gw", ".", "Config", "(", ")", "\n", "\n", "cfg", ".", "set", "(", "{", "\"map_width\"", ":", "map_size", ",", "\"map_height\"", ":", "map_size", "}", ")", "\n", "\n", "predator", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"predator\"", ",", "\n", "{", "\n", "'width'", ":", "2", ",", "'length'", ":", "2", ",", "'hp'", ":", "1", ",", "'speed'", ":", "1", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "5", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "2", ")", ",", "\n", "'attack_penalty'", ":", "-", "0.2", "\n", "}", ")", "\n", "\n", "prey", "=", "cfg", ".", "register_agent_type", "(", "\n", "\"prey\"", ",", "\n", "{", "\n", "'width'", ":", "1", ",", "'length'", ":", "1", ",", "'hp'", ":", "1", ",", "'speed'", ":", "1.5", ",", "\n", "'view_range'", ":", "gw", ".", "CircleRange", "(", "4", ")", ",", "'attack_range'", ":", "gw", ".", "CircleRange", "(", "0", ")", "\n", "}", ")", "\n", "\n", "predator_group", "=", "cfg", ".", "add_group", "(", "predator", ")", "\n", "prey_group", "=", "cfg", ".", "add_group", "(", "prey", ")", "\n", "\n", "a", "=", "gw", ".", "AgentSymbol", "(", "predator_group", ",", "index", "=", "'any'", ")", "\n", "b", "=", "gw", ".", "AgentSymbol", "(", "prey_group", ",", "index", "=", "'any'", ")", "\n", "\n", "cfg", ".", "add_reward_rule", "(", "gw", ".", "Event", "(", "a", ",", "'attack'", ",", "b", ")", ",", "receiver", "=", "[", "a", ",", "b", "]", ",", "value", "=", "[", "1", ",", "-", "1", "]", ")", "\n", "\n", "return", "cfg", "\n", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.rushgather.RushGatherer.__init__": [[10, 18], ["magent.model.BaseModel.__init__", "env.get_action_space", "env.get_view_space", "env.get_view2attack"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_view2attack"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "n_action", "=", "env", ".", "get_action_space", "(", "handle", ")", "\n", "self", ".", "view_size", "=", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "attack_base", ",", "self", ".", "view2attack", "=", "env", ".", "get_view2attack", "(", "handle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.rushgather.RushGatherer.infer_action": [[19, 32], ["magent.c_lib.as_float_c_array", "magent.c_lib.as_float_c_array", "numpy.empty", "magent.c_lib.as_int32_c_array", "magent.c_lib.as_int32_c_array", "magent.c_lib._LIB.gather_infer_action"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array"], ["", "def", "infer_action", "(", "self", ",", "states", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "obs_buf", "=", "as_float_c_array", "(", "states", "[", "0", "]", ")", "\n", "hp_buf", "=", "as_float_c_array", "(", "states", "[", "1", "]", ")", "\n", "n", ",", "height", ",", "width", ",", "n_channel", "=", "states", "[", "0", "]", ".", "shape", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "act_buf", "=", "as_int32_c_array", "(", "buf", ")", "\n", "attack_base", "=", "self", ".", "attack_base", "\n", "\n", "view2attack_buf", "=", "as_int32_c_array", "(", "self", ".", "view2attack", ")", "\n", "\n", "_LIB", ".", "gather_infer_action", "(", "obs_buf", ",", "hp_buf", ",", "n", ",", "height", ",", "width", ",", "n_channel", ",", "\n", "act_buf", ",", "attack_base", ",", "view2attack_buf", ")", "\n", "return", "buf", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.runaway.RunawayPrey.__init__": [[10, 18], ["magent.model.BaseModel.__init__", "env.get_channel", "env.get_view2attack", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_view2attack"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "away_handle", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "\n", "self", ".", "away_channel", "=", "env", ".", "get_channel", "(", "away_handle", ")", "\n", "self", ".", "attack_base", ",", "_", "=", "env", ".", "get_view2attack", "(", "handle", ")", "\n", "self", ".", "move_back", "=", "4", "\n", "\n", "print", "(", "\"attack base\"", ",", "self", ".", "attack_base", ",", "\"away\"", ",", "self", ".", "away_channel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.runaway.RunawayPrey.infer_action": [[19, 28], ["magent.c_lib.as_float_c_array", "magent.c_lib.as_float_c_array", "numpy.empty", "magent.c_lib.as_int32_c_array", "magent.c_lib._LIB.runaway_infer_action"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array"], ["", "def", "infer_action", "(", "self", ",", "observations", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "obs_buf", "=", "as_float_c_array", "(", "observations", "[", "0", "]", ")", "\n", "hp_buf", "=", "as_float_c_array", "(", "observations", "[", "1", "]", ")", "\n", "n", ",", "height", ",", "width", ",", "n_channel", "=", "observations", "[", "0", "]", ".", "shape", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "act_buf", "=", "as_int32_c_array", "(", "buf", ")", "\n", "_LIB", ".", "runaway_infer_action", "(", "obs_buf", ",", "hp_buf", ",", "n", ",", "height", ",", "width", ",", "n_channel", ",", "\n", "self", ".", "attack_base", ",", "act_buf", ",", "self", ".", "away_channel", ",", "self", ".", "move_back", ")", "\n", "return", "buf", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.random.RandomActor.__init__": [[9, 15], ["magent.model.BaseModel.__init__", "env.get_action_space"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "n_action", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.random.RandomActor.infer_action": [[16, 20], ["len", "numpy.random.randint"], "methods", ["None"], ["", "def", "infer_action", "(", "self", ",", "obs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "num", "=", "len", "(", "obs", "[", "0", "]", ")", "\n", "actions", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "n_action", ",", "size", "=", "num", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "return", "actions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.rush.RushPredator.__init__": [[11, 19], ["magent.model.BaseModel.__init__", "env.get_channel", "env.get_view2attack", "print", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.GridWorld.get_view2attack"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "attack_handle", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "\n", "self", ".", "attack_channel", "=", "env", ".", "get_channel", "(", "attack_handle", ")", "\n", "self", ".", "attack_base", ",", "self", ".", "view2attack", "=", "env", ".", "get_view2attack", "(", "handle", ")", "\n", "\n", "print", "(", "\"attack_channel\"", ",", "self", ".", "attack_channel", ")", "\n", "print", "(", "\"view2attack\"", ",", "self", ".", "view2attack", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.rule_model.rush.RushPredator.infer_action": [[20, 34], ["magent.c_lib.as_float_c_array", "magent.c_lib.as_float_c_array", "numpy.empty", "magent.c_lib.as_int32_c_array", "magent.c_lib.as_int32_c_array", "magent.c_lib._LIB.rush_prey_infer_action", "ctypes.c_float"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_float_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array", "home.repos.pwc.inspect_result.mlii_mfrl.magent.c_lib.as_int32_c_array"], ["", "def", "infer_action", "(", "self", ",", "observations", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "obs_buf", "=", "as_float_c_array", "(", "observations", "[", "0", "]", ")", "\n", "hp_buf", "=", "as_float_c_array", "(", "observations", "[", "1", "]", ")", "\n", "n", ",", "height", ",", "width", ",", "n_channel", "=", "observations", "[", "0", "]", ".", "shape", "\n", "buf", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "act_buf", "=", "as_int32_c_array", "(", "buf", ")", "\n", "attack_channel", "=", "self", ".", "attack_channel", "\n", "attack_base", "=", "self", ".", "attack_base", "\n", "view2attack_buf", "=", "as_int32_c_array", "(", "self", ".", "view2attack", ")", "\n", "\n", "_LIB", ".", "rush_prey_infer_action", "(", "obs_buf", ",", "hp_buf", ",", "n", ",", "height", ",", "width", ",", "n_channel", ",", "\n", "act_buf", ",", "attack_channel", ",", "attack_base", ",", "\n", "view2attack_buf", ",", "ctypes", ".", "c_float", "(", "100.0", ")", ")", "\n", "return", "buf", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.a2c.AdvantageActorCritic.__init__": [[13, 101], ["base.MXBaseModel.__init__", "a2c.AdvantageActorCritic._get_ctx", "mxnet.sym.var", "mxnet.sym.var", "a2c.AdvantageActorCritic._create_network", "mxnet.sym.log", "mxnet.sym.BlockGrad", "mxnet.sym.MakeLoss", "mxnet.sym.Group", "mxnet.mod.Module", "a2c.AdvantageActorCritic.model.bind", "a2c.AdvantageActorCritic.model.init_params", "a2c.AdvantageActorCritic.model.init_optimizer", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "env.get_view_space", "env.get_feature_space", "env.get_action_space", "mxnet.sym.sum", "numpy.empty", "numpy.empty", "mxnet.init.Xavier"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.base.MXBaseModel._get_ctx", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space"], ["train_freq", "=", "1", ",", "value_coef", "=", "0.1", ",", "ent_coef", "=", "0.08", ",", "use_comm", "=", "False", ",", "\n", "custom_view_space", "=", "None", ",", "custom_feature_space", "=", "None", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: Environment\n            environment\n        handle: Handle (ctypes.c_int32)\n            handle of this group, can be got by env.get_handles\n        name: str\n            name of this model\n        learning_rate: float\n        batch_size: int\n        reward_decay: float\n            reward_decay in TD\n        eval_obs: numpy array\n            evaluation set of observation\n        train_freq: int\n            mean training times of a sample\n        ent_coef: float\n            weight of entropy loss in total loss\n        value_coef: float\n            weight of value loss in total loss\n        use_comm: bool\n            whether use CommNet\n        custom_feature_space: tuple\n            customized feature space\n        custom_view_space: tuple\n            customized feature space\n        \"\"\"", "\n", "TFBaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\"tfa2c\"", ")", "\n", "# ======================== set config  ========================", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "view_space", "=", "custom_view_space", "or", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "custom_feature_space", "or", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "self", ".", "reward_decay", "=", "reward_decay", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "train_freq", "=", "train_freq", "# train time of every sample (s,a,r,s')", "\n", "\n", "self", ".", "value_coef", "=", "value_coef", "# coefficient of value in the total loss", "\n", "self", ".", "ent_coef", "=", "ent_coef", "# coefficient of entropy in the total loss", "\n", "\n", "self", ".", "train_ct", "=", "0", "\n", "self", ".", "use_comm", "=", "use_comm", "\n", "\n", "# ======================= build network =======================", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "self", ".", "_create_network", "(", "self", ".", "view_space", ",", "self", ".", "feature_space", ")", "\n", "\n", "# init tensorflow session", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "False", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# init training buffers", "\n", "self", ".", "view_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "reward_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "def", "_commnet_block", "(", "self", ",", "n", ",", "hidden", ",", "skip", ",", "name", ",", "hidden_size", ")", ":", "\n", "        ", "\"\"\"a block of CommNet\n\n        Parameters\n        ----------\n        n: int\n            number of agent\n        hidden: tf.tensor\n            hidden layer input\n        skip: tf.tensor\n            skip connection\n        name: str\n        hidden_size: int\n        \"\"\"", "\n", "mask", "=", "(", "tf", ".", "ones", "(", "(", "n", ",", "n", ")", ")", "-", "tf", ".", "eye", "(", "n", ")", ")", "\n", "mask", "*=", "tf", ".", "where", "(", "n", ">", "1", ",", "1.0", "/", "(", "tf", ".", "cast", "(", "n", ",", "tf", ".", "float32", ")", "-", "1.0", ")", ",", "0", ")", "\n", "\n", "C", "=", "tf", ".", "get_variable", "(", "name", "+", "\"_C\"", ",", "shape", "=", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "H", "=", "tf", ".", "get_variable", "(", "name", "+", "\"_H\"", ",", "shape", "=", "(", "hidden_size", ",", "hidden_size", ")", ")", "\n", "\n", "message", "=", "tf", ".", "matmul", "(", "mask", ",", "hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.a2c.AdvantageActorCritic._create_network": [[105, 144], ["mxnet.sym.flatten", "mxnet.sym.FullyConnected", "mxnet.sym.Activation", "mxnet.sym.FullyConnected", "mxnet.sym.Activation", "mxnet.sym.FullyConnected", "mxnet.sym.SoftmaxActivation", "mxnet.sym.clip", "mxnet.sym.FullyConnected", "mxnet.sym.Convolution", "mxnet.sym.Activation", "mxnet.sym.Convolution", "mxnet.sym.Activation", "mxnet.sym.flatten", "mxnet.sym.FullyConnected", "mxnet.sym.Activation"], "methods", ["None"], ["        ", "\"\"\" CommNet Learning Multiagent Communication with Backpropagation by S. Sukhbaatar et al. NIPS 2016\n\n        Parameters\n        ----------\n        n: int\n            number of agent\n        hidden_size: int\n        n_step: int\n            communication step\n\n        Returns\n        -------\n        h: tf.tensor\n            hidden units after CommNet\n        \"\"\"", "\n", "skip", "=", "dense", "\n", "\n", "h", "=", "dense", "\n", "for", "i", "in", "range", "(", "n_step", ")", ":", "\n", "            ", "h", "=", "self", ".", "_commnet_block", "(", "n", ",", "h", ",", "skip", ",", "\"step_%d\"", "%", "i", ",", "hidden_size", ")", "\n", "\n", "", "return", "h", "\n", "\n", "", "def", "_create_network", "(", "self", ",", "view_space", ",", "feature_space", ")", ":", "\n", "        ", "\"\"\"define computation graph of network\n\n        Parameters\n        ----------\n        view_space: tuple\n        feature_space: tuple\n            the input shape\n        \"\"\"", "\n", "# input", "\n", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "view_space", ")", "\n", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "feature_space", ")", "\n", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "reward", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "num_agent", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "]", ")", "\n", "\n", "kernel_num", "=", "[", "32", ",", "32", "]", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.a2c.AdvantageActorCritic.infer_action": [[145, 173], ["len", "numpy.empty", "a2c.AdvantageActorCritic._reset_bind_size", "mxnet.io.DataBatch", "a2c.AdvantageActorCritic.model.forward", "[].asnumpy", "numpy.arange", "range", "numpy.random.choice", "mxnet.nd.array", "mxnet.nd.array", "a2c.AdvantageActorCritic.model.get_outputs"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size"], ["hidden_size", "=", "[", "256", "]", "\n", "\n", "# fully connected", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "input_view", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "input_view", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "dense", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "dense", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "hidden_size", "[", "0", "]", "*", "2", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "if", "self", ".", "use_comm", ":", "\n", "            ", "dense", "=", "self", ".", "_commnet", "(", "num_agent", ",", "dense", ",", "dense", ".", "shape", "[", "-", "1", "]", ".", "value", ")", "\n", "\n", "", "policy", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "activation", "=", "tf", ".", "nn", ".", "softmax", ")", "\n", "policy", "=", "tf", ".", "clip_by_value", "(", "policy", ",", "1e-10", ",", "1", "-", "1e-10", ")", "\n", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "value", ",", "(", "-", "1", ",", ")", ")", "\n", "advantage", "=", "tf", ".", "stop_gradient", "(", "reward", "-", "value", ")", "\n", "\n", "action_mask", "=", "tf", ".", "one_hot", "(", "action", ",", "self", ".", "num_actions", ")", "\n", "\n", "log_policy", "=", "tf", ".", "log", "(", "policy", "+", "1e-6", ")", "\n", "log_prob", "=", "tf", ".", "reduce_sum", "(", "log_policy", "*", "action_mask", ",", "axis", "=", "1", ")", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "advantage", "*", "log_prob", ")", "\n", "vf_loss", "=", "self", ".", "value_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "reward", "-", "value", ")", ")", "\n", "neg_entropy", "=", "self", ".", "ent_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "policy", "*", "log_policy", ",", "axis", "=", "1", ")", ")", "\n", "total_loss", "=", "pg_loss", "+", "vf_loss", "+", "neg_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.a2c.AdvantageActorCritic.train": [[174, 271], ["sample_buffer.episodes", "a2c.AdvantageActorCritic.view_buf.resize", "a2c.AdvantageActorCritic.feature_buf.resize", "a2c.AdvantageActorCritic.action_buf.resize", "a2c.AdvantageActorCritic.value_buf.resize", "a2c.AdvantageActorCritic.advantage_buf.resize", "sample_buffer.episodes", "len", "numpy.zeros", "mxnet.nd.array", "mxnet.nd.array", "mxnet.io.DataBatch", "a2c.AdvantageActorCritic._reset_bind_size", "a2c.AdvantageActorCritic.model.forward", "a2c.AdvantageActorCritic.model.backward", "a2c.AdvantageActorCritic.model.update", "a2c.AdvantageActorCritic.model.get_outputs", "numpy.mean", "numpy.mean", "print", "len", "a2c.AdvantageActorCritic._reset_bind_size", "mxnet.io.DataBatch", "a2c.AdvantageActorCritic.model.forward", "[].asnumpy().flatten", "numpy.empty", "reversed", "mxnet.nd.mean().asnumpy", "log_policy.asnumpy", "numpy.mean.asnumpy", "numpy.mean", "len", "range", "numpy.square", "len", "[].asnumpy", "numpy.arange", "mxnet.nd.array", "mxnet.nd.array", "mxnet.nd.mean", "numpy.arange", "mxnet.nd.array", "mxnet.nd.array", "a2c.AdvantageActorCritic.model.get_outputs"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.update", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size"], ["# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "total_loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", ".", "minimize", "(", "total_loss", ")", "\n", "\n", "self", ".", "input_view", "=", "input_view", "\n", "self", ".", "input_feature", "=", "input_feature", "\n", "self", ".", "action", "=", "action", "\n", "self", ".", "reward", "=", "reward", "\n", "self", ".", "num_agent", "=", "num_agent", "\n", "\n", "self", ".", "policy", ",", "self", ".", "value", "=", "policy", ",", "value", "\n", "self", ".", "train_op", "=", "train_op", "\n", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", "=", "pg_loss", ",", "vf_loss", ",", "neg_entropy", "\n", "self", ".", "total_loss", "=", "total_loss", "\n", "\n", "", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"infer action for a batch of agents\n\n        Parameters\n        ----------\n        raw_obs: tuple(numpy array, numpy array)\n            raw observation of agents tuple(views, features)\n        ids: numpy array\n            ids of agents\n\n        Returns\n        -------\n        acts: numpy array of int32\n            actions for agents\n        \"\"\"", "\n", "view", ",", "feature", "=", "raw_obs", "[", "0", "]", ",", "raw_obs", "[", "1", "]", "\n", "n", "=", "len", "(", "view", ")", "\n", "\n", "policy", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "policy", ",", "{", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "num_agent", ":", "n", "}", ")", "\n", "actions", "=", "np", ".", "arange", "(", "self", ".", "num_actions", ")", "\n", "\n", "ret", "=", "np", ".", "empty", "(", "n", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "ret", "[", "i", "]", "=", "np", ".", "random", ".", "choice", "(", "actions", ",", "p", "=", "policy", "[", "i", "]", ")", "\n", "\n", "", "return", "ret", "\n", "\n", "", "def", "train", "(", "self", ",", "sample_buffer", ",", "print_every", "=", "1000", ")", ":", "\n", "        ", "\"\"\"feed new data sample and train\n\n        Parameters\n        ----------\n        sample_buffer: magent.utility.EpisodesBuffer\n            buffer contains samples\n\n        Returns\n        -------\n        loss: list\n            policy gradient loss, critic loss, entropy loss\n        value: float\n            estimated state value\n        \"\"\"", "\n", "# calc buffer size", "\n", "n", "=", "0", "\n", "for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "n", "+=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "# resize to the new size", "\n", "", "self", ".", "view_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", ".", "resize", "(", "n", ")", "\n", "self", ".", "reward_buf", ".", "resize", "(", "n", ")", "\n", "view", ",", "feature", "=", "self", ".", "view_buf", ",", "self", ".", "feature_buf", "\n", "action", ",", "reward", "=", "self", ".", "action_buf", ",", "self", ".", "reward_buf", "\n", "\n", "ct", "=", "0", "\n", "gamma", "=", "self", ".", "reward_decay", "\n", "# collect episodes from multiple separate buffers to a continuous buffer", "\n", "for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", "\n", "m", "=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "r", ")", "\n", "keep", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "value", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "[", "v", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "input_feature", ":", "[", "f", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "num_agent", ":", "1", "\n", "}", ")", "[", "0", "]", "\n", "for", "i", "in", "reversed", "(", "range", "(", "m", ")", ")", ":", "\n", "                ", "keep", "=", "keep", "*", "gamma", "+", "r", "[", "i", "]", "\n", "r", "[", "i", "]", "=", "keep", "\n", "\n", "", "view", "[", "ct", ":", "ct", "+", "m", "]", "=", "v", "\n", "feature", "[", "ct", ":", "ct", "+", "m", "]", "=", "f", "\n", "action", "[", "ct", ":", "ct", "+", "m", "]", "=", "a", "\n", "reward", "[", "ct", ":", "ct", "+", "m", "]", "=", "r", "\n", "ct", "+=", "m", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.a2c.AdvantageActorCritic._reset_bind_size": [[272, 288], ["a2c.AdvantageActorCritic.model.reshape"], "methods", ["None"], ["\n", "", "assert", "n", "==", "ct", "\n", "\n", "# train", "\n", "_", ",", "pg_loss", ",", "vf_loss", ",", "ent_loss", ",", "state_value", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_op", ",", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", ",", "self", ".", "value", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "action", ":", "action", ",", "\n", "self", ".", "reward", ":", "reward", ",", "\n", "self", ".", "num_agent", ":", "len", "(", "reward", ")", "\n", "}", ")", "\n", "print", "(", "\"sample\"", ",", "n", ",", "pg_loss", ",", "vf_loss", ",", "ent_loss", ")", "\n", "\n", "return", "[", "pg_loss", ",", "vf_loss", ",", "ent_loss", "]", ",", "np", ".", "mean", "(", "state_value", ")", "\n", "\n", "", "def", "get_info", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.a2c.AdvantageActorCritic.get_info": [[290, 298], ["None"], "methods", ["None"], ["\n", "return", "\"a2c train_time: %d\"", "%", "(", "self", ".", "train_ct", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.base.MXBaseModel.__init__": [[9, 23], ["magent.model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "subclass_name", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: magent.Environment\n        handle: handle (ctypes.c_int32)\n        name: str\n        subclass_name: str\n            name of subclass\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "subclass_name", "=", "subclass_name", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.base.MXBaseModel._get_ctx": [[24, 35], ["magent.utility.has_gpu", "mxnet.gpu", "mxnet.cpu"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.utility.has_gpu"], ["", "def", "save", "(", "self", ",", "dir_name", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"save model to dir\n\n        Parameters\n        ----------\n        dir_name: str\n            name of the directory\n        epoch: int\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_name", ")", "\n", "", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "self", ".", "name", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.base.MXBaseModel.save": [[36, 52], ["os.path.join", "os.path.join", "base.MXBaseModel.model.save_checkpoint", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir"], "methods", ["None"], ["if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_name", ")", "\n", "", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "\n", "", "def", "load", "(", "self", ",", "dir_name", ",", "epoch", "=", "0", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"save model to dir\n\n        Parameters\n        ----------\n        dir_name: str\n            name of the directory\n        epoch: int\n        \"\"\"", "\n", "if", "name", "is", "None", "or", "name", "==", "self", ".", "name", ":", "# the name of saved model is the same as ours", "\n", "            ", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "self", ".", "name", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.base.MXBaseModel.load": [[53, 67], ["os.path.join", "os.path.join", "mxnet.model.load_checkpoint", "base.MXBaseModel.model.set_params"], "methods", ["None"], ["model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "", "else", ":", "# load a checkpoint with different name", "\n", "            ", "backup_graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "kv_dict", "=", "{", "}", "\n", "\n", "# load checkpoint from another saved graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "                ", "tf", ".", "train", ".", "import_meta_graph", "(", "os", ".", "path", ".", "join", "(", "dir_name", ",", "name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", "+", "\".meta\"", ")", ")", "\n", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "name", ")", "\n", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "name", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.__init__": [[12, 131], ["base.MXBaseModel.__init__", "dqn.DeepQNetwork._get_ctx", "mxnet.sym.var", "mxnet.sym.var", "mxnet.sym.var", "mxnet.sym.var", "mxnet.sym.var", "dqn.DeepQNetwork._create_network", "mxnet.sym.one_hot", "mxnet.sym.square", "mxnet.sym.MakeLoss", "mxnet.sym.BlockGrad", "mxnet.sym.Group", "mxnet.mod.Module", "mxnet.mod.Module", "dqn.DeepQNetwork.model.bind", "dqn.DeepQNetwork.target_model.bind", "dqn.DeepQNetwork.model.init_params", "dqn.DeepQNetwork.model.init_optimizer", "dqn.DeepQNetwork._copy_network", "common.ReplayBuffer", "common.ReplayBuffer", "common.ReplayBuffer", "common.ReplayBuffer", "common.ReplayBuffer", "common.ReplayBuffer", "env.get_view_space", "env.get_feature_space", "env.get_action_space", "range", "mxnet.sym.sum", "mxnet.sym.sum", "mxnet.gpu", "dqn.DeepQNetwork.ctx.append", "mxnet.sym.sum", "mxnet.init.Xavier", "mxnet.gpu"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.base.MXBaseModel._get_ctx", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._copy_network", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["class", "DeepQNetwork", "(", "TFBaseModel", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\n", "batch_size", "=", "64", ",", "learning_rate", "=", "1e-4", ",", "reward_decay", "=", "0.99", ",", "\n", "train_freq", "=", "1", ",", "target_update", "=", "2000", ",", "memory_size", "=", "2", "**", "20", ",", "eval_obs", "=", "None", ",", "\n", "use_dueling", "=", "True", ",", "use_double", "=", "True", ",", "use_conv", "=", "True", ",", "\n", "custom_view_space", "=", "None", ",", "custom_feature_space", "=", "None", ",", "\n", "num_gpu", "=", "1", ",", "infer_batch_size", "=", "8192", ",", "network_type", "=", "0", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: Environment\n            environment\n        handle: Handle (ctypes.c_int32)\n            handle of this group, can be got by env.get_handles\n        name: str\n            name of this model\n        learning_rate: float\n        batch_size: int\n        reward_decay: float\n            reward_decay in TD\n        train_freq: int\n            mean training times of a sample\n        target_update: int\n            target will update every target_update batches\n        memory_size: int\n            weight of entropy loss in total loss\n        eval_obs: numpy array\n            evaluation set of observation\n        use_dueling: bool\n            whether use dueling q network\n        use_double: bool\n            whether use double q network\n        use_conv: bool\n            use convolution or fully connected layer as state encoder\n        num_gpu: int\n            number of gpu\n        infer_batch_size: int\n            batch size while inferring actions\n        custom_feature_space: tuple\n            customized feature space\n        custom_view_space: tuple\n            customized feature space\n        \"\"\"", "\n", "TFBaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "\"tfdqn\"", ")", "\n", "# ======================== set config  ========================", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "handle", "=", "handle", "\n", "self", ".", "view_space", "=", "custom_view_space", "or", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "custom_feature_space", "or", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "train_freq", "=", "train_freq", "# train time of every sample (s,a,r,s')", "\n", "self", ".", "target_update", "=", "target_update", "# target network update frequency", "\n", "self", ".", "eval_obs", "=", "eval_obs", "\n", "self", ".", "infer_batch_size", "=", "infer_batch_size", "# maximum batch size when infer actions,", "\n", "# change this to fit your GPU memory if you meet a OOM", "\n", "\n", "self", ".", "use_dueling", "=", "use_dueling", "\n", "self", ".", "use_double", "=", "use_double", "\n", "self", ".", "num_gpu", "=", "num_gpu", "\n", "self", ".", "network_type", "=", "network_type", "\n", "\n", "self", ".", "train_ct", "=", "0", "\n", "\n", "# ======================= build network =======================", "\n", "# input place holder", "\n", "self", ".", "target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "self", ".", "weight", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "\n", "self", ".", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "self", ".", "mask", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "self", ".", "eps", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "# e-greedy", "\n", "\n", "# build graph", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"eval_net_scope\"", ")", ":", "\n", "                ", "self", ".", "eval_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "qvalues", "=", "self", ".", "_create_network", "(", "self", ".", "input_view", ",", "self", ".", "input_feature", ",", "use_conv", ")", "\n", "\n", "", "if", "self", ".", "num_gpu", ">", "1", ":", "# build inference graph for multiple gpus", "\n", "                ", "self", ".", "_build_multi_gpu_infer", "(", "self", ".", "num_gpu", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"target_net_scope\"", ")", ":", "\n", "                ", "self", ".", "target_scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "target_qvalues", "=", "self", ".", "_create_network", "(", "self", ".", "input_view", ",", "self", ".", "input_feature", ",", "use_conv", ")", "\n", "\n", "# loss", "\n", "", "", "self", ".", "gamma", "=", "reward_decay", "\n", "self", ".", "actions_onehot", "=", "tf", ".", "one_hot", "(", "self", ".", "action", ",", "self", ".", "num_actions", ")", "\n", "td_error", "=", "tf", ".", "square", "(", "self", ".", "target", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "self", ".", "actions_onehot", ",", "self", ".", "qvalues", ")", ",", "axis", "=", "1", ")", ")", "\n", "self", ".", "loss", "=", "tf", ".", "reduce_sum", "(", "td_error", "*", "self", ".", "mask", ")", "/", "tf", ".", "reduce_sum", "(", "self", ".", "mask", ")", "\n", "\n", "# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "# output action", "\n", "def", "out_action", "(", "qvalues", ")", ":", "\n", "            ", "best_action", "=", "tf", ".", "argmax", "(", "qvalues", ",", "axis", "=", "1", ")", "\n", "best_action", "=", "tf", ".", "to_int32", "(", "best_action", ")", "\n", "random_action", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "best_action", ")", ",", "0", ",", "self", ".", "num_actions", ",", "tf", ".", "int32", ")", "\n", "should_explore", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "best_action", ")", ",", "0", ",", "1", ")", "<", "self", ".", "eps", "\n", "return", "tf", ".", "where", "(", "should_explore", ",", "random_action", ",", "best_action", ")", "\n", "\n", "", "self", ".", "output_action", "=", "out_action", "(", "self", ".", "qvalues", ")", "\n", "if", "self", ".", "num_gpu", ">", "1", ":", "\n", "            ", "self", ".", "infer_out_action", "=", "[", "out_action", "(", "qvalue", ")", "for", "qvalue", "in", "self", ".", "infer_qvalues", "]", "\n", "\n", "# target network update op", "\n", "", "self", ".", "update_target_op", "=", "[", "]", "\n", "t_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "target_scope_name", ")", "\n", "e_params", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "eval_scope_name", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "t_params", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._create_network": [[136, 182], ["mxnet.sym.flatten", "mxnet.sym.FullyConnected", "mxnet.sym.Activation", "mxnet.sym.FullyConnected", "mxnet.sym.Activation", "mxnet.sym.concat", "mxnet.sym.transpose", "mxnet.sym.Convolution", "mxnet.sym.Activation", "mxnet.sym.Convolution", "mxnet.sym.Activation", "mxnet.sym.flatten", "mxnet.sym.FullyConnected", "mxnet.sym.Activation", "mxnet.sym.FullyConnected", "mxnet.sym.FullyConnected", "mxnet.sym.mean", "mxnet.sym.broadcast_sub", "mxnet.sym.broadcast_add", "mxnet.sym.FullyConnected"], "methods", ["None"], ["config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# init replay buffers", "\n", "self", ".", "replay_buf_len", "=", "0", "\n", "self", ".", "memory_size", "=", "memory_size", "\n", "self", ".", "replay_buf_view", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "replay_buf_feature", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "replay_buf_action", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "replay_buf_reward", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ")", "\n", "self", ".", "replay_buf_terminal", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "self", ".", "replay_buf_mask", "=", "ReplayBuffer", "(", "shape", "=", "(", "memory_size", ",", ")", ")", "\n", "# if mask[i] == 0, then the item is used for padding, not for training", "\n", "\n", "", "def", "_create_network", "(", "self", ",", "input_view", ",", "input_feature", ",", "use_conv", "=", "True", ",", "reuse", "=", "None", ")", ":", "\n", "        ", "\"\"\"define computation graph of network\n\n        Parameters\n        ----------\n        input_view: tf.tensor\n        input_feature: tf.tensor\n            the input tensor\n        \"\"\"", "\n", "kernel_num", "=", "[", "32", ",", "32", "]", "\n", "hidden_size", "=", "[", "256", "]", "\n", "\n", "if", "use_conv", ":", "# convolution", "\n", "            ", "h_conv1", "=", "tf", ".", "layers", ".", "conv2d", "(", "input_view", ",", "filters", "=", "kernel_num", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"conv1\"", ",", "reuse", "=", "reuse", ")", "\n", "h_conv2", "=", "tf", ".", "layers", ".", "conv2d", "(", "h_conv1", ",", "filters", "=", "kernel_num", "[", "1", "]", ",", "kernel_size", "=", "3", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"conv2\"", ",", "reuse", "=", "reuse", ")", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "h_conv2", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "h_conv2", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"dense_view\"", ",", "reuse", "=", "reuse", ")", "\n", "", "else", ":", "# fully connected", "\n", "            ", "flatten_view", "=", "tf", ".", "reshape", "(", "input_view", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "input_view", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "\"dense_emb\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "dense", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "use_dueling", ":", "\n", "            ", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ",", "name", "=", "\"value\"", ",", "reuse", "=", "reuse", ")", "\n", "advantage", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "use_bias", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.infer_action": [[183, 231], ["len", "min", "dqn.DeepQNetwork._reset_bind_size", "mxnet.io.NDArrayIter", "numpy.array().flatten", "numpy.random.randint", "numpy.where", "numpy.where.astype", "numpy.tile", "numpy.tile", "len", "dqn.DeepQNetwork.model.forward", "mxnet.nd.argmax", "numpy.array().flatten.append", "numpy.random.uniform", "dqn.DeepQNetwork.model.get_outputs", "numpy.array", "x.asnumpy"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["name", "=", "\"advantage\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "qvalues", "=", "value", "+", "advantage", "-", "tf", ".", "reduce_mean", "(", "advantage", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "qvalues", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "self", ".", "num_actions", ",", "name", "=", "\"value\"", ",", "reuse", "=", "reuse", ")", "\n", "\n", "", "return", "qvalues", "\n", "\n", "", "def", "infer_action", "(", "self", ",", "raw_obs", ",", "ids", ",", "policy", "=", "'e_greedy'", ",", "eps", "=", "0", ")", ":", "\n", "        ", "\"\"\"infer action for a batch of agents\n\n        Parameters\n        ----------\n        raw_obs: tuple(numpy array, numpy array)\n            raw observation of agents tuple(views, features)\n        ids: numpy array\n            ids of agents\n        policy: str\n            can be eps-greedy or greedy\n        eps: float\n            used when policy is eps-greedy\n\n        Returns\n        -------\n        acts: numpy array of int32\n            actions for agents\n        \"\"\"", "\n", "view", ",", "feature", "=", "raw_obs", "[", "0", "]", ",", "raw_obs", "[", "1", "]", "\n", "\n", "if", "policy", "==", "'e_greedy'", ":", "\n", "            ", "eps", "=", "eps", "\n", "", "elif", "policy", "==", "'greedy'", ":", "\n", "            ", "eps", "=", "0", "\n", "\n", "", "n", "=", "len", "(", "view", ")", "\n", "batch_size", "=", "min", "(", "n", ",", "self", ".", "infer_batch_size", ")", "\n", "\n", "if", "self", ".", "num_gpu", ">", "1", "and", "n", ">", "batch_size", ":", "# infer by multi gpu in parallel", "\n", "            ", "ret", "=", "self", ".", "_infer_multi_gpu", "(", "view", ",", "feature", ",", "ids", ",", "eps", ")", "\n", "", "else", ":", "# infer by splitting big batch in serial", "\n", "            ", "ret", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "batch_size", ")", ":", "\n", "                ", "beg", ",", "end", "=", "i", ",", "i", "+", "batch_size", "\n", "ret", ".", "append", "(", "self", ".", "sess", ".", "run", "(", "self", ".", "output_action", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", "[", "beg", ":", "end", "]", ",", "\n", "self", ".", "input_feature", ":", "feature", "[", "beg", ":", "end", "]", ",", "\n", "self", ".", "eps", ":", "eps", "}", ")", ")", "\n", "", "ret", "=", "np", ".", "concatenate", "(", "ret", ")", "\n", "", "return", "ret", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._calc_target": [[232, 252], ["len", "mxnet.io.DataBatch", "dqn.DeepQNetwork._reset_bind_size", "numpy.where", "dqn.DeepQNetwork.target_model.forward", "dqn.DeepQNetwork.model.forward", "[].asnumpy", "[].asnumpy", "dqn.DeepQNetwork.target_model.forward", "[].asnumpy", "numpy.max", "mxnet.nd.array", "mxnet.nd.array", "dqn.DeepQNetwork.target_model.get_outputs", "dqn.DeepQNetwork.model.get_outputs", "numpy.arange", "numpy.argmax", "dqn.DeepQNetwork.target_model.get_outputs"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size"], ["\n", "", "def", "_calc_target", "(", "self", ",", "next_view", ",", "next_feature", ",", "rewards", ",", "terminal", ")", ":", "\n", "        ", "\"\"\"calculate target value\"\"\"", "\n", "n", "=", "len", "(", "rewards", ")", "\n", "if", "self", ".", "use_double", ":", "\n", "            ", "t_qvalues", ",", "qvalues", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "target_qvalues", ",", "self", ".", "qvalues", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "input_view", ":", "next_view", ",", "\n", "self", ".", "input_feature", ":", "next_feature", "}", ")", "\n", "next_value", "=", "t_qvalues", "[", "np", ".", "arange", "(", "n", ")", ",", "np", ".", "argmax", "(", "qvalues", ",", "axis", "=", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "t_qvalues", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "target_qvalues", ",", "{", "self", ".", "input_view", ":", "next_view", ",", "\n", "self", ".", "input_feature", ":", "next_feature", "}", ")", "\n", "next_value", "=", "np", ".", "max", "(", "t_qvalues", ",", "axis", "=", "1", ")", "\n", "\n", "", "target", "=", "np", ".", "where", "(", "terminal", ",", "rewards", ",", "rewards", "+", "self", ".", "gamma", "*", "next_value", ")", "\n", "\n", "return", "target", "\n", "\n", "", "def", "_add_to_replay_buffer", "(", "self", ",", "sample_buffer", ")", ":", "\n", "        ", "\"\"\"add samples in sample_buffer to replay buffer\"\"\"", "\n", "n", "=", "0", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._add_to_replay_buffer": [[253, 279], ["sample_buffer.episodes", "min", "len", "numpy.ones", "numpy.zeros", "dqn.DeepQNetwork.replay_buf_view.put", "dqn.DeepQNetwork.replay_buf_feature.put", "dqn.DeepQNetwork.replay_buf_action.put", "dqn.DeepQNetwork.replay_buf_reward.put", "dqn.DeepQNetwork.replay_buf_terminal.put", "dqn.DeepQNetwork.replay_buf_mask.put"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.put"], ["for", "episode", "in", "sample_buffer", ".", "episodes", "(", ")", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", "\n", "\n", "m", "=", "len", "(", "r", ")", "\n", "\n", "mask", "=", "np", ".", "ones", "(", "(", "m", ",", ")", ")", "\n", "terminal", "=", "np", ".", "zeros", "(", "(", "m", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "if", "episode", ".", "terminal", ":", "\n", "                ", "terminal", "[", "-", "1", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "mask", "[", "-", "1", "]", "=", "0", "\n", "\n", "", "self", ".", "replay_buf_view", ".", "put", "(", "v", ")", "\n", "self", ".", "replay_buf_feature", ".", "put", "(", "f", ")", "\n", "self", ".", "replay_buf_action", ".", "put", "(", "a", ")", "\n", "self", ".", "replay_buf_reward", ".", "put", "(", "r", ")", "\n", "self", ".", "replay_buf_terminal", ".", "put", "(", "terminal", ")", "\n", "self", ".", "replay_buf_mask", ".", "put", "(", "mask", ")", "\n", "\n", "n", "+=", "m", "\n", "\n", "", "self", ".", "replay_buf_len", "=", "min", "(", "self", ".", "memory_size", ",", "self", ".", "replay_buf_len", "+", "n", ")", "\n", "return", "n", "\n", "\n", "", "def", "train", "(", "self", ",", "sample_buffer", ",", "print_every", "=", "1000", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.train": [[280, 352], ["dqn.DeepQNetwork._add_to_replay_buffer", "int", "print", "time.time", "range", "print", "numpy.random.choice", "dqn.DeepQNetwork.replay_buf_view.get", "dqn.DeepQNetwork.replay_buf_feature.get", "dqn.DeepQNetwork.replay_buf_action.get", "dqn.DeepQNetwork.replay_buf_reward.get", "dqn.DeepQNetwork.replay_buf_terminal.get", "dqn.DeepQNetwork.replay_buf_mask.get", "dqn.DeepQNetwork.replay_buf_view.get", "dqn.DeepQNetwork.replay_buf_feature.get", "dqn.DeepQNetwork._calc_target", "dqn.DeepQNetwork._reset_bind_size", "mxnet.io.DataBatch", "dqn.DeepQNetwork.model.forward", "dqn.DeepQNetwork.model.backward", "dqn.DeepQNetwork.model.update", "numpy.mean", "time.time", "max", "dqn.DeepQNetwork._eval", "[].asnumpy", "dqn.DeepQNetwork._copy_network", "print", "mxnet.nd.array", "mxnet.nd.array", "mxnet.nd.array", "mxnet.nd.array", "mxnet.nd.array", "dqn.DeepQNetwork.model.get_outputs", "dqn.DeepQNetwork._eval"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._add_to_replay_buffer", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._calc_target", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.update", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._copy_network", "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval"], ["\n", "add_num", "=", "self", ".", "_add_to_replay_buffer", "(", "sample_buffer", ")", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "total_loss", "=", "0", "\n", "\n", "n_batches", "=", "int", "(", "self", ".", "train_freq", "*", "add_num", "/", "batch_size", ")", "\n", "if", "n_batches", "==", "0", ":", "\n", "            ", "return", "0", ",", "0", "\n", "\n", "", "print", "(", "\"batch number: %d  add: %d  replay_len: %d/%d\"", "%", "\n", "(", "n_batches", ",", "add_num", ",", "self", ".", "replay_buf_len", ",", "self", ".", "memory_size", ")", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ct", "=", "0", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "# fetch a batch", "\n", "            ", "index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "replay_buf_len", "-", "1", ",", "batch_size", ")", "\n", "\n", "batch_view", "=", "self", ".", "replay_buf_view", ".", "get", "(", "index", ")", "\n", "batch_feature", "=", "self", ".", "replay_buf_feature", ".", "get", "(", "index", ")", "\n", "batch_action", "=", "self", ".", "replay_buf_action", ".", "get", "(", "index", ")", "\n", "batch_reward", "=", "self", ".", "replay_buf_reward", ".", "get", "(", "index", ")", "\n", "batch_terminal", "=", "self", ".", "replay_buf_terminal", ".", "get", "(", "index", ")", "\n", "batch_mask", "=", "self", ".", "replay_buf_mask", ".", "get", "(", "index", ")", "\n", "\n", "batch_next_view", "=", "self", ".", "replay_buf_view", ".", "get", "(", "index", "+", "1", ")", "\n", "batch_next_feature", "=", "self", ".", "replay_buf_feature", ".", "get", "(", "index", "+", "1", ")", "\n", "\n", "batch_target", "=", "self", ".", "_calc_target", "(", "batch_next_view", ",", "batch_next_feature", ",", "\n", "batch_reward", ",", "batch_terminal", ")", "\n", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op", ",", "self", ".", "loss", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "batch_view", ",", "\n", "self", ".", "input_feature", ":", "batch_feature", ",", "\n", "self", ".", "action", ":", "batch_action", ",", "\n", "self", ".", "target", ":", "batch_target", ",", "\n", "self", ".", "mask", ":", "batch_mask", "\n", "}", ")", "\n", "loss", "=", "ret", "[", "1", "]", "\n", "total_loss", "+=", "loss", "\n", "\n", "if", "ct", "%", "self", ".", "target_update", "==", "0", ":", "\n", "                ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_op", ")", "\n", "\n", "", "if", "ct", "%", "print_every", "==", "0", ":", "\n", "                ", "print", "(", "\"batch %5d,  loss %.6f, eval %.6f\"", "%", "(", "ct", ",", "loss", ",", "self", ".", "_eval", "(", "batch_target", ")", ")", ")", "\n", "", "ct", "+=", "1", "\n", "self", ".", "train_ct", "+=", "1", "\n", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "step_average", "=", "total_time", "/", "max", "(", "1.0", ",", "(", "ct", "/", "1000.0", ")", ")", "\n", "print", "(", "\"batches: %d,  total time: %.2f,  1k average: %.2f\"", "%", "(", "ct", ",", "total_time", ",", "step_average", ")", ")", "\n", "\n", "return", "total_loss", "/", "ct", "if", "ct", "!=", "0", "else", "0", ",", "self", ".", "_eval", "(", "batch_target", ")", "\n", "\n", "", "def", "_eval", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\"evaluate estimated q value\"\"\"", "\n", "if", "self", ".", "eval_obs", "is", "None", ":", "\n", "            ", "return", "np", ".", "mean", "(", "target", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size": [[353, 370], ["dqn.DeepQNetwork._reset_bind_size._reshape"], "methods", ["None"], ["            ", "return", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "qvalues", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "self", ".", "eval_obs", "[", "0", "]", ",", "\n", "self", ".", "input_feature", ":", "self", ".", "eval_obs", "[", "1", "]", "\n", "}", ")", ")", "\n", "\n", "", "", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "\"\"\"clear replay buffer\"\"\"", "\n", "self", ".", "replay_buf_len", "=", "0", "\n", "self", ".", "replay_buf_view", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_feature", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_action", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_reward", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_terminal", ".", "clear", "(", ")", "\n", "self", ".", "replay_buf_mask", ".", "clear", "(", ")", "\n", "\n", "", "def", "_build_multi_gpu_infer", "(", "self", ",", "num_gpu", ")", ":", "\n", "        ", "\"\"\"build inference graph for multi gpus\"\"\"", "\n", "self", ".", "infer_qvalues", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._copy_network": [[371, 375], ["source.get_params", "dest.set_params"], "methods", ["None"], ["self", ".", "infer_input_view", "=", "[", "]", "\n", "self", ".", "infer_input_feature", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_gpu", ")", ":", "\n", "            ", "self", ".", "infer_input_view", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "view_space", ")", ")", "\n", "self", ".", "infer_input_feature", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "feature_space", ")", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._eval": [[376, 387], ["numpy.mean", "dqn.DeepQNetwork._reset_bind_size", "len", "mxnet.io.DataBatch", "dqn.DeepQNetwork.model.forward", "numpy.mean", "[].asnumpy", "mxnet.nd.array", "mxnet.nd.array", "dqn.DeepQNetwork.model.get_outputs"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork._reset_bind_size"], ["with", "tf", ".", "variable_scope", "(", "\"eval_net_scope\"", ")", ",", "tf", ".", "device", "(", "\"/gpu:%d\"", "%", "i", ")", ":", "\n", "                ", "self", ".", "infer_qvalues", ".", "append", "(", "self", ".", "_create_network", "(", "self", ".", "infer_input_view", "[", "i", "]", ",", "\n", "self", ".", "infer_input_feature", "[", "i", "]", ",", "reuse", "=", "True", ")", ")", "\n", "\n", "", "", "", "def", "_infer_multi_gpu", "(", "self", ",", "view", ",", "feature", ",", "ids", ",", "eps", ")", ":", "\n", "        ", "\"\"\"infer action by multi gpu in parallel \"\"\"", "\n", "ret", "=", "[", "]", "\n", "beg", "=", "0", "\n", "while", "beg", "<", "len", "(", "view", ")", ":", "\n", "            ", "feed_dict", "=", "{", "self", ".", "eps", ":", "eps", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_gpu", ")", ":", "\n", "                ", "end", "=", "beg", "+", "self", ".", "infer_batch_size", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.mx_model.dqn.DeepQNetwork.get_info": [[388, 390], ["None"], "methods", ["None"], ["feed_dict", "[", "self", ".", "infer_input_view", "[", "i", "]", "]", "=", "view", "[", "beg", ":", "end", "]", "\n", "feed_dict", "[", "self", ".", "infer_input_feature", "[", "i", "]", "]", "=", "feature", "[", "beg", ":", "end", "]", "\n", "beg", "+=", "self", ".", "infer_batch_size", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.__init__": [[8, 63], ["env.get_view_space", "env.get_feature_space", "len", "env.get_action_space", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.get_variable_scope", "tensorflow.placeholder", "tensorflow.variable_scope", "base.ValueNet._construct_net", "tensorflow.nn.softmax", "tensorflow.get_collection", "tensorflow.variable_scope", "base.ValueNet._construct_net", "tensorflow.get_collection", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow.assign", "tensorflow.multiply", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "range", "tensorflow.train.AdamOptimizer", "len", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet._construct_net", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet._construct_net"], ["    ", "\"\"\"base model for tensorflow model\"\"\"", "\n", "def", "__init__", "(", "self", ",", "env", ",", "handle", ",", "name", ",", "subclass_name", ")", ":", "\n", "        ", "\"\"\"init a model\n\n        Parameters\n        ----------\n        env: magent.Environment\n        handle: handle (ctypes.c_int32)\n        name: str\n        subclass_name: str\n            name of subclass\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "env", ",", "handle", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "subclass_name", "=", "subclass_name", "\n", "\n", "", "def", "save", "(", "self", ",", "dir_name", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"save model to dir\n\n        Parameters\n        ----------\n        dir_name: str\n            name of the directory\n        epoch: int\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_name", ")", "\n", "", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "self", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_name", ")", "\n", "", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "\n", "", "def", "load", "(", "self", ",", "dir_name", ",", "epoch", "=", "0", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"save model to dir\n\n        Parameters\n        ----------\n        dir_name: str\n            name of the directory\n        epoch: int\n        \"\"\"", "\n", "if", "name", "is", "None", "or", "name", "==", "self", ".", "name", ":", "# the name of saved model is the same as ours", "\n", "            ", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "self", ".", "name", ")", "\n", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "", "else", ":", "# load a checkpoint with different name", "\n", "            ", "backup_graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "kv_dict", "=", "{", "}", "\n", "\n", "# load checkpoint from another saved graph", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "                ", "tf", ".", "train", ".", "import_meta_graph", "(", "os", ".", "path", ".", "join", "(", "dir_name", ",", "name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", "+", "\".meta\"", ")", ")", "\n", "dir_name", "=", "os", ".", "path", ".", "join", "(", "dir_name", ",", "name", ")", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet._construct_net": [[64, 89], ["tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "numpy.prod"], "methods", ["None"], ["model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "name", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "dir_name", ",", "(", "self", ".", "subclass_name", "+", "\"_%d\"", ")", "%", "epoch", ")", ")", "\n", "for", "item", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "                    ", "kv_dict", "[", "item", ".", "name", "]", "=", "sess", ".", "run", "(", "item", ")", "\n", "\n", "# assign to now graph", "\n", "", "", "backup_graph", ".", "as_default", "(", ")", "\n", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name", ")", "\n", "for", "item", "in", "model_vars", ":", "\n", "                ", "old_name", "=", "item", ".", "name", ".", "replace", "(", "self", ".", "name", ",", "name", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "assign", "(", "item", ",", "kv_dict", "[", "old_name", "]", ")", ")", "\n", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.vars": [[90, 93], ["tensorflow.get_collection"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.calc_target_q": [[94, 114], ["base.ValueNet.sess.run", "numpy.argmax", "kwargs.get", "numpy.arange", "q_values.reshape", "len"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get"], []], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.update": [[115, 118], ["base.ValueNet.sess.run"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], []], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.act": [[119, 138], ["base.ValueNet.sess.run", "numpy.argmax().astype", "kwargs.get", "len", "len", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get"], []], "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.train": [[139, 157], ["base.ValueNet.sess.run", "kwargs.get", "numpy.round", "numpy.round", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get"], []], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Buffer.__init__": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Buffer.push": [[16, 18], ["None"], "methods", ["None"], ["", "def", "push", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.__init__": [[21, 27], ["numpy.zeros().astype", "numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "max_len", ",", "dtype", "=", "'float32'", ")", ":", "\n", "        ", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "data", "=", "np", ".", "zeros", "(", "(", "max_len", ",", ")", "+", "shape", ")", ".", "astype", "(", "dtype", ")", "\n", "self", ".", "start", "=", "0", "\n", "self", ".", "length", "=", "0", "\n", "self", ".", "_flag", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.__len__": [[28, 30], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.__getitem__": [[31, 35], ["KeyError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "0", "or", "idx", ">=", "self", ".", "length", ":", "\n", "            ", "raise", "KeyError", "(", ")", "\n", "", "return", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.sample": [[36, 38], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "idx", "%", "self", ".", "length", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.pull": [[39, 41], ["None"], "methods", ["None"], ["", "def", "pull", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", ":", "self", ".", "length", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.append": [[42, 56], ["len", "min", "len"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "value", ")", ":", "\n", "        ", "start", "=", "0", "\n", "num", "=", "len", "(", "value", ")", "\n", "\n", "if", "self", ".", "_flag", "+", "num", ">", "self", ".", "max_len", ":", "\n", "            ", "tail", "=", "self", ".", "max_len", "-", "self", ".", "_flag", "\n", "self", ".", "data", "[", "self", ".", "_flag", ":", "]", "=", "value", "[", ":", "tail", "]", "\n", "num", "-=", "tail", "\n", "start", "=", "tail", "\n", "self", ".", "_flag", "=", "0", "\n", "\n", "", "self", ".", "data", "[", "self", ".", "_flag", ":", "self", ".", "_flag", "+", "num", "]", "=", "value", "[", "start", ":", "]", "\n", "self", ".", "_flag", "+=", "num", "\n", "self", ".", "length", "=", "min", "(", "self", ".", "length", "+", "len", "(", "value", ")", ",", "self", ".", "max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MetaBuffer.reset_new": [[57, 59], ["None"], "methods", ["None"], ["", "def", "reset_new", "(", "self", ",", "start", ",", "value", ")", ":", "\n", "        ", "self", ".", "data", "[", "start", ":", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBufferEntry.__init__": [[63, 70], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "views", "=", "[", "]", "\n", "self", ".", "features", "=", "[", "]", "\n", "self", ".", "actions", "=", "[", "]", "\n", "self", ".", "rewards", "=", "[", "]", "\n", "self", ".", "probs", "=", "[", "]", "\n", "self", ".", "terminal", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBufferEntry.append": [[71, 80], ["tools.EpisodesBufferEntry.views.append", "tools.EpisodesBufferEntry.features.append", "tools.EpisodesBufferEntry.actions.append", "tools.EpisodesBufferEntry.rewards.append", "view.copy", "feature.copy", "tools.EpisodesBufferEntry.probs.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "append", "(", "self", ",", "view", ",", "feature", ",", "action", ",", "reward", ",", "alive", ",", "probs", "=", "None", ")", ":", "\n", "        ", "self", ".", "views", ".", "append", "(", "view", ".", "copy", "(", ")", ")", "\n", "self", ".", "features", ".", "append", "(", "feature", ".", "copy", "(", ")", ")", "\n", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "if", "probs", "is", "not", "None", ":", "\n", "            ", "self", ".", "probs", ".", "append", "(", "probs", ")", "\n", "", "if", "not", "alive", ":", "\n", "            ", "self", ".", "terminal", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.__init__": [[86, 90], ["tools.Buffer.__init__"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["def", "__init__", "(", "self", ",", "use_mean", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "buffer", "=", "{", "}", "\n", "self", ".", "use_mean", "=", "use_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.push": [[91, 115], ["numpy.random.permutation", "range", "len", "len", "buffer.get", "tools.EpisodesBufferEntry", "tools.EpisodesBufferEntry.append", "tools.EpisodesBufferEntry.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "push", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "view", ",", "feature", "=", "kwargs", "[", "'state'", "]", "\n", "acts", "=", "kwargs", "[", "'acts'", "]", "\n", "rewards", "=", "kwargs", "[", "'rewards'", "]", "\n", "alives", "=", "kwargs", "[", "'alives'", "]", "\n", "ids", "=", "kwargs", "[", "'ids'", "]", "\n", "\n", "if", "self", ".", "use_mean", ":", "\n", "            ", "probs", "=", "kwargs", "[", "'prob'", "]", "\n", "\n", "", "buffer", "=", "self", ".", "buffer", "\n", "index", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "view", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ids", ")", ")", ":", "\n", "            ", "i", "=", "index", "[", "i", "]", "\n", "entry", "=", "buffer", ".", "get", "(", "ids", "[", "i", "]", ")", "\n", "if", "entry", "is", "None", ":", "\n", "                ", "entry", "=", "EpisodesBufferEntry", "(", ")", "\n", "buffer", "[", "ids", "[", "i", "]", "]", "=", "entry", "\n", "\n", "", "if", "self", ".", "use_mean", ":", "\n", "                ", "entry", ".", "append", "(", "view", "[", "i", "]", ",", "feature", "[", "i", "]", ",", "acts", "[", "i", "]", ",", "rewards", "[", "i", "]", ",", "alives", "[", "i", "]", ",", "probs", "=", "probs", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "entry", ".", "append", "(", "view", "[", "i", "]", ",", "feature", "[", "i", "]", ",", "acts", "[", "i", "]", ",", "rewards", "[", "i", "]", ",", "alives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.reset": [[116, 119], ["None"], "methods", ["None"], ["", "", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\" clear replay buffer \"\"\"", "\n", "self", ".", "buffer", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes": [[120, 123], ["tools.EpisodesBuffer.buffer.values"], "methods", ["None"], ["", "def", "episodes", "(", "self", ")", ":", "\n", "        ", "\"\"\" get episodes \"\"\"", "\n", "return", "self", ".", "buffer", ".", "values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.__init__": [[126, 136], ["tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "obs_shape", ",", "feat_shape", ",", "act_n", ",", "max_len", ",", "use_mean", "=", "False", ")", ":", "\n", "        ", "self", ".", "obs0", "=", "MetaBuffer", "(", "obs_shape", ",", "max_len", ")", "\n", "self", ".", "feat0", "=", "MetaBuffer", "(", "feat_shape", ",", "max_len", ")", "\n", "self", ".", "actions", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "rewards", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ")", "\n", "self", ".", "terminals", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ",", "dtype", "=", "'bool'", ")", "\n", "self", ".", "use_mean", "=", "use_mean", "\n", "\n", "if", "self", ".", "use_mean", ":", "\n", "            ", "self", ".", "prob", "=", "MetaBuffer", "(", "(", "act_n", ",", ")", ",", "max_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append": [[137, 146], ["tools.AgentMemory.obs0.append", "tools.AgentMemory.feat0.append", "tools.AgentMemory.actions.append", "tools.AgentMemory.rewards.append", "tools.AgentMemory.terminals.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "tools.AgentMemory.prob.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "", "def", "append", "(", "self", ",", "obs0", ",", "feat0", ",", "act", ",", "reward", ",", "alive", ",", "prob", "=", "None", ")", ":", "\n", "        ", "self", ".", "obs0", ".", "append", "(", "np", ".", "array", "(", "[", "obs0", "]", ")", ")", "\n", "self", ".", "feat0", ".", "append", "(", "np", ".", "array", "(", "[", "feat0", "]", ")", ")", "\n", "self", ".", "actions", ".", "append", "(", "np", ".", "array", "(", "[", "act", "]", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "self", ".", "rewards", ".", "append", "(", "np", ".", "array", "(", "[", "reward", "]", ")", ")", "\n", "self", ".", "terminals", ".", "append", "(", "np", ".", "array", "(", "[", "not", "alive", "]", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "if", "self", ".", "use_mean", ":", "\n", "            ", "self", ".", "prob", ".", "append", "(", "np", ".", "array", "(", "[", "prob", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull": [[147, 158], ["tools.AgentMemory.obs0.pull", "tools.AgentMemory.feat0.pull", "tools.AgentMemory.actions.pull", "tools.AgentMemory.rewards.pull", "tools.AgentMemory.terminals.pull", "tools.AgentMemory.prob.pull"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull"], ["", "", "def", "pull", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "\n", "'obs0'", ":", "self", ".", "obs0", ".", "pull", "(", ")", ",", "\n", "'feat0'", ":", "self", ".", "feat0", ".", "pull", "(", ")", ",", "\n", "'act'", ":", "self", ".", "actions", ".", "pull", "(", ")", ",", "\n", "'rewards'", ":", "self", ".", "rewards", ".", "pull", "(", ")", ",", "\n", "'terminals'", ":", "self", ".", "terminals", ".", "pull", "(", ")", ",", "\n", "'prob'", ":", "None", "if", "not", "self", ".", "use_mean", "else", "self", ".", "prob", ".", "pull", "(", ")", "\n", "}", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.__init__": [[161, 180], ["dict", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer", "tools.MetaBuffer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "obs_shape", ",", "feat_shape", ",", "act_n", ",", "max_len", ",", "batch_size", ",", "sub_len", ",", "use_mean", "=", "False", ")", ":", "\n", "        ", "self", ".", "agent", "=", "dict", "(", ")", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "obs_shape", "=", "obs_shape", "\n", "self", ".", "feat_shape", "=", "feat_shape", "\n", "self", ".", "sub_len", "=", "sub_len", "\n", "self", ".", "use_mean", "=", "use_mean", "\n", "self", ".", "act_n", "=", "act_n", "\n", "\n", "self", ".", "obs0", "=", "MetaBuffer", "(", "obs_shape", ",", "max_len", ")", "\n", "self", ".", "feat0", "=", "MetaBuffer", "(", "feat_shape", ",", "max_len", ")", "\n", "self", ".", "actions", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "rewards", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ")", "\n", "self", ".", "terminals", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ",", "dtype", "=", "'bool'", ")", "\n", "self", ".", "masks", "=", "MetaBuffer", "(", "(", ")", ",", "max_len", ",", "dtype", "=", "'bool'", ")", "\n", "if", "use_mean", ":", "\n", "            ", "self", ".", "prob", "=", "MetaBuffer", "(", "(", "act_n", ",", ")", ",", "max_len", ")", "\n", "", "self", ".", "_new_add", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup._flush": [[181, 194], ["tools.MemoryGroup.obs0.append", "tools.MemoryGroup.feat0.append", "tools.MemoryGroup.actions.append", "tools.MemoryGroup.rewards.append", "tools.MemoryGroup.terminals.append", "numpy.where", "tools.MemoryGroup.masks.append", "tools.MemoryGroup.prob.append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "_flush", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "obs0", ".", "append", "(", "kwargs", "[", "'obs0'", "]", ")", "\n", "self", ".", "feat0", ".", "append", "(", "kwargs", "[", "'feat0'", "]", ")", "\n", "self", ".", "actions", ".", "append", "(", "kwargs", "[", "'act'", "]", ")", "\n", "self", ".", "rewards", ".", "append", "(", "kwargs", "[", "'rewards'", "]", ")", "\n", "self", ".", "terminals", ".", "append", "(", "kwargs", "[", "'terminals'", "]", ")", "\n", "\n", "if", "self", ".", "use_mean", ":", "\n", "            ", "self", ".", "prob", ".", "append", "(", "kwargs", "[", "'prob'", "]", ")", "\n", "\n", "", "mask", "=", "np", ".", "where", "(", "kwargs", "[", "'terminals'", "]", "==", "True", ",", "False", ",", "True", ")", "\n", "mask", "[", "-", "1", "]", "=", "False", "\n", "self", ".", "masks", ".", "append", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.push": [[195, 203], ["enumerate", "tools.MemoryGroup.agent.get", "tools.AgentMemory", "tools.MemoryGroup.agent[].append", "tools.MemoryGroup.agent[].append"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.builtin.common.ReplayBuffer.get", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["", "def", "push", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "i", ",", "_id", "in", "enumerate", "(", "kwargs", "[", "'ids'", "]", ")", ":", "\n", "            ", "if", "self", ".", "agent", ".", "get", "(", "_id", ")", "is", "None", ":", "\n", "                ", "self", ".", "agent", "[", "_id", "]", "=", "AgentMemory", "(", "self", ".", "obs_shape", ",", "self", ".", "feat_shape", ",", "self", ".", "act_n", ",", "self", ".", "sub_len", ",", "use_mean", "=", "self", ".", "use_mean", ")", "\n", "", "if", "self", ".", "use_mean", ":", "\n", "                ", "self", ".", "agent", "[", "_id", "]", ".", "append", "(", "obs0", "=", "kwargs", "[", "'state'", "]", "[", "0", "]", "[", "i", "]", ",", "feat0", "=", "kwargs", "[", "'state'", "]", "[", "1", "]", "[", "i", "]", ",", "act", "=", "kwargs", "[", "'acts'", "]", "[", "i", "]", ",", "reward", "=", "kwargs", "[", "'rewards'", "]", "[", "i", "]", ",", "alive", "=", "kwargs", "[", "'alives'", "]", "[", "i", "]", ",", "prob", "=", "kwargs", "[", "'prob'", "]", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "agent", "[", "_id", "]", ".", "append", "(", "obs0", "=", "kwargs", "[", "'state'", "]", "[", "0", "]", "[", "i", "]", ",", "feat0", "=", "kwargs", "[", "'state'", "]", "[", "1", "]", "[", "i", "]", ",", "act", "=", "kwargs", "[", "'acts'", "]", "[", "i", "]", ",", "reward", "=", "kwargs", "[", "'rewards'", "]", "[", "i", "]", ",", "alive", "=", "kwargs", "[", "'alives'", "]", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.tight": [[204, 212], ["list", "numpy.random.shuffle", "dict", "tools.MemoryGroup.agent.keys", "tools.MemoryGroup.agent[].pull", "len", "tools.MemoryGroup._flush"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.pull", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup._flush"], ["", "", "", "def", "tight", "(", "self", ")", ":", "\n", "        ", "ids", "=", "list", "(", "self", ".", "agent", ".", "keys", "(", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "ids", ")", "\n", "for", "ele", "in", "ids", ":", "\n", "            ", "tmp", "=", "self", ".", "agent", "[", "ele", "]", ".", "pull", "(", ")", "\n", "self", ".", "_new_add", "+=", "len", "(", "tmp", "[", "'obs0'", "]", ")", "\n", "self", ".", "_flush", "(", "**", "tmp", ")", "\n", "", "self", ".", "agent", "=", "dict", "(", ")", "# clear", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample": [[213, 232], ["numpy.random.choice", "tools.MemoryGroup.obs0.sample", "tools.MemoryGroup.obs0.sample", "tools.MemoryGroup.feat0.sample", "tools.MemoryGroup.feat0.sample", "tools.MemoryGroup.actions.sample", "tools.MemoryGroup.rewards.sample", "tools.MemoryGroup.terminals.sample", "tools.MemoryGroup.masks.sample", "tools.MemoryGroup.prob.sample", "tools.MemoryGroup.prob.sample"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "nb_entries", ",", "size", "=", "self", ".", "batch_size", ")", "\n", "next_idx", "=", "(", "idx", "+", "1", ")", "%", "self", ".", "nb_entries", "\n", "\n", "obs", "=", "self", ".", "obs0", ".", "sample", "(", "idx", ")", "\n", "obs_next", "=", "self", ".", "obs0", ".", "sample", "(", "next_idx", ")", "\n", "feature", "=", "self", ".", "feat0", ".", "sample", "(", "idx", ")", "\n", "feature_next", "=", "self", ".", "feat0", ".", "sample", "(", "next_idx", ")", "\n", "actions", "=", "self", ".", "actions", ".", "sample", "(", "idx", ")", "\n", "rewards", "=", "self", ".", "rewards", ".", "sample", "(", "idx", ")", "\n", "dones", "=", "self", ".", "terminals", ".", "sample", "(", "idx", ")", "\n", "masks", "=", "self", ".", "masks", ".", "sample", "(", "idx", ")", "\n", "\n", "if", "self", ".", "use_mean", ":", "\n", "            ", "act_prob", "=", "self", ".", "prob", ".", "sample", "(", "idx", ")", "\n", "act_next_prob", "=", "self", ".", "prob", ".", "sample", "(", "next_idx", ")", "\n", "return", "obs", ",", "feature", ",", "actions", ",", "act_prob", ",", "obs_next", ",", "feature_next", ",", "act_next_prob", ",", "rewards", ",", "dones", ",", "masks", "\n", "", "else", ":", "\n", "            ", "return", "obs", ",", "feature", ",", "obs_next", ",", "feature_next", ",", "dones", ",", "rewards", ",", "actions", ",", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.get_batch_num": [[233, 238], ["print", "len"], "methods", ["None"], ["", "", "def", "get_batch_num", "(", "self", ")", ":", "\n", "        ", "print", "(", "'\\n[INFO] Length of buffer and new add:'", ",", "len", "(", "self", ".", "obs0", ")", ",", "self", ".", "_new_add", ")", "\n", "res", "=", "self", ".", "_new_add", "*", "2", "//", "self", ".", "batch_size", "\n", "self", ".", "_new_add", "=", "0", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.nb_entries": [[239, 242], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "nb_entries", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "obs0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.SummaryObj.__init__": [[248, 263], ["set", "tensorflow.Graph", "tensorflow.ConfigProto", "os.path.exists", "os.makedirs", "tools.SummaryObj.gra.as_default", "tensorflow.Session", "tensorflow.summary.FileWriter", "tools.SummaryObj.sess.run", "tensorflow.global_variables_initializer", "tensorflow.get_default_graph"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.gridworld.Config.set", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["def", "__init__", "(", "self", ",", "log_dir", ",", "log_name", ",", "n_group", "=", "1", ")", ":", "\n", "        ", "self", ".", "name_set", "=", "set", "(", ")", "\n", "self", ".", "gra", "=", "tf", ".", "Graph", "(", ")", "\n", "self", ".", "n_group", "=", "n_group", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "", "sess_config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "False", ")", "\n", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "with", "self", ".", "gra", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "sess", "=", "tf", ".", "Session", "(", "graph", "=", "self", ".", "gra", ",", "config", "=", "sess_config", ")", "\n", "self", ".", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", "+", "\"/\"", "+", "log_name", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.SummaryObj.register": [[264, 281], ["tools.SummaryObj.gra.as_default", "tools.SummaryObj.name_set.add", "setattr", "setattr", "Exception", "tensorflow.placeholder", "tensorflow.summary.scalar", "range", "range", "getattr"], "methods", ["None"], ["", "", "def", "register", "(", "self", ",", "name_list", ")", ":", "\n", "        ", "\"\"\"Register summary operations with a list contains names for these operations\n\n        Parameters\n        ----------\n        name_list: list, contains name whose type is str\n        \"\"\"", "\n", "\n", "with", "self", ".", "gra", ".", "as_default", "(", ")", ":", "\n", "            ", "for", "name", "in", "name_list", ":", "\n", "                ", "if", "name", "in", "self", ".", "name_set", ":", "\n", "                    ", "raise", "Exception", "(", "\"You cannot define different operations with same name: `{}`\"", ".", "format", "(", "name", ")", ")", "\n", "", "self", ".", "name_set", ".", "add", "(", "name", ")", "\n", "setattr", "(", "self", ",", "name", ",", "[", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "None", ",", "name", "=", "'Agent_{}_{}'", ".", "format", "(", "i", ",", "name", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_group", ")", "]", ")", "\n", "setattr", "(", "self", ",", "name", "+", "\"_op\"", ",", "[", "tf", ".", "summary", ".", "scalar", "(", "'Agent_{}_{}_op'", ".", "format", "(", "i", ",", "name", ")", ",", "getattr", "(", "self", ",", "name", ")", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_group", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.SummaryObj.write": [[282, 303], ["isinstance", "summary_dict.items", "isinstance", "Exception", "range", "tools.SummaryObj.train_writer.add_summary", "tools.SummaryObj.train_writer.add_summary", "tools.SummaryObj.sess.run", "tools.SummaryObj.sess.run", "getattr", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "", "", "def", "write", "(", "self", ",", "summary_dict", ",", "step", ")", ":", "\n", "        ", "\"\"\"Write summary related to a certain step\n\n        Parameters\n        ----------\n        summary_dict: dict, summary value dict\n        step: int, global step\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "summary_dict", ",", "dict", ")", "\n", "\n", "for", "key", ",", "value", "in", "summary_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "not", "in", "self", ".", "name_set", ":", "\n", "                ", "raise", "Exception", "(", "\"Undefined operation: `{}`\"", ".", "format", "(", "key", ")", ")", "\n", "", "if", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "n_group", ")", ":", "\n", "                    ", "self", ".", "train_writer", ".", "add_summary", "(", "self", ".", "sess", ".", "run", "(", "getattr", "(", "self", ",", "key", "+", "\"_op\"", ")", "[", "i", "]", ",", "feed_dict", "=", "{", "\n", "getattr", "(", "self", ",", "key", ")", "[", "i", "]", ":", "value", "[", "i", "]", "}", ")", ",", "global_step", "=", "step", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "train_writer", ".", "add_summary", "(", "self", ".", "sess", ".", "run", "(", "getattr", "(", "self", ",", "key", "+", "\"_op\"", ")", "[", "0", "]", ",", "feed_dict", "=", "{", "\n", "getattr", "(", "self", ",", "key", ")", "[", "0", "]", ":", "value", "}", ")", ",", "global_step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.__init__": [[306, 368], ["tools.SummaryObj", "tools.Runner.summary.register", "isinstance", "len", "len", "tensorflow.assign", "os.path.exists", "os.makedirs", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.SummaryObj.register"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "env", ",", "handles", ",", "map_size", ",", "max_steps", ",", "models", ",", "\n", "play_handle", ",", "render_every", "=", "None", ",", "save_every", "=", "None", ",", "tau", "=", "None", ",", "log_name", "=", "None", ",", "log_dir", "=", "None", ",", "model_dir", "=", "None", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"Initialize runner\n\n        Parameters\n        ----------\n        sess: tf.Session\n            session\n        env: magent.GridWorld\n            environment handle\n        handles: list\n            group handles\n        map_size: int\n            map size of grid world\n        max_steps: int\n            the maximum of stages in a episode\n        render_every: int\n            render environment interval\n        save_every: int\n            states the interval of evaluation for self-play update\n        models: list\n            contains models\n        play_handle: method like\n            run game\n        tau: float\n            tau index for self-play update\n        log_name: str\n            define the name of log dir\n        log_dir: str\n            donates the directory of logs\n        model_dir: str\n            donates the dircetory of models\n        \"\"\"", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "models", "=", "models", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "handles", "=", "handles", "\n", "self", ".", "map_size", "=", "map_size", "\n", "self", ".", "render_every", "=", "render_every", "\n", "self", ".", "save_every", "=", "save_every", "\n", "self", ".", "play", "=", "play_handle", "\n", "self", ".", "model_dir", "=", "model_dir", "\n", "self", ".", "train", "=", "train", "\n", "\n", "if", "self", ".", "train", ":", "\n", "            ", "self", ".", "summary", "=", "SummaryObj", "(", "log_name", "=", "log_name", ",", "log_dir", "=", "log_dir", ")", "\n", "\n", "summary_items", "=", "[", "'ave_agent_reward'", ",", "'total_reward'", ",", "'kill'", ",", "\"Sum_Reward\"", ",", "\"Kill_Sum\"", "]", "\n", "self", ".", "summary", ".", "register", "(", "summary_items", ")", "# summary register", "\n", "self", ".", "summary_items", "=", "summary_items", "\n", "\n", "assert", "isinstance", "(", "sess", ",", "tf", ".", "Session", ")", "\n", "assert", "self", ".", "models", "[", "0", "]", ".", "name_scope", "!=", "self", ".", "models", "[", "1", "]", ".", "name_scope", "\n", "self", ".", "sess", "=", "sess", "\n", "\n", "l_vars", ",", "r_vars", "=", "self", ".", "models", "[", "0", "]", ".", "vars", ",", "self", ".", "models", "[", "1", "]", ".", "vars", "\n", "assert", "len", "(", "l_vars", ")", "==", "len", "(", "r_vars", ")", "\n", "self", ".", "sp_op", "=", "[", "tf", ".", "assign", "(", "r_vars", "[", "i", "]", ",", "(", "1.", "-", "tau", ")", "*", "l_vars", "[", "i", "]", "+", "tau", "*", "r_vars", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "l_vars", ")", ")", "]", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "model_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "model_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run": [[369, 407], ["tools.Runner.play", "enumerate", "print", "print", "print", "tools.Runner.sess.run", "print", "print", "tools.Runner.models[].save", "tools.Runner.models[].save", "tools.Runner.summary.write", "Color.INFO.format", "Color.INFO.format", "Color.INFO.format"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.battle_model.senario_battle.play", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.SummaryObj.write"], ["", "", "", "def", "run", "(", "self", ",", "variant_eps", ",", "iteration", ",", "win_cnt", "=", "None", ")", ":", "\n", "        ", "info", "=", "{", "'mian'", ":", "None", ",", "'opponent'", ":", "None", "}", "\n", "\n", "# pass", "\n", "info", "[", "'main'", "]", "=", "{", "'ave_agent_reward'", ":", "0.", ",", "'total_reward'", ":", "0.", ",", "'kill'", ":", "0.", "}", "\n", "info", "[", "'opponent'", "]", "=", "{", "'ave_agent_reward'", ":", "0.", ",", "'total_reward'", ":", "0.", ",", "'kill'", ":", "0.", "}", "\n", "\n", "max_nums", ",", "nums", ",", "agent_r_records", ",", "total_rewards", "=", "self", ".", "play", "(", "env", "=", "self", ".", "env", ",", "n_round", "=", "iteration", ",", "map_size", "=", "self", ".", "map_size", ",", "max_steps", "=", "self", ".", "max_steps", ",", "handles", "=", "self", ".", "handles", ",", "\n", "models", "=", "self", ".", "models", ",", "print_every", "=", "50", ",", "eps", "=", "variant_eps", ",", "render", "=", "(", "iteration", "+", "1", ")", "%", "self", ".", "render_every", "if", "self", ".", "render_every", ">", "0", "else", "False", ",", "train", "=", "self", ".", "train", ")", "\n", "\n", "for", "i", ",", "tag", "in", "enumerate", "(", "[", "'main'", ",", "'opponent'", "]", ")", ":", "\n", "            ", "info", "[", "tag", "]", "[", "'total_reward'", "]", "=", "total_rewards", "[", "i", "]", "\n", "info", "[", "tag", "]", "[", "'kill'", "]", "=", "max_nums", "[", "i", "]", "-", "nums", "[", "1", "-", "i", "]", "\n", "info", "[", "tag", "]", "[", "'ave_agent_reward'", "]", "=", "agent_r_records", "[", "i", "]", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "print", "(", "'\\n[INFO] {}'", ".", "format", "(", "info", "[", "'main'", "]", ")", ")", "\n", "\n", "# if self.save_every and (iteration + 1) % self.save_every == 0:", "\n", "if", "info", "[", "'main'", "]", "[", "'total_reward'", "]", ">", "info", "[", "'opponent'", "]", "[", "'total_reward'", "]", ":", "\n", "                ", "print", "(", "Color", ".", "INFO", ".", "format", "(", "'\\n[INFO] Begin self-play Update ...'", ")", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "sp_op", ")", "\n", "print", "(", "Color", ".", "INFO", ".", "format", "(", "'[INFO] Self-play Updated!\\n'", ")", ")", "\n", "\n", "print", "(", "Color", ".", "INFO", ".", "format", "(", "'[INFO] Saving model ...'", ")", ")", "\n", "self", ".", "models", "[", "0", "]", ".", "save", "(", "self", ".", "model_dir", "+", "'-0'", ",", "iteration", ")", "\n", "self", ".", "models", "[", "1", "]", ".", "save", "(", "self", ".", "model_dir", "+", "'-1'", ",", "iteration", ")", "\n", "\n", "self", ".", "summary", ".", "write", "(", "info", "[", "'main'", "]", ",", "iteration", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'\\n[INFO] {0} \\n {1}'", ".", "format", "(", "info", "[", "'main'", "]", ",", "info", "[", "'opponent'", "]", ")", ")", "\n", "if", "info", "[", "'main'", "]", "[", "'kill'", "]", ">", "info", "[", "'opponent'", "]", "[", "'kill'", "]", ":", "\n", "                ", "win_cnt", "[", "'main'", "]", "+=", "1", "\n", "", "elif", "info", "[", "'main'", "]", "[", "'kill'", "]", "<", "info", "[", "'opponent'", "]", "[", "'kill'", "]", ":", "\n", "                ", "win_cnt", "[", "'opponent'", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "win_cnt", "[", "'main'", "]", "+=", "1", "\n", "win_cnt", "[", "'opponent'", "]", "+=", "1", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.DQN.__init__": [[10, 16], ["base.ValueNet.__init__", "tools.MemoryGroup", "q_learning.DQN.sess.run", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "name", ",", "handle", ",", "env", ",", "sub_len", ",", "memory_size", "=", "2", "**", "10", ",", "batch_size", "=", "64", ",", "update_every", "=", "5", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sess", ",", "env", ",", "handle", ",", "name", ",", "update_every", "=", "update_every", ")", "\n", "\n", "self", ".", "replay_buffer", "=", "tools", ".", "MemoryGroup", "(", "self", ".", "view_space", ",", "self", ".", "feature_space", ",", "self", ".", "num_actions", ",", "memory_size", ",", "batch_size", ",", "sub_len", ")", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.DQN.flush_buffer": [[17, 19], ["q_learning.DQN.replay_buffer.push"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.push"], ["", "def", "flush_buffer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "replay_buffer", ".", "push", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.DQN.train": [[20, 33], ["q_learning.DQN.replay_buffer.tight", "q_learning.DQN.replay_buffer.get_batch_num", "range", "q_learning.DQN.replay_buffer.sample", "q_learning.DQN.calc_target_q", "super().train", "q_learning.DQN.update", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.tight", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.get_batch_num", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.calc_target_q", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.train", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.update"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_buffer", ".", "tight", "(", ")", "\n", "batch_num", "=", "self", ".", "replay_buffer", ".", "get_batch_num", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_num", ")", ":", "\n", "            ", "obs", ",", "feats", ",", "obs_next", ",", "feat_next", ",", "dones", ",", "rewards", ",", "actions", ",", "masks", "=", "self", ".", "replay_buffer", ".", "sample", "(", ")", "\n", "target_q", "=", "self", ".", "calc_target_q", "(", "obs", "=", "obs_next", ",", "feature", "=", "feat_next", ",", "rewards", "=", "rewards", ",", "dones", "=", "dones", ")", "\n", "loss", ",", "q", "=", "super", "(", ")", ".", "train", "(", "state", "=", "[", "obs", ",", "feats", "]", ",", "target_q", "=", "target_q", ",", "acts", "=", "actions", ",", "masks", "=", "masks", ")", "\n", "\n", "self", ".", "update", "(", ")", "\n", "\n", "if", "i", "%", "50", "==", "0", ":", "\n", "                ", "print", "(", "'[*] LOSS:'", ",", "loss", ",", "'/ Q:'", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.DQN.save": [[34, 42], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save"], ["", "", "", "def", "save", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"dqn_{}\"", ".", "format", "(", "step", ")", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "\n", "print", "(", "\"[*] Model saved at: {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.DQN.load": [[43, 51], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"dqn_{}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "print", "(", "\"[*] Loaded model from {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.MFQ.__init__": [[54, 70], ["base.ValueNet.__init__", "tools.MemoryGroup"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "name", ",", "handle", ",", "env", ",", "sub_len", ",", "eps", "=", "1.0", ",", "update_every", "=", "5", ",", "memory_size", "=", "2", "**", "10", ",", "batch_size", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sess", ",", "env", ",", "handle", ",", "name", ",", "use_mf", "=", "True", ",", "update_every", "=", "update_every", ")", "\n", "\n", "config", "=", "{", "\n", "'max_len'", ":", "memory_size", ",", "\n", "'batch_size'", ":", "batch_size", ",", "\n", "'obs_shape'", ":", "self", ".", "view_space", ",", "\n", "'feat_shape'", ":", "self", ".", "feature_space", ",", "\n", "'act_n'", ":", "self", ".", "num_actions", ",", "\n", "'use_mean'", ":", "True", ",", "\n", "'sub_len'", ":", "sub_len", "\n", "}", "\n", "\n", "self", ".", "train_ct", "=", "0", "\n", "self", ".", "replay_buffer", "=", "tools", ".", "MemoryGroup", "(", "**", "config", ")", "\n", "self", ".", "update_every", "=", "update_every", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.MFQ.flush_buffer": [[71, 73], ["q_learning.MFQ.replay_buffer.push"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.push"], ["", "def", "flush_buffer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "replay_buffer", ".", "push", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.MFQ.train": [[74, 87], ["q_learning.MFQ.replay_buffer.tight", "q_learning.MFQ.replay_buffer.get_batch_num", "range", "q_learning.MFQ.replay_buffer.sample", "q_learning.MFQ.calc_target_q", "super().train", "q_learning.MFQ.update", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.tight", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.get_batch_num", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.sample", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.calc_target_q", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.train", "home.repos.pwc.inspect_result.mlii_mfrl.algo.base.ValueNet.update"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_buffer", ".", "tight", "(", ")", "\n", "batch_name", "=", "self", ".", "replay_buffer", ".", "get_batch_num", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_name", ")", ":", "\n", "            ", "obs", ",", "feat", ",", "acts", ",", "act_prob", ",", "obs_next", ",", "feat_next", ",", "act_prob_next", ",", "rewards", ",", "dones", ",", "masks", "=", "self", ".", "replay_buffer", ".", "sample", "(", ")", "\n", "target_q", "=", "self", ".", "calc_target_q", "(", "obs", "=", "obs_next", ",", "feature", "=", "feat_next", ",", "rewards", "=", "rewards", ",", "dones", "=", "dones", ",", "prob", "=", "act_prob_next", ")", "\n", "loss", ",", "q", "=", "super", "(", ")", ".", "train", "(", "state", "=", "[", "obs", ",", "feat", "]", ",", "target_q", "=", "target_q", ",", "prob", "=", "act_prob", ",", "acts", "=", "acts", ",", "masks", "=", "masks", ")", "\n", "\n", "self", ".", "update", "(", ")", "\n", "\n", "if", "i", "%", "50", "==", "0", ":", "\n", "                ", "print", "(", "'[*] LOSS:'", ",", "loss", ",", "'/ Q:'", ",", "q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.MFQ.save": [[88, 96], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save"], ["", "", "", "def", "save", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"mfq_{}\"", ".", "format", "(", "step", ")", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "\n", "print", "(", "\"[*] Model saved at: {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.q_learning.MFQ.load": [[97, 104], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"mfq_{}\"", ".", "format", "(", "step", ")", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "\n", "print", "(", "\"[*] Loaded model from {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.__init__.spawn_ai": [[10, 20], ["MFQ", "MFAC", "AC", "IL"], "function", ["None"], []], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.__init__": [[9, 35], ["env.get_view_space", "env.get_feature_space", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "tools.EpisodesBuffer", "env.get_action_space", "tensorflow.variable_scope", "ac.ActorCritic._create_network", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "name", ",", "handle", ",", "env", ",", "value_coef", "=", "0.1", ",", "ent_coef", "=", "0.08", ",", "gamma", "=", "0.95", ",", "batch_size", "=", "64", ",", "learning_rate", "=", "1e-4", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "env", "=", "env", "\n", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "view_space", "=", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "self", ".", "gamma", "=", "gamma", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "\n", "self", ".", "value_coef", "=", "value_coef", "# coefficient of value in the total loss", "\n", "self", ".", "ent_coef", "=", "ent_coef", "# coefficient of entropy in the total loss", "\n", "\n", "# init training buffers", "\n", "self", ".", "view_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "reward_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "replay_buffer", "=", "tools", ".", "EpisodesBuffer", "(", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "_create_network", "(", "self", ".", "view_space", ",", "self", ".", "feature_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.vars": [[36, 39], ["tensorflow.get_collection"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "name_scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.flush_buffer": [[40, 42], ["ac.ActorCritic.replay_buffer.push"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.push"], ["", "def", "flush_buffer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "replay_buffer", ".", "push", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.act": [[43, 49], ["ac.ActorCritic.sess.run", "ac.ActorCritic.astype().reshape", "ac.ActorCritic.astype"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "act", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "action", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "calc_action", ",", "{", "\n", "self", ".", "input_view", ":", "kwargs", "[", "'state'", "]", "[", "0", "]", ",", "\n", "self", ".", "input_feature", ":", "kwargs", "[", "'state'", "]", "[", "1", "]", "\n", "}", ")", "\n", "return", "action", ".", "astype", "(", "np", ".", "int32", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic._create_network": [[50, 104], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.clip_by_value", "tensorflow.multinomial", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.one_hot", "tensorflow.stop_gradient", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "zip", "numpy.prod", "tensorflow.square", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["", "def", "_create_network", "(", "self", ",", "view_space", ",", "feature_space", ")", ":", "\n", "        ", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "view_space", ")", "\n", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "feature_space", ")", "\n", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "\n", "reward", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "\n", "hidden_size", "=", "[", "256", "]", "\n", "\n", "# fully connected", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "input_view", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "input_view", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "dense", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "dense", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "hidden_size", "[", "0", "]", "*", "2", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "policy", "=", "tf", ".", "layers", ".", "dense", "(", "dense", "/", "0.1", ",", "units", "=", "self", ".", "num_actions", ",", "activation", "=", "tf", ".", "nn", ".", "softmax", ")", "\n", "policy", "=", "tf", ".", "clip_by_value", "(", "policy", ",", "1e-10", ",", "1", "-", "1e-10", ")", "\n", "\n", "self", ".", "calc_action", "=", "tf", ".", "multinomial", "(", "tf", ".", "log", "(", "policy", ")", ",", "1", ")", "\n", "\n", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "value", ",", "(", "-", "1", ",", ")", ")", "\n", "\n", "action_mask", "=", "tf", ".", "one_hot", "(", "action", ",", "self", ".", "num_actions", ")", "\n", "advantage", "=", "tf", ".", "stop_gradient", "(", "reward", "-", "value", ")", "\n", "\n", "log_policy", "=", "tf", ".", "log", "(", "policy", "+", "1e-6", ")", "\n", "log_prob", "=", "tf", ".", "reduce_sum", "(", "log_policy", "*", "action_mask", ",", "axis", "=", "1", ")", "\n", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "advantage", "*", "log_prob", ")", "\n", "vf_loss", "=", "self", ".", "value_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "reward", "-", "value", ")", ")", "\n", "neg_entropy", "=", "self", ".", "ent_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "policy", "*", "log_policy", ",", "axis", "=", "1", ")", ")", "\n", "total_loss", "=", "pg_loss", "+", "vf_loss", "+", "neg_entropy", "\n", "\n", "# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "total_loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", ".", "minimize", "(", "total_loss", ")", "\n", "\n", "self", ".", "input_view", "=", "input_view", "\n", "self", ".", "input_feature", "=", "input_feature", "\n", "self", ".", "action", "=", "action", "\n", "self", ".", "reward", "=", "reward", "\n", "\n", "self", ".", "policy", ",", "self", ".", "value", "=", "policy", ",", "value", "\n", "self", ".", "train_op", "=", "train_op", "\n", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", "=", "pg_loss", ",", "vf_loss", ",", "neg_entropy", "\n", "self", ".", "total_loss", "=", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.train": [[105, 158], ["ac.ActorCritic.replay_buffer.episodes", "tools.EpisodesBuffer", "ac.ActorCritic.view_buf.resize", "ac.ActorCritic.feature_buf.resize", "ac.ActorCritic.action_buf.resize", "ac.ActorCritic.reward_buf.resize", "ac.ActorCritic.sess.run", "print", "len", "len", "numpy.array", "reversed", "numpy.round", "numpy.round", "numpy.round", "numpy.mean", "ac.ActorCritic.sess.run", "range"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "train", "(", "self", ")", ":", "\n", "# calc buffer size", "\n", "        ", "n", "=", "0", "\n", "# batch_data = sample_buffer.episodes()", "\n", "batch_data", "=", "self", ".", "replay_buffer", ".", "episodes", "(", ")", "\n", "self", ".", "replay_buffer", "=", "tools", ".", "EpisodesBuffer", "(", ")", "\n", "\n", "for", "episode", "in", "batch_data", ":", "\n", "            ", "n", "+=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "", "self", ".", "view_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", ".", "resize", "(", "n", ")", "\n", "self", ".", "reward_buf", ".", "resize", "(", "n", ")", "\n", "view", ",", "feature", "=", "self", ".", "view_buf", ",", "self", ".", "feature_buf", "\n", "action", ",", "reward", "=", "self", ".", "action_buf", ",", "self", ".", "reward_buf", "\n", "\n", "ct", "=", "0", "\n", "gamma", "=", "self", ".", "gamma", "\n", "# collect episodes from multiple separate buffers to a continuous buffer", "\n", "for", "episode", "in", "batch_data", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", "\n", "m", "=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "r", ")", "\n", "\n", "keep", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "value", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "[", "v", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "input_feature", ":", "[", "f", "[", "-", "1", "]", "]", ",", "\n", "}", ")", "[", "0", "]", "\n", "\n", "for", "i", "in", "reversed", "(", "range", "(", "m", ")", ")", ":", "\n", "                ", "keep", "=", "keep", "*", "gamma", "+", "r", "[", "i", "]", "\n", "r", "[", "i", "]", "=", "keep", "\n", "\n", "", "view", "[", "ct", ":", "ct", "+", "m", "]", "=", "v", "\n", "feature", "[", "ct", ":", "ct", "+", "m", "]", "=", "f", "\n", "action", "[", "ct", ":", "ct", "+", "m", "]", "=", "a", "\n", "reward", "[", "ct", ":", "ct", "+", "m", "]", "=", "r", "\n", "ct", "+=", "m", "\n", "\n", "", "assert", "n", "==", "ct", "\n", "\n", "# train", "\n", "_", ",", "pg_loss", ",", "vf_loss", ",", "ent_loss", ",", "state_value", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_op", ",", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", ",", "self", ".", "value", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "action", ":", "action", ",", "\n", "self", ".", "reward", ":", "reward", ",", "\n", "}", ")", "\n", "\n", "print", "(", "'[*] PG_LOSS:'", ",", "np", ".", "round", "(", "pg_loss", ",", "6", ")", ",", "'/ VF_LOSS:'", ",", "np", ".", "round", "(", "vf_loss", ",", "6", ")", ",", "'/ ENT_LOSS:'", ",", "np", ".", "round", "(", "ent_loss", ")", ",", "'/ Value:'", ",", "np", ".", "mean", "(", "state_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.save": [[159, 167], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save"], ["", "def", "save", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"ac_{}\"", ".", "format", "(", "step", ")", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "\n", "print", "(", "\"[*] Model saved at: {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.ActorCritic.load": [[168, 176], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"ac_{}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "print", "(", "\"[*] Loaded model from {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.__init__": [[179, 205], ["env.get_view_space", "env.get_feature_space", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "tools.EpisodesBuffer", "env.get_action_space", "tensorflow.variable_scope", "ac.MFAC._create_network", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_view_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_feature_space", "home.repos.pwc.inspect_result.mlii_mfrl.magent.environment.Environment.get_action_space", "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "name", ",", "handle", ",", "env", ",", "value_coef", "=", "0.1", ",", "ent_coef", "=", "0.08", ",", "gamma", "=", "0.95", ",", "batch_size", "=", "64", ",", "learning_rate", "=", "1e-4", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "view_space", "=", "env", ".", "get_view_space", "(", "handle", ")", "\n", "self", ".", "feature_space", "=", "env", ".", "get_feature_space", "(", "handle", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "get_action_space", "(", "handle", ")", "[", "0", "]", "\n", "self", ".", "reward_decay", "=", "gamma", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "\n", "self", ".", "value_coef", "=", "value_coef", "# coefficient of value in the total loss", "\n", "self", ".", "ent_coef", "=", "ent_coef", "# coefficient of entropy in the total loss", "\n", "\n", "# init training buffers", "\n", "self", ".", "view_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", "=", "np", ".", "empty", "(", "(", "1", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "reward_buf", "=", "np", ".", "empty", "(", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "replay_buffer", "=", "tools", ".", "EpisodesBuffer", "(", "use_mean", "=", "True", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "self", ".", "name_scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "self", ".", "_create_network", "(", "self", ".", "view_space", ",", "self", ".", "feature_space", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.vars": [[206, 209], ["tensorflow.get_collection"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "name_scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.flush_buffer": [[210, 212], ["ac.MFAC.replay_buffer.push"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.MemoryGroup.push"], ["", "def", "flush_buffer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "replay_buffer", ".", "push", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.act": [[213, 219], ["ac.MFAC.sess.run", "ac.MFAC.astype().reshape", "ac.MFAC.astype"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "act", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "action", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "calc_action", ",", "{", "\n", "self", ".", "input_view", ":", "kwargs", "[", "'state'", "]", "[", "0", "]", ",", "\n", "self", ".", "input_feature", ":", "kwargs", "[", "'state'", "]", "[", "1", "]", "\n", "}", ")", "\n", "return", "action", ".", "astype", "(", "np", ".", "int32", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC._create_network": [[220, 282], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.clip_by_value", "tensorflow.multinomial", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.reshape", "tensorflow.one_hot", "tensorflow.stop_gradient", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer", "zip", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.log", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "zip", "numpy.prod", "tensorflow.square", "tensorflow.reduce_sum", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["", "def", "_create_network", "(", "self", ",", "view_space", ",", "feature_space", ")", ":", "\n", "# input", "\n", "        ", "input_view", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "view_space", ")", "\n", "input_feature", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "feature_space", ")", "\n", "input_act_prob", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "self", ".", "num_actions", ")", ")", "\n", "action", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", "\n", "\n", "reward", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "\n", "hidden_size", "=", "[", "256", "]", "\n", "\n", "# fully connected", "\n", "flatten_view", "=", "tf", ".", "reshape", "(", "input_view", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "input_view", ".", "shape", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "h_view", "=", "tf", ".", "layers", ".", "dense", "(", "flatten_view", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "h_emb", "=", "tf", ".", "layers", ".", "dense", "(", "input_feature", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "concat_layer", "=", "tf", ".", "concat", "(", "[", "h_view", ",", "h_emb", "]", ",", "axis", "=", "1", ")", "\n", "dense", "=", "tf", ".", "layers", ".", "dense", "(", "concat_layer", ",", "units", "=", "hidden_size", "[", "0", "]", "*", "2", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "policy", "=", "tf", ".", "layers", ".", "dense", "(", "dense", "/", "0.1", ",", "units", "=", "self", ".", "num_actions", ",", "activation", "=", "tf", ".", "nn", ".", "softmax", ")", "\n", "policy", "=", "tf", ".", "clip_by_value", "(", "policy", ",", "1e-10", ",", "1", "-", "1e-10", ")", "\n", "\n", "self", ".", "calc_action", "=", "tf", ".", "multinomial", "(", "tf", ".", "log", "(", "policy", ")", ",", "1", ")", "\n", "\n", "# for value obtain", "\n", "emb_prob", "=", "tf", ".", "layers", ".", "dense", "(", "input_act_prob", ",", "units", "=", "64", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "dense_prob", "=", "tf", ".", "layers", ".", "dense", "(", "emb_prob", ",", "units", "=", "32", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "concat_layer", "=", "tf", ".", "concat", "(", "[", "concat_layer", ",", "dense_prob", "]", ",", "axis", "=", "1", ")", "\n", "dense", "=", "tf", ".", "layers", ".", "dense", "(", "concat_layer", ",", "units", "=", "hidden_size", "[", "0", "]", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "value", "=", "tf", ".", "layers", ".", "dense", "(", "dense", ",", "units", "=", "1", ")", "\n", "value", "=", "tf", ".", "reshape", "(", "value", ",", "(", "-", "1", ",", ")", ")", "\n", "\n", "action_mask", "=", "tf", ".", "one_hot", "(", "action", ",", "self", ".", "num_actions", ")", "\n", "advantage", "=", "tf", ".", "stop_gradient", "(", "reward", "-", "value", ")", "\n", "\n", "log_policy", "=", "tf", ".", "log", "(", "policy", "+", "1e-6", ")", "\n", "log_prob", "=", "tf", ".", "reduce_sum", "(", "log_policy", "*", "action_mask", ",", "axis", "=", "1", ")", "\n", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "advantage", "*", "log_prob", ")", "\n", "vf_loss", "=", "self", ".", "value_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "reward", "-", "value", ")", ")", "\n", "neg_entropy", "=", "self", ".", "ent_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "policy", "*", "log_policy", ",", "axis", "=", "1", ")", ")", "\n", "total_loss", "=", "pg_loss", "+", "vf_loss", "+", "neg_entropy", "\n", "\n", "# train op (clip gradient)", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", "\n", "gradients", ",", "variables", "=", "zip", "(", "*", "optimizer", ".", "compute_gradients", "(", "total_loss", ")", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "5.0", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "variables", ")", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "learning_rate", ")", ".", "minimize", "(", "total_loss", ")", "\n", "\n", "self", ".", "input_view", "=", "input_view", "\n", "self", ".", "input_feature", "=", "input_feature", "\n", "self", ".", "input_act_prob", "=", "input_act_prob", "\n", "self", ".", "action", "=", "action", "\n", "self", ".", "reward", "=", "reward", "\n", "\n", "self", ".", "policy", ",", "self", ".", "value", "=", "policy", ",", "value", "\n", "self", ".", "train_op", "=", "train_op", "\n", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", "=", "pg_loss", ",", "vf_loss", ",", "neg_entropy", "\n", "self", ".", "total_loss", "=", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.train": [[283, 344], ["ac.MFAC.replay_buffer.episodes", "tools.EpisodesBuffer", "ac.MFAC.view_buf.resize", "ac.MFAC.feature_buf.resize", "ac.MFAC.action_buf.resize", "ac.MFAC.reward_buf.resize", "numpy.zeros", "enumerate", "ac.MFAC.sess.run", "print", "len", "len", "numpy.array", "reversed", "numpy.round", "numpy.round", "numpy.round", "numpy.mean", "len", "ac.MFAC.sess.run", "range"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.EpisodesBuffer.episodes", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.Runner.run"], ["", "def", "train", "(", "self", ")", ":", "\n", "# calc buffer size", "\n", "        ", "n", "=", "0", "\n", "# batch_data = sample_buffer.episodes()", "\n", "batch_data", "=", "self", ".", "replay_buffer", ".", "episodes", "(", ")", "\n", "self", ".", "replay_buffer", "=", "tools", ".", "EpisodesBuffer", "(", "use_mean", "=", "True", ")", "\n", "\n", "for", "episode", "in", "batch_data", ":", "\n", "            ", "n", "+=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "", "self", ".", "view_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "view_space", ")", "\n", "self", ".", "feature_buf", ".", "resize", "(", "(", "n", ",", ")", "+", "self", ".", "feature_space", ")", "\n", "self", ".", "action_buf", ".", "resize", "(", "n", ")", "\n", "self", ".", "reward_buf", ".", "resize", "(", "n", ")", "\n", "view", ",", "feature", "=", "self", ".", "view_buf", ",", "self", ".", "feature_buf", "\n", "action", ",", "reward", "=", "self", ".", "action_buf", ",", "self", ".", "reward_buf", "\n", "act_prob_buff", "=", "np", ".", "zeros", "(", "(", "n", ",", "self", ".", "num_actions", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "ct", "=", "0", "\n", "gamma", "=", "self", ".", "reward_decay", "\n", "# collect episodes from multiple separate buffers to a continuous buffer", "\n", "for", "k", ",", "episode", "in", "enumerate", "(", "batch_data", ")", ":", "\n", "            ", "v", ",", "f", ",", "a", ",", "r", ",", "prob", "=", "episode", ".", "views", ",", "episode", ".", "features", ",", "episode", ".", "actions", ",", "episode", ".", "rewards", ",", "episode", ".", "probs", "\n", "m", "=", "len", "(", "episode", ".", "rewards", ")", "\n", "\n", "assert", "len", "(", "prob", ")", ">", "0", "\n", "\n", "r", "=", "np", ".", "array", "(", "r", ")", "\n", "\n", "keep", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "value", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "[", "v", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "input_feature", ":", "[", "f", "[", "-", "1", "]", "]", ",", "\n", "self", ".", "input_act_prob", ":", "[", "prob", "[", "-", "1", "]", "]", "\n", "}", ")", "[", "0", "]", "\n", "\n", "for", "i", "in", "reversed", "(", "range", "(", "m", ")", ")", ":", "\n", "                ", "keep", "=", "keep", "*", "gamma", "+", "r", "[", "i", "]", "\n", "r", "[", "i", "]", "=", "keep", "\n", "\n", "", "view", "[", "ct", ":", "ct", "+", "m", "]", "=", "v", "\n", "feature", "[", "ct", ":", "ct", "+", "m", "]", "=", "f", "\n", "action", "[", "ct", ":", "ct", "+", "m", "]", "=", "a", "\n", "reward", "[", "ct", ":", "ct", "+", "m", "]", "=", "r", "\n", "act_prob_buff", "[", "ct", ":", "ct", "+", "m", "]", "=", "prob", "\n", "ct", "+=", "m", "\n", "\n", "", "assert", "n", "==", "ct", "\n", "\n", "# train", "\n", "_", ",", "pg_loss", ",", "vf_loss", ",", "ent_loss", ",", "state_value", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "train_op", ",", "self", ".", "pg_loss", ",", "self", ".", "vf_loss", ",", "self", ".", "reg_loss", ",", "self", ".", "value", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "input_view", ":", "view", ",", "\n", "self", ".", "input_feature", ":", "feature", ",", "\n", "self", ".", "input_act_prob", ":", "act_prob_buff", ",", "\n", "self", ".", "action", ":", "action", ",", "\n", "self", ".", "reward", ":", "reward", ",", "\n", "}", ")", "\n", "\n", "# print(\"sample\", n, pg_loss, vf_loss, ent_loss)", "\n", "\n", "print", "(", "'[*] PG_LOSS:'", ",", "np", ".", "round", "(", "pg_loss", ",", "6", ")", ",", "'/ VF_LOSS:'", ",", "np", ".", "round", "(", "vf_loss", ",", "6", ")", ",", "'/ ENT_LOSS:'", ",", "np", ".", "round", "(", "ent_loss", ",", "6", ")", ",", "'/ VALUE:'", ",", "np", ".", "mean", "(", "state_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save": [[345, 353], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.save", "print"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.save"], ["", "def", "save", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"mfac_{}\"", ".", "format", "(", "step", ")", ")", "\n", "saver", ".", "save", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "\n", "print", "(", "\"[*] Model saved at: {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.algo.ac.MFAC.load": [[354, 362], ["tensorflow.get_collection", "tensorflow.train.Saver", "os.path.join", "tensorflow.train.Saver.restore", "print"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "dir_path", ",", "step", "=", "0", ")", ":", "\n", "        ", "model_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "name_scope", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "model_vars", ")", "\n", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\"mfac_{}\"", ".", "format", "(", "step", ")", ")", "\n", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "file_path", ")", "\n", "print", "(", "\"[*] Loaded model from {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario._calc_mask": [[7, 59], ["list", "list.remove", "range", "numpy.array", "numpy.array", "range", "range", "len", "len", "range", "len", "range", "len", "int", "int", "numpy.array", "numpy.array", "int", "int", "range", "range", "int", "int"], "methods", ["None"], ["  ", "def", "_calc_mask", "(", "self", ",", "agent", ",", "shape_size", ")", ":", "\n", "# compute the neighbour mask for each agent", "\n", "    ", "if", "agent", ".", "view_sight", "==", "-", "1", ":", "\n", "# fully observed", "\n", "      ", "agent", ".", "spin_mask", "+=", "1", "\n", "", "elif", "agent", ".", "view_sight", "==", "0", ":", "\n", "# observe itself", "\n", "      ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "]", "=", "1", "\n", "", "elif", "agent", ".", "view_sight", ">", "0", ":", "\n", "# observe neighbours", "\n", "      ", "delta", "=", "list", "(", "range", "(", "-", "int", "(", "agent", ".", "view_sight", ")", ",", "int", "(", "agent", ".", "view_sight", ")", "+", "1", ",", "1", ")", ")", "\n", "delta", ".", "remove", "(", "0", ")", "# agent itself is not counted as neighbour of itself", "\n", "for", "dt", "in", "delta", ":", "\n", "        ", "row", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "\n", "col", "=", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "row_dt", "=", "row", "+", "dt", "\n", "col_dt", "=", "col", "+", "dt", "\n", "if", "row_dt", "in", "range", "(", "0", ",", "shape_size", ")", ":", "\n", "          ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "+", "shape_size", "*", "dt", "]", "=", "1", "\n", "", "if", "col_dt", "in", "range", "(", "0", ",", "shape_size", ")", ":", "\n", "          ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "+", "dt", "]", "=", "1", "\n", "\n", "# the graph is cyclic, most left and most right are neighbours", "\n", "", "", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "<", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "shape_size", "-", "(", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ")", ",", "1", ")", ")", "+", "1", ")", "\n", "tar", "=", "tar", "*", "shape_size", "+", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "<", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "shape_size", "-", "(", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ")", ",", "1", ")", ")", "+", "1", ")", "\n", "tar", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "*", "shape_size", "+", "tar", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ">=", "shape_size", "-", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "(", "shape_size", "-", "1", "-", "\n", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ")", ")", ",", "\n", "1", ")", "\n", ")", "\n", "tar", "=", "tar", "*", "shape_size", "+", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ">=", "shape_size", "-", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "(", "shape_size", "-", "1", "-", "\n", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ")", ")", ",", "\n", "1", ")", "\n", ")", "\n", "tar", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "*", "shape_size", "+", "tar", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario.make_world": [[60, 78], ["examples.ising_model.multiagent.core.IsingWorld", "int", "numpy.zeros", "numpy.zeros", "Ising.Scenario.reset_world", "numpy.ceil", "examples.ising_model.multiagent.core.IsingAgent", "numpy.power", "range"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario.reset_world"], ["", "", "", "def", "make_world", "(", "self", ",", "num_agents", "=", "100", ",", "agent_view", "=", "1", ")", ":", "\n", "    ", "world", "=", "IsingWorld", "(", ")", "\n", "world", ".", "agent_view_sight", "=", "agent_view", "\n", "world", ".", "dim_spin", "=", "2", "\n", "world", ".", "dim_pos", "=", "2", "\n", "world", ".", "n_agents", "=", "num_agents", "\n", "world", ".", "shape_size", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "power", "(", "num_agents", ",", "1.0", "/", "world", ".", "dim_pos", ")", ")", ")", "\n", "world", ".", "global_state", "=", "np", ".", "zeros", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "# assume 0 external magnetic field", "\n", "world", ".", "field", "=", "np", ".", "zeros", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "\n", "world", ".", "agents", "=", "[", "IsingAgent", "(", "view_sight", "=", "world", ".", "agent_view_sight", ")", "\n", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "\n", "# make initial conditions", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario.reset_world": [[79, 100], ["numpy.array().reshape", "enumerate", "numpy.count_nonzero", "numpy.array", "numpy.where", "numpy.random.choice", "numpy.zeros", "Ising.Scenario._calc_mask", "world.global_state.flatten", "abs", "numpy.array", "range", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario._calc_mask"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "\n", "    ", "world_mat", "=", "np", ".", "array", "(", "\n", "range", "(", "np", ".", "power", "(", "world", ".", "shape_size", ",", "world", ".", "dim_pos", ")", ")", ")", ".", "reshape", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "# init agent state and global state", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "      ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "agent", ".", "state", ".", "id", "=", "i", "\n", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "where", "(", "world_mat", "==", "i", ")", "\n", "agent", ".", "state", ".", "spin", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "dim_spin", ")", "\n", "agent", ".", "spin_mask", "=", "np", ".", "zeros", "(", "world", ".", "n_agents", ")", "\n", "\n", "assert", "world", ".", "dim_pos", "==", "2", ",", "\"cyclic neighbour only support 2D now\"", "\n", "self", ".", "_calc_mask", "(", "agent", ",", "world", ".", "shape_size", ")", "\n", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "=", "agent", ".", "state", ".", "spin", "\n", "\n", "", "n_ups", "=", "np", ".", "count_nonzero", "(", "world", ".", "global_state", ".", "flatten", "(", ")", ")", "\n", "n_downs", "=", "world", ".", "n_agents", "-", "n_ups", "\n", "world", ".", "order_param", "=", "abs", "(", "n_ups", "-", "n_downs", ")", "/", "(", "world", ".", "n_agents", "+", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario.reward": [[101, 112], ["agent.spin_mask.reshape", "numpy.sum", "numpy.where", "int", "numpy.where", "numpy.sqrt", "world.global_state.flatten"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# turn the state into -1/1 for easy computing", "\n", "    ", "world", ".", "global_state", "[", "np", ".", "where", "(", "world", ".", "global_state", "==", "0", ")", "]", "=", "-", "1", "\n", "\n", "mask_display", "=", "agent", ".", "spin_mask", ".", "reshape", "(", "(", "int", "(", "np", ".", "sqrt", "(", "world", ".", "n_agents", ")", ")", ",", "-", "1", ")", ")", "\n", "\n", "local_reward", "=", "-", "0.5", "*", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "*", "np", ".", "sum", "(", "world", ".", "global_state", ".", "flatten", "(", ")", "*", "agent", ".", "spin_mask", ")", "\n", "\n", "world", ".", "global_state", "[", "np", ".", "where", "(", "world", ".", "global_state", "==", "-", "1", ")", "]", "=", "0", "\n", "return", "-", "local_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario.observation": [[113, 120], ["world.global_state.flatten", "numpy.where"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "# agent state is updated in the world.step() function already", "\n", "# update the changes of the world", "\n", "\n", "# return the neighbour state", "\n", "    ", "return", "world", ".", "global_state", ".", "flatten", "(", ")", "[", "np", ".", "where", "(", "agent", ".", "spin_mask", "==", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.Ising.Scenario.done": [[121, 125], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "    ", "if", "world", ".", "order_param", "==", "1.0", ":", "\n", "      ", "return", "True", "\n", "", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.ising_model.__init__.load": [[5, 8], ["os.join", "imp.load_source", "os.dirname"], "function", ["None"], ["# some alias", "\n", "GridWorld", "=", "gridworld", ".", "GridWorld", "\n", "ProcessingModel", "=", "model", ".", "ProcessingModel", "\n", "round", "=", "utility", ".", "rec_round", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingEntityState.__init__": [[5, 8], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "id", "=", "None", "\n", "self", ".", "p_pos", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingAgentState.__init__": [[11, 15], ["core.IsingEntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "IsingAgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# up or down", "\n", "self", ".", "spin", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingAction.__init__": [[18, 21], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# action", "\n", "    ", "self", ".", "a", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingEntity.__init__": [[25, 36], ["core.IsingEntityState"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# name", "\n", "    ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# state: position and spin", "\n", "self", ".", "state", "=", "IsingEntityState", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingAgent.__init__": [[39, 54], ["core.IsingEntity.__init__", "core.IsingAgentState", "core.IsingAction"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__"], ["  ", "def", "__init__", "(", "self", ",", "view_sight", "=", "1", ")", ":", "\n", "    ", "super", "(", "IsingAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "False", "\n", "# -1: observe the whole state, 0: itself, 1: neighbour of 1 unit", "\n", "self", ".", "view_sight", "=", "view_sight", "\n", "self", ".", "spin_mask", "=", "None", "# the mask for who is neighbours", "\n", "# state", "\n", "self", ".", "state", "=", "IsingAgentState", "(", ")", "\n", "self", ".", "state", ".", "spin_range", "=", "[", "0", ",", "1", "]", "\n", "# action", "\n", "self", ".", "action", "=", "IsingAction", "(", ")", "\n", "self", ".", "action", ".", "a_range", "=", "[", "0", ",", "1", "]", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.__init__": [[58, 82], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "    ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "n_agents", "=", "1", "\n", "self", ".", "agent_view_sight", "=", "1", "\n", "# position dimensionality", "\n", "self", ".", "dim_pos", "=", "2", "\n", "# state dimension", "\n", "self", ".", "dim_spin", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# world size", "\n", "self", ".", "shape_size", "=", "1", "\n", "# ising specific", "\n", "self", ".", "global_state", "=", "None", "# log all spins", "\n", "self", ".", "moment", "=", "1", "\n", "self", ".", "field", "=", "None", "# external magnetic field", "\n", "self", ".", "temperature", "=", ".1", "# Temperature (in units of energy)", "\n", "self", ".", "interaction", "=", "1", "# Interaction (ferromagnetic if positive,", "\n", "# antiferromagnetic if negative)", "\n", "self", ".", "order_param", "=", "1.0", "\n", "self", ".", "order_param_delta", "=", "0.01", "# log the change of order parameter for \"done\"", "\n", "self", ".", "n_up", "=", "0", "\n", "self", ".", "n_down", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.entities": [[84, 87], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.policy_agents": [[89, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "    ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.scripted_agents": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "    ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step": [[99, 115], ["numpy.count_nonzero", "agent.action_callback", "core.IsingWorld.update_agent_state", "core.IsingWorld.global_state.flatten", "abs"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.update_agent_state"], ["", "def", "step", "(", "self", ")", ":", "\n", "\n", "# set actions for scripted agents, no use for now", "\n", "    ", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "      ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "\n", "# update agent state, and to the global_state", "\n", "", "for", "agent", "in", "self", ".", "agents", ":", "\n", "      ", "self", ".", "update_agent_state", "(", "agent", ")", "\n", "self", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "=", "agent", ".", "state", ".", "spin", "\n", "\n", "# update the world's order parameters", "\n", "", "self", ".", "n_up", "=", "np", ".", "count_nonzero", "(", "self", ".", "global_state", ".", "flatten", "(", ")", ")", "\n", "self", ".", "n_down", "=", "self", ".", "n_agents", "-", "self", ".", "n_up", "\n", "order_param_old", "=", "self", ".", "order_param", "\n", "self", ".", "order_param", "=", "abs", "(", "self", ".", "n_up", "-", "self", ".", "n_down", ")", "/", "(", "self", ".", "n_agents", "+", "0.0", ")", "\n", "# self.order_param_delta = (self.order_param - order_param_old) /", "\n"]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.update_agent_state": [[118, 126], ["None"], "methods", ["None"], ["", "def", "update_agent_state", "(", "self", ",", "agent", ")", ":", "\n", "    ", "if", "agent", ".", "action", ".", "a", "==", "0", ":", "\n", "# agent.state.spin = agent.state.spin", "\n", "      ", "agent", ".", "state", ".", "spin", "=", "0", "\n", "", "else", ":", "\n", "# print(agent.name + \" change spin\")", "\n", "# agent.state.spin = 1.0 - agent.state.spin", "\n", "      ", "agent", ".", "state", ".", "spin", "=", "1", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv.__init__": [[11, 48], ["len", "environment.IsingMultiAgentEnv.observation_space.append", "len", "environment.IsingMultiAgentEnv.action_space.append", "NotImplementedError", "gym.spaces.MultiBinary", "gym.spaces.Discrete"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append"], ["\n", "# ====== RUN ======", "\n", "", "def", "get_observation", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "set_action", "(", "self", ",", "handle", ",", "actions", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "render", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "render_next_file", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "get_reward", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n", "# ====== INFO ======", "\n", "", "def", "get_num", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "get_action_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "get_view_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "def", "get_feature_space", "(", "self", ",", "handle", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._step": [[49, 79], ["action_n.reshape", "enumerate", "environment.IsingMultiAgentEnv.world.step", "numpy.sum", "environment.IsingMultiAgentEnv._set_action", "obs_n.append", "reward_n.append", "done_n.append", "int", "environment.IsingMultiAgentEnv._get_obs", "environment.IsingMultiAgentEnv._get_reward", "environment.IsingMultiAgentEnv._get_done", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.multiagent.core.IsingWorld.step", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._set_action", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_obs", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_reward", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_done"], []], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._reset": [[80, 89], ["environment.IsingMultiAgentEnv.reset_callback", "obs_n.append", "environment.IsingMultiAgentEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.mlii_mfrl.algo.tools.AgentMemory.append", "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_obs"], []], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_obs": [[91, 96], ["environment.IsingMultiAgentEnv.observation_callback", "numpy.zeros"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_done": [[98, 103], ["environment.IsingMultiAgentEnv.done_callback"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._get_reward": [[105, 110], ["environment.IsingMultiAgentEnv.reward_callback"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mlii_mfrl.multiagent.environment.IsingMultiAgentEnv._set_action": [[112, 115], ["len"], "methods", ["None"], []]}