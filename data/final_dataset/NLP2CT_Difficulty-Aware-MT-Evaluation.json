{"home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.__init__": [[5, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "encoded_ref", ")", ":", "\n", "        ", "self", ".", "encoded_ref", "=", "encoded_ref", "\n", "self", ".", "token_weights", "=", "{", "}", "\n", "self", ".", "encoded_hypos", "=", "[", "]", "\n", "self", ".", "sys_ref_status", "=", "[", "]", "\n", "self", ".", "sys_hypo_status", "=", "[", "]", "\n", "self", ".", "sys_ref_maxsim_loc", "=", "[", "]", "\n", "self", ".", "sys_hypo_maxsim_loc", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_encoded_hypos": [[14, 16], ["score_diffculty.BertScoreDifficulty.encoded_hypos.append"], "methods", ["None"], ["", "def", "add_encoded_hypos", "(", "self", ",", "encoded_hypos", ")", ":", "\n", "        ", "self", ".", "encoded_hypos", ".", "append", "(", "encoded_hypos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_ref_status": [[17, 19], ["score_diffculty.BertScoreDifficulty.sys_ref_status.append"], "methods", ["None"], ["", "def", "add_ref_status", "(", "self", ",", "ref_status", ")", ":", "\n", "        ", "self", ".", "sys_ref_status", ".", "append", "(", "ref_status", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_hypo_status": [[20, 22], ["score_diffculty.BertScoreDifficulty.sys_hypo_status.append"], "methods", ["None"], ["", "def", "add_hypo_status", "(", "self", ",", "hypo_status", ")", ":", "\n", "        ", "self", ".", "sys_hypo_status", ".", "append", "(", "hypo_status", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_ref_sloc": [[23, 25], ["score_diffculty.BertScoreDifficulty.sys_ref_maxsim_loc.append"], "methods", ["None"], ["", "def", "add_ref_sloc", "(", "self", ",", "ref_maxsim_loc", ")", ":", "\n", "        ", "self", ".", "sys_ref_maxsim_loc", ".", "append", "(", "ref_maxsim_loc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_hypo_sloc": [[26, 28], ["score_diffculty.BertScoreDifficulty.sys_hypo_maxsim_loc.append"], "methods", ["None"], ["", "def", "add_hypo_sloc", "(", "self", ",", "hypo_maxsim_loc", ")", ":", "\n", "        ", "self", ".", "sys_hypo_maxsim_loc", ".", "append", "(", "hypo_maxsim_loc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.cal_token_weights": [[29, 38], ["enumerate", "len", "len", "token_weights.keys", "token_weights.keys", "set"], "methods", ["None"], ["", "def", "cal_token_weights", "(", "self", ",", "weight", ")", ":", "\n", "        ", "token_weights", "=", "{", "}", "\n", "for", "idx", ",", "token", "in", "enumerate", "(", "self", ".", "encoded_ref", ")", ":", "\n", "            ", "if", "token", "not", "in", "token_weights", ".", "keys", "(", ")", ":", "\n", "                ", "token_weights", "[", "token", "]", "=", "weight", "[", "idx", "]", "\n", "", "else", ":", "\n", "                ", "token_weights", "[", "token", "]", "=", "(", "token_weights", "[", "token", "]", "+", "weight", "[", "idx", "]", ")", "/", "2", "\n", "", "", "assert", "len", "(", "token_weights", ".", "keys", "(", ")", ")", "==", "len", "(", "set", "(", "self", ".", "encoded_ref", ")", ")", "\n", "self", ".", "token_weights", "=", "token_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.normalized": [[39, 47], ["numpy.max", "print", "numpy.zeros"], "methods", ["None"], ["", "def", "normalized", "(", "self", ",", "weight_arr", ")", ":", "\n", "        ", "max_val", "=", "np", ".", "max", "(", "weight_arr", ")", "\n", "if", "max_val", "==", "0", "or", "max_val", "<", "1e-06", ":", "\n", "            ", "print", "(", "'Non-valuable sample'", ")", "\n", "return", "np", ".", "zeros", "(", "weight_arr", ".", "shape", ")", "\n", "", "else", ":", "\n", "# return softmax(weight_arr)", "\n", "            ", "return", "weight_arr", "/", "max_val", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.score_sent": [[48, 104], ["numpy.array", "numpy.mean", "numpy.mean", "score_diffculty.BertScoreDifficulty.cal_token_weights", "enumerate", "score_diffculty.BertScoreDifficulty.reshape", "scipy.special.softmax", "score_diffculty.BertScoreDifficulty.normalized", "numpy.sum", "numpy.zeros", "sent_P.append", "numpy.ones", "enumerate", "weighted_sent_P.append", "numpy.array", "numpy.array", "numpy.zeros.reshape", "len", "print", "sent_P.append", "weighted_sent_P.append", "sys_hypo.mean", "ipdb.set_trace", "len", "scipy.special.softmax", "score_diffculty.BertScoreDifficulty.normalized", "numpy.sum", "numpy.dot", "numpy.sum", "numpy.dot", "score_diffculty.BertScoreDifficulty.token_weights.keys", "numpy.sum", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.cal_token_weights", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.normalized", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.normalized"], ["", "", "def", "score_sent", "(", "self", ",", "softmax_norm", "=", "False", ",", "max_norm", "=", "False", ",", "range_one", "=", "False", ",", "ref_diff", "=", "False", ")", ":", "\n", "        ", "sys_ref_status", "=", "np", ".", "array", "(", "self", ".", "sys_ref_status", ")", "\n", "weight", "=", "np", ".", "mean", "(", "sys_ref_status", ",", "axis", "=", "0", ")", "\n", "weight", "=", "1.0", "-", "weight", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "if", "softmax_norm", ":", "\n", "            ", "weight", "=", "softmax", "(", "weight", ")", "\n", "", "if", "max_norm", ":", "\n", "            ", "weight", "=", "self", ".", "normalized", "(", "weight", ")", "\n", "", "assert", "sys_ref_status", ".", "shape", "[", "1", "]", "==", "weight", ".", "shape", "[", "0", "]", "\n", "# Cal R", "\n", "sent_R", "=", "np", ".", "mean", "(", "sys_ref_status", ",", "axis", "=", "1", ")", "\n", "if", "np", ".", "sum", "(", "weight", ")", "==", "0", ":", "\n", "            ", "weighted_sent_R", "=", "np", ".", "zeros", "(", "[", "sys_ref_status", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "range_one", ":", "\n", "                ", "weighted_sent_R", "=", "np", ".", "dot", "(", "sys_ref_status", ",", "weight", ")", "/", "np", ".", "sum", "(", "weight", ")", "\n", "", "else", ":", "\n", "                ", "weighted_sent_R", "=", "np", ".", "dot", "(", "sys_ref_status", ",", "weight", ")", "/", "weight", ".", "shape", "[", "0", "]", "\n", "", "", "self", ".", "cal_token_weights", "(", "weight", ")", "\n", "# Cal P", "\n", "sent_P", "=", "[", "]", "\n", "weighted_sent_P", "=", "[", "]", "\n", "for", "sys_no", ",", "sys_hypo", "in", "enumerate", "(", "self", ".", "sys_hypo_status", ")", ":", "\n", "            ", "if", "len", "(", "sys_hypo", ")", "==", "0", ":", "\n", "                ", "print", "(", "'Empty Hypo, Set P=0'", ")", "\n", "sent_P", ".", "append", "(", "0.0", ")", "\n", "weighted_sent_P", ".", "append", "(", "0.0", ")", "\n", "continue", "\n", "", "sent_P", ".", "append", "(", "sys_hypo", ".", "mean", "(", ")", ")", "\n", "encoded_sys_hypo", "=", "self", ".", "encoded_hypos", "[", "sys_no", "]", "\n", "sent_P_weight", "=", "np", ".", "ones", "(", "sys_hypo", ".", "shape", "[", "0", "]", ")", "\n", "for", "loc", ",", "hypo_token", "in", "enumerate", "(", "encoded_sys_hypo", ")", ":", "\n", "                ", "if", "hypo_token", "in", "self", ".", "token_weights", ".", "keys", "(", ")", ":", "\n", "                    ", "sent_P_weight", "[", "loc", "]", "=", "self", ".", "token_weights", "[", "hypo_token", "]", "\n", "", "elif", "ref_diff", ":", "\n", "                    ", "sent_P_weight", "[", "loc", "]", "=", "weight", "[", "self", ".", "sys_hypo_maxsim_loc", "[", "sys_no", "]", "[", "loc", "]", "]", "[", "0", "]", "\n", "\n", "", "", "if", "self", ".", "sys_hypo_maxsim_loc", "[", "sys_no", "]", ".", "shape", "!=", "sys_hypo", ".", "shape", ":", "\n", "                ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "assert", "len", "(", "encoded_sys_hypo", ")", "==", "sys_hypo", ".", "shape", "[", "0", "]", "\n", "assert", "sys_hypo", ".", "shape", "==", "sent_P_weight", ".", "shape", "\n", "if", "softmax_norm", ":", "\n", "                ", "sent_P_weight", "=", "softmax", "(", "sent_P_weight", ")", "\n", "", "if", "max_norm", ":", "\n", "                ", "sent_P_weight", "=", "self", ".", "normalized", "(", "sent_P_weight", ")", "\n", "\n", "", "if", "np", ".", "sum", "(", "sent_P_weight", ")", "==", "0", ":", "\n", "                ", "weighted_P", "=", "0", "\n", "", "else", ":", "\n", "                ", "if", "range_one", ":", "\n", "                    ", "weighted_P", "=", "np", ".", "sum", "(", "sys_hypo", "*", "sent_P_weight", ")", "/", "np", ".", "sum", "(", "sent_P_weight", ")", "\n", "", "else", ":", "\n", "                    ", "weighted_P", "=", "(", "sys_hypo", "*", "sent_P_weight", ")", ".", "mean", "(", ")", "\n", "", "", "weighted_sent_P", ".", "append", "(", "weighted_P", ")", "\n", "", "return", "np", ".", "array", "(", "sent_P", ")", ",", "sent_R", ",", "np", ".", "array", "(", "\n", "weighted_sent_P", ")", ",", "weighted_sent_R", ".", "reshape", "(", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score.score": [[33, 175], ["utils.get_tokenizer", "utils.get_model", "utils.get_model.to", "time.perf_counter", "utils.bert_cos_score_idf().cpu", "len", "len", "isinstance", "zip", "lang.lower.lower", "collections.defaultdict", "isinstance", "print", "torch.stack", "os.path.isfile", "print", "tuple", "ref_group_boundaries.append", "len", "torch.cuda.is_available", "time.perf_counter", "utils.get_idf_dict", "utils.bert_cos_score_idf", "max_preds.append", "os.path.join", "print", "time.perf_counter", "len", "print", "print", "print", "os.path.dirname", "[].float", "[].unsqueeze().float", "utils.get_hash", "all_preds[].max", "len", "[].unsqueeze", "len", "time.perf_counter", "torch.from_numpy", "pandas.read_csv().iloc[].to_numpy", "torch.from_numpy", "pandas.read_csv().to_numpy", "pandas.read_csv", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_tokenizer", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_model", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_idf_dict", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.bert_cos_score_idf", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_hash"], ["def", "score", "(", "\n", "cands", ",", "\n", "refs", ",", "\n", "model_type", "=", "None", ",", "\n", "num_layers", "=", "None", ",", "\n", "verbose", "=", "False", ",", "\n", "idf", "=", "False", ",", "\n", "device", "=", "None", ",", "\n", "batch_size", "=", "64", ",", "\n", "nthreads", "=", "4", ",", "\n", "all_layers", "=", "False", ",", "\n", "lang", "=", "None", ",", "\n", "return_hash", "=", "False", ",", "\n", "rescale_with_baseline", "=", "False", ",", "\n", "baseline_path", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    BERTScore metric.\n\n    Args:\n        - :param: `cands` (list of str): candidate sentences\n        - :param: `refs` (list of str or list of list of str): reference sentences\n        - :param: `model_type` (str): bert specification, default using the suggested\n                  model for the target langauge; has to specify at least one of\n                  `model_type` or `lang`\n        - :param: `num_layers` (int): the layer of representation to use.\n                  default using the number of layer tuned on WMT16 correlation data\n        - :param: `verbose` (bool): turn on intermediate status update\n        - :param: `idf` (bool or dict): use idf weighting, can also be a precomputed idf_dict\n        - :param: `device` (str): on which the contextual embedding model will be allocated on.\n                  If this argument is None, the model lives on cuda:0 if cuda is available.\n        - :param: `nthreads` (int): number of threads\n        - :param: `batch_size` (int): bert score processing batch size\n        - :param: `lang` (str): language of the sentences; has to specify\n                  at least one of `model_type` or `lang`. `lang` needs to be\n                  specified when `rescale_with_baseline` is True.\n        - :param: `return_hash` (bool): return hash code of the setting\n        - :param: `rescale_with_baseline` (bool): rescale bertscore with pre-computed baseline\n        - :param: `baseline_path` (str): customized baseline file\n\n    Return:\n        - :param: `(P, R, F)`: each is of shape (N); N = number of input\n                  candidate reference pairs. if returning hashcode, the\n                  output will be ((P, R, F), hashcode). If a candidate have\n                  multiple references, the returned score of this candidate is\n                  the *best* score among all references.\n    \"\"\"", "\n", "assert", "len", "(", "cands", ")", "==", "len", "(", "refs", ")", ",", "\"Different number of candidates and references\"", "\n", "\n", "assert", "lang", "is", "not", "None", "or", "model_type", "is", "not", "None", ",", "\"Either lang or model_type should be specified\"", "\n", "\n", "ref_group_boundaries", "=", "None", "\n", "if", "not", "isinstance", "(", "refs", "[", "0", "]", ",", "str", ")", ":", "\n", "        ", "ref_group_boundaries", "=", "[", "]", "\n", "ori_cands", ",", "ori_refs", "=", "cands", ",", "refs", "\n", "cands", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "count", "=", "0", "\n", "for", "cand", ",", "ref_group", "in", "zip", "(", "ori_cands", ",", "ori_refs", ")", ":", "\n", "            ", "cands", "+=", "[", "cand", "]", "*", "len", "(", "ref_group", ")", "\n", "refs", "+=", "ref_group", "\n", "ref_group_boundaries", ".", "append", "(", "(", "count", ",", "count", "+", "len", "(", "ref_group", ")", ")", ")", "\n", "count", "+=", "len", "(", "ref_group", ")", "\n", "\n", "", "", "if", "rescale_with_baseline", ":", "\n", "        ", "assert", "lang", "is", "not", "None", ",", "\"Need to specify Language when rescaling with baseline\"", "\n", "\n", "", "if", "model_type", "is", "None", ":", "\n", "        ", "lang", "=", "lang", ".", "lower", "(", ")", "\n", "model_type", "=", "lang2model", "[", "lang", "]", "\n", "", "if", "num_layers", "is", "None", ":", "\n", "        ", "num_layers", "=", "model2layers", "[", "model_type", "]", "\n", "\n", "", "tokenizer", "=", "get_tokenizer", "(", "model_type", ")", "\n", "model", "=", "get_model", "(", "model_type", ",", "num_layers", ",", "all_layers", ")", "\n", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "not", "idf", ":", "\n", "        ", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "1.0", ")", "\n", "# set idf for [SEP] and [CLS] to 0", "\n", "idf_dict", "[", "tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "idf_dict", "[", "tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "", "elif", "isinstance", "(", "idf", ",", "dict", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"using predefined IDF dict...\"", ")", "\n", "", "idf_dict", "=", "idf", "\n", "", "else", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"preparing IDF dict...\"", ")", "\n", "", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "idf_dict", "=", "get_idf_dict", "(", "refs", ",", "tokenizer", ",", "nthreads", "=", "nthreads", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"done in {:.2f} seconds\"", ".", "format", "(", "time", ".", "perf_counter", "(", ")", "-", "start", ")", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"calculating scores...\"", ")", "\n", "", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "all_preds", "=", "bert_cos_score_idf", "(", "\n", "model", ",", "\n", "refs", ",", "\n", "cands", ",", "\n", "tokenizer", ",", "\n", "idf_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "device", "=", "device", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "all_layers", "=", "all_layers", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "if", "ref_group_boundaries", "is", "not", "None", ":", "\n", "        ", "max_preds", "=", "[", "]", "\n", "for", "beg", ",", "end", "in", "ref_group_boundaries", ":", "\n", "            ", "max_preds", ".", "append", "(", "all_preds", "[", "beg", ":", "end", "]", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ")", "\n", "", "all_preds", "=", "torch", ".", "stack", "(", "max_preds", ",", "dim", "=", "0", ")", "\n", "\n", "", "use_custom_baseline", "=", "baseline_path", "is", "not", "None", "\n", "if", "rescale_with_baseline", ":", "\n", "        ", "if", "baseline_path", "is", "None", ":", "\n", "            ", "baseline_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "f\"rescale_baseline/{lang}/{model_type}.tsv\"", ")", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "baseline_path", ")", ":", "\n", "            ", "if", "not", "all_layers", ":", "\n", "                ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "iloc", "[", "num_layers", "]", ".", "to_numpy", "(", ")", ")", "[", "1", ":", "]", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "to_numpy", "(", ")", ")", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "\n", "", "all_preds", "=", "(", "all_preds", "-", "baselines", ")", "/", "(", "1", "-", "baselines", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Warning: Baseline not Found for {model_type} on {lang} at {baseline_path}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "", "out", "=", "all_preds", "[", "...", ",", "0", "]", ",", "all_preds", "[", "...", ",", "1", "]", ",", "all_preds", "[", "...", ",", "2", "]", "# P, R, F", "\n", "\n", "if", "verbose", ":", "\n", "        ", "time_diff", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "print", "(", "f\"done in {time_diff:.2f} seconds, {len(refs) / time_diff:.2f} sentences/sec\"", ")", "\n", "\n", "", "if", "return_hash", ":", "\n", "        ", "return", "tuple", "(", "\n", "[", "out", ",", "get_hash", "(", "model_type", ",", "num_layers", ",", "idf", ",", "rescale_with_baseline", ",", "use_custom_baseline", "=", "use_custom_baseline", ")", "]", "\n", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score.compute_diff": [[176, 317], ["utils.get_tokenizer", "enumerate", "lang.lower.lower", "score_diffculty.BertScoreDifficulty", "utils.get_model", "utils.get_model.to", "time.perf_counter", "utils.bert_cos_score_idf", "torch.stack.cpu", "range", "len", "len", "isinstance", "zip", "collections.defaultdict", "isinstance", "print", "torch.stack", "os.path.isfile", "print", "tuple", "outs.append", "outs.append", "len", "sents_diff_dict[].add_encoded_hypos", "sents_diff_dict[].add_ref_status", "sents_diff_dict[].add_hypo_status", "sents_diff_dict[].add_ref_sloc", "sents_diff_dict[].add_hypo_sloc", "str", "utils.sent_encode", "ref_group_boundaries.append", "len", "torch.cuda.is_available", "time.perf_counter", "utils.get_idf_dict", "max_preds.append", "os.path.join", "print", "time.perf_counter", "baselines[].item", "ref_maxsim_loc[].numpy", "hypo_maxsim_loc[].numpy", "len", "print", "print", "print", "os.path.dirname", "[].float", "[].unsqueeze().float", "utils.get_hash", "utils.sent_encode", "all_preds[].max", "ref_maxsim[].numpy", "hypo_maxsim[].numpy", "ref_maxsim[].numpy", "hypo_maxsim[].numpy", "len", "[].unsqueeze", "len", "str", "str", "str", "str", "str", "time.perf_counter", "torch.from_numpy", "pandas.read_csv().iloc[].to_numpy", "torch.from_numpy", "pandas.read_csv().to_numpy", "pandas.read_csv", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_tokenizer", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_model", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.bert_cos_score_idf", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_encoded_hypos", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_ref_status", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_hypo_status", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_ref_sloc", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.add_hypo_sloc", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_idf_dict", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_hash", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode"], ["", "def", "compute_diff", "(", "\n", "sys_cands", ",", "\n", "refs", ",", "\n", "model_type", "=", "None", ",", "\n", "num_layers", "=", "None", ",", "\n", "verbose", "=", "False", ",", "\n", "idf", "=", "False", ",", "\n", "device", "=", "None", ",", "\n", "batch_size", "=", "64", ",", "\n", "nthreads", "=", "4", ",", "\n", "all_layers", "=", "False", ",", "\n", "lang", "=", "None", ",", "\n", "return_hash", "=", "False", ",", "\n", "rescale_with_baseline", "=", "False", ",", "\n", "baseline_path", "=", "None", ",", "\n", ")", ":", "\n", "    ", "outs", "=", "[", "]", "\n", "sents_diff_dict", "=", "{", "}", "\n", "\n", "if", "model_type", "is", "None", ":", "\n", "        ", "lang", "=", "lang", ".", "lower", "(", ")", "\n", "model_type", "=", "lang2model", "[", "lang", "]", "\n", "", "if", "num_layers", "is", "None", ":", "\n", "        ", "num_layers", "=", "model2layers", "[", "model_type", "]", "\n", "\n", "", "tokenizer", "=", "get_tokenizer", "(", "model_type", ")", "\n", "for", "idx", ",", "ref", "in", "enumerate", "(", "refs", ")", ":", "\n", "        ", "sents_diff_dict", "[", "str", "(", "idx", ")", "]", "=", "BertScoreDifficulty", "(", "sent_encode", "(", "tokenizer", ",", "ref", "[", "0", "]", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "", "for", "cands", "in", "sys_cands", ":", "\n", "        ", "assert", "len", "(", "cands", ")", "==", "len", "(", "refs", ")", ",", "\"Different number of candidates and references\"", "\n", "\n", "assert", "lang", "is", "not", "None", "or", "model_type", "is", "not", "None", ",", "\"Either lang or model_type should be specified\"", "\n", "\n", "ref_group_boundaries", "=", "None", "\n", "if", "not", "isinstance", "(", "refs", "[", "0", "]", ",", "str", ")", ":", "\n", "            ", "ref_group_boundaries", "=", "[", "]", "\n", "ori_cands", ",", "ori_refs", "=", "cands", ",", "refs", "\n", "cands", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "count", "=", "0", "\n", "for", "cand", ",", "ref_group", "in", "zip", "(", "ori_cands", ",", "ori_refs", ")", ":", "\n", "                ", "cands", "+=", "[", "cand", "]", "*", "len", "(", "ref_group", ")", "\n", "refs", "+=", "ref_group", "\n", "ref_group_boundaries", ".", "append", "(", "(", "count", ",", "count", "+", "len", "(", "ref_group", ")", ")", ")", "\n", "count", "+=", "len", "(", "ref_group", ")", "\n", "\n", "", "", "if", "rescale_with_baseline", ":", "\n", "            ", "assert", "lang", "is", "not", "None", ",", "\"Need to specify Language when rescaling with baseline\"", "\n", "\n", "", "model", "=", "get_model", "(", "model_type", ",", "num_layers", ",", "all_layers", ")", "\n", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "not", "idf", ":", "\n", "            ", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "1.0", ")", "\n", "# set idf for [SEP] and [CLS] to 0", "\n", "idf_dict", "[", "tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "idf_dict", "[", "tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "", "elif", "isinstance", "(", "idf", ",", "dict", ")", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "\"using predefined IDF dict...\"", ")", "\n", "", "idf_dict", "=", "idf", "\n", "", "else", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "\"preparing IDF dict...\"", ")", "\n", "", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "idf_dict", "=", "get_idf_dict", "(", "refs", ",", "tokenizer", ",", "nthreads", "=", "nthreads", ")", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "\"done in {:.2f} seconds\"", ".", "format", "(", "time", ".", "perf_counter", "(", ")", "-", "start", ")", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"calculating scores...\"", ")", "\n", "", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "all_preds", ",", "ref_maxsim", ",", "hypo_maxsim", ",", "ref_maxsim_loc", ",", "hypo_maxsim_loc", "=", "bert_cos_score_idf", "(", "\n", "model", ",", "\n", "refs", ",", "\n", "cands", ",", "\n", "tokenizer", ",", "\n", "idf_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "device", "=", "device", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "all_layers", "=", "all_layers", ",", "\n", "return_details", "=", "True", "\n", ")", "\n", "all_preds", "=", "all_preds", ".", "cpu", "(", ")", "\n", "# add system status to diffculty class", "\n", "\n", "if", "ref_group_boundaries", "is", "not", "None", ":", "\n", "            ", "max_preds", "=", "[", "]", "\n", "for", "beg", ",", "end", "in", "ref_group_boundaries", ":", "\n", "                ", "max_preds", ".", "append", "(", "all_preds", "[", "beg", ":", "end", "]", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ")", "\n", "", "all_preds", "=", "torch", ".", "stack", "(", "max_preds", ",", "dim", "=", "0", ")", "\n", "\n", "", "no_baseline_flag", "=", "False", "\n", "# use_custom_baseline = baseline_path is not None", "\n", "if", "rescale_with_baseline", ":", "\n", "            ", "if", "baseline_path", "is", "None", ":", "\n", "                ", "baseline_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "f\"rescale_baseline/{lang}/{model_type}.tsv\"", ")", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "baseline_path", ")", ":", "\n", "                ", "if", "not", "all_layers", ":", "\n", "                    ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "iloc", "[", "num_layers", "]", ".", "to_numpy", "(", ")", ")", "[", "1", ":", "]", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                    ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "to_numpy", "(", ")", ")", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "\n", "", "all_preds", "=", "(", "all_preds", "-", "baselines", ")", "/", "(", "1", "-", "baselines", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f\"Warning: Baseline not Found for {model_type} on {lang} at {baseline_path}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "no_baseline_flag", "=", "True", "\n", "\n", "", "", "out", "=", "all_preds", "[", "...", ",", "0", "]", ",", "all_preds", "[", "...", ",", "1", "]", ",", "all_preds", "[", "...", ",", "2", "]", "# P, R, F", "\n", "\n", "if", "verbose", ":", "\n", "            ", "time_diff", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "print", "(", "f\"done in {time_diff:.2f} seconds, {len(refs) / time_diff:.2f} sentences/sec\"", ")", "\n", "\n", "", "if", "return_hash", ":", "\n", "            ", "out", "=", "tuple", "(", "\n", "[", "out", ",", "get_hash", "(", "model_type", ",", "num_layers", ",", "idf", ",", "rescale_with_baseline", ",", "use_custom_baseline", "=", "False", ")", "]", "\n", ")", "\n", "outs", ".", "append", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "outs", ".", "append", "(", "out", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "0", ",", "len", "(", "refs", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "scale", "=", "baselines", "[", "2", "]", ".", "item", "(", ")", "\n", "sys_ref_status", "=", "(", "ref_maxsim", "[", "idx", "]", ".", "numpy", "(", ")", "-", "scale", ")", "/", "(", "1", "-", "scale", ")", "\n", "sys_hypo_status", "=", "(", "hypo_maxsim", "[", "idx", "]", ".", "numpy", "(", ")", "-", "scale", ")", "/", "(", "1", "-", "scale", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "if", "no_baseline_flag", ":", "\n", "                    ", "sys_ref_status", "=", "ref_maxsim", "[", "idx", "]", ".", "numpy", "(", ")", "\n", "sys_hypo_status", "=", "hypo_maxsim", "[", "idx", "]", ".", "numpy", "(", ")", "\n", "", "", "sents_diff_dict", "[", "str", "(", "idx", ")", "]", ".", "add_encoded_hypos", "(", "sent_encode", "(", "tokenizer", ",", "cands", "[", "idx", "]", ")", "[", "1", ":", "-", "1", "]", ")", "\n", "sents_diff_dict", "[", "str", "(", "idx", ")", "]", ".", "add_ref_status", "(", "sys_ref_status", ")", "\n", "sents_diff_dict", "[", "str", "(", "idx", ")", "]", ".", "add_hypo_status", "(", "sys_hypo_status", ")", "\n", "sents_diff_dict", "[", "str", "(", "idx", ")", "]", ".", "add_ref_sloc", "(", "ref_maxsim_loc", "[", "idx", "]", ".", "numpy", "(", ")", ")", "\n", "sents_diff_dict", "[", "str", "(", "idx", ")", "]", ".", "add_hypo_sloc", "(", "hypo_maxsim_loc", "[", "idx", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "return", "outs", ",", "sents_diff_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score.bert_score_with_diff": [[319, 349], ["sents_diff_dict.keys", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "sents_diff_dict[].score_sent", "np.mean.append", "np.mean.append", "np.mean.append", "np.mean.append", "numpy.array", "numpy.array", "range", "numpy.array", "numpy.array", "numpy.array", "len", "len", "len", "len", "len", "len", "numpy.array", "numpy.array", "len", "np.array.append"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score_diffculty.BertScoreDifficulty.score_sent"], ["", "def", "bert_score_with_diff", "(", "sents_diff_dict", ",", "softmax_norm", "=", "False", ",", "max_norm", "=", "False", ",", "range_one", "=", "False", ",", "ref_diff", "=", "False", ",", "seg_level", "=", "False", ")", ":", "\n", "    ", "all_P", "=", "[", "]", "\n", "all_R", "=", "[", "]", "\n", "weight_P", "=", "[", "]", "\n", "weight_R", "=", "[", "]", "\n", "for", "sent", "in", "sents_diff_dict", ".", "keys", "(", ")", ":", "\n", "        ", "sent_P", ",", "sent_R", ",", "weighted_sent_P", ",", "weighted_sent_R", "=", "sents_diff_dict", "[", "sent", "]", ".", "score_sent", "(", "softmax_norm", "=", "softmax_norm", ",", "max_norm", "=", "max_norm", ",", "range_one", "=", "range_one", ",", "ref_diff", "=", "ref_diff", ")", "\n", "all_P", ".", "append", "(", "sent_P", ")", "\n", "all_R", ".", "append", "(", "sent_R", ")", "\n", "weight_P", ".", "append", "(", "weighted_sent_P", ")", "\n", "weight_R", ".", "append", "(", "weighted_sent_R", ")", "\n", "", "all_P", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "all_P", ")", ",", "axis", "=", "0", ")", "\n", "all_R", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "all_R", ")", ",", "axis", "=", "0", ")", "\n", "F", "=", "2", "*", "all_P", "*", "all_R", "/", "(", "all_P", "+", "all_R", ")", "\n", "\n", "if", "seg_level", ":", "\n", "        ", "seg_weight_P", "=", "np", ".", "array", "(", "weight_P", ")", ".", "T", "\n", "seg_weight_R", "=", "np", ".", "array", "(", "weight_R", ")", ".", "T", "\n", "seg_weight_F", "=", "2", "*", "seg_weight_P", "*", "seg_weight_R", "/", "(", "seg_weight_P", "+", "seg_weight_R", ")", "\n", "seg_weight_F", "=", "[", "]", "\n", "for", "sysno", "in", "range", "(", "len", "(", "seg_weight_P", ")", ")", ":", "\n", "            ", "seg_weight_F", ".", "append", "(", "2", "*", "seg_weight_P", "[", "sysno", "]", "*", "seg_weight_R", "[", "sysno", "]", "/", "(", "seg_weight_P", "[", "sysno", "]", "+", "seg_weight_R", "[", "sysno", "]", ")", ")", "\n", "", "seg_weight_F", "=", "np", ".", "array", "(", "seg_weight_F", ")", "\n", "return", "seg_weight_P", ",", "seg_weight_R", ",", "seg_weight_F", "\n", "\n", "", "weight_P", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "weight_P", ")", ",", "axis", "=", "0", ")", "\n", "weight_R", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "weight_R", ")", ",", "axis", "=", "0", ")", "\n", "weight_F", "=", "2", "*", "weight_P", "*", "weight_R", "/", "(", "weight_P", "+", "weight_R", ")", "# systems", "\n", "assert", "len", "(", "all_P", ")", "==", "len", "(", "all_R", ")", "==", "len", "(", "weight_P", ")", "==", "len", "(", "weight_R", ")", "==", "len", "(", "F", ")", "==", "len", "(", "weight_F", ")", "\n", "return", "all_P", ",", "all_R", ",", "F", ",", "weight_P", ",", "weight_R", ",", "weight_F", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score.plot_example": [[351, 472], ["isinstance", "isinstance", "utils.get_tokenizer", "utils.get_model", "utils.get_model.to", "collections.defaultdict", "utils.get_bert_embedding", "utils.get_bert_embedding", "ref_embedding.div_", "hyp_embedding.div_", "torch.bmm", "sim.squeeze().cpu.squeeze().cpu", "matplotlib.subplots", "ax.imshow", "ax.set_xticks", "ax.set_yticks", "ax.set_xticklabels", "ax.set_yticklabels", "ax.grid", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "mpl_toolkits.axes_grid1.make_axes_locatable", "mpl_toolkits.axes_grid1.make_axes_locatable.append_axes", "fig.colorbar", "matplotlib.setp", "range", "fig.tight_layout", "matplotlib.show", "lang.lower.lower", "torch.cuda.is_available", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "ref_embedding.transpose", "os.path.isfile", "numpy.arange", "numpy.arange", "ax.get_xticklabels", "len", "range", "pickle.dump", "matplotlib.savefig", "print", "sim.squeeze().cpu.squeeze", "utils.get_tokenizer.decode", "utils.get_tokenizer.decode", "os.path.join", "[].float", "print", "len", "len", "len", "ax.text", "open", "torch.norm", "torch.norm", "utils.sent_encode", "utils.sent_encode", "os.path.dirname", "len", "len", "baselines[].item", "baselines[].item", "sim[].item", "torch.from_numpy", "pandas.read_csv().iloc[].to_numpy", "sim[].item", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_tokenizer", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_model", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_bert_embedding", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_bert_embedding", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode"], ["", "def", "plot_example", "(", "\n", "candidate", ",", "\n", "reference", ",", "\n", "model_type", "=", "None", ",", "\n", "num_layers", "=", "None", ",", "\n", "lang", "=", "None", ",", "\n", "rescale_with_baseline", "=", "False", ",", "\n", "baseline_path", "=", "None", ",", "\n", "fname", "=", "\"\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    BERTScore metric.\n\n    Args:\n        - :param: `candidate` (str): a candidate sentence\n        - :param: `reference` (str): a reference sentence\n        - :param: `verbose` (bool): turn on intermediate status update\n        - :param: `model_type` (str): bert specification, default using the suggested\n                  model for the target langauge; has to specify at least one of\n                  `model_type` or `lang`\n        - :param: `num_layers` (int): the layer of representation to use\n        - :param: `lang` (str): language of the sentences; has to specify\n                  at least one of `model_type` or `lang`. `lang` needs to be\n                  specified when `rescale_with_baseline` is True.\n        - :param: `return_hash` (bool): return hash code of the setting\n        - :param: `rescale_with_baseline` (bool): rescale bertscore with pre-computed baseline\n        - :param: `fname` (str): path to save the output plot\n    \"\"\"", "\n", "assert", "isinstance", "(", "candidate", ",", "str", ")", "\n", "assert", "isinstance", "(", "reference", ",", "str", ")", "\n", "\n", "assert", "lang", "is", "not", "None", "or", "model_type", "is", "not", "None", ",", "\"Either lang or model_type should be specified\"", "\n", "\n", "if", "rescale_with_baseline", ":", "\n", "        ", "assert", "lang", "is", "not", "None", ",", "\"Need to specify Language when rescaling with baseline\"", "\n", "\n", "", "if", "model_type", "is", "None", ":", "\n", "        ", "lang", "=", "lang", ".", "lower", "(", ")", "\n", "model_type", "=", "lang2model", "[", "lang", "]", "\n", "", "if", "num_layers", "is", "None", ":", "\n", "        ", "num_layers", "=", "model2layers", "[", "model_type", "]", "\n", "\n", "", "tokenizer", "=", "get_tokenizer", "(", "model_type", ")", "\n", "model", "=", "get_model", "(", "model_type", ",", "num_layers", ")", "\n", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "1.0", ")", "\n", "# set idf for [SEP] and [CLS] to 0", "\n", "idf_dict", "[", "tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "idf_dict", "[", "tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "\n", "hyp_embedding", ",", "masks", ",", "padded_idf", "=", "get_bert_embedding", "(", "\n", "[", "candidate", "]", ",", "model", ",", "tokenizer", ",", "idf_dict", ",", "device", "=", "device", ",", "all_layers", "=", "False", "\n", ")", "\n", "ref_embedding", ",", "masks", ",", "padded_idf", "=", "get_bert_embedding", "(", "\n", "[", "reference", "]", ",", "model", ",", "tokenizer", ",", "idf_dict", ",", "device", "=", "device", ",", "all_layers", "=", "False", "\n", ")", "\n", "ref_embedding", ".", "div_", "(", "torch", ".", "norm", "(", "ref_embedding", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "hyp_embedding", ".", "div_", "(", "torch", ".", "norm", "(", "hyp_embedding", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "sim", "=", "torch", ".", "bmm", "(", "hyp_embedding", ",", "ref_embedding", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "sim", "=", "sim", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", "\n", "\n", "# remove [CLS] and [SEP] tokens", "\n", "r_tokens", "=", "[", "tokenizer", ".", "decode", "(", "[", "i", "]", ")", "for", "i", "in", "sent_encode", "(", "tokenizer", ",", "reference", ")", "]", "[", "1", ":", "-", "1", "]", "\n", "h_tokens", "=", "[", "tokenizer", ".", "decode", "(", "[", "i", "]", ")", "for", "i", "in", "sent_encode", "(", "tokenizer", ",", "candidate", ")", "]", "[", "1", ":", "-", "1", "]", "\n", "sim", "=", "sim", "[", "1", ":", "-", "1", ",", "1", ":", "-", "1", "]", "\n", "\n", "if", "rescale_with_baseline", ":", "\n", "        ", "if", "baseline_path", "is", "None", ":", "\n", "            ", "baseline_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "f\"rescale_baseline/{lang}/{model_type}.tsv\"", ")", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "baseline_path", ")", ":", "\n", "            ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "iloc", "[", "num_layers", "]", ".", "to_numpy", "(", ")", ")", "[", "1", ":", "]", ".", "float", "(", ")", "\n", "sim", "=", "(", "sim", "-", "baselines", "[", "2", "]", ".", "item", "(", ")", ")", "/", "(", "1", "-", "baselines", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Warning: Baseline not Found for {model_type} on {lang} at {baseline_path}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "len", "(", "r_tokens", ")", ",", "len", "(", "h_tokens", ")", ")", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "sim", ",", "cmap", "=", "\"Blues\"", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "\n", "# We want to show all ticks...", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "r_tokens", ")", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "h_tokens", ")", ")", ")", "\n", "# ... and label them with the respective list entries", "\n", "ax", ".", "set_xticklabels", "(", "r_tokens", ",", "fontsize", "=", "13", ")", "\n", "ax", ".", "set_yticklabels", "(", "h_tokens", ",", "fontsize", "=", "13", ")", "\n", "ax", ".", "grid", "(", "False", ")", "\n", "plt", ".", "xlabel", "(", "\"Reference (tokenized)\"", ",", "fontsize", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "\"Candidate (tokenized)\"", ",", "fontsize", "=", "14", ")", "\n", "title", "=", "\"Similarity Matrix\"", "\n", "if", "rescale_with_baseline", ":", "\n", "        ", "title", "+=", "\" (after Rescaling)\"", "\n", "", "plt", ".", "title", "(", "title", ",", "fontsize", "=", "14", ")", "\n", "\n", "divider", "=", "make_axes_locatable", "(", "ax", ")", "\n", "cax", "=", "divider", ".", "append_axes", "(", "\"right\"", ",", "size", "=", "\"2%\"", ",", "pad", "=", "0.2", ")", "\n", "fig", ".", "colorbar", "(", "im", ",", "cax", "=", "cax", ")", "\n", "\n", "# Rotate the tick labels and set their alignment.", "\n", "plt", ".", "setp", "(", "ax", ".", "get_xticklabels", "(", ")", ",", "rotation", "=", "45", ",", "ha", "=", "\"right\"", ",", "rotation_mode", "=", "\"anchor\"", ")", "\n", "\n", "# Loop over data dimensions and create text annotations.", "\n", "for", "i", "in", "range", "(", "len", "(", "h_tokens", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "r_tokens", ")", ")", ":", "\n", "            ", "text", "=", "ax", ".", "text", "(", "\n", "j", ",", "\n", "i", ",", "\n", "\"{:.3f}\"", ".", "format", "(", "sim", "[", "i", ",", "j", "]", ".", "item", "(", ")", ")", ",", "\n", "ha", "=", "\"center\"", ",", "\n", "va", "=", "\"center\"", ",", "\n", "color", "=", "\"k\"", "if", "sim", "[", "i", ",", "j", "]", ".", "item", "(", ")", "<", "0.5", "else", "\"w\"", ",", "\n", ")", "\n", "\n", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "if", "fname", "!=", "\"\"", ":", "\n", "        ", "import", "pickle", "\n", "dumped_item", "=", "(", "sim", ",", "r_tokens", ",", "h_tokens", ")", "\n", "pickle", ".", "dump", "(", "dumped_item", ",", "open", "(", "fname", "+", "'.pkl'", ",", "'wb'", ")", ")", "\n", "plt", ".", "savefig", "(", "fname", ",", "dpi", "=", "100", ")", "\n", "print", "(", "\"Saved figure to file: \"", ",", "fname", ")", "\n", "", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode": [[103, 133], ["sent.strip.strip", "tokenizer.build_inputs_with_special_tokens", "isinstance", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tokenizer.encode", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tokenizer.encode", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tokenizer.encode", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tokenizer.encode", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tokenizer.encode", "NotImplementedError", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "tokenizer.encode", "NotImplementedError"], "function", ["None"], ["def", "sent_encode", "(", "tokenizer", ",", "sent", ")", ":", "\n", "    ", "\"Encoding as sentence based on the tokenizer\"", "\n", "sent", "=", "sent", ".", "strip", "(", ")", "\n", "if", "sent", "==", "\"\"", ":", "\n", "        ", "return", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "[", "]", ")", "\n", "", "elif", "isinstance", "(", "tokenizer", ",", "GPT2Tokenizer", ")", ":", "\n", "# for RoBERTa and GPT-2", "\n", "        ", "if", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"4.0.0\"", ")", ":", "\n", "            ", "return", "tokenizer", ".", "encode", "(", "\n", "sent", ",", "add_special_tokens", "=", "True", ",", "add_prefix_space", "=", "True", ",", "max_length", "=", "tokenizer", ".", "model_max_length", ",", "\n", "truncation", "=", "True", "\n", ")", "\n", "", "elif", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"3.0.0\"", ")", ":", "\n", "            ", "return", "tokenizer", ".", "encode", "(", "\n", "sent", ",", "add_special_tokens", "=", "True", ",", "add_prefix_space", "=", "True", ",", "max_length", "=", "tokenizer", ".", "max_len", ",", "truncation", "=", "True", "\n", ")", "\n", "", "elif", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"2.0.0\"", ")", ":", "\n", "            ", "return", "tokenizer", ".", "encode", "(", "sent", ",", "add_special_tokens", "=", "True", ",", "add_prefix_space", "=", "True", ",", "max_length", "=", "tokenizer", ".", "max_len", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"transformers version {trans_version} is not supported\"", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"4.0.0\"", ")", ":", "\n", "            ", "return", "tokenizer", ".", "encode", "(", "sent", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "tokenizer", ".", "model_max_length", ",", "\n", "truncation", "=", "True", ")", "\n", "", "elif", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"3.0.0\"", ")", ":", "\n", "            ", "return", "tokenizer", ".", "encode", "(", "sent", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "tokenizer", ".", "max_len", ",", "truncation", "=", "True", ")", "\n", "", "elif", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"2.0.0\"", ")", ":", "\n", "            ", "return", "tokenizer", ".", "encode", "(", "sent", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "tokenizer", ".", "max_len", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"transformers version {trans_version} is not supported\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_model": [[135, 183], ["model_type.startswith", "AutoModel.from_pretrained.eval", "transformers.AutoModel.from_pretrained", "transformers.AutoModel.from_pretrained", "hasattr", "hasattr", "utils.cache_scibert", "hasattr", "hasattr", "torch.nn.ModuleList", "hasattr", "hasattr", "len", "hasattr", "hasattr", "ValueError", "len", "torch.nn.ModuleList", "torch.nn.ModuleList", "ValueError", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.cache_scibert"], ["", "", "", "def", "get_model", "(", "model_type", ",", "num_layers", ",", "all_layers", "=", "None", ")", ":", "\n", "    ", "if", "model_type", ".", "startswith", "(", "\"scibert\"", ")", ":", "\n", "        ", "model", "=", "AutoModel", ".", "from_pretrained", "(", "cache_scibert", "(", "model_type", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_type", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "# drop unused layers", "\n", "if", "not", "all_layers", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"n_layers\"", ")", ":", "# xlm", "\n", "            ", "assert", "(", "\n", "0", "<=", "num_layers", "<=", "model", ".", "n_layers", "\n", ")", ",", "f\"Invalid num_layers: num_layers should be between 0 and {model.n_layers} for {model_type}\"", "\n", "model", ".", "n_layers", "=", "num_layers", "\n", "", "elif", "hasattr", "(", "model", ",", "\"layer\"", ")", ":", "# xlnet", "\n", "            ", "assert", "(", "\n", "0", "<=", "num_layers", "<=", "len", "(", "model", ".", "layer", ")", "\n", ")", ",", "f\"Invalid num_layers: num_layers should be between 0 and {len(model.layer)} for {model_type}\"", "\n", "model", ".", "layer", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "layer", "for", "layer", "in", "model", ".", "layer", "[", ":", "num_layers", "]", "]", ")", "\n", "", "elif", "hasattr", "(", "model", ",", "\"encoder\"", ")", ":", "# albert", "\n", "            ", "if", "hasattr", "(", "model", ".", "encoder", ",", "\"albert_layer_groups\"", ")", ":", "\n", "                ", "assert", "(", "\n", "0", "<=", "num_layers", "<=", "model", ".", "encoder", ".", "config", ".", "num_hidden_layers", "\n", ")", ",", "f\"Invalid num_layers: num_layers should be between 0 and {model.encoder.config.num_hidden_layers} for {model_type}\"", "\n", "model", ".", "encoder", ".", "config", ".", "num_hidden_layers", "=", "num_layers", "\n", "", "else", ":", "# bert, roberta", "\n", "                ", "assert", "(", "\n", "0", "<=", "num_layers", "<=", "len", "(", "model", ".", "encoder", ".", "layer", ")", "\n", ")", ",", "f\"Invalid num_layers: num_layers should be between 0 and {len(model.encoder.layer)} for {model_type}\"", "\n", "model", ".", "encoder", ".", "layer", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "layer", "for", "layer", "in", "model", ".", "encoder", ".", "layer", "[", ":", "num_layers", "]", "]", ")", "\n", "", "", "elif", "hasattr", "(", "model", ",", "\"transformer\"", ")", ":", "# bert, roberta", "\n", "            ", "assert", "(", "\n", "0", "<=", "num_layers", "<=", "len", "(", "model", ".", "transformer", ".", "layer", ")", "\n", ")", ",", "f\"Invalid num_layers: num_layers should be between 0 and {len(model.transformer.layer)} for {model_type}\"", "\n", "model", ".", "transformer", ".", "layer", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "layer", "for", "layer", "in", "model", ".", "transformer", ".", "layer", "[", ":", "num_layers", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not supported\"", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"output_hidden_states\"", ")", ":", "\n", "            ", "model", ".", "output_hidden_states", "=", "True", "\n", "", "elif", "hasattr", "(", "model", ",", "\"encoder\"", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "output_hidden_states", "=", "True", "\n", "", "elif", "hasattr", "(", "model", ",", "\"transformer\"", ")", ":", "\n", "            ", "model", ".", "transformer", ".", "output_hidden_states", "=", "True", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Not supported model architecture: {model_type}\"", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_tokenizer": [[185, 195], ["cache_scibert.startswith", "utils.cache_scibert", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoTokenizer.from_pretrained"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.cache_scibert"], ["", "def", "get_tokenizer", "(", "model_type", ")", ":", "\n", "    ", "if", "model_type", ".", "startswith", "(", "\"scibert\"", ")", ":", "\n", "        ", "model_type", "=", "cache_scibert", "(", "model_type", ")", "\n", "\n", "", "if", "LooseVersion", "(", "trans_version", ")", ">=", "LooseVersion", "(", "\"4.0.0\"", ")", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_type", ",", "use_fast", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_type", ")", "\n", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.padding": [[197, 206], ["torch.LongTensor", "torch.LongTensor.max().item", "torch.zeros", "enumerate", "torch.ones", "len", "torch.tensor", "len", "torch.LongTensor.max", "len"], "function", ["None"], ["", "def", "padding", "(", "arr", ",", "pad_token", ",", "dtype", "=", "torch", ".", "long", ")", ":", "\n", "    ", "lens", "=", "torch", ".", "LongTensor", "(", "[", "len", "(", "a", ")", "for", "a", "in", "arr", "]", ")", "\n", "max_len", "=", "lens", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "padded", "=", "torch", ".", "ones", "(", "len", "(", "arr", ")", ",", "max_len", ",", "dtype", "=", "dtype", ")", "*", "pad_token", "\n", "mask", "=", "torch", ".", "zeros", "(", "len", "(", "arr", ")", ",", "max_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "i", ",", "a", "in", "enumerate", "(", "arr", ")", ":", "\n", "        ", "padded", "[", "i", ",", ":", "lens", "[", "i", "]", "]", "=", "torch", ".", "tensor", "(", "a", ",", "dtype", "=", "dtype", ")", "\n", "mask", "[", "i", ",", ":", "lens", "[", "i", "]", "]", "=", "1", "\n", "", "return", "padded", ",", "lens", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.bert_encode": [[208, 217], ["model.eval", "torch.no_grad", "model", "torch.stack"], "function", ["None"], ["", "def", "bert_encode", "(", "model", ",", "x", ",", "attention_mask", ",", "all_layers", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "out", "=", "model", "(", "x", ",", "attention_mask", "=", "attention_mask", ")", "\n", "", "if", "all_layers", ":", "\n", "        ", "emb", "=", "torch", ".", "stack", "(", "out", "[", "-", "1", "]", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "        ", "emb", "=", "out", "[", "0", "]", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.process": [[219, 223], ["set", "utils.sent_encode"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode"], ["", "def", "process", "(", "a", ",", "tokenizer", "=", "None", ")", ":", "\n", "    ", "if", "tokenizer", "is", "not", "None", ":", "\n", "        ", "a", "=", "sent_encode", "(", "tokenizer", ",", "a", ")", "\n", "", "return", "set", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_idf_dict": [[225, 246], ["collections.Counter", "len", "functools.partial", "collections.defaultdict", "collections.defaultdict.update", "multiprocessing.Pool", "collections.Counter.update", "itertools.chain.from_iterable", "math.log", "math.log", "p.map", "collections.Counter.items"], "function", ["None"], ["", "def", "get_idf_dict", "(", "arr", ",", "tokenizer", ",", "nthreads", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Returns mapping from word piece index to its inverse document frequency.\n\n\n    Args:\n        - :param: `arr` (list of str) : sentences to process.\n        - :param: `tokenizer` : a BERT tokenizer corresponds to `model`.\n        - :param: `nthreads` (int) : number of CPU threads to use\n    \"\"\"", "\n", "idf_count", "=", "Counter", "(", ")", "\n", "num_docs", "=", "len", "(", "arr", ")", "\n", "\n", "process_partial", "=", "partial", "(", "process", ",", "tokenizer", "=", "tokenizer", ")", "\n", "\n", "with", "Pool", "(", "nthreads", ")", "as", "p", ":", "\n", "        ", "idf_count", ".", "update", "(", "chain", ".", "from_iterable", "(", "p", ".", "map", "(", "process_partial", ",", "arr", ")", ")", ")", "\n", "\n", "", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "log", "(", "(", "num_docs", "+", "1", ")", "/", "(", "1", ")", ")", ")", "\n", "idf_dict", ".", "update", "(", "{", "idx", ":", "log", "(", "(", "num_docs", "+", "1", ")", "/", "(", "c", "+", "1", ")", ")", "for", "(", "idx", ",", "c", ")", "in", "idf_count", ".", "items", "(", ")", "}", ")", "\n", "return", "idf_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.collate_idf": [[248, 277], ["utils.padding", "utils.padding", "padded.to.to", "mask.to.to", "lens.to.to", "utils.sent_encode"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.padding", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.padding", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode"], ["", "def", "collate_idf", "(", "arr", ",", "tokenizer", ",", "idf_dict", ",", "device", "=", "\"cuda:0\"", ")", ":", "\n", "    ", "\"\"\"\n    Helper function that pads a list of sentences to hvae the same length and\n    loads idf score for words in the sentences.\n\n    Args:\n        - :param: `arr` (list of str): sentences to process.\n        - :param: `tokenize` : a function that takes a string and return list\n                  of tokens.\n        - :param: `numericalize` : a function that takes a list of tokens and\n                  return list of token indexes.\n        - :param: `idf_dict` (dict): mapping a word piece index to its\n                               inverse document frequency\n        - :param: `pad` (str): the padding token.\n        - :param: `device` (str): device to use, e.g. 'cpu' or 'cuda'\n    \"\"\"", "\n", "arr", "=", "[", "sent_encode", "(", "tokenizer", ",", "a", ")", "for", "a", "in", "arr", "]", "\n", "\n", "idf_weights", "=", "[", "[", "idf_dict", "[", "i", "]", "for", "i", "in", "a", "]", "for", "a", "in", "arr", "]", "\n", "\n", "pad_token", "=", "tokenizer", ".", "pad_token_id", "\n", "\n", "padded", ",", "lens", ",", "mask", "=", "padding", "(", "arr", ",", "pad_token", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "padded_idf", ",", "_", ",", "_", "=", "padding", "(", "idf_weights", ",", "0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "padded", "=", "padded", ".", "to", "(", "device", "=", "device", ")", "\n", "mask", "=", "mask", ".", "to", "(", "device", "=", "device", ")", "\n", "lens", "=", "lens", ".", "to", "(", "device", "=", "device", ")", "\n", "return", "padded", ",", "padded_idf", ",", "lens", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_bert_embedding": [[279, 309], ["utils.collate_idf", "torch.cat", "len", "torch.no_grad", "range", "len", "utils.bert_encode", "embeddings.append"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.collate_idf", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.bert_encode"], ["", "def", "get_bert_embedding", "(", "all_sens", ",", "model", ",", "tokenizer", ",", "idf_dict", ",", "batch_size", "=", "-", "1", ",", "device", "=", "\"cuda:0\"", ",", "all_layers", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute BERT embedding in batches.\n\n    Args:\n        - :param: `all_sens` (list of str) : sentences to encode.\n        - :param: `model` : a BERT model from `pytorch_pretrained_bert`.\n        - :param: `tokenizer` : a BERT tokenizer corresponds to `model`.\n        - :param: `idf_dict` (dict) : mapping a word piece index to its\n                               inverse document frequency\n        - :param: `device` (str): device to use, e.g. 'cpu' or 'cuda'\n    \"\"\"", "\n", "\n", "padded_sens", ",", "padded_idf", ",", "lens", ",", "mask", "=", "collate_idf", "(", "all_sens", ",", "tokenizer", ",", "idf_dict", ",", "device", "=", "device", ")", "\n", "\n", "if", "batch_size", "==", "-", "1", ":", "\n", "        ", "batch_size", "=", "len", "(", "all_sens", ")", "\n", "\n", "", "embeddings", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "all_sens", ")", ",", "batch_size", ")", ":", "\n", "            ", "batch_embedding", "=", "bert_encode", "(", "\n", "model", ",", "padded_sens", "[", "i", ":", "i", "+", "batch_size", "]", ",", "attention_mask", "=", "mask", "[", "i", ":", "i", "+", "batch_size", "]", ",", "all_layers", "=", "all_layers", "\n", ")", "\n", "embeddings", ".", "append", "(", "batch_embedding", ")", "\n", "del", "batch_embedding", "\n", "\n", "", "", "total_embedding", "=", "torch", ".", "cat", "(", "embeddings", ",", "dim", "=", "0", ")", "\n", "\n", "return", "total_embedding", ",", "mask", ",", "padded_idf", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.greedy_cos_idf": [[311, 420], ["ref_embedding.transpose().transpose().contiguous().view.div_", "hyp_embedding.transpose().transpose().contiguous().view.div_", "ref_embedding.transpose().transpose().contiguous().view.size", "torch.bmm", "torch.bmm", "masks.expand().contiguous().view_as.float().to", "hyp_idf.div_", "ref_idf.div_", "hyp_idf.to", "ref_idf.to", "hyp_masks.sum().eq", "ref_masks.sum().eq", "torch.any", "torch.any", "F.view.masked_fill", "range", "range", "range", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "hyp_embedding.transpose().transpose().contiguous().view.size", "hyp_embedding.transpose().transpose().contiguous().view.transpose().transpose().contiguous().view", "ref_embedding.transpose().transpose().contiguous().view.transpose().transpose().contiguous().view", "ref_embedding.transpose().transpose().contiguous().view.transpose", "hyp_masks.unsqueeze().float", "ref_masks.unsqueeze().float", "masks.expand().contiguous().view_as.unsqueeze().expand().contiguous().view_as", "masks.expand().contiguous().view_as.expand().contiguous().view_as", "torch.bmm.max", "torch.bmm.max", "hyp_idf.sum", "ref_idf.sum", "precision_scale.unsqueeze().expand().contiguous().view_as.unsqueeze().expand().contiguous().view_as", "recall_scale.unsqueeze().expand().contiguous().view_as.unsqueeze().expand().contiguous().view_as", "P.masked_fill.view", "R.masked_fill.view", "F.view.view", "print", "P.masked_fill.masked_fill", "print", "R.masked_fill.masked_fill", "torch.isnan", "word_recall.size", "word_precision.size", "torch.bmm.size", "hyp_embedding.transpose().transpose().contiguous().view.size", "ref_embedding.transpose().transpose().contiguous().view.size", "masks.expand().contiguous().view_as.float", "hyp_masks.sum", "ref_masks.sum", "ref_tokens_sim.append", "ref_tokens_sim.append", "hypo_tokens_sim.append", "hypo_tokens_sim.append", "hypo_match_loc.append", "ref_match_loc.append", "hypo_match_loc.append", "ref_match_loc.append", "torch.norm", "torch.norm", "hyp_embedding.transpose().transpose().contiguous().view.transpose().transpose().contiguous", "ref_embedding.transpose().transpose().contiguous().view.transpose().transpose().contiguous", "hyp_masks.unsqueeze", "ref_masks.unsqueeze", "masks.expand().contiguous().view_as.unsqueeze().expand().contiguous", "masks.expand().contiguous().view_as.expand().contiguous", "precision_scale.unsqueeze().expand().contiguous().view_as.unsqueeze().expand().contiguous", "recall_scale.unsqueeze().expand().contiguous().view_as.unsqueeze().expand().contiguous", "torch.zeros().cpu", "[].cpu", "torch.zeros().cpu", "[].cpu", "torch.zeros().cpu", "torch.zeros().cpu", "[].argmax().cpu", "[].argmax().cpu", "hyp_embedding.transpose().transpose().contiguous().view.transpose().transpose", "ref_embedding.transpose().transpose().contiguous().view.transpose().transpose", "masks.expand().contiguous().view_as.unsqueeze().expand", "masks.expand().contiguous().view_as.expand", "precision_scale.unsqueeze().expand().contiguous().view_as.unsqueeze().expand", "recall_scale.unsqueeze().expand().contiguous().view_as.unsqueeze().expand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "[].argmax", "[].argmax", "[].size", "[].size", "ref_tokens_sim[].size", "hyp_embedding.transpose().transpose().contiguous().view.transpose", "ref_embedding.transpose().transpose().contiguous().view.transpose", "masks.expand().contiguous().view_as.unsqueeze", "precision_scale.unsqueeze().expand().contiguous().view_as.unsqueeze", "recall_scale.unsqueeze().expand().contiguous().view_as.unsqueeze", "hypo_tokens_sim[].size", "ref_tokens_sim[].size", "hypo_tokens_sim[].size", "ref_tokens_sim[].size"], "function", ["None"], ["", "def", "greedy_cos_idf", "(", "ref_embedding", ",", "ref_masks", ",", "ref_idf", ",", "hyp_embedding", ",", "hyp_masks", ",", "hyp_idf", ",", "all_layers", "=", "False", ",", "return_details", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute greedy matching based on cosine similarity.\n\n    Args:\n        - :param: `ref_embedding` (torch.Tensor):\n                   embeddings of reference sentences, BxKxd,\n                   B: batch size, K: longest length, d: bert dimenison\n        - :param: `ref_lens` (list of int): list of reference sentence length.\n        - :param: `ref_masks` (torch.LongTensor): BxKxK, BERT attention mask for\n                   reference sentences.\n        - :param: `ref_idf` (torch.Tensor): BxK, idf score of each word\n                   piece in the reference setence\n        - :param: `hyp_embedding` (torch.Tensor):\n                   embeddings of candidate sentences, BxKxd,\n                   B: batch size, K: longest length, d: bert dimenison\n        - :param: `hyp_lens` (list of int): list of candidate sentence length.\n        - :param: `hyp_masks` (torch.LongTensor): BxKxK, BERT attention mask for\n                   candidate sentences.\n        - :param: `hyp_idf` (torch.Tensor): BxK, idf score of each word\n                   piece in the candidate setence\n    \"\"\"", "\n", "ref_embedding", ".", "div_", "(", "torch", ".", "norm", "(", "ref_embedding", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "hyp_embedding", ".", "div_", "(", "torch", ".", "norm", "(", "hyp_embedding", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "if", "all_layers", ":", "\n", "        ", "B", ",", "_", ",", "L", ",", "D", "=", "hyp_embedding", ".", "size", "(", ")", "\n", "hyp_embedding", "=", "hyp_embedding", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "L", "*", "B", ",", "hyp_embedding", ".", "size", "(", "1", ")", ",", "D", ")", "\n", "ref_embedding", "=", "ref_embedding", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "L", "*", "B", ",", "ref_embedding", ".", "size", "(", "1", ")", ",", "D", ")", "\n", "", "batch_size", "=", "ref_embedding", ".", "size", "(", "0", ")", "\n", "sim", "=", "torch", ".", "bmm", "(", "hyp_embedding", ",", "ref_embedding", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "masks", "=", "torch", ".", "bmm", "(", "hyp_masks", ".", "unsqueeze", "(", "2", ")", ".", "float", "(", ")", ",", "ref_masks", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", ")", "\n", "if", "all_layers", ":", "\n", "        ", "masks", "=", "masks", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "L", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view_as", "(", "sim", ")", "\n", "", "else", ":", "\n", "        ", "masks", "=", "masks", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view_as", "(", "sim", ")", "\n", "\n", "", "masks", "=", "masks", ".", "float", "(", ")", ".", "to", "(", "sim", ".", "device", ")", "\n", "sim", "=", "sim", "*", "masks", "\n", "\n", "word_precision", "=", "sim", ".", "max", "(", "dim", "=", "2", ")", "[", "0", "]", "\n", "word_recall", "=", "sim", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n", "hyp_idf", ".", "div_", "(", "hyp_idf", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "ref_idf", ".", "div_", "(", "ref_idf", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "precision_scale", "=", "hyp_idf", ".", "to", "(", "word_precision", ".", "device", ")", "\n", "recall_scale", "=", "ref_idf", ".", "to", "(", "word_recall", ".", "device", ")", "\n", "if", "all_layers", ":", "\n", "        ", "precision_scale", "=", "precision_scale", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "L", ",", "B", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view_as", "(", "word_precision", ")", "\n", "recall_scale", "=", "recall_scale", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "L", ",", "B", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view_as", "(", "word_recall", ")", "\n", "", "P", "=", "(", "word_precision", "*", "precision_scale", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "R", "=", "(", "word_recall", "*", "recall_scale", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "F", "=", "2", "*", "P", "*", "R", "/", "(", "P", "+", "R", ")", "\n", "\n", "hyp_zero_mask", "=", "hyp_masks", ".", "sum", "(", "dim", "=", "1", ")", ".", "eq", "(", "2", ")", "\n", "ref_zero_mask", "=", "ref_masks", ".", "sum", "(", "dim", "=", "1", ")", ".", "eq", "(", "2", ")", "\n", "\n", "if", "all_layers", ":", "\n", "        ", "P", "=", "P", ".", "view", "(", "L", ",", "B", ")", "\n", "R", "=", "R", ".", "view", "(", "L", ",", "B", ")", "\n", "F", "=", "F", ".", "view", "(", "L", ",", "B", ")", "\n", "\n", "", "if", "torch", ".", "any", "(", "hyp_zero_mask", ")", ":", "\n", "        ", "print", "(", "\"Warning: Empty candidate sentence detected; setting precision to be 0.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "P", "=", "P", ".", "masked_fill", "(", "hyp_zero_mask", ",", "0.0", ")", "\n", "\n", "", "if", "torch", ".", "any", "(", "ref_zero_mask", ")", ":", "\n", "        ", "print", "(", "\"Warning: Empty reference sentence detected; setting recall to be 0.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "R", "=", "R", ".", "masked_fill", "(", "ref_zero_mask", ",", "0.0", ")", "\n", "\n", "", "F", "=", "F", ".", "masked_fill", "(", "torch", ".", "isnan", "(", "F", ")", ",", "0.0", ")", "\n", "\n", "ref_tokens_sim", "=", "[", "]", "\n", "hypo_tokens_sim", "=", "[", "]", "\n", "# Get non-padded token max sim, exclude [SEP], etc.", "\n", "for", "i", "in", "range", "(", "0", ",", "word_recall", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "if", "hyp_zero_mask", "[", "i", "]", ":", "\n", "            ", "ref_tokens_sim", ".", "append", "(", "torch", ".", "zeros", "(", "word_recall", "[", "i", "]", "[", "ref_masks", "[", "i", "]", "==", "True", "]", "[", "1", ":", "-", "1", "]", ".", "size", "(", ")", ")", ".", "cpu", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "ref_tokens_sim", ".", "append", "(", "word_recall", "[", "i", "]", "[", "ref_masks", "[", "i", "]", "==", "True", "]", "[", "1", ":", "-", "1", "]", ".", "cpu", "(", ")", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "0", ",", "word_precision", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "if", "hyp_zero_mask", "[", "i", "]", ":", "\n", "            ", "hypo_tokens_sim", ".", "append", "(", "torch", ".", "zeros", "(", "word_precision", "[", "i", "]", "[", "hyp_masks", "[", "i", "]", "==", "True", "]", "[", "1", ":", "-", "1", "]", ".", "size", "(", ")", ")", ".", "cpu", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "hypo_tokens_sim", ".", "append", "(", "word_precision", "[", "i", "]", "[", "hyp_masks", "[", "i", "]", "==", "True", "]", "[", "1", ":", "-", "1", "]", ".", "cpu", "(", ")", ")", "\n", "\n", "# ref_tokens_sim = [word_recall[i][ref_masks[i]==True][1:-1].cpu() for i in range(0, word_recall.size(0))]", "\n", "# hypo_tokens_sim = [word_precision[i][hyp_masks[i]==True][1:-1].cpu() for i in range(0, word_precision.size(0))]", "\n", "\n", "", "", "hypo_match_loc", "=", "[", "]", "\n", "ref_match_loc", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "sim", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "if", "hyp_zero_mask", "[", "i", "]", ":", "\n", "            ", "hypo_match_loc", ".", "append", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cpu", "(", ")", ")", "\n", "ref_match_loc", ".", "append", "(", "torch", ".", "zeros", "(", "ref_tokens_sim", "[", "i", "]", ".", "size", "(", "0", ")", ")", ".", "cpu", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "hypo_match_loc", ".", "append", "(", "sim", "[", "i", "]", "[", "1", ":", "hypo_tokens_sim", "[", "i", "]", ".", "size", "(", "0", ")", "+", "1", ",", "1", ":", "ref_tokens_sim", "[", "i", "]", ".", "size", "(", "0", ")", "+", "1", "]", ".", "argmax", "(", "axis", "=", "1", ")", ".", "cpu", "(", ")", ")", "\n", "ref_match_loc", ".", "append", "(", "sim", "[", "i", "]", "[", "1", ":", "hypo_tokens_sim", "[", "i", "]", ".", "size", "(", "0", ")", "+", "1", ",", "1", ":", "ref_tokens_sim", "[", "i", "]", ".", "size", "(", "0", ")", "+", "1", "]", ".", "argmax", "(", "axis", "=", "0", ")", ".", "cpu", "(", ")", ")", "\n", "\n", "# hypo_match_loc = [sim[i][1:hypo_tokens_sim[i].size(0)+1, 1:ref_tokens_sim[i].size(0)+1].argmax(axis=1).cpu() for i in range(0, sim.size(0))]", "\n", "# ref_match_loc = [sim[i][1:hypo_tokens_sim[i].size(0)+1, 1:ref_tokens_sim[i].size(0)+1].argmax(axis=0).cpu() for i in range(0, sim.size(0))]", "\n", "\n", "#     CUDA_VISIBLE_DEVICES=0 bert-score -v --diff --batch_size 256 --diff_weight_file weight.pkl --lang en --ref /home/zhanrunzhe/workspace/diffculty-eval-nmt/test_data/wmt2020/references/newstest2020-iuen-ref.en.txt --cand_list /home/zhanrunzhe/workspace/diffculty-eval-nmt/test_data/wmt2020/system-outputs/iu-en/newstest2020.iu-en.UQAM_TanLe.520.txt --save_path wmt2020_res/iu-en", "\n", "#     '''", "\n", "\n", "", "", "if", "return_details", ":", "\n", "        ", "return", "P", ",", "R", ",", "F", ",", "ref_tokens_sim", ",", "hypo_tokens_sim", ",", "ref_match_loc", ",", "hypo_match_loc", "\n", "", "return", "P", ",", "R", ",", "F", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.bert_cos_score_idf": [[421, 517], ["utils.bert_cos_score_idf.dedup_and_sort"], "function", ["None"], ["", "def", "bert_cos_score_idf", "(", "\n", "model", ",", "refs", ",", "hyps", ",", "tokenizer", ",", "idf_dict", ",", "verbose", "=", "False", ",", "batch_size", "=", "64", ",", "device", "=", "\"cuda:0\"", ",", "all_layers", "=", "False", ",", "return_details", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Compute BERTScore.\n\n    Args:\n        - :param: `model` : a BERT model in `pytorch_pretrained_bert`\n        - :param: `refs` (list of str): reference sentences\n        - :param: `hyps` (list of str): candidate sentences\n        - :param: `tokenzier` : a BERT tokenizer corresponds to `model`\n        - :param: `idf_dict` : a dictionary mapping a word piece index to its\n                               inverse document frequency\n        - :param: `verbose` (bool): turn on intermediate status update\n        - :param: `batch_size` (int): bert score processing batch size\n        - :param: `device` (str): device to use, e.g. 'cpu' or 'cuda'\n    \"\"\"", "\n", "preds", "=", "[", "]", "\n", "ref_maxsim", "=", "[", "]", "\n", "hypo_maxsim", "=", "[", "]", "\n", "ref_maxsim_loc", "=", "[", "]", "\n", "hypo_maxsim_loc", "=", "[", "]", "\n", "\n", "def", "dedup_and_sort", "(", "l", ")", ":", "\n", "        ", "return", "sorted", "(", "list", "(", "set", "(", "l", ")", ")", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "split", "(", "\" \"", ")", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "", "sentences", "=", "dedup_and_sort", "(", "refs", "+", "hyps", ")", "\n", "embs", "=", "[", "]", "\n", "iter_range", "=", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "batch_size", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"computing bert embedding.\"", ")", "\n", "iter_range", "=", "tqdm", "(", "iter_range", ")", "\n", "", "stats_dict", "=", "dict", "(", ")", "\n", "for", "batch_start", "in", "iter_range", ":", "\n", "        ", "sen_batch", "=", "sentences", "[", "batch_start", ":", "batch_start", "+", "batch_size", "]", "\n", "embs", ",", "masks", ",", "padded_idf", "=", "get_bert_embedding", "(", "\n", "sen_batch", ",", "model", ",", "tokenizer", ",", "idf_dict", ",", "device", "=", "device", ",", "all_layers", "=", "all_layers", "\n", ")", "\n", "embs", "=", "embs", ".", "cpu", "(", ")", "\n", "masks", "=", "masks", ".", "cpu", "(", ")", "\n", "padded_idf", "=", "padded_idf", ".", "cpu", "(", ")", "\n", "for", "i", ",", "sen", "in", "enumerate", "(", "sen_batch", ")", ":", "\n", "            ", "sequence_len", "=", "masks", "[", "i", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "emb", "=", "embs", "[", "i", ",", ":", "sequence_len", "]", "\n", "idf", "=", "padded_idf", "[", "i", ",", ":", "sequence_len", "]", "\n", "stats_dict", "[", "sen", "]", "=", "(", "emb", ",", "idf", ")", "\n", "\n", "", "", "def", "pad_batch_stats", "(", "sen_batch", ",", "stats_dict", ",", "device", ")", ":", "\n", "        ", "stats", "=", "[", "stats_dict", "[", "s", "]", "for", "s", "in", "sen_batch", "]", "\n", "emb", ",", "idf", "=", "zip", "(", "*", "stats", ")", "\n", "emb", "=", "[", "e", ".", "to", "(", "device", ")", "for", "e", "in", "emb", "]", "\n", "idf", "=", "[", "i", ".", "to", "(", "device", ")", "for", "i", "in", "idf", "]", "\n", "lens", "=", "[", "e", ".", "size", "(", "0", ")", "for", "e", "in", "emb", "]", "\n", "emb_pad", "=", "pad_sequence", "(", "emb", ",", "batch_first", "=", "True", ",", "padding_value", "=", "2.0", ")", "\n", "idf_pad", "=", "pad_sequence", "(", "idf", ",", "batch_first", "=", "True", ")", "\n", "\n", "def", "length_to_mask", "(", "lens", ")", ":", "\n", "            ", "lens", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "base", "=", "torch", ".", "arange", "(", "max_len", ",", "dtype", "=", "torch", ".", "long", ")", ".", "expand", "(", "len", "(", "lens", ")", ",", "max_len", ")", "\n", "return", "base", "<", "lens", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "pad_mask", "=", "length_to_mask", "(", "lens", ")", ".", "to", "(", "device", ")", "\n", "return", "emb_pad", ",", "pad_mask", ",", "idf_pad", "\n", "\n", "", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "iter_range", "=", "range", "(", "0", ",", "len", "(", "refs", ")", ",", "batch_size", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"computing greedy matching.\"", ")", "\n", "iter_range", "=", "tqdm", "(", "iter_range", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_start", "in", "iter_range", ":", "\n", "            ", "batch_refs", "=", "refs", "[", "batch_start", ":", "batch_start", "+", "batch_size", "]", "\n", "batch_hyps", "=", "hyps", "[", "batch_start", ":", "batch_start", "+", "batch_size", "]", "\n", "ref_stats", "=", "pad_batch_stats", "(", "batch_refs", ",", "stats_dict", ",", "device", ")", "\n", "hyp_stats", "=", "pad_batch_stats", "(", "batch_hyps", ",", "stats_dict", ",", "device", ")", "\n", "\n", "P", ",", "R", ",", "F1", ",", "ref_tokens_sim", ",", "hypo_tokens_sim", ",", "ref_match_loc", ",", "hypo_match_loc", "=", "greedy_cos_idf", "(", "*", "ref_stats", ",", "*", "hyp_stats", ",", "all_layers", ",", "return_details", "=", "return_details", ")", "\n", "preds", ".", "append", "(", "torch", ".", "stack", "(", "(", "P", ",", "R", ",", "F1", ")", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ")", "\n", "if", "return_details", ":", "\n", "                ", "ref_maxsim", "+=", "ref_tokens_sim", "\n", "hypo_maxsim", "+=", "hypo_tokens_sim", "\n", "ref_maxsim_loc", "+=", "ref_match_loc", "\n", "hypo_maxsim_loc", "+=", "hypo_match_loc", "\n", "\n", "", "", "if", "return_details", ":", "\n", "            ", "assert", "len", "(", "ref_maxsim", ")", "==", "len", "(", "refs", ")", "\n", "assert", "len", "(", "hypo_maxsim", ")", "==", "len", "(", "refs", ")", "\n", "assert", "len", "(", "ref_maxsim_loc", ")", "==", "len", "(", "refs", ")", "\n", "assert", "len", "(", "hypo_maxsim_loc", ")", "==", "len", "(", "refs", ")", "\n", "\n", "", "", "preds", "=", "torch", ".", "cat", "(", "preds", ",", "dim", "=", "1", "if", "all_layers", "else", "0", ")", "\n", "if", "return_details", ":", "\n", "        ", "return", "preds", ",", "ref_maxsim", ",", "hypo_maxsim", ",", "ref_maxsim_loc", ",", "hypo_maxsim_loc", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_hash": [[519, 529], ["None"], "function", ["None"], ["", "def", "get_hash", "(", "model", ",", "num_layers", ",", "idf", ",", "rescale_with_baseline", ",", "use_custom_baseline", ")", ":", "\n", "    ", "msg", "=", "\"{}_L{}{}_version={}(hug_trans={})\"", ".", "format", "(", "\n", "model", ",", "num_layers", ",", "\"_idf\"", "if", "idf", "else", "\"_no-idf\"", ",", "__version__", ",", "trans_version", "\n", ")", "\n", "if", "rescale_with_baseline", ":", "\n", "        ", "if", "use_custom_baseline", ":", "\n", "            ", "msg", "+=", "\"-custom-rescaled\"", "\n", "", "else", ":", "\n", "            ", "msg", "+=", "\"-rescaled\"", "\n", "", "", "return", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.cache_scibert": [[531, 572], ["model_type.replace", "os.path.abspath", "os.path.join", "os.path.join", "os.path.join", "model_type.startswith", "os.path.expanduser", "os.path.exists", "print", "print", "os.system", "os.path.exists", "os.path.exists", "os.path.join", "open", "print", "open", "print", "os.path.exists", "open", "print"], "function", ["None"], ["", "def", "cache_scibert", "(", "model_type", ",", "cache_folder", "=", "\"~/.cache/torch/transformers\"", ")", ":", "\n", "    ", "if", "not", "model_type", ".", "startswith", "(", "\"scibert\"", ")", ":", "\n", "        ", "return", "model_type", "\n", "\n", "", "underscore_model_type", "=", "model_type", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "\n", "cache_folder", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "cache_folder", ")", ")", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "cache_folder", ",", "underscore_model_type", ")", "\n", "\n", "# download SciBERT models", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "cmd", "=", "f\"mkdir -p {cache_folder}; cd {cache_folder};\"", "\n", "cmd", "+=", "f\"wget {SCIBERT_URL_DICT[model_type]}; tar -xvf {underscore_model_type}.tar;\"", "\n", "cmd", "+=", "(", "\n", "f\"rm -f {underscore_model_type}.tar ; cd {underscore_model_type}; tar -zxvf weights.tar.gz; mv weights/* .;\"", "\n", ")", "\n", "cmd", "+=", "f\"rm -f weights.tar.gz; rmdir weights; mv bert_config.json config.json;\"", "\n", "print", "(", "cmd", ")", "\n", "print", "(", "f\"downloading {model_type} model\"", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "# fix the missing files in scibert", "\n", "", "json_file", "=", "os", ".", "path", ".", "join", "(", "filename", ",", "\"special_tokens_map.json\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "json_file", ")", ":", "\n", "        ", "with", "open", "(", "json_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "print", "(", "\n", "'{\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"}'", ",", "\n", "file", "=", "f", ",", "\n", ")", "\n", "\n", "", "", "json_file", "=", "os", ".", "path", ".", "join", "(", "filename", ",", "\"added_tokens.json\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "json_file", ")", ":", "\n", "        ", "with", "open", "(", "json_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "print", "(", "\"{}\"", ",", "file", "=", "f", ")", "\n", "\n", "", "", "if", "\"uncased\"", "in", "model_type", ":", "\n", "        ", "json_file", "=", "os", ".", "path", ".", "join", "(", "filename", ",", "\"tokenizer_config.json\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "json_file", ")", ":", "\n", "            ", "with", "open", "(", "json_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "print", "(", "'{\"do_lower_case\": true, \"max_len\": 512, \"init_inputs\": []}'", ",", "file", "=", "f", ")", "\n", "\n", "", "", "", "return", "filename", "\n", "", ""]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.__init__": [[34, 114], ["utils.get_tokenizer", "utils.get_model", "scorer.BERTScorer._model.to", "lang.lower.lower.lower", "scorer.BERTScorer.compute_idf", "os.path.join", "torch.cuda.is_available", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_tokenizer", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_model", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.compute_idf"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model_type", "=", "None", ",", "\n", "num_layers", "=", "None", ",", "\n", "batch_size", "=", "64", ",", "\n", "nthreads", "=", "4", ",", "\n", "all_layers", "=", "False", ",", "\n", "idf", "=", "False", ",", "\n", "idf_sents", "=", "None", ",", "\n", "device", "=", "None", ",", "\n", "lang", "=", "None", ",", "\n", "rescale_with_baseline", "=", "False", ",", "\n", "baseline_path", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            - :param: `model_type` (str): contexual embedding model specification, default using the suggested\n                      model for the target langauge; has to specify at least one of\n                      `model_type` or `lang`\n            - :param: `num_layers` (int): the layer of representation to use.\n                      default using the number of layer tuned on WMT16 correlation data\n            - :param: `verbose` (bool): turn on intermediate status update\n            - :param: `idf` (bool): a booling to specify whether to use idf or not (this should be True even if `idf_sents` is given)\n            - :param: `idf_sents` (List of str): list of sentences used to compute the idf weights\n            - :param: `device` (str): on which the contextual embedding model will be allocated on.\n                      If this argument is None, the model lives on cuda:0 if cuda is available.\n            - :param: `batch_size` (int): bert score processing batch size\n            - :param: `nthreads` (int): number of threads\n            - :param: `lang` (str): language of the sentences; has to specify\n                      at least one of `model_type` or `lang`. `lang` needs to be\n                      specified when `rescale_with_baseline` is True.\n            - :param: `return_hash` (bool): return hash code of the setting\n            - :param: `rescale_with_baseline` (bool): rescale bertscore with pre-computed baseline\n            - :param: `baseline_path` (str): customized baseline file\n        \"\"\"", "\n", "\n", "assert", "lang", "is", "not", "None", "or", "model_type", "is", "not", "None", ",", "\"Either lang or model_type should be specified\"", "\n", "\n", "if", "rescale_with_baseline", ":", "\n", "            ", "assert", "lang", "is", "not", "None", ",", "\"Need to specify Language when rescaling with baseline\"", "\n", "\n", "", "if", "device", "is", "None", ":", "\n", "            ", "self", ".", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "device", "\n", "\n", "", "self", ".", "_lang", "=", "lang", "\n", "self", ".", "_rescale_with_baseline", "=", "rescale_with_baseline", "\n", "self", ".", "_idf", "=", "idf", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "nthreads", "=", "nthreads", "\n", "self", ".", "all_layers", "=", "all_layers", "\n", "\n", "if", "model_type", "is", "None", ":", "\n", "            ", "lang", "=", "lang", ".", "lower", "(", ")", "\n", "self", ".", "_model_type", "=", "lang2model", "[", "lang", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_model_type", "=", "model_type", "\n", "\n", "", "if", "num_layers", "is", "None", ":", "\n", "            ", "self", ".", "_num_layers", "=", "model2layers", "[", "self", ".", "model_type", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_num_layers", "=", "num_layers", "\n", "\n", "# Building model and tokenizer", "\n", "\n", "", "self", ".", "_tokenizer", "=", "get_tokenizer", "(", "self", ".", "model_type", ")", "\n", "self", ".", "_model", "=", "get_model", "(", "self", ".", "model_type", ",", "self", ".", "num_layers", ",", "self", ".", "all_layers", ")", "\n", "self", ".", "_model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "_idf_dict", "=", "None", "\n", "if", "idf_sents", "is", "not", "None", ":", "\n", "            ", "self", ".", "compute_idf", "(", "idf_sents", ")", "\n", "\n", "", "self", ".", "_baseline_vals", "=", "None", "\n", "self", ".", "baseline_path", "=", "baseline_path", "\n", "self", ".", "use_custom_baseline", "=", "self", ".", "baseline_path", "is", "not", "None", "\n", "if", "self", ".", "baseline_path", "is", "None", ":", "\n", "            ", "self", ".", "baseline_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "f\"rescale_baseline/{self.lang}/{self.model_type}.tsv\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.lang": [[116, 119], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "lang", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_lang", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.idf": [[120, 123], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "idf", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_idf", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.model_type": [[124, 127], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_type", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model_type", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.num_layers": [[128, 131], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.rescale_with_baseline": [[132, 135], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "rescale_with_baseline", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_rescale_with_baseline", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.baseline_vals": [[136, 152], ["os.path.isfile", "ValueError", "[].float", "[].unsqueeze().float", "[].unsqueeze", "torch.from_numpy", "pandas.read_csv().iloc[].to_numpy", "torch.from_numpy", "pandas.read_csv().to_numpy", "pandas.read_csv", "pandas.read_csv"], "methods", ["None"], ["", "@", "property", "\n", "def", "baseline_vals", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_baseline_vals", "is", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "self", ".", "baseline_path", ")", ":", "\n", "                ", "if", "not", "self", ".", "all_layers", ":", "\n", "                    ", "self", ".", "_baseline_vals", "=", "torch", ".", "from_numpy", "(", "\n", "pd", ".", "read_csv", "(", "self", ".", "baseline_path", ")", ".", "iloc", "[", "self", ".", "num_layers", "]", ".", "to_numpy", "(", ")", "\n", ")", "[", "1", ":", "]", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_baseline_vals", "=", "(", "\n", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "self", ".", "baseline_path", ")", ".", "to_numpy", "(", ")", ")", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Baseline not Found for {self.model_type} on {self.lang} at {self.baseline_path}\"", ")", "\n", "\n", "", "", "return", "self", ".", "_baseline_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.hash": [[153, 157], ["utils.get_hash"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_hash"], ["", "@", "property", "\n", "def", "hash", "(", "self", ")", ":", "\n", "        ", "return", "get_hash", "(", "\n", "self", ".", "model_type", ",", "self", ".", "num_layers", ",", "self", ".", "idf", ",", "self", ".", "rescale_with_baseline", ",", "self", ".", "use_custom_baseline", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.compute_idf": [[159, 168], ["utils.get_idf_dict", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_idf_dict"], ["", "def", "compute_idf", "(", "self", ",", "sents", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n\n        \"\"\"", "\n", "if", "self", ".", "_idf_dict", "is", "not", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Overwriting the previous importance weights.\"", ")", "\n", "\n", "", "self", ".", "_idf_dict", "=", "get_idf_dict", "(", "sents", ",", "self", ".", "_tokenizer", ",", "nthreads", "=", "self", ".", "nthreads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.score": [[169, 238], ["utils.bert_cos_score_idf().cpu", "isinstance", "zip", "print", "time.perf_counter", "collections.defaultdict", "torch.stack", "print", "tuple", "ref_group_boundaries.append", "len", "utils.bert_cos_score_idf", "max_preds.append", "time.perf_counter", "len", "all_preds[].max", "len", "len"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.bert_cos_score_idf"], ["", "def", "score", "(", "self", ",", "cands", ",", "refs", ",", "verbose", "=", "False", ",", "batch_size", "=", "64", ",", "return_hash", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            - :param: `cands` (list of str): candidate sentences\n            - :param: `refs` (list of str or list of list of str): reference sentences\n\n        Return:\n            - :param: `(P, R, F)`: each is of shape (N); N = number of input\n                      candidate reference pairs. if returning hashcode, the\n                      output will be ((P, R, F), hashcode). If a candidate have \n                      multiple references, the returned score of this candidate is \n                      the *best* score among all references.\n        \"\"\"", "\n", "\n", "ref_group_boundaries", "=", "None", "\n", "if", "not", "isinstance", "(", "refs", "[", "0", "]", ",", "str", ")", ":", "\n", "            ", "ref_group_boundaries", "=", "[", "]", "\n", "ori_cands", ",", "ori_refs", "=", "cands", ",", "refs", "\n", "cands", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "count", "=", "0", "\n", "for", "cand", ",", "ref_group", "in", "zip", "(", "ori_cands", ",", "ori_refs", ")", ":", "\n", "                ", "cands", "+=", "[", "cand", "]", "*", "len", "(", "ref_group", ")", "\n", "refs", "+=", "ref_group", "\n", "ref_group_boundaries", ".", "append", "(", "(", "count", ",", "count", "+", "len", "(", "ref_group", ")", ")", ")", "\n", "count", "+=", "len", "(", "ref_group", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"calculating scores...\"", ")", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "", "if", "self", ".", "idf", ":", "\n", "            ", "assert", "self", ".", "_idf_dict", ",", "\"IDF weights are not computed\"", "\n", "idf_dict", "=", "self", ".", "_idf_dict", "\n", "", "else", ":", "\n", "            ", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "1.0", ")", "\n", "idf_dict", "[", "self", ".", "_tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "idf_dict", "[", "self", ".", "_tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "\n", "", "all_preds", "=", "bert_cos_score_idf", "(", "\n", "self", ".", "_model", ",", "\n", "refs", ",", "\n", "cands", ",", "\n", "self", ".", "_tokenizer", ",", "\n", "idf_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "all_layers", "=", "self", ".", "all_layers", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "if", "ref_group_boundaries", "is", "not", "None", ":", "\n", "            ", "max_preds", "=", "[", "]", "\n", "for", "start", ",", "end", "in", "ref_group_boundaries", ":", "\n", "                ", "max_preds", ".", "append", "(", "all_preds", "[", "start", ":", "end", "]", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ")", "\n", "", "all_preds", "=", "torch", ".", "stack", "(", "max_preds", ",", "dim", "=", "0", ")", "\n", "\n", "", "if", "self", ".", "rescale_with_baseline", ":", "\n", "            ", "all_preds", "=", "(", "all_preds", "-", "self", ".", "baseline_vals", ")", "/", "(", "1", "-", "self", ".", "baseline_vals", ")", "\n", "\n", "", "out", "=", "all_preds", "[", "...", ",", "0", "]", ",", "all_preds", "[", "...", ",", "1", "]", ",", "all_preds", "[", "...", ",", "2", "]", "# P, R, F", "\n", "\n", "if", "verbose", ":", "\n", "            ", "time_diff", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "print", "(", "f\"done in {time_diff:.2f} seconds, {len(refs) / time_diff:.2f} sentences/sec\"", ")", "\n", "\n", "", "if", "return_hash", ":", "\n", "            ", "out", "=", "tuple", "(", "[", "out", ",", "self", ".", "hash", "]", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.plot_example": [[239, 313], ["isinstance", "isinstance", "collections.defaultdict", "utils.get_bert_embedding", "utils.get_bert_embedding", "ref_embedding.div_", "hyp_embedding.div_", "torch.bmm", "sim.squeeze().cpu.squeeze().cpu.squeeze().cpu", "matplotlib.subplots", "ax.imshow", "ax.set_xticks", "ax.set_yticks", "ax.set_xticklabels", "ax.set_yticklabels", "ax.grid", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "mpl_toolkits.axes_grid1.make_axes_locatable", "mpl_toolkits.axes_grid1.make_axes_locatable.append_axes", "fig.colorbar", "matplotlib.setp", "range", "fig.tight_layout", "matplotlib.show", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "ref_embedding.transpose", "numpy.arange", "numpy.arange", "ax.get_xticklabels", "len", "range", "matplotlib.savefig", "print", "sim.squeeze().cpu.squeeze().cpu.squeeze", "scorer.BERTScorer._tokenizer.decode", "scorer.BERTScorer._tokenizer.decode", "len", "len", "len", "ax.text", "torch.norm", "torch.norm", "utils.sent_encode", "utils.sent_encode", "scorer.BERTScorer.baseline_vals[].item", "scorer.BERTScorer.baseline_vals[].item", "len", "len", "sim[].item", "sim[].item"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_bert_embedding", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.get_bert_embedding", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.utils.sent_encode"], ["", "def", "plot_example", "(", "self", ",", "candidate", ",", "reference", ",", "fname", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            - :param: `candidate` (str): a candidate sentence\n            - :param: `reference` (str): a reference sentence\n            - :param: `fname` (str): path to save the output plot\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "candidate", ",", "str", ")", "\n", "assert", "isinstance", "(", "reference", ",", "str", ")", "\n", "\n", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "1.0", ")", "\n", "idf_dict", "[", "self", ".", "_tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "idf_dict", "[", "self", ".", "_tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "\n", "hyp_embedding", ",", "masks", ",", "padded_idf", "=", "get_bert_embedding", "(", "\n", "[", "candidate", "]", ",", "self", ".", "_model", ",", "self", ".", "_tokenizer", ",", "idf_dict", ",", "device", "=", "self", ".", "device", ",", "all_layers", "=", "False", "\n", ")", "\n", "ref_embedding", ",", "masks", ",", "padded_idf", "=", "get_bert_embedding", "(", "\n", "[", "reference", "]", ",", "self", ".", "_model", ",", "self", ".", "_tokenizer", ",", "idf_dict", ",", "device", "=", "self", ".", "device", ",", "all_layers", "=", "False", "\n", ")", "\n", "ref_embedding", ".", "div_", "(", "torch", ".", "norm", "(", "ref_embedding", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "hyp_embedding", ".", "div_", "(", "torch", ".", "norm", "(", "hyp_embedding", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "sim", "=", "torch", ".", "bmm", "(", "hyp_embedding", ",", "ref_embedding", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "sim", "=", "sim", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", "\n", "\n", "r_tokens", "=", "[", "self", ".", "_tokenizer", ".", "decode", "(", "[", "i", "]", ")", "for", "i", "in", "sent_encode", "(", "self", ".", "_tokenizer", ",", "reference", ")", "]", "[", "1", ":", "-", "1", "]", "\n", "h_tokens", "=", "[", "self", ".", "_tokenizer", ".", "decode", "(", "[", "i", "]", ")", "for", "i", "in", "sent_encode", "(", "self", ".", "_tokenizer", ",", "candidate", ")", "]", "[", "1", ":", "-", "1", "]", "\n", "sim", "=", "sim", "[", "1", ":", "-", "1", ",", "1", ":", "-", "1", "]", "\n", "\n", "if", "self", ".", "rescale_with_baseline", ":", "\n", "            ", "sim", "=", "(", "sim", "-", "self", ".", "baseline_vals", "[", "2", "]", ".", "item", "(", ")", ")", "/", "(", "1", "-", "self", ".", "baseline_vals", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "len", "(", "r_tokens", ")", ",", "len", "(", "h_tokens", ")", ")", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "sim", ",", "cmap", "=", "\"Blues\"", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "\n", "# We want to show all ticks...", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "r_tokens", ")", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "h_tokens", ")", ")", ")", "\n", "# ... and label them with the respective list entries", "\n", "ax", ".", "set_xticklabels", "(", "r_tokens", ",", "fontsize", "=", "10", ")", "\n", "ax", ".", "set_yticklabels", "(", "h_tokens", ",", "fontsize", "=", "10", ")", "\n", "ax", ".", "grid", "(", "False", ")", "\n", "plt", ".", "xlabel", "(", "\"Reference (tokenized)\"", ",", "fontsize", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "\"Candidate (tokenized)\"", ",", "fontsize", "=", "14", ")", "\n", "title", "=", "\"Similarity Matrix\"", "\n", "if", "self", ".", "rescale_with_baseline", ":", "\n", "            ", "title", "+=", "\" (after Rescaling)\"", "\n", "", "plt", ".", "title", "(", "title", ",", "fontsize", "=", "14", ")", "\n", "\n", "divider", "=", "make_axes_locatable", "(", "ax", ")", "\n", "cax", "=", "divider", ".", "append_axes", "(", "\"right\"", ",", "size", "=", "\"2%\"", ",", "pad", "=", "0.2", ")", "\n", "fig", ".", "colorbar", "(", "im", ",", "cax", "=", "cax", ")", "\n", "\n", "# Rotate the tick labels and set their alignment.", "\n", "plt", ".", "setp", "(", "ax", ".", "get_xticklabels", "(", ")", ",", "rotation", "=", "45", ",", "ha", "=", "\"right\"", ",", "rotation_mode", "=", "\"anchor\"", ")", "\n", "\n", "# Loop over data dimensions and create text annotations.", "\n", "for", "i", "in", "range", "(", "len", "(", "h_tokens", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "r_tokens", ")", ")", ":", "\n", "                ", "text", "=", "ax", ".", "text", "(", "\n", "j", ",", "\n", "i", ",", "\n", "\"{:.3f}\"", ".", "format", "(", "sim", "[", "i", ",", "j", "]", ".", "item", "(", ")", ")", ",", "\n", "ha", "=", "\"center\"", ",", "\n", "va", "=", "\"center\"", ",", "\n", "color", "=", "\"k\"", "if", "sim", "[", "i", ",", "j", "]", ".", "item", "(", ")", "<", "0.5", "else", "\"w\"", ",", "\n", ")", "\n", "\n", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "if", "fname", "!=", "\"\"", ":", "\n", "            ", "plt", ".", "savefig", "(", "fname", ",", "dpi", "=", "100", ")", "\n", "print", "(", "\"Saved figure to file: \"", ",", "fname", ")", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.__repr__": [[314, 316], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.__class__.__name__}(hash={self.hash}, batch_size={self.batch_size}, nthreads={self.nthreads})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.__str__": [[317, 319], ["scorer.BERTScorer.__repr__"], "methods", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score_cli.visualize.main": [[11, 38], ["torch.multiprocessing.set_sharing_strategy", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "bert_score.plot_example"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.plot_example"], ["def", "main", "(", ")", ":", "\n", "    ", "torch", ".", "multiprocessing", ".", "set_sharing_strategy", "(", "\"file_system\"", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Visualize BERTScore\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lang\"", ",", "type", "=", "str", ",", "default", "=", "\"en\"", ",", "help", "=", "\"two-letter abbreviation of the language (e.g., en)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-m\"", ",", "\"--model\"", ",", "default", "=", "None", ",", "help", "=", "\"BERT model name (default: bert-base-uncased)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-l\"", ",", "\"--num_layers\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "\"use first N layer in BERT (default: 8)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"increase output verbosity\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-r\"", ",", "\"--ref\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"reference sentence\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-c\"", ",", "\"--cand\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"candidate sentence\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-f\"", ",", "\"--file\"", ",", "type", "=", "str", ",", "default", "=", "\"visualize.png\"", ",", "help", "=", "\"name of file to save output matrix in\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rescale_with_baseline\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Rescaling the numerical score with precomputed baselines\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--baseline_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"path of custom baseline csv file\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "bert_score", ".", "plot_example", "(", "\n", "args", ".", "cand", ",", "\n", "args", ".", "ref", ",", "\n", "model_type", "=", "args", ".", "model", ",", "\n", "lang", "=", "args", ".", "lang", ",", "\n", "num_layers", "=", "args", ".", "num_layers", ",", "\n", "fname", "=", "args", ".", "file", ",", "\n", "rescale_with_baseline", "=", "args", ".", "rescale_with_baseline", ",", "\n", "baseline_path", "=", "args", ".", "baseline_path", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score_cli.score.ori_bert_score_output": [[13, 24], ["avg_scores[].cpu().item", "avg_scores[].cpu().item", "avg_scores[].cpu().item", "print", "s.mean", "zip", "avg_scores[].cpu", "avg_scores[].cpu", "avg_scores[].cpu", "print"], "function", ["None"], ["from", "transformers", "import", "AutoTokenizer", "\n", "from", ".", "score_diffculty", "import", "BertScoreDifficulty", "\n", "\n", "from", ".", "utils", "import", "(", "\n", "get_model", ",", "\n", "get_tokenizer", ",", "\n", "get_idf_dict", ",", "\n", "bert_cos_score_idf", ",", "\n", "get_bert_embedding", ",", "\n", "lang2model", ",", "\n", "model2layers", ",", "\n", "get_hash", ",", "\n"]], "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score_cli.score.main": [[25, 175], ["torch.multiprocessing.set_sharing_strategy", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "sys.exit", "os.path.isfile", "da_bert_score.score", "avg_scores[].cpu().item", "avg_scores[].cpu().item", "avg_scores[].cpu().item", "print", "list", "da_bert_score.compute_diff", "da_bert_score.bert_score_with_diff", "enumerate", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "list", "os.path.isfile", "s.mean", "zip", "cands_list.append", "os.path.exists", "zip", "print", "ori_P.append", "ori_R.append", "ori_F.append", "os.path.join", "os.path.join", "open", "os.path.exists", "zip", "os.path.exists", "avg_scores[].cpu", "avg_scores[].cpu", "avg_scores[].cpu", "print", "open", "open", "list.append", "s.mean", "avg_scores[].cpu().item", "avg_scores[].cpu().item", "avg_scores[].cpu().item", "[].split", "[].split", "line.strip", "open", "list.append", "line.strip", "line.strip", "len", "len", "[].split", "line.strip", "len", "len", "avg_scores[].cpu", "avg_scores[].cpu", "avg_scores[].cpu", "i.split", "i.split", "i.split"], "function", ["home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.scorer.BERTScorer.score", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score.compute_diff", "home.repos.pwc.inspect_result.NLP2CT_Difficulty-Aware-MT-Evaluation.da_bert_score.score.bert_score_with_diff"], ["cache_scibert", ",", "\n", "sent_encode", ",", "\n", ")", "\n", "\n", "\n", "__all__", "=", "[", "\"score\"", ",", "\"compute_diff\"", ",", "\"bert_score_with_diff\"", ",", "\"plot_example\"", "]", "\n", "\n", "\n", "def", "score", "(", "\n", "cands", ",", "\n", "refs", ",", "\n", "model_type", "=", "None", ",", "\n", "num_layers", "=", "None", ",", "\n", "verbose", "=", "False", ",", "\n", "idf", "=", "False", ",", "\n", "device", "=", "None", ",", "\n", "batch_size", "=", "64", ",", "\n", "nthreads", "=", "4", ",", "\n", "all_layers", "=", "False", ",", "\n", "lang", "=", "None", ",", "\n", "return_hash", "=", "False", ",", "\n", "rescale_with_baseline", "=", "False", ",", "\n", "baseline_path", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    BERTScore metric.\n\n    Args:\n        - :param: `cands` (list of str): candidate sentences\n        - :param: `refs` (list of str or list of list of str): reference sentences\n        - :param: `model_type` (str): bert specification, default using the suggested\n                  model for the target langauge; has to specify at least one of\n                  `model_type` or `lang`\n        - :param: `num_layers` (int): the layer of representation to use.\n                  default using the number of layer tuned on WMT16 correlation data\n        - :param: `verbose` (bool): turn on intermediate status update\n        - :param: `idf` (bool or dict): use idf weighting, can also be a precomputed idf_dict\n        - :param: `device` (str): on which the contextual embedding model will be allocated on.\n                  If this argument is None, the model lives on cuda:0 if cuda is available.\n        - :param: `nthreads` (int): number of threads\n        - :param: `batch_size` (int): bert score processing batch size\n        - :param: `lang` (str): language of the sentences; has to specify\n                  at least one of `model_type` or `lang`. `lang` needs to be\n                  specified when `rescale_with_baseline` is True.\n        - :param: `return_hash` (bool): return hash code of the setting\n        - :param: `rescale_with_baseline` (bool): rescale bertscore with pre-computed baseline\n        - :param: `baseline_path` (str): customized baseline file\n\n    Return:\n        - :param: `(P, R, F)`: each is of shape (N); N = number of input\n                  candidate reference pairs. if returning hashcode, the\n                  output will be ((P, R, F), hashcode). If a candidate have\n                  multiple references, the returned score of this candidate is\n                  the *best* score among all references.\n    \"\"\"", "\n", "assert", "len", "(", "cands", ")", "==", "len", "(", "refs", ")", ",", "\"Different number of candidates and references\"", "\n", "\n", "assert", "lang", "is", "not", "None", "or", "model_type", "is", "not", "None", ",", "\"Either lang or model_type should be specified\"", "\n", "\n", "ref_group_boundaries", "=", "None", "\n", "if", "not", "isinstance", "(", "refs", "[", "0", "]", ",", "str", ")", ":", "\n", "        ", "ref_group_boundaries", "=", "[", "]", "\n", "ori_cands", ",", "ori_refs", "=", "cands", ",", "refs", "\n", "cands", ",", "refs", "=", "[", "]", ",", "[", "]", "\n", "count", "=", "0", "\n", "for", "cand", ",", "ref_group", "in", "zip", "(", "ori_cands", ",", "ori_refs", ")", ":", "\n", "            ", "cands", "+=", "[", "cand", "]", "*", "len", "(", "ref_group", ")", "\n", "refs", "+=", "ref_group", "\n", "ref_group_boundaries", ".", "append", "(", "(", "count", ",", "count", "+", "len", "(", "ref_group", ")", ")", ")", "\n", "count", "+=", "len", "(", "ref_group", ")", "\n", "\n", "", "", "if", "rescale_with_baseline", ":", "\n", "        ", "assert", "lang", "is", "not", "None", ",", "\"Need to specify Language when rescaling with baseline\"", "\n", "\n", "", "if", "model_type", "is", "None", ":", "\n", "        ", "lang", "=", "lang", ".", "lower", "(", ")", "\n", "model_type", "=", "lang2model", "[", "lang", "]", "\n", "", "if", "num_layers", "is", "None", ":", "\n", "        ", "num_layers", "=", "model2layers", "[", "model_type", "]", "\n", "\n", "", "tokenizer", "=", "get_tokenizer", "(", "model_type", ")", "\n", "model", "=", "get_model", "(", "model_type", ",", "num_layers", ",", "all_layers", ")", "\n", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "not", "idf", ":", "\n", "        ", "idf_dict", "=", "defaultdict", "(", "lambda", ":", "1.0", ")", "\n", "# set idf for [SEP] and [CLS] to 0", "\n", "idf_dict", "[", "tokenizer", ".", "sep_token_id", "]", "=", "0", "\n", "idf_dict", "[", "tokenizer", ".", "cls_token_id", "]", "=", "0", "\n", "", "elif", "isinstance", "(", "idf", ",", "dict", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"using predefined IDF dict...\"", ")", "\n", "", "idf_dict", "=", "idf", "\n", "", "else", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "\"preparing IDF dict...\"", ")", "\n", "", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "idf_dict", "=", "get_idf_dict", "(", "refs", ",", "tokenizer", ",", "nthreads", "=", "nthreads", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"done in {:.2f} seconds\"", ".", "format", "(", "time", ".", "perf_counter", "(", ")", "-", "start", ")", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"calculating scores...\"", ")", "\n", "", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "all_preds", "=", "bert_cos_score_idf", "(", "\n", "model", ",", "\n", "refs", ",", "\n", "cands", ",", "\n", "tokenizer", ",", "\n", "idf_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "device", "=", "device", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "all_layers", "=", "all_layers", ",", "\n", ")", ".", "cpu", "(", ")", "\n", "\n", "if", "ref_group_boundaries", "is", "not", "None", ":", "\n", "        ", "max_preds", "=", "[", "]", "\n", "for", "beg", ",", "end", "in", "ref_group_boundaries", ":", "\n", "            ", "max_preds", ".", "append", "(", "all_preds", "[", "beg", ":", "end", "]", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", ")", "\n", "", "all_preds", "=", "torch", ".", "stack", "(", "max_preds", ",", "dim", "=", "0", ")", "\n", "\n", "", "use_custom_baseline", "=", "baseline_path", "is", "not", "None", "\n", "if", "rescale_with_baseline", ":", "\n", "        ", "if", "baseline_path", "is", "None", ":", "\n", "            ", "baseline_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "f\"rescale_baseline/{lang}/{model_type}.tsv\"", ")", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "baseline_path", ")", ":", "\n", "            ", "if", "not", "all_layers", ":", "\n", "                ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "iloc", "[", "num_layers", "]", ".", "to_numpy", "(", ")", ")", "[", "1", ":", "]", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "baselines", "=", "torch", ".", "from_numpy", "(", "pd", ".", "read_csv", "(", "baseline_path", ")", ".", "to_numpy", "(", ")", ")", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "\n", "", "all_preds", "=", "(", "all_preds", "-", "baselines", ")", "/", "(", "1", "-", "baselines", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Warning: Baseline not Found for {model_type} on {lang} at {baseline_path}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "", "out", "=", "all_preds", "[", "...", ",", "0", "]", ",", "all_preds", "[", "...", ",", "1", "]", ",", "all_preds", "[", "...", ",", "2", "]", "# P, R, F", "\n", "\n", "if", "verbose", ":", "\n", "        ", "time_diff", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "print", "(", "f\"done in {time_diff:.2f} seconds, {len(refs) / time_diff:.2f} sentences/sec\"", ")", "\n", "\n", "", "if", "return_hash", ":", "\n", "        ", "return", "tuple", "(", "\n", "[", "out", ",", "get_hash", "(", "model_type", ",", "num_layers", ",", "idf", ",", "rescale_with_baseline", ",", "use_custom_baseline", "=", "use_custom_baseline", ")", "]", "\n", ")", "\n", "\n", "", "return", "out", "\n", "\n"]]}