{"home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_joint.DataParallelPassthrough.__getattr__": [[211, 216], ["super().__getattr__", "getattr"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.DataParallelPassthrough.__getattr__"], ["def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "module", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_joint.cos_decay": [[21, 30], ["min", "math.cos", "params.params.Params"], "function", ["None"], ["def", "cos_decay", "(", "global_step", ",", "decay_steps", ")", ":", "\n", "    ", "\"\"\"Cosine decay function\n\n    Arguments:\n        global_step -- current training step\n        decay_steps -- number of decay steps\n    \"\"\"", "\n", "global_step", "=", "min", "(", "global_step", ",", "decay_steps", ")", "\n", "return", "0.5", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "global_step", "/", "decay_steps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_joint.train": [[32, 99], ["model.train", "enumerate", "time.time", "optimizer.zero_grad", "list", "model", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "criterion.update_states", "time.time", "map", "train_joint.cos_decay", "utils.lengths_to_mask", "torch.zeros_like", "range", "model.parameters", "utils.logging.Logger.training", "len", "max", "torch.argmax", "torch.sum().item", "torch.sum().item", "torch.nn.functional.softmax", "time.time", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientClippingFunction.backward", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.update_states", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.cos_decay", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.training"], ["", "def", "train", "(", "logging_start_epoch", ",", "epoch", ",", "data", ",", "model", ",", "criterion", ",", "optimizer", ")", ":", "\n", "    ", "\"\"\"Main training procedure.\n\n    Arguments:\n        logging_start_epoch -- number of the first epoch to be logged\n        epoch -- current epoch\n        data -- DataLoader which can provide batches for an epoch\n        model -- model to be trained\n        criterion -- instance of loss function to be optimized\n        optimizer -- instance of optimizer which will be used for parameter updates\n    \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# initialize counters, etc.", "\n", "learning_rate", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "cla", "=", "0", "\n", "done", ",", "start_time", "=", "0", ",", "time", ".", "time", "(", ")", "\n", "\n", "# loop through epoch batches", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "        ", "global_step", "=", "done", "+", "epoch", "*", "len", "(", "data", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# parse batch", "\n", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# get teacher forcing ratio", "\n", "if", "hp", ".", "constant_teacher_forcing", ":", "tf", "=", "hp", ".", "teacher_forcing", "\n", "else", ":", "tf", "=", "cos_decay", "(", "max", "(", "global_step", "-", "hp", ".", "teacher_forcing_start_steps", ",", "0", ")", ",", "hp", ".", "teacher_forcing_steps", ")", "\n", "\n", "# run the model", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "tf", ")", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss", ",", "batch_losses", "=", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "\n", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "\n", "# evaluate adversarial classifier accuracy, if present", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "input_mask", "=", "lengths_to_mask", "(", "src_len", ")", "\n", "trg_spkrs", "=", "torch", ".", "zeros_like", "(", "input_mask", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "s", "in", "range", "(", "hp", ".", "speaker_number", ")", ":", "\n", "                ", "speaker_mask", "=", "(", "spkrs", "==", "s", ")", "\n", "trg_spkrs", "[", "speaker_mask", "]", "=", "s", "\n", "", "matches", "=", "(", "trg_spkrs", "==", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "spkrs_pred", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "matches", "[", "~", "input_mask", "]", "=", "False", "\n", "cla", "=", "torch", ".", "sum", "(", "matches", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "input_mask", ")", ".", "item", "(", ")", "\n", "\n", "# comptute gradients and make a step", "\n", "", "loss", ".", "backward", "(", ")", "\n", "gradient", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "hp", ".", "gradient_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# log training progress", "\n", "if", "epoch", ">=", "logging_start_epoch", ":", "\n", "            ", "Logger", ".", "training", "(", "global_step", ",", "batch_losses", ",", "gradient", ",", "learning_rate", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "cla", ")", "\n", "\n", "# update criterion states (params and decay of the loss and so on ...)", "\n", "", "criterion", ".", "update_states", "(", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "done", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_joint.evaluate": [[101, 207], ["model.eval", "eval_losses.keys", "utils.logging.Logger.evaluation", "sum", "torch.no_grad", "enumerate", "len", "eval_losses.values", "list", "model", "model", "torch.sigmoid", "criterion", "enumerate", "batch_losses.items", "utils.logging.Logger._sw.add_scalar", "map", "zip", "gen[].data.cpu().numpy", "ref[].data.cpu().numpy", "utils.lengths_to_mask", "torch.zeros_like", "range", "torch.no_grad", "enumerate", "numpy.where", "min", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "utils.audio.linear_to_mel", "torch.argmax", "list", "model", "torch.sigmoid", "enumerate", "len", "audio.linear_to_mel.size", "gen[].data.cpu", "ref[].data.cpu", "utils.audio.mel_cepstral_distorision", "torch.nn.functional.softmax", "map", "zip", "gen[].data.cpu().numpy", "ref[].data.cpu().numpy", "stop.cpu().numpy", "numpy.min", "audio.linear_to_mel.size", "torch.sum().item", "torch.sum().item", "numpy.where", "min", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "utils.audio.linear_to_mel", "len", "audio.linear_to_mel.size", "gen[].data.cpu", "ref[].data.cpu", "utils.audio.mel_cepstral_distorision", "stop.cpu", "torch.sum", "torch.sum", "stop.cpu().numpy", "numpy.min", "audio.linear_to_mel.size", "stop.cpu"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.evaluation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.linear_to_mel", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_cepstral_distorision", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.linear_to_mel", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_cepstral_distorision"], ["", "", "def", "evaluate", "(", "epoch", ",", "data", ",", "model", ",", "criterion", ",", "eval_loaders", "=", "None", ")", ":", "\n", "    ", "\"\"\"Main evaluation procedure.\n\n    Arguments:\n        epoch -- current epoch\n        data -- DataLoader which can provide validation batches\n        model -- model to be evaluated\n        criterion -- instance of loss function to measure performance\n    \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# initialize counters, etc.", "\n", "mcd", ",", "mcd_count", "=", "0", ",", "0", "\n", "cla", ",", "cla_count", "=", "0", ",", "0", "\n", "eval_losses", "=", "{", "}", "\n", "\n", "# loop through epoch batches", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "# parse batch", "\n", "            ", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# run the model (twice, with and without teacher forcing)", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "1.0", ")", "\n", "post_pred_0", ",", "_", ",", "stop_pred_0", ",", "alignment_0", ",", "_", ",", "_", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "0.0", ")", "\n", "stop_pred_probs", "=", "torch", ".", "sigmoid", "(", "stop_pred_0", ")", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss", ",", "batch_losses", "=", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "\n", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "\n", "# compute mel cepstral distorsion", "\n", "for", "j", ",", "(", "gen", ",", "ref", ",", "stop", ")", "in", "enumerate", "(", "zip", "(", "post_pred_0", ",", "trg_mel", ",", "stop_pred_probs", ")", ")", ":", "\n", "                ", "stop_idxes", "=", "np", ".", "where", "(", "stop", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "[", "0", "]", "\n", "stop_idx", "=", "min", "(", "np", ".", "min", "(", "stop_idxes", ")", "+", "hp", ".", "stop_frames", ",", "gen", ".", "size", "(", ")", "[", "1", "]", ")", "if", "len", "(", "stop_idxes", ")", ">", "0", "else", "gen", ".", "size", "(", ")", "[", "1", "]", "\n", "gen", "=", "gen", "[", ":", ",", ":", "stop_idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ref", "=", "ref", "[", ":", ",", ":", "trg_len", "[", "j", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "hp", ".", "normalize_spectrogram", ":", "\n", "                    ", "gen", "=", "audio", ".", "denormalize_spectrogram", "(", "gen", ",", "not", "hp", ".", "predict_linear", ")", "\n", "ref", "=", "audio", ".", "denormalize_spectrogram", "(", "ref", ",", "True", ")", "\n", "", "if", "hp", ".", "predict_linear", ":", "gen", "=", "audio", ".", "linear_to_mel", "(", "gen", ")", "\n", "mcd", "=", "(", "mcd_count", "*", "mcd", "+", "audio", ".", "mel_cepstral_distorision", "(", "gen", ",", "ref", ",", "'dtw'", ")", ")", "/", "(", "mcd_count", "+", "1", ")", "\n", "mcd_count", "+=", "1", "\n", "\n", "# compute adversarial classifier accuracy", "\n", "", "if", "hp", ".", "reversal_classifier", ":", "\n", "                ", "input_mask", "=", "lengths_to_mask", "(", "src_len", ")", "\n", "trg_spkrs", "=", "torch", ".", "zeros_like", "(", "input_mask", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "s", "in", "range", "(", "hp", ".", "speaker_number", ")", ":", "\n", "                    ", "speaker_mask", "=", "(", "spkrs", "==", "s", ")", "\n", "trg_spkrs", "[", "speaker_mask", "]", "=", "s", "\n", "", "matches", "=", "(", "trg_spkrs", "==", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "spkrs_pred", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "matches", "[", "~", "input_mask", "]", "=", "False", "\n", "cla", "=", "(", "cla_count", "*", "cla", "+", "torch", ".", "sum", "(", "matches", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "input_mask", ")", ".", "item", "(", ")", ")", "/", "(", "cla_count", "+", "1", ")", "\n", "cla_count", "+=", "1", "\n", "\n", "# add batch losses to epoch losses", "\n", "", "for", "k", ",", "v", "in", "batch_losses", ".", "items", "(", ")", ":", "\n", "                ", "eval_losses", "[", "k", "]", "=", "v", "+", "eval_losses", "[", "k", "]", "if", "k", "in", "eval_losses", "else", "v", "\n", "\n", "# normalize loss per batch", "\n", "", "", "", "for", "k", "in", "eval_losses", ".", "keys", "(", ")", ":", "\n", "        ", "eval_losses", "[", "k", "]", "/=", "len", "(", "data", ")", "\n", "\n", "# log evaluation", "\n", "", "Logger", ".", "evaluation", "(", "epoch", "+", "1", ",", "eval_losses", ",", "mcd", ",", "src_len", ",", "trg_len", ",", "src", ",", "post_trg", ",", "post_pred", ",", "post_pred_0", ",", "stop_pred_probs", ",", "stop_trg", ",", "alignment_0", ",", "cla", ")", "\n", "\n", "if", "eval_loaders", "is", "not", "None", ":", "\n", "        ", "for", "eval_lang", ",", "eval_loader", "in", "eval_loaders", ":", "\n", "            ", "mcd_old_tasks", ",", "mcd_count_old_tasks", "=", "0.", ",", "0.", "\n", "# loop through epoch batches", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "i", ",", "batch", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "\n", "# parse batch", "\n", "                    ", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src_old", ",", "src_len_old", ",", "trg_mel_old", ",", "trg_lin_old", ",", "trg_len_old", ",", "stop_trg_old", ",", "spkrs_old", ",", "langs_old", "=", "batch", "\n", "\n", "# run the model (without teacher forcing, computing mcd only)", "\n", "post_pred_0_old", ",", "_", ",", "stop_pred_0_old", ",", "_", ",", "_", ",", "_", "=", "model", "(", "src_old", ",", "src_len_old", ",", "trg_mel_old", ",", "trg_len_old", ",", "spkrs_old", ",", "langs_old", ",", "0.0", ")", "\n", "stop_pred_probs", "=", "torch", ".", "sigmoid", "(", "stop_pred_0_old", ")", "\n", "\n", "\n", "# compute mel cepstral distorsion", "\n", "for", "j", ",", "(", "gen", ",", "ref", ",", "stop", ")", "in", "enumerate", "(", "zip", "(", "post_pred_0_old", ",", "trg_mel_old", ",", "stop_pred_probs", ")", ")", ":", "\n", "                        ", "stop_idxes", "=", "np", ".", "where", "(", "stop", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "[", "0", "]", "\n", "stop_idx", "=", "min", "(", "np", ".", "min", "(", "stop_idxes", ")", "+", "hp", ".", "stop_frames", ",", "gen", ".", "size", "(", ")", "[", "1", "]", ")", "if", "len", "(", "stop_idxes", ")", ">", "0", "else", "gen", ".", "size", "(", ")", "[", "1", "]", "\n", "gen", "=", "gen", "[", ":", ",", ":", "stop_idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ref", "=", "ref", "[", ":", ",", ":", "trg_len_old", "[", "j", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "hp", ".", "normalize_spectrogram", ":", "\n", "                            ", "gen", "=", "audio", ".", "denormalize_spectrogram", "(", "gen", ",", "not", "hp", ".", "predict_linear", ")", "\n", "ref", "=", "audio", ".", "denormalize_spectrogram", "(", "ref", ",", "True", ")", "\n", "", "if", "hp", ".", "predict_linear", ":", "gen", "=", "audio", ".", "linear_to_mel", "(", "gen", ")", "\n", "mcd_old_tasks", "=", "(", "mcd_count_old_tasks", "*", "mcd_old_tasks", "+", "audio", ".", "mel_cepstral_distorision", "(", "gen", ",", "ref", ",", "'dtw'", ")", ")", "/", "(", "mcd_count_old_tasks", "+", "1", ")", "\n", "mcd_count_old_tasks", "+=", "1", "\n", "\n", "# add per-lang mcd to logger", "\n", "", "", "", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Eval/mcd_{eval_lang}'", ",", "mcd_old_tasks", ",", "epoch", "+", "1", ")", "\n", "\n", "\n", "", "", "return", "sum", "(", "eval_losses", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.synthesize.synthesize": [[18, 54], ["input_data.split", "torch.LongTensor", "t.cuda.size", "torch.LongTensor", "torch.LongTensor.unsqueeze().expand().unsqueeze", "torch.zeros().zero_", "torch.zeros().zero_.scatter_", "model.inference().cpu().detach().numpy", "utils.audio.denormalize_spectrogram", "utils.text.remove_punctuation", "utils.text.to_lower", "utils.text.remove_odd_whitespaces", "utils.text.to_sequence", "torch.LongTensor", "torch.cuda.is_available", "t.cuda.cuda", "params.params.Params.languages.index", "torch.LongTensor.unsqueeze().expand", "torch.zeros", "l.cuda.cuda", "s.cuda.cuda", "model.inference().cpu().detach", "l.cuda.size", "l.cuda.size", "params.params.Params.unique_speakers.index", "torch.LongTensor.unsqueeze", "model.inference().cpu", "model.inference"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_punctuation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_lower", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_odd_whitespaces", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_sequence", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron.inference"], ["def", "synthesize", "(", "model", ",", "input_data", ",", "force_cpu", "=", "False", ",", "mel_mean", "=", "None", ",", "mel_var", "=", "None", ")", ":", "\n", "\n", "    ", "item", "=", "input_data", ".", "split", "(", "'|'", ")", "\n", "clean_text", "=", "item", "[", "1", "]", "\n", "\n", "if", "not", "hp", ".", "use_punctuation", ":", "\n", "        ", "clean_text", "=", "text", ".", "remove_punctuation", "(", "clean_text", ")", "\n", "", "if", "not", "hp", ".", "case_sensitive", ":", "\n", "        ", "clean_text", "=", "text", ".", "to_lower", "(", "clean_text", ")", "\n", "", "if", "hp", ".", "remove_multiple_wspaces", ":", "\n", "        ", "clean_text", "=", "text", ".", "remove_odd_whitespaces", "(", "clean_text", ")", "\n", "\n", "", "t", "=", "torch", ".", "LongTensor", "(", "text", ".", "to_sequence", "(", "clean_text", ",", "use_phonemes", "=", "hp", ".", "use_phonemes", ")", ")", "\n", "text_length", "=", "t", ".", "size", "(", "0", ")", "\n", "\n", "# prepare language one-hot embedding", "\n", "language", "=", "item", "[", "2", "]", "\n", "language", "=", "torch", ".", "LongTensor", "(", "[", "hp", ".", "languages", ".", "index", "(", "language", ")", "]", ")", "\n", "l", "=", "language", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "text_length", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "l", ".", "size", "(", "0", ")", ",", "l", ".", "size", "(", "1", ")", ",", "hp", ".", "language_number", ")", ".", "zero_", "(", ")", "\n", "l", "=", "one_hots", ".", "scatter_", "(", "2", ",", "l", ".", "data", ",", "1", ")", "\n", "\n", "s", "=", "torch", ".", "LongTensor", "(", "[", "hp", ".", "unique_speakers", ".", "index", "(", "item", "[", "2", "]", ")", "]", ")", "if", "hp", ".", "multi_speaker", "else", "None", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "force_cpu", ":", "\n", "        ", "t", "=", "t", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "if", "l", "is", "not", "None", ":", "l", "=", "l", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "if", "s", "is", "not", "None", ":", "s", "=", "s", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "", "s", "=", "model", ".", "inference", "(", "t", ",", "speaker", "=", "s", ",", "language", "=", "l", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "mel_mean", "is", "not", "None", "and", "mel_var", "is", "not", "None", ":", "\n", "        ", "hp", ".", "mel_normalize_mean", "=", "mel_mean", "\n", "hp", ".", "mel_normalize_variance", "=", "mel_var", "\n", "", "s", "=", "audio", ".", "denormalize_spectrogram", "(", "s", ",", "not", "hp", ".", "predict_linear", ")", "\n", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.DataParallelPassthrough.__getattr__": [[408, 413], ["super().__getattr__", "getattr"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.DataParallelPassthrough.__getattr__"], ["def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "super", "(", ")", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "module", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.cos_decay": [[26, 35], ["min", "math.cos", "params.params.Params", "params.params.Params"], "function", ["None"], ["def", "cos_decay", "(", "global_step", ",", "decay_steps", ")", ":", "\n", "    ", "\"\"\"Cosine decay function\n\n    Arguments:\n        global_step -- current training step\n        decay_steps -- number of decay steps\n    \"\"\"", "\n", "global_step", "=", "min", "(", "global_step", ",", "decay_steps", ")", "\n", "return", "0.5", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "global_step", "/", "decay_steps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train": [[37, 108], ["model.train", "enumerate", "time.time", "optimizer.zero_grad", "list", "model", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "criterion.update_states", "time.time", "map", "train_continual.cos_decay", "utils.lengths_to_mask", "torch.zeros_like", "range", "model.parameters", "utils.logging.Logger.training", "len", "max", "torch.argmax", "torch.sum().item", "torch.sum().item", "ewc.penalty", "torch.nn.functional.softmax", "time.time", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientClippingFunction.backward", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.update_states", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.cos_decay", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.training", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.penalty"], ["", "def", "train", "(", "logging_start_epoch", ",", "epoch", ",", "data", ",", "model", ",", "criterion", ",", "optimizer", ",", "ewc", "=", "None", ")", ":", "\n", "    ", "\"\"\"Main training procedure.\n\n    Arguments:\n        logging_start_epoch -- number of the first epoch to be logged\n        epoch -- current epoch\n        data -- DataLoader which can provide batches for an epoch\n        model -- model to be trained\n        criterion -- instance of loss function to be optimized\n        optimizer -- instance of optimizer which will be used for parameter updates\n    \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# initialize counters, etc.", "\n", "learning_rate", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "cla", "=", "0", "\n", "done", ",", "start_time", "=", "0", ",", "time", ".", "time", "(", ")", "\n", "\n", "# loop through epoch batches", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "        ", "global_step", "=", "done", "+", "epoch", "*", "len", "(", "data", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# parse batch", "\n", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# get teacher forcing ratio", "\n", "if", "hp", ".", "constant_teacher_forcing", ":", "tf", "=", "hp", ".", "teacher_forcing", "\n", "else", ":", "tf", "=", "cos_decay", "(", "max", "(", "global_step", "-", "hp", ".", "teacher_forcing_start_steps", ",", "0", ")", ",", "hp", ".", "teacher_forcing_steps", ")", "\n", "\n", "# run the current model (student)", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "tf", ")", "\n", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss", ",", "batch_losses", "=", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "\n", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "\n", "\n", "# evaluate adversarial classifier accuracy, if present", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "input_mask", "=", "lengths_to_mask", "(", "src_len", ")", "\n", "trg_spkrs", "=", "torch", ".", "zeros_like", "(", "input_mask", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "s", "in", "range", "(", "hp", ".", "speaker_number", ")", ":", "\n", "                ", "speaker_mask", "=", "(", "spkrs", "==", "s", ")", "\n", "trg_spkrs", "[", "speaker_mask", "]", "=", "s", "\n", "", "matches", "=", "(", "trg_spkrs", "==", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "spkrs_pred", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "matches", "[", "~", "input_mask", "]", "=", "False", "\n", "cla", "=", "torch", ".", "sum", "(", "matches", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "input_mask", ")", ".", "item", "(", ")", "\n", "\n", "# comptute gradients and make a step", "\n", "", "if", "ewc", "is", "not", "None", ":", "\n", "            ", "loss", "+=", "hp", ".", "ewc_importance", "*", "ewc", ".", "penalty", "(", "model", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "gradient", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "hp", ".", "gradient_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# log training progress", "\n", "if", "epoch", ">=", "logging_start_epoch", ":", "\n", "            ", "Logger", ".", "training", "(", "global_step", ",", "batch_losses", ",", "gradient", ",", "learning_rate", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "cla", ")", "\n", "\n", "# update criterion states (params and decay of the loss and so on ...)", "\n", "", "criterion", ".", "update_states", "(", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "done", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train_aux": [[110, 198], ["model.train", "enumerate", "time.time", "zip", "optimizer.zero_grad", "list", "model", "criterion", "list", "model", "criterion", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "criterion.update_states", "time.time", "map", "train_continual.cos_decay", "map", "utils.lengths_to_mask", "torch.zeros_like", "range", "model.parameters", "utils.logging.Logger.training", "len", "max", "torch.argmax", "torch.sum().item", "torch.sum().item", "ewc.penalty", "torch.nn.functional.softmax", "time.time", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.update_states", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.cos_decay", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.training", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.penalty"], ["", "", "def", "train_aux", "(", "logging_start_epoch", ",", "epoch", ",", "data", ",", "model", ",", "criterion", ",", "optimizer", ",", "ewc", "=", "None", ",", "data_aux", "=", "None", ")", ":", "\n", "    ", "\"\"\"Main training procedure.\n\n    Arguments:\n        logging_start_epoch -- number of the first epoch to be logged\n        epoch -- current epoch\n        data -- DataLoader which can provide batches for an epoch\n        model -- model to be trained\n        criterion -- instance of loss function to be optimized\n        optimizer -- instance of optimizer which will be used for parameter updates\n    \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# initialize counters, etc.", "\n", "learning_rate", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "cla", "=", "0", "\n", "done", ",", "start_time", "=", "0", ",", "time", ".", "time", "(", ")", "\n", "\n", "# loop through epoch batches", "\n", "# data: cbs batch; data_aux: rrs batch", "\n", "for", "i", ",", "(", "batch_cbs", ",", "batch_rrs", ")", "in", "enumerate", "(", "zip", "(", "data", ",", "data_aux", ")", ")", ":", "\n", "\n", "        ", "global_step", "=", "done", "+", "epoch", "*", "len", "(", "data", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "##### run aux batch (rrs batch)", "\n", "# parse batch", "\n", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch_rrs", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# get teacher forcing ratio", "\n", "if", "hp", ".", "constant_teacher_forcing", ":", "tf", "=", "hp", ".", "teacher_forcing", "\n", "else", ":", "tf", "=", "cos_decay", "(", "max", "(", "global_step", "-", "hp", ".", "teacher_forcing_start_steps", ",", "0", ")", ",", "hp", ".", "teacher_forcing_steps", ")", "\n", "\n", "# run the current model (student)", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "tf", ",", "is_rrs", "=", "True", ")", "\n", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss_rrs", ",", "batch_losses_rrs", "=", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "\n", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "(", "hp", ".", "rrs_importance", "*", "loss_rrs", ")", ".", "backward", "(", ")", "\n", "\n", "##### run primary batch (cbs batch)", "\n", "# parse batch", "\n", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch_cbs", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "# run the current model (student)", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "tf", ",", "is_rrs", "=", "False", ")", "\n", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss", ",", "batch_losses", "=", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "\n", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "(", "hp", ".", "cbs_importance", "*", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "# evaluate adversarial classifier accuracy, if present", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "input_mask", "=", "lengths_to_mask", "(", "src_len", ")", "\n", "trg_spkrs", "=", "torch", ".", "zeros_like", "(", "input_mask", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "s", "in", "range", "(", "hp", ".", "speaker_number", ")", ":", "\n", "                ", "speaker_mask", "=", "(", "spkrs", "==", "s", ")", "\n", "trg_spkrs", "[", "speaker_mask", "]", "=", "s", "\n", "", "matches", "=", "(", "trg_spkrs", "==", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "spkrs_pred", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "matches", "[", "~", "input_mask", "]", "=", "False", "\n", "cla", "=", "torch", ".", "sum", "(", "matches", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "input_mask", ")", ".", "item", "(", ")", "\n", "\n", "# comptute gradients and make a step", "\n", "", "if", "ewc", "is", "not", "None", ":", "\n", "            ", "loss", "+=", "hp", ".", "ewc_importance", "*", "ewc", ".", "penalty", "(", "model", ")", "\n", "# loss.backward()", "\n", "", "gradient", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "hp", ".", "gradient_clipping", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# log training progress", "\n", "if", "epoch", ">=", "logging_start_epoch", ":", "\n", "            ", "Logger", ".", "training", "(", "global_step", ",", "batch_losses", ",", "gradient", ",", "learning_rate", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "cla", ")", "\n", "\n", "# update criterion states (params and decay of the loss and so on ...)", "\n", "", "criterion", ".", "update_states", "(", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "done", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train_gem": [[199, 246], ["gem.train", "gem.net.train", "enumerate", "time.time", "gem.opt.zero_grad", "gem.observe", "gem.criterion.update_states", "time.time", "utils.lengths_to_mask", "torch.zeros_like", "range", "utils.logging.Logger.training", "len", "torch.argmax", "torch.sum().item", "torch.sum().item", "torch.nn.functional.softmax", "time.time", "torch.sum", "torch.sum"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.GEM.observe", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.update_states", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.training"], ["", "", "def", "train_gem", "(", "logging_start_epoch", ",", "epoch", ",", "data", ",", "gem", ",", "cur_task_id", ")", ":", "\n", "    ", "\"\"\"Main training procedure.\n\n    Arguments:\n        logging_start_epoch -- number of the first epoch to be logged\n        epoch -- current epoch\n        data -- DataLoader which can provide batches for an epoch\n        gem -- gem trainer\n    \"\"\"", "\n", "\n", "gem", ".", "train", "(", ")", "\n", "gem", ".", "net", ".", "train", "(", ")", "\n", "\n", "# initialize counters, etc.", "\n", "learning_rate", "=", "gem", ".", "opt", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "cla", "=", "0", "\n", "done", ",", "start_time", "=", "0", ",", "time", ".", "time", "(", ")", "\n", "\n", "# loop through epoch batches", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "        ", "global_step", "=", "done", "+", "epoch", "*", "len", "(", "data", ")", "\n", "gem", ".", "opt", ".", "zero_grad", "(", ")", "\n", "\n", "_", ",", "batch_losses", ",", "gradient", "=", "gem", ".", "observe", "(", "batch", ",", "cur_task_id", ")", "\n", "\n", "\n", "# evaluate adversarial classifier accuracy, if present", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "input_mask", "=", "lengths_to_mask", "(", "src_len", ")", "\n", "trg_spkrs", "=", "torch", ".", "zeros_like", "(", "input_mask", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "s", "in", "range", "(", "hp", ".", "speaker_number", ")", ":", "\n", "                ", "speaker_mask", "=", "(", "spkrs", "==", "s", ")", "\n", "trg_spkrs", "[", "speaker_mask", "]", "=", "s", "\n", "", "matches", "=", "(", "trg_spkrs", "==", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "spkrs_pred", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "matches", "[", "~", "input_mask", "]", "=", "False", "\n", "cla", "=", "torch", ".", "sum", "(", "matches", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "input_mask", ")", ".", "item", "(", ")", "\n", "\n", "# log training progress", "\n", "", "if", "epoch", ">=", "logging_start_epoch", ":", "\n", "            ", "Logger", ".", "training", "(", "global_step", ",", "batch_losses", ",", "gradient", ",", "learning_rate", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "cla", ")", "\n", "\n", "# update criterion states (params and decay of the loss and so on ...)", "\n", "", "gem", ".", "criterion", ".", "update_states", "(", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "done", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.evaluate": [[247, 352], ["model.eval", "eval_losses.keys", "utils.logging.Logger.evaluation", "sum", "torch.no_grad", "enumerate", "len", "eval_losses.values", "list", "model", "model", "torch.sigmoid", "criterion", "enumerate", "batch_losses.items", "utils.logging.Logger._sw.add_scalar", "map", "zip", "gen[].data.cpu().numpy", "ref[].data.cpu().numpy", "utils.lengths_to_mask", "torch.zeros_like", "range", "torch.no_grad", "enumerate", "numpy.where", "min", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "utils.audio.linear_to_mel", "torch.argmax", "list", "model", "torch.sigmoid", "enumerate", "len", "audio.linear_to_mel.size", "gen[].data.cpu", "ref[].data.cpu", "utils.audio.mel_cepstral_distorision", "torch.nn.functional.softmax", "map", "zip", "gen[].data.cpu().numpy", "ref[].data.cpu().numpy", "stop.cpu().numpy", "numpy.min", "audio.linear_to_mel.size", "torch.sum().item", "torch.sum().item", "numpy.where", "min", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "utils.audio.linear_to_mel", "len", "audio.linear_to_mel.size", "gen[].data.cpu", "ref[].data.cpu", "utils.audio.mel_cepstral_distorision", "stop.cpu", "torch.sum", "torch.sum", "stop.cpu().numpy", "numpy.min", "audio.linear_to_mel.size", "stop.cpu"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.evaluation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.linear_to_mel", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_cepstral_distorision", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.linear_to_mel", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_cepstral_distorision"], ["", "", "def", "evaluate", "(", "epoch", ",", "data", ",", "model", ",", "criterion", ",", "eval_loaders", "=", "None", ")", ":", "\n", "    ", "\"\"\"Main evaluation procedure.\n\n    Arguments:\n        epoch -- current epoch\n        data -- DataLoader which can provide validation batches\n        model -- model to be evaluated\n        criterion -- instance of loss function to measure performance\n    \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# initialize counters, etc.", "\n", "mcd", ",", "mcd_count", "=", "0", ",", "0", "\n", "cla", ",", "cla_count", "=", "0", ",", "0", "\n", "eval_losses", "=", "{", "}", "\n", "\n", "# loop through epoch batches", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "# parse batch", "\n", "            ", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# run the model (twice, with and without teacher forcing)", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "1.0", ")", "\n", "post_pred_0", ",", "_", ",", "stop_pred_0", ",", "alignment_0", ",", "_", ",", "_", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "0.0", ")", "\n", "stop_pred_probs", "=", "torch", ".", "sigmoid", "(", "stop_pred_0", ")", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss", ",", "batch_losses", "=", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "\n", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "\n", "# compute mel cepstral distorsion", "\n", "for", "j", ",", "(", "gen", ",", "ref", ",", "stop", ")", "in", "enumerate", "(", "zip", "(", "post_pred_0", ",", "trg_mel", ",", "stop_pred_probs", ")", ")", ":", "\n", "                ", "stop_idxes", "=", "np", ".", "where", "(", "stop", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "[", "0", "]", "\n", "stop_idx", "=", "min", "(", "np", ".", "min", "(", "stop_idxes", ")", "+", "hp", ".", "stop_frames", ",", "gen", ".", "size", "(", ")", "[", "1", "]", ")", "if", "len", "(", "stop_idxes", ")", ">", "0", "else", "gen", ".", "size", "(", ")", "[", "1", "]", "\n", "gen", "=", "gen", "[", ":", ",", ":", "stop_idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ref", "=", "ref", "[", ":", ",", ":", "trg_len", "[", "j", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "hp", ".", "normalize_spectrogram", ":", "\n", "                    ", "gen", "=", "audio", ".", "denormalize_spectrogram", "(", "gen", ",", "not", "hp", ".", "predict_linear", ")", "\n", "ref", "=", "audio", ".", "denormalize_spectrogram", "(", "ref", ",", "True", ")", "\n", "", "if", "hp", ".", "predict_linear", ":", "gen", "=", "audio", ".", "linear_to_mel", "(", "gen", ")", "\n", "mcd", "=", "(", "mcd_count", "*", "mcd", "+", "audio", ".", "mel_cepstral_distorision", "(", "gen", ",", "ref", ",", "'dtw'", ")", ")", "/", "(", "mcd_count", "+", "1", ")", "\n", "mcd_count", "+=", "1", "\n", "\n", "# compute adversarial classifier accuracy", "\n", "", "if", "hp", ".", "reversal_classifier", ":", "\n", "                ", "input_mask", "=", "lengths_to_mask", "(", "src_len", ")", "\n", "trg_spkrs", "=", "torch", ".", "zeros_like", "(", "input_mask", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "s", "in", "range", "(", "hp", ".", "speaker_number", ")", ":", "\n", "                    ", "speaker_mask", "=", "(", "spkrs", "==", "s", ")", "\n", "trg_spkrs", "[", "speaker_mask", "]", "=", "s", "\n", "", "matches", "=", "(", "trg_spkrs", "==", "torch", ".", "argmax", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "spkrs_pred", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ")", "\n", "matches", "[", "~", "input_mask", "]", "=", "False", "\n", "cla", "=", "(", "cla_count", "*", "cla", "+", "torch", ".", "sum", "(", "matches", ")", ".", "item", "(", ")", "/", "torch", ".", "sum", "(", "input_mask", ")", ".", "item", "(", ")", ")", "/", "(", "cla_count", "+", "1", ")", "\n", "cla_count", "+=", "1", "\n", "\n", "# add batch losses to epoch losses", "\n", "", "for", "k", ",", "v", "in", "batch_losses", ".", "items", "(", ")", ":", "\n", "                ", "eval_losses", "[", "k", "]", "=", "v", "+", "eval_losses", "[", "k", "]", "if", "k", "in", "eval_losses", "else", "v", "\n", "\n", "# normalize loss per batch", "\n", "", "", "", "for", "k", "in", "eval_losses", ".", "keys", "(", ")", ":", "\n", "        ", "eval_losses", "[", "k", "]", "/=", "len", "(", "data", ")", "\n", "\n", "# log evaluation", "\n", "", "Logger", ".", "evaluation", "(", "epoch", "+", "1", ",", "eval_losses", ",", "mcd", ",", "src_len", ",", "trg_len", ",", "src", ",", "post_trg", ",", "post_pred", ",", "post_pred_0", ",", "stop_pred_probs", ",", "stop_trg", ",", "alignment_0", ",", "cla", ")", "\n", "\n", "if", "eval_loaders", "is", "not", "None", ":", "\n", "        ", "for", "eval_lang", ",", "eval_loader", "in", "eval_loaders", ":", "\n", "            ", "mcd_old_tasks", ",", "mcd_count_old_tasks", "=", "0.", ",", "0.", "\n", "# loop through epoch batches", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "i", ",", "batch", "in", "enumerate", "(", "eval_loader", ")", ":", "\n", "\n", "# parse batch", "\n", "                    ", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src_old", ",", "src_len_old", ",", "trg_mel_old", ",", "trg_lin_old", ",", "trg_len_old", ",", "stop_trg_old", ",", "spkrs_old", ",", "langs_old", "=", "batch", "\n", "\n", "# run the model (without teacher forcing, computing mcd only)", "\n", "post_pred_0_old", ",", "_", ",", "stop_pred_0_old", ",", "_", ",", "_", ",", "_", "=", "model", "(", "src_old", ",", "src_len_old", ",", "trg_mel_old", ",", "trg_len_old", ",", "spkrs_old", ",", "langs_old", ",", "0.0", ")", "\n", "stop_pred_probs", "=", "torch", ".", "sigmoid", "(", "stop_pred_0_old", ")", "\n", "\n", "\n", "# compute mel cepstral distorsion", "\n", "for", "j", ",", "(", "gen", ",", "ref", ",", "stop", ")", "in", "enumerate", "(", "zip", "(", "post_pred_0_old", ",", "trg_mel_old", ",", "stop_pred_probs", ")", ")", ":", "\n", "                        ", "stop_idxes", "=", "np", ".", "where", "(", "stop", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "[", "0", "]", "\n", "stop_idx", "=", "min", "(", "np", ".", "min", "(", "stop_idxes", ")", "+", "hp", ".", "stop_frames", ",", "gen", ".", "size", "(", ")", "[", "1", "]", ")", "if", "len", "(", "stop_idxes", ")", ">", "0", "else", "gen", ".", "size", "(", ")", "[", "1", "]", "\n", "gen", "=", "gen", "[", ":", ",", ":", "stop_idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ref", "=", "ref", "[", ":", ",", ":", "trg_len_old", "[", "j", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "hp", ".", "normalize_spectrogram", ":", "\n", "                            ", "gen", "=", "audio", ".", "denormalize_spectrogram", "(", "gen", ",", "not", "hp", ".", "predict_linear", ")", "\n", "ref", "=", "audio", ".", "denormalize_spectrogram", "(", "ref", ",", "True", ")", "\n", "", "if", "hp", ".", "predict_linear", ":", "gen", "=", "audio", ".", "linear_to_mel", "(", "gen", ")", "\n", "mcd_old_tasks", "=", "(", "mcd_count_old_tasks", "*", "mcd_old_tasks", "+", "audio", ".", "mel_cepstral_distorision", "(", "gen", ",", "ref", ",", "'dtw'", ")", ")", "/", "(", "mcd_count_old_tasks", "+", "1", ")", "\n", "mcd_count_old_tasks", "+=", "1", "\n", "# add per-lang mcd to logger", "\n", "", "", "", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Eval/mcd_{eval_lang}'", ",", "mcd_old_tasks", ",", "epoch", "+", "1", ")", "\n", "\n", "\n", "", "", "return", "sum", "(", "eval_losses", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.compute_mcd_on_data_loader": [[354, 404], ["model.eval", "torch.no_grad", "enumerate", "torch.cuda.is_available", "model", "torch.sigmoid", "enumerate", "list", "zip", "gen[].data.cpu().numpy", "ref[].data.cpu().numpy", "map", "numpy.where", "min", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "utils.audio.linear_to_mel", "len", "audio.linear_to_mel.size", "gen[].data.cpu", "ref[].data.cpu", "utils.audio.mel_cepstral_distorision", "stop.cpu().numpy", "numpy.min", "audio.linear_to_mel.size", "stop.cpu"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.linear_to_mel", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_cepstral_distorision"], ["", "def", "compute_mcd_on_data_loader", "(", "data", ",", "model", ",", "mel_mean", "=", "None", ",", "mel_var", "=", "None", ")", ":", "\n", "    ", "\"\"\"Main evaluation procedure.\n\n    Arguments:\n        epoch -- current epoch\n        data -- DataLoader which can provide validation batches\n        model -- model to be evaluated\n        criterion -- instance of loss function to measure performance\n    \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# For any given eval langauge, should provide the corresponding cached mel mean and var", "\n", "# otherwise the model will use the mel mean and var that it was trained on", "\n", "if", "mel_mean", "is", "not", "None", "and", "mel_var", "is", "not", "None", ":", "\n", "        ", "hp", ".", "mel_normalize_mean", "=", "mel_mean", "\n", "hp", ".", "mel_normalize_variance", "=", "mel_var", "\n", "\n", "# initialize counters, etc.", "\n", "", "mcd", ",", "mcd_count", "=", "0", ",", "0", "\n", "\n", "# loop through epoch batches", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "# parse batch", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# run the model (only once, without teacher forcing)", "\n", "# post_pred, pre_pred, stop_pred, alignment, spkrs_pred, enc_output = model(src, src_len, trg_mel, trg_len, spkrs, langs, 1.0)", "\n", "post_pred_0", ",", "_", ",", "stop_pred_0", ",", "alignment_0", ",", "_", ",", "_", "=", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "0.0", ")", "\n", "stop_pred_probs", "=", "torch", ".", "sigmoid", "(", "stop_pred_0", ")", "\n", "\n", "\n", "# compute mel cepstral distorsion", "\n", "for", "j", ",", "(", "gen", ",", "ref", ",", "stop", ")", "in", "enumerate", "(", "zip", "(", "post_pred_0", ",", "trg_mel", ",", "stop_pred_probs", ")", ")", ":", "\n", "                ", "stop_idxes", "=", "np", ".", "where", "(", "stop", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ">", "0.5", ")", "[", "0", "]", "\n", "stop_idx", "=", "min", "(", "np", ".", "min", "(", "stop_idxes", ")", "+", "hp", ".", "stop_frames", ",", "gen", ".", "size", "(", ")", "[", "1", "]", ")", "if", "len", "(", "stop_idxes", ")", ">", "0", "else", "gen", ".", "size", "(", ")", "[", "1", "]", "\n", "gen", "=", "gen", "[", ":", ",", ":", "stop_idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ref", "=", "ref", "[", ":", ",", ":", "trg_len", "[", "j", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "hp", ".", "normalize_spectrogram", ":", "\n", "                    ", "gen", "=", "audio", ".", "denormalize_spectrogram", "(", "gen", ",", "not", "hp", ".", "predict_linear", ")", "\n", "ref", "=", "audio", ".", "denormalize_spectrogram", "(", "ref", ",", "True", ")", "\n", "", "if", "hp", ".", "predict_linear", ":", "gen", "=", "audio", ".", "linear_to_mel", "(", "gen", ")", "\n", "mcd", "=", "(", "mcd_count", "*", "mcd", "+", "audio", ".", "mel_cepstral_distorision", "(", "gen", ",", "ref", ",", "'dtw'", ")", ")", "/", "(", "mcd_count", "+", "1", ")", "\n", "mcd_count", "+=", "1", "\n", "\n", "", "", "", "return", "mcd", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.__init__": [[20, 32], ["copy.deepcopy().items", "ewc.variable", "ewc.EWC.model.named_parameters", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.variable"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "\n", "criterion", ":", "nn", ".", "Module", ")", ":", "\n", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "criterion", "=", "criterion", "\n", "# self.dataset = dataset", "\n", "\n", "self", ".", "params", "=", "{", "n", ":", "p", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "}", "\n", "self", ".", "_means", "=", "{", "}", "\n", "\n", "for", "n", ",", "p", "in", "deepcopy", "(", "self", ".", "params", ")", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_means", "[", "n", "]", "=", "variable", "(", "p", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC._diag_fisher": [[34, 83], ["copy.deepcopy().items", "ewc.EWC.model.train", "print", "enumerate", "print", "p.data.zero_", "ewc.variable", "list", "ewc.EWC.model", "ewc.EWC.criterion", "loss.backward", "src.size", "ewc.EWC.model.named_parameters", "copy.deepcopy", "map", "cos_decay", "precision_matrices.items", "max"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.train", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.variable", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientClippingFunction.backward", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.cos_decay"], ["", "", "def", "_diag_fisher", "(", "self", ",", "dataset", ",", "sample_size", "=", "None", ")", ":", "\n", "        ", "precision_matrices", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "deepcopy", "(", "self", ".", "params", ")", ".", "items", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "zero_", "(", ")", "\n", "precision_matrices", "[", "n", "]", "=", "variable", "(", "p", ".", "data", ")", "\n", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "# for input in self.dataset:", "\n", "#     self.model.zero_grad()", "\n", "#     input = variable(input)", "\n", "#     output = self.model(input).view(1, -1)", "\n", "#     label = output.max(1)[1].view(-1)", "\n", "#     loss = F.nll_loss(F.log_softmax(output, dim=1), label)", "\n", "#     loss.backward()", "\n", "\n", "print", "(", "\"Computing Fisher...\"", ")", "\n", "cnt", "=", "0.", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataset", ")", ":", "\n", "# parse batch", "\n", "            ", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "batch", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "\n", "# get teacher forcing ratio", "\n", "if", "hp", ".", "constant_teacher_forcing", ":", "tf", "=", "hp", ".", "teacher_forcing", "\n", "else", ":", "tf", "=", "cos_decay", "(", "max", "(", "global_step", "-", "hp", ".", "teacher_forcing_start_steps", ",", "0", ")", ",", "hp", ".", "teacher_forcing_steps", ")", "\n", "\n", "# run the model", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "self", ".", "model", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "tf", ")", "\n", "\n", "# evaluate loss function", "\n", "post_trg", "=", "trg_lin", "if", "hp", ".", "predict_linear", "else", "trg_mel", "\n", "classifier", "=", "model", ".", "_reversal_classifier", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "loss", ",", "batch_losses", "=", "self", ".", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "post_trg", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "classifier", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "\n", "cnt", "+=", "src", ".", "size", "(", "0", ")", "\n", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "precision_matrices", "[", "n", "]", ".", "data", "+=", "p", ".", "grad", ".", "data", "**", "2", "\n", "\n", "", "if", "sample_size", ":", "\n", "                ", "if", "cnt", ">=", "sample_size", ":", "\n", "                    ", "break", "\n", "", "", "", "print", "(", "\"computed Fisher using {} samples\"", ".", "format", "(", "cnt", ")", ")", "\n", "\n", "\n", "precision_matrices", "=", "{", "n", ":", "p", "/", "cnt", "for", "n", ",", "p", "in", "precision_matrices", ".", "items", "(", ")", "}", "# mean over sampled data", "\n", "return", "precision_matrices", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.update_fisher": [[84, 86], ["ewc.EWC._diag_fisher"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC._diag_fisher"], ["", "def", "update_fisher", "(", "self", ",", "dataset", ":", "DataLoader", ",", "sample_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "_precision_matrices", "=", "self", ".", "_diag_fisher", "(", "dataset", ",", "sample_size", "=", "sample_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.load_fisher": [[87, 91], ["print", "p.cuda", "fisher_matrices.items"], "methods", ["None"], ["", "def", "load_fisher", "(", "self", ",", "fisher_matrices", ")", ":", "\n", "        ", "assert", "fisher_matrices", "!=", "{", "}", "\n", "self", ".", "_precision_matrices", "=", "{", "n", ":", "p", ".", "cuda", "(", ")", "for", "n", ",", "p", "in", "fisher_matrices", ".", "items", "(", ")", "}", "\n", "print", "(", "\"fisher loaded.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.get_fisher": [[92, 94], ["None"], "methods", ["None"], ["", "def", "get_fisher", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_precision_matrices", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.EWC.penalty": [[95, 101], ["model.named_parameters", "_loss.sum"], "methods", ["None"], ["", "def", "penalty", "(", "self", ",", "model", ":", "nn", ".", "Module", ")", ":", "\n", "        ", "loss", "=", "0", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "_loss", "=", "self", ".", "_precision_matrices", "[", "n", "]", "*", "(", "p", "-", "self", ".", "_means", "[", "n", "]", ")", "**", "2", "\n", "loss", "+=", "_loss", ".", "sum", "(", ")", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.ewc.variable": [[13, 17], ["torch.autograd.Variable", "torch.cuda.is_available", "t.cuda.cuda"], "function", ["None"], ["def", "variable", "(", "t", ":", "torch", ".", "Tensor", ",", "use_cuda", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "use_cuda", ":", "\n", "        ", "t", "=", "t", ".", "cuda", "(", ")", "\n", "", "return", "Variable", "(", "t", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.GEM.__init__": [[74, 104], ["torch.Module.__init__", "gem.GEM.parameters", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "gem.GEM.grad_dims.append", "param.data.numel", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "sum"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "mem_data", ",", "\n", "n_tasks", ",", "\n", "hp", ")", ":", "\n", "        ", "\"\"\"\n        mem_data: data loader of buffered prev samples\n        n_tasks: num of total tasks. should include current task. e.g when training french\n                 n_tasks should be 2.\n        \"\"\"", "\n", "super", "(", "GEM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hp", "=", "hp", "\n", "self", ".", "margin", "=", "hp", ".", "memory_strength", "\n", "self", ".", "n_tasks", "=", "n_tasks", "\n", "\n", "self", ".", "net", "=", "model", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "opt", "=", "optimizer", "\n", "\n", "# allocate episodic memory", "\n", "self", ".", "mem_data", "=", "mem_data", "\n", "\n", "# allocate temporary synaptic memory", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "self", ".", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "", "self", ".", "grads", "=", "torch", ".", "Tensor", "(", "sum", "(", "self", ".", "grad_dims", ")", ",", "n_tasks", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.GEM.forward": [[105, 115], ["gem.GEM.net", "cos_decay", "max"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.None.train_continual.cos_decay"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "x", "\n", "\n", "# get teacher forcing ratio", "\n", "if", "self", ".", "hp", ".", "constant_teacher_forcing", ":", "tf", "=", "self", ".", "hp", ".", "teacher_forcing", "\n", "else", ":", "tf", "=", "cos_decay", "(", "max", "(", "global_step", "-", "self", ".", "hp", ".", "teacher_forcing_start_steps", ",", "0", ")", ",", "self", ".", "hp", ".", "teacher_forcing_steps", ")", "\n", "\n", "# run the current model (teacher forcing )", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "self", ".", "net", "(", "src", ",", "src_len", ",", "trg_mel", ",", "trg_len", ",", "spkrs", ",", "langs", ",", "1.0", ")", "\n", "return", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.GEM.parse_batch_by_task": [[116, 122], ["torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select"], "methods", ["None"], ["", "def", "parse_batch_by_task", "(", "self", ",", "x", ",", "sel_indices", ")", ":", "\n", "        ", "\"\"\"\n        select samples from a batch that correspond to a task\n        \"\"\"", "\n", "if", "x", "is", "None", ":", "return", "x", "\n", "return", "torch", ".", "index_select", "(", "x", ",", "0", ",", "sel_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.GEM.observe": [[124, 175], ["range", "gem.GEM.zero_grad", "list", "gem.GEM.forward", "gem.GEM.criterion", "loss.backward", "gem.store_grad", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "gem.GEM.opt.step", "gem.GEM.zero_grad", "gem.store_grad", "map", "list", "gem.GEM.grads[].unsqueeze", "gem.GEM.grads.index_select", "gem.project2cone2", "gem.overwrite_grad", "gem.GEM.net.parameters", "batch[].size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "list", "gem.GEM.forward", "gem.GEM.criterion", "range", "gem.GEM.grads[].unsqueeze", "gem.GEM.grads.index_select", "gem.GEM.parse_batch_by_task", "map", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientClippingFunction.backward", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.store_grad", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.store_grad", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.project2cone2", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.overwrite_grad", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward", "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.GEM.parse_batch_by_task"], ["", "def", "observe", "(", "self", ",", "cur_batch", ",", "cur_task", ")", ":", "\n", "\n", "# compute gradient on previous tasks", "\n", "        ", "for", "task_idx", "in", "range", "(", "self", ".", "n_tasks", "-", "1", ")", ":", "\n", "# -1 means exclude current task", "\n", "            ", "self", ".", "zero_grad", "(", ")", "\n", "for", "batch", "in", "self", ".", "mem_data", ":", "\n", "                ", "bs", "=", "batch", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "batch_langs", "=", "batch", "[", "7", "]", "\n", "# task_idx: an int representing task identifier.", "\n", "# e.g. 0 for german, 1 for french, 2 for spanish", "\n", "sel_indices", "=", "torch", ".", "LongTensor", "(", "\n", "[", "i", "for", "i", "in", "range", "(", "bs", ")", "if", "batch_langs", "[", "i", "]", "[", "0", "]", "[", "task_idx", "]", "==", "1", "]", ")", "\n", "if", "not", "len", "(", "sel_indices", ")", ">", "0", ":", "\n", "# batch does not have data for target task", "\n", "                    ", "continue", "\n", "", "batch_task", "=", "[", "self", ".", "parse_batch_by_task", "(", "x", ",", "sel_indices", ")", "for", "x", "in", "batch", "]", "\n", "batch_task", "=", "list", "(", "map", "(", "to_gpu", ",", "batch_task", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch_task", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "self", ".", "forward", "(", "batch_task", ")", "\n", "# evaluate loss function", "\n", "ptloss", ",", "_", "=", "self", ".", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "trg_mel", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "None", ")", "\n", "(", "ptloss", "/", "len", "(", "self", ".", "mem_data", ")", ")", ".", "backward", "(", ")", "\n", "", "store_grad", "(", "self", ".", "parameters", ",", "self", ".", "grads", ",", "self", ".", "grad_dims", ",", "task_idx", ")", "\n", "\n", "\n", "# now compute the grad on the current minibatch", "\n", "", "self", ".", "zero_grad", "(", ")", "\n", "\n", "batch", "=", "list", "(", "map", "(", "to_gpu", ",", "cur_batch", ")", ")", "\n", "src", ",", "src_len", ",", "trg_mel", ",", "trg_lin", ",", "trg_len", ",", "stop_trg", ",", "spkrs", ",", "langs", "=", "batch", "\n", "post_pred", ",", "pre_pred", ",", "stop_pred", ",", "alignment", ",", "spkrs_pred", ",", "enc_output", "=", "self", ".", "forward", "(", "batch", ")", "\n", "loss", ",", "batch_losses", "=", "self", ".", "criterion", "(", "src_len", ",", "trg_len", ",", "pre_pred", ",", "trg_mel", ",", "post_pred", ",", "trg_mel", ",", "stop_pred", ",", "stop_trg", ",", "alignment", ",", "spkrs", ",", "spkrs_pred", ",", "enc_output", ",", "None", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# check if gradient violates constraints", "\n", "# copy gradient", "\n", "store_grad", "(", "self", ".", "parameters", ",", "self", ".", "grads", ",", "self", ".", "grad_dims", ",", "cur_task", ")", "\n", "indx", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "list", "(", "range", "(", "cur_task", ")", ")", ")", "\n", "dotp", "=", "torch", ".", "mm", "(", "self", ".", "grads", "[", ":", ",", "cur_task", "]", ".", "unsqueeze", "(", "0", ")", ",", "\n", "self", ".", "grads", ".", "index_select", "(", "1", ",", "indx", ")", ")", "\n", "if", "(", "dotp", "<", "0", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "            ", "project2cone2", "(", "self", ".", "grads", "[", ":", ",", "cur_task", "]", ".", "unsqueeze", "(", "1", ")", ",", "\n", "self", ".", "grads", ".", "index_select", "(", "1", ",", "indx", ")", ",", "self", ".", "margin", ")", "\n", "# copy gradients back", "\n", "overwrite_grad", "(", "self", ".", "parameters", ",", "self", ".", "grads", "[", ":", ",", "cur_task", "]", ",", "\n", "self", ".", "grad_dims", ")", "\n", "\n", "", "gradient", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "net", ".", "parameters", "(", ")", ",", "self", ".", "hp", ".", "gradient_clipping", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "return", "loss", ",", "batch_losses", ",", "gradient", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.store_grad": [[13, 30], ["grads[].fill_", "pp", "sum", "grads[].copy_", "sum", "param.grad.data.view"], "function", ["None"], ["def", "store_grad", "(", "pp", ",", "grads", ",", "grad_dims", ",", "tid", ")", ":", "\n", "    ", "\"\"\"\n        This stores parameter gradients of past tasks.\n        pp: parameters\n        grads: gradients\n        grad_dims: list with number of parameters per layers\n        tid: task id\n    \"\"\"", "\n", "# store the gradients", "\n", "grads", "[", ":", ",", "tid", "]", ".", "fill_", "(", "0.0", ")", "\n", "cnt", "=", "0", "\n", "for", "param", "in", "pp", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "en", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "grads", "[", "beg", ":", "en", ",", "tid", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.overwrite_grad": [[32, 49], ["pp", "sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "function", ["None"], ["", "", "def", "overwrite_grad", "(", "pp", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "    ", "\"\"\"\n        This is used to overwrite the gradients with a new gradient\n        vector, whenever violations occur.\n        pp: parameters\n        newgrad: corrected gradient\n        grad_dims: list storing number of parameters at each layer\n    \"\"\"", "\n", "cnt", "=", "0", "\n", "for", "param", "in", "pp", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "en", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "beg", ":", "en", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.None.gem.project2cone2": [[51, 71], ["memories.cpu().t().double().numpy", "gradient.cpu().contiguous().view().double().numpy", "numpy.dot", "numpy.eye", "gradient.copy_", "memories.cpu().t().double().numpy.transpose", "numpy.dot", "numpy.zeros", "quadprog.solve_qp", "numpy.dot", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "memories.cpu().t().double", "gradient.cpu().contiguous().view().double", "numpy.eye", "np.dot.transpose", "torch.Tensor", "torch.Tensor", "torch.Tensor", "memories.cpu().t", "gradient.cpu().contiguous().view", "memories.cpu", "gradient.cpu().contiguous", "gradient.cpu"], "function", ["None"], ["", "", "def", "project2cone2", "(", "gradient", ",", "memories", ",", "margin", "=", "0.5", ",", "eps", "=", "1e-3", ")", ":", "\n", "    ", "\"\"\"\n        Solves the GEM dual QP described in the paper given a proposed\n        gradient \"gradient\", and a memory of task gradients \"memories\".\n        Overwrites \"gradient\" with the final projected update.\n        input:  gradient, p-vector\n        input:  memories, (t * p)-vector\n        output: x, p-vector\n    \"\"\"", "\n", "memories_np", "=", "memories", ".", "cpu", "(", ")", ".", "t", "(", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "gradient_np", "=", "gradient", ".", "cpu", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "double", "(", ")", ".", "numpy", "(", ")", "\n", "t", "=", "memories_np", ".", "shape", "[", "0", "]", "\n", "P", "=", "np", ".", "dot", "(", "memories_np", ",", "memories_np", ".", "transpose", "(", ")", ")", "\n", "P", "=", "0.5", "*", "(", "P", "+", "P", ".", "transpose", "(", ")", ")", "+", "np", ".", "eye", "(", "t", ")", "*", "eps", "\n", "q", "=", "np", ".", "dot", "(", "memories_np", ",", "gradient_np", ")", "*", "-", "1", "\n", "G", "=", "np", ".", "eye", "(", "t", ")", "\n", "h", "=", "np", ".", "zeros", "(", "t", ")", "+", "margin", "\n", "v", "=", "quadprog", ".", "solve_qp", "(", "P", ",", "q", ",", "G", ",", "h", ")", "[", "0", "]", "\n", "x", "=", "np", ".", "dot", "(", "v", ",", "memories_np", ")", "+", "gradient_np", "\n", "gradient", ".", "copy_", "(", "torch", ".", "Tensor", "(", "x", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.WeightedSampler.__init__": [[14, 27], ["range", "float", "torch.utils.data.sampler.WeightedRandomSampler", "len", "sum", "len", "lebel_freq.values", "range", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ")", ":", "\n", "\n", "        ", "lebel_freq", "=", "{", "}", "\n", "for", "idx", "in", "range", "(", "len", "(", "data_source", ")", ")", ":", "\n", "            ", "label", "=", "data_source", ".", "items", "[", "idx", "]", "[", "'language'", "]", "\n", "if", "label", "in", "lebel_freq", ":", "lebel_freq", "[", "label", "]", "+=", "1", "\n", "else", ":", "lebel_freq", "[", "label", "]", "=", "1", "\n", "", "self", ".", "lebel_freq", "=", "lebel_freq", "\n", "\n", "total", "=", "float", "(", "sum", "(", "lebel_freq", ".", "values", "(", ")", ")", ")", "\n", "weights", "=", "[", "total", "/", "lebel_freq", "[", "data_source", ".", "items", "[", "idx", "]", "[", "'language'", "]", "]", "for", "idx", "in", "range", "(", "len", "(", "data_source", ")", ")", "]", "\n", "\n", "self", ".", "_sampler", "=", "WeightedRandomSampler", "(", "weights", ",", "len", "(", "weights", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.WeightedSampler.__iter__": [[28, 30], ["samplers.WeightedSampler._sampler.__iter__"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.BalancedBatchSampler.__iter__"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sampler", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.WeightedSampler.__len__": [[31, 33], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.RandomCycleIter.__init__": [[38, 43], ["list", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "self", ".", "data_list", "=", "list", "(", "data", ")", "\n", "self", ".", "length", "=", "len", "(", "self", ".", "data_list", ")", "\n", "self", ".", "i", "=", "self", ".", "length", "-", "1", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "# self.test_mode = test_mode", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.RandomCycleIter.__iter__": [[45, 47], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.RandomCycleIter.__next__": [[48, 57], ["random.shuffle"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "self", ".", "i", "+=", "1", "\n", "\n", "if", "self", ".", "i", "==", "self", ".", "length", ":", "\n", "            ", "self", ".", "i", "=", "0", "\n", "if", "self", ".", "shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "self", ".", "data_list", ")", "\n", "\n", "", "", "return", "self", ".", "data_list", "[", "self", ".", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.BalancedBatchSampler.__init__": [[60, 75], ["range", "list", "len", "samplers.BalancedBatchSampler.label_indices[].append", "samplers.BalancedBatchSampler.label_indices.keys", "samplers.RandomCycleIter", "enumerate"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_source", ",", "batch_size", ",", "n_samples", ",", "shuffle", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "label_indices", "=", "{", "}", "\n", "for", "idx", "in", "range", "(", "len", "(", "data_source", ")", ")", ":", "\n", "            ", "label", "=", "data_source", ".", "items", "[", "idx", "]", "[", "'language'", "]", "\n", "if", "label", "not", "in", "self", ".", "label_indices", ":", "self", ".", "label_indices", "[", "label", "]", "=", "[", "]", "\n", "self", ".", "label_indices", "[", "label", "]", ".", "append", "(", "idx", ")", "\n", "", "languages", "=", "list", "(", "self", ".", "label_indices", ".", "keys", "(", ")", ")", "\n", "\n", "self", ".", "_samplers", "=", "[", "RandomCycleIter", "(", "self", ".", "label_indices", "[", "i", "]", ",", "shuffle", ")", "for", "i", ",", "_", "in", "enumerate", "(", "languages", ")", "]", "\n", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "n_samples", "=", "n_samples", "\n", "self", ".", "data_source", "=", "data_source", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.BalancedBatchSampler.__iter__": [[76, 93], ["iter", "next", "b.append", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "\n", "        ", "batch", "=", "[", "]", "\n", "iters", "=", "[", "iter", "(", "s", ")", "for", "s", "in", "self", ".", "_samplers", "]", "\n", "done", "=", "False", "\n", "cnt", "=", "0", "\n", "\n", "while", "cnt", "<", "self", ".", "n_samples", ":", "\n", "            ", "b", "=", "[", "]", "\n", "for", "it", "in", "iters", ":", "\n", "                ", "idx", "=", "next", "(", "it", ")", "\n", "b", ".", "append", "(", "idx", ")", "\n", "cnt", "+=", "1", "\n", "", "batch", "+=", "b", "\n", "if", "len", "(", "batch", ")", "==", "self", ".", "_batch_size", ":", "\n", "                ", "yield", "batch", "\n", "batch", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.samplers.BalancedBatchSampler.__len__": [[94, 96], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_source", ")", "//", "self", ".", "_batch_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.initialize": [[14, 23], ["torch.utils.tensorboard.SummaryWriter"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "initialize", "(", "logdir", ",", "flush_seconds", ")", ":", "\n", "        ", "\"\"\"Initialize Tensorboard logger.\n\n        Arguments:\n            logdir -- location of Tensorboard log files\n            flush_seconds -- see Tensorboard documentation\n        \"\"\"", "\n", "Logger", ".", "_sw", "=", "SummaryWriter", "(", "log_dir", "=", "logdir", ",", "flush_secs", "=", "flush_seconds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.progress": [[24, 41], ["print", "int", "max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "progress", "(", "progress", ",", "prefix", "=", "''", ",", "length", "=", "70", ")", ":", "\n", "        ", "\"\"\"Prints a pretty console progress bar.\n\n        Arguments:\n            progress -- percentage (from 0 to 1.0)\n        Keyword argumnets:\n            prefix (default: '') -- string which is prepended to the progress bar\n            length (default: 70) -- size of the full-size bar\n        \"\"\"", "\n", "progress", "*=", "100", "\n", "step", "=", "100", "/", "length", "\n", "filled", ",", "reminder", "=", "int", "(", "progress", "//", "step", ")", ",", "progress", "%", "step", "\n", "loading_bar", "=", "filled", "*", "'\u2588'", "\n", "loading_bar", "+=", "'\u2591'", "if", "reminder", "<", "step", "/", "3", "else", "'\u2592'", "if", "reminder", "<", "step", "*", "2", "/", "3", "else", "'\u2593'", "\n", "loading_bar", "+=", "max", "(", "0", ",", "length", "-", "filled", ")", "*", "'\u2591'", "if", "progress", "<", "100", "else", "''", "\n", "print", "(", "f'\\r{prefix} {loading_bar} {progress:.1f}%'", ",", "end", "=", "(", "''", "if", "progress", "<", "100", "else", "'\\n'", ")", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.training": [[42, 73], ["sum", "Logger._sw.add_scalar", "losses.items", "Logger._sw.add_scalar", "Logger._sw.add_scalar", "Logger._sw.add_scalar", "losses.values", "Logger._sw.add_scalar", "Logger._sw.add_scalar"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "training", "(", "train_step", ",", "losses", ",", "gradient", ",", "learning_rate", ",", "duration", ",", "classifier", ")", ":", "\n", "        ", "\"\"\"Log batch training.\n\n        Arguments:\n            train_step -- number of the current training step\n            losses (dictionary of {loss name, value})-- dictionary with values of batch losses\n            gradient (float) -- gradient norm\n            learning_rate (float) -- current learning rate\n            duration (float) -- duration of the current step\n            classifier (float) -- accuracy of the reversal classifier\n        \"\"\"", "\n", "\n", "# log losses", "\n", "total_loss", "=", "sum", "(", "losses", ".", "values", "(", ")", ")", "\n", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Train/loss_total'", ",", "total_loss", ",", "train_step", ")", "\n", "for", "n", ",", "l", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Train/loss_{n}'", ",", "l", ",", "train_step", ")", "\n", "\n", "# log gradient norm", "\n", "", "Logger", ".", "_sw", ".", "add_scalar", "(", "\"Train/gradient_norm\"", ",", "gradient", ",", "train_step", ")", "\n", "\n", "# log learning rate", "\n", "Logger", ".", "_sw", ".", "add_scalar", "(", "\"Train/learning_rate\"", ",", "learning_rate", ",", "train_step", ")", "\n", "\n", "# log duration", "\n", "Logger", ".", "_sw", ".", "add_scalar", "(", "\"Train/duration\"", ",", "duration", ",", "train_step", ")", "\n", "\n", "# log classifier accuracy", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Train/classifier'", ",", "classifier", ",", "train_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.evaluation": [[74, 141], ["sum", "Logger._sw.add_scalar", "losses.items", "random.randint", "prediction[].data.cpu().numpy", "prediction_forced[].data.cpu().numpy", "target[].data.cpu().numpy", "Logger._sw.add_figure", "Logger._sw.add_figure", "Logger._sw.add_figure", "utils.audio.inverse_spectrogram", "Logger._sw.add_audio", "utils.audio.inverse_spectrogram", "Logger._sw.add_audio", "Logger._sw.add_figure", "utils.text.to_text", "Logger._sw.add_text", "Logger._sw.add_figure", "Logger._sw.add_scalar", "losses.values", "Logger._sw.add_scalar", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "utils.audio.denormalize_spectrogram", "logging.Logger._plot_spectrogram", "logging.Logger._plot_spectrogram", "logging.Logger._plot_spectrogram", "alignment[].data.cpu().numpy", "logging.Logger._plot_alignment", "logging.Logger._plot_stop_tokens", "Logger._sw.add_scalar", "alignment.size", "prediction[].data.cpu", "prediction_forced[].data.cpu", "target[].data.cpu", "source[].data.cpu().numpy", "stop_target[].data.cpu().numpy", "stop_prediction[].data.cpu().numpy", "alignment[].data.cpu", "source[].data.cpu", "stop_target[].data.cpu", "stop_prediction[].data.cpu"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.inverse_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.inverse_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_text", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_alignment", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_stop_tokens"], ["", "", "@", "staticmethod", "\n", "def", "evaluation", "(", "eval_step", ",", "losses", ",", "mcd", ",", "source_len", ",", "target_len", ",", "source", ",", "target", ",", "prediction_forced", ",", "prediction", ",", "stop_prediction", ",", "stop_target", ",", "alignment", ",", "classifier", ")", ":", "\n", "        ", "\"\"\"Log evaluation results.\n\n        Arguments:\n            eval_step -- number of the current evaluation step (i.e. epoch)\n            losses (dictionary of {loss name, value})-- dictionary with values of batch losses\n            mcd (float) -- evaluation Mel Cepstral Distorsion\n            source_len (tensor) -- number of characters of input utterances\n            target_len (tensor) -- number of frames of ground-truth spectrograms\n            source (tensor) -- input utterances\n            target (tensor) -- ground-truth spectrograms\n            prediction_forced (tensor) -- ground-truth-aligned spectrograms\n            prediction (tensor) -- predicted spectrograms\n            stop_prediction (tensor) -- predicted stop token probabilities\n            stop_target (tensor) -- true stop token probabilities\n            alignment (tensor) -- alignments (attention weights for each frame) of the last evaluation batch\n            classifier (float) -- accuracy of the reversal classifier\n        \"\"\"", "\n", "\n", "# log losses", "\n", "total_loss", "=", "sum", "(", "losses", ".", "values", "(", ")", ")", "\n", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Eval/loss_total'", ",", "total_loss", ",", "eval_step", ")", "\n", "for", "n", ",", "l", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Eval/loss_{n}'", ",", "l", ",", "eval_step", ")", "\n", "\n", "# show random sample: spectrogram, stop token probability, alignment and audio", "\n", "", "idx", "=", "random", ".", "randint", "(", "0", ",", "alignment", ".", "size", "(", "0", ")", "-", "1", ")", "\n", "predicted_spec", "=", "prediction", "[", "idx", ",", ":", ",", ":", "target_len", "[", "idx", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "f_predicted_spec", "=", "prediction_forced", "[", "idx", ",", ":", ",", ":", "target_len", "[", "idx", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "target_spec", "=", "target", "[", "idx", ",", ":", ",", ":", "target_len", "[", "idx", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# log spectrograms", "\n", "if", "hp", ".", "normalize_spectrogram", ":", "\n", "            ", "predicted_spec", "=", "audio", ".", "denormalize_spectrogram", "(", "predicted_spec", ",", "not", "hp", ".", "predict_linear", ")", "\n", "f_predicted_spec", "=", "audio", ".", "denormalize_spectrogram", "(", "f_predicted_spec", ",", "not", "hp", ".", "predict_linear", ")", "\n", "target_spec", "=", "audio", ".", "denormalize_spectrogram", "(", "target_spec", ",", "not", "hp", ".", "predict_linear", ")", "\n", "", "Logger", ".", "_sw", ".", "add_figure", "(", "f\"Predicted/generated\"", ",", "Logger", ".", "_plot_spectrogram", "(", "predicted_spec", ")", ",", "eval_step", ")", "\n", "Logger", ".", "_sw", ".", "add_figure", "(", "f\"Predicted/forced\"", ",", "Logger", ".", "_plot_spectrogram", "(", "f_predicted_spec", ")", ",", "eval_step", ")", "\n", "Logger", ".", "_sw", ".", "add_figure", "(", "f\"Target/eval\"", ",", "Logger", ".", "_plot_spectrogram", "(", "target_spec", ")", ",", "eval_step", ")", "\n", "\n", "# log audio", "\n", "waveform", "=", "audio", ".", "inverse_spectrogram", "(", "predicted_spec", ",", "not", "hp", ".", "predict_linear", ")", "\n", "Logger", ".", "_sw", ".", "add_audio", "(", "f\"Audio/generated\"", ",", "waveform", ",", "eval_step", ",", "sample_rate", "=", "hp", ".", "sample_rate", ")", "\n", "waveform", "=", "audio", ".", "inverse_spectrogram", "(", "f_predicted_spec", ",", "not", "hp", ".", "predict_linear", ")", "\n", "Logger", ".", "_sw", ".", "add_audio", "(", "f\"Audio/forced\"", ",", "waveform", ",", "eval_step", ",", "sample_rate", "=", "hp", ".", "sample_rate", ")", "\n", "\n", "# log alignment", "\n", "alignment", "=", "alignment", "[", "idx", ",", ":", "target_len", "[", "idx", "]", ",", ":", "source_len", "[", "idx", "]", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "T", "\n", "Logger", ".", "_sw", ".", "add_figure", "(", "f\"Alignment/eval\"", ",", "Logger", ".", "_plot_alignment", "(", "alignment", ")", ",", "eval_step", ")", "\n", "\n", "# log source text", "\n", "utterance", "=", "text", ".", "to_text", "(", "source", "[", "idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "source_len", "[", "idx", "]", "]", ",", "hp", ".", "use_phonemes", ")", "\n", "Logger", ".", "_sw", ".", "add_text", "(", "f\"Text/eval\"", ",", "utterance", ",", "eval_step", ")", "\n", "\n", "# log stop tokens", "\n", "Logger", ".", "_sw", ".", "add_figure", "(", "f\"Stop/eval\"", ",", "Logger", ".", "_plot_stop_tokens", "(", "stop_target", "[", "idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "stop_prediction", "[", "idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "eval_step", ")", "\n", "\n", "# log mel cepstral distorsion", "\n", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Eval/mcd'", ",", "mcd", ",", "eval_step", ")", "\n", "\n", "# # log mel cepstral distorsion", "\n", "# Logger._sw.add_scalar(f'Eval/mcd_old_tasks', mcd_old_tasks, eval_step)", "\n", "\n", "# log reversal language classifier accuracy", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "Logger", ".", "_sw", ".", "add_scalar", "(", "f'Eval/classifier'", ",", "classifier", ",", "eval_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_spectrogram": [[143, 150], ["matplotlib.figure", "int", "librosa.display.specshow", "matplotlib.colorbar"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_plot_spectrogram", "(", "s", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "16", ",", "4", ")", ")", "\n", "hf", "=", "int", "(", "hp", ".", "sample_rate", "*", "hp", ".", "stft_shift_ms", "/", "1000", ")", "\n", "librosa", ".", "display", ".", "specshow", "(", "s", ",", "sr", "=", "hp", ".", "sample_rate", ",", "hop_length", "=", "hf", ",", "x_axis", "=", "'time'", ",", "y_axis", "=", "'mel'", ",", "cmap", "=", "'magma'", ")", "\n", "plt", ".", "colorbar", "(", "format", "=", "'%+2.0f dB'", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_alignment": [[151, 161], ["matplotlib.figure", "matplotlib.figure.add_subplot", "plt.figure.add_subplot.imshow", "matplotlib.figure.colorbar", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.tight_layout"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_plot_alignment", "(", "alignment", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "4", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "cax", "=", "ax", ".", "imshow", "(", "alignment", ",", "origin", "=", "'lower'", ",", "aspect", "=", "'auto'", ",", "interpolation", "=", "'nearest'", ")", "\n", "fig", ".", "colorbar", "(", "cax", ",", "ax", "=", "ax", ")", "\n", "plt", ".", "ylabel", "(", "'Input index'", ")", "\n", "plt", ".", "xlabel", "(", "'Decoder step'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_stop_tokens": [[162, 172], ["matplotlib.figure", "matplotlib.figure.add_subplot", "plt.figure.add_subplot.scatter", "plt.figure.add_subplot.scatter", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "range", "range", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_plot_stop_tokens", "(", "target", ",", "prediciton", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "4", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax", ".", "scatter", "(", "range", "(", "len", "(", "target", ")", ")", ",", "target", ",", "alpha", "=", "0.5", ",", "color", "=", "'blue'", ",", "marker", "=", "'+'", ",", "s", "=", "1", ",", "label", "=", "'target'", ")", "\n", "ax", ".", "scatter", "(", "range", "(", "len", "(", "prediciton", ")", ")", ",", "prediciton", ",", "alpha", "=", "0.5", ",", "color", "=", "'red'", ",", "marker", "=", "'.'", ",", "s", "=", "1", ",", "label", "=", "'predicted'", ")", "\n", "plt", ".", "xlabel", "(", "\"Frames (Blue target, Red predicted)\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Stop token probability\"", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger._plot_mfcc": [[173, 182], ["matplotlib.figure", "librosa.display.specshow", "matplotlib.colorbar", "matplotlib.title", "matplotlib.tight_layout", "matplotlib.show"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_plot_mfcc", "(", "mfcc", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "16", ",", "4", ")", ")", "\n", "librosa", ".", "display", ".", "specshow", "(", "mfcc", ",", "x_axis", "=", "'time'", ",", "cmap", "=", "'magma'", ")", "\n", "plt", ".", "colorbar", "(", ")", "\n", "plt", ".", "title", "(", "'MFCC'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "return", "fig", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._other_symbols": [[17, 19], ["list", "list"], "function", ["None"], ["def", "_other_symbols", "(", ")", ":", "\n", "    ", "return", "[", "_pad", ",", "_eos", ",", "_unk", "]", "+", "list", "(", "hp", ".", "punctuations_in", ")", "+", "list", "(", "hp", ".", "punctuations_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.build_phoneme_dicts": [[21, 34], ["utils.logging.Logger.progress", "enumerate", "remove_punctuation().split", "utils.logging.Logger.progress", "len", "text.remove_punctuation", "text._phonemize", "len"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.progress", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.progress", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_punctuation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._phonemize"], ["", "def", "build_phoneme_dicts", "(", "text_lang_pairs", ")", ":", "\n", "    ", "\"\"\"Create dictionaries (possibly more languages) of words (from a list of texts) with IPA equivalents.\"\"\"", "\n", "dictionaries", "=", "{", "}", "\n", "Logger", ".", "progress", "(", "0", "/", "len", "(", "text_lang_pairs", ")", ",", "prefix", "=", "'Building phoneme dictionary:'", ")", "\n", "for", "i", ",", "(", "t", ",", "l", ")", "in", "enumerate", "(", "text_lang_pairs", ")", ":", "\n", "        ", "if", "not", "(", "l", "in", "dictionaries", ")", ":", "\n", "            ", "dictionaries", "[", "l", "]", "=", "{", "}", "\n", "", "clear_words", "=", "remove_punctuation", "(", "t", ")", ".", "split", "(", ")", "\n", "for", "w", "in", "clear_words", ":", "\n", "            ", "if", "w", "in", "dictionaries", "[", "l", "]", ":", "continue", "\n", "dictionaries", "[", "l", "]", "[", "w", "]", "=", "_phonemize", "(", "w", ",", "l", ")", "[", ":", "-", "1", "]", "\n", "", "Logger", ".", "progress", "(", "(", "i", "+", "1", ")", "/", "len", "(", "text_lang_pairs", ")", ",", "prefix", "=", "'Building phoneme dictionary:'", ")", "\n", "", "return", "dictionaries", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_phoneme": [[36, 87], ["text.remove_punctuation", "remove_punctuation.split", "enumerate", "phonemes.append", "text._phonemize", "len", "text._phonemize"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_punctuation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._phonemize", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._phonemize"], ["", "def", "to_phoneme", "(", "text", ",", "ignore_punctuation", ",", "language", ",", "phoneme_dictionary", "=", "None", ")", ":", "\n", "    ", "\"\"\"Convert graphemes of the utterance without new line to phonemes.\n\n    Arguments:\n        text (string): The text to be translated into IPA.\n        ignore_punctuation (bool): Set to False if the punctuation should be preserved.\n        language (default hp.language): language code (e.g. en-us)\n    Keyword argumnets:\n        phoneme_dictionary (default None): A language specific dictionary of words with IPA equivalents,\n            used to speed up the translation which preserves punctuation (because the used phonemizer\n            cannot handle punctuation properly, so we need to do it word by word).\n    \"\"\"", "\n", "\n", "clear_text", "=", "remove_punctuation", "(", "text", ")", "\n", "if", "ignore_punctuation", ":", "\n", "        ", "return", "_phonemize", "(", "clear_text", ")", "[", ":", "-", "1", "]", "\n", "\n", "# phonemize words of the input text", "\n", "", "clear_words", "=", "clear_text", ".", "split", "(", ")", "\n", "if", "not", "phoneme_dictionary", ":", "phoneme_dictionary", "=", "{", "}", "\n", "phonemes", "=", "[", "]", "\n", "for", "w", "in", "clear_words", ":", "\n", "        ", "phonemes", ".", "append", "(", "phoneme_dictionary", "[", "w", "]", "if", "w", "in", "phoneme_dictionary", "else", "_phonemize", "(", "w", ",", "language", ")", "[", ":", "-", "1", "]", ")", "\n", "\n", "# add punctuation to match the punctuation in the input", "\n", "", "in_word", "=", "False", "\n", "punctuation_seen", "=", "False", "\n", "text_phonemes", "=", "\"\"", "\n", "clear_offset", "=", "word_idx", "=", "0", "\n", "\n", "for", "idx", ",", "char", "in", "enumerate", "(", "text", ")", ":", "\n", "# encountered non-punctuation char", "\n", "        ", "if", "idx", "-", "clear_offset", "<", "len", "(", "clear_text", ")", "and", "char", "==", "clear_text", "[", "idx", "-", "clear_offset", "]", ":", "\n", "            ", "if", "not", "in_word", ":", "\n", "                ", "if", "char", "in", "string", ".", "whitespace", ":", "\n", "                    ", "punctuation_seen", "=", "False", "\n", "continue", "\n", "", "in_word", "=", "True", "\n", "text_phonemes", "+=", "(", "' '", "if", "idx", "!=", "0", "and", "not", "punctuation_seen", "else", "''", ")", "+", "phonemes", "[", "word_idx", "]", "\n", "word_idx", "+=", "1", "\n", "", "else", ":", "\n", "                ", "if", "char", "in", "string", ".", "whitespace", ":", "in_word", "=", "False", "\n", "", "punctuation_seen", "=", "False", "\n", "# this should be punctuation", "\n", "", "else", ":", "\n", "            ", "clear_offset", "+=", "1", "\n", "if", "in_word", "and", "char", "in", "hp", ".", "punctuations_in", ":", "continue", "\n", "text_phonemes", "+=", "(", "' '", "if", "not", "in_word", "and", "not", "punctuation_seen", "else", "''", ")", "+", "char", "\n", "punctuation_seen", "=", "True", "\n", "\n", "", "", "return", "text_phonemes", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._phonemize": [[89, 102], ["epi.transliterate.replace", "phonemizer.separator.Separator", "phonemizer.phonemize.phonemize", "epitran.Epitran", "epitran.Epitran.transliterate"], "function", ["None"], ["", "def", "_phonemize", "(", "text", ",", "language", ")", ":", "\n", "\n", "    ", "language_tocode", "=", "{", "\"german\"", ":", "\"de\"", ",", "\"french\"", ":", "\"fr-fr\"", ",", "\"spanish\"", ":", "\"es\"", "}", "\n", "\n", "try", ":", "\n", "        ", "seperators", "=", "Separator", "(", "word", "=", "' '", ",", "phone", "=", "''", ")", "\n", "phonemes", "=", "phonemize", "(", "text", ",", "separator", "=", "seperators", ",", "backend", "=", "'espeak'", ",", "language", "=", "language_tocode", "[", "language", "]", ")", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "if", "language", "==", "\"chinese\"", ":", "\n", "            ", "epi", "=", "epitran", ".", "Epitran", "(", "language_tocode", "[", "language", "]", ",", "cedict_file", "=", "\"/home/grads/y/yangmu/cedict_ts.u8\"", ")", "\n", "phonemes", "=", "epi", ".", "transliterate", "(", "text", ",", "normpunc", "=", "True", ")", "\n", "", "", "phonemes", ".", "replace", "(", "'\\n'", ",", "' '", ",", "1", ")", "\n", "return", "phonemes", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_lower": [[104, 107], ["text.lower"], "function", ["None"], ["", "def", "to_lower", "(", "text", ")", ":", "\n", "    ", "\"\"\"Convert uppercase text into lowercase.\"\"\"", "\n", "return", "text", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_odd_whitespaces": [[109, 112], ["text.split"], "function", ["None"], ["", "def", "remove_odd_whitespaces", "(", "text", ")", ":", "\n", "    ", "\"\"\"Remove multiple and trailing/leading whitespaces.\"\"\"", "\n", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_punctuation": [[114, 118], ["re.sub", "punct_re.replace"], "function", ["None"], ["", "def", "remove_punctuation", "(", "text", ")", ":", "\n", "    ", "\"\"\"Remove punctuation from text.\"\"\"", "\n", "punct_re", "=", "'['", "+", "hp", ".", "punctuations_out", "+", "hp", ".", "punctuations_in", "+", "']'", "\n", "return", "re", ".", "sub", "(", "punct_re", ".", "replace", "(", "'-'", ",", "'\\-'", ")", ",", "''", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_sequence": [[120, 126], ["sequence.append", "enumerate", "text._other_symbols", "list"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._other_symbols"], ["", "def", "to_sequence", "(", "text", ",", "use_phonemes", "=", "False", ")", ":", "\n", "    ", "\"\"\"Converts a string of text to a sequence of IDs corresponding to the symbols in the text.\"\"\"", "\n", "transform_dict", "=", "{", "s", ":", "i", "for", "i", ",", "s", "in", "enumerate", "(", "_other_symbols", "(", ")", "+", "list", "(", "hp", ".", "phonemes", "if", "use_phonemes", "else", "hp", ".", "characters", ")", ")", "}", "\n", "sequence", "=", "[", "transform_dict", "[", "_unk", "]", "if", "c", "not", "in", "transform_dict", "else", "transform_dict", "[", "c", "]", "for", "c", "in", "text", "]", "\n", "sequence", ".", "append", "(", "transform_dict", "[", "_eos", "]", ")", "\n", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_text": [[128, 138], ["enumerate", "text._other_symbols", "list"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text._other_symbols"], ["", "def", "to_text", "(", "sequence", ",", "use_phonemes", "=", "False", ")", ":", "\n", "    ", "\"\"\"Converts a sequence of IDs back to a string\"\"\"", "\n", "transform_dict", "=", "{", "i", ":", "s", "for", "i", ",", "s", "in", "enumerate", "(", "_other_symbols", "(", ")", "+", "list", "(", "hp", ".", "phonemes", "if", "use_phonemes", "else", "hp", ".", "characters", ")", ")", "}", "\n", "result", "=", "''", "\n", "for", "symbol_id", "in", "sequence", ":", "\n", "        ", "if", "symbol_id", "in", "transform_dict", ":", "\n", "            ", "s", "=", "transform_dict", "[", "symbol_id", "]", "\n", "if", "s", "==", "_eos", ":", "break", "\n", "result", "+=", "s", "\n", "", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.load": [[12, 18], ["soundfile.read"], "function", ["None"], ["def", "load", "(", "path", ")", ":", "\n", "    ", "\"\"\"Load a sound file into numpy array.\"\"\"", "\n", "data", ",", "sample_rate", "=", "sf", ".", "read", "(", "path", ")", "\n", "assert", "hp", ".", "sample_rate", "==", "sample_rate", ",", "(", "\n", "f'Sample rate do not match: given {hp.sample_rate}, expected {sample_rate}'", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.save": [[20, 23], ["soundfile.write"], "function", ["None"], ["", "def", "save", "(", "data", ",", "path", ")", ":", "\n", "    ", "\"\"\"Save numpy array as sound file.\"\"\"", "\n", "sf", ".", "write", "(", "path", ",", "data", ",", "samplerate", "=", "hp", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames": [[25, 28], ["int", "params.params.Params", "params.params.Params", "params.params.Params", "params.params.Params"], "function", ["None"], ["", "def", "ms_to_frames", "(", "ms", ")", ":", "\n", "    ", "\"\"\"Convert milliseconds into number of frames.\"\"\"", "\n", "return", "int", "(", "hp", ".", "sample_rate", "*", "ms", "/", "1000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.trim_silence": [[30, 37], ["audio.ms_to_frames", "audio.ms_to_frames", "audio.ms_to_frames", "librosa.effects.trim", "librosa.effects.trim", "librosa.effects.trim"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames"], ["", "def", "trim_silence", "(", "data", ",", "window_ms", ",", "hop_ms", ",", "top_db", "=", "50", ",", "margin_ms", "=", "0", ")", ":", "\n", "    ", "\"\"\"Trim leading and trailing silence from an audio signal.\"\"\"", "\n", "wf", "=", "ms_to_frames", "(", "window_ms", ")", "\n", "hf", "=", "ms_to_frames", "(", "hop_ms", ")", "\n", "mf", "=", "ms_to_frames", "(", "margin_ms", ")", "\n", "if", "mf", "!=", "0", ":", "data", "=", "data", "[", "mf", ":", "-", "mf", "]", "\n", "return", "librosa", ".", "effects", ".", "trim", "(", "data", ",", "top_db", "=", "top_db", ",", "frame_length", "=", "wf", ",", "hop_length", "=", "hf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.duration": [[39, 42], ["librosa.get_duration", "librosa.get_duration", "librosa.get_duration"], "function", ["None"], ["", "def", "duration", "(", "data", ")", ":", "\n", "    ", "\"\"\"Return duration of an audio signal in seconds.\"\"\"", "\n", "return", "librosa", ".", "get_duration", "(", "data", ",", "sr", "=", "hp", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.amplitude_to_db": [[44, 47], ["librosa.amplitude_to_db", "librosa.amplitude_to_db", "librosa.amplitude_to_db"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.amplitude_to_db", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.amplitude_to_db", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.amplitude_to_db"], ["", "def", "amplitude_to_db", "(", "x", ")", ":", "\n", "    ", "\"\"\"Convert amplitude to decibels.\"\"\"", "\n", "return", "librosa", ".", "amplitude_to_db", "(", "x", ",", "ref", "=", "np", ".", "max", ",", "top_db", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.db_to_amplitude": [[49, 52], ["librosa.db_to_amplitude", "librosa.db_to_amplitude", "librosa.db_to_amplitude"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.db_to_amplitude", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.db_to_amplitude", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.db_to_amplitude"], ["", "def", "db_to_amplitude", "(", "x", ")", ":", "\n", "    ", "\"\"\"Convert decibels to amplitude.\"\"\"", "\n", "return", "librosa", ".", "db_to_amplitude", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.preemphasis": [[54, 58], ["scipy.signal.lfilter"], "function", ["None"], ["", "def", "preemphasis", "(", "y", ")", ":", "\n", "    ", "\"\"\"Preemphasize the signal.\"\"\"", "\n", "# y[n] = x[n] - perc * x[n-1]", "\n", "return", "scipy", ".", "signal", ".", "lfilter", "(", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "[", "1", "]", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.deemphasis": [[60, 64], ["scipy.signal.lfilter"], "function", ["None"], ["", "def", "deemphasis", "(", "y", ")", ":", "\n", "    ", "\"\"\"Deemphasize the signal.\"\"\"", "\n", "# y[n] + perc * y[n-1] = x[n] ", "\n", "return", "scipy", ".", "signal", ".", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.spectrogram": [[66, 74], ["audio.ms_to_frames", "audio.ms_to_frames", "numpy.abs", "audio.amplitude_to_db", "audio.preemphasis", "librosa.stft", "librosa.stft", "librosa.stft", "librosa.feature.melspectrogram", "librosa.feature.melspectrogram", "librosa.feature.melspectrogram"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.amplitude_to_db", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.preemphasis"], ["", "def", "spectrogram", "(", "y", ",", "mel", "=", "False", ")", ":", "\n", "    ", "\"\"\"Convert waveform to log-magnitude spectrogram.\"\"\"", "\n", "if", "hp", ".", "use_preemphasis", ":", "y", "=", "preemphasis", "(", "y", ")", "\n", "wf", "=", "ms_to_frames", "(", "hp", ".", "stft_window_ms", ")", "\n", "hf", "=", "ms_to_frames", "(", "hp", ".", "stft_shift_ms", ")", "\n", "S", "=", "np", ".", "abs", "(", "librosa", ".", "stft", "(", "y", ",", "n_fft", "=", "hp", ".", "num_fft", ",", "hop_length", "=", "hf", ",", "win_length", "=", "wf", ")", ")", "\n", "if", "mel", ":", "S", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "S", "=", "S", ",", "sr", "=", "hp", ".", "sample_rate", ",", "n_mels", "=", "hp", ".", "num_mels", ")", "\n", "return", "amplitude_to_db", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_spectrogram": [[76, 79], ["audio.spectrogram"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.spectrogram"], ["", "def", "mel_spectrogram", "(", "y", ")", ":", "\n", "    ", "\"\"\"Convert waveform to log-mel-spectrogram.\"\"\"", "\n", "return", "spectrogram", "(", "y", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.linear_to_mel": [[81, 86], ["audio.db_to_amplitude", "librosa.feature.melspectrogram", "librosa.feature.melspectrogram", "librosa.feature.melspectrogram", "audio.amplitude_to_db"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.db_to_amplitude", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.amplitude_to_db"], ["", "def", "linear_to_mel", "(", "S", ")", ":", "\n", "    ", "\"\"\"Convert linear to mel spectrogram (this does not return the same spec. as mel_spec. method due to the db->amplitude conversion).\"\"\"", "\n", "S", "=", "db_to_amplitude", "(", "S", ")", "\n", "S", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "S", "=", "S", ",", "sr", "=", "hp", ".", "sample_rate", ",", "n_mels", "=", "hp", ".", "num_mels", ")", "\n", "return", "amplitude_to_db", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.inverse_spectrogram": [[88, 98], ["audio.db_to_amplitude", "audio.ms_to_frames", "audio.ms_to_frames", "librosa.griffinlim", "librosa.griffinlim", "librosa.griffinlim", "max", "librosa.feature.inverse.mel_to_stft", "librosa.feature.inverse.mel_to_stft", "librosa.feature.inverse.mel_to_stft", "audio.deemphasis"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.db_to_amplitude", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.ms_to_frames", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.deemphasis"], ["", "def", "inverse_spectrogram", "(", "s", ",", "mel", "=", "False", ")", ":", "\n", "    ", "\"\"\"Convert log-magnitude spectrogram to waveform.\"\"\"", "\n", "S", "=", "db_to_amplitude", "(", "s", ")", "\n", "wf", "=", "ms_to_frames", "(", "hp", ".", "stft_window_ms", ")", "\n", "hf", "=", "ms_to_frames", "(", "hp", ".", "stft_shift_ms", ")", "\n", "if", "mel", ":", "S", "=", "librosa", ".", "feature", ".", "inverse", ".", "mel_to_stft", "(", "S", ",", "power", "=", "1", ",", "sr", "=", "hp", ".", "sample_rate", ",", "n_fft", "=", "hp", ".", "num_fft", ")", "\n", "y", "=", "librosa", ".", "griffinlim", "(", "S", "**", "hp", ".", "griffin_lim_power", ",", "n_iter", "=", "hp", ".", "griffin_lim_iters", ",", "hop_length", "=", "hf", ",", "win_length", "=", "wf", ")", "\n", "if", "hp", ".", "use_preemphasis", ":", "y", "=", "deemphasis", "(", "y", ")", "\n", "y", "/=", "max", "(", "y", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.inverse_mel_spectrogram": [[100, 103], ["audio.inverse_spectrogram"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.inverse_spectrogram"], ["", "def", "inverse_mel_spectrogram", "(", "s", ")", ":", "\n", "    ", "\"\"\"Convert log-mel-spectrogram to waveform.\"\"\"", "\n", "return", "inverse_spectrogram", "(", "s", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.normalize_spectrogram": [[105, 109], ["None"], "function", ["None"], ["", "def", "normalize_spectrogram", "(", "S", ",", "is_mel", ")", ":", "\n", "    ", "\"\"\"Normalize log-magnitude spectrogram.\"\"\"", "\n", "if", "is_mel", ":", "return", "(", "S", "-", "hp", ".", "mel_normalize_mean", ")", "/", "hp", ".", "mel_normalize_variance", "\n", "else", ":", "return", "(", "S", "-", "hp", ".", "lin_normalize_mean", ")", "/", "hp", ".", "lin_normalize_variance", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.denormalize_spectrogram": [[111, 115], ["None"], "function", ["None"], ["", "def", "denormalize_spectrogram", "(", "S", ",", "is_mel", ")", ":", "\n", "    ", "\"\"\"Denormalize log-magnitude spectrogram.\"\"\"", "\n", "if", "is_mel", ":", "return", "S", "*", "hp", ".", "mel_normalize_variance", "+", "hp", ".", "mel_normalize_mean", "\n", "else", ":", "return", "S", "*", "hp", ".", "lin_normalize_variance", "+", "hp", ".", "lin_normalize_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.get_spectrogram_mfcc": [[117, 120], ["librosa.feature.mfcc", "librosa.feature.mfcc", "librosa.feature.mfcc"], "function", ["None"], ["", "def", "get_spectrogram_mfcc", "(", "S", ")", ":", "\n", "    ", "\"\"\"Compute MFCCs of a mel spectrogram.\"\"\"", "\n", "return", "librosa", ".", "feature", ".", "mfcc", "(", "n_mfcc", "=", "hp", ".", "num_mfcc", ",", "S", "=", "(", "S", "/", "10", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.get_mfcc": [[122, 125], ["audio.get_mfcc", "audio.mel_spectrogram"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.get_mfcc", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_spectrogram"], ["", "def", "get_mfcc", "(", "y", ")", ":", "\n", "    ", "\"\"\"Compute MFCCs of a waveform.\"\"\"", "\n", "return", "get_mfcc", "(", "audio", ".", "mel_spectrogram", "(", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.mel_cepstral_distorision": [[127, 162], ["audio.mel_cepstral_distorision.mcd"], "function", ["None"], ["", "def", "mel_cepstral_distorision", "(", "S1", ",", "S2", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Compute Mel Cepstral Distorsion between two mel spectrograms.\n\n    Arguments:\n        S1 and S2 -- mel spectrograms\n        mode -- 'cut' to cut off frames of longer seq.\n                'stretch' to stretch linearly the shorter seq.\n                'dtw' to compute DTW with minimal possible MCD\n    \"\"\"", "\n", "\n", "def", "mcd", "(", "s1", ",", "s2", ")", ":", "\n", "        ", "diff", "=", "s1", "-", "s2", "\n", "return", "np", ".", "average", "(", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "diff", "*", "diff", ",", "axis", "=", "0", ")", ")", ")", "\n", "\n", "", "x", ",", "y", "=", "get_spectrogram_mfcc", "(", "S1", ")", "[", "1", ":", "]", ",", "get_spectrogram_mfcc", "(", "S2", ")", "[", "1", ":", "]", "\n", "\n", "if", "mode", "==", "'cut'", ":", "\n", "        ", "if", "y", ".", "shape", "[", "1", "]", ">", "x", ".", "shape", "[", "1", "]", ":", "y", "=", "y", "[", ":", ",", ":", "x", ".", "shape", "[", "1", "]", "]", "\n", "if", "x", ".", "shape", "[", "1", "]", ">", "y", ".", "shape", "[", "1", "]", ":", "x", "=", "x", "[", ":", ",", ":", "y", ".", "shape", "[", "1", "]", "]", "\n", "\n", "", "elif", "mode", "==", "'stretch'", ":", "\n", "        ", "if", "x", ".", "shape", "[", "1", "]", ">", "y", ".", "shape", "[", "1", "]", ":", "\n", "            ", "m", "=", "x", ".", "shape", "[", "1", "]", "\n", "y", "=", "np", ".", "array", "(", "[", "y", "[", ":", ",", "i", "*", "y", ".", "shape", "[", "1", "]", "//", "m", "]", "for", "i", "in", "range", "(", "m", ")", "]", ")", ".", "T", "\n", "", "else", ":", "\n", "            ", "m", "=", "y", ".", "shape", "[", "1", "]", "\n", "x", "=", "np", ".", "array", "(", "[", "x", "[", ":", ",", "i", "*", "x", ".", "shape", "[", "1", "]", "//", "m", "]", "for", "i", "in", "range", "(", "m", ")", "]", ")", ".", "T", "\n", "\n", "", "", "elif", "mode", "==", "'dtw'", ":", "\n", "        ", "x", ",", "y", "=", "x", ".", "T", ",", "y", ".", "T", "\n", "_", ",", "path", "=", "fastdtw", "(", "x", ",", "y", ",", "dist", "=", "mcd", ")", "\n", "pathx", ",", "pathy", "=", "map", "(", "list", ",", "zip", "(", "*", "path", ")", ")", "\n", "x", ",", "y", "=", "x", "[", "pathx", "]", ".", "T", ",", "y", "[", "pathy", "]", ".", "T", "\n", "\n", "", "return", "mcd", "(", "x", ",", "y", ")", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask": [[7, 11], ["torch.max", "torch.arange"], "function", ["None"], ["def", "lengths_to_mask", "(", "lengths", ",", "max_length", "=", "None", ")", ":", "\n", "    ", "\"\"\"Convert tensor of lengths into a boolean mask.\"\"\"", "\n", "ml", "=", "torch", ".", "max", "(", "lengths", ")", "if", "max_length", "is", "None", "else", "max_length", "\n", "return", "torch", ".", "arange", "(", "ml", ",", "device", "=", "lengths", ".", "device", ")", "[", "None", ",", ":", "]", "<", "lengths", "[", ":", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.to_gpu": [[13, 18], ["x.contiguous.contiguous", "torch.cuda.is_available", "x.contiguous.cuda"], "function", ["None"], ["", "def", "to_gpu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compact and move CPU tensor to GPU.\"\"\"", "\n", "if", "x", "is", "None", ":", "return", "x", "\n", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "return", "x", ".", "cuda", "(", "non_blocking", "=", "True", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.remove_dataparallel_prefix": [[20, 27], ["collections.OrderedDict", "state_dict.items"], "function", ["None"], ["", "def", "remove_dataparallel_prefix", "(", "state_dict", ")", ":", "\n", "    ", "\"\"\"Removes dataparallel prefix of layer names in a checkpoint state dictionary.\"\"\"", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "name", "=", "k", "[", "7", ":", "]", "if", "k", "[", ":", "7", "]", "==", "\"module.\"", "else", "k", "\n", "new_state_dict", "[", "name", "]", "=", "v", "\n", "", "return", "new_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.build_model": [[29, 38], ["torch.device", "torch.load", "params.params.Params.load_state_dict", "modules.tacotron2.Tacotron", "modules.tacotron2.Tacotron.load_state_dict", "modules.tacotron2.Tacotron.to", "__init__.remove_dataparallel_prefix", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load_state_dict", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load_state_dict", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.remove_dataparallel_prefix"], ["", "def", "build_model", "(", "checkpoint", ",", "force_cpu", "=", "False", ")", ":", "\n", "    ", "\"\"\"Load and build model a from checkpoint.\"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "force_cpu", "else", "\"cpu\"", ")", "\n", "state", "=", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "device", ")", "\n", "hp", ".", "load_state_dict", "(", "state", "[", "'parameters'", "]", ")", "\n", "model", "=", "Tacotron", "(", ")", "\n", "model", ".", "load_state_dict", "(", "remove_dataparallel_prefix", "(", "state", "[", "'model'", "]", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "return", "model", ",", "hp", "\n", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.get_loader_by_name": [[6, 10], ["getattr", "name.lower"], "function", ["None"], ["def", "get_loader_by_name", "(", "name", ")", ":", "\n", "    ", "\"\"\"Return the respective loading function.\"\"\"", "\n", "thismodule", "=", "sys", ".", "modules", "[", "__name__", "]", "\n", "return", "getattr", "(", "thismodule", ",", "name", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.vctk": [[12, 30], ["glob.glob.sort", "glob.glob", "os.path.basename().split", "file_name.split", "file_name.split", "open", "ttf.read", "os.path.join", "os.path.join", "os.path.isfile", "items.append", "os.path.basename"], "function", ["None"], ["", "def", "vctk", "(", "root_path", ",", "meta_files", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load VCTK sound and meta files.\"\"\"", "\n", "if", "meta_files", "is", "None", ":", "meta_files", "=", "glob", "(", "f\"{root_path}/txt/**/*.txt\"", ",", "recursive", "=", "True", ")", "\n", "meta_files", ".", "sort", "(", ")", "\n", "items", "=", "[", "]", "\n", "language", "=", "\"\"", "\n", "for", "meta_file", "in", "meta_files", ":", "\n", "        ", "file_name", "=", "os", ".", "path", ".", "basename", "(", "meta_file", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "speaker_name", "=", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "utterance_id", "=", "file_name", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "with", "open", "(", "meta_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ttf", ":", "\n", "            ", "text", "=", "ttf", ".", "read", "(", ")", "\n", "audio", "=", "os", ".", "path", ".", "join", "(", "\"wav48\"", ",", "speaker_name", ",", "file_name", "+", "\".wav\"", ")", "\n", "full_audio", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "audio", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_audio", ")", ",", "(", "\n", "f'Referenced audio file {full_audio} does not exist!'", ")", "\n", "items", ".", "append", "(", "[", "text", "[", ":", "-", "1", "]", ",", "audio", ",", "speaker_name", ",", "language", "]", ")", "\n", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.mailabs": [[32, 52], ["glob.glob.sort", "glob.glob", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "open", "os.path.basename", "os.path.basename", "line[].split", "os.path.join", "os.path.join", "os.path.isfile", "items.append", "len"], "function", ["None"], ["", "def", "mailabs", "(", "root_path", ",", "meta_files", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load M-AILABS sound and meta files.\"\"\"", "\n", "if", "meta_files", "is", "None", ":", "meta_files", "=", "glob", "(", "f\"{root_path}/*/*/*/*/metadata.csv\"", ",", "recursive", "=", "True", ")", "\n", "meta_files", ".", "sort", "(", ")", "\n", "items", "=", "[", "]", "\n", "for", "meta_file", "in", "meta_files", ":", "\n", "        ", "book_dir", "=", "os", ".", "path", ".", "dirname", "(", "meta_file", ")", "\n", "speaker_dir", "=", "os", ".", "path", ".", "dirname", "(", "book_dir", ")", "\n", "language_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "speaker_dir", ")", ")", "\n", "with", "open", "(", "meta_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ttf", ":", "\n", "            ", "speaker_name", "=", "os", ".", "path", ".", "basename", "(", "speaker_dir", ")", "\n", "language", "=", "os", ".", "path", ".", "basename", "(", "language_dir", ")", "\n", "for", "line", "in", "ttf", ":", "\n", "                ", "cols", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'|'", ")", "\n", "audio", "=", "os", ".", "path", ".", "join", "(", "book_dir", "[", "len", "(", "root_path", ")", "+", "1", ":", "]", ",", "\"wavs\"", ",", "cols", "[", "0", "]", "+", "\".wav\"", ")", "\n", "full_audio", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "audio", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_audio", ")", ",", "(", "\n", "f'Referenced audio file {full_audio} does not exist!'", ")", "\n", "items", ".", "append", "(", "[", "cols", "[", "2", "]", ",", "audio", ",", "speaker_name", ",", "language", "]", ")", "\n", "", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.css10": [[54, 73], ["meta_files.sort", "os.path.dirname", "open", "os.path.basename", "line.rstrip().split", "os.path.join", "os.path.join", "os.path.isfile", "items.append", "line.rstrip"], "function", ["None"], ["", "def", "css10", "(", "root_path", ",", "meta_files", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load CSS10 sound and meta files.\"\"\"", "\n", "# if meta_files is None: meta_files = glob(f\"{root_path}/*/transcript.txt\", recursive=True)", "\n", "meta_files", "=", "[", "f'{root_path}/spanish/transcript.txt'", ",", "f'{root_path}/german/transcript.txt'", ",", "f'{root_path}/french/transcript.txt'", "]", "\n", "meta_files", ".", "sort", "(", ")", "\n", "items", "=", "[", "]", "\n", "for", "meta_file", "in", "meta_files", ":", "\n", "        ", "language_dir", "=", "os", ".", "path", ".", "dirname", "(", "meta_file", ")", "\n", "with", "open", "(", "meta_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ttf", ":", "\n", "            ", "language", "=", "os", ".", "path", ".", "basename", "(", "language_dir", ")", "\n", "speaker_name", "=", "language", "\n", "for", "line", "in", "ttf", ":", "\n", "                ", "cols", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "audio", "=", "os", ".", "path", ".", "join", "(", "language", ",", "cols", "[", "0", "]", ")", "\n", "full_audio", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "audio", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_audio", ")", ",", "(", "\n", "f'Referenced audio file {full_audio} does not exist!'", ")", "\n", "items", ".", "append", "(", "[", "cols", "[", "2", "]", ",", "audio", ",", "speaker_name", ",", "language", "]", ")", "\n", "", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.my_blizzard": [[75, 98], ["glob.glob.sort", "enumerate", "glob.glob", "os.path.dirname", "os.path.splitext", "open", "os.path.basename", "line[].split", "folder.replace", "os.path.join", "os.path.join", "os.path.isfile", "items.append"], "function", ["None"], ["", "def", "my_blizzard", "(", "root_path", ",", "meta_files", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load My Blizzard 2013 audio and meta files.\"\"\"", "\n", "if", "meta_files", "is", "None", ":", "transcript_files", "=", "glob", "(", "f\"{root_path}/transcripts/**/*.txt\"", ",", "recursive", "=", "False", ")", "\n", "else", ":", "transcript_files", "=", "meta_files", "\n", "transcript_files", ".", "sort", "(", ")", "\n", "folders", "=", "[", "os", ".", "path", ".", "dirname", "(", "f", ")", "for", "f", "in", "transcript_files", "]", "\n", "items", "=", "[", "]", "\n", "speaker_name", "=", "\"\"", "\n", "language", "=", "\"\"", "\n", "for", "idx", ",", "transcript", "in", "enumerate", "(", "transcript_files", ")", ":", "\n", "        ", "folder", "=", "folders", "[", "idx", "]", "\n", "filename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "transcript", ")", ")", "[", "0", "]", "\n", "with", "open", "(", "transcript", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ttf", ":", "\n", "            ", "for", "line", "in", "ttf", ":", "\n", "                ", "cols", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'|'", ")", "\n", "segments_folder", "=", "folder", ".", "replace", "(", "f\"{root_path}/transcripts\"", ",", "\"segments\"", ")", "\n", "audio", "=", "os", ".", "path", ".", "join", "(", "segments_folder", ",", "filename", "+", "'-'", "+", "cols", "[", "0", "]", "+", "'.wav'", ")", "\n", "full_audio", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "audio", ")", "\n", "text", "=", "cols", "[", "1", "]", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_audio", ")", ",", "(", "\n", "f'Referenced audio file {full_audio} does not exist!'", ")", "\n", "items", ".", "append", "(", "[", "text", ",", "audio", ",", "speaker_name", ",", "language", "]", ")", "\n", "", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.ljspeech": [[100, 117], ["os.path.isfile", "os.path.join", "open", "line[].split", "os.path.join", "os.path.join", "os.path.isfile", "items.append"], "function", ["None"], ["", "def", "ljspeech", "(", "root_path", ",", "meta_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load the LJ Speech audios and meta files\"\"\"", "\n", "if", "meta_file", "is", "None", ":", "txt_file", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"metadata.csv\"", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "txt_file", ")", ",", "(", "f'Dataset meta-file not found: given given {txt_file}'", ")", "\n", "items", "=", "[", "]", "\n", "speaker_name", "=", "\"\"", "\n", "language", "=", "\"\"", "\n", "with", "open", "(", "txt_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ttf", ":", "\n", "        ", "for", "line", "in", "ttf", ":", "\n", "            ", "cols", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'|'", ")", "\n", "audio", "=", "os", ".", "path", ".", "join", "(", "'wavs'", ",", "cols", "[", "0", "]", "+", "'.wav'", ")", "\n", "full_audio", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "audio", ")", "\n", "text", "=", "cols", "[", "2", "]", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_audio", ")", ",", "(", "\n", "f'Referenced audio file {full_audio} does not exist!'", ")", "\n", "items", ".", "append", "(", "[", "text", ",", "audio", ",", "speaker_name", ",", "language", "]", ")", "\n", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.my_common_voice": [[119, 137], ["glob.glob.sort", "glob.glob", "os.path.dirname", "open", "os.path.basename", "line.rstrip().split", "os.path.join", "os.path.join", "os.path.isfile", "items.append", "line.rstrip"], "function", ["None"], ["", "def", "my_common_voice", "(", "root_path", ",", "meta_files", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load My Common Voice sound and meta files.\"\"\"", "\n", "if", "meta_files", "is", "None", ":", "meta_files", "=", "glob", "(", "f\"{root_path}/*/meta.csv\"", ",", "recursive", "=", "True", ")", "\n", "meta_files", ".", "sort", "(", ")", "\n", "items", "=", "[", "]", "\n", "for", "meta_file", "in", "meta_files", ":", "\n", "        ", "language_dir", "=", "os", ".", "path", ".", "dirname", "(", "meta_file", ")", "\n", "with", "open", "(", "meta_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "ttf", ":", "\n", "            ", "language", "=", "os", ".", "path", ".", "basename", "(", "language_dir", ")", "\n", "for", "line", "in", "ttf", ":", "\n", "                ", "cols", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "speaker_name", "=", "cols", "[", "0", "]", "\n", "audio", "=", "os", ".", "path", ".", "join", "(", "language", ",", "\"wavs\"", ",", "cols", "[", "0", "]", ",", "cols", "[", "1", "]", ")", "\n", "full_audio", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "audio", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "full_audio", ")", ",", "(", "\n", "f'Referenced audio file {full_audio} does not exist!'", ")", "\n", "items", ".", "append", "(", "[", "cols", "[", "2", "]", ",", "audio", ",", "speaker_name", ",", "language", "]", ")", "\n", "", "", "", "return", "items", "\n", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDatasetCollection.__init__": [[30, 56], ["os.path.join", "dataset.TextToSpeechDataset", "os.path.join", "dataset.TextToSpeechDataset", "os.path.exists", "IOError", "os.path.join", "dataset.TextToSpeechDataset", "os.path.exists", "IOError", "os.path.exists", "IOError", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset_root_dir", ",", "training_file", "=", "\"train.txt\"", ",", "validation_file", "=", "\"val.txt\"", ",", "test_file", "=", "None", ")", ":", "\n", "\n", "        ", "if", "training_file", ":", "\n", "# create training set", "\n", "            ", "train_full_path", "=", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "training_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_full_path", ")", ":", "\n", "                ", "raise", "IOError", "(", "f'The training set meta-file not found, given: {train_full_path}'", ")", "\n", "", "self", ".", "train", "=", "TextToSpeechDataset", "(", "train_full_path", ",", "dataset_root_dir", ")", "\n", "\n", "# create validation set", "\n", "", "val_full_path", "=", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "validation_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "val_full_path", ")", ":", "\n", "            ", "raise", "IOError", "(", "f'The validation set meta-file not found, given: {val_full_path}'", ")", "\n", "# self.dev = TextToSpeechDataset(val_full_path, dataset_root_dir, self.train.unique_speakers)", "\n", "", "self", ".", "dev", "=", "TextToSpeechDataset", "(", "val_full_path", ",", "dataset_root_dir", ")", "\n", "# assert len(self.dev.unique_speakers) == len(self.train.unique_speakers), (", "\n", "#         f'Validation set contains speakers which are not present in train set!')", "\n", "\n", "# create test set", "\n", "if", "test_file", ":", "\n", "            ", "test_full_path", "=", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "test_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "test_full_path", ")", ":", "\n", "                ", "raise", "IOError", "(", "f'The test set meta-file not found, given: {test_full_path}'", ")", "\n", "", "self", ".", "test", "=", "TextToSpeechDataset", "(", "test_full_path", ",", "dataset_root_dir", ",", "self", ".", "train", ".", "unique_speakers", ")", "\n", "assert", "len", "(", "self", ".", "test", ".", "unique_speakers", ")", "==", "len", "(", "self", ".", "train", ".", "unique_speakers", ")", ",", "(", "\n", "f'Test set contains speakers which are not present in test set!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.__init__": [[79, 131], ["random.seed", "known_unique_speakers.copy", "set", "range", "range", "open", "random.sample", "len", "len", "utils.text.to_sequence", "utils.text.to_sequence", "dataset.TextToSpeechDataset.unique_speakers.index", "params.params.Params.languages.index", "line[].split", "utils.text.remove_punctuation", "utils.text.remove_punctuation", "utils.text.to_lower", "utils.text.remove_odd_whitespaces", "utils.text.remove_odd_whitespaces", "dataset.TextToSpeechDataset.items.append", "set.add", "dataset.TextToSpeechDataset.unique_speakers.append"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_sequence", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_sequence", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_punctuation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_punctuation", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_lower", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_odd_whitespaces", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.remove_odd_whitespaces"], ["def", "__init__", "(", "self", ",", "meta_file", ",", "dataset_root_dir", ",", "known_unique_speakers", "=", "[", "]", ",", "sample_size", "=", "None", ")", ":", "\n", "        ", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "root_dir", "=", "dataset_root_dir", "\n", "\n", "# read meta-file: id|speaker|language|audio_file_path|mel_spectrogram_path|linear_spectrogram_path|text|phonemized_text", "\n", "\n", "self", ".", "unique_speakers", "=", "known_unique_speakers", ".", "copy", "(", ")", "\n", "unique_speakers_set", "=", "set", "(", "self", ".", "unique_speakers", ")", "\n", "self", ".", "items", "=", "[", "]", "\n", "with", "open", "(", "meta_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line_tokens", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'|'", ")", "\n", "item", "=", "{", "\n", "'id'", ":", "line_tokens", "[", "0", "]", ",", "\n", "'speaker'", ":", "line_tokens", "[", "1", "]", ",", "\n", "'language'", ":", "line_tokens", "[", "2", "]", ",", "\n", "'audio'", ":", "line_tokens", "[", "3", "]", ",", "\n", "'spectrogram'", ":", "line_tokens", "[", "4", "]", ",", "\n", "'linear_spectrogram'", ":", "line_tokens", "[", "5", "]", ",", "\n", "'text'", ":", "line_tokens", "[", "6", "]", ",", "\n", "'phonemes'", ":", "line_tokens", "[", "7", "]", "\n", "}", "\n", "if", "item", "[", "'language'", "]", "in", "hp", ".", "languages", ":", "\n", "                    ", "if", "line_tokens", "[", "1", "]", "not", "in", "unique_speakers_set", ":", "\n", "                        ", "unique_speakers_set", ".", "add", "(", "line_tokens", "[", "1", "]", ")", "\n", "self", ".", "unique_speakers", ".", "append", "(", "line_tokens", "[", "1", "]", ")", "\n", "", "self", ".", "items", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "if", "sample_size", ":", "\n", "            ", "self", ".", "items", "=", "random", ".", "sample", "(", "self", ".", "items", ",", "sample_size", ")", "\n", "\n", "# clean text with basic stuff -- multiple spaces, case sensitivity and punctuation", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "items", ")", ")", ":", "\n", "            ", "item_text", "=", "self", ".", "items", "[", "idx", "]", "[", "'text'", "]", "\n", "item_phon", "=", "self", ".", "items", "[", "idx", "]", "[", "'phonemes'", "]", "\n", "if", "not", "hp", ".", "use_punctuation", ":", "\n", "                ", "item_text", "=", "text", ".", "remove_punctuation", "(", "item_text", ")", "\n", "item_phon", "=", "text", ".", "remove_punctuation", "(", "item_phon", ")", "\n", "", "if", "not", "hp", ".", "case_sensitive", ":", "\n", "                ", "item_text", "=", "text", ".", "to_lower", "(", "item_text", ")", "\n", "", "if", "hp", ".", "remove_multiple_wspaces", ":", "\n", "                ", "item_text", "=", "text", ".", "remove_odd_whitespaces", "(", "item_text", ")", "\n", "item_phon", "=", "text", ".", "remove_odd_whitespaces", "(", "item_phon", ")", "\n", "", "self", ".", "items", "[", "idx", "]", "[", "'text'", "]", "=", "item_text", "\n", "self", ".", "items", "[", "idx", "]", "[", "'phonemes'", "]", "=", "item_phon", "\n", "\n", "# convert text into a sequence of character IDs, convert language and speaker names to IDs", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "items", ")", ")", ":", "\n", "            ", "self", ".", "items", "[", "idx", "]", "[", "'phonemes'", "]", "=", "text", ".", "to_sequence", "(", "self", ".", "items", "[", "idx", "]", "[", "'phonemes'", "]", ",", "use_phonemes", "=", "True", ")", "\n", "self", ".", "items", "[", "idx", "]", "[", "'text'", "]", "=", "text", ".", "to_sequence", "(", "self", ".", "items", "[", "idx", "]", "[", "'text'", "]", ",", "use_phonemes", "=", "False", ")", "\n", "self", ".", "items", "[", "idx", "]", "[", "'speaker'", "]", "=", "self", ".", "unique_speakers", ".", "index", "(", "self", ".", "items", "[", "idx", "]", "[", "'speaker'", "]", ")", "\n", "self", ".", "items", "[", "idx", "]", "[", "'language'", "]", "=", "hp", ".", "languages", ".", "index", "(", "self", ".", "items", "[", "idx", "]", "[", "'language'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.__len__": [[132, 134], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.__getitem__": [[135, 141], ["dataset.TextToSpeechDataset.load_spectrogram", "dataset.TextToSpeechDataset.load_spectrogram"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.load_spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.load_spectrogram"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item", "=", "self", ".", "items", "[", "index", "]", "\n", "audio_path", "=", "item", "[", "'audio'", "]", "\n", "mel_spec", "=", "self", ".", "load_spectrogram", "(", "audio_path", ",", "item", "[", "'spectrogram'", "]", ",", "hp", ".", "normalize_spectrogram", ",", "True", ")", "\n", "lin_spec", "=", "self", ".", "load_spectrogram", "(", "audio_path", ",", "item", "[", "'linear_spectrogram'", "]", ",", "hp", ".", "normalize_spectrogram", ",", "False", ")", "if", "hp", ".", "predict_linear", "else", "None", "\n", "return", "(", "item", "[", "'speaker'", "]", ",", "item", "[", "'language'", "]", ",", "item", "[", "'phonemes'", "]", "if", "hp", ".", "use_phonemes", "else", "item", "[", "'text'", "]", ",", "mel_spec", ",", "lin_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.concat_dataset": [[142, 153], ["len", "len", "dataset.TextToSpeechDataset.items.extend", "len"], "methods", ["None"], ["", "def", "concat_dataset", "(", "self", ",", "new_data", ")", ":", "\n", "        ", "\"\"\"\n        new_data: an TextToSpeechDataset object\n        will update the self.items attribute\n        \"\"\"", "\n", "self_len", "=", "len", "(", "self", ".", "items", ")", "\n", "new_len", "=", "len", "(", "new_data", ".", "items", ")", "\n", "\n", "self", ".", "items", ".", "extend", "(", "new_data", ".", "items", ")", "\n", "\n", "assert", "len", "(", "self", ".", "items", ")", "==", "self_len", "+", "new_len", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.sample_n_items": [[154, 161], ["random.sample"], "methods", ["None"], ["", "def", "sample_n_items", "(", "self", ",", "n_items", ")", ":", "\n", "        ", "\"\"\"\n        sample `n_items` from the list `self.items`\n        \"\"\"", "\n", "# self.items = self.items[:n_items]", "\n", "self", ".", "items", "=", "random", ".", "sample", "(", "self", ".", "items", ",", "n_items", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.remove": [[162, 169], ["range", "random.randint", "dataset.TextToSpeechDataset.items.pop", "len"], "methods", ["None"], ["", "def", "remove", "(", "self", ",", "n_rm_items", ")", ":", "\n", "        ", "\"\"\"\n        remove `n_rm_items` items from the list `self.items`\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "n_rm_items", ")", ":", "\n", "            ", "rm_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "items", ")", ")", "\n", "self", ".", "items", ".", "pop", "(", "rm_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.load_spectrogram": [[171, 200], ["os.path.join", "numpy.load", "os.path.join", "utils.audio.load", "utils.audio.spectrogram", "utils.audio.normalize_spectrogram", "numpy.shape", "numpy.shape"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.normalize_spectrogram"], ["", "", "def", "load_spectrogram", "(", "self", ",", "audio_path", ",", "spectrogram_path", ",", "normalize", ",", "is_mel", ")", ":", "\n", "        ", "\"\"\"Load a mel or linear spectrogram from file or compute from scratch if needed.\n\n        Arguments:\n            audio_path (string): Path to the audio from which will (possibly) be the spectrogram computed.\n            spectrogram_path (string): Path to the spectrogram file which will be loaded (possibly).\n            normalize (boolean): If True, the spectrogram is normalized (per channel, extract mean and divide by std).\n            is_mel (boolean): If True, the mel spectrogram is loaded or computed, otherwise returns a linear spectrogram.\n        \"\"\"", "\n", "\n", "# load or compute spectrogram", "\n", "if", "hp", ".", "cache_spectrograms", ":", "\n", "            ", "full_spec_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "spectrogram_path", ")", "\n", "spectrogram", "=", "np", ".", "load", "(", "full_spec_path", ")", "\n", "", "else", ":", "\n", "            ", "full_audio_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "audio_path", ")", "\n", "audio_data", "=", "audio", ".", "load", "(", "full_audio_path", ")", "\n", "spectrogram", "=", "audio", ".", "spectrogram", "(", "audio_data", ",", "is_mel", ")", "\n", "\n", "# check spectrogram dimensions", "\n", "", "expected_dimension", "=", "hp", ".", "num_mels", "if", "is_mel", "else", "hp", ".", "num_fft", "//", "2", "+", "1", "\n", "assert", "np", ".", "shape", "(", "spectrogram", ")", "[", "0", "]", "==", "expected_dimension", ",", "(", "\n", "f'Spectrogram dimensions mismatch: given {np.shape(spectrogram)[0]}, expected {expected_dimension}'", ")", "\n", "\n", "# normalize if desired", "\n", "if", "normalize", ":", "\n", "            ", "spectrogram", "=", "audio", ".", "normalize_spectrogram", "(", "spectrogram", ",", "is_mel", ")", "\n", "\n", "", "return", "spectrogram", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.get_normalization_constants": [[201, 213], ["len", "len", "dataset.TextToSpeechDataset.load_spectrogram", "numpy.mean", "numpy.std"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.load_spectrogram"], ["", "def", "get_normalization_constants", "(", "self", ",", "is_mel", ")", ":", "\n", "        ", "\"\"\"Compute per-channel mean and variance of the data contained in this collection.\"\"\"", "\n", "mean", "=", "0.0", "\n", "std", "=", "0.0", "\n", "for", "item", "in", "self", ".", "items", ":", "\n", "            ", "path", "=", "item", "[", "'spectrogram'", "]", "if", "is_mel", "else", "item", "[", "'linear_spectrogram'", "]", "\n", "spectrogram", "=", "self", ".", "load_spectrogram", "(", "item", "[", "'audio'", "]", ",", "path", ",", "False", ",", "is_mel", ")", "\n", "mean", "+=", "np", ".", "mean", "(", "spectrogram", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "std", "+=", "np", ".", "std", "(", "spectrogram", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "", "mean", "/=", "len", "(", "self", ".", "items", ")", "\n", "std", "/=", "len", "(", "self", ".", "items", ")", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.get_num_speakers": [[214, 220], ["set", "range", "len", "len", "set.add"], "methods", ["None"], ["", "def", "get_num_speakers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get number of unique speakers in the dataset.\"\"\"", "\n", "speakers", "=", "set", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "items", ")", ")", ":", "\n", "            ", "speakers", ".", "add", "(", "self", ".", "items", "[", "idx", "]", "[", "'speaker'", "]", ")", "\n", "", "return", "len", "(", "speakers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.get_num_languages": [[221, 227], ["set", "range", "len", "len", "set.add"], "methods", ["None"], ["", "def", "get_num_languages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get number of unique languages in the dataset.\"\"\"", "\n", "languages", "=", "set", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "items", ")", ")", ":", "\n", "            ", "languages", ".", "add", "(", "self", ".", "items", "[", "idx", "]", "[", "'language'", "]", ")", "\n", "", "return", "len", "(", "languages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechDataset.create_meta_file": [[228, 296], ["os.path.join", "dataset.loaders.get_loader_by_name", "utils.text.build_phoneme_dicts", "open", "utils.logging.Logger.progress", "range", "os.path.join", "os.path.join", "len", "print", "utils.logging.Logger.progress", "os.path.exists", "os.makedirs", "utils.text.to_phoneme", "utils.audio.load", "numpy.save", "numpy.save", "os.path.join", "os.path.join", "utils.audio.spectrogram", "os.path.join", "utils.audio.spectrogram", "os.path.join", "len", "str().zfill", "os.path.join", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.loaders.get_loader_by_name", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.build_phoneme_dicts", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.progress", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.logging.Logger.progress", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.text.to_phoneme", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.save", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.save", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.spectrogram", "home.repos.pwc.inspect_result.mu-y_lll-tts.utils.audio.spectrogram"], ["", "@", "staticmethod", "\n", "def", "create_meta_file", "(", "dataset_name", ",", "dataset_root_dir", ",", "output_metafile_name", ",", "audio_sample_rate", ",", "num_fft_freqs", ",", "spectrograms", "=", "True", ",", "phonemes", "=", "True", ")", ":", "\n", "        ", "\"\"\"Create the meta-file and spectrograms (mel and linear, optionally) or phonemized utterances (optionally).\n\n        Format details:\n            Every line of the metadata file contains info about one dataset item.\n            The line has following format\n                'id|speaker|language|audio_file_path|mel_spectrogram_path|linear_spectrogram_path|text|phonemized_text'\n            And the following must hold\n                'audio_file_path' can be empty if loading just spectrograms\n                'text' should be carefully normalized and should contain interpunction\n                'phonemized_text' can be empty if loading just raw text\n\n        Arguments:\n            dataset_name (string): Name of the dataset, loaders.py should contain a function for loading with a corresponding name.\n            dataset_root_dir (string): Root directory from which is the dataset build and to which are spectrograms and the meta-file saved..\n            output_metafile_name (string): Name of the output meta-file.\n            audio_sample_rate (int): Sample rate of audios, used if spectrograms is set True.\n            num_fft_freqs (int): Number of frequency bands used during spectrogram computation, used if spectrograms is set True.\n        Keyword arguments:\n            spectrograms (boolean, default True): If true, spetrograms (both mel and linear) are computed and saved.\n            phonemes (boolean, default True): If true, phonemized variants of utterances are computed and saved.\n        \"\"\"", "\n", "\n", "# save current sample rate and fft freqs hyperparameters, as we may process dataset with different sample rate", "\n", "if", "spectrograms", ":", "\n", "            ", "old_sample_rate", "=", "hp", ".", "sample_rate", "\n", "hp", ".", "sample_rate", "=", "audio_sample_rate", "\n", "old_fft_freqs", "=", "hp", ".", "num_fft", "\n", "hp", ".", "num_fft", "=", "num_fft_freqs", "\n", "\n", "# load metafiles, an item is a list like: [text, audiopath, speaker_id, language_code]", "\n", "", "items", "=", "loaders", ".", "get_loader_by_name", "(", "dataset_name", ")", "(", "dataset_root_dir", ")", "\n", "\n", "# build dictionaries for translation to IPA from source languages, see utils.text for details", "\n", "if", "phonemes", ":", "\n", "            ", "text_lang_pairs", "=", "[", "(", "i", "[", "0", "]", ",", "hp", ".", "languages", "[", "0", "]", "if", "i", "[", "3", "]", "==", "\"\"", "else", "i", "[", "3", "]", ")", "for", "i", "in", "items", "]", "\n", "phoneme_dicts", "=", "text", ".", "build_phoneme_dicts", "(", "text_lang_pairs", ")", "\n", "\n", "# prepare directories which will store spectrograms", "\n", "", "if", "spectrograms", ":", "\n", "            ", "spectrogram_dirs", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "'spectrograms'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "'linear_spectrograms'", ")", "]", "\n", "for", "x", "in", "spectrogram_dirs", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "x", ")", ":", "os", ".", "makedirs", "(", "x", ")", "\n", "\n", "# iterate through items and build the meta-file", "\n", "", "", "metafile_path", "=", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "output_metafile_name", ")", "\n", "with", "open", "(", "metafile_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "Logger", ".", "progress", "(", "0", ",", "prefix", "=", "'Building metafile:'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "items", ")", ")", ":", "\n", "                ", "raw_text", ",", "audio_path", ",", "speaker", ",", "language", "=", "items", "[", "i", "]", "\n", "if", "language", "==", "\"\"", ":", "language", "=", "hp", ".", "languages", "[", "0", "]", "\n", "phonemized_text", "=", "text", ".", "to_phoneme", "(", "raw_text", ",", "False", ",", "language", ",", "phoneme_dicts", "[", "language", "]", ")", "if", "phonemes", "else", "\"\"", "\n", "spectrogram_paths", "=", "\"|\"", "\n", "if", "spectrograms", ":", "\n", "                    ", "spec_name", "=", "f'{str(i).zfill(6)}.npy'", "\n", "audio_data", "=", "audio", ".", "load", "(", "os", ".", "path", ".", "join", "(", "dataset_root_dir", ",", "audio_path", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "spectrogram_dirs", "[", "0", "]", ",", "spec_name", ")", ",", "audio", ".", "spectrogram", "(", "audio_data", ",", "True", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "spectrogram_dirs", "[", "1", "]", ",", "spec_name", ")", ",", "audio", ".", "spectrogram", "(", "audio_data", ",", "False", ")", ")", "\n", "spectrogram_paths", "=", "os", ".", "path", ".", "join", "(", "'spectrograms'", ",", "spec_name", ")", "+", "'|'", "+", "os", ".", "path", ".", "join", "(", "'linear_spectrograms'", ",", "spec_name", ")", "\n", "", "print", "(", "f'{str(i).zfill(6)}|{speaker}|{language}|{audio_path}|{spectrogram_paths}|{raw_text}|{phonemized_text}'", ",", "file", "=", "f", ")", "\n", "Logger", ".", "progress", "(", "(", "i", "+", "1", ")", "/", "len", "(", "items", ")", ",", "prefix", "=", "'Building metafile:'", ")", "\n", "\n", "# restore the original sample rate and fft freq values", "\n", "", "", "if", "spectrograms", ":", "\n", "            ", "hp", ".", "sample_rate", "=", "old_sample_rate", "\n", "hp", ".", "num_fft", "=", "old_fft_freqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechCollate.__init__": [[305, 307], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sort_by_text_length", ")", ":", "\n", "        ", "self", ".", "sort_by_text_length", "=", "sort_by_text_length", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.dataset.dataset.TextToSpeechCollate.__call__": [[308, 373], ["len", "torch.LongTensor", "torch.LongTensor", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "speakers.append", "torch.zeros().zero_.scatter_.append", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor", "torch.LongTensor", "torch.sort", "range", "torch.zeros().zero_.scatter_.unsqueeze().expand().unsqueeze", "torch.zeros().zero_", "torch.zeros().zero_.scatter_", "max", "torch.zeros", "torch.LongTensor", "torch.FloatTensor", "len", "len", "torch.FloatTensor", "torch.zeros().zero_.scatter_.unsqueeze().expand", "torch.zeros", "torch.zeros().zero_.scatter_.size", "torch.zeros().zero_.scatter_.size", "len", "torch.zeros().zero_.scatter_.unsqueeze", "max"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch_size", "=", "len", "(", "batch", ")", "\n", "\n", "# iterate batch, get lengths of spectrograms and uttrances", "\n", "utterance_lengths", ",", "spectrogram_lengths", "=", "[", "]", ",", "[", "]", "\n", "speakers", "=", "[", "]", "\n", "languages", "=", "[", "]", "\n", "max_frames", "=", "0", "\n", "for", "s", ",", "l", ",", "u", ",", "a", ",", "_", "in", "batch", ":", "# spk, lang, text/phn, mel, lin_mel", "\n", "            ", "speakers", ".", "append", "(", "s", ")", "\n", "languages", ".", "append", "(", "l", ")", "\n", "utterance_lengths", ".", "append", "(", "len", "(", "u", ")", ")", "\n", "spectrogram_lengths", ".", "append", "(", "len", "(", "a", "[", "0", "]", ")", ")", "\n", "if", "spectrogram_lengths", "[", "-", "1", "]", ">", "max_frames", ":", "\n", "                ", "max_frames", "=", "spectrogram_lengths", "[", "-", "1", "]", "\n", "\n", "# convert collected lists to tensors", "\n", "", "", "utterance_lengths", "=", "torch", ".", "LongTensor", "(", "utterance_lengths", ")", "\n", "spectrogram_lengths", "=", "torch", ".", "LongTensor", "(", "spectrogram_lengths", ")", "\n", "speakers", "=", "None", "if", "not", "hp", ".", "multi_speaker", "else", "torch", ".", "LongTensor", "(", "speakers", ")", "\n", "languages", "=", "None", "if", "not", "hp", ".", "multi_language", "else", "torch", ".", "LongTensor", "(", "languages", ")", "\n", "\n", "if", "self", ".", "sort_by_text_length", ":", "\n", "            ", "utterance_lengths", ",", "sorted_idxs", "=", "torch", ".", "sort", "(", "utterance_lengths", ",", "descending", "=", "True", ")", "\n", "# # permute other tensors according to sorted_idx", "\n", "# spectrogram_lengths = spectrogram_lengths[sorted_idxs]", "\n", "# if speakers is not None: speakers = speakers[sorted_idxs]", "\n", "# if languages is not None:", "\n", "#     languages = languages[sorted_idxs]", "\n", "#     # convert a vector of language indices into a vector of one-hots (used as weight vectors for accent control)", "\n", "#     one_hots = torch.zeros(languages.size(0), languages.size(1), hp.language_number).zero_()", "\n", "#     languages = one_hot.scatter_(2, languages.data, 1)", "\n", "", "else", ":", "\n", "            ", "sorted_idxs", "=", "range", "(", "batch_size", ")", "\n", "\n", "# permute other tensors according to sorted_idx", "\n", "", "spectrogram_lengths", "=", "spectrogram_lengths", "[", "sorted_idxs", "]", "\n", "if", "speakers", "is", "not", "None", ":", "speakers", "=", "speakers", "[", "sorted_idxs", "]", "\n", "if", "languages", "is", "not", "None", ":", "\n", "            ", "languages", "=", "languages", "[", "sorted_idxs", "]", "\n", "\n", "# if use one hot as lang embedding, convert int to one hot", "\n", "", "if", "hp", ".", "one_hot_lang_emb", ":", "\n", "            ", "languages", "=", "languages", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "max", "(", "utterance_lengths", ")", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "one_hots", "=", "torch", ".", "zeros", "(", "languages", ".", "size", "(", "0", ")", ",", "languages", ".", "size", "(", "1", ")", ",", "hp", ".", "language_number", ")", ".", "zero_", "(", ")", "\n", "languages", "=", "one_hots", ".", "scatter_", "(", "2", ",", "languages", ".", "data", ",", "1", ")", "\n", "\n", "\n", "# zero-pad utterances, spectrograms", "\n", "", "utterances", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max", "(", "utterance_lengths", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "mel_spectrograms", "=", "torch", ".", "zeros", "(", "batch_size", ",", "hp", ".", "num_mels", ",", "max_frames", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "lin_spectrograms", "=", "torch", ".", "zeros", "(", "batch_size", ",", "hp", ".", "num_fft", "//", "2", "+", "1", ",", "max_frames", ",", "dtype", "=", "torch", ".", "float", ")", "if", "hp", ".", "predict_linear", "else", "None", "\n", "stop_tokens", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max_frames", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# fill tensors", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "sorted_idxs", ")", ":", "\n", "            ", "_", ",", "_", ",", "u", ",", "a", ",", "b", "=", "batch", "[", "idx", "]", "\n", "utterances", "[", "i", ",", ":", "len", "(", "u", ")", "]", "=", "torch", ".", "LongTensor", "(", "u", ")", "\n", "mel_spectrograms", "[", "i", ",", ":", ",", ":", "a", "[", "0", "]", ".", "size", "]", "=", "torch", ".", "FloatTensor", "(", "a", ")", "\n", "if", "hp", ".", "predict_linear", ":", "\n", "                ", "lin_spectrograms", "[", "i", ",", ":", ",", ":", "b", "[", "0", "]", ".", "size", "]", "=", "torch", ".", "FloatTensor", "(", "b", ")", "\n", "", "stop_tokens", "[", "i", ",", "a", "[", "0", "]", ".", "size", "-", "hp", ".", "stop_frames", ":", "]", "=", "1", "\n", "\n", "\n", "", "return", "utterances", ",", "utterance_lengths", ",", "mel_spectrograms", ",", "lin_spectrograms", ",", "spectrogram_lengths", ",", "stop_tokens", ",", "speakers", ",", "languages", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.Encoder.__init__": [[27, 35], ["super().__init__", "torch.nn.Sequential", "torch.nn.LSTM", "modules.layers.ConvBlock", "modules.layers.ConvBlock", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "num_blocks", ",", "kernel_size", ",", "dropout", ",", "generated", "=", "False", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "num_blocks", ">", "0", ",", "(", "'There must be at least one convolutional block in the encoder.'", ")", "\n", "assert", "output_dim", "%", "2", "==", "0", ",", "(", "'Bidirectional LSTM output dimension must be divisible by 2.'", ")", "\n", "convs", "=", "[", "ConvBlock", "(", "input_dim", ",", "output_dim", ",", "kernel_size", ",", "dropout", ",", "'relu'", ")", "]", "+", "[", "ConvBlock", "(", "output_dim", ",", "output_dim", ",", "kernel_size", ",", "dropout", ",", "'relu'", ")", "for", "_", "in", "range", "(", "num_blocks", "-", "1", ")", "]", "\n", "self", ".", "_convs", "=", "Sequential", "(", "*", "convs", ")", "\n", "self", ".", "_lstm", "=", "LSTM", "(", "output_dim", ",", "output_dim", "//", "2", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.Encoder.forward": [[36, 47], ["torch.nn.utils.rnn.pack_padded_sequence.transpose", "encoder.Encoder._convs", "torch.nn.utils.rnn.pack_padded_sequence.transpose", "torch.nn.utils.rnn.pack_padded_sequence.size", "torch.nn.utils.rnn.pack_padded_sequence", "encoder.Encoder._lstm.flatten_parameters", "encoder.Encoder._lstm", "torch.nn.utils.rnn.pad_packed_sequence", "x_lenghts.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lenghts", ",", "x_langs", "=", "None", ")", ":", "\n", "# x_langs argument is there just for convenience", "\n", "        ", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "_convs", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "ml", "=", "x", ".", "size", "(", "1", ")", "\n", "x", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "x_lenghts", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "_lstm", ".", "flatten_parameters", "(", ")", "\n", "x", ",", "_", "=", "self", ".", "_lstm", "(", "x", ")", "\n", "x", ",", "_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "x", ",", "batch_first", "=", "True", ",", "total_length", "=", "ml", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.ConditionalEncoder.__init__": [[58, 66], ["super().__init__", "torch.nn.Embedding", "list", "tuple", "encoder.Encoder"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "num_langs", ",", "langs_embedding_dim", ",", "encoder_args", ")", ":", "\n", "        ", "super", "(", "ConditionalEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_language_embedding", "=", "Embedding", "(", "num_langs", ",", "langs_embedding_dim", ")", "\n", "# modify input_dim of the underlying Encoder", "\n", "encoder_args", "=", "list", "(", "encoder_args", ")", "\n", "encoder_args", "[", "0", "]", "+=", "langs_embedding_dim", "\n", "encoder_args", "=", "tuple", "(", "encoder_args", ")", "\n", "self", ".", "_encoder", "=", "Encoder", "(", "*", "encoder_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.ConditionalEncoder.forward": [[67, 73], ["encoder.ConditionalEncoder._language_embedding", "torch.cat", "encoder.ConditionalEncoder._encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lenghts", ",", "x_langs", ")", ":", "\n", "# x_langs = torch.argmax(x_langs, dim=2)", "\n", "        ", "l", "=", "self", ".", "_language_embedding", "(", "x_langs", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "l", ")", ",", "dim", "=", "-", "1", ")", "\n", "x", "=", "self", ".", "_encoder", "(", "x", ",", "x_lenghts", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.MultiEncoder.__init__": [[83, 87], ["super().__init__", "torch.nn.ModuleList", "encoder.Encoder", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "num_langs", ",", "encoder_args", ")", ":", "\n", "        ", "super", "(", "MultiEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_num_langs", "=", "num_langs", "\n", "self", ".", "_encoders", "=", "ModuleList", "(", "[", "Encoder", "(", "*", "encoder_args", ")", "for", "_", "in", "range", "(", "num_langs", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.MultiEncoder.forward": [[88, 99], ["range", "x_langs_normed[].reshape", "x_langs.sum", "x_langs_normed[].reshape.bool().any", "torch.zeros_like", "x_langs_normed[].reshape.bool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lenghts", ",", "x_langs", ")", ":", "\n", "        ", "xs", "=", "None", "\n", "x_langs_normed", "=", "x_langs", "/", "x_langs", ".", "sum", "(", "2", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "_num_langs", ")", ":", "\n", "            ", "w", "=", "x_langs_normed", "[", ":", ",", ":", ",", "l", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "if", "not", "w", ".", "bool", "(", ")", ".", "any", "(", ")", ":", "continue", "\n", "ex", "=", "self", ".", "_encoders", "[", "l", "]", "(", "x", ",", "x_lenghts", ")", "\n", "if", "xs", "is", "None", ":", "\n", "                ", "xs", "=", "torch", ".", "zeros_like", "(", "ex", ")", "\n", "", "xs", "+=", "w", "*", "ex", "\n", "", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.ConvolutionalEncoder.__init__": [[116, 134], ["super().__init__", "torch.nn.Sequential", "modules.layers.HighwayConvBlock", "modules.layers.HighwayConvBlock", "range", "modules.layers.HighwayConvBlock", "range", "modules.layers.ConvBlock", "modules.layers.ConvBlock", "modules.layers.HighwayConvBlock", "range", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "dropout", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", "ConvolutionalEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_groups", "=", "groups", "\n", "self", ".", "_input_dim", "=", "input_dim", "\n", "self", ".", "_output_dim", "=", "output_dim", "\n", "\n", "input_dim", "*=", "groups", "\n", "output_dim", "*=", "groups", "\n", "\n", "layers", "=", "[", "ConvBlock", "(", "input_dim", ",", "output_dim", ",", "1", ",", "dropout", ",", "activation", "=", "'relu'", ",", "groups", "=", "groups", ")", ",", "\n", "ConvBlock", "(", "output_dim", ",", "output_dim", ",", "1", ",", "dropout", ",", "groups", "=", "groups", ")", "]", "+", "[", "HighwayConvBlock", "(", "output_dim", ",", "output_dim", ",", "3", ",", "dropout", ",", "dilation", "=", "3", "**", "i", ",", "groups", "=", "groups", ")", "for", "i", "in", "range", "(", "4", ")", "]", "+", "[", "HighwayConvBlock", "(", "output_dim", ",", "output_dim", ",", "3", ",", "dropout", ",", "dilation", "=", "3", "**", "i", ",", "groups", "=", "groups", ")", "for", "i", "in", "range", "(", "4", ")", "]", "+", "[", "HighwayConvBlock", "(", "output_dim", ",", "output_dim", ",", "3", ",", "dropout", ",", "dilation", "=", "1", ",", "groups", "=", "groups", ")", "for", "_", "in", "range", "(", "2", ")", "]", "+", "[", "HighwayConvBlock", "(", "output_dim", ",", "output_dim", ",", "1", ",", "dropout", ",", "dilation", "=", "1", ",", "groups", "=", "groups", ")", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "\n", "self", ".", "_layers", "=", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.ConvolutionalEncoder.forward": [[135, 158], ["x.expand.expand.transpose", "x.expand.expand.reshape", "encoder.ConvolutionalEncoder._layers", "x.expand.expand.reshape", "x.expand.expand.transpose", "x.expand.expand.expand", "torch.zeros", "range", "x_langs_normed[].reshape", "x_langs.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lenghts", "=", "None", ",", "x_langs", "=", "None", ")", ":", "\n", "\n", "# x_langs is specified during inference with batch size 1, so we need to", "\n", "# expand the single language to create complete groups (all langs. in parallel)", "\n", "        ", "if", "x_langs", "is", "not", "None", "and", "x_langs", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "x", "=", "x", ".", "expand", "(", "(", "self", ".", "_groups", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "x", ".", "reshape", "(", "bs", "//", "self", ".", "_groups", ",", "self", ".", "_groups", "*", "self", ".", "_input_dim", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "_layers", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "bs", ",", "self", ".", "_output_dim", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "x_langs", "is", "not", "None", "and", "x_langs", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "xr", "=", "torch", ".", "zeros", "(", "1", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "device", "=", "x", ".", "device", ")", "\n", "x_langs_normed", "=", "x_langs", "/", "x_langs", ".", "sum", "(", "2", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "_groups", ")", ":", "\n", "                ", "w", "=", "x_langs_normed", "[", "0", ",", ":", ",", "l", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "xr", "[", "0", "]", "+=", "w", "*", "x", "[", "l", "]", "\n", "", "x", "=", "xr", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.GeneratedConvolutionalEncoder.__init__": [[171, 196], ["super().__init__", "torch.nn.Sequential", "torch.nn.Embedding", "modules.layers.HighwayConvBlockGenerated", "modules.layers.HighwayConvBlockGenerated", "range", "modules.layers.HighwayConvBlockGenerated", "range", "modules.layers.ConvBlockGenerated", "modules.layers.ConvBlockGenerated", "modules.layers.HighwayConvBlockGenerated", "range", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "dropout", ",", "embedding_dim", ",", "bottleneck_dim", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", "GeneratedConvolutionalEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_groups", "=", "groups", "\n", "self", ".", "_input_dim", "=", "input_dim", "\n", "self", ".", "_output_dim", "=", "output_dim", "\n", "\n", "input_dim", "*=", "groups", "\n", "output_dim", "*=", "groups", "\n", "\n", "layers", "=", "[", "ConvBlockGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "input_dim", ",", "output_dim", ",", "1", ",", "\n", "dropout", "=", "dropout", ",", "activation", "=", "'relu'", ",", "groups", "=", "groups", ")", ",", "\n", "ConvBlockGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "output_dim", ",", "output_dim", ",", "1", ",", "\n", "dropout", "=", "dropout", ",", "groups", "=", "groups", ")", "]", "+", "[", "HighwayConvBlockGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "output_dim", ",", "output_dim", ",", "3", ",", "\n", "dropout", "=", "dropout", ",", "dilation", "=", "3", "**", "i", ",", "groups", "=", "groups", ")", "for", "i", "in", "range", "(", "4", ")", "]", "+", "[", "HighwayConvBlockGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "output_dim", ",", "output_dim", ",", "3", ",", "\n", "dropout", "=", "dropout", ",", "dilation", "=", "3", "**", "i", ",", "groups", "=", "groups", ")", "for", "i", "in", "range", "(", "4", ")", "]", "+", "[", "HighwayConvBlockGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "output_dim", ",", "output_dim", ",", "3", ",", "\n", "dropout", "=", "dropout", ",", "dilation", "=", "1", ",", "groups", "=", "groups", ")", "for", "_", "in", "range", "(", "2", ")", "]", "+", "[", "HighwayConvBlockGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "output_dim", ",", "output_dim", ",", "1", ",", "\n", "dropout", "=", "dropout", ",", "dilation", "=", "1", ",", "groups", "=", "groups", ")", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "\n", "self", ".", "_layers", "=", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "_embedding", "=", "Embedding", "(", "groups", ",", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.encoder.GeneratedConvolutionalEncoder.forward": [[197, 223], ["encoder.GeneratedConvolutionalEncoder._embedding", "x.expand.expand.transpose", "x.expand.expand.reshape", "encoder.GeneratedConvolutionalEncoder._layers", "x.expand.expand.reshape", "x.expand.expand.transpose", "x.expand.expand.expand", "torch.arange", "torch.zeros", "range", "x_langs_normed[].reshape", "x_langs.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lenghts", "=", "None", ",", "x_langs", "=", "None", ")", ":", "\n", "\n", "# x_langs is specified during inference with batch size 1, so we need to", "\n", "# expand the single language to create complete groups (all langs. in parallel)", "\n", "        ", "if", "x_langs", "is", "not", "None", "and", "x_langs", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "x", "=", "x", ".", "expand", "(", "(", "self", ".", "_groups", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "# create generator embeddings for all groups", "\n", "", "e", "=", "self", ".", "_embedding", "(", "torch", ".", "arange", "(", "self", ".", "_groups", ",", "device", "=", "x", ".", "device", ")", ")", "\n", "\n", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "x", ".", "reshape", "(", "bs", "//", "self", ".", "_groups", ",", "self", ".", "_groups", "*", "self", ".", "_input_dim", ",", "-", "1", ")", "\n", "_", ",", "x", "=", "self", ".", "_layers", "(", "(", "e", ",", "x", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "bs", ",", "self", ".", "_output_dim", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "x_langs", "is", "not", "None", "and", "x_langs", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "xr", "=", "torch", ".", "zeros", "(", "1", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "device", "=", "x", ".", "device", ")", "\n", "x_langs_normed", "=", "x_langs", "/", "x_langs", ".", "sum", "(", "2", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "for", "l", "in", "range", "(", "self", ".", "_groups", ")", ":", "\n", "                ", "w", "=", "x_langs_normed", "[", "0", ",", ":", ",", "l", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "xr", "[", "0", "]", "+=", "w", "*", "x", "[", "l", "]", "\n", "", "x", "=", "xr", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.cbhg.PostnetCBHG.__init__": [[24, 44], ["super().__init__", "torch.nn.ModuleList", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.GRU", "torch.nn.Linear", "torch.nn.ConstantPad1d", "torch.nn.MaxPool1d", "modules.layers.ConvBlock", "modules.layers.ConvBlock", "cbhg.HighwayLayer", "torch.nn.Linear", "torch.nn.ReLU", "modules.layers.ConvBlock", "range", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "bank_size", ",", "bank_channels", ",", "projection_channels", ",", "projection_kernel_size", ",", "highway_dim", ",", "gru_dim", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "PostnetCBHG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "gru_dim", "%", "2", "==", "0", ",", "(", "'Bidirectional GRU dimension must be divisible by 2.'", ")", "\n", "self", ".", "_bank", "=", "ModuleList", "(", "[", "\n", "ConvBlock", "(", "input_dim", ",", "bank_channels", ",", "k", ",", "dropout", ",", "'relu'", ")", "for", "k", "in", "range", "(", "1", ",", "bank_size", "+", "1", ")", "\n", "]", ")", "\n", "self", ".", "_pool_and_project", "=", "Sequential", "(", "\n", "ConstantPad1d", "(", "(", "0", ",", "1", ")", ",", "0.0", ")", ",", "\n", "MaxPool1d", "(", "2", ",", "stride", "=", "1", ")", ",", "\n", "ConvBlock", "(", "bank_channels", "*", "bank_size", ",", "projection_channels", ",", "projection_kernel_size", ",", "dropout", ",", "'relu'", ")", ",", "\n", "ConvBlock", "(", "projection_channels", ",", "input_dim", ",", "projection_kernel_size", ",", "dropout", ",", "'identity'", ")", "\n", ")", "\n", "highways", "=", "[", "HighwayLayer", "(", "highway_dim", ")", "for", "_", "in", "range", "(", "4", ")", "]", "\n", "self", ".", "_highway_layers", "=", "Sequential", "(", "\n", "Linear", "(", "input_dim", ",", "highway_dim", ")", ",", "\n", "ReLU", "(", ")", ",", "\n", "*", "highways", "\n", ")", "\n", "self", ".", "_gru", "=", "GRU", "(", "highway_dim", ",", "gru_dim", "//", "2", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "_output_layer", "=", "Linear", "(", "gru_dim", ",", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.cbhg.PostnetCBHG.forward": [[45, 70], ["torch.cat", "cbhg.PostnetCBHG._pool_and_project", "x.transpose.transpose.transpose", "cbhg.PostnetCBHG._highway_layers", "x.transpose.transpose.size", "torch.sort", "torch.nn.utils.rnn.pack_padded_sequence", "cbhg.PostnetCBHG._gru.flatten_parameters", "cbhg.PostnetCBHG._gru", "torch.nn.utils.rnn.pad_packed_sequence", "torch.zeros_like", "cbhg.PostnetCBHG._output_layer", "x.transpose.transpose.transpose", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lengths", ")", ":", "\n", "\n", "        ", "residual", "=", "x", "\n", "bx", "=", "[", "layer", "(", "x", ")", "for", "layer", "in", "self", ".", "_bank", "]", "\n", "x", "=", "torch", ".", "cat", "(", "bx", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "_pool_and_project", "(", "x", ")", "\n", "\n", "x", "=", "x", "+", "residual", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "_highway_layers", "(", "x", ")", "\n", "\n", "ml", "=", "x", ".", "size", "(", "1", ")", "\n", "sorted_lengths", ",", "sorted_idxs", "=", "torch", ".", "sort", "(", "x_lengths", ",", "descending", "=", "True", ")", "\n", "x", "=", "x", "[", "sorted_idxs", "]", "\n", "x", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "sorted_lengths", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "_gru", ".", "flatten_parameters", "(", ")", "\n", "x", ",", "_", "=", "self", ".", "_gru", "(", "x", ")", "\n", "bx", ",", "_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "x", ",", "batch_first", "=", "True", ",", "total_length", "=", "ml", ")", "\n", "x", "=", "torch", ".", "zeros_like", "(", "bx", ")", "\n", "x", "[", "sorted_idxs", "]", "=", "bx", "\n", "\n", "x", "=", "self", ".", "_output_layer", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.cbhg.HighwayLayer.__init__": [[75, 84], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "dimension", ")", ":", "\n", "        ", "super", "(", "HighwayLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_linear", "=", "Sequential", "(", "\n", "Linear", "(", "dimension", ",", "dimension", ")", ",", "\n", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "_gate", "=", "Sequential", "(", "\n", "Linear", "(", "dimension", ",", "dimension", ")", ",", "\n", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.cbhg.HighwayLayer.forward": [[86, 89], ["cbhg.HighwayLayer._gate", "cbhg.HighwayLayer._linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "p", "=", "self", ".", "_gate", "(", "x", ")", "\n", "return", "self", ".", "_linear", "(", "x", ")", "*", "p", "+", "x", "*", "(", "1.0", "-", "p", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.ZoneoutLSTMCell.__init__": [[21, 25], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "zoneout_rate_hidden", ",", "zoneout_rate_cell", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "ZoneoutLSTMCell", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "bias", ")", "\n", "self", ".", "zoneout_c", "=", "zoneout_rate_cell", "\n", "self", ".", "zoneout_h", "=", "zoneout_rate_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.ZoneoutLSTMCell.forward": [[26, 35], ["super().forward", "torch.nn.functional.dropout", "torch.nn.functional.dropout"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward"], ["", "def", "forward", "(", "self", ",", "cell_input", ",", "h", ",", "c", ")", ":", "\n", "        ", "new_h", ",", "new_c", "=", "super", "(", "ZoneoutLSTMCell", ",", "self", ")", ".", "forward", "(", "cell_input", ",", "(", "h", ",", "c", ")", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "new_h", "=", "(", "1", "-", "self", ".", "zoneout_h", ")", "*", "F", ".", "dropout", "(", "new_h", "-", "h", ",", "self", ".", "zoneout_h", ")", "+", "h", "\n", "new_c", "=", "(", "1", "-", "self", ".", "zoneout_c", ")", "*", "F", ".", "dropout", "(", "new_c", "-", "c", ",", "self", ".", "zoneout_c", ")", "+", "c", "\n", "", "else", ":", "\n", "            ", "new_h", "=", "self", ".", "zoneout_h", "*", "h", "+", "(", "1", "-", "self", ".", "zoneout_h", ")", "*", "new_h", "\n", "new_c", "=", "self", ".", "zoneout_c", "*", "c", "+", "(", "1", "-", "self", ".", "zoneout_c", ")", "*", "new_c", "\n", "", "return", "new_h", ",", "new_c", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.DropoutLSTMCell.__init__": [[40, 43], ["super().__init__", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "dropout_rate", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "DropoutLSTMCell", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "bias", ")", "\n", "self", ".", "_dropout", "=", "Dropout", "(", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.DropoutLSTMCell.forward": [[44, 48], ["super().forward", "layers.DropoutLSTMCell._dropout"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward"], ["", "def", "forward", "(", "self", ",", "cell_input", ",", "h", ",", "c", ")", ":", "\n", "        ", "new_h", ",", "new_c", "=", "super", "(", "DropoutLSTMCell", ",", "self", ")", ".", "forward", "(", "cell_input", ",", "(", "h", ",", "c", ")", ")", "\n", "new_h", "=", "self", ".", "_dropout", "(", "new_h", ")", "\n", "return", "new_h", ",", "new_c", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.ConvBlock.__init__": [[66, 84], ["super().__init__", "torch.nn.Sequential", "torch.nn.ConstantPad1d", "torch.nn.Conv1d", "layers.get_activation", "torch.nn.Dropout", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.get_activation"], ["def", "__init__", "(", "self", ",", "input_channels", ",", "output_channels", ",", "kernel", ",", "\n", "dropout", "=", "0.0", ",", "activation", "=", "'identity'", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "batch_norm", "=", "True", ")", ":", "\n", "        ", "super", "(", "ConvBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_groups", "=", "groups", "\n", "\n", "p", "=", "(", "kernel", "-", "1", ")", "*", "dilation", "//", "2", "\n", "padding", "=", "p", "if", "kernel", "%", "2", "!=", "0", "else", "(", "p", ",", "p", "+", "1", ")", "\n", "layers", "=", "[", "ConstantPad1d", "(", "padding", ",", "0.0", ")", ",", "\n", "Conv1d", "(", "input_channels", ",", "output_channels", ",", "kernel", ",", "padding", "=", "0", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "(", "not", "batch_norm", ")", ")", "]", "\n", "\n", "if", "batch_norm", ":", "\n", "            ", "layers", "+=", "[", "BatchNorm1d", "(", "output_channels", ")", "]", "\n", "\n", "", "layers", "+=", "[", "get_activation", "(", "activation", ")", "]", "\n", "layers", "+=", "[", "Dropout", "(", "dropout", ")", "]", "\n", "\n", "self", ".", "_block", "=", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.ConvBlock.forward": [[85, 87], ["layers.ConvBlock._block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_block", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.ConvBlockGenerated.__init__": [[106, 122], ["super().__init__", "torch.nn.ConstantPad1d", "modules.generated.Conv1dGenerated", "torch.nn.Sequential", "modules.generated.BatchNorm1dGenerated", "layers.get_activation", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.get_activation"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "bottleneck_dim", ",", "input_channels", ",", "output_channels", ",", "kernel", ",", "\n", "dropout", "=", "0.0", ",", "activation", "=", "'identity'", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "batch_norm", "=", "True", ")", ":", "\n", "        ", "super", "(", "ConvBlockGenerated", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_groups", "=", "groups", "\n", "\n", "p", "=", "(", "kernel", "-", "1", ")", "*", "dilation", "//", "2", "\n", "padding", "=", "p", "if", "kernel", "%", "2", "!=", "0", "else", "(", "p", ",", "p", "+", "1", ")", "\n", "\n", "self", ".", "_padding", "=", "ConstantPad1d", "(", "padding", ",", "0.0", ")", "\n", "self", ".", "_convolution", "=", "Conv1dGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "input_channels", ",", "output_channels", ",", "kernel", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "(", "not", "batch_norm", ")", ")", "\n", "self", ".", "_regularizer", "=", "BatchNorm1dGenerated", "(", "embedding_dim", ",", "bottleneck_dim", ",", "output_channels", ",", "groups", "=", "groups", ")", "if", "batch_norm", "else", "None", "\n", "self", ".", "_activation", "=", "Sequential", "(", "\n", "get_activation", "(", "activation", ")", ",", "\n", "Dropout", "(", "dropout", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.ConvBlockGenerated.forward": [[124, 132], ["layers.ConvBlockGenerated._padding", "layers.ConvBlockGenerated._convolution", "layers.ConvBlockGenerated._activation", "layers.ConvBlockGenerated._regularizer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "e", ",", "x", "=", "x", "\n", "x", "=", "self", ".", "_padding", "(", "x", ")", "\n", "x", "=", "self", ".", "_convolution", "(", "e", ",", "x", ")", "\n", "if", "self", ".", "_regularizer", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "_regularizer", "(", "e", ",", "x", ")", "\n", "", "x", "=", "self", ".", "_activation", "(", "x", ")", "\n", "return", "e", ",", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.HighwayConvBlock.__init__": [[141, 146], ["layers.ConvBlock.__init__", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_channels", ",", "output_channels", ",", "kernel", ",", "\n", "dropout", "=", "0.0", ",", "activation", "=", "'identity'", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "batch_norm", "=", "True", ")", ":", "\n", "        ", "super", "(", "HighwayConvBlock", ",", "self", ")", ".", "__init__", "(", "input_channels", ",", "2", "*", "output_channels", ",", "kernel", ",", "dropout", ",", "activation", ",", "\n", "dilation", ",", "groups", ",", "batch_norm", ")", "\n", "self", ".", "_gate", "=", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.HighwayConvBlock.forward": [[147, 154], ["layers.ConvBlock.forward", "torch.chunk", "torch.cat", "torch.cat", "layers.HighwayConvBlock._gate"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "super", "(", "HighwayConvBlock", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "chunks", "=", "torch", ".", "chunk", "(", "h", ",", "2", "*", "self", ".", "_groups", ",", "1", ")", "\n", "h1", "=", "torch", ".", "cat", "(", "chunks", "[", "0", ":", ":", "2", "]", ",", "1", ")", "\n", "h2", "=", "torch", ".", "cat", "(", "chunks", "[", "1", ":", ":", "2", "]", ",", "1", ")", "\n", "p", "=", "self", ".", "_gate", "(", "h1", ")", "\n", "return", "h2", "*", "p", "+", "x", "*", "(", "1.0", "-", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.HighwayConvBlockGenerated.__init__": [[165, 170], ["layers.ConvBlockGenerated.__init__", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "bottleneck_dim", ",", "input_channels", ",", "output_channels", ",", "kernel", ",", "\n", "dropout", "=", "0.0", ",", "activation", "=", "'identity'", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "batch_norm", "=", "True", ")", ":", "\n", "        ", "super", "(", "HighwayConvBlockGenerated", ",", "self", ")", ".", "__init__", "(", "embedding_dim", ",", "bottleneck_dim", ",", "input_channels", ",", "2", "*", "output_channels", ",", "kernel", ",", "\n", "dropout", ",", "activation", ",", "dilation", ",", "groups", ",", "batch_norm", ")", "\n", "self", ".", "_gate", "=", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.HighwayConvBlockGenerated.forward": [[171, 179], ["layers.ConvBlockGenerated.forward", "torch.chunk", "torch.cat", "torch.cat", "layers.HighwayConvBlockGenerated._gate"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "e", ",", "x", "=", "x", "\n", "_", ",", "h", "=", "super", "(", "HighwayConvBlockGenerated", ",", "self", ")", ".", "forward", "(", "(", "e", ",", "x", ")", ")", "\n", "chunks", "=", "torch", ".", "chunk", "(", "h", ",", "2", "*", "self", ".", "_groups", ",", "1", ")", "\n", "h1", "=", "torch", ".", "cat", "(", "chunks", "[", "0", ":", ":", "2", "]", ",", "1", ")", "\n", "h2", "=", "torch", ".", "cat", "(", "chunks", "[", "1", ":", ":", "2", "]", ",", "1", ")", "\n", "p", "=", "self", ".", "_gate", "(", "h1", ")", "\n", "return", "e", ",", "h2", "*", "p", "+", "x", "*", "(", "1.0", "-", "p", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.layers.get_activation": [[8, 16], ["torch.nn.ReLU", "torch.nn.Sigmoid", "torch.nn.Tanh", "torch.nn.Identity"], "function", ["None"], ["def", "get_activation", "(", "name", ")", ":", "\n", "    ", "\"\"\"Get activation function by name.\"\"\"", "\n", "return", "{", "\n", "'relu'", ":", "ReLU", "(", ")", ",", "\n", "'sigmoid'", ":", "Sigmoid", "(", ")", ",", "\n", "'tanh'", ":", "Tanh", "(", ")", ",", "\n", "'identity'", ":", "Identity", "(", ")", "\n", "}", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.AttentionBase.__init__": [[15, 22], ["super().__init__", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "representation_dim", ",", "query_dim", ",", "memory_dim", ")", ":", "\n", "        ", "super", "(", "AttentionBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_bias", "=", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "representation_dim", ")", ")", "\n", "self", ".", "_energy", "=", "Linear", "(", "representation_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "_query", "=", "Linear", "(", "query_dim", ",", "representation_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "_memory", "=", "Linear", "(", "memory_dim", ",", "representation_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "_memory_dim", "=", "memory_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.AttentionBase.reset": [[23, 29], ["attention.AttentionBase._memory", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "encoded_input", ",", "batch_size", ",", "max_len", ",", "device", ")", ":", "\n", "        ", "\"\"\"Initialize previous attention weights & prepare attention memory.\"\"\"", "\n", "self", ".", "_memory_transform", "=", "self", ".", "_memory", "(", "encoded_input", ")", "\n", "self", ".", "_prev_weights", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max_len", ",", "device", "=", "device", ")", "\n", "self", ".", "_prev_context", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_memory_dim", ",", "device", "=", "device", ")", "\n", "return", "self", ".", "_prev_context", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.AttentionBase._attent": [[30, 32], ["None"], "methods", ["None"], ["", "def", "_attent", "(", "self", ",", "query", ",", "memory_transform", ",", "weights", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.AttentionBase._combine_weights": [[33, 35], ["None"], "methods", ["None"], ["", "def", "_combine_weights", "(", "self", ",", "previsous_weights", ",", "weights", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.AttentionBase._normalize": [[36, 38], ["None"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "energies", ",", "mask", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.AttentionBase.forward": [[39, 46], ["attention.AttentionBase._attent", "attention.AttentionBase._normalize", "attention.AttentionBase._combine_weights", "attention_weights.unsqueeze.unsqueeze.unsqueeze", "torch.bmm().squeeze", "attention_weights.unsqueeze.unsqueeze.squeeze", "torch.bmm"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition._attent", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._normalize", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._combine_weights"], ["", "def", "forward", "(", "self", ",", "query", ",", "memory", ",", "mask", ",", "prev_decoder_output", ")", ":", "\n", "        ", "energies", "=", "self", ".", "_attent", "(", "query", ",", "self", ".", "_memory_transform", ",", "self", ".", "_prev_weights", ")", "\n", "attention_weights", "=", "self", ".", "_normalize", "(", "energies", ",", "mask", ")", "\n", "self", ".", "_prev_weights", "=", "self", ".", "_combine_weights", "(", "self", ".", "_prev_weights", ",", "attention_weights", ")", "\n", "attention_weights", "=", "attention_weights", ".", "unsqueeze", "(", "1", ")", "\n", "self", ".", "_prev_context", "=", "torch", ".", "bmm", "(", "attention_weights", ",", "memory", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "self", ".", "_prev_context", ",", "attention_weights", ".", "squeeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.LocationSensitiveAttention.__init__": [[61, 66], ["attention.AttentionBase.__init__", "torch.nn.Linear", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", ",", "channels", ",", "smoothing", ",", "representation_dim", ",", "query_dim", ",", "memory_dim", ")", ":", "\n", "        ", "super", "(", "LocationSensitiveAttention", ",", "self", ")", ".", "__init__", "(", "representation_dim", ",", "query_dim", ",", "memory_dim", ")", "\n", "self", ".", "_location", "=", "Linear", "(", "channels", ",", "representation_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "_loc_features", "=", "Conv1d", "(", "1", ",", "channels", ",", "kernel_size", ",", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", ",", "bias", "=", "False", ")", "\n", "self", ".", "_smoothing", "=", "smoothing", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.LocationSensitiveAttention._attent": [[67, 75], ["attention.LocationSensitiveAttention._query", "cum_weights.unsqueeze.unsqueeze.unsqueeze", "attention.LocationSensitiveAttention._loc_features", "attention.LocationSensitiveAttention._location", "attention.LocationSensitiveAttention._energy", "attention.LocationSensitiveAttention.squeeze", "attention.LocationSensitiveAttention.unsqueeze", "cum_weights.unsqueeze.unsqueeze.transpose", "attention.LocationSensitiveAttention.transpose", "torch.tanh"], "methods", ["None"], ["", "def", "_attent", "(", "self", ",", "query", ",", "memory_transform", ",", "cum_weights", ")", ":", "\n", "        ", "query", "=", "self", ".", "_query", "(", "query", ".", "unsqueeze", "(", "1", ")", ")", "\n", "cum_weights", "=", "cum_weights", ".", "unsqueeze", "(", "-", "1", ")", "\n", "loc_features", "=", "self", ".", "_loc_features", "(", "cum_weights", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "loc_features", "=", "self", ".", "_location", "(", "loc_features", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "energy", "=", "query", "+", "memory_transform", "+", "loc_features", "\n", "energy", "=", "self", ".", "_energy", "(", "torch", ".", "tanh", "(", "energy", "+", "self", ".", "_bias", ")", ")", "\n", "return", "energy", ".", "squeeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.LocationSensitiveAttention._normalize": [[76, 84], ["float", "torch.sigmoid", "torch.sum", "torch.nn.functional.softmax"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "energies", ",", "mask", ")", ":", "\n", "        ", "energies", "[", "~", "mask", "]", "=", "float", "(", "'-inf'", ")", "\n", "if", "self", ".", "_smoothing", ":", "\n", "            ", "sigmoid", "=", "torch", ".", "sigmoid", "(", "energies", ")", "\n", "total", "=", "torch", ".", "sum", "(", "sigmoid", ",", "dim", "=", "-", "1", ")", "\n", "return", "sigmoid", "/", "total", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "energies", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.LocationSensitiveAttention._combine_weights": [[85, 87], ["None"], "methods", ["None"], ["", "", "def", "_combine_weights", "(", "self", ",", "previous_weights", ",", "weights", ")", ":", "\n", "        ", "return", "previous_weights", "+", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention.__init__": [[98, 100], ["attention.AttentionBase.__init__"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ForwardAttention", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention.reset": [[101, 105], ["attention.AttentionBase.reset"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition.reset"], ["", "def", "reset", "(", "self", ",", "encoded_input", ",", "batch_size", ",", "max_len", ",", "device", ")", ":", "\n", "        ", "super", "(", "ForwardAttention", ",", "self", ")", ".", "reset", "(", "encoded_input", ",", "batch_size", ",", "max_len", ",", "device", ")", "\n", "self", ".", "_prev_weights", "[", ":", ",", "0", "]", "=", "1", "\n", "return", "self", ".", "_prev_context", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._prepare_transition": [[106, 113], ["attention.ForwardAttention._query", "attention.ForwardAttention._energy().squeeze", "torch.nn.functional.softmax", "attention.ForwardAttention.unsqueeze", "torch.nn.functional.pad", "attention.ForwardAttention._energy", "torch.tanh"], "methods", ["None"], ["", "def", "_prepare_transition", "(", "self", ",", "query", ",", "memory_transform", ",", "weights", ")", ":", "\n", "        ", "query", "=", "self", ".", "_query", "(", "query", ".", "unsqueeze", "(", "1", ")", ")", "\n", "energy", "=", "query", "+", "memory_transform", "\n", "energy", "=", "self", ".", "_energy", "(", "torch", ".", "tanh", "(", "energy", "+", "self", ".", "_bias", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "energy", "=", "F", ".", "softmax", "(", "energy", ",", "dim", "=", "1", ")", "\n", "shifted_weights", "=", "F", ".", "pad", "(", "weights", ",", "(", "1", ",", "0", ")", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "return", "energy", ",", "shifted_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._attent": [[114, 118], ["attention.ForwardAttention._prepare_transition"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._prepare_transition"], ["", "def", "_attent", "(", "self", ",", "query", ",", "memory_transform", ",", "cum_weights", ")", ":", "\n", "        ", "energy", ",", "shifted_weights", "=", "self", ".", "_prepare_transition", "(", "query", ",", "memory_transform", ",", "self", ".", "_prev_weights", ")", "\n", "self", ".", "_prev_weights", "=", "(", "self", ".", "_prev_weights", "+", "shifted_weights", ")", "*", "energy", "\n", "return", "self", ".", "_prev_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._normalize": [[119, 122], ["float", "torch.nn.functional.normalize", "torch.clamp"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "energies", ",", "mask", ")", ":", "\n", "        ", "energies", "[", "~", "mask", "]", "=", "float", "(", "0", ")", "\n", "return", "F", ".", "normalize", "(", "torch", ".", "clamp", "(", "energies", ",", "1e-6", ")", ",", "p", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._combine_weights": [[123, 125], ["None"], "methods", ["None"], ["", "def", "_combine_weights", "(", "self", ",", "previous_weights", ",", "weights", ")", ":", "\n", "        ", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition.__init__": [[137, 140], ["attention.ForwardAttention.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "decoder_output_dim", ",", "representation_dim", ",", "query_dim", ",", "memory_dim", ")", ":", "\n", "        ", "super", "(", "ForwardAttentionWithTransition", ",", "self", ")", ".", "__init__", "(", "representation_dim", ",", "query_dim", ",", "memory_dim", ")", "\n", "self", ".", "_transition_agent", "=", "Linear", "(", "memory_dim", "+", "query_dim", "+", "decoder_output_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition.reset": [[141, 145], ["attention.ForwardAttention.reset"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition.reset"], ["", "def", "reset", "(", "self", ",", "encoded_input", ",", "batch_size", ",", "max_len", ")", ":", "\n", "        ", "super", "(", "ForwardAttentionWithTransition", ",", "self", ")", ".", "reset", "(", "encoded_input", ",", "batch_size", ",", "max_len", ")", "\n", "self", ".", "_t_prob", "=", "0.5", "\n", "return", "self", ".", "_prev_context", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition._attent": [[146, 150], ["attention.ForwardAttentionWithTransition._prepare_transition"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttention._prepare_transition"], ["", "def", "_attent", "(", "self", ",", "query", ",", "memory_transform", ",", "cum_weights", ")", ":", "\n", "        ", "energy", ",", "shifted_weights", "=", "self", ".", "_prepare_transition", "(", "query", ",", "memory_transform", ",", "self", ".", "_prev_weights", ")", "\n", "self", ".", "_prev_weights", "=", "(", "(", "1", "-", "self", ".", "_t_prob", ")", "*", "self", ".", "_prev_weights", "+", "self", ".", "_t_prob", "*", "shifted_weights", ")", "*", "energy", "\n", "return", "self", ".", "_prev_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition.forward": [[151, 157], ["attention.AttentionBase.forward", "torch.cat", "attention.ForwardAttentionWithTransition._transition_agent", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward"], ["", "def", "forward", "(", "self", ",", "query", ",", "memory", ",", "mask", ",", "prev_decoder_output", ")", ":", "\n", "        ", "context", ",", "weights", "=", "super", "(", "ForwardAttentionWithTransition", ",", "self", ")", ".", "forward", "(", "query", ",", "memory", ",", "mask", ",", "None", ")", "\n", "transtition_input", "=", "torch", ".", "cat", "(", "[", "self", ".", "_prev_context", ",", "query", ",", "prev_decoder_output", "]", ",", "dim", "=", "1", ")", "\n", "t_prob", "=", "self", ".", "_transition_agent", "(", "transtition_input", ")", "\n", "self", ".", "_t_prob", "=", "torch", ".", "sigmoid", "(", "t_prob", ")", "\n", "return", "context", ",", "weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Prenet.__init__": [[30, 37], ["super().__init__", "torch.nn.ReLU", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "Prenet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "num_layers", ">", "0", ",", "(", "'There must be at least one layer in the pre-net.'", ")", "\n", "self", ".", "_dropout_rate", "=", "dropout", "\n", "self", ".", "_activation", "=", "ReLU", "(", ")", "\n", "layers", "=", "[", "Linear", "(", "input_dim", ",", "output_dim", ")", "]", "+", "[", "Linear", "(", "output_dim", ",", "output_dim", ")", "for", "_", "in", "range", "(", "num_layers", "-", "1", ")", "]", "\n", "self", ".", "_layers", "=", "ModuleList", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Prenet._layer_pass": [[38, 43], ["layer", "tacotron2.Prenet._activation", "torch.nn.functional.dropout"], "methods", ["None"], ["", "def", "_layer_pass", "(", "self", ",", "x", ",", "layer", ")", ":", "\n", "        ", "x", "=", "layer", "(", "x", ")", "\n", "x", "=", "self", ".", "_activation", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "_dropout_rate", ",", "training", "=", "True", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Prenet.forward": [[44, 48], ["tacotron2.Prenet._layer_pass"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Prenet._layer_pass"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "_layers", ":", "\n", "            ", "x", "=", "self", ".", "_layer_pass", "(", "x", ",", "layer", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Postnet.__init__": [[64, 71], ["super().__init__", "torch.nn.Sequential", "modules.layers.ConvBlock", "modules.layers.ConvBlock", "modules.layers.ConvBlock", "range"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dimension", ",", "postnet_dimension", ",", "num_blocks", ",", "kernel_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "Postnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "num_blocks", ">", "1", ",", "(", "'There must be at least two convolutional blocks in the post-net.'", ")", "\n", "self", ".", "_convs", "=", "Sequential", "(", "\n", "ConvBlock", "(", "input_dimension", ",", "postnet_dimension", ",", "kernel_size", ",", "dropout", ",", "'tanh'", ")", ",", "\n", "*", "[", "ConvBlock", "(", "postnet_dimension", ",", "postnet_dimension", ",", "kernel_size", ",", "dropout", ",", "'tanh'", ")", "for", "_", "in", "range", "(", "num_blocks", "-", "2", ")", "]", ",", "\n", "ConvBlock", "(", "postnet_dimension", ",", "input_dimension", ",", "kernel_size", ",", "dropout", ",", "'identity'", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Postnet.forward": [[73, 78], ["tacotron2.Postnet._convs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lengths", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "x", "=", "self", ".", "_convs", "(", "x", ")", "\n", "x", "+=", "residual", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder.__init__": [[103, 126], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "tacotron2.Decoder._get_embedding", "tacotron2.Decoder._get_embedding", "len"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._get_embedding", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._get_embedding"], ["def", "__init__", "(", "self", ",", "output_dim", ",", "decoder_dim", ",", "attention", ",", "generator_rnn", ",", "attention_rnn", ",", "context_dim", ",", "prenet", ",", "prenet_dim", ",", "max_frames", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_prenet", "=", "prenet", "\n", "self", ".", "_attention", "=", "attention", "\n", "self", ".", "_output_dim", "=", "output_dim", "\n", "self", ".", "_decoder_dim", "=", "decoder_dim", "\n", "self", ".", "_max_frames", "=", "max_frames", "\n", "self", ".", "_attention_lstm", "=", "attention_rnn", "\n", "self", ".", "_generator_lstm", "=", "generator_rnn", "\n", "self", ".", "_frame_prediction", "=", "Linear", "(", "context_dim", "+", "decoder_dim", ",", "output_dim", ")", "\n", "self", ".", "_stop_prediction", "=", "Linear", "(", "context_dim", "+", "decoder_dim", ",", "1", ")", "\n", "\n", "if", "hp", ".", "use_replay", "and", "hp", ".", "dual_sampling", ":", "\n", "            ", "self", ".", "_frame_prediction_rrs", "=", "Linear", "(", "context_dim", "+", "decoder_dim", ",", "output_dim", ")", "\n", "self", ".", "_stop_prediction_rrs", "=", "Linear", "(", "context_dim", "+", "decoder_dim", ",", "1", ")", "\n", "\n", "", "self", ".", "_speaker_embedding", ",", "self", ".", "_language_embedding", "=", "None", ",", "None", "\n", "\n", "if", "hp", ".", "multi_speaker", "and", "hp", ".", "speaker_embedding_dimension", ">", "0", ":", "\n", "            ", "self", ".", "_speaker_embedding", "=", "self", ".", "_get_embedding", "(", "hp", ".", "speaker_embedding_dimension", ",", "hp", ".", "speaker_number", ")", "\n", "", "if", "hp", ".", "multi_language", "and", "hp", ".", "language_embedding_dimension", ">", "0", ":", "\n", "            ", "if", "not", "hp", ".", "one_hot_lang_emb", ":", "\n", "                ", "self", ".", "_language_embedding", "=", "self", ".", "_get_embedding", "(", "hp", ".", "language_embedding_dimension", ",", "len", "(", "hp", ".", "languages", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._get_embedding": [[127, 131], ["torch.nn.Embedding", "torch.nn.init.xavier_uniform_"], "methods", ["None"], ["", "", "", "def", "_get_embedding", "(", "self", ",", "embedding_dimension", ",", "size", "=", "None", ")", ":", "\n", "        ", "embedding", "=", "Embedding", "(", "size", ",", "embedding_dimension", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "embedding", ".", "weight", ")", "\n", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._target_init": [[132, 140], ["torch.zeros().unsqueeze", "tacotron2.Decoder.transpose", "torch.cat", "tacotron2.Decoder._prenet", "torch.zeros"], "methods", ["None"], ["", "def", "_target_init", "(", "self", ",", "target", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Prepend target spectrogram with a zero frame and pass it through pre-net.\"\"\"", "\n", "# the F.pad function has some issues: https://github.com/pytorch/pytorch/issues/13058", "\n", "first_frame", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_output_dim", ",", "device", "=", "target", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "target", "=", "target", ".", "transpose", "(", "1", ",", "2", ")", "# [B, F, N_MEL]", "\n", "target", "=", "torch", ".", "cat", "(", "(", "first_frame", ",", "target", ")", ",", "dim", "=", "1", ")", "\n", "target", "=", "self", ".", "_prenet", "(", "target", ")", "\n", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._decoder_init": [[141, 148], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_decoder_init", "(", "self", ",", "batch_size", ",", "device", ")", ":", "\n", "        ", "\"\"\"Initialize hidden and cell state of the deocder's RNNs.\"\"\"", "\n", "h_att", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_decoder_dim", ",", "device", "=", "device", ")", "\n", "c_att", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_decoder_dim", ",", "device", "=", "device", ")", "\n", "h_gen", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_decoder_dim", ",", "device", "=", "device", ")", "\n", "c_gen", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_decoder_dim", ",", "device", "=", "device", ")", "\n", "return", "h_att", ",", "c_att", ",", "h_gen", ",", "c_gen", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._add_conditional_embedding": [[149, 158], ["layer", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "_add_conditional_embedding", "(", "self", ",", "encoded", ",", "layer", ",", "condition", ",", "is_one_hot", "=", "False", ")", ":", "\n", "        ", "\"\"\"Compute speaker (lang.) embedding and concat it to the encoder output.\"\"\"", "\n", "if", "is_one_hot", "is", "False", ":", "\n", "# embedding table lookup by nn.Embedding", "\n", "            ", "embedded", "=", "layer", "(", "encoded", "if", "condition", "is", "None", "else", "condition", ")", "\n", "return", "torch", ".", "cat", "(", "(", "encoded", ",", "embedded", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "elif", "is_one_hot", "is", "True", ":", "\n", "# directly use one hot as embedding", "\n", "            ", "return", "torch", ".", "cat", "(", "(", "encoded", ",", "condition", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._decode": [[160, 226], ["tacotron2.Decoder.size", "tacotron2.Decoder.size", "tacotron2.Decoder._attention.reset", "tacotron2.Decoder._decoder_init", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "tacotron2.Decoder.size", "tacotron2.Decoder._add_conditional_embedding", "tacotron2.Decoder._add_conditional_embedding", "tacotron2.Decoder._target_init", "torch.cat", "tacotron2.Decoder._attention_lstm", "tacotron2.Decoder._attention", "torch.cat", "tacotron2.Decoder._generator_lstm", "torch.cat", "torch.zeros.squeeze", "torch.rand", "tacotron2.Decoder._prenet", "tacotron2.Decoder._frame_prediction_rrs", "tacotron2.Decoder._stop_prediction_rrs", "tacotron2.Decoder._frame_prediction", "tacotron2.Decoder._stop_prediction", "torch.sigmoid().ge", "torch.sigmoid", "stop_tokens[].squeeze"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.attention.ForwardAttentionWithTransition.reset", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._decoder_init", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._add_conditional_embedding", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._add_conditional_embedding", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._target_init"], ["", "", "def", "_decode", "(", "self", ",", "encoded_input", ",", "mask", ",", "target", ",", "teacher_forcing_ratio", ",", "speaker", ",", "language", ",", "is_rrs", "=", "False", ")", ":", "\n", "        ", "\"\"\"Perform decoding of the encoded input sequence.\"\"\"", "\n", "\n", "batch_size", "=", "encoded_input", ".", "size", "(", "0", ")", "\n", "max_length", "=", "encoded_input", ".", "size", "(", "1", ")", "\n", "inference", "=", "target", "is", "None", "\n", "max_frames", "=", "self", ".", "_max_frames", "if", "inference", "else", "target", ".", "size", "(", "2", ")", "\n", "input_device", "=", "encoded_input", ".", "device", "\n", "\n", "# obtain speaker and language embeddings (or a dummy tensor)", "\n", "if", "hp", ".", "multi_speaker", "and", "self", ".", "_speaker_embedding", "is", "not", "None", ":", "\n", "            ", "encoded_input", "=", "self", ".", "_add_conditional_embedding", "(", "encoded_input", ",", "self", ".", "_speaker_embedding", ",", "speaker", ")", "\n", "", "if", "hp", ".", "multi_language", ":", "\n", "            ", "encoded_input", "=", "self", ".", "_add_conditional_embedding", "(", "encoded_input", ",", "self", ".", "_language_embedding", ",", "language", ",", "hp", ".", "one_hot_lang_emb", ")", "\n", "\n", "# attention and decoder states initialization", "\n", "", "context", "=", "self", ".", "_attention", ".", "reset", "(", "encoded_input", ",", "batch_size", ",", "max_length", ",", "input_device", ")", "\n", "h_att", ",", "c_att", ",", "h_gen", ",", "c_gen", "=", "self", ".", "_decoder_init", "(", "batch_size", ",", "input_device", ")", "\n", "\n", "# prepare some inference or train specific variables (teacher forcing, max. predicted length)", "\n", "frame", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "_output_dim", ",", "device", "=", "input_device", ")", "\n", "if", "not", "inference", ":", "\n", "            ", "target", "=", "self", ".", "_target_init", "(", "target", ",", "batch_size", ")", "\n", "teacher", "=", "torch", ".", "rand", "(", "[", "max_frames", "]", ",", "device", "=", "input_device", ")", ">", "(", "1", "-", "teacher_forcing_ratio", ")", "\n", "\n", "# tensors for storing output", "\n", "", "spectrogram", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max_frames", ",", "self", ".", "_output_dim", ",", "device", "=", "input_device", ")", "\n", "alignments", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max_frames", ",", "max_length", ",", "device", "=", "input_device", ")", "\n", "stop_tokens", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max_frames", ",", "1", ",", "device", "=", "input_device", ")", "\n", "\n", "# decoding loop", "\n", "stop_frames", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "max_frames", ")", ":", "\n", "            ", "prev_frame", "=", "self", ".", "_prenet", "(", "frame", ")", "if", "inference", "or", "not", "teacher", "[", "i", "]", "else", "target", "[", ":", ",", "i", "]", "\n", "\n", "# run decoder attention and RNNs", "\n", "attention_input", "=", "torch", ".", "cat", "(", "(", "prev_frame", ",", "context", ")", ",", "dim", "=", "1", ")", "\n", "h_att", ",", "c_att", "=", "self", ".", "_attention_lstm", "(", "attention_input", ",", "h_att", ",", "c_att", ")", "\n", "context", ",", "weights", "=", "self", ".", "_attention", "(", "h_att", ",", "encoded_input", ",", "mask", ",", "prev_frame", ")", "\n", "generator_input", "=", "torch", ".", "cat", "(", "(", "h_att", ",", "context", ")", ",", "dim", "=", "1", ")", "\n", "h_gen", ",", "c_gen", "=", "self", ".", "_generator_lstm", "(", "generator_input", ",", "h_gen", ",", "c_gen", ")", "\n", "\n", "# predict frame and stop token", "\n", "proto_output", "=", "torch", ".", "cat", "(", "(", "h_gen", ",", "context", ")", ",", "dim", "=", "1", ")", "\n", "if", "is_rrs", ":", "\n", "                ", "frame", "=", "self", ".", "_frame_prediction_rrs", "(", "proto_output", ")", "\n", "stop_logits", "=", "self", ".", "_stop_prediction_rrs", "(", "proto_output", ")", "\n", "", "else", ":", "\n", "                ", "frame", "=", "self", ".", "_frame_prediction", "(", "proto_output", ")", "\n", "stop_logits", "=", "self", ".", "_stop_prediction", "(", "proto_output", ")", "\n", "\n", "# store outputs", "\n", "", "spectrogram", "[", ":", ",", "i", "]", "=", "frame", "\n", "alignments", "[", ":", ",", "i", "]", "=", "weights", "\n", "stop_tokens", "[", ":", ",", "i", "]", "=", "stop_logits", "\n", "\n", "# stop decoding if predicted (just during inference)", "\n", "if", "inference", "and", "torch", ".", "sigmoid", "(", "stop_logits", ")", ".", "ge", "(", "0.5", ")", ":", "\n", "                ", "if", "stop_frames", "==", "-", "1", ":", "\n", "                    ", "stop_frames", "=", "hp", ".", "stop_frames", "\n", "continue", "\n", "", "stop_frames", "-=", "1", "\n", "if", "stop_frames", "==", "0", ":", "\n", "                    ", "return", "spectrogram", "[", ":", ",", ":", "i", "+", "1", "]", ",", "stop_tokens", "[", ":", ",", ":", "i", "+", "1", "]", ".", "squeeze", "(", "2", ")", ",", "alignments", "[", ":", ",", ":", "i", "+", "1", "]", "\n", "\n", "", "", "", "return", "spectrogram", ",", "stop_tokens", ".", "squeeze", "(", "2", ")", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder.forward": [[227, 231], ["encoded_input.size", "utils.lengths_to_mask", "tacotron2.Decoder._decode"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._decode"], ["", "def", "forward", "(", "self", ",", "encoded_input", ",", "encoded_lenghts", ",", "target", ",", "teacher_forcing_ratio", ",", "speaker", ",", "language", ",", "is_rrs", "=", "False", ")", ":", "\n", "        ", "ml", "=", "encoded_input", ".", "size", "(", "1", ")", "\n", "mask", "=", "utils", ".", "lengths_to_mask", "(", "encoded_lenghts", ",", "max_length", "=", "ml", ")", "\n", "return", "self", ".", "_decode", "(", "encoded_input", ",", "mask", ",", "target", ",", "teacher_forcing_ratio", ",", "speaker", ",", "language", ",", "is_rrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder.inference": [[232, 236], ["utils.lengths_to_mask", "tacotron2.Decoder._decode", "torch.LongTensor", "encoded_input.size"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Decoder._decode"], ["", "def", "inference", "(", "self", ",", "encoded_input", ",", "speaker", ",", "language", ")", ":", "\n", "        ", "mask", "=", "utils", ".", "lengths_to_mask", "(", "torch", ".", "LongTensor", "(", "[", "encoded_input", ".", "size", "(", "1", ")", "]", ")", ")", "\n", "spectrogram", ",", "_", ",", "_", "=", "self", ".", "_decode", "(", "encoded_input", ",", "mask", ",", "None", ",", "0.0", ",", "speaker", ",", "language", ",", "is_rrs", "=", "False", ")", "\n", "return", "spectrogram", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron.__init__": [[248, 306], ["super().__init__", "torch.nn.Embedding", "torch.nn.init.xavier_uniform_", "tacotron2.Tacotron._get_encoder", "tacotron2.Prenet", "tacotron2.Tacotron._get_attention", "tacotron2.Decoder", "tacotron2.Tacotron._get_postnet", "tacotron2.Tacotron._get_adversarial_classifier", "modules.layers.ZoneoutLSTMCell", "modules.layers.ZoneoutLSTMCell", "modules.layers.DropoutLSTMCell", "modules.layers.DropoutLSTMCell", "params.params.Params.symbols_count", "tacotron2.Tacotron._get_postnet"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_encoder", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_attention", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_postnet", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_adversarial_classifier", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.symbols_count", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_postnet"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Tacotron", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Encoder embedding", "\n", "other_symbols", "=", "3", "# PAD, EOS, UNK", "\n", "self", ".", "_embedding", "=", "Embedding", "(", "hp", ".", "symbols_count", "(", ")", "+", "other_symbols", ",", "\n", "hp", ".", "embedding_dimension", ",", "padding_idx", "=", "0", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_embedding", ".", "weight", ")", "\n", "\n", "# Encoder transforming graphmenes or phonemes into abstract input representation", "\n", "self", ".", "_encoder", "=", "self", ".", "_get_encoder", "(", "hp", ".", "encoder_type", ")", "\n", "\n", "# Reversal language classifier to make encoder truly languagge independent", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "self", ".", "_reversal_classifier", "=", "self", ".", "_get_adversarial_classifier", "(", "hp", ".", "reversal_classifier_type", ")", "\n", "\n", "# Prenet for transformation of previous predicted frame", "\n", "", "self", ".", "_prenet", "=", "Prenet", "(", "hp", ".", "num_mels", ",", "hp", ".", "prenet_dimension", ",", "hp", ".", "prenet_layers", ",", "hp", ".", "dropout", ")", "\n", "\n", "# Speaker and language embeddings make decoder bigger", "\n", "decoder_input_dimension", "=", "hp", ".", "encoder_dimension", "\n", "if", "hp", ".", "multi_speaker", ":", "\n", "            ", "decoder_input_dimension", "+=", "hp", ".", "speaker_embedding_dimension", "\n", "", "if", "hp", ".", "multi_language", ":", "\n", "            ", "decoder_input_dimension", "+=", "hp", ".", "language_embedding_dimension", "\n", "\n", "# Decoder attention layer", "\n", "", "self", ".", "_attention", "=", "self", ".", "_get_attention", "(", "hp", ".", "attention_type", ",", "decoder_input_dimension", ")", "\n", "\n", "# Instantiate decoder RNN layers", "\n", "gen_cell_dimension", "=", "decoder_input_dimension", "+", "hp", ".", "decoder_dimension", "\n", "att_cell_dimension", "=", "decoder_input_dimension", "+", "hp", ".", "prenet_dimension", "\n", "if", "hp", ".", "decoder_regularization", "==", "'zoneout'", ":", "\n", "            ", "generator_rnn", "=", "ZoneoutLSTMCell", "(", "gen_cell_dimension", ",", "hp", ".", "decoder_dimension", ",", "hp", ".", "zoneout_hidden", ",", "hp", ".", "zoneout_cell", ")", "\n", "attention_rnn", "=", "ZoneoutLSTMCell", "(", "att_cell_dimension", ",", "hp", ".", "decoder_dimension", ",", "hp", ".", "zoneout_hidden", ",", "hp", ".", "zoneout_cell", ")", "\n", "", "else", ":", "\n", "            ", "generator_rnn", "=", "DropoutLSTMCell", "(", "gen_cell_dimension", ",", "hp", ".", "decoder_dimension", ",", "hp", ".", "dropout_hidden", ")", "\n", "attention_rnn", "=", "DropoutLSTMCell", "(", "att_cell_dimension", ",", "hp", ".", "decoder_dimension", ",", "hp", ".", "dropout_hidden", ")", "\n", "\n", "# Decoder which controls attention and produces mel frames and stop tokens", "\n", "", "self", ".", "_decoder", "=", "Decoder", "(", "\n", "hp", ".", "num_mels", ",", "\n", "hp", ".", "decoder_dimension", ",", "\n", "self", ".", "_attention", ",", "\n", "generator_rnn", ",", "\n", "attention_rnn", ",", "\n", "decoder_input_dimension", ",", "\n", "self", ".", "_prenet", ",", "\n", "hp", ".", "prenet_dimension", ",", "\n", "hp", ".", "max_output_length", ")", "\n", "\n", "# Postnet transforming predicted mel frames (residual mel or linear frames)", "\n", "self", ".", "_postnet", "=", "self", ".", "_get_postnet", "(", "\"cbhg\"", "if", "hp", ".", "predict_linear", "else", "\"conv\"", ")", "\n", "try", ":", "\n", "            ", "if", "hp", ".", "unique_postnet", ":", "\n", "                ", "self", ".", "_postnet_rrs", "=", "self", ".", "_get_postnet", "(", "\"cbhg\"", "if", "hp", ".", "predict_linear", "else", "\"conv\"", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_encoder": [[308, 326], ["modules.encoder.Encoder", "modules.encoder.MultiEncoder", "modules.encoder.ConditionalEncoder", "modules.encoder.ConvolutionalEncoder", "modules.encoder.GeneratedConvolutionalEncoder"], "methods", ["None"], ["", "", "def", "_get_encoder", "(", "self", ",", "name", ")", ":", "\n", "        ", "args", "=", "(", "hp", ".", "embedding_dimension", ",", "\n", "hp", ".", "encoder_dimension", ",", "\n", "hp", ".", "encoder_blocks", ",", "\n", "hp", ".", "encoder_kernel_size", ",", "\n", "hp", ".", "dropout", ")", "\n", "ln", "=", "1", "if", "not", "hp", ".", "multi_language", "else", "hp", ".", "language_number", "\n", "if", "name", "==", "\"simple\"", ":", "\n", "            ", "return", "Encoder", "(", "*", "args", ")", "\n", "", "elif", "name", "==", "\"separate\"", ":", "\n", "            ", "return", "MultiEncoder", "(", "hp", ".", "language_number", ",", "args", ")", "\n", "", "elif", "name", "==", "\"shared\"", ":", "\n", "            ", "return", "ConditionalEncoder", "(", "hp", ".", "language_number", ",", "hp", ".", "input_language_embedding", ",", "args", ")", "\n", "", "elif", "name", "==", "\"convolutional\"", ":", "\n", "            ", "return", "ConvolutionalEncoder", "(", "hp", ".", "embedding_dimension", ",", "hp", ".", "encoder_dimension", ",", "0.05", ",", "ln", ")", "\n", "", "elif", "name", "==", "\"generated\"", ":", "\n", "            ", "return", "GeneratedConvolutionalEncoder", "(", "hp", ".", "embedding_dimension", ",", "hp", ".", "encoder_dimension", ",", "0.05", ",", "\n", "hp", ".", "generator_dim", ",", "hp", ".", "generator_bottleneck_dim", ",", "groups", "=", "ln", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_adversarial_classifier": [[327, 339], ["modules.classifier.ReversalClassifier", "modules.classifier.CosineSimilarityClassifier"], "methods", ["None"], ["", "", "def", "_get_adversarial_classifier", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "==", "\"reversal\"", ":", "\n", "            ", "return", "ReversalClassifier", "(", "\n", "hp", ".", "encoder_dimension", ",", "\n", "hp", ".", "reversal_classifier_dim", ",", "\n", "hp", ".", "speaker_number", ",", "\n", "hp", ".", "reversal_gradient_clipping", ")", "\n", "", "elif", "name", "==", "\"cosine\"", ":", "\n", "            ", "return", "CosineSimilarityClassifier", "(", "\n", "hp", ".", "encoder_dimension", ",", "\n", "hp", ".", "speaker_number", ",", "\n", "hp", ".", "reversal_gradient_clipping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_attention": [[340, 356], ["modules.attention.LocationSensitiveAttention", "modules.attention.ForwardAttention", "modules.attention.ForwardAttentionWithTransition"], "methods", ["None"], ["", "", "def", "_get_attention", "(", "self", ",", "name", ",", "memory_dimension", ")", ":", "\n", "        ", "args", "=", "(", "hp", ".", "attention_dimension", ",", "\n", "hp", ".", "decoder_dimension", ",", "\n", "memory_dimension", ")", "\n", "if", "name", "==", "\"location_sensitive\"", ":", "\n", "            ", "return", "LocationSensitiveAttention", "(", "\n", "hp", ".", "attention_kernel_size", ",", "\n", "hp", ".", "attention_location_dimension", ",", "\n", "False", ",", "\n", "*", "args", ")", "\n", "", "elif", "name", "==", "\"forward\"", ":", "\n", "            ", "return", "ForwardAttention", "(", "*", "args", ")", "\n", "", "elif", "name", "==", "\"forward_transition_agent\"", ":", "\n", "            ", "return", "ForwardAttentionWithTransition", "(", "\n", "hp", ".", "prenet_dimension", ",", "\n", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron._get_postnet": [[357, 376], ["modules.cbhg.PostnetCBHG", "tacotron2.Postnet"], "methods", ["None"], ["", "", "def", "_get_postnet", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "==", "\"cbhg\"", ":", "\n", "            ", "return", "PostnetCBHG", "(", "\n", "hp", ".", "num_mels", ",", "\n", "hp", ".", "num_fft", "//", "2", "+", "1", ",", "\n", "hp", ".", "cbhg_bank_kernels", ",", "\n", "hp", ".", "cbhg_bank_dimension", ",", "\n", "hp", ".", "cbhg_projection_dimension", ",", "\n", "hp", ".", "cbhg_projection_kernel_size", ",", "\n", "hp", ".", "cbhg_highway_dimension", ",", "\n", "hp", ".", "cbhg_rnn_dim", ",", "\n", "hp", ".", "cbhg_dropout", ")", "\n", "", "elif", "name", "==", "\"conv\"", ":", "\n", "            ", "return", "Postnet", "(", "\n", "hp", ".", "num_mels", ",", "\n", "hp", ".", "postnet_dimension", ",", "\n", "hp", ".", "postnet_blocks", ",", "\n", "hp", ".", "postnet_kernel_size", ",", "\n", "hp", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron.forward": [[377, 416], ["tacotron2.Tacotron._embedding", "tacotron2.Tacotron._encoder", "tacotron2.Tacotron._decoder", "prediction.transpose", "utils.lengths_to_mask", "stop_token.masked_fill_", "target_mask.unsqueeze().float.unsqueeze().float.unsqueeze().float", "speakers.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.argmax.unsqueeze().expand", "tacotron2.Tacotron._reversal_classifier", "tacotron2.Tacotron._postnet_rrs", "tacotron2.Tacotron._postnet", "target.size", "speakers.unsqueeze().expand.unsqueeze().expand.dim", "torch.argmax.dim", "torch.argmax", "target_mask.unsqueeze().float.unsqueeze().float.unsqueeze", "speakers.unsqueeze().expand.unsqueeze().expand.unsqueeze", "text.size", "torch.argmax.unsqueeze", "text.size", "torch.argmax.dim"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.utils.__init__.lengths_to_mask"], ["", "", "def", "forward", "(", "self", ",", "text", ",", "text_length", ",", "target", ",", "target_length", ",", "speakers", ",", "languages", ",", "teacher_forcing_ratio", "=", "0.0", ",", "is_rrs", "=", "False", ")", ":", "\n", "\n", "\n", "# enlarge speakers and languages to match sentence length if needed", "\n", "        ", "if", "speakers", "is", "not", "None", "and", "speakers", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "speakers", "=", "speakers", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "text", ".", "size", "(", "1", ")", ")", ")", "\n", "", "if", "languages", "is", "not", "None", "and", "languages", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "languages", "=", "languages", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "text", ".", "size", "(", "1", ")", ")", ")", "\n", "\n", "# encode input", "\n", "", "embedded", "=", "self", ".", "_embedding", "(", "text", ")", "\n", "encoded", "=", "self", ".", "_encoder", "(", "embedded", ",", "text_length", ",", "languages", ")", "\n", "encoder_output", "=", "encoded", "\n", "\n", "# predict language as an adversarial task if needed", "\n", "speaker_prediction", "=", "self", ".", "_reversal_classifier", "(", "encoded", ")", "if", "hp", ".", "reversal_classifier", "else", "None", "\n", "\n", "# decode", "\n", "if", "not", "hp", ".", "one_hot_lang_emb", ":", "\n", "# when using emb table lookup, need to assure that languages is ints", "\n", "# so that can use the emb table inside decoder", "\n", "            ", "if", "languages", "is", "not", "None", "and", "languages", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "languages", "=", "torch", ".", "argmax", "(", "languages", ",", "dim", "=", "2", ")", "# convert one-hot into indices", "\n", "", "", "decoded", "=", "self", ".", "_decoder", "(", "encoded", ",", "text_length", ",", "target", ",", "teacher_forcing_ratio", ",", "speakers", ",", "languages", ",", "is_rrs", ")", "\n", "prediction", ",", "stop_token", ",", "alignment", "=", "decoded", "\n", "pre_prediction", "=", "prediction", ".", "transpose", "(", "1", ",", "2", ")", "\n", "if", "is_rrs", "and", "hp", ".", "unique_postnet", ":", "\n", "            ", "post_prediction", "=", "self", ".", "_postnet_rrs", "(", "pre_prediction", ",", "target_length", ")", "\n", "", "else", ":", "\n", "            ", "post_prediction", "=", "self", ".", "_postnet", "(", "pre_prediction", ",", "target_length", ")", "\n", "\n", "# mask output paddings", "\n", "", "target_mask", "=", "utils", ".", "lengths_to_mask", "(", "target_length", ",", "target", ".", "size", "(", "2", ")", ")", "\n", "stop_token", ".", "masked_fill_", "(", "~", "target_mask", ",", "1000", ")", "\n", "target_mask", "=", "target_mask", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "pre_prediction", "=", "pre_prediction", "*", "target_mask", "\n", "post_prediction", "=", "post_prediction", "*", "target_mask", "\n", "\n", "return", "post_prediction", ",", "pre_prediction", ",", "stop_token", ",", "alignment", ",", "speaker_prediction", ",", "encoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron.inference": [[417, 442], ["text.unsqueeze_", "tacotron2.Tacotron._embedding", "tacotron2.Tacotron._encoder", "tacotron2.Tacotron._decoder.inference", "prediction.transpose.transpose.transpose", "tacotron2.Tacotron._postnet", "tacotron2.Tacotron.squeeze", "speaker.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.argmax.unsqueeze().expand", "torch.LongTensor", "torch.LongTensor", "speaker.unsqueeze().expand.unsqueeze().expand.dim", "torch.argmax.dim", "torch.argmax", "speaker.unsqueeze().expand.unsqueeze().expand.unsqueeze", "text.size", "torch.argmax.unsqueeze", "text.size", "text.size", "torch.argmax.dim", "prediction.transpose.transpose.size"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.Tacotron.inference"], ["", "def", "inference", "(", "self", ",", "text", ",", "speaker", "=", "None", ",", "language", "=", "None", ")", ":", "\n", "# pretend having a batch of size 1", "\n", "        ", "text", ".", "unsqueeze_", "(", "0", ")", "\n", "\n", "if", "speaker", "is", "not", "None", "and", "speaker", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "speaker", "=", "speaker", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "text", ".", "size", "(", "1", ")", ")", ")", "\n", "", "if", "language", "is", "not", "None", "and", "language", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "language", "=", "language", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "-", "1", ",", "text", ".", "size", "(", "1", ")", ")", ")", "\n", "\n", "# encode input", "\n", "", "embedded", "=", "self", ".", "_embedding", "(", "text", ")", "\n", "encoded", "=", "self", ".", "_encoder", "(", "embedded", ",", "torch", ".", "LongTensor", "(", "[", "text", ".", "size", "(", "1", ")", "]", ")", ",", "language", ")", "\n", "\n", "# decode with respect to speaker and language embeddings", "\n", "if", "not", "hp", ".", "one_hot_lang_emb", ":", "\n", "# when using emb table lookup, need to assure that languages is ints", "\n", "# so that can use the emb table inside decoder", "\n", "            ", "if", "language", "is", "not", "None", "and", "language", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "language", "=", "torch", ".", "argmax", "(", "language", ",", "dim", "=", "2", ")", "# convert one-hot into indices", "\n", "", "", "prediction", "=", "self", ".", "_decoder", ".", "inference", "(", "encoded", ",", "speaker", ",", "language", ")", "\n", "\n", "# post process generated spectrogram", "\n", "prediction", "=", "prediction", ".", "transpose", "(", "1", ",", "2", ")", "\n", "post_prediction", "=", "self", ".", "_postnet", "(", "prediction", ",", "torch", ".", "LongTensor", "(", "[", "prediction", ".", "size", "(", "2", ")", "]", ")", ")", "\n", "return", "post_prediction", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.__init__": [[460, 465], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "guided_att_steps", ",", "guided_att_variance", ",", "guided_att_gamma", ")", ":", "\n", "        ", "super", "(", "TacotronLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_g", "=", "guided_att_variance", "\n", "self", ".", "_gamma", "=", "guided_att_gamma", "\n", "self", ".", "_g_steps", "=", "guided_att_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.load_state_dict": [[466, 468], ["d.items", "setattr"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "d", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.state_dict": [[469, 471], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"_g\"", ":", "self", ".", "_g", ",", "\"_g_steps\"", ":", "self", ".", "_g_steps", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.update_states": [[472, 475], ["max"], "methods", ["None"], ["", "def", "update_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "_g", "*=", "self", ".", "_gamma", "\n", "self", ".", "_g_steps", "=", "max", "(", "0", ",", "self", ".", "_g_steps", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss._guided_attention": [[476, 491], ["torch.zeros_like", "enumerate", "torch.sum", "torch.mean", "zip", "torch.meshgrid", "torch.arange", "torch.arange", "torch.exp", "target_lengths.float"], "methods", ["None"], ["", "def", "_guided_attention", "(", "self", ",", "alignments", ",", "input_lengths", ",", "target_lengths", ")", ":", "\n", "        ", "if", "self", ".", "_g_steps", "==", "0", ":", "return", "0", "\n", "input_device", "=", "alignments", ".", "device", "\n", "\n", "# compute guided attention weights (diagonal matrix with zeros on a 'blurry' diagonal)", "\n", "weights", "=", "torch", ".", "zeros_like", "(", "alignments", ")", "\n", "for", "i", ",", "(", "f", ",", "l", ")", "in", "enumerate", "(", "zip", "(", "target_lengths", ",", "input_lengths", ")", ")", ":", "\n", "            ", "grid_f", ",", "grid_l", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "f", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_device", ")", ",", "torch", ".", "arange", "(", "l", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_device", ")", ")", "\n", "weights", "[", "i", ",", ":", "f", ",", ":", "l", "]", "=", "1", "-", "torch", ".", "exp", "(", "-", "(", "grid_l", "/", "l", "-", "grid_f", "/", "f", ")", "**", "2", "/", "(", "2", "*", "self", ".", "_g", "**", "2", ")", ")", "\n", "\n", "# apply weights and compute mean loss", "\n", "", "loss", "=", "torch", ".", "sum", "(", "weights", "*", "alignments", ",", "dim", "=", "(", "1", ",", "2", ")", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", "/", "target_lengths", ".", "float", "(", ")", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss.forward": [[492, 519], ["torch.tensor", "torch.nn.functional.mse_loss", "tacotron2.TacotronLoss._guided_attention", "sum", "torch.nn.functional.mse_loss", "torch.nn.functional.binary_cross_entropy_with_logits", "modules.classifier.ReversalClassifier.loss", "losses.values", "modules.classifier.CosineSimilarityClassifier.loss"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss._guided_attention", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.loss", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.loss"], ["", "def", "forward", "(", "self", ",", "source_length", ",", "target_length", ",", "pre_prediction", ",", "pre_target", ",", "post_prediction", ",", "post_target", ",", "stop", ",", "target_stop", ",", "alignment", ",", "\n", "speaker", ",", "speaker_prediction", ",", "encoder_outputs", ",", "classifier", ")", ":", "\n", "        ", "pre_target", ".", "requires_grad", "=", "False", "\n", "post_target", ".", "requires_grad", "=", "False", "\n", "target_stop", ".", "requires_grad", "=", "False", "\n", "\n", "# standard Tacotron 2 loss, not the emphasis on mel_pre and the mask and weighting of positive class of stop_token", "\n", "stop_balance", "=", "torch", ".", "tensor", "(", "[", "100", "]", ",", "device", "=", "stop", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "losses", "=", "{", "\n", "'mel_pre'", ":", "2", "*", "F", ".", "mse_loss", "(", "pre_prediction", ",", "pre_target", ")", ",", "\n", "'mel_pos'", ":", "F", ".", "mse_loss", "(", "post_prediction", ",", "post_target", ")", ",", "\n", "'stop_token'", ":", "F", ".", "binary_cross_entropy_with_logits", "(", "stop", ",", "target_stop", ",", "pos_weight", "=", "stop_balance", ")", "/", "(", "hp", ".", "num_mels", "+", "2", ")", ",", "\n", "}", "\n", "\n", "# loss of the adversarial classifier, if exists", "\n", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "if", "hp", ".", "reversal_classifier_type", "==", "\"reversal\"", ":", "\n", "                ", "losses", "[", "'lang_class'", "]", "=", "ReversalClassifier", ".", "loss", "(", "source_length", ",", "speaker", ",", "speaker_prediction", ")", "\n", "", "elif", "hp", ".", "reversal_classifier_type", "==", "\"cosine\"", ":", "\n", "                ", "losses", "[", "'lang_class'", "]", "=", "CosineSimilarityClassifier", ".", "loss", "(", "source_length", ",", "speaker", ",", "speaker_prediction", ",", "encoder_outputs", ",", "classifier", ")", "\n", "", "losses", "[", "'lang_class'", "]", "*=", "hp", ".", "reversal_classifier_w", "/", "(", "hp", ".", "num_mels", "+", "2", ")", "\n", "\n", "# guided attention loss", "\n", "", "if", "hp", ".", "guided_attention_loss", ":", "\n", "            ", "losses", "[", "'guided_att'", "]", "=", "self", ".", "_guided_attention", "(", "alignment", ",", "source_length", ",", "target_length", ")", "\n", "\n", "", "return", "sum", "(", "losses", ".", "values", "(", ")", ")", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss_kd.__init__": [[526, 533], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "kd_stop_token", "=", "True", ",", "kd_attention", "=", "True", ")", ":", "\n", "        ", "super", "(", "TacotronLoss_kd", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# self._g = guided_att_variance", "\n", "# self._gamma = guided_att_gamma", "\n", "# self._g_steps = guided_att_steps", "\n", "self", ".", "kd_stop_token", "=", "kd_stop_token", "\n", "self", ".", "kd_attention", "=", "kd_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss_kd.attention_kd": [[544, 562], ["torch.nn.functional.mse_loss"], "methods", ["None"], ["", "def", "attention_kd", "(", "self", ",", "alignments", ",", "alignments_tchr", ")", ":", "\n", "# if self._g_steps == 0: return 0", "\n", "# input_device = alignments.device", "\n", "\n", "# # compute guided attention weights (diagonal matrix with zeros on a 'blurry' diagonal)", "\n", "# weights = torch.zeros_like(alignments)", "\n", "# for i, (f, l) in enumerate(zip(target_lengths, input_lengths)):", "\n", "#     grid_f, grid_l = torch.meshgrid(torch.arange(f, dtype=torch.float, device=input_device), torch.arange(l, dtype=torch.float, device=input_device))", "\n", "#     weights[i, :f, :l] = 1 - torch.exp(-(grid_l/l - grid_f/f)**2 / (2 * self._g ** 2))", "\n", "\n", "# # apply weights and compute mean loss", "\n", "# loss = torch.sum(weights * alignments, dim=(1,2))", "\n", "# loss = torch.mean(loss / target_lengths.float())", "\n", "\n", "# MSE loss between Teacher-generated alignments and Student-generated alignments", "\n", "        ", "loss", "=", "F", ".", "mse_loss", "(", "alignments", ",", "alignments_tchr", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss_kd.forward": [[563, 596], ["pre_tchr.detach.detach.detach", "post_tchr.detach.detach.detach", "stop_tchr.detach.detach.detach", "alignment_tchr.detach.detach.detach", "torch.nn.functional.mse_loss", "losses.update", "tacotron2.TacotronLoss_kd.attention_kd", "sum", "torch.nn.functional.mse_loss", "modules.classifier.ReversalClassifier.loss", "losses.values", "modules.classifier.CosineSimilarityClassifier.loss", "torch.nn.functional.mse_loss"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.tacotron2.TacotronLoss_kd.attention_kd", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.loss", "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.loss"], ["", "def", "forward", "(", "self", ",", "source_length", ",", "target_length", ",", "pre_prediction", ",", "pre_tchr", ",", "post_prediction", ",", "post_tchr", ",", "stop", ",", "stop_tchr", ",", "alignment", ",", "alignment_tchr", ",", "\n", "speaker", ",", "speaker_prediction", ",", "encoder_outputs", ",", "classifier", ")", ":", "\n", "# pre_tchr.requires_grad = False", "\n", "# post_tchr.requires_grad = False", "\n", "# stop_tchr.requires_grad = False", "\n", "\n", "        ", "pre_tchr", "=", "pre_tchr", ".", "detach", "(", ")", "\n", "post_tchr", "=", "post_tchr", ".", "detach", "(", ")", "\n", "stop_tchr", "=", "stop_tchr", ".", "detach", "(", ")", "\n", "alignment_tchr", "=", "alignment_tchr", ".", "detach", "(", ")", "\n", "\n", "# standard Tacotron 2 loss, not the emphasis on mel_pre and the mask and weighting of positive class of stop_token", "\n", "# stop_balance = torch.tensor([100], device=stop.device, dtype=torch.float32)", "\n", "losses", "=", "{", "\n", "'mel_pre'", ":", "2", "*", "F", ".", "mse_loss", "(", "pre_prediction", ",", "pre_tchr", ")", ",", "\n", "'mel_pos'", ":", "F", ".", "mse_loss", "(", "post_prediction", ",", "post_tchr", ")", ",", "\n", "}", "\n", "if", "self", ".", "kd_stop_token", ":", "\n", "            ", "losses", ".", "update", "(", "{", "'stop_token'", ":", "F", ".", "mse_loss", "(", "stop", ",", "stop_tchr", ")", "/", "(", "hp", ".", "num_mels", "+", "2", ")", "}", ")", "\n", "\n", "# loss of the adversarial classifier, if exists", "\n", "", "if", "hp", ".", "reversal_classifier", ":", "\n", "            ", "if", "hp", ".", "reversal_classifier_type", "==", "\"reversal\"", ":", "\n", "                ", "losses", "[", "'lang_class'", "]", "=", "ReversalClassifier", ".", "loss", "(", "source_length", ",", "speaker", ",", "speaker_prediction", ")", "\n", "", "elif", "hp", ".", "reversal_classifier_type", "==", "\"cosine\"", ":", "\n", "                ", "losses", "[", "'lang_class'", "]", "=", "CosineSimilarityClassifier", ".", "loss", "(", "source_length", ",", "speaker", ",", "speaker_prediction", ",", "encoder_outputs", ",", "classifier", ")", "\n", "", "losses", "[", "'lang_class'", "]", "*=", "hp", ".", "reversal_classifier_w", "/", "(", "hp", ".", "num_mels", "+", "2", ")", "\n", "\n", "# guided attention loss", "\n", "", "if", "self", ".", "kd_attention", ":", "\n", "            ", "losses", "[", "'kd_att'", "]", "=", "self", ".", "attention_kd", "(", "alignment", ",", "alignment_tchr", ")", "\n", "\n", "", "return", "sum", "(", "losses", ".", "values", "(", ")", ")", ",", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.generated.Conv1dGenerated.__init__": [[16, 33], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "bottleneck_dim", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "Conv1dGenerated", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_in_channels", "=", "in_channels", "\n", "self", ".", "_out_channels", "=", "out_channels", "\n", "self", ".", "_kernel_size", "=", "kernel_size", "\n", "self", ".", "_stride", "=", "stride", "\n", "self", ".", "_padding", "=", "padding", "\n", "self", ".", "_dilation", "=", "dilation", "\n", "self", ".", "_groups", "=", "groups", "\n", "\n", "# in_channels and out_channels is divisible by groups", "\n", "# tf.nn.functional.conv1d accepts weights of shape [out_channels, in_channels // groups, kernel] ", "\n", "\n", "self", ".", "_bottleneck", "=", "Linear", "(", "embedding_dim", ",", "bottleneck_dim", ")", "\n", "self", ".", "_kernel", "=", "Linear", "(", "bottleneck_dim", ",", "out_channels", "//", "groups", "*", "in_channels", "//", "groups", "*", "kernel_size", ")", "\n", "self", ".", "_bias", "=", "Linear", "(", "bottleneck_dim", ",", "out_channels", "//", "groups", ")", "if", "bias", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.generated.Conv1dGenerated.forward": [[34, 43], ["generated.Conv1dGenerated._bottleneck", "generated.Conv1dGenerated._kernel().view", "torch.nn.functional.conv1d", "torch.nn.functional.conv1d", "generated.Conv1dGenerated._bias().view", "generated.Conv1dGenerated._kernel", "generated.Conv1dGenerated._bias"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "generator_embedding", ",", "x", ")", ":", "\n", "\n", "        ", "assert", "generator_embedding", ".", "shape", "[", "0", "]", "==", "self", ".", "_groups", ",", "(", "'Number of groups of a convolutional layer must match the number of generators.'", ")", "\n", "\n", "e", "=", "self", ".", "_bottleneck", "(", "generator_embedding", ")", "\n", "kernel", "=", "self", ".", "_kernel", "(", "e", ")", ".", "view", "(", "self", ".", "_out_channels", ",", "self", ".", "_in_channels", "//", "self", ".", "_groups", ",", "self", ".", "_kernel_size", ")", "\n", "bias", "=", "self", ".", "_bias", "(", "e", ")", ".", "view", "(", "self", ".", "_out_channels", ")", "if", "self", ".", "_bias", "else", "None", "\n", "\n", "return", "F", ".", "conv1d", "(", "x", ",", "kernel", ",", "bias", ",", "self", ".", "_stride", ",", "self", ".", "_padding", ",", "self", ".", "_dilation", ",", "self", ".", "_groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.generated.BatchNorm1dGenerated.__init__": [[56, 70], ["super().__init__", "generated.BatchNorm1dGenerated.register_buffer", "generated.BatchNorm1dGenerated.register_buffer", "generated.BatchNorm1dGenerated.register_buffer", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "bottleneck_dim", ",", "num_features", ",", "groups", "=", "1", ",", "eps", "=", "1e-8", ",", "momentum", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "BatchNorm1dGenerated", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'num_batches_tracked'", ",", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n", "self", ".", "_num_features", "=", "num_features", "//", "groups", "\n", "self", ".", "_eps", "=", "eps", "\n", "self", ".", "_momentum", "=", "momentum", "\n", "self", ".", "_groups", "=", "groups", "\n", "\n", "self", ".", "_bottleneck", "=", "Linear", "(", "embedding_dim", ",", "bottleneck_dim", ")", "\n", "self", ".", "_affine", "=", "Linear", "(", "bottleneck_dim", ",", "self", ".", "_num_features", "+", "self", ".", "_num_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.generated.BatchNorm1dGenerated.forward": [[71, 97], ["generated.BatchNorm1dGenerated._bottleneck", "generated.BatchNorm1dGenerated._affine", "affine[].contiguous().view", "affine[].contiguous().view", "torch.nn.functional.batch_norm", "torch.nn.functional.batch_norm", "affine[].contiguous", "affine[].contiguous", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "generator_embedding", ",", "x", ")", ":", "\n", "\n", "        ", "assert", "generator_embedding", ".", "shape", "[", "0", "]", "==", "self", ".", "_groups", ",", "(", "\n", "'Number of groups of a batchnorm layer must match the number of generators.'", ")", "\n", "\n", "if", "self", ".", "_momentum", "is", "None", ":", "\n", "            ", "exponential_average_factor", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "exponential_average_factor", "=", "self", ".", "_momentum", "\n", "\n", "", "e", "=", "self", ".", "_bottleneck", "(", "generator_embedding", ")", "\n", "affine", "=", "self", ".", "_affine", "(", "e", ")", "\n", "scale", "=", "affine", "[", ":", ",", ":", "self", ".", "_num_features", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "bias", "=", "affine", "[", ":", ",", "self", ".", "_num_features", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "self", ".", "num_batches_tracked", "is", "not", "None", ":", "\n", "                ", "self", ".", "num_batches_tracked", "+=", "1", "\n", "if", "self", ".", "_momentum", "is", "None", ":", "\n", "                    ", "exponential_average_factor", "=", "1.0", "/", "float", "(", "self", ".", "num_batches_tracked", ")", "\n", "", "else", ":", "\n", "                    ", "exponential_average_factor", "=", "self", ".", "_momentum", "\n", "\n", "", "", "", "return", "F", ".", "batch_norm", "(", "\n", "x", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "scale", ",", "bias", ",", "\n", "self", ".", "training", ",", "exponential_average_factor", ",", "self", ".", "_eps", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientReversalFunction.forward": [[9, 14], ["x.view_as"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "l", ",", "c", ")", ":", "\n", "        ", "ctx", ".", "l", "=", "l", "\n", "ctx", ".", "c", "=", "c", "\n", "return", "x", ".", "view_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientReversalFunction.backward": [[15, 19], ["grad_output.clamp.clamp.clamp", "grad_output.clamp.clamp.neg"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "grad_output", "=", "grad_output", ".", "clamp", "(", "-", "ctx", ".", "c", ",", "ctx", ".", "c", ")", "\n", "return", "ctx", ".", "l", "*", "grad_output", ".", "neg", "(", ")", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientClippingFunction.forward": [[24, 28], ["x.view_as"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "c", ")", ":", "\n", "        ", "ctx", ".", "c", "=", "c", "\n", "return", "x", ".", "view_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.GradientClippingFunction.backward": [[29, 33], ["grad_output.clamp.clamp.clamp"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "grad_output", "=", "grad_output", ".", "clamp", "(", "-", "ctx", ".", "c", ",", "ctx", ".", "c", ")", "\n", "return", "grad_output", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.ReversalClassifier.__init__": [[47, 55], ["super().__init__", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "output_dim", ",", "gradient_clipping_bounds", ",", "scale_factor", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "ReversalClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_lambda", "=", "scale_factor", "\n", "self", ".", "_clipping", "=", "gradient_clipping_bounds", "\n", "self", ".", "_output_dim", "=", "output_dim", "\n", "self", ".", "_classifier", "=", "Sequential", "(", "\n", "Linear", "(", "input_dim", ",", "hidden_dim", ")", ",", "\n", "Linear", "(", "hidden_dim", ",", "output_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.ReversalClassifier.forward": [[57, 61], ["GradientReversalFunction.apply", "classifier.ReversalClassifier._classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "GradientReversalFunction", ".", "apply", "(", "x", ",", "self", ".", "_lambda", ",", "self", ".", "_clipping", ")", "\n", "x", "=", "self", ".", "_classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.ReversalClassifier.loss": [[62, 70], ["torch.max", "speakers.repeat().transpose", "torch.nn.functional.cross_entropy", "prediction.transpose", "torch.arange", "speakers.repeat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "loss", "(", "input_lengths", ",", "speakers", ",", "prediction", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "ignore_index", "=", "-", "100", "\n", "ml", "=", "torch", ".", "max", "(", "input_lengths", ")", "\n", "input_mask", "=", "torch", ".", "arange", "(", "ml", ",", "device", "=", "input_lengths", ".", "device", ")", "[", "None", ",", ":", "]", "<", "input_lengths", "[", ":", ",", "None", "]", "\n", "target", "=", "speakers", ".", "repeat", "(", "ml", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "target", "[", "~", "input_mask", "]", "=", "ignore_index", "\n", "return", "F", ".", "cross_entropy", "(", "prediction", ".", "transpose", "(", "1", ",", "2", ")", ",", "target", ",", "ignore_index", "=", "ignore_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__": [[81, 85], ["super().__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "gradient_clipping_bounds", ")", ":", "\n", "        ", "super", "(", "CosineSimilarityClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_classifier", "=", "Linear", "(", "input_dim", ",", "output_dim", ")", "\n", "self", ".", "_clipping", "=", "gradient_clipping_bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.forward": [[86, 89], ["GradientClippingFunction.apply", "classifier.CosineSimilarityClassifier._classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "GradientClippingFunction", ".", "apply", "(", "x", ",", "self", ".", "_clipping", ")", "\n", "return", "self", ".", "_classifier", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.loss": [[90, 107], ["classifier.ReversalClassifier.loss", "torch.norm().unsqueeze", "torch.div", "torch.norm().view", "torch.div", "torch.abs", "torch.sum", "torch.mean", "torch.norm", "torch.norm"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.modules.classifier.CosineSimilarityClassifier.loss"], ["", "@", "staticmethod", "\n", "def", "loss", "(", "input_lengths", ",", "speakers", ",", "prediction", ",", "embeddings", ",", "instance", ")", ":", "\n", "        ", "l", "=", "ReversalClassifier", ".", "loss", "(", "input_lengths", ",", "speakers", ",", "prediction", ")", "\n", "\n", "w", "=", "instance", ".", "_classifier", ".", "weight", ".", "T", "# output x input", "\n", "\n", "dot", "=", "embeddings", "@", "w", "\n", "norm_e", "=", "torch", ".", "norm", "(", "embeddings", ",", "2", ",", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cosine_loss", "=", "torch", ".", "div", "(", "dot", ",", "norm_e", ")", "\n", "norm_w", "=", "torch", ".", "norm", "(", "w", ",", "2", ",", "0", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "cosine_loss", "=", "torch", ".", "div", "(", "cosine_loss", ",", "norm_w", ")", "\n", "cosine_loss", "=", "torch", ".", "abs", "(", "cosine_loss", ")", "\n", "\n", "cosine_loss", "=", "torch", ".", "sum", "(", "cosine_loss", ",", "dim", "=", "2", ")", "\n", "l", "+=", "torch", ".", "mean", "(", "cosine_loss", ")", "\n", "\n", "return", "l", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load_state_dict": [[141, 144], ["d.items", "setattr"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "load_state_dict", "(", "d", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "setattr", "(", "Params", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.state_dict": [[145, 149], ["dir", "callable", "attr.startswith", "getattr"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "state_dict", "(", ")", ":", "\n", "        ", "members", "=", "[", "attr", "for", "attr", "in", "dir", "(", "Params", ")", "if", "not", "callable", "(", "getattr", "(", "Params", ",", "attr", ")", ")", "and", "not", "attr", ".", "startswith", "(", "\"__\"", ")", "]", "\n", "return", "{", "k", ":", "Params", ".", "__dict__", "[", "k", "]", "for", "k", "in", "members", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load": [[150, 155], ["open", "json.load", "json.load.Params.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load", "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.load_state_dict"], ["", "@", "staticmethod", "\n", "def", "load", "(", "json_path", ")", ":", "\n", "        ", "with", "open", "(", "json_path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "params", "=", "json", ".", "load", "(", "f", ")", "\n", "Params", ".", "load_state_dict", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.save": [[156, 161], ["open", "params.Params.state_dict", "json.dump"], "methods", ["home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.state_dict"], ["", "", "@", "staticmethod", "\n", "def", "save", "(", "json_path", ")", ":", "\n", "        ", "with", "open", "(", "json_path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "d", "=", "Params", ".", "state_dict", "(", ")", "\n", "json", ".", "dump", "(", "d", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mu-y_lll-tts.params.params.Params.symbols_count": [[162, 168], ["len", "len", "len", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "symbols_count", "(", ")", ":", "\n", "        ", "symbols_count", "=", "len", "(", "Params", ".", "characters", ")", "\n", "if", "Params", ".", "use_phonemes", ":", "symbols_count", "=", "len", "(", "Params", ".", "phonemes", ")", "\n", "if", "Params", ".", "use_punctuation", ":", "symbols_count", "+=", "len", "(", "Params", ".", "punctuations_out", ")", "+", "len", "(", "Params", ".", "punctuations_in", ")", "\n", "return", "symbols_count", "\n", "", "", ""]]}