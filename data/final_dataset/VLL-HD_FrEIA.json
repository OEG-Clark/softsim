{"home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.reversible_sequential_net.ReversibleSequential.__init__": [[7, 13], ["warnings.warn", "FrEIA.framework.sequence_inn.SequenceINN.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "dims", ":", "int", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"ReversibleSequential is deprecated in favour of \"", "\n", "\"SequenceINN. It will be removed in a future version \"", "\n", "\"of FrEIA.\"", ",", "\n", "DeprecationWarning", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "dims", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.reversible_graph_net.ReversibleGraphNet.__init__": [[10, 27], ["warnings.warn", "graph_inn.GraphINN.__init__", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_list", ",", "ind_in", "=", "None", ",", "ind_out", "=", "None", ",", "verbose", "=", "True", ",", "\n", "force_tuple_output", "=", "False", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"ReversibleGraphNet is deprecated in favour of GraphINN. \"", "\n", "\"It will be removed in the next version of FrEIA.\"", ",", "\n", "DeprecationWarning", ")", "\n", "if", "ind_in", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"ReversibleGraphNet's ind_in was removed in FrEIA v0.3.0. \"", "\n", "\"Please use InputNodes and switch to GraphINN.\"", "\n", ")", "\n", "", "if", "ind_out", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"ReversibleGraphNet's ind_out was removed in FrEIA v0.3.0. \"", "\n", "\"Please use OutputNodes and switch to GraphINN.\"", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "node_list", ",", "verbose", "=", "verbose", ",", "\n", "force_tuple_output", "=", "force_tuple_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.reversible_graph_net.ReversibleGraphNet.forward": [[28, 37], ["warnings.warn", "super().forward"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.forward"], ["", "def", "forward", "(", "self", ",", "x_or_z", ":", "Union", "[", "Tensor", ",", "Iterable", "[", "Tensor", "]", "]", ",", "\n", "c", ":", "Iterable", "[", "Tensor", "]", "=", "None", ",", "rev", ":", "bool", "=", "False", ",", "jac", ":", "bool", "=", "True", ",", "\n", "intermediate_outputs", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "Tuple", "[", "Tensor", "]", ",", "Tensor", "]", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"ReversibleGraphNet's forward() now \"", "\n", "\"returns a tuple (output, jacobian). \"", "\n", "\"It will be removed in the next version of FrEIA.\"", ",", "\n", "DeprecationWarning", ")", "\n", "return", "super", "(", ")", ".", "forward", "(", "x_or_z", ",", "c", ",", "rev", ",", "jac", ",", "intermediate_outputs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__init__": [[28, 36], ["FrEIA.modules.InvertibleModule.__init__", "torch.ModuleList", "torch.ModuleList", "tuple"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "*", "dims", ":", "int", ",", "force_tuple_output", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "[", "dims", "]", ")", "\n", "\n", "self", ".", "shapes", "=", "[", "tuple", "(", "dims", ")", "]", "\n", "self", ".", "conditions", "=", "[", "]", "\n", "self", ".", "module_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "force_tuple_output", "=", "force_tuple_output", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append": [[37, 60], ["sequence_inn.SequenceINN.conditions.append", "module_class", "sequence_inn.SequenceINN.module_list.append", "module_class.output_dims", "sequence_inn.SequenceINN.shapes.append", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.output_dims", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["", "def", "append", "(", "self", ",", "module_class", ",", "cond", "=", "None", ",", "cond_shape", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Append a reversible block from FrEIA.modules to the network.\n\n        Args:\n          module_class: Class from FrEIA.modules.\n          cond (int): index of which condition to use (conditions will be passed as list to forward()).\n            Conditioning nodes are not needed for SequenceINN.\n          cond_shape (tuple[int]): the shape of the condition tensor.\n          **kwargs: Further keyword arguments that are passed to the constructor of module_class (see example).\n        \"\"\"", "\n", "\n", "dims_in", "=", "[", "self", ".", "shapes", "[", "-", "1", "]", "]", "\n", "self", ".", "conditions", ".", "append", "(", "cond", ")", "\n", "\n", "if", "cond", "is", "not", "None", ":", "\n", "            ", "kwargs", "[", "'dims_c'", "]", "=", "[", "cond_shape", "]", "\n", "\n", "", "module", "=", "module_class", "(", "dims_in", ",", "**", "kwargs", ")", "\n", "self", ".", "module_list", ".", "append", "(", "module", ")", "\n", "ouput_dims", "=", "module", ".", "output_dims", "(", "dims_in", ")", "\n", "assert", "len", "(", "ouput_dims", ")", "==", "1", ",", "\"Module has more than one output\"", "\n", "self", ".", "shapes", ".", "append", "(", "ouput_dims", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__getitem__": [[61, 63], ["sequence_inn.SequenceINN.module_list.__getitem__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "module_list", ".", "__getitem__", "(", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__len__": [[64, 66], ["sequence_inn.SequenceINN.module_list.__len__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__len__"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "module_list", ".", "__len__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__iter__": [[67, 69], ["sequence_inn.SequenceINN.module_list.__iter__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.__iter__"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "module_list", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.output_dims": [[70, 75], ["ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ":", "List", "[", "Tuple", "[", "int", "]", "]", ")", "->", "List", "[", "Tuple", "[", "int", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "force_tuple_output", ":", "\n", "            ", "raise", "ValueError", "(", "\"You can only call output_dims on a SequentialINN \"", "\n", "\"when setting force_tuple_output=True.\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.forward": [[76, 111], ["range", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "len", "reversed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_or_z", ":", "Tensor", ",", "c", ":", "Iterable", "[", "Tensor", "]", "=", "None", ",", "\n", "rev", ":", "bool", "=", "False", ",", "jac", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "Tensor", ",", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Executes the sequential INN in forward or inverse (rev=True) direction.\n\n        Args:\n            x_or_z: input tensor (in contrast to GraphINN, a list of\n                    tensors is not supported, as SequenceINN only has\n                    one input).\n            c: list of conditions.\n            rev: whether to compute the network forward or reversed.\n            jac: whether to compute the log jacobian\n\n        Returns:\n            z_or_x (Tensor): network output.\n            jac (Tensor): log-jacobian-determinant.\n        \"\"\"", "\n", "\n", "iterator", "=", "range", "(", "len", "(", "self", ".", "module_list", ")", ")", "\n", "log_det_jac", "=", "0", "\n", "\n", "if", "rev", ":", "\n", "            ", "iterator", "=", "reversed", "(", "iterator", ")", "\n", "\n", "", "if", "torch", ".", "is_tensor", "(", "x_or_z", ")", ":", "\n", "            ", "x_or_z", "=", "(", "x_or_z", ",", ")", "\n", "", "for", "i", "in", "iterator", ":", "\n", "            ", "if", "self", ".", "conditions", "[", "i", "]", "is", "None", ":", "\n", "                ", "x_or_z", ",", "j", "=", "self", ".", "module_list", "[", "i", "]", "(", "x_or_z", ",", "jac", "=", "jac", ",", "rev", "=", "rev", ")", "\n", "", "else", ":", "\n", "                ", "x_or_z", ",", "j", "=", "self", ".", "module_list", "[", "i", "]", "(", "x_or_z", ",", "c", "=", "[", "c", "[", "self", ".", "conditions", "[", "i", "]", "]", "]", ",", "\n", "jac", "=", "jac", ",", "rev", "=", "rev", ")", "\n", "", "log_det_jac", "=", "j", "+", "log_det_jac", "\n", "\n", "", "return", "x_or_z", "if", "self", ".", "force_tuple_output", "else", "x_or_z", "[", "0", "]", ",", "log_det_jac", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.Node.__init__": [[22, 62], ["graph_inn.Node.parse_inputs", "isinstance", "graph_inn.Node.build_module", "enumerate", "range", "len", "graph_inn.Node.outputs.append", "hex", "id"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.Node.parse_inputs", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.OutputNode.build_module", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["def", "__init__", "(", "self", ",", "inputs", ":", "Union", "[", "\"Node\"", ",", "Tuple", "[", "\"Node\"", ",", "int", "]", ",", "\n", "Iterable", "[", "Tuple", "[", "\"Node\"", ",", "int", "]", "]", "]", ",", "\n", "module_type", ",", "module_args", ":", "dict", ",", "conditions", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "if", "conditions", "is", "None", ":", "\n", "            ", "conditions", "=", "[", "]", "\n", "\n", "", "if", "name", ":", "\n", "            ", "self", ".", "name", "=", "name", "\n", "", "else", ":", "\n", "            ", "self", ".", "name", "=", "hex", "(", "id", "(", "self", ")", ")", "[", "-", "6", ":", "]", "\n", "", "self", ".", "inputs", "=", "self", ".", "parse_inputs", "(", "inputs", ")", "\n", "if", "isinstance", "(", "conditions", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "conditions", "=", "conditions", "\n", "", "else", ":", "\n", "            ", "self", ".", "conditions", "=", "[", "conditions", ",", "]", "\n", "\n", "", "self", ".", "outputs", ":", "List", "[", "Tuple", "[", "Node", ",", "int", "]", "]", "=", "[", "]", "\n", "self", ".", "module_type", "=", "module_type", "\n", "self", ".", "module_args", "=", "module_args", "\n", "\n", "input_shapes", "=", "[", "input_node", ".", "output_dims", "[", "node_out_idx", "]", "\n", "for", "input_node", ",", "node_out_idx", "in", "self", ".", "inputs", "]", "\n", "condition_shapes", "=", "[", "cond_node", ".", "output_dims", "[", "0", "]", "\n", "for", "cond_node", "in", "self", ".", "conditions", "]", "\n", "\n", "self", ".", "input_dims", "=", "input_shapes", "\n", "self", ".", "condition_dims", "=", "condition_shapes", "\n", "self", ".", "module", ",", "self", ".", "output_dims", "=", "self", ".", "build_module", "(", "condition_shapes", ",", "\n", "input_shapes", ")", "\n", "\n", "# Notify preceding nodes that their output ends up here", "\n", "# Entry at position co -> (n, ci) means:", "\n", "# My output co goes to input channel ci of n.", "\n", "for", "in_idx", ",", "(", "in_node", ",", "out_idx", ")", "in", "enumerate", "(", "self", ".", "inputs", ")", ":", "\n", "            ", "in_node", ".", "outputs", "[", "out_idx", "]", "=", "(", "self", ",", "in_idx", ")", "\n", "\n", "# Enable .outX access", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "output_dims", ")", ")", ":", "\n", "            ", "self", ".", "__dict__", "[", "f\"out{i}\"", "]", "=", "self", ",", "i", "\n", "self", ".", "outputs", ".", "append", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.Node.build_module": [[63, 75], ["len", "graph_inn.Node.module_type", "graph_inn.Node.module_type", "graph_inn.Node.output_dims"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.output_dims"], ["", "", "def", "build_module", "(", "self", ",", "condition_shapes", ",", "input_shapes", ")", "->", "Tuple", "[", "InvertibleModule", ",", "List", "[", "Tuple", "[", "int", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Instantiates the module and determines the output dimension by\n        calling InvertibleModule#output_dims.\n        \"\"\"", "\n", "if", "len", "(", "self", ".", "conditions", ")", ">", "0", ":", "\n", "            ", "module", "=", "self", ".", "module_type", "(", "input_shapes", ",", "dims_c", "=", "condition_shapes", ",", "\n", "**", "self", ".", "module_args", ")", "\n", "", "else", ":", "\n", "            ", "module", "=", "self", ".", "module_type", "(", "input_shapes", ",", "**", "self", ".", "module_args", ")", "\n", "", "return", "module", ",", "module", ".", "output_dims", "(", "input_shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.Node.parse_inputs": [[76, 105], ["isinstance", "len", "isinstance", "isinstance", "TypeError", "len", "ValueError", "type"], "methods", ["None"], ["", "def", "parse_inputs", "(", "self", ",", "inputs", ":", "Union", "[", "\"Node\"", ",", "Tuple", "[", "\"Node\"", ",", "int", "]", ",", "\n", "Iterable", "[", "Tuple", "[", "\"Node\"", ",", "int", "]", "]", "]", ")", "->", "List", "[", "Tuple", "[", "\"Node\"", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Converts specified inputs to a node to a canonical format.\n        Inputs can be specified in three forms:\n\n        - a single node, then this nodes first output is taken as input\n        - a single tuple (node, idx), specifying output idx of node\n        - a list of tuples [(node, idx)], each specifying output idx of node\n\n        All such formats are converted to the last format.\n        \"\"\"", "\n", "if", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "inputs", ")", "==", "0", ":", "\n", "                ", "return", "inputs", "\n", "", "elif", "isinstance", "(", "inputs", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "return", "inputs", "\n", "", "elif", "len", "(", "inputs", ")", "==", "2", ":", "\n", "                ", "return", "[", "inputs", ",", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Cannot parse inputs provided to node '{self.name}'.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "isinstance", "(", "inputs", ",", "Node", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f\"Received object of invalid type \"", "\n", "f\"({type(inputs)}) as input for node \"", "\n", "f\"'{self.name}'.\"", ")", "\n", "", "return", "[", "(", "inputs", ",", "0", ")", ",", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.Node.__str__": [[106, 111], ["None"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "module_hint", "=", "(", "self", ".", "module_type", ".", "__name__", "if", "self", ".", "module_type", "is", "not", "None", "\n", "else", "\"\"", ")", "\n", "name_hint", "=", "f\" {self.name!r}\"", "if", "self", ".", "name", "is", "not", "None", "else", "\"\"", "\n", "return", "f\"{self.__class__.__name__}{name_hint}: {self.input_dims} -> \"", "f\"{module_hint} -> {self.output_dims}\"", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.Node.__repr__": [[113, 116], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "name_hint", "=", "f\" {self.name!r}\"", "if", "self", ".", "name", "is", "not", "None", "else", "\"\"", "\n", "return", "f\"{self.__class__.__name__}{name_hint}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.InputNode.__init__": [[124, 127], ["graph_inn.Node.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "*", "dims", ":", "int", ",", "name", "=", "None", ")", ":", "\n", "        ", "self", ".", "dims", "=", "dims", "\n", "super", "(", ")", ".", "__init__", "(", "[", "]", ",", "None", ",", "{", "}", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.InputNode.build_module": [[128, 135], ["len", "ValueError", "len"], "methods", ["None"], ["", "def", "build_module", "(", "self", ",", "condition_shapes", ",", "input_shapes", ")", "->", "Tuple", "[", "None", ",", "List", "[", "Tuple", "[", "int", "]", "]", "]", ":", "\n", "        ", "if", "len", "(", "condition_shapes", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{self.__class__.__name__} does not accept conditions\"", ")", "\n", "", "assert", "len", "(", "input_shapes", ")", "==", "0", ",", "\"Forbidden by constructor\"", "\n", "return", "None", ",", "[", "self", ".", "dims", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.ConditionNode.__init__": [[143, 147], ["graph_inn.Node.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "*", "dims", ":", "int", ",", "name", "=", "None", ")", ":", "\n", "        ", "self", ".", "dims", "=", "dims", "\n", "super", "(", ")", ".", "__init__", "(", "[", "]", ",", "None", ",", "{", "}", ",", "name", "=", "name", ")", "\n", "self", ".", "outputs", ":", "List", "[", "Tuple", "[", "Node", ",", "int", "]", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.ConditionNode.build_module": [[148, 155], ["len", "ValueError", "len"], "methods", ["None"], ["", "def", "build_module", "(", "self", ",", "condition_shapes", ",", "input_shapes", ")", "->", "Tuple", "[", "None", ",", "List", "[", "Tuple", "[", "int", "]", "]", "]", ":", "\n", "        ", "if", "len", "(", "condition_shapes", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{self.__class__.__name__} does not accept conditions\"", ")", "\n", "", "assert", "len", "(", "input_shapes", ")", "==", "0", ",", "\"Forbidden by constructor\"", "\n", "return", "None", ",", "[", "self", ".", "dims", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.OutputNode.__init__": [[163, 165], ["graph_inn.Node.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "in_node", ":", "Union", "[", "Node", ",", "Tuple", "[", "Node", ",", "int", "]", "]", ",", "name", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_node", ",", "None", ",", "{", "}", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.OutputNode.build_module": [[166, 175], ["len", "ValueError", "len", "ValueError", "len"], "methods", ["None"], ["", "def", "build_module", "(", "self", ",", "condition_shapes", ",", "input_shapes", ")", "->", "Tuple", "[", "None", ",", "List", "[", "Tuple", "[", "int", "]", "]", "]", ":", "\n", "        ", "if", "len", "(", "condition_shapes", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{self.__class__.__name__} does not accept conditions\"", ")", "\n", "", "if", "len", "(", "input_shapes", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Output node received {len(input_shapes)} inputs,\"", "\n", "f\"but only single input is allowed.\"", ")", "\n", "", "return", "None", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.__init__": [[188, 234], ["graph_inn.topological_order", "modules.base.InvertibleModule.__init__", "torch.ModuleList", "torch.ModuleList", "print", "range", "isinstance", "range", "isinstance", "range", "isinstance", "len", "len", "len", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.topological_order", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "node_list", ",", "force_tuple_output", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "# Gather lists of input, output and condition nodes", "\n", "        ", "in_nodes", "=", "[", "node_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "node_list", ")", ")", "\n", "if", "isinstance", "(", "node_list", "[", "i", "]", ",", "InputNode", ")", "]", "\n", "out_nodes", "=", "[", "node_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "node_list", ")", ")", "\n", "if", "isinstance", "(", "node_list", "[", "i", "]", ",", "OutputNode", ")", "]", "\n", "condition_nodes", "=", "[", "node_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "node_list", ")", ")", "if", "\n", "isinstance", "(", "node_list", "[", "i", "]", ",", "ConditionNode", ")", "]", "\n", "\n", "# Check that all nodes are in the list", "\n", "for", "node", "in", "node_list", ":", "\n", "            ", "for", "in_node", ",", "idx", "in", "node", ".", "inputs", ":", "\n", "                ", "if", "in_node", "not", "in", "node_list", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"{node} gets input from {in_node}, \"", "\n", "f\"but the latter is not in the node_list \"", "\n", "f\"passed to GraphINN.\"", ")", "\n", "", "", "for", "out_node", ",", "idx", "in", "node", ".", "outputs", ":", "\n", "                ", "if", "out_node", "not", "in", "node_list", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"{out_node} gets input from {node}, \"", "\n", "f\"but the it's not in the node_list \"", "\n", "f\"passed to GraphINN.\"", ")", "\n", "\n", "# Build the graph and tell nodes about their dimensions so that they can", "\n", "# build the modules", "\n", "", "", "", "node_list", "=", "topological_order", "(", "node_list", ",", "in_nodes", ",", "out_nodes", ")", "\n", "global_in_shapes", "=", "[", "node", ".", "output_dims", "[", "0", "]", "for", "node", "in", "in_nodes", "]", "\n", "global_out_shapes", "=", "[", "node", ".", "input_dims", "[", "0", "]", "for", "node", "in", "out_nodes", "]", "\n", "global_cond_shapes", "=", "[", "node", ".", "output_dims", "[", "0", "]", "for", "node", "in", "condition_nodes", "]", "\n", "\n", "# Only now we can set out shapes", "\n", "super", "(", ")", ".", "__init__", "(", "global_in_shapes", ",", "global_cond_shapes", ")", "\n", "self", ".", "node_list", "=", "node_list", "\n", "\n", "# Now we can store everything -- before calling super constructor,", "\n", "# nn.Module doesn't allow assigning anything", "\n", "self", ".", "in_nodes", "=", "in_nodes", "\n", "self", ".", "condition_nodes", "=", "condition_nodes", "\n", "self", ".", "out_nodes", "=", "out_nodes", "\n", "\n", "self", ".", "global_out_shapes", "=", "global_out_shapes", "\n", "self", ".", "force_tuple_output", "=", "force_tuple_output", "\n", "self", ".", "module_list", "=", "nn", ".", "ModuleList", "(", "[", "n", ".", "module", "for", "n", "in", "node_list", "\n", "if", "n", ".", "module", "is", "not", "None", "]", ")", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.output_dims": [[235, 241], ["ValueError", "len"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ":", "List", "[", "Tuple", "[", "int", "]", "]", ")", "->", "List", "[", "Tuple", "[", "int", "]", "]", ":", "\n", "        ", "if", "len", "(", "self", ".", "global_out_shapes", ")", "==", "1", "and", "not", "self", ".", "force_tuple_output", ":", "\n", "            ", "raise", "ValueError", "(", "\"You can only call output_dims on a \"", "\n", "\"GraphINN with more than one output \"", "\n", "\"or when setting force_tuple_output=True.\"", ")", "\n", "", "return", "self", ".", "global_out_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.forward": [[242, 327], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "zip", "zip", "warnings.warn", "len", "len", "ValueError", "len", "len", "ValueError", "tuple", "tuple", "graph_inn.GraphINN._check_output", "enumerate", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "tuple.append", "tuple.append", "node.module", "node.module", "RuntimeError", "len", "tuple", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN._check_output", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["", "def", "forward", "(", "self", ",", "x_or_z", ":", "Union", "[", "Tensor", ",", "Iterable", "[", "Tensor", "]", "]", ",", "\n", "c", ":", "Iterable", "[", "Tensor", "]", "=", "None", ",", "rev", ":", "bool", "=", "False", ",", "jac", ":", "bool", "=", "True", ",", "\n", "intermediate_outputs", ":", "bool", "=", "False", ",", "x", ":", "None", "=", "None", ")", "->", "Tuple", "[", "Tuple", "[", "Tensor", "]", ",", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward or backward computation of the whole net.\n        \"\"\"", "\n", "if", "x", "is", "not", "None", ":", "\n", "            ", "x_or_z", "=", "x", "\n", "warnings", ".", "warn", "(", "\"You called GraphINN(x=...). x is now called x_or_z, \"", "\n", "\"please pass input as positional argument.\"", ")", "\n", "\n", "", "if", "torch", ".", "is_tensor", "(", "x_or_z", ")", ":", "\n", "            ", "x_or_z", "=", "x_or_z", ",", "\n", "", "if", "torch", ".", "is_tensor", "(", "c", ")", ":", "\n", "            ", "c", "=", "c", ",", "\n", "\n", "", "jacobian", "=", "torch", ".", "zeros", "(", "x_or_z", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "x_or_z", "[", "0", "]", ")", "\n", "outs", "=", "{", "}", "\n", "jacobian_dict", "=", "{", "}", "if", "jac", "else", "None", "\n", "\n", "# Explicitly set conditions and starts", "\n", "start_nodes", "=", "self", ".", "out_nodes", "if", "rev", "else", "self", ".", "in_nodes", "\n", "if", "len", "(", "x_or_z", ")", "!=", "len", "(", "start_nodes", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Got {len(x_or_z)} inputs, but expected \"", "\n", "f\"{len(start_nodes)}.\"", ")", "\n", "", "for", "tensor", ",", "start_node", "in", "zip", "(", "x_or_z", ",", "start_nodes", ")", ":", "\n", "            ", "outs", "[", "start_node", ",", "0", "]", "=", "tensor", "\n", "\n", "", "if", "c", "is", "None", ":", "\n", "            ", "c", "=", "[", "]", "\n", "", "if", "len", "(", "c", ")", "!=", "len", "(", "self", ".", "condition_nodes", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Got {len(c)} conditions, but expected \"", "\n", "f\"{len(self.condition_nodes)}.\"", ")", "\n", "", "for", "tensor", ",", "condition_node", "in", "zip", "(", "c", ",", "self", ".", "condition_nodes", ")", ":", "\n", "            ", "outs", "[", "condition_node", ",", "0", "]", "=", "tensor", "\n", "\n", "# Go backwards through nodes if rev=True", "\n", "", "for", "node", "in", "self", ".", "node_list", "[", ":", ":", "-", "1", "if", "rev", "else", "1", "]", ":", "\n", "# Skip all special nodes", "\n", "            ", "if", "node", "in", "self", ".", "in_nodes", "+", "self", ".", "out_nodes", "+", "self", ".", "condition_nodes", ":", "\n", "                ", "continue", "\n", "\n", "", "has_condition", "=", "len", "(", "node", ".", "conditions", ")", ">", "0", "\n", "\n", "mod_in", "=", "[", "]", "\n", "mod_c", "=", "[", "]", "\n", "for", "prev_node", ",", "channel", "in", "(", "node", ".", "outputs", "if", "rev", "else", "node", ".", "inputs", ")", ":", "\n", "                ", "mod_in", ".", "append", "(", "outs", "[", "prev_node", ",", "channel", "]", ")", "\n", "", "for", "cond_node", "in", "node", ".", "conditions", ":", "\n", "                ", "mod_c", ".", "append", "(", "outs", "[", "cond_node", ",", "0", "]", ")", "\n", "", "mod_in", "=", "tuple", "(", "mod_in", ")", "\n", "mod_c", "=", "tuple", "(", "mod_c", ")", "\n", "\n", "try", ":", "\n", "                ", "if", "has_condition", ":", "\n", "                    ", "mod_out", "=", "node", ".", "module", "(", "mod_in", ",", "c", "=", "mod_c", ",", "rev", "=", "rev", ",", "jac", "=", "jac", ")", "\n", "", "else", ":", "\n", "                    ", "mod_out", "=", "node", ".", "module", "(", "mod_in", ",", "rev", "=", "rev", ",", "jac", "=", "jac", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "raise", "RuntimeError", "(", "f\"{node} encountered an error.\"", ")", "from", "e", "\n", "\n", "", "out", ",", "mod_jac", "=", "self", ".", "_check_output", "(", "node", ",", "mod_out", ",", "jac", ",", "rev", ")", "\n", "\n", "for", "out_idx", ",", "out_value", "in", "enumerate", "(", "out", ")", ":", "\n", "                ", "outs", "[", "node", ",", "out_idx", "]", "=", "out_value", "\n", "\n", "", "if", "jac", ":", "\n", "                ", "jacobian", "=", "jacobian", "+", "mod_jac", "\n", "jacobian_dict", "[", "node", "]", "=", "mod_jac", "\n", "\n", "", "", "for", "out_node", "in", "(", "self", ".", "in_nodes", "if", "rev", "else", "self", ".", "out_nodes", ")", ":", "\n", "# This copies the one input of the out node", "\n", "            ", "outs", "[", "out_node", ",", "0", "]", "=", "outs", "[", "(", "out_node", ".", "outputs", "if", "rev", "\n", "else", "out_node", ".", "inputs", ")", "[", "0", "]", "]", "\n", "\n", "", "if", "intermediate_outputs", ":", "\n", "            ", "return", "outs", ",", "jacobian_dict", "\n", "", "else", ":", "\n", "            ", "out_list", "=", "[", "outs", "[", "out_node", ",", "0", "]", "for", "out_node", "\n", "in", "(", "self", ".", "in_nodes", "if", "rev", "else", "self", ".", "out_nodes", ")", "]", "\n", "if", "len", "(", "out_list", ")", "==", "1", "and", "not", "self", ".", "force_tuple_output", ":", "\n", "                ", "return", "out_list", "[", "0", "]", ",", "jacobian", "\n", "", "else", ":", "\n", "                ", "return", "tuple", "(", "out_list", ")", ",", "jacobian", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN._check_output": [[328, 366], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "ValueError", "len", "ValueError", "ValueError", "len", "len", "ValueError", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "isinstance", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "ValueError", "len", "len", "len", "ValueError", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "", "", "def", "_check_output", "(", "self", ",", "node", ",", "mod_out", ",", "jac", ",", "rev", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "mod_out", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The node {node}'s module returned a tensor only. This \"", "\n", "f\"is deprecated without fallback. Please follow the \"", "\n", "f\"signature of InvertibleOperator#forward in your module \"", "\n", "f\"if you want to use it in a GraphINN.\"", ")", "\n", "\n", "", "if", "len", "(", "mod_out", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The node {node}'s module returned a tuple of length \"", "\n", "f\"{len(mod_out)}, but should return a tuple `z_or_x, jac`.\"", ")", "\n", "\n", "", "out", ",", "mod_jac", "=", "mod_out", "\n", "\n", "if", "torch", ".", "is_tensor", "(", "out", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"The node {node}'s module returns a tensor. \"", "\n", "f\"This is deprecated.\"", ")", "\n", "\n", "", "if", "len", "(", "out", ")", "!=", "len", "(", "node", ".", "inputs", "if", "rev", "else", "node", ".", "outputs", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The node {node}'s module returned {len(out)} output \"", "\n", "f\"variables, but should return \"", "\n", "f\"{len(node.inputs if rev else node.outputs)}.\"", ")", "\n", "\n", "", "if", "not", "torch", ".", "is_tensor", "(", "mod_jac", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod_jac", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "                ", "mod_jac", "=", "torch", ".", "zeros", "(", "out", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "out", "[", "0", "]", ".", "device", ")", "+", "mod_jac", "\n", "", "elif", "jac", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"The node {node}'s module returned a non-tensor as \"", "\n", "f\"Jacobian: {mod_jac}\"", ")", "\n", "", "elif", "not", "jac", "and", "mod_jac", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"The node {node}'s module returned neither None nor a \"", "\n", "f\"Jacobian: {mod_jac}\"", ")", "\n", "", "", "return", "out", ",", "mod_jac", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.log_jacobian_numerical": [[367, 406], ["isinstance", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "x[].new_zeros", "range", "sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.prod", "x.reshape", "x[].new_zeros", "isinstance", "graph_inn.GraphINN.forward", "graph_inn.GraphINN.forward", "isinstance", "numpy.prod", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "x_i.view", "x_upper[].view", "x_lower[].view", "range", "range", "y_i.view", "y_i.view", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.forward", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.forward"], ["", "def", "log_jacobian_numerical", "(", "self", ",", "x", ",", "c", "=", "None", ",", "rev", "=", "False", ",", "h", "=", "1e-04", ")", ":", "\n", "        ", "\"\"\"\n        Approximate log Jacobian determinant via finite differences.\n        \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "batch_size", "=", "x", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "ndim_x_separate", "=", "[", "np", ".", "prod", "(", "x_i", ".", "shape", "[", "1", ":", "]", ")", "for", "x_i", "in", "x", "]", "\n", "ndim_x_total", "=", "sum", "(", "ndim_x_separate", ")", "\n", "x_flat", "=", "torch", ".", "cat", "(", "[", "x_i", ".", "view", "(", "batch_size", ",", "-", "1", ")", "for", "x_i", "in", "x", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "ndim_x_total", "=", "np", ".", "prod", "(", "x", ".", "shape", "[", "1", ":", "]", ")", "\n", "x_flat", "=", "x", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "J_num", "=", "torch", ".", "zeros", "(", "batch_size", ",", "ndim_x_total", ",", "ndim_x_total", ")", "\n", "for", "i", "in", "range", "(", "ndim_x_total", ")", ":", "\n", "            ", "offset", "=", "x", "[", "0", "]", ".", "new_zeros", "(", "batch_size", ",", "ndim_x_total", ")", "\n", "offset", "[", ":", ",", "i", "]", "=", "h", "\n", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "x_upper", "=", "torch", ".", "split", "(", "x_flat", "+", "offset", ",", "ndim_x_separate", ",", "dim", "=", "1", ")", "\n", "x_upper", "=", "[", "x_upper", "[", "i", "]", ".", "view", "(", "*", "x", "[", "i", "]", ".", "shape", ")", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", "]", "\n", "x_lower", "=", "torch", ".", "split", "(", "x_flat", "-", "offset", ",", "ndim_x_separate", ",", "dim", "=", "1", ")", "\n", "x_lower", "=", "[", "x_lower", "[", "i", "]", ".", "view", "(", "*", "x", "[", "i", "]", ".", "shape", ")", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "x_upper", "=", "(", "x_flat", "+", "offset", ")", ".", "view", "(", "*", "x", ".", "shape", ")", "\n", "x_lower", "=", "(", "x_flat", "-", "offset", ")", ".", "view", "(", "*", "x", ".", "shape", ")", "\n", "", "y_upper", ",", "_", "=", "self", ".", "forward", "(", "x_upper", ",", "c", "=", "c", ",", "rev", "=", "rev", ",", "jac", "=", "False", ")", "\n", "y_lower", ",", "_", "=", "self", ".", "forward", "(", "x_lower", ",", "c", "=", "c", ",", "rev", "=", "rev", ",", "jac", "=", "False", ")", "\n", "if", "isinstance", "(", "y_upper", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "y_upper", "=", "torch", ".", "cat", "(", "\n", "[", "y_i", ".", "view", "(", "batch_size", ",", "-", "1", ")", "for", "y_i", "in", "y_upper", "]", ",", "dim", "=", "1", ")", "\n", "y_lower", "=", "torch", ".", "cat", "(", "\n", "[", "y_i", ".", "view", "(", "batch_size", ",", "-", "1", ")", "for", "y_i", "in", "y_lower", "]", ",", "dim", "=", "1", ")", "\n", "", "J_num", "[", ":", ",", ":", ",", "i", "]", "=", "(", "y_upper", "-", "y_lower", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "/", "(", "2", "*", "h", ")", "\n", "", "logdet_num", "=", "x", "[", "0", "]", ".", "new_zeros", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "logdet_num", "[", "i", "]", "=", "torch", ".", "slogdet", "(", "J_num", "[", "i", "]", ")", "[", "1", "]", "\n", "\n", "", "return", "logdet_num", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.get_node_by_name": [[407, 415], ["None"], "methods", ["None"], ["", "def", "get_node_by_name", "(", "self", ",", "name", ")", "->", "Optional", "[", "Node", "]", ":", "\n", "        ", "\"\"\"\n        Return the first node in the graph with the provided name.\n        \"\"\"", "\n", "for", "node", "in", "self", ".", "node_list", ":", "\n", "            ", "if", "node", ".", "name", "==", "name", ":", "\n", "                ", "return", "node", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.get_module_by_name": [[416, 425], ["graph_inn.GraphINN.get_node_by_name"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.get_node_by_name"], ["", "def", "get_module_by_name", "(", "self", ",", "name", ")", "->", "Optional", "[", "nn", ".", "Module", "]", ":", "\n", "        ", "\"\"\"\n        Return module of the first node in the graph with the provided name.\n        \"\"\"", "\n", "node", "=", "self", ".", "get_node_by_name", "(", "name", ")", "\n", "try", ":", "\n", "            ", "return", "node", ".", "module", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.topological_order": [[427, 472], ["collections.defaultdict", "edges_out_to_in.items", "collections.deque", "len", "collections.deque.popleft", "sorted_nodes.append", "list", "sum", "ValueError", "edges_in_to_out[].add", "edges_out_to_in[].remove", "edges_in_to_out[].remove", "ValueError", "map", "len", "collections.deque.append", "collections.defaultdict.values"], "function", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["", "", "", "def", "topological_order", "(", "all_nodes", ":", "List", "[", "Node", "]", ",", "in_nodes", ":", "List", "[", "InputNode", "]", ",", "\n", "out_nodes", ":", "List", "[", "OutputNode", "]", ")", "->", "List", "[", "Node", "]", ":", "\n", "    ", "\"\"\"\n    Computes the topological order of nodes.\n\n    Parameters:\n        all_nodes: All nodes in the computation graph.\n        in_nodes: Input nodes (must also be present in `all_nodes`)\n        out_nodes: Output nodes (must also be present in `all_nodes`)\n\n    Returns:\n        A sorted list of nodes, where the inputs to some node in the list\n        are available when all previous nodes in the list have been executed.\n    \"\"\"", "\n", "# Edge dicts in both directions", "\n", "edges_out_to_in", "=", "{", "node_b", ":", "{", "node_a", "for", "node_a", ",", "out_idx", "in", "node_b", ".", "inputs", "}", "for", "\n", "node_b", "in", "all_nodes", "+", "out_nodes", "}", "\n", "edges_in_to_out", "=", "defaultdict", "(", "set", ")", "\n", "for", "node_out", ",", "node_ins", "in", "edges_out_to_in", ".", "items", "(", ")", ":", "\n", "        ", "for", "node_in", "in", "node_ins", ":", "\n", "            ", "edges_in_to_out", "[", "node_in", "]", ".", "add", "(", "node_out", ")", "\n", "\n", "# Kahn's algorithm starting from the output nodes", "\n", "", "", "sorted_nodes", "=", "[", "]", "\n", "no_pending_edges", "=", "deque", "(", "out_nodes", ")", "\n", "\n", "while", "len", "(", "no_pending_edges", ")", ">", "0", ":", "\n", "        ", "node", "=", "no_pending_edges", ".", "popleft", "(", ")", "\n", "sorted_nodes", ".", "append", "(", "node", ")", "\n", "for", "in_node", "in", "list", "(", "edges_out_to_in", "[", "node", "]", ")", ":", "\n", "            ", "edges_out_to_in", "[", "node", "]", ".", "remove", "(", "in_node", ")", "\n", "edges_in_to_out", "[", "in_node", "]", ".", "remove", "(", "node", ")", "\n", "\n", "if", "len", "(", "edges_in_to_out", "[", "in_node", "]", ")", "==", "0", ":", "\n", "                ", "no_pending_edges", ".", "append", "(", "in_node", ")", "\n", "\n", "", "", "", "for", "in_node", "in", "in_nodes", ":", "\n", "        ", "if", "in_node", "not", "in", "sorted_nodes", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Error in graph: {in_node} is not connected \"", "\n", "f\"to any output.\"", ")", "\n", "\n", "", "", "if", "sum", "(", "map", "(", "len", ",", "edges_in_to_out", ".", "values", "(", ")", ")", ")", "==", "0", ":", "\n", "        ", "return", "sorted_nodes", "[", ":", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Graph is cyclic.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.ActNorm.__init__": [[27, 53], ["InvertibleModule.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "invertible_resnet.ActNorm._register_load_state_dict_pre_hook", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "invertible_resnet.ActNorm._initialize_with_data", "range", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.ActNorm._initialize_with_data"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "init_data", ":", "Union", "[", "torch", ".", "Tensor", ",", "None", "]", "=", "None", ")", ":", "\n", "        ", "'''\n        Args:\n          init_data: If ``None``, use the first batch of data passed through this\n            module to initialize the mean and standard deviation.\n            If ``torch.Tensor``, use this as data to initialize instead of the\n            first real batch.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "dims_in", "=", "dims_in", "[", "0", "]", "\n", "param_dims", "=", "[", "1", ",", "self", ".", "dims_in", "[", "0", "]", "]", "+", "[", "1", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dims_in", ")", "-", "1", ")", "]", "\n", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "*", "param_dims", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "*", "param_dims", ")", ")", "\n", "\n", "if", "init_data", ":", "\n", "            ", "self", ".", "_initialize_with_data", "(", "init_data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "init_on_next_batch", "=", "True", "\n", "\n", "", "def", "on_load_state_dict", "(", "*", "args", ")", ":", "\n", "# when this module is loading state dict, we SHOULDN'T init with data,", "\n", "# because that will reset the trained parameters. Registering a hook", "\n", "# that disable this initialisation.", "\n", "            ", "self", ".", "init_on_next_batch", "=", "False", "\n", "", "self", ".", "_register_load_state_dict_pre_hook", "(", "on_load_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.ActNorm._initialize_with_data": [[54, 65], ["all", "torch.log", "torch.log", "torch.log", "torch.log", "invertible_resnet.ActNorm.scale.data.view", "invertible_resnet.ActNorm.scale.exp", "invertible_resnet.ActNorm.bias.data.view", "data.transpose().contiguous().view().mean", "data.transpose().contiguous().view().std", "range", "data.transpose().contiguous().view", "len", "data.transpose().contiguous().view", "data.transpose().contiguous", "data.transpose().contiguous", "data.transpose", "data.transpose"], "methods", ["None"], ["", "def", "_initialize_with_data", "(", "self", ",", "data", ")", ":", "\n", "# Initialize to mean 0 and std 1 with sample batch", "\n", "# 'data' expected to be of shape (batch, channels[, ...])", "\n", "        ", "assert", "all", "(", "[", "data", ".", "shape", "[", "i", "+", "1", "]", "==", "self", ".", "dims_in", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dims_in", ")", ")", "]", ")", ",", "\"Can't initialize ActNorm layer, provided data don't match input dimensions.\"", "\n", "self", ".", "scale", ".", "data", ".", "view", "(", "-", "1", ")", "[", ":", "]", "=", "torch", ".", "log", "(", "1", "/", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "dims_in", "[", "0", "]", ",", "-", "1", ")", ".", "std", "(", "dim", "=", "-", "1", ")", ")", "\n", "data", "=", "data", "*", "self", ".", "scale", ".", "exp", "(", ")", "\n", "self", ".", "bias", ".", "data", ".", "view", "(", "-", "1", ")", "[", ":", "]", "=", "-", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "dims_in", "[", "0", "]", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "init_on_next_batch", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.ActNorm.forward": [[66, 78], ["invertible_resnet.ActNorm._initialize_with_data", "invertible_resnet.ActNorm.scale.sum", "numpy.prod", "invertible_resnet.ActNorm.scale.exp", "invertible_resnet.ActNorm.scale.exp"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.ActNorm._initialize_with_data"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "init_on_next_batch", ":", "\n", "            ", "self", ".", "_initialize_with_data", "(", "x", "[", "0", "]", ")", "\n", "\n", "", "jac", "=", "(", "self", ".", "scale", ".", "sum", "(", ")", "*", "np", ".", "prod", "(", "self", ".", "dims_in", "[", "1", ":", "]", ")", ")", ".", "repeat", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ")", "\n", "if", "rev", ":", "\n", "            ", "jac", "=", "-", "jac", "\n", "\n", "", "if", "not", "rev", ":", "\n", "            ", "return", "[", "x", "[", "0", "]", "*", "self", ".", "scale", ".", "exp", "(", ")", "+", "self", ".", "bias", "]", ",", "jac", "\n", "", "else", ":", "\n", "            ", "return", "[", "(", "x", "[", "0", "]", "-", "self", ".", "bias", ")", "/", "self", ".", "scale", ".", "exp", "(", ")", "]", ",", "jac", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.ActNorm.output_dims": [[79, 82], ["len"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "assert", "len", "(", "input_dims", ")", "==", "1", ",", "\"Can only use 1 input\"", "\n", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer.__init__": [[91, 132], ["InvertibleModule.__init__", "torch.Sequential", "torch.Sequential", "len", "range", "invertible_resnet.IResNetLayer.layers.append", "range", "invertible_resnet.IResNetLayer.layers.append", "torch.ELU", "torch.ELU", "sum", "torch.Linear", "torch.Linear", "invertible_resnet.IResNetLayer.layers.append", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "invertible_resnet.IResNetLayer.layers.append", "torch.Conv2d", "torch.Conv2d", "range", "zip", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "internal_size", "=", "None", ",", "\n", "n_internal_layers", "=", "1", ",", "\n", "jacobian_iterations", "=", "20", ",", "\n", "hutchinson_samples", "=", "1", ",", "\n", "fixed_point_iterations", "=", "50", ",", "\n", "lipschitz_iterations", "=", "10", ",", "\n", "lipschitz_batchsize", "=", "10", ",", "\n", "spectral_norm_max", "=", "0.8", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "if", "internal_size", ":", "\n", "            ", "self", ".", "internal_size", "=", "internal_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "internal_size", "=", "2", "*", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "", "self", ".", "n_internal_layers", "=", "n_internal_layers", "\n", "self", ".", "jacobian_iterations", "=", "jacobian_iterations", "\n", "self", ".", "hutchinson_samples", "=", "hutchinson_samples", "\n", "self", ".", "fixed_point_iterations", "=", "fixed_point_iterations", "\n", "self", ".", "lipschitz_iterations", "=", "lipschitz_iterations", "\n", "self", ".", "lipschitz_batchsize", "=", "lipschitz_batchsize", "\n", "self", ".", "spectral_norm_max", "=", "spectral_norm_max", "\n", "assert", "0", "<", "spectral_norm_max", "<=", "1", ",", "\"spectral_norm_max must be in (0,1].\"", "\n", "\n", "self", ".", "dims_in", "=", "dims_in", "[", "0", "]", "\n", "if", "len", "(", "self", ".", "dims_in", ")", "==", "1", ":", "\n", "# Linear case", "\n", "            ", "self", ".", "layers", "=", "[", "nn", ".", "Linear", "(", "self", ".", "dims_in", "[", "0", "]", ",", "self", ".", "internal_size", ")", ",", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_internal_layers", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "self", ".", "internal_size", ",", "self", ".", "internal_size", ")", ")", "\n", "", "self", ".", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "self", ".", "internal_size", ",", "self", ".", "dims_in", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "# Convolutional case", "\n", "            ", "self", ".", "layers", "=", "[", "nn", ".", "Conv2d", "(", "self", ".", "dims_in", "[", "0", "]", ",", "self", ".", "internal_size", ",", "3", ",", "padding", "=", "1", ")", ",", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_internal_layers", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "self", ".", "internal_size", ",", "self", ".", "internal_size", ",", "3", ",", "padding", "=", "1", ")", ")", "\n", "", "self", ".", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "self", ".", "internal_size", ",", "self", ".", "dims_in", "[", "0", "]", ",", "3", ",", "padding", "=", "1", ")", ")", "\n", "", "elus", "=", "[", "nn", ".", "ELU", "(", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", "]", "\n", "module_list", "=", "sum", "(", "zip", "(", "self", ".", "layers", ",", "elus", ")", ",", "(", ")", ")", "[", ":", "-", "1", "]", "# interleaves the lists", "\n", "self", ".", "residual", "=", "nn", ".", "Sequential", "(", "*", "module_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer.lipschitz_correction": [[134, 158], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "len", "range", "range", "W.t().matmul().squeeze", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "torch.nn.functional.conv_transpose2d", "torch.nn.functional.conv_transpose2d", "W.t().matmul", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "W.matmul", "W.matmul().squeeze", "torch.nn.functional.conv2d().view", "torch.nn.functional.conv2d().view", "torch.nn.functional.conv_transpose2d.view", "torch.nn.functional.conv_transpose2d.view", "W.t", "torch.nn.functional.conv_transpose2d.unsqueeze", "torch.nn.functional.conv_transpose2d.unsqueeze", "W.matmul", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "torch.nn.functional.conv_transpose2d.unsqueeze", "torch.nn.functional.conv_transpose2d.unsqueeze"], "methods", ["None"], ["", "def", "lipschitz_correction", "(", "self", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Power method to approximate spectral norm", "\n", "# Following https://arxiv.org/pdf/1804.04368.pdf", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "                ", "W", "=", "self", ".", "layers", "[", "i", "]", ".", "weight", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "lipschitz_batchsize", ",", "W", ".", "shape", "[", "1", "]", ",", "*", "self", ".", "dims_in", "[", "1", ":", "]", ",", "device", "=", "W", ".", "device", ")", "\n", "\n", "if", "len", "(", "self", ".", "dims_in", ")", "==", "1", ":", "\n", "# Linear case", "\n", "                    ", "for", "j", "in", "range", "(", "self", ".", "lipschitz_iterations", ")", ":", "\n", "                        ", "x", "=", "W", ".", "t", "(", ")", ".", "matmul", "(", "W", ".", "matmul", "(", "x", ".", "unsqueeze", "(", "-", "1", ")", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "spectral_norm", "=", "(", "torch", ".", "norm", "(", "W", ".", "matmul", "(", "x", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ",", "dim", "=", "1", ")", "/", "torch", ".", "norm", "(", "x", ",", "dim", "=", "1", ")", ")", ".", "max", "(", ")", "\n", "", "else", ":", "\n", "# Convolutional case", "\n", "                    ", "for", "j", "in", "range", "(", "self", ".", "lipschitz_iterations", ")", ":", "\n", "                        ", "x", "=", "conv2d", "(", "x", ",", "W", ")", "\n", "x", "=", "conv_transpose2d", "(", "x", ",", "W", ")", "\n", "", "spectral_norm", "=", "(", "torch", ".", "norm", "(", "conv2d", "(", "x", ",", "W", ")", ".", "view", "(", "self", ".", "lipschitz_batchsize", ",", "-", "1", ")", ",", "dim", "=", "1", ")", "/", "torch", ".", "norm", "(", "x", ".", "view", "(", "self", ".", "lipschitz_batchsize", ",", "-", "1", ")", ",", "dim", "=", "1", ")", ")", ".", "max", "(", ")", "\n", "\n", "", "if", "spectral_norm", ">", "self", ".", "spectral_norm_max", ":", "\n", "                    ", "self", ".", "layers", "[", "i", "]", ".", "weight", ".", "data", "*=", "self", ".", "spectral_norm_max", "/", "spectral_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer.forward": [[160, 176], ["invertible_resnet.IResNetLayer._jacobian", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "invertible_resnet.IResNetLayer.residual", "invertible_resnet.IResNetLayer.residual", "invertible_resnet.IResNetLayer.residual", "x_hat.detach"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer._jacobian"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "if", "jac", ":", "\n", "            ", "jac", "=", "self", ".", "_jacobian", "(", "x", ",", "c", ",", "rev", "=", "rev", ")", "\n", "", "else", ":", "\n", "            ", "jac", "=", "None", "\n", "\n", "", "if", "not", "rev", ":", "\n", "            ", "return", "[", "x", "[", "0", "]", "+", "self", ".", "residual", "(", "x", "[", "0", "]", ")", "]", ",", "jac", "\n", "", "else", ":", "\n", "# Fixed-point iteration (works if residual has Lipschitz constant < 1)", "\n", "            ", "y", "=", "x", "[", "0", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x_hat", "=", "x", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "fixed_point_iterations", ")", ":", "\n", "                    ", "x_hat", "=", "y", "-", "self", ".", "residual", "(", "x_hat", ")", "\n", "", "", "return", "[", "y", "-", "self", ".", "residual", "(", "x_hat", ".", "detach", "(", ")", ")", "]", ",", "jac", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer._jacobian": [[178, 226], ["x[].new_zeros", "range", "torch.randn_like().sign", "torch.randn_like().sign", "torch.randn_like().sign", "torch.randn_like().sign", "v.clone", "range", "invertible_resnet.IResNetLayer._jacobian", "range", "invertible_resnet.IResNetLayer.residual", "torch.stack().mean.append", "torch.stack().mean.append", "len", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "v_left[].view().matmul().squeeze().squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "v_left[].view().matmul().squeeze", "v_left[].view().matmul", "v_right[].view", "v_left[].view"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer._jacobian", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["", "", "def", "_jacobian", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ")", ":", "\n", "        ", "if", "rev", ":", "\n", "            ", "return", "-", "self", ".", "_jacobian", "(", "x", ",", "c", "=", "c", ")", "\n", "\n", "# Initialize log determinant of Jacobian to zero", "\n", "", "batch_size", "=", "x", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "logdet_J", "=", "x", "[", "0", "]", ".", "new_zeros", "(", "batch_size", ")", "\n", "# Make sure we can get vector-Jacobian product w.r.t. x even if x is the network input", "\n", "if", "x", "[", "0", "]", ".", "is_leaf", ":", "\n", "            ", "x", "[", "0", "]", ".", "requires_grad", "=", "True", "\n", "\n", "# Sample random vectors for Hutchinson trace estimate", "\n", "", "v_right", "=", "[", "torch", ".", "randn_like", "(", "x", "[", "0", "]", ")", ".", "sign", "(", ")", "for", "i", "in", "range", "(", "self", ".", "hutchinson_samples", ")", "]", "\n", "v_left", "=", "[", "v", ".", "clone", "(", ")", "for", "v", "in", "v_right", "]", "\n", "\n", "# Compute terms of power series", "\n", "for", "k", "in", "range", "(", "1", ",", "self", ".", "jacobian_iterations", "+", "1", ")", ":", "\n", "# Estimate trace of Jacobian of residual branch", "\n", "            ", "trace_est", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "hutchinson_samples", ")", ":", "\n", "# Compute vector-Jacobian product v.t() * J", "\n", "                ", "residual", "=", "self", ".", "residual", "(", "x", "[", "0", "]", ")", "\n", "v_left", "[", "i", "]", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "[", "residual", "]", ",", "\n", "inputs", "=", "x", ",", "\n", "grad_outputs", "=", "[", "v_left", "[", "i", "]", "]", ")", "[", "0", "]", "\n", "trace_est", ".", "append", "(", "v_left", "[", "i", "]", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ")", ".", "matmul", "(", "v_right", "[", "i", "]", ".", "view", "(", "batch_size", ",", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", ")", "\n", "", "if", "len", "(", "trace_est", ")", ">", "1", ":", "\n", "                ", "trace_est", "=", "torch", ".", "stack", "(", "trace_est", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "trace_est", "=", "trace_est", "[", "0", "]", "\n", "# Update power series approximation of log determinant for the whole block", "\n", "", "logdet_J", "=", "logdet_J", "+", "(", "-", "1", ")", "**", "(", "k", "+", "1", ")", "*", "trace_est", "/", "k", "\n", "\n", "# # Shorter version when self.hutchinson_samples is fixed to one", "\n", "# v_right = torch.randn_like(x[0])", "\n", "# v_left = v_right.clone()", "\n", "# residual = self.residual(x[0])", "\n", "# for k in range(1, self.jacobian_iterations+1):", "\n", "#     # Compute vector-Jacobian product v.t() * J", "\n", "#     v_left = torch.autograd.grad(outputs=[residual],", "\n", "#                                  inputs=x,", "\n", "#                                  grad_outputs=[v_left],", "\n", "#                                  retain_graph=(k < self.jacobian_iterations))[0]", "\n", "#     # Iterate power series approximation of log determinant", "\n", "#     trace_est = v_left.view(batch_size, 1, -1).matmul(v_right.view(batch_size, -1, 1)).squeeze(-1).squeeze(-1)", "\n", "#     logdet_J = logdet_J + (-1)**(k+1) * trace_est / k", "\n", "\n", "", "return", "logdet_J", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer.output_dims": [[228, 231], ["len"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "assert", "len", "(", "input_dims", ")", "==", "1", ",", "\"Can only use 1 input\"", "\n", "return", "input_dims", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.__init__": [[23, 30], ["InvertibleModule.__init__", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.eye().bool", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "self", ".", "x_dims", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "# Prepare masks for filling the (triangular) Cholesky factors of the precision matrices", "\n", "self", ".", "mask_upper", "=", "(", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "self", ".", "x_dims", ",", "self", ".", "x_dims", ")", ",", "diagonal", "=", "1", ")", "==", "1", ")", "\n", "self", ".", "mask_diagonal", "=", "torch", ".", "eye", "(", "self", ".", "x_dims", ",", "self", ".", "x_dims", ")", ".", "bool", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.pick_mixture_component": [[32, 52], ["torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "isinstance", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.sum().int", "torch.sum().int", "torch.sum().int", "torch.sum().int", "rng.manual_seed.manual_seed.manual_seed", "rng.manual_seed.manual_seed.seed", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pick_mixture_component", "(", "w", ",", "seed", "=", "None", ")", ":", "\n", "        ", "'''Randomly choose mixture component indices with probability given by\n        the component weights w. Works on batches of component weights.\n\n        w:      Weights of the mixture components, must be positive and sum to one\n        seed:   Optional RNG seed for consistent decisions'''", "\n", "\n", "w_thresholds", "=", "torch", ".", "cumsum", "(", "w", ",", "dim", "=", "1", ")", "\n", "# Prepare local random number generator", "\n", "rng", "=", "torch", ".", "Generator", "(", "device", "=", "w", ".", "device", ")", "\n", "if", "isinstance", "(", "seed", ",", "int", ")", ":", "\n", "            ", "rng", "=", "rng", ".", "manual_seed", "(", "seed", ")", "\n", "", "else", ":", "\n", "            ", "rng", ".", "seed", "(", ")", "\n", "# Draw one uniform random number per batch row and compare against thresholds", "\n", "", "u", "=", "torch", ".", "rand", "(", "w", ".", "shape", "[", "0", "]", ",", "1", ",", "device", "=", "w", ".", "device", ",", "generator", "=", "rng", ")", "\n", "indices", "=", "torch", ".", "sum", "(", "u", ">", "w_thresholds", ",", "dim", "=", "1", ")", ".", "int", "(", ")", "\n", "# Return mixture component indices", "\n", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.normalize_weights": [[54, 63], ["torch.softmax", "torch.softmax", "w.max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "normalize_weights", "(", "w", ")", ":", "\n", "        ", "'''Apply softmax to ensure component weights are positive and sum to\n        one. Works on batches of component weights.\n\n        w:  Unnormalized weights for Gaussian mixture components, must be of\n            size [batch_size, n_components]'''", "\n", "\n", "return", "F", ".", "softmax", "(", "w", "-", "w", ".", "max", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.nll_loss": [[65, 77], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "nll_loss", "(", "w", ",", "z", ",", "log_jacobian", ")", ":", "\n", "        ", "'''Negative log-likelihood loss for training a Mixture Density Network.\n\n        w:              Mixture component weights, must be positive and sum to\n                        one. Tensor must be of size [batch_size, n_components].\n        z:              Latent codes for all mixture components. Tensor must be\n                        of size [batch, n_components, n_dims].\n        log_jacobian:   Jacobian log-determinants for each precision matrix.\n                        Tensor size must be [batch_size, n_components].'''", "\n", "\n", "return", "-", "(", "(", "-", "0.5", "*", "(", "z", "**", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "+", "log_jacobian", ")", ".", "exp", "(", ")", "*", "w", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.nll_upper_bound": [[79, 92], ["w.log"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "nll_upper_bound", "(", "w", ",", "z", ",", "log_jacobian", ")", ":", "\n", "        ", "'''Numerically more stable upper bound of the negative log-likelihood\n        loss for training a Mixture Density Network.\n\n        w:              Mixture component weights, must be positive and sum to\n                        one. Tensor must be of size [batch_size, n_components].\n        z:              Latent codes for all mixture components. Tensor must be\n                        of size [batch, n_components, n_dims].\n        log_jacobian:   Jacobian log-determinants for each precision matrix.\n                        Tensor size must be [batch_size, n_components].'''", "\n", "\n", "return", "-", "(", "w", ".", "log", "(", ")", "-", "0.5", "*", "(", "z", "**", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "+", "log_jacobian", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.forward": [[94, 171], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "U_entries[].reshape", "U_entries[].exp().reshape", "len", "len", "gaussian_mixture.GaussianMixtureModel.mask_upper.expand", "gaussian_mixture.GaussianMixtureModel.mask_diagonal.expand", "U_entries[].exp", "isinstance", "gaussian_mixture.GaussianMixtureModel.pick_mixture_component", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "U_entries[].sum", "len", "U_entries[].sum", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "range", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "range", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.pick_mixture_component"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "'''Map between data distribution and standard normal latent distribution\n        of mixture components or entire mixture, in an invertible way.\n\n        x:  Data during forward pass or latent codes during backward pass. Size\n            must be [batch_size, n_dims] if component indices i are specified\n            and should be [batch_size, n_components, n_dims] if not.\n\n        The conditional input c must be a list [w, mu, U, i] of parameters for\n        the Gaussian mixture model with the following properties:\n\n        w:  Weights of the mixture components, must be positive and sum to one\n            and have size [batch_size, n_components].\n        mu: Means of the mixture components, must have size [batch_size,\n            n_components, n_dims].\n        U:  Entries for the (upper triangular) Cholesky factors for the\n            precision matrices of the mixture components. These are needed to\n            parameterize the covariance of the mixture components and must have\n            size [batch_size, n_components, n_dims * (n_dims + 1) / 2].\n        i:  Tensor of component indices (size [batch_size]), or a single integer\n            to be used as random number generator seed for component selection,\n            or None to indicate that all mixture components are modelled.'''", "\n", "assert", "len", "(", "x", ")", "==", "1", ",", "f\"GaussianMixtureModel got {len(x)} inputs, but \"", "f\"only one is allowed.\"", "\n", "x", "=", "x", "[", "0", "]", "\n", "\n", "# Get GMM parameters", "\n", "w", ",", "mu", ",", "U_entries", ",", "i", "=", "c", "\n", "batch_size", ",", "n_components", "=", "w", ".", "shape", "\n", "\n", "# Construct upper triangular Cholesky factors U of all precision matrices", "\n", "U", "=", "torch", ".", "zeros", "(", "batch_size", ",", "n_components", ",", "self", ".", "x_dims", ",", "self", ".", "x_dims", ",", "device", "=", "x", ".", "device", ")", "\n", "# Fill everything above the diagonal as is", "\n", "U", "[", "self", ".", "mask_upper", ".", "expand", "(", "batch_size", ",", "n_components", ",", "-", "1", ",", "-", "1", ")", "]", "=", "U_entries", "[", ":", ",", ":", ",", "self", ".", "x_dims", ":", "]", ".", "reshape", "(", "-", "1", ")", "\n", "# Diagonal entries must be positive", "\n", "U", "[", "self", ".", "mask_diagonal", ".", "expand", "(", "batch_size", ",", "n_components", ",", "-", "1", ",", "-", "1", ")", "]", "=", "U_entries", "[", ":", ",", ":", ",", ":", "self", ".", "x_dims", "]", ".", "exp", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# Indices of chosen mixture components, if provided", "\n", "if", "i", "is", "None", ":", "\n", "            ", "fixed_components", "=", "False", "\n", "", "else", ":", "\n", "            ", "fixed_components", "=", "True", "\n", "if", "not", "isinstance", "(", "i", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "i", "=", "self", ".", "pick_mixture_component", "(", "w", ",", "seed", "=", "i", ")", "\n", "\n", "", "", "if", "jac", ":", "\n", "# Compute Jacobian log-determinants", "\n", "# Note: we avoid a log operation by taking diagonal entries directly from U_entries, where they are in log space", "\n", "            ", "if", "fixed_components", ":", "\n", "# Keep Jacobian log-determinants for chosen components only", "\n", "                ", "j", "=", "torch", ".", "stack", "(", "[", "U_entries", "[", "b", ",", "i", "[", "b", "]", ",", ":", "self", ".", "x_dims", "]", ".", "sum", "(", "dim", "=", "-", "1", ")", "for", "b", "in", "range", "(", "batch_size", ")", "]", ")", "\n", "", "else", ":", "\n", "# Keep Jacobian log-determinants for all components simultaneously", "\n", "                ", "j", "=", "U_entries", "[", ":", ",", ":", ",", ":", "self", ".", "x_dims", "]", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n", "", "if", "rev", ":", "\n", "                ", "j", "*=", "-", "1", "\n", "", "", "else", ":", "\n", "            ", "j", "=", "None", "\n", "\n", "# Actual forward and inverse pass", "\n", "", "if", "not", "rev", ":", "\n", "            ", "if", "fixed_components", ":", "\n", "# Return latent codes of x according to chosen component distributions only", "\n", "                ", "return", "[", "torch", ".", "stack", "(", "[", "torch", ".", "matmul", "(", "U", "[", "b", ",", "i", "[", "b", "]", ",", ":", ",", ":", "]", ",", "x", "[", "b", ",", ":", "]", "-", "mu", "[", "b", ",", "i", "[", "b", "]", ",", ":", "]", ")", "for", "b", "in", "range", "(", "batch_size", ")", "]", ")", "]", ",", "j", "\n", "", "else", ":", "\n", "# Return latent codes of x according to all component distributions simultaneously", "\n", "                ", "if", "len", "(", "x", ".", "shape", ")", "<", "3", ":", "\n", "                    ", "x", "=", "x", "[", ":", ",", "None", ",", ":", "]", "\n", "", "return", "[", "torch", ".", "matmul", "(", "U", ",", "(", "x", "-", "mu", ")", "[", "...", ",", "None", "]", ")", "[", "...", ",", "0", "]", "]", ",", "j", "\n", "", "", "else", ":", "\n", "            ", "if", "fixed_components", ":", "\n", "# Transform latent samples to samples from chosen mixture distributions", "\n", "                ", "return", "[", "torch", ".", "stack", "(", "[", "mu", "[", "b", ",", "i", "[", "b", "]", ",", ":", "]", "+", "torch", ".", "matmul", "(", "torch", ".", "inverse", "(", "U", "[", "b", ",", "i", "[", "b", "]", ",", ":", ",", ":", "]", ")", ",", "x", "[", "b", ",", ":", "]", ")", "for", "b", "in", "range", "(", "batch_size", ")", "]", ")", "]", ",", "j", "\n", "", "else", ":", "\n", "# Transform latent samples to samples from all mixture distributions simultaneously", "\n", "                ", "return", "[", "torch", ".", "matmul", "(", "torch", ".", "inverse", "(", "U", ")", ",", "x", "[", "...", ",", "None", "]", ")", "[", "...", ",", "0", "]", "+", "mu", "]", ",", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.output_dims": [[172, 175], ["len"], "methods", ["None"], ["", "", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "assert", "len", "(", "input_dims", ")", "==", "1", ",", "\"Can only use 1 input\"", "\n", "return", "input_dims", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.base.InvertibleModule.__init__": [[34, 48], ["torch.Module.__init__", "list", "list"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ":", "Iterable", "[", "Tuple", "[", "int", "]", "]", ",", "\n", "dims_c", ":", "Iterable", "[", "Tuple", "[", "int", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dims_in: list of tuples specifying the shape of the inputs to this\n                     operator: ``dims_in = [shape_x_0, shape_x_1, ...]``\n            dims_c:  list of tuples specifying the shape of the conditions to\n                     this operator.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "dims_c", "is", "None", ":", "\n", "            ", "dims_c", "=", "[", "]", "\n", "", "self", ".", "dims_in", "=", "list", "(", "dims_in", ")", "\n", "self", ".", "dims_c", "=", "list", "(", "dims_c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.base.InvertibleModule.forward": [[49, 81], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_or_z", ":", "Iterable", "[", "Tensor", "]", ",", "c", ":", "Iterable", "[", "Tensor", "]", "=", "None", ",", "\n", "rev", ":", "bool", "=", "False", ",", "jac", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "Tuple", "[", "Tensor", "]", ",", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Perform a forward (default, ``rev=False``) or backward pass (``rev=True``)\n        through this module/operator.\n\n        **Note to implementers:**\n\n        - Subclasses MUST return a Jacobian when ``jac=True``, but CAN return a\n          valid Jacobian when ``jac=False`` (not punished). The latter is only recommended\n          if the computation of the Jacobian is trivial.\n        - Subclasses MUST follow the convention that the returned Jacobian be\n          consistent with the evaluation direction. Let's make this more precise:\n          Let :math:`f` be the function that the subclass represents. Then:\n\n          .. math::\n\n              J &= \\\\log \\\\det \\\\frac{\\\\partial f}{\\\\partial x} \\\\\\\\\n              -J &= \\\\log \\\\det \\\\frac{\\\\partial f^{-1}}{\\\\partial z}.\n\n          Any subclass MUST return :math:`J` for forward evaluation (``rev=False``),\n          and :math:`-J` for backward evaluation (``rev=True``).\n\n        Args:\n            x_or_z: input data (array-like of one or more tensors)\n            c:      conditioning data (array-like of none or more tensors)\n            rev:    perform backward pass\n            jac:    return Jacobian associated to the direction\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "f\"{self.__class__.__name__} does not provide forward(...) method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.base.InvertibleModule.log_jacobian": [[82, 85], ["DeprecationWarning"], "methods", ["None"], ["", "def", "log_jacobian", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''This method is deprecated, and does nothing except raise a warning.'''", "\n", "raise", "DeprecationWarning", "(", "\"module.log_jacobian(...) is deprecated. \"", "\n", "\"module.forward(..., jac=True) returns a \"", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.base.InvertibleModule.output_dims": [[88, 113], ["NotImplementedError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ":", "List", "[", "Tuple", "[", "int", "]", "]", ")", "->", "List", "[", "Tuple", "[", "int", "]", "]", ":", "\n", "        ", "'''\n        Used for shape inference during construction of the graph. MUST be\n        implemented for each subclass of ``InvertibleModule``.\n\n        Args:\n          input_dims: A list with one entry for each input to the module.\n            Even if the module only has one input, must be a list with one\n            entry. Each entry is a tuple giving the shape of that input,\n            excluding the batch dimension. For example for a module with one\n            input, which receives a 32x32 pixel RGB image, ``input_dims`` would\n            be ``[(3, 32, 32)]``\n\n        Returns:\n            A list structured in the same way as ``input_dims``. Each entry\n            represents one output of the module, and the entry is a tuple giving\n            the shape of that output. For example if the module splits the image\n            into a right and a left half, the return value should be\n            ``[(3, 16, 32), (3, 16, 32)]``. It is up to the implementor of the\n            subclass to ensure that the total number of elements in all inputs\n            and all outputs is consistent.\n\n        '''", "\n", "raise", "NotImplementedError", "(", "\n", "f\"{self.__class__.__name__} does not provide output_dims(...)\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoActTwoSided.__init__": [[29, 53], ["InvertibleModule.__init__", "len", "inv_auto_layers.InvAutoActTwoSided.alpha_pos.view", "torch.Parameter", "torch.Parameter", "torch.Parameter", "inv_auto_layers.InvAutoActTwoSided.alpha_neg.view", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "init_pos", ":", "float", "=", "2.0", ",", "init_neg", ":", "float", "=", "0.5", ",", "learnable", ":", "bool", "=", "True", ")", ":", "\n", "        ", "'''\n        Args:\n          init_pos: The initial slope for the positive half of the activation. Must be > 0.\n            Note that the initial value accounts for the exp-activation, meaning\n            :math:`\\\\exp(\\\\alpha_+) =` ``init_pos``.\n          init_pos: The initial slope for the negative half of the activation. Must be > 0.\n            The initial value accounts for the exp-activation the same as init_pos.\n          learnable: If False, the slopes are fixed at their initial value, and not learned.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "tensor_rank", "=", "len", "(", "dims_in", "[", "0", "]", ")", "\n", "\n", "self", ".", "alpha_pos", "=", "np", ".", "log", "(", "init_pos", ")", "*", "torch", ".", "ones", "(", "dims_in", "[", "0", "]", "[", "0", "]", ")", "\n", "self", ".", "alpha_pos", "=", "self", ".", "alpha_pos", ".", "view", "(", "1", ",", "-", "1", ",", "*", "(", "[", "1", "]", "*", "(", "self", ".", "tensor_rank", "-", "1", ")", ")", ")", "\n", "self", ".", "alpha_pos", "=", "nn", ".", "Parameter", "(", "self", ".", "alpha_pos", ")", "\n", "\n", "self", ".", "alpha_neg", "=", "np", ".", "log", "(", "init_neg", ")", "*", "torch", ".", "ones", "(", "dims_in", "[", "0", "]", "[", "0", "]", ")", "\n", "self", ".", "alpha_neg", "=", "self", ".", "alpha_neg", ".", "view", "(", "1", ",", "-", "1", ",", "*", "(", "[", "1", "]", "*", "(", "self", ".", "tensor_rank", "-", "1", ")", ")", ")", "\n", "self", ".", "alpha_neg", "=", "nn", ".", "Parameter", "(", "self", ".", "alpha_neg", ")", "\n", "\n", "if", "not", "learnable", ":", "\n", "            ", "self", ".", "alpha_pos", ".", "requires_grad", "=", "False", "\n", "self", ".", "alpha_neg", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoActTwoSided.forward": [[54, 66], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x[].sign", "tuple", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "range"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "\n", "        ", "log_slope", "=", "self", ".", "alpha_pos", "+", "0.5", "*", "(", "self", ".", "alpha_neg", "-", "self", ".", "alpha_pos", ")", "*", "(", "1", "-", "x", "[", "0", "]", ".", "sign", "(", ")", ")", "\n", "if", "rev", ":", "\n", "            ", "log_slope", "*=", "-", "1", "\n", "\n", "", "if", "jac", ":", "\n", "            ", "j", "=", "torch", ".", "sum", "(", "log_slope", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "tensor_rank", "+", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "j", "=", "None", "\n", "\n", "", "return", "[", "x", "[", "0", "]", "*", "torch", ".", "exp", "(", "log_slope", ")", "]", ",", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoActTwoSided.output_dims": [[67, 71], ["len", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoAct.__init__": [[90, 105], ["InvertibleModule.__init__", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "slope_init", "=", "2.0", ",", "learnable", "=", "True", ")", ":", "\n", "        ", "'''\n        Args:\n          slope_init: The initial value of the slope on the positive side.\n            Accounts for the exp-activation, i.e. :math:`\\\\exp(\\\\alpha) =` ``slope_init``.\n          learnable: If False, the slopes are fixed at their initial value, and not learned.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "self", ".", "tensor_rank", "=", "len", "(", "dims_in", "[", "0", "]", ")", "\n", "self", ".", "alpha", "=", "np", ".", "log", "(", "slope_init", ")", "*", "torch", ".", "ones", "(", "1", ",", "dims_in", "[", "0", "]", "[", "0", "]", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "dims_in", "[", "0", "]", ")", "-", "1", ")", ")", ")", "\n", "self", ".", "alpha", "=", "nn", ".", "Parameter", "(", "self", ".", "alpha", ")", "\n", "\n", "if", "not", "learnable", ":", "\n", "            ", "self", ".", "alpha", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoAct.forward": [[106, 117], ["x[].sign", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "tuple", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "range"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "log_slope", "=", "self", ".", "alpha", "*", "x", "[", "0", "]", ".", "sign", "(", ")", "\n", "if", "rev", ":", "\n", "            ", "log_slope", "*=", "-", "1", "\n", "\n", "", "if", "jac", ":", "\n", "            ", "j", "=", "torch", ".", "sum", "(", "log_slope", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "tensor_rank", "+", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "j", "=", "None", "\n", "\n", "", "return", "[", "x", "[", "0", "]", "*", "torch", ".", "exp", "(", "log_slope", ")", "]", ",", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoAct.output_dims": [[118, 122], ["len", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoActFixed.__init__": [[125, 128], ["inv_auto_layers.InvAutoAct.__init__", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "warnings", ".", "warn", "(", "\"Deprecated: please use InvAutoAct with the learnable=False argument.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.LearnedElementwiseScaling.__init__": [[141, 149], ["InvertibleModule.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.log", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "init_scale", "=", "1.0", ")", ":", "\n", "        ", "'''\n        Args:\n          init_scale: The initial scaling value. It accounts for the exp-activation, \n            i.e. :math:`\\\\exp(s) =` ``init_scale``.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "s", "=", "nn", ".", "Parameter", "(", "np", ".", "log", "(", "init_scale", ")", "*", "torch", ".", "zeros", "(", "1", ",", "*", "dims_in", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.LearnedElementwiseScaling.forward": [[150, 163], ["torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "\n", "        ", "if", "rev", ":", "\n", "            ", "scale", "=", "-", "self", ".", "s", "\n", "", "else", ":", "\n", "            ", "scale", "=", "self", ".", "s", "\n", "\n", "", "if", "jac", ":", "\n", "            ", "jac", "=", "torch", ".", "sum", "(", "self", ".", "s", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "jac", "=", "None", "\n", "\n", "", "return", "[", "x", "[", "0", "]", "*", "torch", ".", "exp", "(", "scale", ")", "]", ",", "jac", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.LearnedElementwiseScaling.output_dims": [[164, 168], ["len", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoFC.__init__": [[177, 197], ["InvertibleModule.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "print", "print", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "numpy.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "dims_out", "=", "None", ")", ":", "\n", "        ", "'''\n        Args:\n          dims_out: If None, the output dimenison equals the input dimenison.\n            However, becuase InvAuto is only asymptotically invertible, there is\n            no strict limitation to have the same number of input- and\n            ouput-dimensions. If dims_out is an integer instead of None,\n            that number of output dimensions is used.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "dims_in", "=", "dims_in", "\n", "if", "dims_out", "is", "None", ":", "\n", "            ", "self", ".", "dims_out", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dims_out", "=", "dims_out", "\n", "\n", "", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "np", ".", "sqrt", "(", "1.", "/", "self", ".", "dims_out", ")", "*", "torch", ".", "randn", "(", "self", ".", "dims_out", ",", "self", ".", "dims_in", "[", "0", "]", "[", "0", "]", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "self", ".", "dims_out", ")", ")", "\n", "print", "(", "self", ".", "weights", ".", "shape", ")", "\n", "print", "(", "self", ".", "bias", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoFC.forward": [[198, 207], ["warnings.warn", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "inv_auto_layers.InvAutoFC.weights.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "if", "jac", ":", "\n", "            ", "warnings", ".", "warn", "(", "'Invertible Autoencoder layers do not have a tractable log-det-Jacobian. '", "\n", "'It approaches 0 at convergence, but the value may be incorrect duing training.'", ")", "\n", "\n", "", "if", "not", "rev", ":", "\n", "            ", "return", "[", "f", ".", "linear", "(", "x", "[", "0", "]", ",", "self", ".", "weights", ")", "+", "self", ".", "bias", "]", ",", "0.", "\n", "", "else", ":", "\n", "            ", "return", "[", "f", ".", "linear", "(", "x", "[", "0", "]", "-", "self", ".", "bias", ",", "self", ".", "weights", ".", "t", "(", ")", ")", "]", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoFC.output_dims": [[208, 214], ["len", "ValueError", "len", "ValueError"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use flattened (1D) input\"", ")", "\n", "", "return", "[", "(", "self", ".", "dims_out", ",", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoConv2D.__init__": [[224, 252], ["InvertibleModule.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "dims_out", "=", "None", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ":", "\n", "        ", "'''\n        Args:\n          kernel_size: Spatial size of the convlution kernel.\n          padding: Padding of the input. Choosing ``padding = kernel_size // 2`` retains\n            the image shape between in- and output.\n          dims_out: If None, the output dimenison equals the input dimenison.\n            However, becuase InvAuto is only asymptotically invertible, there is\n            no strict limitation to have the same number of input- and\n            ouput-dimensions. Therefore dims_out can also be a tuple of length 3:\n            (channels, width, height). The channels are the output channels of the\n            convolution. The user is responsible for making the width and height match\n            with the actual output, depending on kernel_size and padding.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "dims_in", "=", "dims_in", "\n", "\n", "if", "dims_out", "is", "None", ":", "\n", "            ", "self", ".", "dims_out", "=", "dims_in", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dims_out", "=", "dims_out", "\n", "\n", "", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding", "=", "padding", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "dims_in", "[", "0", "]", "[", "0", "]", ",", "self", ".", "dims_out", "[", "0", "]", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "self", ".", "dims_out", "[", "0", "]", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoConv2D.forward": [[253, 266], ["warnings.warn", "inv_auto_layers.InvAutoConv2D.conv2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "if", "jac", ":", "\n", "            ", "warnings", ".", "warn", "(", "'Invertible Autoencoder layers do not have a tractable log-det-Jacobian.'", "\n", "'It approaches 0 at convergence, but the value may be incorrect duing training.'", ")", "\n", "\n", "", "if", "not", "rev", ":", "\n", "            ", "out", "=", "self", ".", "conv2d", "(", "x", "[", "0", "]", ")", "\n", "out", "+=", "self", ".", "bias", "\n", "", "else", ":", "\n", "            ", "out", "=", "x", "[", "0", "]", "-", "self", ".", "bias", "\n", "out", "=", "f", ".", "conv_transpose2d", "(", "out", ",", "self", ".", "conv2d", ".", "weight", ",", "bias", "=", "None", ",", "padding", "=", "self", ".", "padding", ")", "\n", "\n", "", "return", "[", "out", "]", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.inv_auto_layers.InvAutoConv2D.output_dims": [[267, 273], ["len", "ValueError", "len", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use image input (3D tensors)\"", ")", "\n", "", "return", "[", "self", ".", "dims_out", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.IRevNetDownsampling.__init__": [[18, 68], ["InvertibleModule.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Parameter", "torch.Parameter", "torch.Parameter"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "legacy_backend", ":", "bool", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule) for more.\n\n        Args:\n          legacy_backend: If True, uses the splitting and concatenating method,\n            adapted from\n            github.com/jhjacobsen/pytorch-i-revnet/blob/master/models/model_utils.py\n            for the use in FrEIA. Is usually slower on GPU.\n            If False, uses a 2d strided convolution with a kernel representing\n            the downsampling. Note that the ordering of the output channels\n            will be different. If pixels in each patch in channel 1\n            are ``a1, b1,...``, and in channel 2 are ``a2, b2,...``\n            Then the output channels will be the following:\n\n            ``legacy_backend=True: a1, a2, ..., b1, b2, ..., c1, c2, ...``\n\n            ``legacy_backend=False: a1, b1, ..., a2, b2, ..., a3, b3, ...``\n\n            (see also order_by_wavelet in module HaarDownsampling)\n            Generally this difference is completely irrelevant,\n            unless a certaint subset of pixels or channels is supposed to be\n            split off or extracted.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "self", ".", "channels", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "block_size", "=", "2", "\n", "self", ".", "block_size_sq", "=", "self", ".", "block_size", "**", "2", "\n", "self", ".", "legacy_backend", "=", "legacy_backend", "\n", "\n", "if", "not", "self", ".", "legacy_backend", ":", "\n", "# this kernel represents the reshape:", "\n", "# it applies to 2x2 patches (stride 2), and transforms each", "\n", "# input channel to 4 channels.", "\n", "# The input value is transferred wherever the kernel is 1.", "\n", "# (hence the indexing pattern 00, 01, 10, 11 represents the", "\n", "# checkerboard.", "\n", "# For the upsampling, a transposed convolution is used for the", "\n", "# opposite effect.", "\n", "\n", "            ", "self", ".", "downsample_kernel", "=", "torch", ".", "zeros", "(", "4", ",", "1", ",", "2", ",", "2", ")", "\n", "\n", "self", ".", "downsample_kernel", "[", "0", ",", "0", ",", "0", ",", "0", "]", "=", "1", "\n", "self", ".", "downsample_kernel", "[", "1", ",", "0", ",", "0", ",", "1", "]", "=", "1", "\n", "self", ".", "downsample_kernel", "[", "2", ",", "0", ",", "1", ",", "0", "]", "=", "1", "\n", "self", ".", "downsample_kernel", "[", "3", ",", "0", ",", "1", ",", "1", "]", "=", "1", "\n", "\n", "self", ".", "downsample_kernel", "=", "torch", ".", "cat", "(", "[", "self", ".", "downsample_kernel", "]", "*", "self", ".", "channels", ",", "0", ")", "\n", "self", ".", "downsample_kernel", "=", "nn", ".", "Parameter", "(", "self", ".", "downsample_kernel", ")", "\n", "self", ".", "downsample_kernel", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.IRevNetDownsampling.forward": [[69, 116], ["input.permute", "torch.conv_transpose2d.size", "torch.conv_transpose2d.split", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.conv_transpose2d.permute", "torch.conv_transpose2d.permute", "torch.conv2d", "torch.conv2d", "torch.conv2d", "input.permute", "torch.conv_transpose2d.size", "int", "int", "int", "torch.conv_transpose2d.contiguous().view", "F.conv_transpose2d.contiguous().view.split", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.conv_transpose2d.permute().contiguous", "torch.conv_transpose2d.view", "torch.conv_transpose2d.permute", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "t_t.contiguous().view", "t_t.contiguous().view", "torch.conv_transpose2d.contiguous", "torch.conv_transpose2d.contiguous", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.conv_transpose2d.permute", "torch.conv_transpose2d.contiguous", "t_t.contiguous", "t_t.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "jac", "=", "True", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "input", "=", "x", "[", "0", "]", "\n", "if", "not", "rev", ":", "\n", "            ", "if", "self", ".", "legacy_backend", ":", "\n", "# only j.h. jacobsen understands how this works,", "\n", "# https://github.com/jhjacobsen/pytorch-i-revnet/blob/master/models/model_utils.py", "\n", "                ", "output", "=", "input", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "(", "batch_size", ",", "s_height", ",", "s_width", ",", "s_depth", ")", "=", "output", ".", "size", "(", ")", "\n", "d_depth", "=", "s_depth", "*", "self", ".", "block_size_sq", "\n", "d_height", "=", "s_height", "//", "self", ".", "block_size", "\n", "\n", "t_1", "=", "output", ".", "split", "(", "self", ".", "block_size", ",", "dim", "=", "2", ")", "\n", "stack", "=", "[", "t_t", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "d_height", ",", "d_depth", ")", "\n", "for", "t_t", "in", "t_1", "]", "\n", "output", "=", "torch", ".", "stack", "(", "stack", ",", "1", ")", "\n", "output", "=", "output", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "output", "=", "output", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "(", "output", ".", "contiguous", "(", ")", ",", ")", ",", "0.", "\n", "", "else", ":", "\n", "                ", "output", "=", "F", ".", "conv2d", "(", "input", ",", "self", ".", "downsample_kernel", ",", "stride", "=", "2", ",", "groups", "=", "self", ".", "channels", ")", "\n", "return", "(", "output", ",", ")", ",", "0.", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "legacy_backend", ":", "\n", "# only j.h. jacobsen understands how this works,", "\n", "# https://github.com/jhjacobsen/pytorch-i-revnet/blob/master/models/model_utils.py", "\n", "                ", "output", "=", "input", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "(", "batch_size", ",", "d_height", ",", "d_width", ",", "d_depth", ")", "=", "output", ".", "size", "(", ")", "\n", "s_depth", "=", "int", "(", "d_depth", "/", "self", ".", "block_size_sq", ")", "\n", "s_width", "=", "int", "(", "d_width", "*", "self", ".", "block_size", ")", "\n", "s_height", "=", "int", "(", "d_height", "*", "self", ".", "block_size", ")", "\n", "t_1", "=", "output", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "d_height", ",", "d_width", ",", "\n", "self", ".", "block_size_sq", ",", "s_depth", ")", "\n", "spl", "=", "t_1", ".", "split", "(", "self", ".", "block_size", ",", "3", ")", "\n", "stack", "=", "[", "t_t", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "d_height", ",", "s_width", ",", "\n", "s_depth", ")", "for", "t_t", "in", "spl", "]", "\n", "output", "=", "torch", ".", "stack", "(", "stack", ",", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "output", "=", "output", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", ".", "contiguous", "(", ")", "\n", "output", "=", "output", ".", "view", "(", "batch_size", ",", "s_height", ",", "s_width", ",", "s_depth", ")", "\n", "output", "=", "output", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "(", "output", ".", "contiguous", "(", ")", ",", ")", ",", "0.", "\n", "", "else", ":", "\n", "                ", "output", "=", "F", ".", "conv_transpose2d", "(", "input", ",", "self", ".", "downsample_kernel", ",", "\n", "stride", "=", "2", ",", "groups", "=", "self", ".", "channels", ")", "\n", "return", "(", "output", ",", ")", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.IRevNetDownsampling.output_dims": [[117, 134], ["len", "ValueError", "len", "ValueError", "ValueError"], "methods", ["None"], ["", "", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "\n", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"i-RevNet downsampling must have exactly 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"i-RevNet downsampling can only transform 2D images\"", "\n", "\"of the shape CxWxH (channels, width, height)\"", ")", "\n", "\n", "", "c", ",", "w", ",", "h", "=", "input_dims", "[", "0", "]", "\n", "c2", ",", "w2", ",", "h2", "=", "c", "*", "4", ",", "w", "//", "2", ",", "h", "//", "2", "\n", "\n", "if", "c", "*", "h", "*", "w", "!=", "c2", "*", "h2", "*", "w2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Input cannot be cleanly reshaped, most likely because\"", "\n", "\"the input height or width are an odd number\"", ")", "\n", "\n", "", "return", "(", "(", "c2", ",", "w2", ",", "h2", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.IRevNetUpsampling.__init__": [[139, 167], ["reshapes.IRevNetUpsampling.output_dims", "reshapes.IRevNetDownsampling.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.output_dims", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "legacy_backend", ":", "bool", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule) for more.\n\n        Args:\n          legacy_backend: If True, uses the splitting and concatenating method,\n            adapted from\n            github.com/jhjacobsen/pytorch-i-revnet/blob/master/models/model_utils.py\n            for the use in FrEIA. Is usually slower on GPU.\n            If False, uses a 2d strided transposed convolution with a representing\n            the downsampling. Note that the expected ordering of the input channels\n            will be different. If pixels in each output patch in channel 1\n            are ``a1, b1,...``, and in channel 2 are ``a2, b2,...``\n            Then the expected input channels are be the following:\n\n            ``legacy_backend=True: a1, a2, ..., b1, b2, ..., c1, c2, ...``\n\n            ``legacy_backend=False: a1, b1, ..., a2, b2, ..., a3, b3, ...``\n\n            (see also order_by_wavelet in module HaarDownsampling)\n            Generally this difference is completely irrelevant,\n            unless a certaint subset of pixels or channels is supposed to be\n            split off or extracted.\n        '''", "\n", "\n", "# have to initialize with the OUTPUT shape, because everything is", "\n", "# inherited from IRevNetDownsampling:", "\n", "inv_shape", "=", "self", ".", "output_dims", "(", "dims_in", ")", "\n", "super", "(", ")", ".", "__init__", "(", "inv_shape", ",", "dims_c", ",", "legacy_backend", "=", "legacy_backend", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.IRevNetUpsampling.forward": [[168, 171], ["reshapes.IRevNetDownsampling.forward"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "jac", "=", "True", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "return", "super", "(", ")", ".", "forward", "(", "x", ",", "c", "=", "None", ",", "rev", "=", "not", "rev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.IRevNetUpsampling.output_dims": [[172, 189], ["len", "ValueError", "len", "ValueError", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "\n", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"i-RevNet downsampling must have exactly 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"i-RevNet downsampling can only transform 2D images\"", "\n", "\"of the shape cxwxh (channels, width, height)\"", ")", "\n", "\n", "", "c", ",", "w", ",", "h", "=", "input_dims", "[", "0", "]", "\n", "c2", ",", "w2", ",", "h2", "=", "c", "//", "4", ",", "w", "*", "2", ",", "h", "*", "2", "\n", "\n", "if", "c", "*", "h", "*", "w", "!=", "c2", "*", "h2", "*", "w2", ":", "\n", "            ", "raise", "ValueError", "(", "\"input cannot be cleanly reshaped, most likely because\"", "\n", "\"the input height or width are an odd number\"", ")", "\n", "\n", "", "return", "(", "(", "c2", ",", "w2", ",", "h2", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.HaarDownsampling.__init__": [[195, 272], ["InvertibleModule.__init__", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ValueError", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "enumerate", "numpy.log", "numpy.log", "numpy.log", "numpy.log", "range"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "\n", "order_by_wavelet", ":", "bool", "=", "False", ",", "\n", "rebalance", ":", "float", "=", "1.", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule) for more.\n\n        Args:\n          order_by_wavelet: Whether to group the output by original channels or\n            by wavelet. I.e. if the average, vertical, horizontal and diagonal\n            wavelets for channel 1 are ``a1, v1, h1, d1``, those for channel 2 are\n            ``a2, v2, h2, d2``, etc, then the output channels will be structured as\n            follows:\n\n            set to ``True: a1, a2, ..., v1, v2, ..., h1, h2, ..., d1, d2, ...``\n\n            set to ``False: a1, v1, h1, d1, a2, v2, h2, d2, ...``\n\n            The ``True`` option is slightly slower to compute than the ``False`` option.\n            The option is useful if e.g. the average channels should be split\n            off by a FrEIA.modules.Split. Then, setting ``order_by_wavelet=True``\n            allows to split off the first quarter of channels to isolate the\n            average wavelets only.\n          rebalance: Must be !=0. There exist different conventions how to define\n            the Haar wavelets. The wavelet components in the forward direction\n            are multiplied with this factor, and those in the inverse direction\n            are adjusted accordingly, so that the module as a whole is\n            invertible.  Stability of the network may be increased for rebalance\n            < 1 (e.g. 0.5).\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "if", "rebalance", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"'rebalance' argument must be != 0.\"", ")", "\n", "\n", "", "self", ".", "in_channels", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "\n", "# self.jac_{fwd,rev} is the log Jacobian determinant for a single pixel", "\n", "# in a single channel computed explicitly from the matrix below.", "\n", "\n", "self", ".", "fac_fwd", "=", "0.5", "*", "rebalance", "\n", "self", ".", "jac_fwd", "=", "(", "np", ".", "log", "(", "16.", ")", "+", "4", "*", "np", ".", "log", "(", "self", ".", "fac_fwd", ")", ")", "/", "4.", "\n", "\n", "self", ".", "fac_rev", "=", "0.5", "/", "rebalance", "\n", "self", ".", "jac_rev", "=", "(", "np", ".", "log", "(", "16.", ")", "+", "4", "*", "np", ".", "log", "(", "self", ".", "fac_rev", ")", ")", "/", "4.", "\n", "\n", "# See https://en.wikipedia.org/wiki/Haar_wavelet#Haar_matrix", "\n", "# for an explanation of how this weight matrix comes about", "\n", "self", ".", "haar_weights", "=", "torch", ".", "ones", "(", "4", ",", "1", ",", "2", ",", "2", ")", "\n", "\n", "self", ".", "haar_weights", "[", "1", ",", "0", ",", "0", ",", "1", "]", "=", "-", "1", "\n", "self", ".", "haar_weights", "[", "1", ",", "0", ",", "1", ",", "1", "]", "=", "-", "1", "\n", "\n", "self", ".", "haar_weights", "[", "2", ",", "0", ",", "1", ",", "0", "]", "=", "-", "1", "\n", "self", ".", "haar_weights", "[", "2", ",", "0", ",", "1", ",", "1", "]", "=", "-", "1", "\n", "\n", "self", ".", "haar_weights", "[", "3", ",", "0", ",", "1", ",", "0", "]", "=", "-", "1", "\n", "self", ".", "haar_weights", "[", "3", ",", "0", ",", "0", ",", "1", "]", "=", "-", "1", "\n", "\n", "self", ".", "haar_weights", "=", "torch", ".", "cat", "(", "[", "self", ".", "haar_weights", "]", "*", "self", ".", "in_channels", ",", "0", ")", "\n", "self", ".", "haar_weights", "=", "nn", ".", "Parameter", "(", "self", ".", "haar_weights", ")", "\n", "self", ".", "haar_weights", ".", "requires_grad", "=", "False", "\n", "\n", "# for 'order_by_wavelet', we just perform the channel-wise wavelet", "\n", "# transform as usual, and then permute the channels into the correct", "\n", "# order afterward (hence 'self.permute')", "\n", "self", ".", "permute", "=", "order_by_wavelet", "\n", "\n", "if", "self", ".", "permute", ":", "\n", "            ", "permutation", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "                ", "permutation", "+=", "[", "i", "+", "4", "*", "j", "for", "j", "in", "range", "(", "self", ".", "in_channels", ")", "]", "\n", "\n", "", "self", ".", "perm", "=", "torch", ".", "LongTensor", "(", "permutation", ")", "\n", "self", ".", "perm_inv", "=", "torch", ".", "LongTensor", "(", "permutation", ")", "\n", "\n", "# clever trick to invert a permutation", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "self", ".", "perm", ")", ":", "\n", "                ", "self", ".", "perm_inv", "[", "p", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.HaarDownsampling.forward": [[273, 301], ["inp[].numel", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "jac", "=", "True", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "\n", "inp", "=", "x", "[", "0", "]", "\n", "#number total entries except for batch dimension:", "\n", "ndims", "=", "inp", "[", "0", "]", ".", "numel", "(", ")", "\n", "\n", "if", "not", "rev", ":", "\n", "            ", "jac", "=", "ndims", "*", "self", ".", "jac_fwd", "\n", "out", "=", "F", ".", "conv2d", "(", "inp", ",", "self", ".", "haar_weights", ",", "\n", "bias", "=", "None", ",", "stride", "=", "2", ",", "groups", "=", "self", ".", "in_channels", ")", "\n", "\n", "if", "self", ".", "permute", ":", "\n", "                ", "return", "(", "out", "[", ":", ",", "self", ".", "perm", "]", "*", "self", ".", "fac_fwd", ",", ")", ",", "jac", "\n", "", "else", ":", "\n", "                ", "return", "(", "out", "*", "self", ".", "fac_fwd", ",", ")", ",", "jac", "\n", "\n", "", "", "else", ":", "\n", "            ", "jac", "=", "ndims", "*", "self", ".", "jac_rev", "\n", "if", "self", ".", "permute", ":", "\n", "                ", "x_perm", "=", "inp", "[", ":", ",", "self", ".", "perm_inv", "]", "\n", "", "else", ":", "\n", "                ", "x_perm", "=", "inp", "\n", "\n", "", "x_perm", "*=", "self", ".", "fac_rev", "\n", "out", "=", "F", ".", "conv_transpose2d", "(", "x_perm", ",", "self", ".", "haar_weights", ",", "stride", "=", "2", ",", "groups", "=", "self", ".", "in_channels", ")", "\n", "\n", "return", "(", "out", ",", ")", ",", "jac", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.HaarDownsampling.output_dims": [[302, 319], ["len", "ValueError", "len", "ValueError", "ValueError"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "\n", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"HaarDownsampling must have exactly 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"HaarDownsampling can only transform 2D images\"", "\n", "\"of the shape CxWxH (channels, width, height)\"", ")", "\n", "\n", "", "c", ",", "w", ",", "h", "=", "input_dims", "[", "0", "]", "\n", "c2", ",", "w2", ",", "h2", "=", "c", "*", "4", ",", "w", "//", "2", ",", "h", "//", "2", "\n", "\n", "if", "c", "*", "h", "*", "w", "!=", "c2", "*", "h2", "*", "w2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Input cannot be cleanly reshaped, most likely because\"", "\n", "\"the input height or width are an odd number\"", ")", "\n", "\n", "", "return", "(", "(", "c2", ",", "w2", ",", "h2", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.HaarUpsampling.__init__": [[324, 353], ["reshapes.HaarUpsampling.output_dims", "reshapes.HaarDownsampling.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.output_dims", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "\n", "order_by_wavelet", ":", "bool", "=", "False", ",", "\n", "rebalance", ":", "float", "=", "1.", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule) for more.\n\n        Args:\n          order_by_wavelet: Expected grouping of the input channels by wavelet or\n            by output channel. I.e. if the average, vertical, horizontal and diagonal\n            wavelets for channel 1 are ``a1, v1, h1, d1``, those for channel 2 are\n            ``a2, v2, h2, d2``, etc, then the input channels are taken as follows:\n\n            set to ``True: a1, a2, ..., v1, v2, ..., h1, h2, ..., d1, d2, ...``\n\n            set to ``False: a1, v1, h1, d1, a2, v2, h2, d2, ...``\n\n            The ``True`` option is slightly slower to compute than the ``False`` option.\n            The option is useful if e.g. the input has been concatentated from average\n            channels and the higher-frequency channels. Then, setting\n            ``order_by_wavelet=True`` allows to split off the first quarter of\n            channels to isolate the average wavelets only.\n          rebalance: Must be !=0. There exist different conventions how to define\n            the Haar wavelets. The wavelet components in the forward direction\n            are multiplied with this factor, and those in the inverse direction\n            are adjusted accordingly, so that the module as a whole is\n            invertible.  Stability of the network may be increased for rebalance\n            < 1 (e.g. 0.5).\n        '''", "\n", "inv_shape", "=", "self", ".", "output_dims", "(", "dims_in", ")", "\n", "super", "(", ")", ".", "__init__", "(", "inv_shape", ",", "dims_c", ",", "order_by_wavelet", ",", "rebalance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.HaarUpsampling.forward": [[354, 357], ["reshapes.HaarDownsampling.forward"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "jac", "=", "True", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "return", "super", "(", ")", ".", "forward", "(", "x", ",", "c", "=", "None", ",", "rev", "=", "not", "rev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.HaarUpsampling.output_dims": [[358, 375], ["len", "ValueError", "len", "ValueError", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "\n", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"i-revnet downsampling must have exactly 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"i-revnet downsampling can only tranform 2d images\"", "\n", "\"of the shape cxwxh (channels, width, height)\"", ")", "\n", "\n", "", "c", ",", "w", ",", "h", "=", "input_dims", "[", "0", "]", "\n", "c2", ",", "w2", ",", "h2", "=", "c", "//", "4", ",", "w", "*", "2", ",", "h", "*", "2", "\n", "\n", "if", "c", "*", "h", "*", "w", "!=", "c2", "*", "h2", "*", "w2", ":", "\n", "            ", "raise", "ValueError", "(", "\"input cannot be cleanly reshaped, most likely because\"", "\n", "\"the input height or width are an odd number\"", ")", "\n", "\n", "", "return", "(", "(", "c2", ",", "w2", ",", "h2", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.Flatten.__init__": [[380, 389], ["InvertibleModule.__init__", "len", "ValueError", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "if", "len", "(", "dims_in", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Flattening must have exactly 1 input\"", ")", "\n", "\n", "", "self", ".", "input_shape", "=", "dims_in", "[", "0", "]", "\n", "self", ".", "output_shape", "=", "(", "int", "(", "np", ".", "prod", "(", "dims_in", "[", "0", "]", ")", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.Flatten.forward": [[390, 396], ["x[].view", "x[].view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "jac", "=", "True", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "if", "not", "rev", ":", "\n", "            ", "return", "(", "x", "[", "0", "]", ".", "view", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ",", ")", ",", "0.", "\n", "", "else", ":", "\n", "            ", "return", "(", "x", "[", "0", "]", ".", "view", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "*", "self", ".", "input_shape", ")", ",", ")", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.Flatten.output_dims": [[397, 400], ["None"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "return", "(", "self", ".", "output_shape", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.Reshape.__init__": [[408, 433], ["InvertibleModule.__init__", "warnings.warn", "ValueError", "len", "ValueError", "int", "int", "ValueError", "numpy.prod", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "output_dims", ":", "Iterable", "[", "int", "]", "=", "None", ",", "target_dim", "=", "None", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule) for more.\n\n        Args:\n          output_dims: The shape the reshaped output is supposed to have (not\n            including batch dimension)\n          target_dim: Deprecated name for output_dims\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "if", "target_dim", "is", "not", "None", ":", "\n", "            ", "warn", "(", "\"Use the new name for the 'target_dim' argument: 'output_dims'\"", "\n", "\"the 'target_dim' argument will be removed in the next version\"", ")", "\n", "output_dims", "=", "target_dim", "\n", "\n", "", "if", "output_dims", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Please specify the desired output shape\"", ")", "\n", "\n", "", "self", ".", "size", "=", "dims_in", "[", "0", "]", "\n", "self", ".", "target_dim", "=", "output_dims", "\n", "\n", "if", "len", "(", "dims_in", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Reshape must have exactly 1 input\"", ")", "\n", "", "if", "int", "(", "np", ".", "prod", "(", "dims_in", "[", "0", "]", ")", ")", "!=", "int", "(", "np", ".", "prod", "(", "self", ".", "target_dim", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Incoming dimensions {dims_in[0]} and target_dim\"", "\n", "f\"{self.target_dim} don't match.\"", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.Reshape.forward": [[436, 443], ["x[].reshape", "x[].reshape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "jac", "=", "True", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "\n", "if", "not", "rev", ":", "\n", "            ", "return", "(", "x", "[", "0", "]", ".", "reshape", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "*", "self", ".", "target_dim", ")", ",", ")", ",", "0.", "\n", "", "else", ":", "\n", "            ", "return", "(", "x", "[", "0", "]", ".", "reshape", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "*", "self", ".", "size", ")", ",", ")", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.reshapes.Reshape.output_dims": [[444, 447], ["None"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "dim", ")", ":", "\n", "        ", "'''See docstring of base class (FrEIA.modules.InvertibleModule).'''", "\n", "return", "(", "self", ".", "target_dim", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.PermuteRandom.__init__": [[15, 36], ["InvertibleModule.__init__", "numpy.random.permutation", "numpy.zeros_like", "enumerate", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.random.seed", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "seed", ":", "Union", "[", "int", ",", "None", "]", "=", "None", ")", ":", "\n", "        ", "'''Additional args in docstring of base class FrEIA.modules.InvertibleModule.\n\n        Args:\n          seed: Int seed for the permutation (numpy is used for RNG). If seed is\n            None, do not reseed RNG.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "self", ".", "in_channels", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "\n", "if", "seed", "is", "not", "None", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "", "self", ".", "perm", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "in_channels", ")", "\n", "\n", "self", ".", "perm_inv", "=", "np", ".", "zeros_like", "(", "self", ".", "perm", ")", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "self", ".", "perm", ")", ":", "\n", "            ", "self", ".", "perm_inv", "[", "p", "]", "=", "i", "\n", "\n", "", "self", ".", "perm", "=", "nn", ".", "Parameter", "(", "torch", ".", "LongTensor", "(", "self", ".", "perm", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "perm_inv", "=", "nn", ".", "Parameter", "(", "torch", ".", "LongTensor", "(", "self", ".", "perm_inv", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.PermuteRandom.forward": [[37, 42], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "if", "not", "rev", ":", "\n", "            ", "return", "[", "x", "[", "0", "]", "[", ":", ",", "self", ".", "perm", "]", "]", ",", "0.", "\n", "", "else", ":", "\n", "            ", "return", "[", "x", "[", "0", "]", "[", ":", ",", "self", ".", "perm_inv", "]", "]", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.PermuteRandom.output_dims": [[43, 47], ["len", "ValueError"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.FixedLinearTransform.__init__": [[54, 79], ["InvertibleModule.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ValueError", "M.t", "M.t().inverse", "torch.Parameter", "torch.Parameter", "torch.Parameter", "b.unsqueeze", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "M.t"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "M", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "b", ":", "Union", "[", "None", ",", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "'''Additional args in docstring of base class FrEIA.modules.InvertibleModule.\n\n        Args:\n          M: Square, invertible matrix, with which each input is multiplied. Shape ``(d, d)``.\n          b: Optional vector which is added element-wise. Shape ``(d,)``.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "# TODO: it should be possible to give conditioning instead of M, so that the condition", "\n", "# provides M and b on each forward pass.", "\n", "\n", "if", "M", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need to specify the M argument, the matrix to be multiplied.\"", ")", "\n", "\n", "", "self", ".", "M", "=", "nn", ".", "Parameter", "(", "M", ".", "t", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "M_inv", "=", "nn", ".", "Parameter", "(", "M", ".", "t", "(", ")", ".", "inverse", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "if", "b", "is", "None", ":", "\n", "            ", "self", ".", "b", "=", "0.", "\n", "", "else", ":", "\n", "            ", "self", ".", "b", "=", "nn", ".", "Parameter", "(", "b", ".", "unsqueeze", "(", "0", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "self", ".", "logDetM", "=", "nn", ".", "Parameter", "(", "torch", ".", "slogdet", "(", "M", ")", "[", "1", "]", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.FixedLinearTransform.forward": [[80, 88], ["fixed_transforms.FixedLinearTransform.logDetM.expand", "x[].mm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "j", "=", "self", ".", "logDetM", ".", "expand", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ")", "\n", "if", "not", "rev", ":", "\n", "            ", "out", "=", "x", "[", "0", "]", ".", "mm", "(", "self", ".", "M", ")", "+", "self", ".", "b", "\n", "return", "(", "out", ",", ")", ",", "j", "\n", "", "else", ":", "\n", "            ", "out", "=", "(", "x", "[", "0", "]", "-", "self", ".", "b", ")", ".", "mm", "(", "self", ".", "M_inv", ")", "\n", "return", "(", "out", ",", ")", ",", "-", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.FixedLinearTransform.output_dims": [[89, 93], ["len", "ValueError"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.Fixed1x1Conv.__init__": [[100, 117], ["InvertibleModule.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ValueError", "M.t().view", "M.t().inverse().view", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "torch.slogdet", "M.t", "M.t().inverse", "M.t"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "M", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "'''Additional args in docstring of base class FrEIA.modules.InvertibleModule.\n\n        Args:\n          M: Square, invertible matrix, with which each input is multiplied. Shape ``(d, d)``.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "# TODO: it should be possible to give conditioning instead of M, so that the condition", "\n", "# provides M and b on each forward pass.", "\n", "\n", "if", "M", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need to specify the M argument, the matrix to be multiplied.\"", ")", "\n", "\n", "", "self", ".", "M", "=", "nn", ".", "Parameter", "(", "M", ".", "t", "(", ")", ".", "view", "(", "*", "M", ".", "shape", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "M_inv", "=", "nn", ".", "Parameter", "(", "M", ".", "t", "(", ")", ".", "inverse", "(", ")", ".", "view", "(", "*", "M", ".", "shape", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "logDetM", "=", "nn", ".", "Parameter", "(", "torch", ".", "slogdet", "(", "M", ")", "[", "1", "]", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.Fixed1x1Conv.forward": [[118, 126], ["[].numel", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "n_pixels", "=", "x", "[", "0", "]", "[", "0", ",", "0", "]", ".", "numel", "(", ")", "\n", "j", "=", "self", ".", "logDetM", "*", "n_pixels", "\n", "\n", "if", "not", "rev", ":", "\n", "            ", "return", "(", "F", ".", "conv2d", "(", "x", "[", "0", "]", ",", "self", ".", "M", ")", ",", ")", ",", "j", "\n", "", "else", ":", "\n", "            ", "return", "(", "F", ".", "conv2d", "(", "x", "[", "0", "]", ",", "self", ".", "M_inv", ")", ",", ")", ",", "-", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.Fixed1x1Conv.output_dims": [[127, 134], ["len", "ValueError", "len", "ValueError"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See base class for docstring'''", "\n", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} requires 3D input (channels, height, width)\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.InvertibleSigmoid.__init__": [[153, 155], ["InvertibleModule.__init__"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.InvertibleSigmoid.output_dims": [[156, 158], ["None"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "dims_in", ")", ":", "\n", "        ", "return", "dims_in", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.fixed_transforms.InvertibleSigmoid.forward": [[159, 183], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log.sum", "torch.log.sum", "torch.log.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_or_z", ":", "Iterable", "[", "torch", ".", "Tensor", "]", ",", "c", ":", "Iterable", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "rev", ":", "bool", "=", "False", ",", "jac", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "Tuple", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "x_or_z", "=", "x_or_z", "[", "0", "]", "\n", "if", "not", "rev", ":", "\n", "# S(x)", "\n", "            ", "result", "=", "1", "/", "(", "1", "+", "torch", ".", "exp", "(", "-", "x_or_z", ")", ")", "\n", "", "else", ":", "\n", "# S^-1(z)", "\n", "# only defined within range 0-1, non-inclusive; else, it will returns nan.", "\n", "            ", "result", "=", "torch", ".", "log", "(", "x_or_z", "/", "(", "1", "-", "x_or_z", ")", ")", "\n", "", "if", "not", "jac", ":", "\n", "            ", "return", "(", "result", ",", ")", "\n", "\n", "# always compute jacobian using the forward direction, but with different inputs", "\n", "", "_input", "=", "result", "if", "rev", "else", "x_or_z", "\n", "# the following is the diagonal Jacobian as sigmoid is an element-wise op", "\n", "logJ", "=", "torch", ".", "log", "(", "1", "/", "(", "(", "1", "+", "torch", ".", "exp", "(", "_input", ")", ")", "*", "(", "1", "+", "torch", ".", "exp", "(", "-", "_input", ")", ")", ")", ")", "\n", "# determinant of a log diagonal Jacobian is simply the sum of its diagonals", "\n", "detLogJ", "=", "logJ", ".", "sum", "(", "1", ")", "\n", "if", "not", "rev", ":", "\n", "            ", "return", "(", "(", "result", ",", ")", ",", "detLogJ", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "result", ",", ")", ",", "-", "detLogJ", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology.Split.__init__": [[18, 72], ["InvertibleModule.__init__", "len", "len", "isinstance", "warnings.warn", "isinstance", "sum", "sum", "warnings.warn", "list().append", "list", "sum"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["def", "__init__", "(", "self", ",", "\n", "dims_in", ":", "Sequence", "[", "Sequence", "[", "int", "]", "]", ",", "\n", "section_sizes", ":", "Union", "[", "int", ",", "Sequence", "[", "int", "]", "]", "=", "None", ",", "\n", "n_sections", ":", "int", "=", "2", ",", "\n", "dim", ":", "int", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits the Split module with the attributes described above and\n        checks that split sizes and dimensionality are compatible.\n\n        Args:\n          dims_in:\n            A list of tuples containing the non-batch dimensionality of all\n            incoming tensors. Handled automatically during compute graph setup.\n            Split only takes one input tensor.\n          section_sizes:\n            If set, takes precedence over ``n_sections`` and behaves like the\n            argument in torch.split(), except when a list of section sizes is given\n            that doesn't add up to the size of ``dim``, an additional split section is\n            created to take the slack. Defaults to None.\n          n_sections:\n            If ``section_sizes`` is None, the tensor is split into ``n_sections``\n            parts of equal size or close to it. This mode behaves like\n            ``numpy.array_split()``. Defaults to 2, i.e. splitting the data into two\n            equal halves.\n          dim:\n            Index of the dimension along which to split, not counting the batch\n            dimension. Defaults to 0, i.e. the channel dimension in structured data.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ")", "\n", "\n", "# Size and dimensionality checks", "\n", "assert", "len", "(", "dims_in", ")", "==", "1", ",", "\"Split layer takes exactly one input tensor\"", "\n", "assert", "len", "(", "dims_in", "[", "0", "]", ")", ">=", "dim", ",", "\"Split dimension index out of range\"", "\n", "self", ".", "dim", "=", "dim", "\n", "l_dim", "=", "dims_in", "[", "0", "]", "[", "dim", "]", "\n", "\n", "if", "section_sizes", "is", "None", ":", "\n", "            ", "assert", "2", "<=", "n_sections", ",", "\"'n_sections' must be a least 2\"", "\n", "if", "l_dim", "%", "n_sections", "!=", "0", ":", "\n", "                ", "warnings", ".", "warn", "(", "'Split will create sections of unequal size'", ")", "\n", "", "self", ".", "split_size_or_sections", "=", "(", "\n", "[", "l_dim", "//", "n_sections", "+", "1", "]", "*", "(", "l_dim", "%", "n_sections", ")", "+", "\n", "[", "l_dim", "//", "n_sections", "]", "*", "(", "n_sections", "-", "l_dim", "%", "n_sections", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "section_sizes", ",", "int", ")", ":", "\n", "                ", "assert", "section_sizes", "<", "l_dim", ",", "\"'section_sizes' too large\"", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "section_sizes", ",", "(", "list", ",", "tuple", ")", ")", ",", "\"'section_sizes' must be either int or list/tuple of int\"", "\n", "assert", "sum", "(", "section_sizes", ")", "<=", "l_dim", ",", "\"'section_sizes' too large\"", "\n", "if", "sum", "(", "section_sizes", ")", "<", "l_dim", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\"'section_sizes' too small, adding additional section\"", ")", "\n", "section_sizes", "=", "list", "(", "section_sizes", ")", ".", "append", "(", "l_dim", "-", "sum", "(", "section_sizes", ")", ")", "\n", "", "", "self", ".", "split_size_or_sections", "=", "section_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology.Split.forward": [[73, 81], ["torch.split", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "\"\"\"See super class InvertibleModule.\n        Jacobian log-det of splitting is always zero.\"\"\"", "\n", "if", "rev", ":", "\n", "            ", "return", "[", "torch", ".", "cat", "(", "x", ",", "dim", "=", "self", ".", "dim", "+", "1", ")", "]", ",", "0", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "split", "(", "x", "[", "0", "]", ",", "self", ".", "split_size_or_sections", ",", "\n", "dim", "=", "self", ".", "dim", "+", "1", ")", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology.Split.output_dims": [[82, 89], ["len", "tuple", "range", "len"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "\"\"\"See super class InvertibleModule.\"\"\"", "\n", "assert", "len", "(", "input_dims", ")", "==", "1", ",", "\"Split layer takes exactly one input tensor\"", "\n", "# Assemble dims of all resulting outputs", "\n", "return", "[", "tuple", "(", "input_dims", "[", "0", "]", "[", "j", "]", "if", "(", "j", "!=", "self", ".", "dim", ")", "else", "section_size", "\n", "for", "j", "in", "range", "(", "len", "(", "input_dims", "[", "0", "]", ")", ")", ")", "\n", "for", "section_size", "in", "self", ".", "split_size_or_sections", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology.Concat.__init__": [[99, 135], ["InvertibleModule.__init__", "all", "all", "len", "len", "range", "len", "len", "range", "range", "range", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dims_in", ":", "Sequence", "[", "Sequence", "[", "int", "]", "]", ",", "\n", "dim", ":", "int", "=", "0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Inits the Concat module with the attributes described above and\n        checks that all dimensions are compatible.\n\n        Args:\n          dims_in:\n            A list of tuples containing the non-batch dimensionality of all\n            incoming tensors. Handled automatically during compute graph setup.\n            Dimensionality of incoming tensors must be identical, except in the\n            merge dimension ``dim``. Concat only makes sense with multiple input\n            tensors.\n          dim:\n            Index of the dimension along which to concatenate, not counting the\n            batch dimension. Defaults to 0, i.e. the channel dimension in structured\n            data.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ")", "\n", "assert", "len", "(", "dims_in", ")", ">", "1", ",", "(", "\"Concatenation only makes sense for \"", "\n", "\"multiple inputs\"", ")", "\n", "assert", "len", "(", "dims_in", "[", "0", "]", ")", ">=", "dim", ",", "\"Merge dimension index out of range\"", "\n", "assert", "all", "(", "len", "(", "dims_in", "[", "i", "]", ")", "==", "len", "(", "dims_in", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dims_in", ")", ")", ")", ",", "(", "\n", "\"All input tensors must have same number of \"", "\n", "\"dimensions\"", "\n", ")", "\n", "assert", "all", "(", "dims_in", "[", "i", "]", "[", "j", "]", "==", "dims_in", "[", "0", "]", "[", "j", "]", "for", "i", "in", "range", "(", "len", "(", "dims_in", ")", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "dims_in", "[", "i", "]", ")", ")", "if", "j", "!=", "dim", ")", ",", "(", "\n", "\"All input tensor dimensions except merge \"", "\n", "\"dimension must be identical\"", "\n", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "split_size_or_sections", "=", "[", "dims_in", "[", "i", "]", "[", "dim", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dims_in", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology.Concat.forward": [[136, 144], ["torch.split", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "\"\"\"See super class InvertibleModule.\n        Jacobian log-det of concatenation is always zero.\"\"\"", "\n", "if", "rev", ":", "\n", "            ", "return", "torch", ".", "split", "(", "x", "[", "0", "]", ",", "self", ".", "split_size_or_sections", ",", "\n", "dim", "=", "self", ".", "dim", "+", "1", ")", ",", "0", "\n", "", "else", ":", "\n", "            ", "return", "[", "torch", ".", "cat", "(", "x", ",", "dim", "=", "self", ".", "dim", "+", "1", ")", "]", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology.Concat.output_dims": [[145, 153], ["copy.deepcopy", "sum", "len", "list", "tuple"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "\"\"\"See super class InvertibleModule.\"\"\"", "\n", "assert", "len", "(", "input_dims", ")", ">", "1", ",", "(", "\"Concatenation only makes sense for \"", "\n", "\"multiple inputs\"", ")", "\n", "output_dims", "=", "deepcopy", "(", "list", "(", "input_dims", "[", "0", "]", ")", ")", "\n", "output_dims", "[", "self", ".", "dim", "]", "=", "sum", "(", "input_dim", "[", "self", ".", "dim", "]", "\n", "for", "input_dim", "in", "input_dims", ")", "\n", "return", "[", "tuple", "(", "output_dims", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.graph_topology._deprecated_by": [[155, 164], ["warnings.warn", "super().__init__"], "function", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["", "", "def", "_deprecated_by", "(", "orig_class", ")", ":", "\n", "    ", "class", "deprecated_class", "(", "orig_class", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "F\"{self.__class__.__name__} is deprecated and will be removed in the public release. \"", "\n", "F\"Use {orig_class.__name__} instead.\"", ",", "\n", "DeprecationWarning", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "deprecated_class", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers._BaseCouplingBlock.__init__": [[16, 76], ["InvertibleModule.__init__", "len", "isinstance", "all", "sum", "isinstance", "round", "len", "ValueError", "ValueError", "tuple", "tuple", "range", "range", "len", "len", "torch.atan", "ValueError", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "clamp", ":", "float", "=", "2.", ",", "\n", "clamp_activation", ":", "Union", "[", "str", ",", "Callable", "]", "=", "\"ATAN\"", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          clamp: Soft clamping for the multiplicative component. The\n            amplification or attenuation of each input dimension can be at most\n            exp(\u00b1clamp).\n          clamp_activation: Function to perform the clamping. String values\n            \"ATAN\", \"TANH\", and \"SIGMOID\" are recognized, or a function of\n            object can be passed. TANH behaves like the original realNVP paper.\n            A custom function should take tensors and map -inf to -1 and +inf to +1.\n          split_len: Specify the dimension where the data should be split.\n            If given as int, directly indicates the split dimension.\n            If given as float, must fulfil 0 <= split_len <= 1 and number of\n            unchanged dimensions is set to `round(split_len * dims_in[0, 0])`.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "self", ".", "channels", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "\n", "# ndims means the rank of tensor strictly speaking.", "\n", "# i.e. 1D, 2D, 3D tensor, etc.", "\n", "self", ".", "ndims", "=", "len", "(", "dims_in", "[", "0", "]", ")", "\n", "\n", "if", "isinstance", "(", "split_len", ",", "float", ")", ":", "\n", "            ", "if", "not", "(", "0", "<=", "split_len", "<=", "1", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Float split_len must be in range [0, 1], \"", "\n", "f\"but is: {split_len}\"", ")", "\n", "", "split_len", "=", "round", "(", "self", ".", "channels", "*", "split_len", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "(", "0", "<=", "split_len", "<=", "self", ".", "channels", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Integer split_len must be in range \"", "\n", "f\"0 <= split_len <= {self.channels}, \"", "\n", "f\"but is: {split_len}\"", ")", "\n", "", "", "self", ".", "split_len1", "=", "split_len", "\n", "self", ".", "split_len2", "=", "self", ".", "channels", "-", "split_len", "\n", "\n", "self", ".", "clamp", "=", "clamp", "\n", "\n", "assert", "all", "(", "[", "tuple", "(", "dims_c", "[", "i", "]", "[", "1", ":", "]", ")", "==", "tuple", "(", "dims_in", "[", "0", "]", "[", "1", ":", "]", ")", "for", "i", "in", "range", "(", "len", "(", "dims_c", ")", ")", "]", ")", ",", "F\"Dimensions of input {dims_in} and one or more conditions {dims_c} don't agree.\"", "\n", "self", ".", "conditional", "=", "(", "len", "(", "dims_c", ")", ">", "0", ")", "\n", "self", ".", "condition_length", "=", "sum", "(", "[", "dims_c", "[", "i", "]", "[", "0", "]", "for", "i", "in", "range", "(", "len", "(", "dims_c", ")", ")", "]", ")", "\n", "\n", "if", "isinstance", "(", "clamp_activation", ",", "str", ")", ":", "\n", "            ", "if", "clamp_activation", "==", "\"ATAN\"", ":", "\n", "                ", "self", ".", "f_clamp", "=", "(", "lambda", "u", ":", "0.636", "*", "torch", ".", "atan", "(", "u", ")", ")", "\n", "", "elif", "clamp_activation", "==", "\"TANH\"", ":", "\n", "                ", "self", ".", "f_clamp", "=", "torch", ".", "tanh", "\n", "", "elif", "clamp_activation", "==", "\"SIGMOID\"", ":", "\n", "                ", "self", ".", "f_clamp", "=", "(", "lambda", "u", ":", "2.", "*", "(", "torch", ".", "sigmoid", "(", "u", ")", "-", "0.5", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Unknown clamp activation \"{clamp_activation}\"'", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "f_clamp", "=", "clamp_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers._BaseCouplingBlock.forward": [[77, 103], ["torch.split", "coupling_layers._BaseCouplingBlock._coupling1", "coupling_layers._BaseCouplingBlock._coupling2", "coupling_layers._BaseCouplingBlock._coupling2", "coupling_layers._BaseCouplingBlock._coupling1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock._coupling1", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock._coupling2", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock._coupling2", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock._coupling1"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "'''See base class docstring'''", "\n", "\n", "# notation:", "\n", "# x1, x2: two halves of the input", "\n", "# y1, y2: two halves of the output", "\n", "# *_c: variable with condition concatenated", "\n", "# j1, j2: Jacobians of the two coupling operations", "\n", "\n", "x1", ",", "x2", "=", "torch", ".", "split", "(", "x", "[", "0", "]", ",", "[", "self", ".", "split_len1", ",", "self", ".", "split_len2", "]", ",", "dim", "=", "1", ")", "\n", "\n", "if", "not", "rev", ":", "\n", "            ", "x2_c", "=", "torch", ".", "cat", "(", "[", "x2", ",", "*", "c", "]", ",", "1", ")", "if", "self", ".", "conditional", "else", "x2", "\n", "y1", ",", "j1", "=", "self", ".", "_coupling1", "(", "x1", ",", "x2_c", ")", "\n", "\n", "y1_c", "=", "torch", ".", "cat", "(", "[", "y1", ",", "*", "c", "]", ",", "1", ")", "if", "self", ".", "conditional", "else", "y1", "\n", "y2", ",", "j2", "=", "self", ".", "_coupling2", "(", "x2", ",", "y1_c", ")", "\n", "", "else", ":", "\n", "# names of x and y are swapped for the reverse computation", "\n", "            ", "x1_c", "=", "torch", ".", "cat", "(", "[", "x1", ",", "*", "c", "]", ",", "1", ")", "if", "self", ".", "conditional", "else", "x1", "\n", "y2", ",", "j2", "=", "self", ".", "_coupling2", "(", "x2", ",", "x1_c", ",", "rev", "=", "True", ")", "\n", "\n", "y2_c", "=", "torch", ".", "cat", "(", "[", "y2", ",", "*", "c", "]", ",", "1", ")", "if", "self", ".", "conditional", "else", "y2", "\n", "y1", ",", "j1", "=", "self", ".", "_coupling1", "(", "x1", ",", "y2_c", ",", "rev", "=", "True", ")", "\n", "\n", "", "return", "(", "torch", ".", "cat", "(", "(", "y1", ",", "y2", ")", ",", "1", ")", ",", ")", ",", "j1", "+", "j2", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers._BaseCouplingBlock._coupling1": [[104, 117], ["NotImplementedError"], "methods", ["None"], ["", "def", "_coupling1", "(", "self", ",", "x1", ",", "u2", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''The first/left coupling operation in a two-sided coupling block.\n\n        Args:\n          x1 (Tensor): the 'active' half being transformed.\n          u2 (Tensor): the 'passive' half, including the conditions, from\n            which the transformation is computed.\n        Returns:\n          y1 (Tensor): same shape as x1, the transformed 'active' half.\n          j1 (float or Tensor): the Jacobian, only has batch dimension.\n            If the Jacobian is zero of fixed, may also return float.\n        '''", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers._BaseCouplingBlock._coupling2": [[118, 131], ["NotImplementedError"], "methods", ["None"], ["", "def", "_coupling2", "(", "self", ",", "x2", ",", "u1", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''The second/right coupling operation in a two-sided coupling block.\n\n        Args:\n          x2 (Tensor): the 'active' half being transformed.\n          u1 (Tensor): the 'passive' half, including the conditions, from\n            which the transformation is computed.\n        Returns:\n          y2 (Tensor): same shape as x1, the transformed 'active' half.\n          j2 (float or Tensor): the Jacobian, only has batch dimension.\n            If the Jacobian is zero of fixed, may also return float.\n        '''", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers._BaseCouplingBlock.output_dims": [[132, 137], ["len", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "'''See base class for docstring'''", "\n", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Can only use 1 input\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.NICECouplingBlock.__init__": [[146, 166], ["coupling_layers._BaseCouplingBlock.__init__", "subnet_constructor", "subnet_constructor"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "callable", "=", "None", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          subnet_constructor:\n            Callable function, class, or factory object, with signature\n            constructor(dims_in, dims_out). The result should be a torch\n            nn.Module, that takes dims_in input channels, and dims_out output\n            channels. See tutorial for examples.\n            Two of these subnetworks will be initialized inside the block.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ",", "\n", "clamp", "=", "0.", ",", "clamp_activation", "=", "(", "lambda", "u", ":", "u", ")", ",", "\n", "split_len", "=", "split_len", ")", "\n", "\n", "self", ".", "F", "=", "subnet_constructor", "(", "self", ".", "split_len2", "+", "self", ".", "condition_length", ",", "self", ".", "split_len1", ")", "\n", "self", ".", "G", "=", "subnet_constructor", "(", "self", ".", "split_len1", "+", "self", ".", "condition_length", ",", "self", ".", "split_len2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.NICECouplingBlock._coupling1": [[167, 171], ["coupling_layers.NICECouplingBlock.F", "coupling_layers.NICECouplingBlock.F"], "methods", ["None"], ["", "def", "_coupling1", "(", "self", ",", "x1", ",", "u2", ",", "rev", "=", "False", ")", ":", "\n", "        ", "if", "rev", ":", "\n", "            ", "return", "x1", "-", "self", ".", "F", "(", "u2", ")", ",", "0.", "\n", "", "return", "x1", "+", "self", ".", "F", "(", "u2", ")", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.NICECouplingBlock._coupling2": [[172, 176], ["coupling_layers.NICECouplingBlock.G", "coupling_layers.NICECouplingBlock.G"], "methods", ["None"], ["", "def", "_coupling2", "(", "self", ",", "x2", ",", "u1", ",", "rev", "=", "False", ")", ":", "\n", "        ", "if", "rev", ":", "\n", "            ", "return", "x2", "-", "self", ".", "G", "(", "u1", ")", ",", "0.", "\n", "", "return", "x2", "+", "self", ".", "G", "(", "u1", ")", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.RNVPCouplingBlock.__init__": [[186, 216], ["coupling_layers._BaseCouplingBlock.__init__", "subnet_constructor", "subnet_constructor", "subnet_constructor", "subnet_constructor"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "Callable", "=", "None", ",", "\n", "clamp", ":", "float", "=", "2.", ",", "\n", "clamp_activation", ":", "Union", "[", "str", ",", "Callable", "]", "=", "\"ATAN\"", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          subnet_constructor: function or class, with signature\n            constructor(dims_in, dims_out).  The result should be a torch\n            nn.Module, that takes dims_in input channels, and dims_out output\n            channels. See tutorial for examples. Four of these subnetworks will be\n            initialized in the block.\n          clamp: Soft clamping for the multiplicative component. The\n            amplification or attenuation of each input dimension can be at most\n            exp(\u00b1clamp).\n          clamp_activation: Function to perform the clamping. String values\n            \"ATAN\", \"TANH\", and \"SIGMOID\" are recognized, or a function of\n            object can be passed. TANH behaves like the original realNVP paper.\n            A custom function should take tensors and map -inf to -1 and +inf to +1.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ",", "clamp", ",", "clamp_activation", ",", "\n", "split_len", "=", "split_len", ")", "\n", "\n", "self", ".", "subnet_s1", "=", "subnet_constructor", "(", "self", ".", "split_len1", "+", "self", ".", "condition_length", ",", "self", ".", "split_len2", ")", "\n", "self", ".", "subnet_t1", "=", "subnet_constructor", "(", "self", ".", "split_len1", "+", "self", ".", "condition_length", ",", "self", ".", "split_len2", ")", "\n", "self", ".", "subnet_s2", "=", "subnet_constructor", "(", "self", ".", "split_len2", "+", "self", ".", "condition_length", ",", "self", ".", "split_len1", ")", "\n", "self", ".", "subnet_t2", "=", "subnet_constructor", "(", "self", ".", "split_len2", "+", "self", ".", "condition_length", ",", "self", ".", "split_len1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.RNVPCouplingBlock._coupling1": [[217, 238], ["torch.sum", "coupling_layers.RNVPCouplingBlock.subnet_s2", "coupling_layers.RNVPCouplingBlock.subnet_t2", "coupling_layers.RNVPCouplingBlock.f_clamp", "tuple", "torch.exp", "range", "torch.exp"], "methods", ["None"], ["", "def", "_coupling1", "(", "self", ",", "x1", ",", "u2", ",", "rev", "=", "False", ")", ":", "\n", "\n", "# notation (same for _coupling2):", "\n", "# x: inputs (i.e. 'x-side' when rev is False, 'z-side' when rev is True)", "\n", "# y: outputs (same scheme)", "\n", "# *_c: variables with condition appended", "\n", "# *1, *2: left half, right half", "\n", "# a: all affine coefficients", "\n", "# s, t: multiplicative and additive coefficients", "\n", "# j: log det Jacobian", "\n", "\n", "        ", "s2", ",", "t2", "=", "self", ".", "subnet_s2", "(", "u2", ")", ",", "self", ".", "subnet_t2", "(", "u2", ")", "\n", "s2", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s2", ")", "\n", "j1", "=", "torch", ".", "sum", "(", "s2", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "ndims", "+", "1", ")", ")", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y1", "=", "(", "x1", "-", "t2", ")", "*", "torch", ".", "exp", "(", "-", "s2", ")", "\n", "return", "y1", ",", "-", "j1", "\n", "", "else", ":", "\n", "            ", "y1", "=", "torch", ".", "exp", "(", "s2", ")", "*", "x1", "+", "t2", "\n", "return", "y1", ",", "j1", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.RNVPCouplingBlock._coupling2": [[239, 250], ["torch.sum", "coupling_layers.RNVPCouplingBlock.subnet_s1", "coupling_layers.RNVPCouplingBlock.subnet_t1", "coupling_layers.RNVPCouplingBlock.f_clamp", "tuple", "torch.exp", "range", "torch.exp"], "methods", ["None"], ["", "", "def", "_coupling2", "(", "self", ",", "x2", ",", "u1", ",", "rev", "=", "False", ")", ":", "\n", "        ", "s1", ",", "t1", "=", "self", ".", "subnet_s1", "(", "u1", ")", ",", "self", ".", "subnet_t1", "(", "u1", ")", "\n", "s1", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s1", ")", "\n", "j2", "=", "torch", ".", "sum", "(", "s1", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "ndims", "+", "1", ")", ")", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y2", "=", "(", "x2", "-", "t1", ")", "*", "torch", ".", "exp", "(", "-", "s1", ")", "\n", "return", "y2", ",", "-", "j2", "\n", "", "else", ":", "\n", "            ", "y2", "=", "torch", ".", "exp", "(", "s1", ")", "*", "x2", "+", "t1", "\n", "return", "y2", ",", "j2", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GLOWCouplingBlock.__init__": [[261, 289], ["coupling_layers._BaseCouplingBlock.__init__", "subnet_constructor", "subnet_constructor"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "Callable", "=", "None", ",", "\n", "clamp", ":", "float", "=", "2.", ",", "\n", "clamp_activation", ":", "Union", "[", "str", ",", "Callable", "]", "=", "\"ATAN\"", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          subnet_constructor: function or class, with signature\n            constructor(dims_in, dims_out).  The result should be a torch\n            nn.Module, that takes dims_in input channels, and dims_out output\n            channels. See tutorial for examples. Two of these subnetworks will be\n            initialized in the block.\n          clamp: Soft clamping for the multiplicative component. The\n            amplification or attenuation of each input dimension can be at most\n            exp(\u00b1clamp).\n          clamp_activation: Function to perform the clamping. String values\n            \"ATAN\", \"TANH\", and \"SIGMOID\" are recognized, or a function of\n            object can be passed. TANH behaves like the original realNVP paper.\n            A custom function should take tensors and map -inf to -1 and +inf to +1.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ",", "clamp", ",", "clamp_activation", ",", "\n", "split_len", "=", "split_len", ")", "\n", "\n", "self", ".", "subnet1", "=", "subnet_constructor", "(", "self", ".", "split_len1", "+", "self", ".", "condition_length", ",", "self", ".", "split_len2", "*", "2", ")", "\n", "self", ".", "subnet2", "=", "subnet_constructor", "(", "self", ".", "split_len2", "+", "self", ".", "condition_length", ",", "self", ".", "split_len1", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GLOWCouplingBlock._coupling1": [[290, 312], ["coupling_layers.GLOWCouplingBlock.subnet2", "torch.sum", "coupling_layers.GLOWCouplingBlock.f_clamp", "tuple", "torch.exp", "range", "torch.exp"], "methods", ["None"], ["", "def", "_coupling1", "(", "self", ",", "x1", ",", "u2", ",", "rev", "=", "False", ")", ":", "\n", "\n", "# notation (same for _coupling2):", "\n", "# x: inputs (i.e. 'x-side' when rev is False, 'z-side' when rev is True)", "\n", "# y: outputs (same scheme)", "\n", "# *_c: variables with condition appended", "\n", "# *1, *2: left half, right half", "\n", "# a: all affine coefficients", "\n", "# s, t: multiplicative and additive coefficients", "\n", "# j: log det Jacobian", "\n", "\n", "        ", "a2", "=", "self", ".", "subnet2", "(", "u2", ")", "\n", "s2", ",", "t2", "=", "a2", "[", ":", ",", ":", "self", ".", "split_len1", "]", ",", "a2", "[", ":", ",", "self", ".", "split_len1", ":", "]", "\n", "s2", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s2", ")", "\n", "j1", "=", "torch", ".", "sum", "(", "s2", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "ndims", "+", "1", ")", ")", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y1", "=", "(", "x1", "-", "t2", ")", "*", "torch", ".", "exp", "(", "-", "s2", ")", "\n", "return", "y1", ",", "-", "j1", "\n", "", "else", ":", "\n", "            ", "y1", "=", "torch", ".", "exp", "(", "s2", ")", "*", "x1", "+", "t2", "\n", "return", "y1", ",", "j1", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GLOWCouplingBlock._coupling2": [[313, 325], ["coupling_layers.GLOWCouplingBlock.subnet1", "torch.sum", "coupling_layers.GLOWCouplingBlock.f_clamp", "tuple", "torch.exp", "range", "torch.exp"], "methods", ["None"], ["", "", "def", "_coupling2", "(", "self", ",", "x2", ",", "u1", ",", "rev", "=", "False", ")", ":", "\n", "        ", "a1", "=", "self", ".", "subnet1", "(", "u1", ")", "\n", "s1", ",", "t1", "=", "a1", "[", ":", ",", ":", "self", ".", "split_len2", "]", ",", "a1", "[", ":", ",", "self", ".", "split_len2", ":", "]", "\n", "s1", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s1", ")", "\n", "j2", "=", "torch", ".", "sum", "(", "s1", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "ndims", "+", "1", ")", ")", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y2", "=", "(", "x2", "-", "t1", ")", "*", "torch", ".", "exp", "(", "-", "s1", ")", "\n", "return", "y2", ",", "-", "j2", "\n", "", "else", ":", "\n", "            ", "y2", "=", "torch", ".", "exp", "(", "s1", ")", "*", "x2", "+", "t1", "\n", "return", "y2", ",", "j2", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock.__init__": [[342, 370], ["coupling_layers._BaseCouplingBlock.__init__", "subnet_constructor", "subnet_constructor"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "Callable", "=", "None", ",", "\n", "clamp", ":", "float", "=", "2.", ",", "\n", "clamp_activation", ":", "Union", "[", "str", ",", "Callable", "]", "=", "\"ATAN\"", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          subnet_constructor: function or class, with signature\n            constructor(dims_in, dims_out).  The result should be a torch\n            nn.Module, that takes dims_in input channels, and dims_out output\n            channels. See tutorial for examples. Two of these subnetworks will be\n            initialized in the block.\n          clamp: Soft clamping for the multiplicative component. The\n            amplification or attenuation of each input dimension can be at most\n            exp(\u00b1clamp).\n          clamp_activation: Function to perform the clamping. String values\n            \"ATAN\", \"TANH\", and \"SIGMOID\" are recognized, or a function of\n            object can be passed. TANH behaves like the original realNVP paper.\n            A custom function should take tensors and map -inf to -1 and +inf to +1.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ",", "clamp", ",", "clamp_activation", ",", "\n", "split_len", "=", "split_len", ")", "\n", "\n", "self", ".", "subnet1", "=", "subnet_constructor", "(", "self", ".", "split_len1", "+", "self", ".", "condition_length", ",", "self", ".", "split_len2", "*", "2", ")", "\n", "self", ".", "subnet2", "=", "subnet_constructor", "(", "self", ".", "split_len2", "+", "self", ".", "condition_length", ",", "self", ".", "split_len1", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock._coupling1": [[371, 393], ["coupling_layers.GINCouplingBlock.subnet2", "s2.mean", "coupling_layers.GINCouplingBlock.f_clamp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "_coupling1", "(", "self", ",", "x1", ",", "u2", ",", "rev", "=", "False", ")", ":", "\n", "\n", "# notation (same for _coupling2):", "\n", "# x: inputs (i.e. 'x-side' when rev is False, 'z-side' when rev is True)", "\n", "# y: outputs (same scheme)", "\n", "# *_c: variables with condition appended", "\n", "# *1, *2: left half, right half", "\n", "# a: all affine coefficients", "\n", "# s, t: multiplicative and additive coefficients", "\n", "# j: log det Jacobian", "\n", "\n", "        ", "a2", "=", "self", ".", "subnet2", "(", "u2", ")", "\n", "s2", ",", "t2", "=", "a2", "[", ":", ",", ":", "self", ".", "split_len1", "]", ",", "a2", "[", ":", ",", "self", ".", "split_len1", ":", "]", "\n", "s2", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s2", ")", "\n", "s2", "-=", "s2", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y1", "=", "(", "x1", "-", "t2", ")", "*", "torch", ".", "exp", "(", "-", "s2", ")", "\n", "return", "y1", ",", "0.", "\n", "", "else", ":", "\n", "            ", "y1", "=", "torch", ".", "exp", "(", "s2", ")", "*", "x1", "+", "t2", "\n", "return", "y1", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.GINCouplingBlock._coupling2": [[394, 406], ["coupling_layers.GINCouplingBlock.subnet1", "s1.mean", "coupling_layers.GINCouplingBlock.f_clamp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "", "def", "_coupling2", "(", "self", ",", "x2", ",", "u1", ",", "rev", "=", "False", ")", ":", "\n", "        ", "a1", "=", "self", ".", "subnet1", "(", "u1", ")", "\n", "s1", ",", "t1", "=", "a1", "[", ":", ",", ":", "self", ".", "split_len2", "]", ",", "a1", "[", ":", ",", "self", ".", "split_len2", ":", "]", "\n", "s1", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s1", ")", "\n", "s1", "-=", "s1", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y2", "=", "(", "x2", "-", "t1", ")", "*", "torch", ".", "exp", "(", "-", "s1", ")", "\n", "return", "y2", ",", "0.", "\n", "", "else", ":", "\n", "            ", "y2", "=", "torch", ".", "exp", "(", "s1", ")", "*", "x2", "+", "t1", "\n", "return", "y2", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.AffineCouplingOneSided.__init__": [[414, 440], ["coupling_layers._BaseCouplingBlock.__init__", "subnet_constructor"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "Callable", "=", "None", ",", "\n", "clamp", ":", "float", "=", "2.", ",", "\n", "clamp_activation", ":", "Union", "[", "str", ",", "Callable", "]", "=", "\"ATAN\"", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          subnet_constructor: function or class, with signature\n            constructor(dims_in, dims_out).  The result should be a torch\n            nn.Module, that takes dims_in input channels, and dims_out output\n            channels. See tutorial for examples. One subnetwork will be\n            initialized in the block.\n          clamp: Soft clamping for the multiplicative component. The\n            amplification or attenuation of each input dimension can be at most\n            exp(\u00b1clamp).\n          clamp_activation: Function to perform the clamping. String values\n            \"ATAN\", \"TANH\", and \"SIGMOID\" are recognized, or a function of\n            object can be passed. TANH behaves like the original realNVP paper.\n            A custom function should take tensors and map -inf to -1 and +inf to +1.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ",", "clamp", ",", "clamp_activation", ",", "\n", "split_len", "=", "split_len", ")", "\n", "self", ".", "subnet", "=", "subnet_constructor", "(", "self", ".", "split_len1", "+", "self", ".", "condition_length", ",", "2", "*", "self", ".", "split_len2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.AffineCouplingOneSided.forward": [[441, 464], ["torch.split", "coupling_layers.AffineCouplingOneSided.subnet", "torch.sum", "torch.cat", "coupling_layers.AffineCouplingOneSided.f_clamp", "tuple", "torch.exp", "torch.cat", "range", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "x1", ",", "x2", "=", "torch", ".", "split", "(", "x", "[", "0", "]", ",", "[", "self", ".", "split_len1", ",", "self", ".", "split_len2", "]", ",", "dim", "=", "1", ")", "\n", "x1_c", "=", "torch", ".", "cat", "(", "[", "x1", ",", "*", "c", "]", ",", "1", ")", "if", "self", ".", "conditional", "else", "x1", "\n", "\n", "# notation:", "\n", "# x1, x2: two halves of the input", "\n", "# y1, y2: two halves of the output", "\n", "# a: all affine coefficients", "\n", "# s, t: multiplicative and additive coefficients", "\n", "# j: log det Jacobian", "\n", "\n", "a", "=", "self", ".", "subnet", "(", "x1_c", ")", "\n", "s", ",", "t", "=", "a", "[", ":", ",", ":", "self", ".", "split_len2", "]", ",", "a", "[", ":", ",", "self", ".", "split_len2", ":", "]", "\n", "s", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s", ")", "\n", "j", "=", "torch", ".", "sum", "(", "s", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "ndims", "+", "1", ")", ")", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y2", "=", "(", "x2", "-", "t", ")", "*", "torch", ".", "exp", "(", "-", "s", ")", "\n", "j", "*=", "-", "1", "\n", "", "else", ":", "\n", "            ", "y2", "=", "x2", "*", "torch", ".", "exp", "(", "s", ")", "+", "t", "\n", "\n", "", "return", "(", "torch", ".", "cat", "(", "(", "x1", ",", "y2", ")", ",", "1", ")", ",", ")", ",", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.ConditionalAffineTransform.__init__": [[472, 502], ["coupling_layers._BaseCouplingBlock.__init__", "subnet_constructor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "Callable", "=", "None", ",", "\n", "clamp", ":", "float", "=", "2.", ",", "\n", "clamp_activation", ":", "Union", "[", "str", ",", "Callable", "]", "=", "\"ATAN\"", ",", "\n", "split_len", ":", "Union", "[", "float", ",", "int", "]", "=", "0.5", ")", ":", "\n", "        ", "'''\n        Additional args in docstring of base class.\n\n        Args:\n          subnet_constructor: function or class, with signature\n            constructor(dims_in, dims_out).  The result should be a torch\n            nn.Module, that takes dims_in input channels, and dims_out output\n            channels. See tutorial for examples. One subnetwork will be\n            initialized in the block.\n          clamp: Soft clamping for the multiplicative component. The\n            amplification or attenuation of each input dimension can be at most\n            exp(\u00b1clamp).\n          clamp_activation: Function to perform the clamping. String values\n            \"ATAN\", \"TANH\", and \"SIGMOID\" are recognized, or a function of\n            object can be passed. TANH behaves like the original realNVP paper.\n            A custom function should take tensors and map -inf to -1 and +inf to +1.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ",", "clamp", ",", "clamp_activation", ",", "\n", "split_len", "=", "split_len", ")", "\n", "\n", "if", "not", "self", ".", "conditional", ":", "\n", "            ", "raise", "ValueError", "(", "\"ConditionalAffineTransform must have a condition\"", ")", "\n", "\n", "", "self", ".", "subnet", "=", "subnet_constructor", "(", "self", ".", "condition_length", ",", "2", "*", "self", ".", "channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.coupling_layers.ConditionalAffineTransform.forward": [[503, 529], ["coupling_layers.ConditionalAffineTransform.subnet", "torch.sum", "len", "torch.cat", "coupling_layers.ConditionalAffineTransform.f_clamp", "tuple", "torch.exp", "range", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "if", "len", "(", "c", ")", ">", "1", ":", "\n", "            ", "cond", "=", "torch", ".", "cat", "(", "c", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "cond", "=", "c", "[", "0", "]", "\n", "\n", "# notation:", "\n", "# x: inputs (i.e. 'x-side' when rev is False, 'z-side' when rev is True)", "\n", "# y: outputs (same scheme)", "\n", "# *_c: variables with condition appended", "\n", "# *1, *2: left half, right half", "\n", "# a: all affine coefficients", "\n", "# s, t: multiplicative and additive coefficients", "\n", "# j: log det Jacobian", "\n", "\n", "", "a", "=", "self", ".", "subnet", "(", "cond", ")", "\n", "s", ",", "t", "=", "a", "[", ":", ",", ":", "self", ".", "channels", "]", ",", "a", "[", ":", ",", "self", ".", "channels", ":", "]", "\n", "s", "=", "self", ".", "clamp", "*", "self", ".", "f_clamp", "(", "s", ")", "\n", "j", "=", "torch", ".", "sum", "(", "s", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "self", ".", "ndims", "+", "1", ")", ")", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "y", "=", "(", "x", "[", "0", "]", "-", "t", ")", "*", "torch", ".", "exp", "(", "-", "s", ")", "\n", "return", "(", "y", ",", ")", ",", "-", "j", "\n", "", "else", ":", "\n", "            ", "y", "=", "torch", ".", "exp", "(", "s", ")", "*", "x", "[", "0", "]", "+", "t", "\n", "return", "(", "y", ",", ")", ",", "j", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.OrthogonalTransform.__init__": [[96, 124], ["InvertibleModule.__init__", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "orthogonal.OrthogonalTransform.register_backward_hook", "numpy.random.randint", "orthogonal.OrthogonalTransform.weights.t", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "\n", "correction_interval", ":", "int", "=", "256", ",", "\n", "clamp", ":", "float", "=", "5.", ")", ":", "\n", "        ", "'''\n        Args:\n\n          correction_interval: After this many gradient steps, the matrix is\n            projected back to the Stiefel manifold to make it perfectly orthogonal.\n          clamp: clamps the log scaling for stability. Corresponds to\n            :math:`alpha` above.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "width", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "clamp", "=", "clamp", "\n", "\n", "self", ".", "correction_interval", "=", "correction_interval", "\n", "self", ".", "back_counter", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "correction_interval", ")", "//", "2", "\n", "\n", "self", ".", "weights", "=", "torch", ".", "randn", "(", "self", ".", "width", ",", "self", ".", "width", ")", "\n", "self", ".", "weights", "=", "self", ".", "weights", "+", "self", ".", "weights", ".", "t", "(", ")", "\n", "self", ".", "weights", ",", "S", ",", "V", "=", "torch", ".", "svd", "(", "self", ".", "weights", ")", "\n", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "self", ".", "weights", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "0.05", "*", "torch", ".", "randn", "(", "1", ",", "self", ".", "width", ")", ")", "\n", "self", ".", "scaling", "=", "nn", ".", "Parameter", "(", "0.02", "*", "torch", ".", "randn", "(", "1", ",", "self", ".", "width", ")", ")", "\n", "\n", "self", ".", "register_backward_hook", "(", "correct_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.OrthogonalTransform._log_e": [[125, 128], ["torch.atan", "torch.atan", "torch.atan", "torch.atan"], "methods", ["None"], ["", "def", "_log_e", "(", "self", ",", "s", ")", ":", "\n", "        ", "'''log of the nonlinear function e'''", "\n", "return", "self", ".", "clamp", "*", "0.636", "*", "torch", ".", "atan", "(", "s", "/", "self", ".", "clamp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.OrthogonalTransform.forward": [[129, 136], ["orthogonal.OrthogonalTransform._log_e", "torch.sum().expand", "torch.sum().expand", "torch.sum().expand", "torch.sum().expand", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "orthogonal.OrthogonalTransform.weights.t", "x[].mm", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.OrthogonalTransform._log_e"], ["", "def", "forward", "(", "self", ",", "x", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "log_scaling", "=", "self", ".", "_log_e", "(", "self", ".", "scaling", ")", "\n", "j", "=", "torch", ".", "sum", "(", "log_scaling", ",", "dim", "=", "1", ")", ".", "expand", "(", "x", "[", "0", "]", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "rev", ":", "\n", "            ", "return", "[", "(", "x", "[", "0", "]", "*", "torch", ".", "exp", "(", "-", "log_scaling", ")", "-", "self", ".", "bias", ")", ".", "mm", "(", "self", ".", "weights", ".", "t", "(", ")", ")", "]", ",", "-", "j", "\n", "", "return", "[", "(", "x", "[", "0", "]", ".", "mm", "(", "self", ".", "weights", ")", "+", "self", ".", "bias", ")", "*", "torch", ".", "exp", "(", "log_scaling", ")", "]", ",", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.OrthogonalTransform.output_dims": [[137, 143], ["len", "ValueError", "len", "ValueError"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} input tensor must be 1D\"", ")", "\n", "", "return", "input_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.HouseholderPerm.__init__": [[163, 209], ["InvertibleModule.__init__", "ValueError", "torch.eye.transpose", "torch.eye.transpose", "torch.Parameter", "torch.Parameter", "orthogonal.HouseholderPerm.register_parameter", "orthogonal._fast_h", "torch.Parameter", "torch.Parameter", "orthogonal.HouseholderPerm.register_parameter", "len", "len", "ValueError", "ValueError", "numpy.prod", "ValueError", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal._fast_h"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "None", ",", "\n", "n_reflections", ":", "int", "=", "1", ",", "\n", "fixed", ":", "bool", "=", "False", ")", ":", "\n", "        ", "'''\n        Args:\n\n          n_reflections: How many subsequent householder reflections to perform.\n            Each householder reflection is learned independently.\n            Must be ``>= 2`` due to implementation reasons.\n          fixed: If true, the householder matrices are initialized randomly and\n            only computed once, and then kept fixed from there on.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "self", ".", "width", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "n_reflections", "=", "n_reflections", "\n", "self", ".", "fixed", "=", "fixed", "\n", "self", ".", "conditional", "=", "(", "not", "dims_c", "is", "None", ")", "and", "(", "len", "(", "dims_c", ")", ">", "0", ")", "\n", "\n", "if", "self", ".", "n_reflections", "<", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need at least 2 householder reflections.\"", ")", "\n", "\n", "", "if", "self", ".", "conditional", ":", "\n", "            ", "if", "len", "(", "dims_c", ")", "!=", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"No more than one conditional input supported.\"", ")", "\n", "", "if", "self", ".", "fixed", ":", "\n", "                ", "raise", "ValueError", "(", "\"Permutation can't be fixed and conditional simultaneously.\"", ")", "\n", "", "if", "np", ".", "prod", "(", "dims_c", "[", "0", "]", ")", "!=", "self", ".", "width", "*", "self", ".", "n_reflections", ":", "\n", "                ", "raise", "ValueError", "(", "\"Dimensions of input, n_reflections and condition don't agree.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "fixed", ":", "\n", "# init randomly", "\n", "                ", "init", "=", "torch", ".", "randn", "(", "self", ".", "width", ",", "self", ".", "n_reflections", ")", "\n", "", "else", ":", "\n", "# init close to identity", "\n", "                ", "init", "=", "torch", ".", "eye", "(", "self", ".", "width", ",", "self", ".", "n_reflections", ")", "\n", "init", "+=", "torch", ".", "randn_like", "(", "init", ")", "*", "0.1", "\n", "", "Vs", "=", "init", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "self", ".", "Vs", "=", "nn", ".", "Parameter", "(", "Vs", ")", "\n", "\n", "Vs", ".", "requires_grad", "=", "not", "self", ".", "fixed", "\n", "self", ".", "register_parameter", "(", "'Vs'", ",", "self", ".", "Vs", ")", "\n", "\n", "", "if", "self", ".", "fixed", ":", "\n", "            ", "self", ".", "W", "=", "_fast_h", "(", "self", ".", "Vs", ")", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "self", ".", "W", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "register_parameter", "(", "'weight'", ",", "self", ".", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.HouseholderPerm.forward": [[210, 225], ["c[].reshape().transpose", "orthogonal._fast_h", "orthogonal._fast_h", "c[].reshape", "x[].mm", "x[].mm", "_fast_h.transpose"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal._fast_h", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal._fast_h"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "\n", "        ", "if", "self", ".", "conditional", ":", "\n", "            ", "Vs", "=", "c", "[", "0", "]", ".", "reshape", "(", "-", "1", ",", "self", ".", "width", ",", "self", ".", "n_reflections", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "W", "=", "_fast_h", "(", "Vs", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "fixed", ":", "\n", "                ", "W", "=", "self", ".", "W", "\n", "", "else", ":", "\n", "                ", "W", "=", "_fast_h", "(", "self", ".", "Vs", ")", "\n", "\n", "", "", "if", "not", "rev", ":", "\n", "            ", "return", "[", "x", "[", "0", "]", ".", "mm", "(", "W", ")", "]", ",", "0.", "\n", "", "else", ":", "\n", "            ", "return", "[", "x", "[", "0", "]", ".", "mm", "(", "W", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "]", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.HouseholderPerm.output_dims": [[226, 232], ["len", "ValueError", "len", "ValueError"], "methods", ["None"], ["", "", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "if", "len", "(", "input_dims", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} can only use 1 input\"", ")", "\n", "", "if", "len", "(", "input_dims", "[", "0", "]", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"{self.__class__.__name__} input tensor must be 1D\"", ")", "\n", "", "return", "input_dims", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal._fast_h": [[7, 64], ["v.unsqueeze.unsqueeze", "torch.eye", "torch.eye", "range", "range", "reversed", "torch.norm", "torch.norm", "ID.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "range", "range", "range", "torch.matmul", "torch.matmul", "Y[].transpose", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "v[].transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Y[].transpose", "v[].transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Y_resi[].transpose", "v[].transpose"], "function", ["None"], ["def", "_fast_h", "(", "v", ",", "stride", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    Fast product of a series of Householder matrices. This implementation is oriented to the one introducesd in:\n    https://invertibleworkshop.github.io/accepted_papers/pdfs/10.pdf\n    This makes use of method 2 in: https://ecommons.cornell.edu/bitstream/handle/1813/6521/85-681.pdf?sequence=1&isAllowed=y\n\n    :param v: Batched series of Householder matrices. The last dim is the dim of one vector and the second last is the\n    number of elements in one product. This is the min amount of dims that need to be present.\n    All further ones are considered batch dimensions.\n    :param stride: Controls the number of parallel operations by the WY representation (see paper)\n    should not be larger than half the number of matrices in one product.\n    :return: The batched product of Householder matrices defined by v\n    \"\"\"", "\n", "assert", "v", ".", "ndim", ">", "1", "\n", "assert", "stride", "<=", "v", ".", "shape", "[", "-", "2", "]", "\n", "\n", "d", ",", "m", "=", "v", ".", "shape", "[", "-", "2", "]", ",", "v", ".", "shape", "[", "-", "1", "]", "\n", "k", "=", "d", "//", "stride", "\n", "last", "=", "k", "*", "stride", "\n", "v", "=", "v", "/", "torch", ".", "norm", "(", "v", ",", "dim", "=", "-", "1", ",", "p", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "v", "=", "v", ".", "unsqueeze", "(", "-", "1", ")", "\n", "u", "=", "2", "*", "v", "\n", "ID", "=", "torch", ".", "eye", "(", "m", ",", "device", "=", "u", ".", "device", ")", "\n", "for", "dim", "in", "range", "(", "v", ".", "ndim", "-", "3", ")", ":", "\n", "        ", "ID", "=", "ID", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# step 1 (compute intermediate groupings P_i)", "\n", "", "W", "=", "u", "[", "...", ",", "0", ":", "last", ":", "stride", ",", ":", ",", ":", "]", "\n", "Y", "=", "v", "[", "...", ",", "0", ":", "last", ":", "stride", ",", ":", ",", ":", "]", "\n", "\n", "for", "idx", "in", "range", "(", "1", ",", "stride", ")", ":", "\n", "        ", "Pt", "=", "ID", "-", "torch", ".", "matmul", "(", "u", "[", "...", ",", "idx", ":", "last", ":", "stride", ",", ":", ",", ":", "]", ",", "v", "[", "...", ",", "idx", ":", "last", ":", "stride", ",", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "W", "=", "torch", ".", "cat", "(", "[", "W", ",", "u", "[", "...", ",", "idx", ":", "last", ":", "stride", ",", ":", ",", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "Y", "=", "torch", ".", "cat", "(", "[", "torch", ".", "matmul", "(", "Pt", ",", "Y", ")", ",", "v", "[", "...", ",", "idx", ":", "last", ":", "stride", ",", ":", ",", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# step 2 (multiply the WY reps)", "\n", "", "P", "=", "ID", "-", "torch", ".", "matmul", "(", "W", "[", "...", ",", "k", "-", "1", ",", ":", ",", ":", "]", ",", "Y", "[", "...", ",", "k", "-", "1", ",", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "for", "idx", "in", "reversed", "(", "range", "(", "0", ",", "k", "-", "1", ")", ")", ":", "\n", "        ", "P", "=", "P", "-", "torch", ".", "matmul", "(", "W", "[", "...", ",", "idx", ",", ":", ",", ":", "]", ",", "torch", ".", "matmul", "(", "Y", "[", "...", ",", "idx", ",", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ",", "P", ")", ")", "\n", "\n", "# deal with the residual, using a stride of 2 here maxes the amount of parallel ops", "\n", "", "if", "d", ">", "last", ":", "\n", "        ", "even_end", "=", "d", "if", "(", "d", "-", "last", ")", "%", "2", "==", "0", "else", "d", "-", "1", "\n", "W_resi", "=", "u", "[", "...", ",", "last", ":", "even_end", ":", "2", ",", ":", ",", ":", "]", "\n", "Y_resi", "=", "v", "[", "...", ",", "last", ":", "even_end", ":", "2", ",", ":", ",", ":", "]", "\n", "for", "idx", "in", "range", "(", "last", "+", "1", ",", "d", "if", "d", "==", "last", "+", "1", "else", "last", "+", "2", ")", ":", "\n", "            ", "Pt", "=", "ID", "-", "torch", ".", "matmul", "(", "u", "[", "...", ",", "idx", ":", "even_end", ":", "2", ",", ":", ",", ":", "]", ",", "v", "[", "...", ",", "idx", ":", "even_end", ":", "2", ",", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "W_resi", "=", "torch", ".", "cat", "(", "[", "W_resi", ",", "u", "[", "...", ",", "idx", ":", "even_end", ":", "2", ",", ":", ",", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "Y_resi", "=", "torch", ".", "cat", "(", "[", "torch", ".", "matmul", "(", "Pt", ",", "Y_resi", ")", ",", "v", "[", "...", ",", "idx", ":", "even_end", ":", "2", ",", ":", ",", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "0", ",", "W_resi", ".", "shape", "[", "-", "3", "]", ")", ":", "\n", "            ", "P", "=", "P", "-", "torch", ".", "matmul", "(", "P", ",", "torch", ".", "matmul", "(", "W_resi", "[", "...", ",", "idx", ",", ":", ",", ":", "]", ",", "Y_resi", "[", "...", ",", "idx", ",", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ")", "\n", "\n", "", "if", "even_end", "!=", "d", ":", "\n", "            ", "P", "=", "P", "-", "torch", ".", "matmul", "(", "P", ",", "torch", ".", "matmul", "(", "u", "[", "...", ",", "-", "1", ",", ":", ",", ":", "]", ",", "v", "[", "...", ",", "-", "1", ",", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ")", "\n", "\n", "", "", "return", "P", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.orth_correction": [[65, 71], ["torch.norm", "torch.norm", "range", "torch.sum", "torch.sum", "torch.norm", "torch.norm", "R[].t", "torch.matmul", "torch.matmul"], "function", ["None"], ["", "def", "orth_correction", "(", "R", ")", ":", "\n", "    ", "R", "[", "0", "]", "/=", "torch", ".", "norm", "(", "R", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "R", ".", "shape", "[", "0", "]", ")", ":", "\n", "\n", "        ", "R", "[", "i", "]", "-=", "torch", ".", "sum", "(", "R", "[", ":", "i", "]", ".", "t", "(", ")", "*", "torch", ".", "matmul", "(", "R", "[", ":", "i", "]", ",", "R", "[", "i", "]", ")", ",", "dim", "=", "1", ")", "\n", "R", "[", "i", "]", "/=", "torch", ".", "norm", "(", "R", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.correct_weights": [[72, 79], ["orthogonal.orth_correction", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.orthogonal.orth_correction"], ["", "", "def", "correct_weights", "(", "module", ",", "grad_in", ",", "grad_out", ")", ":", "\n", "\n", "    ", "module", ".", "back_counter", "+=", "1", "\n", "\n", "if", "module", ".", "back_counter", ">", "module", ".", "correction_interval", ":", "\n", "        ", "module", ".", "back_counter", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "module", ".", "correction_interval", ")", "//", "4", "\n", "orth_correction", "(", "module", ".", "weights", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.__init__": [[45, 169], ["InvertibleModule.__init__", "tuple", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "subnet_constructor", "len", "range", "len", "sum", "warnings.warn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "scipy.stats.special_ortho_group.rvs", "numpy.zeros", "enumerate", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ValueError", "tuple", "tuple", "ValueError", "numpy.log", "torch.Softplus", "torch.Softplus", "torch.Softplus", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "float", "numpy.random.permutation", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.FloatTensor().view", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "numpy.log", "numpy.log", "ValueError", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "all_in_one_block.AllInOneBlock.softplus", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.exp"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["def", "__init__", "(", "self", ",", "dims_in", ",", "dims_c", "=", "[", "]", ",", "\n", "subnet_constructor", ":", "Callable", "=", "None", ",", "\n", "affine_clamping", ":", "float", "=", "2.", ",", "\n", "gin_block", ":", "bool", "=", "False", ",", "\n", "global_affine_init", ":", "float", "=", "1.", ",", "\n", "global_affine_type", ":", "str", "=", "'SOFTPLUS'", ",", "\n", "permute_soft", ":", "bool", "=", "False", ",", "\n", "learned_householder_permutation", ":", "int", "=", "0", ",", "\n", "reverse_permutation", ":", "bool", "=", "False", ")", ":", "\n", "        ", "'''\n        Args:\n          subnet_constructor:\n            class or callable ``f``, called as ``f(channels_in, channels_out)`` and\n            should return a torch.nn.Module. Predicts coupling coefficients :math:`s, t`.\n          affine_clamping:\n            clamp the output of the multiplicative coefficients before\n            exponentiation to +/- ``affine_clamping`` (see :math:`\\\\alpha` above).\n          gin_block:\n            Turn the block into a GIN block from Sorrenson et al, 2019.\n            Makes it so that the coupling operations as a whole is volume preserving.\n          global_affine_init:\n            Initial value for the global affine scaling :math:`s_\\mathrm{global}`.\n          global_affine_init:\n            ``'SIGMOID'``, ``'SOFTPLUS'``, or ``'EXP'``. Defines the activation to be used\n            on the beta for the global affine scaling (:math:`\\\\Psi` above).\n          permute_soft:\n            bool, whether to sample the permutation matrix :math:`R` from :math:`SO(N)`,\n            or to use hard permutations instead. Note, ``permute_soft=True`` is very slow\n            when working with >512 dimensions.\n          learned_householder_permutation:\n            Int, if >0, turn on the matrix :math:`V` above, that represents\n            multiple learned householder reflections. Slow if large number.\n            Dubious whether it actually helps network performance.\n          reverse_permutation:\n            Reverse the permutation before the block, as introduced by Putzky\n            et al, 2019. Turns on the :math:`R^{-1} V^{-1}` pre-multiplication above.\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "dims_in", ",", "dims_c", ")", "\n", "\n", "channels", "=", "dims_in", "[", "0", "]", "[", "0", "]", "\n", "# rank of the tensors means 1d, 2d, 3d tensor etc.", "\n", "self", ".", "input_rank", "=", "len", "(", "dims_in", "[", "0", "]", ")", "-", "1", "\n", "# tuple containing all dims except for batch-dim (used at various points)", "\n", "self", ".", "sum_dims", "=", "tuple", "(", "range", "(", "1", ",", "2", "+", "self", ".", "input_rank", ")", ")", "\n", "\n", "if", "len", "(", "dims_c", ")", "==", "0", ":", "\n", "            ", "self", ".", "conditional", "=", "False", "\n", "self", ".", "condition_channels", "=", "0", "\n", "", "else", ":", "\n", "            ", "assert", "tuple", "(", "dims_c", "[", "0", "]", "[", "1", ":", "]", ")", "==", "tuple", "(", "dims_in", "[", "0", "]", "[", "1", ":", "]", ")", ",", "F\"Dimensions of input and condition don't agree: {dims_c} vs {dims_in}.\"", "\n", "self", ".", "conditional", "=", "True", "\n", "self", ".", "condition_channels", "=", "sum", "(", "dc", "[", "0", "]", "for", "dc", "in", "dims_c", ")", "\n", "\n", "", "split_len1", "=", "channels", "-", "channels", "//", "2", "\n", "split_len2", "=", "channels", "//", "2", "\n", "self", ".", "splits", "=", "[", "split_len1", ",", "split_len2", "]", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "permute_function", "=", "{", "0", ":", "F", ".", "linear", ",", "\n", "1", ":", "F", ".", "conv1d", ",", "\n", "2", ":", "F", ".", "conv2d", ",", "\n", "3", ":", "F", ".", "conv3d", "}", "[", "self", ".", "input_rank", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Data is {1 + self.input_rank}D. Must be 1D-4D.\"", ")", "\n", "\n", "", "self", ".", "in_channels", "=", "channels", "\n", "self", ".", "clamp", "=", "affine_clamping", "\n", "self", ".", "GIN", "=", "gin_block", "\n", "self", ".", "reverse_pre_permute", "=", "reverse_permutation", "\n", "self", ".", "householder", "=", "learned_householder_permutation", "\n", "\n", "if", "permute_soft", "and", "channels", ">", "512", ":", "\n", "            ", "warnings", ".", "warn", "(", "(", "\"Soft permutation will take a very long time to initialize \"", "\n", "f\"with {channels} feature channels. Consider using hard permutation instead.\"", ")", ")", "\n", "\n", "# global_scale is used as the initial value for the global affine scale", "\n", "# (pre-activation). It is computed such that", "\n", "# global_scale_activation(global_scale) = global_affine_init", "\n", "# the 'magic numbers' (specifically for sigmoid) scale the activation to", "\n", "# a sensible range.", "\n", "", "if", "global_affine_type", "==", "'SIGMOID'", ":", "\n", "            ", "global_scale", "=", "2.", "-", "np", ".", "log", "(", "10.", "/", "global_affine_init", "-", "1.", ")", "\n", "self", ".", "global_scale_activation", "=", "(", "lambda", "a", ":", "10", "*", "torch", ".", "sigmoid", "(", "a", "-", "2.", ")", ")", "\n", "", "elif", "global_affine_type", "==", "'SOFTPLUS'", ":", "\n", "            ", "global_scale", "=", "2.", "*", "np", ".", "log", "(", "np", ".", "exp", "(", "0.5", "*", "10.", "*", "global_affine_init", ")", "-", "1", ")", "\n", "self", ".", "softplus", "=", "nn", ".", "Softplus", "(", "beta", "=", "0.5", ")", "\n", "self", ".", "global_scale_activation", "=", "(", "lambda", "a", ":", "0.1", "*", "self", ".", "softplus", "(", "a", ")", ")", "\n", "", "elif", "global_affine_type", "==", "'EXP'", ":", "\n", "            ", "global_scale", "=", "np", ".", "log", "(", "global_affine_init", ")", "\n", "self", ".", "global_scale_activation", "=", "(", "lambda", "a", ":", "torch", ".", "exp", "(", "a", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Global affine activation must be \"SIGMOID\", \"SOFTPLUS\" or \"EXP\"'", ")", "\n", "\n", "", "self", ".", "global_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "self", ".", "in_channels", ",", "*", "(", "[", "1", "]", "*", "self", ".", "input_rank", ")", ")", "*", "float", "(", "global_scale", ")", ")", "\n", "self", ".", "global_offset", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "self", ".", "in_channels", ",", "*", "(", "[", "1", "]", "*", "self", ".", "input_rank", ")", ")", ")", "\n", "\n", "if", "permute_soft", ":", "\n", "            ", "w", "=", "special_ortho_group", ".", "rvs", "(", "channels", ")", "\n", "", "else", ":", "\n", "            ", "w", "=", "np", ".", "zeros", "(", "(", "channels", ",", "channels", ")", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "np", ".", "random", ".", "permutation", "(", "channels", ")", ")", ":", "\n", "                ", "w", "[", "i", ",", "j", "]", "=", "1.", "\n", "\n", "", "", "if", "self", ".", "householder", ":", "\n", "# instead of just the permutation matrix w, the learned housholder", "\n", "# permutation keeps track of reflection vectors vk, in addition to a", "\n", "# random initial permutation w_0.", "\n", "            ", "self", ".", "vk_householder", "=", "nn", ".", "Parameter", "(", "0.2", "*", "torch", ".", "randn", "(", "self", ".", "householder", ",", "channels", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "w_perm", "=", "None", "\n", "self", ".", "w_perm_inv", "=", "None", "\n", "self", ".", "w_0", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "w", ")", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "w_perm", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "w", ")", ".", "view", "(", "channels", ",", "channels", ",", "*", "(", "[", "1", "]", "*", "self", ".", "input_rank", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "self", ".", "w_perm_inv", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "w", ".", "T", ")", ".", "view", "(", "channels", ",", "channels", ",", "*", "(", "[", "1", "]", "*", "self", ".", "input_rank", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "\n", "", "if", "subnet_constructor", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Please supply a callable subnet_constructor\"", "\n", "\"function or object (see docstring)\"", ")", "\n", "", "self", ".", "subnet", "=", "subnet_constructor", "(", "self", ".", "splits", "[", "0", "]", "+", "self", ".", "condition_channels", ",", "2", "*", "self", ".", "splits", "[", "1", "]", ")", "\n", "self", ".", "last_jac", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._construct_householder_permutation": [[170, 180], ["range", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "w.unsqueeze.unsqueeze.unsqueeze", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.dot", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger"], "methods", ["None"], ["", "def", "_construct_householder_permutation", "(", "self", ")", ":", "\n", "        ", "'''Computes a permutation matrix from the reflection vectors that are\n        learned internally as nn.Parameters.'''", "\n", "w", "=", "self", ".", "w_0", "\n", "for", "vk", "in", "self", ".", "vk_householder", ":", "\n", "            ", "w", "=", "torch", ".", "mm", "(", "w", ",", "torch", ".", "eye", "(", "self", ".", "in_channels", ")", ".", "to", "(", "w", ".", "device", ")", "-", "2", "*", "torch", ".", "ger", "(", "vk", ",", "vk", ")", "/", "torch", ".", "dot", "(", "vk", ",", "vk", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "input_rank", ")", ":", "\n", "            ", "w", "=", "w", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "return", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._permute": [[181, 197], ["all_in_one_block.AllInOneBlock.global_scale_activation", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "all_in_one_block.AllInOneBlock.permute_function", "all_in_one_block.AllInOneBlock.permute_function"], "methods", ["None"], ["", "def", "_permute", "(", "self", ",", "x", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''Performs the permutation and scaling after the coupling operation.\n        Returns transformed outputs and the LogJacDet of the scaling operation.'''", "\n", "if", "self", ".", "GIN", ":", "\n", "            ", "scale", "=", "1.", "\n", "perm_log_jac", "=", "0.", "\n", "", "else", ":", "\n", "            ", "scale", "=", "self", ".", "global_scale_activation", "(", "self", ".", "global_scale", ")", "\n", "perm_log_jac", "=", "torch", ".", "sum", "(", "torch", ".", "log", "(", "scale", ")", ")", "\n", "\n", "", "if", "rev", ":", "\n", "            ", "return", "(", "(", "self", ".", "permute_function", "(", "x", ",", "self", ".", "w_perm_inv", ")", "-", "self", ".", "global_offset", ")", "/", "scale", ",", "\n", "perm_log_jac", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "self", ".", "permute_function", "(", "x", "*", "scale", "+", "self", ".", "global_offset", ",", "self", ".", "w_perm", ")", ",", "\n", "perm_log_jac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._pre_permute": [[198, 205], ["all_in_one_block.AllInOneBlock.permute_function", "all_in_one_block.AllInOneBlock.permute_function"], "methods", ["None"], ["", "", "def", "_pre_permute", "(", "self", ",", "x", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''Permutes before the coupling block, only used if\n        reverse_permutation is set'''", "\n", "if", "rev", ":", "\n", "            ", "return", "self", ".", "permute_function", "(", "x", ",", "self", ".", "w_perm", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "permute_function", "(", "x", ",", "self", ".", "w_perm_inv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._affine": [[206, 226], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "", "def", "_affine", "(", "self", ",", "x", ",", "a", ",", "rev", "=", "False", ")", ":", "\n", "        ", "'''Given the passive half, and the pre-activation outputs of the\n        coupling subnetwork, perform the affine coupling operation.\n        Returns both the transformed inputs and the LogJacDet.'''", "\n", "\n", "# the entire coupling coefficient tensor is scaled down by a", "\n", "# factor of ten for stability and easier initialization.", "\n", "a", "*=", "0.1", "\n", "ch", "=", "x", ".", "shape", "[", "1", "]", "\n", "\n", "sub_jac", "=", "self", ".", "clamp", "*", "torch", ".", "tanh", "(", "a", "[", ":", ",", ":", "ch", "]", ")", "\n", "if", "self", ".", "GIN", ":", "\n", "            ", "sub_jac", "-=", "torch", ".", "mean", "(", "sub_jac", ",", "dim", "=", "self", ".", "sum_dims", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "if", "not", "rev", ":", "\n", "            ", "return", "(", "x", "*", "torch", ".", "exp", "(", "sub_jac", ")", "+", "a", "[", ":", ",", "ch", ":", "]", ",", "\n", "torch", ".", "sum", "(", "sub_jac", ",", "dim", "=", "self", ".", "sum_dims", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "x", "-", "a", "[", ":", ",", "ch", ":", "]", ")", "*", "torch", ".", "exp", "(", "-", "sub_jac", ")", ",", "\n", "-", "torch", ".", "sum", "(", "sub_jac", ",", "dim", "=", "self", ".", "sum_dims", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.forward": [[227, 269], ["torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_out[].numel", "all_in_one_block.AllInOneBlock._construct_householder_permutation", "all_in_one_block.AllInOneBlock._permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all_in_one_block.AllInOneBlock.subnet", "all_in_one_block.AllInOneBlock._affine", "all_in_one_block.AllInOneBlock.subnet", "all_in_one_block.AllInOneBlock._affine", "all_in_one_block.AllInOneBlock._permute", "all_in_one_block.AllInOneBlock.w_perm.transpose().contiguous", "all_in_one_block.AllInOneBlock._pre_permute", "all_in_one_block.AllInOneBlock._pre_permute", "all_in_one_block.AllInOneBlock.w_perm.transpose"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._construct_householder_permutation", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._permute", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._affine", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._affine", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._permute", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._pre_permute", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock._pre_permute"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "[", "]", ",", "rev", "=", "False", ",", "jac", "=", "True", ")", ":", "\n", "        ", "'''See base class docstring'''", "\n", "if", "self", ".", "householder", ":", "\n", "            ", "self", ".", "w_perm", "=", "self", ".", "_construct_householder_permutation", "(", ")", "\n", "if", "rev", "or", "self", ".", "reverse_pre_permute", ":", "\n", "                ", "self", ".", "w_perm_inv", "=", "self", ".", "w_perm", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "", "if", "rev", ":", "\n", "            ", "x", ",", "global_scaling_jac", "=", "self", ".", "_permute", "(", "x", "[", "0", "]", ",", "rev", "=", "True", ")", "\n", "x", "=", "(", "x", ",", ")", "\n", "", "elif", "self", ".", "reverse_pre_permute", ":", "\n", "            ", "x", "=", "(", "self", ".", "_pre_permute", "(", "x", "[", "0", "]", ",", "rev", "=", "False", ")", ",", ")", "\n", "\n", "", "x1", ",", "x2", "=", "torch", ".", "split", "(", "x", "[", "0", "]", ",", "self", ".", "splits", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "conditional", ":", "\n", "            ", "x1c", "=", "torch", ".", "cat", "(", "[", "x1", ",", "*", "c", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "x1c", "=", "x1", "\n", "\n", "", "if", "not", "rev", ":", "\n", "            ", "a1", "=", "self", ".", "subnet", "(", "x1c", ")", "\n", "x2", ",", "j2", "=", "self", ".", "_affine", "(", "x2", ",", "a1", ")", "\n", "", "else", ":", "\n", "            ", "a1", "=", "self", ".", "subnet", "(", "x1c", ")", "\n", "x2", ",", "j2", "=", "self", ".", "_affine", "(", "x2", ",", "a1", ",", "rev", "=", "True", ")", "\n", "\n", "", "log_jac_det", "=", "j2", "\n", "x_out", "=", "torch", ".", "cat", "(", "(", "x1", ",", "x2", ")", ",", "1", ")", "\n", "\n", "if", "not", "rev", ":", "\n", "            ", "x_out", ",", "global_scaling_jac", "=", "self", ".", "_permute", "(", "x_out", ",", "rev", "=", "False", ")", "\n", "", "elif", "self", ".", "reverse_pre_permute", ":", "\n", "            ", "x_out", "=", "self", ".", "_pre_permute", "(", "x_out", ",", "rev", "=", "True", ")", "\n", "\n", "# add the global scaling Jacobian to the total.", "\n", "# trick to get the total number of non-channel dimensions:", "\n", "# number of elements of the first channel of the first batch member", "\n", "", "n_pixels", "=", "x_out", "[", "0", ",", ":", "1", "]", ".", "numel", "(", ")", "\n", "log_jac_det", "+=", "(", "-", "1", ")", "**", "rev", "*", "n_pixels", "*", "global_scaling_jac", "\n", "\n", "return", "(", "x_out", ",", ")", ",", "log_jac_det", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.all_in_one_block.AllInOneBlock.output_dims": [[270, 272], ["None"], "methods", ["None"], ["", "def", "output_dims", "(", "self", ",", "input_dims", ")", ":", "\n", "        ", "return", "input_dims", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.SimpleComputeGraph.test_build": [[40, 54], ["FrEIA.InputNode", "FrEIA.InputNode", "FrEIA.OutputNode", "FrEIA.OutputNode", "FrEIA.GraphINN", "FrEIA.GraphINN", "test_reversible_graph_net.SimpleComputeGraph.assertEqual", "test_reversible_graph_net.SimpleComputeGraph.assertEqual", "test_reversible_graph_net.SimpleComputeGraph.assertEqual", "test_reversible_graph_net.SimpleComputeGraph.assertEqual"], "methods", ["None"], ["    ", "def", "test_build", "(", "self", ")", ":", "\n", "\n", "        ", "in_node", "=", "Ff", ".", "InputNode", "(", "3", ",", "10", ",", "10", ")", "\n", "out_node", "=", "Ff", ".", "OutputNode", "(", "in_node", ")", "\n", "graph", "=", "Ff", ".", "GraphINN", "(", "[", "in_node", ",", "out_node", "]", ")", "\n", "\n", "# the input node should not have any graph edges going in", "\n", "self", ".", "assertEqual", "(", "in_node", ".", "input_dims", ",", "[", "]", ")", "\n", "# the output node should not have any graph edges going out", "\n", "self", ".", "assertEqual", "(", "out_node", ".", "output_dims", ",", "[", "]", ")", "\n", "\n", "# dimensions should match", "\n", "self", ".", "assertEqual", "(", "in_node", ".", "output_dims", ",", "out_node", ".", "input_dims", ")", "\n", "self", ".", "assertEqual", "(", "graph", ".", "dims_in", ",", "in_node", ".", "output_dims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.ComplexComputeGraph.__init__": [[58, 103], ["unittest.TestCase.__init__", "FrEIA.InputNode", "FrEIA.InputNode", "FrEIA.ConditionNode", "FrEIA.ConditionNode", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.OutputNode", "FrEIA.OutputNode", "FrEIA.GraphINN", "FrEIA.GraphINN", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "self", ".", "inp_size", "=", "(", "3", ",", "10", ",", "10", ")", "\n", "self", ".", "cond_size", "=", "(", "1", ",", "10", ",", "10", ")", "\n", "\n", "inp", "=", "Ff", ".", "InputNode", "(", "*", "self", ".", "inp_size", ",", "name", "=", "'input'", ")", "\n", "cond", "=", "Ff", ".", "ConditionNode", "(", "*", "self", ".", "cond_size", ",", "name", "=", "'cond'", ")", "\n", "split", "=", "Ff", ".", "Node", "(", "inp", ",", "Fm", ".", "Split", ",", "{", "'section_sizes'", ":", "[", "1", ",", "2", "]", ",", "'dim'", ":", "0", "}", ",", "name", "=", "'split1'", ")", "\n", "\n", "flatten1", "=", "Ff", ".", "Node", "(", "split", ".", "out0", ",", "Fm", ".", "Flatten", ",", "{", "}", ",", "name", "=", "'flatten1'", ")", "\n", "perm", "=", "Ff", ".", "Node", "(", "flatten1", ",", "Fm", ".", "PermuteRandom", ",", "{", "'seed'", ":", "123", "}", ",", "name", "=", "'perm'", ")", "\n", "unflatten1", "=", "Ff", ".", "Node", "(", "perm", ",", "Fm", ".", "Reshape", ",", "{", "'output_dims'", ":", "(", "1", ",", "10", ",", "10", ")", "}", ",", "name", "=", "'unflatten1'", ")", "\n", "\n", "conv", "=", "Ff", ".", "Node", "(", "split", ".", "out1", ",", "\n", "Fm", ".", "RNVPCouplingBlock", ",", "\n", "{", "'subnet_constructor'", ":", "F_conv", ",", "'clamp'", ":", "1.0", "}", ",", "\n", "conditions", "=", "cond", ",", "\n", "name", "=", "'conv'", ")", "\n", "\n", "flatten2", "=", "Ff", ".", "Node", "(", "conv", ",", "Fm", ".", "Flatten", ",", "{", "}", ",", "name", "=", "'flatten2'", ")", "\n", "\n", "linear", "=", "Ff", ".", "Node", "(", "flatten2", ",", "\n", "Fm", ".", "RNVPCouplingBlock", ",", "\n", "{", "'subnet_constructor'", ":", "F_fully_connected", ",", "'clamp'", ":", "1.0", "}", ",", "\n", "name", "=", "'linear'", ")", "\n", "\n", "unflatten2", "=", "Ff", ".", "Node", "(", "linear", ",", "Fm", ".", "Reshape", ",", "{", "'output_dims'", ":", "(", "2", ",", "10", ",", "10", ")", "}", ",", "name", "=", "'unflatten2'", ")", "\n", "concat", "=", "Ff", ".", "Node", "(", "[", "unflatten1", ".", "out0", ",", "unflatten2", ".", "out0", "]", ",", "Fm", ".", "Concat", ",", "{", "'dim'", ":", "0", "}", ",", "name", "=", "'concat'", ")", "\n", "haar", "=", "Ff", ".", "Node", "(", "concat", ",", "Fm", ".", "HaarDownsampling", ",", "{", "}", ",", "name", "=", "'haar'", ")", "\n", "out", "=", "Ff", ".", "OutputNode", "(", "haar", ",", "name", "=", "'output'", ")", "\n", "\n", "self", ".", "test_net", "=", "Ff", ".", "GraphINN", "(", "[", "inp", ",", "cond", ",", "split", ",", "flatten1", ",", "perm", ",", "unflatten1", ",", "conv", ",", "\n", "flatten2", ",", "linear", ",", "unflatten2", ",", "concat", ",", "haar", ",", "out", "]", ")", "\n", "\n", "# this is only used for the cuda variant of the tests.", "\n", "# if true, all tests are skipped.", "\n", "self", ".", "skip_all", "=", "False", "\n", "\n", "self", ".", "batch_size", "=", "32", "\n", "self", ".", "inv_tol", "=", "1e-4", "\n", "torch", ".", "manual_seed", "(", "self", ".", "batch_size", ")", "\n", "\n", "self", ".", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size", ")", "\n", "self", ".", "cond", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "cond_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.ComplexComputeGraph.test_output_shape": [[104, 114], ["test_reversible_graph_net.ComplexComputeGraph.assertTrue", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "test_reversible_graph_net.ComplexComputeGraph.assertEqual", "unittest.SkipTest", "test_reversible_graph_net.ComplexComputeGraph.test_net", "isinstance", "type", "type"], "methods", ["None"], ["", "def", "test_output_shape", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "skip_all", ":", "\n", "            ", "raise", "unittest", ".", "SkipTest", "(", "\"No CUDA-device found, skipping CUDA test.\"", ")", "\n", "\n", "", "y", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "cond", "]", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "y", ",", "type", "(", "self", ".", "x", ")", ")", ",", "f\"{type(y)}\"", ")", "\n", "\n", "exp", "=", "torch", ".", "Size", "(", "[", "self", ".", "batch_size", ",", "self", ".", "inp_size", "[", "0", "]", "*", "4", ",", "self", ".", "inp_size", "[", "1", "]", "//", "2", ",", "self", ".", "inp_size", "[", "2", "]", "//", "2", "]", ")", "\n", "self", ".", "assertEqual", "(", "y", ".", "shape", ",", "exp", ",", "f\"{y.shape}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.ComplexComputeGraph.test_inverse": [[115, 127], ["test_reversible_graph_net.ComplexComputeGraph.test_net", "test_reversible_graph_net.ComplexComputeGraph.test_net", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "test_reversible_graph_net.ComplexComputeGraph.assertTrue", "test_reversible_graph_net.ComplexComputeGraph.assertTrue", "unittest.SkipTest", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "test_inverse", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "skip_all", ":", "\n", "            ", "raise", "unittest", ".", "SkipTest", "(", "\"No CUDA-device found, skipping CUDA test.\"", ")", "\n", "\n", "", "y", ",", "j", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "cond", "]", ")", "\n", "x_re", ",", "j_re", "=", "self", ".", "test_net", "(", "y", ",", "c", "=", "[", "self", ".", "cond", "]", ",", "rev", "=", "True", ")", "\n", "\n", "obs", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "self", ".", "x", "-", "x_re", ")", ")", "\n", "obs_j", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "j", "+", "j_re", ")", ")", "\n", "self", ".", "assertTrue", "(", "obs", "<", "self", ".", "inv_tol", ",", "f\"Inversion {obs} !< {self.inv_tol}\"", ")", "\n", "self", ".", "assertTrue", "(", "obs_j", "<", "self", ".", "inv_tol", ",", "f\"Jacobian inversion {obs} !< {self.inv_tol}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.ComplexComputeGraph.test_jacobian": [[128, 139], ["test_reversible_graph_net.ComplexComputeGraph.test_net.log_jacobian_numerical", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "test_reversible_graph_net.ComplexComputeGraph.assertTrue", "unittest.SkipTest", "test_reversible_graph_net.ComplexComputeGraph.test_net"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.log_jacobian_numerical"], ["", "def", "test_jacobian", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "skip_all", ":", "\n", "            ", "raise", "unittest", ".", "SkipTest", "(", "\"No CUDA-device found, skipping CUDA test.\"", ")", "\n", "\n", "", "logdet", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "cond", "]", ")", "[", "1", "]", "\n", "# Approximate log det of Jacobian numerically", "\n", "logdet_num", "=", "self", ".", "test_net", ".", "log_jacobian_numerical", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "cond", "]", ",", "h", "=", "1e-3", ")", "\n", "# Check that they are the same (within tolerance)", "\n", "obs", "=", "torch", ".", "allclose", "(", "logdet", ",", "logdet_num", ",", "atol", "=", "np", ".", "inf", ",", "rtol", "=", "0.03", ")", "\n", "self", ".", "assertTrue", "(", "obs", ",", "f\"Numerical Jacobian check {logdet, logdet_num}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.ComplexComputeGraphCuda.__init__": [[143, 152], ["test_reversible_graph_net.ComplexComputeGraph.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "test_reversible_graph_net.ComplexComputeGraphCuda.x.cuda", "test_reversible_graph_net.ComplexComputeGraphCuda.cond.cuda", "test_reversible_graph_net.ComplexComputeGraphCuda.test_net.cuda"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "x", ".", "cuda", "(", ")", "\n", "self", ".", "cond", "=", "self", ".", "cond", ".", "cuda", "(", ")", "\n", "self", ".", "test_net", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "skip_all", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.F_conv": [[11, 18], ["torch.Sequential", "nn.Sequential.apply", "torch.Conv2d", "torch.ReLU", "torch.Conv2d"], "function", ["None"], ["def", "F_conv", "(", "cin", ",", "cout", ")", ":", "\n", "    ", "'''Simple convolutional subnetwork'''", "\n", "net", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "cin", ",", "32", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "cout", ",", "3", ",", "padding", "=", "1", ")", ")", "\n", "net", ".", "apply", "(", "subnet_initialization", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.F_fully_connected": [[20, 27], ["torch.Sequential", "nn.Sequential.apply", "torch.Linear", "torch.ReLU", "torch.Linear"], "function", ["None"], ["", "def", "F_fully_connected", "(", "cin", ",", "cout", ")", ":", "\n", "    ", "'''Simple fully connected subnetwork'''", "\n", "net", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "cin", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "cout", ")", ")", "\n", "net", ".", "apply", "(", "subnet_initialization", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_reversible_graph_net.subnet_initialization": [[31, 36], ["isinstance", "isinstance", "torch.init.kaiming_uniform_"], "function", ["None"], ["", "def", "subnet_initialization", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "weight", ".", "data", "*=", "0.3", "\n", "m", ".", "bias", ".", "data", "*=", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_base.BaseLayerTest.__init__": [[12, 25], ["unittest.TestCase.__init__", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "self", ".", "batch_size", "=", "32", "\n", "self", ".", "tol", "=", "1e-4", "\n", "\n", "input_size", "=", "8", "\n", "cond_size", "=", "32", "#this could be 2D too", "\n", "\n", "torch", ".", "manual_seed", "(", "self", ".", "batch_size", ")", "\n", "\n", "self", ".", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "input_size", ")", "\n", "self", ".", "c", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "cond_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_base.BaseLayerTest.test_constructs": [[26, 30], ["FrEIA.modules.InvertibleModule", "test_base.BaseLayerTest.assertTrue", "isinstance"], "methods", ["None"], ["", "def", "test_constructs", "(", "self", ")", ":", "\n", "\n", "        ", "b", "=", "InvertibleModule", "(", "self", ".", "x", ".", "shape", ",", "self", ".", "c", ".", "shape", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "b", ",", "InvertibleModule", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_invertible_resnet.ActNormTest.__init__": [[16, 35], ["unittest.TestCase.__init__", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "nodes.append", "nodes.append", "GraphINN", "nodes.append", "nodes.append", "GraphINN", "InputNode", "Node", "OutputNode", "InputNode", "Node", "OutputNode"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "self", ".", "batch_size", "=", "256", "\n", "self", ".", "inp_size_linear", "=", "(", "20", ",", ")", "\n", "self", ".", "inp_size_conv", "=", "(", "3", ",", "10", ",", "10", ")", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "\n", "nodes", "=", "[", "InputNode", "(", "*", "self", ".", "inp_size_linear", ",", "name", "=", "'input'", ")", "]", "\n", "nodes", ".", "append", "(", "Node", "(", "nodes", "[", "-", "1", "]", ",", "ActNorm", ",", "{", "}", ",", "\n", "name", "=", "f'actnorm'", ")", ")", "\n", "nodes", ".", "append", "(", "OutputNode", "(", "nodes", "[", "-", "1", "]", ",", "name", "=", "'output'", ")", ")", "\n", "self", ".", "net_linear", "=", "GraphINN", "(", "nodes", ",", "verbose", "=", "False", ")", "\n", "\n", "nodes", "=", "[", "InputNode", "(", "*", "self", ".", "inp_size_conv", ",", "name", "=", "'input'", ")", "]", "\n", "nodes", ".", "append", "(", "Node", "(", "nodes", "[", "-", "1", "]", ",", "ActNorm", ",", "{", "}", ",", "\n", "name", "=", "f'actnorm'", ")", ")", "\n", "nodes", ".", "append", "(", "OutputNode", "(", "nodes", "[", "-", "1", "]", ",", "name", "=", "'output'", ")", ")", "\n", "self", ".", "net_conv", "=", "GraphINN", "(", "nodes", ",", "verbose", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_invertible_resnet.ActNormTest.test_init": [[37, 57], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.ActNormTest.assertTrue", "test_invertible_resnet.ActNormTest.assertTrue", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.ActNormTest.assertTrue", "test_invertible_resnet.ActNormTest.assertTrue", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "test_invertible_resnet.ActNormTest.net_linear", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "test_invertible_resnet.ActNormTest.net_conv", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "y.transpose().contiguous().view().mean", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "y.transpose().contiguous().view().std", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "y.transpose().contiguous().view().mean", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "y.transpose().contiguous().view().std", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "y.transpose().contiguous().view", "y.transpose().contiguous().view", "y.transpose().contiguous().view", "y.transpose().contiguous().view", "y.transpose().contiguous", "y.transpose().contiguous", "y.transpose().contiguous", "y.transpose().contiguous", "y.transpose", "y.transpose", "y.transpose", "y.transpose"], "methods", ["None"], ["", "def", "test_init", "(", "self", ")", ":", "\n", "        ", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_linear", ")", "\n", "x", "=", "x", "*", "torch", ".", "rand_like", "(", "x", ")", "+", "torch", ".", "randn_like", "(", "x", ")", "\n", "y", "=", "self", ".", "net_linear", "(", "x", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "# Channel-wise mean should be zero", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "y", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "inp_size_linear", "[", "0", "]", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", ",", "\n", "torch", ".", "zeros", "(", "self", ".", "inp_size_linear", "[", "0", "]", ")", ",", "atol", "=", "1e-06", ")", ")", "\n", "# Channel-wise std should be one", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "y", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "inp_size_linear", "[", "0", "]", ",", "-", "1", ")", ".", "std", "(", "dim", "=", "-", "1", ")", ",", "\n", "torch", ".", "ones", "(", "self", ".", "inp_size_linear", "[", "0", "]", ")", ",", "atol", "=", "1e-06", ")", ")", "\n", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_conv", ")", "\n", "x", "=", "x", "*", "torch", ".", "rand_like", "(", "x", ")", "+", "torch", ".", "randn_like", "(", "x", ")", "\n", "y", "=", "self", ".", "net_conv", "(", "x", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "# Channel-wise mean should be zero", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "y", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "inp_size_conv", "[", "0", "]", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", ",", "\n", "torch", ".", "zeros", "(", "self", ".", "inp_size_conv", "[", "0", "]", ")", ",", "atol", "=", "1e-06", ")", ")", "\n", "# Channel-wise std should be one", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "y", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "inp_size_conv", "[", "0", "]", ",", "-", "1", ")", ".", "std", "(", "dim", "=", "-", "1", ")", ",", "\n", "torch", ".", "ones", "(", "self", ".", "inp_size_conv", "[", "0", "]", ")", ",", "atol", "=", "1e-06", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_invertible_resnet.IResNetTest.__init__": [[61, 101], ["unittest.TestCase.__init__", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "ConditionNode", "range", "nodes.append", "GraphINN", "range", "nodes.append", "GraphINN", "InputNode", "nodes.append", "nodes.append", "OutputNode", "isinstance", "InputNode", "nodes.append", "nodes.append", "OutputNode", "isinstance", "Node", "Node", "node.module.lipschitz_correction", "Node", "Node", "node.module.lipschitz_correction"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.sequence_inn.SequenceINN.append", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer.lipschitz_correction", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.invertible_resnet.IResNetLayer.lipschitz_correction"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "self", ".", "batch_size", "=", "7", "\n", "self", ".", "inp_size_linear", "=", "(", "20", ",", ")", "\n", "self", ".", "inp_size_conv", "=", "(", "3", ",", "10", ",", "10", ")", "\n", "self", ".", "tol", "=", "1e-6", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "\n", "nodes", "=", "[", "InputNode", "(", "*", "self", ".", "inp_size_linear", ",", "name", "=", "'input'", ")", "]", "\n", "cond", "=", "ConditionNode", "(", "*", "self", ".", "inp_size_linear", ",", "name", "=", "'cond'", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "nodes", ".", "append", "(", "Node", "(", "nodes", "[", "-", "1", "]", ",", "ActNorm", ",", "{", "}", ",", "\n", "name", "=", "f'actnorm_{i}'", ")", ")", "\n", "nodes", ".", "append", "(", "Node", "(", "nodes", "[", "-", "1", "]", ",", "IResNetLayer", ",", "\n", "{", "'hutchinson_samples'", ":", "20", ",", "\n", "'internal_size'", ":", "100", ",", "\n", "'n_internal_layers'", ":", "3", "}", ",", "\n", "conditions", "=", "[", "cond", "]", ",", "\n", "name", "=", "f'i_resnet_{i}'", ")", ")", "\n", "", "nodes", ".", "append", "(", "OutputNode", "(", "nodes", "[", "-", "1", "]", ",", "name", "=", "'output'", ")", ")", "\n", "self", ".", "i_resnet_linear", "=", "GraphINN", "(", "nodes", "+", "[", "cond", ",", "]", ",", "verbose", "=", "False", ")", "\n", "\n", "for", "node", "in", "self", ".", "i_resnet_linear", ".", "node_list", ":", "\n", "            ", "if", "isinstance", "(", "node", ".", "module", ",", "IResNetLayer", ")", ":", "\n", "                ", "node", ".", "module", ".", "lipschitz_correction", "(", ")", "\n", "\n", "\n", "", "", "nodes", "=", "[", "InputNode", "(", "*", "self", ".", "inp_size_conv", ",", "name", "=", "'input'", ")", "]", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "nodes", ".", "append", "(", "Node", "(", "nodes", "[", "-", "1", "]", ",", "ActNorm", ",", "{", "}", ",", "\n", "name", "=", "f'actnorm_{i}'", ")", ")", "\n", "nodes", ".", "append", "(", "Node", "(", "nodes", "[", "-", "1", "]", ",", "IResNetLayer", ",", "{", "'hutchinson_samples'", ":", "20", "}", ",", "\n", "name", "=", "f'i_resnet_{i}'", ")", ")", "\n", "", "nodes", ".", "append", "(", "OutputNode", "(", "nodes", "[", "-", "1", "]", ",", "name", "=", "'output'", ")", ")", "\n", "self", ".", "i_resnet_conv", "=", "GraphINN", "(", "nodes", ",", "verbose", "=", "False", ")", "\n", "\n", "for", "node", "in", "self", ".", "i_resnet_conv", ".", "node_list", ":", "\n", "            ", "if", "isinstance", "(", "node", ".", "module", ",", "IResNetLayer", ")", ":", "\n", "                ", "node", ".", "module", ".", "lipschitz_correction", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_invertible_resnet.IResNetTest.test_inverse": [[103, 122], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.IResNetTest.assertTrue", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.IResNetTest.assertTrue", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "test_invertible_resnet.IResNetTest.i_resnet_linear", "test_invertible_resnet.IResNetTest.i_resnet_linear", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "test_invertible_resnet.IResNetTest.i_resnet_conv", "test_invertible_resnet.IResNetTest.i_resnet_conv", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose"], "methods", ["None"], ["", "", "", "def", "test_inverse", "(", "self", ")", ":", "\n", "        ", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_linear", ")", "\n", "x", "=", "x", "*", "torch", ".", "randn_like", "(", "x", ")", "\n", "x", "=", "x", "+", "torch", ".", "randn_like", "(", "x", ")", "\n", "c", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_linear", ")", "\n", "\n", "y", "=", "self", ".", "i_resnet_linear", "(", "x", ",", "c", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "x_hat", "=", "self", ".", "i_resnet_linear", "(", "y", ",", "c", ",", "rev", "=", "True", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "# Check that inverse is close to input", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "x", ",", "x_hat", ",", "atol", "=", "self", ".", "tol", ")", ")", "\n", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_conv", ")", "\n", "x", "=", "x", "*", "torch", ".", "randn_like", "(", "x", ")", "\n", "x", "=", "x", "+", "torch", ".", "randn_like", "(", "x", ")", "\n", "\n", "y", "=", "self", ".", "i_resnet_conv", "(", "x", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "x_hat", "=", "self", ".", "i_resnet_conv", "(", "y", ",", "rev", "=", "True", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "# Check that inverse is close to input", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "x", ",", "x_hat", ",", "atol", "=", "self", ".", "tol", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_invertible_resnet.IResNetTest.test_jacobian": [[124, 150], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.IResNetTest.i_resnet_linear", "test_invertible_resnet.IResNetTest.i_resnet_linear.log_jacobian_numerical", "test_invertible_resnet.IResNetTest.assertTrue", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.IResNetTest.i_resnet_conv.log_jacobian_numerical", "test_invertible_resnet.IResNetTest.assertTrue", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_invertible_resnet.IResNetTest.i_resnet_conv", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "range", "range", "range", "range", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.log_jacobian_numerical", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.log_jacobian_numerical"], ["", "def", "test_jacobian", "(", "self", ")", ":", "\n", "        ", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_linear", ")", "\n", "x", "=", "x", "*", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "[", "1", "for", "i", "in", "range", "(", "len", "(", "self", ".", "inp_size_linear", ")", ")", "]", ")", "\n", "x", "=", "x", "+", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "[", "1", "for", "i", "in", "range", "(", "len", "(", "self", ".", "inp_size_linear", ")", ")", "]", ")", "\n", "c", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_linear", ")", "\n", "\n", "# Estimate log det of Jacobian via power series", "\n", "z", ",", "logdet", "=", "self", ".", "i_resnet_linear", "(", "x", ",", "c", "=", "c", ")", "\n", "# Approximate log det of Jacobian numerically", "\n", "logdet_num", "=", "self", ".", "i_resnet_linear", ".", "log_jacobian_numerical", "(", "x", ",", "c", "=", "c", ")", "\n", "# Check that they are the same (with huge tolerance)", "\n", "# print(f'\\n{logdet}\\n{logdet_num}')", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "logdet", ",", "logdet_num", ",", "atol", "=", "1.5", ",", "rtol", "=", "0.15", ")", ")", "\n", "\n", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size_conv", ")", "\n", "x", "=", "x", "*", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "[", "1", "for", "i", "in", "range", "(", "len", "(", "self", ".", "inp_size_conv", ")", ")", "]", ")", "\n", "x", "=", "x", "+", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "[", "1", "for", "i", "in", "range", "(", "len", "(", "self", ".", "inp_size_conv", ")", ")", "]", ")", "\n", "\n", "# Estimate log det of Jacobian via power series", "\n", "logdet", "=", "self", ".", "i_resnet_conv", "(", "x", ")", "[", "1", "]", "\n", "# Approximate log det of Jacobian numerically", "\n", "logdet_num", "=", "self", ".", "i_resnet_conv", ".", "log_jacobian_numerical", "(", "x", ")", "\n", "# Check that they are the same (with huge tolerance)", "\n", "# print(f'\\n{logdet}\\n{logdet_num}')", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "logdet", ",", "logdet_num", ",", "atol", "=", "1.5", ",", "rtol", "=", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.ConditioningTest.__init__": [[40, 84], ["unittest.TestCase.__init__", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "FrEIA.InputNode", "FrEIA.InputNode", "FrEIA.ConditionNode", "FrEIA.ConditionNode", "FrEIA.ConditionNode", "FrEIA.ConditionNode", "FrEIA.ConditionNode", "FrEIA.ConditionNode", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.Node", "FrEIA.OutputNode", "FrEIA.OutputNode", "FrEIA.GraphINN", "FrEIA.GraphINN"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "self", ".", "batch_size", "=", "32", "\n", "self", ".", "inv_tol", "=", "1e-4", "\n", "torch", ".", "manual_seed", "(", "self", ".", "batch_size", ")", "\n", "\n", "self", ".", "inp_size", "=", "(", "3", ",", "10", ",", "10", ")", "\n", "self", ".", "c1_size", "=", "(", "1", ",", "10", ",", "10", ")", "\n", "self", ".", "c2_size", "=", "(", "50", ",", ")", "\n", "self", ".", "c3_size", "=", "(", "20", ",", ")", "\n", "\n", "self", ".", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "inp_size", ")", "\n", "self", ".", "c1", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "c1_size", ")", "\n", "self", ".", "c2", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "c2_size", ")", "\n", "self", ".", "c3", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "c3_size", ")", "\n", "\n", "# this is only used for the cuda variant of the tests.", "\n", "# if true, all tests are skipped.", "\n", "self", ".", "skip_all", "=", "False", "\n", "\n", "inp", "=", "Ff", ".", "InputNode", "(", "*", "self", ".", "inp_size", ",", "name", "=", "'input'", ")", "\n", "c1", "=", "Ff", ".", "ConditionNode", "(", "*", "self", ".", "c1_size", ",", "name", "=", "'c1'", ")", "\n", "c2", "=", "Ff", ".", "ConditionNode", "(", "*", "self", ".", "c2_size", ",", "name", "=", "'c2'", ")", "\n", "c3", "=", "Ff", ".", "ConditionNode", "(", "*", "self", ".", "c3_size", ",", "name", "=", "'c3'", ")", "\n", "\n", "conv", "=", "Ff", ".", "Node", "(", "inp", ",", "\n", "Fm", ".", "RNVPCouplingBlock", ",", "\n", "{", "'subnet_constructor'", ":", "F_conv", ",", "'clamp'", ":", "1.0", "}", ",", "\n", "conditions", "=", "c1", ",", "\n", "name", "=", "'conv::c1'", ")", "\n", "flatten", "=", "Ff", ".", "Node", "(", "conv", ",", "\n", "Fm", ".", "Flatten", ",", "\n", "{", "}", ",", "\n", "name", "=", "'flatten'", ")", "\n", "\n", "linear", "=", "Ff", ".", "Node", "(", "flatten", ",", "\n", "Fm", ".", "RNVPCouplingBlock", ",", "\n", "{", "'subnet_constructor'", ":", "F_fully_connected", ",", "'clamp'", ":", "1.0", "}", ",", "\n", "conditions", "=", "[", "c2", ",", "c3", "]", ",", "\n", "name", "=", "'linear::c2|c3'", ")", "\n", "\n", "outp", "=", "Ff", ".", "OutputNode", "(", "linear", ",", "name", "=", "'output'", ")", "\n", "self", ".", "test_net", "=", "Ff", ".", "GraphINN", "(", "[", "inp", ",", "c1", ",", "conv", ",", "flatten", ",", "c2", ",", "c3", ",", "linear", ",", "outp", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.ConditioningTest.test_output_shape": [[85, 107], ["test_conditioning.ConditioningTest.assertTrue", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "test_conditioning.ConditioningTest.assertEqual", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "unittest.SkipTest", "test_conditioning.ConditioningTest.test_net", "isinstance", "test_conditioning.ConditioningTest.assertRaises", "test_conditioning.ConditioningTest.test_net", "test_conditioning.ConditioningTest.assertRaises", "test_conditioning.ConditioningTest.test_net", "test_conditioning.ConditioningTest.assertRaises", "test_conditioning.ConditioningTest.test_net", "type", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "type"], "methods", ["None"], ["", "def", "test_output_shape", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "skip_all", ":", "\n", "            ", "raise", "unittest", ".", "SkipTest", "(", "\"No CUDA-device found, skipping CUDA test.\"", ")", "\n", "\n", "", "y", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "c1", ",", "self", ".", "c2", ",", "self", ".", "c3", "]", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "y", ",", "type", "(", "self", ".", "x", ")", ")", ",", "f\"{type(y)}\"", ")", "\n", "\n", "exp", "=", "torch", ".", "Size", "(", "[", "self", ".", "batch_size", ",", "self", ".", "inp_size", "[", "0", "]", "*", "self", ".", "inp_size", "[", "1", "]", "*", "self", ".", "inp_size", "[", "2", "]", "]", ")", "\n", "self", ".", "assertEqual", "(", "y", ".", "shape", ",", "exp", ",", "f\"{y.shape}\"", ")", "\n", "\n", "# Assert that wrong condition inputs throw exceptions", "\n", "with", "self", ".", "assertRaises", "(", "Exception", ")", "as", "context", ":", "\n", "            ", "y", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "c2", ",", "self", ".", "c1", ",", "self", ".", "c3", "]", ")", "\n", "\n", "", "c2a", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "self", ".", "c2_size", "[", "0", "]", "+", "4", ",", "*", "self", ".", "c2_size", "[", "1", ":", "]", ")", ".", "to", "(", "self", ".", "c2", ".", "device", ")", "\n", "with", "self", ".", "assertRaises", "(", "Exception", ")", "as", "context", ":", "\n", "            ", "y", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "c1", ",", "c2a", ",", "self", ".", "c3", "]", ")", "\n", "\n", "", "c1a", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "*", "self", ".", "c1_size", "[", ":", "2", "]", ",", "self", ".", "c1_size", "[", "2", "]", "+", "1", ")", ".", "to", "(", "self", ".", "c1", ".", "device", ")", "\n", "with", "self", ".", "assertRaises", "(", "Exception", ")", "as", "context", ":", "\n", "            ", "y", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "c1a", ",", "self", ".", "c2", ",", "self", ".", "c3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.ConditioningTest.test_inverse": [[108, 120], ["test_conditioning.ConditioningTest.test_net", "test_conditioning.ConditioningTest.test_net", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "test_conditioning.ConditioningTest.assertTrue", "test_conditioning.ConditioningTest.assertTrue", "unittest.SkipTest", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "", "def", "test_inverse", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "skip_all", ":", "\n", "            ", "raise", "unittest", ".", "SkipTest", "(", "\"No CUDA-device found, skipping CUDA test.\"", ")", "\n", "\n", "", "y", ",", "j", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "c1", ",", "self", ".", "c2", ",", "self", ".", "c3", "]", ")", "\n", "x_re", ",", "j_re", "=", "self", ".", "test_net", "(", "y", ",", "c", "=", "[", "self", ".", "c1", ",", "self", ".", "c2", ",", "self", ".", "c3", "]", ",", "rev", "=", "True", ")", "\n", "\n", "obs", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "self", ".", "x", "-", "x_re", ")", ")", "\n", "obs_j", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "j", "+", "j_re", ")", ")", "\n", "self", ".", "assertTrue", "(", "obs", "<", "self", ".", "inv_tol", ",", "f\"Inversion {obs} !< {self.inv_tol}\"", ")", "\n", "self", ".", "assertTrue", "(", "obs_j", "<", "self", ".", "inv_tol", ",", "f\"Jacobian inversion {obs} !< {self.inv_tol}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.ConditioningTest.test_jacobian": [[121, 133], ["test_conditioning.ConditioningTest.test_net.log_jacobian_numerical", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose", "test_conditioning.ConditioningTest.assertTrue", "unittest.SkipTest", "test_conditioning.ConditioningTest.test_net"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.log_jacobian_numerical"], ["", "def", "test_jacobian", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "skip_all", ":", "\n", "            ", "raise", "unittest", ".", "SkipTest", "(", "\"No CUDA-device found, skipping CUDA test.\"", ")", "\n", "\n", "# Compute log det of Jacobian", "\n", "", "logdet", "=", "self", ".", "test_net", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "c1", ",", "self", ".", "c2", ",", "self", ".", "c3", "]", ")", "[", "1", "]", "\n", "# Approximate log det of Jacobian numerically", "\n", "logdet_num", "=", "self", ".", "test_net", ".", "log_jacobian_numerical", "(", "self", ".", "x", ",", "c", "=", "[", "self", ".", "c1", ",", "self", ".", "c2", ",", "self", ".", "c3", "]", ",", "h", "=", "1e-3", ")", "\n", "# Check that they are the same (within tolerance)", "\n", "obs", "=", "torch", ".", "allclose", "(", "logdet", ",", "logdet_num", ",", "atol", "=", "np", ".", "inf", ",", "rtol", "=", "0.03", ")", "\n", "self", ".", "assertTrue", "(", "obs", ",", "f\"Numerical Jacobian check {logdet, logdet_num}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.ConditioningTestCuda.__init__": [[137, 148], ["test_conditioning.ConditioningTest.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "test_conditioning.ConditioningTestCuda.x.cuda", "test_conditioning.ConditioningTestCuda.c1.cuda", "test_conditioning.ConditioningTestCuda.c2.cuda", "test_conditioning.ConditioningTestCuda.c3.cuda", "test_conditioning.ConditioningTestCuda.test_net.cuda"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "x", ".", "cuda", "(", ")", "\n", "self", ".", "c1", "=", "self", ".", "c1", ".", "cuda", "(", ")", "\n", "self", ".", "c2", "=", "self", ".", "c2", ".", "cuda", "(", ")", "\n", "self", ".", "c3", "=", "self", ".", "c3", ".", "cuda", "(", ")", "\n", "self", ".", "test_net", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "skip_all", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.F_conv": [[12, 19], ["torch.Sequential", "nn.Sequential.apply", "torch.Conv2d", "torch.ReLU", "torch.Conv2d"], "function", ["None"], ["def", "F_conv", "(", "cin", ",", "cout", ")", ":", "\n", "    ", "'''Simple convolutional subnetwork'''", "\n", "net", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "cin", ",", "32", ",", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "cout", ",", "3", ",", "padding", "=", "1", ")", ")", "\n", "net", ".", "apply", "(", "subnet_initialization", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.F_fully_connected": [[21, 28], ["torch.Sequential", "nn.Sequential.apply", "torch.Linear", "torch.ReLU", "torch.Linear"], "function", ["None"], ["", "def", "F_fully_connected", "(", "cin", ",", "cout", ")", ":", "\n", "    ", "'''Simple fully connected subnetwork'''", "\n", "net", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "cin", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "cout", ")", ")", "\n", "net", ".", "apply", "(", "subnet_initialization", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_conditioning.subnet_initialization": [[32, 36], ["isinstance", "isinstance", "torch.init.kaiming_uniform_"], "function", ["None"], ["", "def", "subnet_initialization", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "bias", ".", "data", "*=", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_orthogonal_layer.OrthogonalTest.__init__": [[29, 35], ["unittest.TestCase.__init__", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n", "self", ".", "batch_size", "=", "256", "\n", "self", ".", "tol", "=", "1e-4", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_orthogonal_layer.OrthogonalTest.test_inverse": [[36, 48], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_net", "test_net", "test_orthogonal_layer.OrthogonalTest.assertTrue", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "print", "print", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "test_inverse", "(", "self", ")", ":", "\n", "        ", "return", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "inp_size", ")", "\n", "\n", "y", "=", "test_net", "(", "x", ")", "\n", "x_re", "=", "test_net", "(", "y", ",", "rev", "=", "True", ")", "\n", "\n", "if", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ">", "self", ".", "tol", ":", "\n", "            ", "print", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ".", "item", "(", ")", ",", "end", "=", "'   '", ")", "\n", "print", "(", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "self", ".", "assertTrue", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", "<", "self", ".", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_orthogonal_layer.OrthogonalTest.test_param_update": [[49, 78], ["range", "optim.zero_grad", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.backward", "torch.mean.backward", "torch.mean.backward", "test_net.named_parameters", "optim.step", "test_net", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "weights.t", "print", "print", "print", "print", "p.data.t", "torch.mean.item", "torch.mean.item", "torch.mean.item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mm.t", "torch.mm.t", "torch.mm.t", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "test_param_update", "(", "self", ")", ":", "\n", "# TODO: there should be some quantifyable test condition at least...", "\n", "\n", "        ", "for", "i", "in", "range", "(", "2500", ")", ":", "\n", "            ", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "inp_size", ")", "\n", "y", "=", "test_net", "(", "x", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "\n", "loss", "=", "torch", ".", "mean", "(", "(", "y", "-", "x", ")", "**", "2", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "name", ",", "p", "in", "test_net", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weights'", "in", "name", ":", "\n", "                    ", "gp", "=", "torch", ".", "mm", "(", "p", ".", "grad", ",", "p", ".", "data", ".", "t", "(", ")", ")", "\n", "p", ".", "grad", "=", "torch", ".", "mm", "(", "gp", "-", "gp", ".", "t", "(", ")", ",", "p", ".", "data", ")", "\n", "\n", "weights", "=", "p", ".", "data", "\n", "\n", "", "", "optim", ".", "step", "(", ")", "\n", "\n", "if", "i", "%", "25", "==", "0", ":", "\n", "                ", "WWt", "=", "torch", ".", "mm", "(", "weights", ",", "weights", ".", "t", "(", ")", ")", "\n", "WWt", "-=", "torch", ".", "eye", "(", "weights", ".", "shape", "[", "0", "]", ")", "\n", "if", "VERBOSE", ":", "\n", "                    ", "print", "(", "loss", ".", "item", "(", ")", ",", "end", "=", "'\\t'", ")", "\n", "print", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "WWt", ")", ")", ".", "item", "(", ")", ",", "end", "=", "'\\t'", ")", "\n", "print", "(", "torch", ".", "mean", "(", "WWt", "**", "2", ")", ".", "item", "(", ")", ",", "end", "=", "'\\t'", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_orthogonal_layer.OrthogonalTest.test_cuda": [[79, 90], ["test_net.to", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "test_orthogonal_layer.OrthogonalTest.assertTrue", "test_net.to", "test_net", "test_net", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "", "", "", "def", "test_cuda", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n", "test_net", ".", "to", "(", "'cuda'", ")", "\n", "x", "=", "torch", ".", "randn", "(", "self", ".", "batch_size", ",", "inp_size", ")", ".", "cuda", "(", ")", "\n", "\n", "y", "=", "test_net", "(", "x", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "x_re", "=", "test_net", "(", "y", ",", "rev", "=", "True", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "\n", "self", ".", "assertTrue", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", "<", "self", ".", "tol", ")", "\n", "test_net", ".", "to", "(", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__": [[36, 40], ["unittest.TestCase.__init__", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ")", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "self", ".", "tol", "=", "2e-3", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.test_inverse_fixed_components": [[41, 65], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "GaussianMixtureModel.normalize_weights", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "test_gaussian_mixture.GMMTest.assertTrue", "test_gaussian_mixture.GMMTest.assertTrue", "test_net", "test_net", "torch.max", "torch.max", "torch.max", "torch.max", "print", "print", "test_net", "test_net", "torch.max", "torch.max", "torch.max", "torch.max", "print", "print", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.max", "torch.max", "torch.max", "torch.max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.normalize_weights"], ["", "def", "test_inverse_fixed_components", "(", "self", ")", ":", "\n", "        ", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "x_size", ")", "\n", "w", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "w_size", ")", "\n", "w", "=", "GaussianMixtureModel", ".", "normalize_weights", "(", "w", ")", "\n", "mu", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "mu_size", ")", "\n", "U", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "U_size", ")", "\n", "i", "=", "torch", ".", "randint", "(", "0", ",", "n_components", ",", "(", "batch_size", ",", ")", ")", "\n", "\n", "z", "=", "test_net", "(", "x", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "i", "]", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "x_re", "=", "test_net", "(", "z", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "i", "]", ",", "rev", "=", "True", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "\n", "if", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ">", "self", ".", "tol", ":", "\n", "            ", "print", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ".", "item", "(", ")", ",", "end", "=", "'   '", ")", "\n", "print", "(", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ".", "item", "(", ")", ")", "\n", "", "self", ".", "assertTrue", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", "<", "self", ".", "tol", ")", "\n", "\n", "\n", "z", "=", "test_net", "(", "x", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "12345", "]", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "x_re", "=", "test_net", "(", "z", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "12345", "]", ",", "rev", "=", "True", ",", "jac", "=", "False", ")", "[", "0", "]", "\n", "\n", "if", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ">", "self", ".", "tol", ":", "\n", "            ", "print", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ".", "item", "(", ")", ",", "end", "=", "'   '", ")", "\n", "print", "(", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", ".", "item", "(", ")", ")", "\n", "", "self", ".", "assertTrue", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", ")", ")", "<", "self", ".", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.test_inverse_all_components": [[66, 85], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "GaussianMixtureModel.normalize_weights", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_net", "test_net", "range", "test_gaussian_mixture.GMMTest.assertTrue", "torch.max", "torch.max", "torch.max", "torch.max", "print", "print", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.normalize_weights"], ["", "def", "test_inverse_all_components", "(", "self", ")", ":", "\n", "# TODO: check what is going on here.", "\n", "# jac has shape n_components, not batchsize,", "\n", "# and it crashes the reversible graph net.", "\n", "\n", "        ", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "x_size", ")", "\n", "w", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "w_size", ")", "\n", "w", "=", "GaussianMixtureModel", ".", "normalize_weights", "(", "w", ")", "\n", "mu", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "mu_size", ")", "\n", "U", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "U_size", ")", "\n", "\n", "z", ",", "_", "=", "test_net", "(", "x", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "None", "]", ",", "jac", "=", "False", ")", "\n", "x_re", ",", "_", "=", "test_net", "(", "z", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "None", "]", ",", "rev", "=", "True", ",", "jac", "=", "False", ")", "\n", "\n", "for", "comp_idx", "in", "range", "(", "n_components", ")", ":", "\n", "            ", "if", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", "[", ":", ",", "comp_idx", ",", ":", "]", ")", ")", ">", "self", ".", "tol", ":", "\n", "                ", "print", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", "[", ":", ",", "comp_idx", ",", ":", "]", ")", ")", ".", "item", "(", ")", ",", "end", "=", "'   '", ")", "\n", "print", "(", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "x", "-", "x_re", "[", ":", ",", "comp_idx", ",", ":", "]", ")", ")", ".", "item", "(", ")", ")", "\n", "", "self", ".", "assertTrue", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "x", "-", "x_re", "[", ":", ",", "comp_idx", ",", ":", "]", ")", ")", "<", "self", ".", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.VLL-HD_FrEIA.tests.test_gaussian_mixture.GMMTest.test_jacobian_fixed_components": [[91, 105], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "GaussianMixtureModel.normalize_weights", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "test_net", "test_net.log_jacobian_numerical", "test_gaussian_mixture.GMMTest.assertTrue", "torch.allclose", "torch.allclose", "torch.allclose", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.VLL-HD_FrEIA.modules.gaussian_mixture.GaussianMixtureModel.normalize_weights", "home.repos.pwc.inspect_result.VLL-HD_FrEIA.framework.graph_inn.GraphINN.log_jacobian_numerical"], ["", "", "def", "test_jacobian_fixed_components", "(", "self", ")", ":", "\n", "        ", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "x_size", ")", "\n", "w", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "w_size", ")", "\n", "w", "=", "GaussianMixtureModel", ".", "normalize_weights", "(", "w", ")", "\n", "mu", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "mu_size", ")", "\n", "U", "=", "torch", ".", "randn", "(", "batch_size", ",", "*", "U_size", ")", "\n", "\n", "# Compute log det of Jacobian", "\n", "z", ",", "logdet", "=", "test_net", "(", "x", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "12345", "]", ")", "\n", "# Approximate log det of Jacobian numerically", "\n", "logdet_num", "=", "test_net", ".", "log_jacobian_numerical", "(", "x", ",", "c", "=", "[", "w", ",", "mu", ",", "U", ",", "12345", "]", ",", "h", "=", "1e-3", ")", "\n", "# Check that they are the same (within tolerance)", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "logdet", ",", "logdet_num", ",", "atol", "=", "1", ",", "rtol", "=", "0.03", ")", ",", "\n", "f'Numerical jacobian {logdet, logdet_num}'", ")", "\n", "\n"]]}