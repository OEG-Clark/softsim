{"home.repos.pwc.inspect_result.juntaoy_aracoref.None.get_char_vocab.get_char_vocab": [[8, 21], ["set", "sorted", "print", "list", "open", "open", "f.readlines", "f.write", "len", "json.loads", "sorted.update"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update"], ["def", "get_char_vocab", "(", "input_filenames", ",", "output_filename", ")", ":", "\n", "  ", "vocab", "=", "set", "(", ")", "\n", "for", "filename", "in", "input_filenames", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "      ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "        ", "for", "sentence", "in", "json", ".", "loads", "(", "line", ")", "[", "\"sentences\"", "]", ":", "\n", "          ", "for", "word", "in", "sentence", ":", "\n", "            ", "vocab", ".", "update", "(", "word", ")", "\n", "", "", "", "", "", "vocab", "=", "sorted", "(", "list", "(", "vocab", ")", ")", "\n", "with", "open", "(", "output_filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "for", "char", "in", "vocab", ":", "\n", "      ", "f", ".", "write", "(", "u\"{}\\n\"", ".", "format", "(", "char", ")", ".", "encode", "(", "\"utf8\"", ")", ")", "\n", "", "", "print", "(", "\"Wrote {} characters to {}\"", ".", "format", "(", "len", "(", "vocab", ")", ",", "output_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.get_char_vocab.get_char_vocab_language": [[22, 24], ["get_char_vocab.get_char_vocab"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.get_char_vocab.get_char_vocab"], ["", "def", "get_char_vocab_language", "(", "language", ")", ":", "\n", "  ", "get_char_vocab", "(", "[", "\"{}.{}.jsonlines\"", ".", "format", "(", "partition", ",", "language", ")", "for", "partition", "in", "(", "\"train\"", ",", "\"dev\"", ",", "\"test\"", ")", "]", ",", "\"char_vocab.{}.txt\"", ".", "format", "(", "language", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.get_doc_key": [[17, 19], ["int"], "function", ["None"], ["def", "get_doc_key", "(", "doc_id", ",", "part", ")", ":", "\n", "  ", "return", "\"{}_{}\"", ".", "format", "(", "doc_id", ",", "int", "(", "part", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.output_conll": [[20, 73], ["predictions.items", "input_file.readlines", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "enumerate", "collections.defaultdict.items", "collections.defaultdict.items", "line.split", "len", "output_file.write", "row[].startswith", "re.match", "output_file.write", "output_file.write", "output_file.write", "output_file.write", "word_map[].append", "start_map[].append", "end_map[].append", "sorted", "sorted", "conll.get_doc_key", "conll.get_doc_key", "len", "re.match.group", "re.match.group", "coref_list.append", "coref_list.append", "coref_list.append", "operator.itemgetter", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.get_doc_key", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.get_doc_key"], ["", "def", "output_conll", "(", "input_file", ",", "output_file", ",", "predictions", ")", ":", "\n", "  ", "prediction_map", "=", "{", "}", "\n", "for", "doc_key", ",", "clusters", "in", "predictions", ".", "items", "(", ")", ":", "\n", "    ", "start_map", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "end_map", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "word_map", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "cluster_id", ",", "mentions", "in", "enumerate", "(", "clusters", ")", ":", "\n", "      ", "for", "start", ",", "end", "in", "mentions", ":", "\n", "        ", "if", "start", "==", "end", ":", "\n", "          ", "word_map", "[", "start", "]", ".", "append", "(", "cluster_id", ")", "\n", "", "else", ":", "\n", "          ", "start_map", "[", "start", "]", ".", "append", "(", "(", "cluster_id", ",", "end", ")", ")", "\n", "end_map", "[", "end", "]", ".", "append", "(", "(", "cluster_id", ",", "start", ")", ")", "\n", "", "", "", "for", "k", ",", "v", "in", "start_map", ".", "items", "(", ")", ":", "\n", "      ", "start_map", "[", "k", "]", "=", "[", "cluster_id", "for", "cluster_id", ",", "end", "in", "sorted", "(", "v", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "]", "\n", "", "for", "k", ",", "v", "in", "end_map", ".", "items", "(", ")", ":", "\n", "      ", "end_map", "[", "k", "]", "=", "[", "cluster_id", "for", "cluster_id", ",", "start", "in", "sorted", "(", "v", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "]", "\n", "", "prediction_map", "[", "doc_key", "]", "=", "(", "start_map", ",", "end_map", ",", "word_map", ")", "\n", "\n", "", "word_index", "=", "0", "\n", "for", "line", "in", "input_file", ".", "readlines", "(", ")", ":", "\n", "    ", "row", "=", "line", ".", "split", "(", ")", "\n", "if", "len", "(", "row", ")", "==", "0", ":", "\n", "      ", "output_file", ".", "write", "(", "\"\\n\"", ")", "\n", "", "elif", "row", "[", "0", "]", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "      ", "begin_match", "=", "re", ".", "match", "(", "BEGIN_DOCUMENT_REGEX", ",", "line", ")", "\n", "if", "begin_match", ":", "\n", "        ", "doc_key", "=", "get_doc_key", "(", "begin_match", ".", "group", "(", "1", ")", ",", "begin_match", ".", "group", "(", "2", ")", ")", "\n", "start_map", ",", "end_map", ",", "word_map", "=", "prediction_map", "[", "doc_key", "]", "\n", "word_index", "=", "0", "\n", "", "output_file", ".", "write", "(", "line", ")", "\n", "output_file", ".", "write", "(", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "      ", "assert", "get_doc_key", "(", "row", "[", "0", "]", ",", "row", "[", "1", "]", ")", "==", "doc_key", "\n", "coref_list", "=", "[", "]", "\n", "if", "word_index", "in", "end_map", ":", "\n", "        ", "for", "cluster_id", "in", "end_map", "[", "word_index", "]", ":", "\n", "          ", "coref_list", ".", "append", "(", "\"{})\"", ".", "format", "(", "cluster_id", ")", ")", "\n", "", "", "if", "word_index", "in", "word_map", ":", "\n", "        ", "for", "cluster_id", "in", "word_map", "[", "word_index", "]", ":", "\n", "          ", "coref_list", ".", "append", "(", "\"({})\"", ".", "format", "(", "cluster_id", ")", ")", "\n", "", "", "if", "word_index", "in", "start_map", ":", "\n", "        ", "for", "cluster_id", "in", "start_map", "[", "word_index", "]", ":", "\n", "          ", "coref_list", ".", "append", "(", "\"({}\"", ".", "format", "(", "cluster_id", ")", ")", "\n", "\n", "", "", "if", "len", "(", "coref_list", ")", "==", "0", ":", "\n", "        ", "row", "[", "-", "1", "]", "=", "\"-\"", "\n", "", "else", ":", "\n", "        ", "row", "[", "-", "1", "]", "=", "\"|\"", ".", "join", "(", "coref_list", ")", "\n", "\n", "", "output_file", ".", "write", "(", "\"   \"", ".", "join", "(", "row", ")", ")", "\n", "output_file", ".", "write", "(", "\"\\n\"", ")", "\n", "word_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.official_conll_eval": [[74, 93], ["subprocess.Popen", "subprocess.Popen.communicate", "subprocess.Popen.wait", "stdout.decode.decode", "re.match", "float", "float", "float", "print", "print", "print", "re.match.group", "re.match.group", "re.match.group"], "function", ["None"], ["", "", "", "def", "official_conll_eval", "(", "gold_path", ",", "predicted_path", ",", "metric", ",", "official_stdout", "=", "False", ")", ":", "\n", "  ", "cmd", "=", "[", "\"conll-2012/scorer/v8.01/scorer.pl\"", ",", "metric", ",", "gold_path", ",", "predicted_path", ",", "\"none\"", "]", "\n", "process", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "stdout", ",", "stderr", "=", "process", ".", "communicate", "(", ")", "\n", "process", ".", "wait", "(", ")", "\n", "\n", "stdout", "=", "stdout", ".", "decode", "(", "\"utf-8\"", ")", "\n", "if", "stderr", "is", "not", "None", ":", "\n", "    ", "print", "(", "stderr", ")", "\n", "\n", "", "if", "official_stdout", ":", "\n", "    ", "print", "(", "\"Official result for {}\"", ".", "format", "(", "metric", ")", ")", "\n", "print", "(", "stdout", ")", "\n", "\n", "", "coref_results_match", "=", "re", ".", "match", "(", "COREF_RESULTS_REGEX", ",", "stdout", ")", "\n", "recall", "=", "float", "(", "coref_results_match", ".", "group", "(", "1", ")", ")", "\n", "precision", "=", "float", "(", "coref_results_match", ".", "group", "(", "2", ")", ")", "\n", "f1", "=", "float", "(", "coref_results_match", ".", "group", "(", "3", ")", ")", "\n", "return", "{", "\"r\"", ":", "recall", ",", "\"p\"", ":", "precision", ",", "\"f\"", ":", "f1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.evaluate_conll": [[94, 100], ["tempfile.NamedTemporaryFile", "print", "conll.official_conll_eval", "open", "conll.output_conll"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.official_conll_eval", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.output_conll"], ["", "def", "evaluate_conll", "(", "gold_path", ",", "predictions", ",", "official_stdout", "=", "False", ")", ":", "\n", "  ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ",", "mode", "=", "\"w\"", ")", "as", "prediction_file", ":", "\n", "    ", "with", "open", "(", "gold_path", ",", "\"r\"", ")", "as", "gold_file", ":", "\n", "      ", "output_conll", "(", "gold_file", ",", "prediction_file", ",", "predictions", ")", "\n", "", "print", "(", "\"Predicted conll file: {}\"", ".", "format", "(", "prediction_file", ".", "name", ")", ")", "\n", "", "return", "{", "m", ":", "official_conll_eval", "(", "gold_file", ".", "name", ",", "prediction_file", ".", "name", ",", "m", ",", "official_stdout", ")", "for", "m", "in", "(", "\"muc\"", ",", "\"bcub\"", ",", "\"ceafe\"", ")", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.preprocess_arabic.clean_text": [[8, 25], ["text.replace.replace", "text.replace.replace", "re.compile", "re.sub", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace"], "function", ["None"], ["def", "clean_text", "(", "text", ")", ":", "\n", "# remove tashkeel", "\n", "    ", "text", "=", "text", ".", "replace", "(", "'{'", ",", "'\u0627'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'}'", ",", "'\u0627'", ")", "\n", "\n", "#text = text.replace('-','')", "\n", "p_tashkeel", "=", "re", ".", "compile", "(", "r'[\\u0617-\\u061A\\u064B-\\u0652]'", ")", "\n", "text", "=", "re", ".", "sub", "(", "p_tashkeel", ",", "\"\"", ",", "text", ")", "\n", "\n", "#Other typos in the conll files", "\n", "text", "=", "text", ".", "replace", "(", "'\u0647`\u0630\u0627'", ",", "'\u0647\u0630\u0627'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u0647`\u0630\u0647'", ",", "'\u0647\u0630\u0647'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u0647`\u0630\u064a\u0646'", ",", "'\u0647\u0630\u064a\u0646'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u0627\u0644\u0644`\u0647'", ",", "'\u0627\u0644\u0644\u0647'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u0630`\u0644\u0643'", ",", "'\u0630\u0644\u0643'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u0625\u0644`\u0647'", ",", "'\u0625\u0644\u0647'", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.CorefEvaluator.__init__": [[16, 18], ["metrics.Evaluator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "evaluators", "=", "[", "Evaluator", "(", "m", ")", "for", "m", "in", "(", "muc", ",", "b_cubed", ",", "ceafe", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.CorefEvaluator.update": [[19, 22], ["e.update"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update"], ["", "def", "update", "(", "self", ",", "predicted", ",", "gold", ",", "mention_to_predicted", ",", "mention_to_gold", ")", ":", "\n", "        ", "for", "e", "in", "self", ".", "evaluators", ":", "\n", "            ", "e", ".", "update", "(", "predicted", ",", "gold", ",", "mention_to_predicted", ",", "mention_to_gold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.CorefEvaluator.get_f1": [[23, 25], ["sum", "len", "e.get_f1"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_f1"], ["", "", "def", "get_f1", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "e", ".", "get_f1", "(", ")", "for", "e", "in", "self", ".", "evaluators", ")", "/", "len", "(", "self", ".", "evaluators", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.CorefEvaluator.get_recall": [[26, 28], ["sum", "len", "e.get_recall"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_recall"], ["", "def", "get_recall", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "e", ".", "get_recall", "(", ")", "for", "e", "in", "self", ".", "evaluators", ")", "/", "len", "(", "self", ".", "evaluators", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.CorefEvaluator.get_precision": [[29, 31], ["sum", "len", "e.get_precision"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_precision"], ["", "def", "get_precision", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "e", ".", "get_precision", "(", ")", "for", "e", "in", "self", ".", "evaluators", ")", "/", "len", "(", "self", ".", "evaluators", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.CorefEvaluator.get_prf": [[32, 34], ["metrics.CorefEvaluator.get_precision", "metrics.CorefEvaluator.get_recall", "metrics.CorefEvaluator.get_f1"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_precision", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_recall", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_f1"], ["", "def", "get_prf", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_precision", "(", ")", ",", "self", ".", "get_recall", "(", ")", ",", "self", ".", "get_f1", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.__init__": [[36, 43], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "metric", ",", "beta", "=", "1", ")", ":", "\n", "        ", "self", ".", "p_num", "=", "0", "\n", "self", ".", "p_den", "=", "0", "\n", "self", ".", "r_num", "=", "0", "\n", "self", ".", "r_den", "=", "0", "\n", "self", ".", "metric", "=", "metric", "\n", "self", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.update": [[44, 54], ["metrics.Evaluator.metric", "metrics.Evaluator.metric", "metrics.Evaluator.metric"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "predicted", ",", "gold", ",", "mention_to_predicted", ",", "mention_to_gold", ")", ":", "\n", "        ", "if", "self", ".", "metric", "==", "ceafe", ":", "\n", "            ", "pn", ",", "pd", ",", "rn", ",", "rd", "=", "self", ".", "metric", "(", "predicted", ",", "gold", ")", "\n", "", "else", ":", "\n", "            ", "pn", ",", "pd", "=", "self", ".", "metric", "(", "predicted", ",", "mention_to_gold", ")", "\n", "rn", ",", "rd", "=", "self", ".", "metric", "(", "gold", ",", "mention_to_predicted", ")", "\n", "", "self", ".", "p_num", "+=", "pn", "\n", "self", ".", "p_den", "+=", "pd", "\n", "self", ".", "r_num", "+=", "rn", "\n", "self", ".", "r_den", "+=", "rd", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_f1": [[55, 57], ["metrics.f1"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.f1"], ["", "def", "get_f1", "(", "self", ")", ":", "\n", "        ", "return", "f1", "(", "self", ".", "p_num", ",", "self", ".", "p_den", ",", "self", ".", "r_num", ",", "self", ".", "r_den", ",", "beta", "=", "self", ".", "beta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_recall": [[58, 60], ["float"], "methods", ["None"], ["", "def", "get_recall", "(", "self", ")", ":", "\n", "        ", "return", "0", "if", "self", ".", "r_num", "==", "0", "else", "self", ".", "r_num", "/", "float", "(", "self", ".", "r_den", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_precision": [[61, 63], ["float"], "methods", ["None"], ["", "def", "get_precision", "(", "self", ")", ":", "\n", "        ", "return", "0", "if", "self", ".", "p_num", "==", "0", "else", "self", ".", "p_num", "/", "float", "(", "self", ".", "p_den", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_prf": [[64, 66], ["metrics.Evaluator.get_precision", "metrics.Evaluator.get_recall", "metrics.Evaluator.get_f1"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_precision", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_recall", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_f1"], ["", "def", "get_prf", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_precision", "(", ")", ",", "self", ".", "get_recall", "(", ")", ",", "self", ".", "get_f1", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_counts": [[67, 69], ["None"], "methods", ["None"], ["", "def", "get_counts", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "p_num", ",", "self", ".", "p_den", ",", "self", ".", "r_num", ",", "self", ".", "r_den", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.f1": [[10, 14], ["float", "float"], "function", ["None"], ["def", "f1", "(", "p_num", ",", "p_den", ",", "r_num", ",", "r_den", ",", "beta", "=", "1", ")", ":", "\n", "    ", "p", "=", "0", "if", "p_den", "==", "0", "else", "p_num", "/", "float", "(", "p_den", ")", "\n", "r", "=", "0", "if", "r_den", "==", "0", "else", "r_num", "/", "float", "(", "r_den", ")", "\n", "return", "0", "if", "p", "+", "r", "==", "0", "else", "(", "1", "+", "beta", "*", "beta", ")", "*", "p", "*", "r", "/", "(", "beta", "*", "beta", "*", "p", "+", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.evaluate_documents": [[71, 76], ["metrics.Evaluator", "metrics.Evaluator.update", "metrics.Evaluator.get_precision", "metrics.Evaluator.get_recall", "metrics.Evaluator.get_f1"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_precision", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_recall", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_f1"], ["", "", "def", "evaluate_documents", "(", "documents", ",", "metric", ",", "beta", "=", "1", ")", ":", "\n", "    ", "evaluator", "=", "Evaluator", "(", "metric", ",", "beta", "=", "beta", ")", "\n", "for", "document", "in", "documents", ":", "\n", "        ", "evaluator", ".", "update", "(", "document", ")", "\n", "", "return", "evaluator", ".", "get_precision", "(", ")", ",", "evaluator", ".", "get_recall", "(", ")", ",", "evaluator", ".", "get_f1", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.b_cubed": [[78, 98], ["collections.Counter", "collections.Counter.items", "len", "len", "float", "len", "len", "tuple"], "function", ["None"], ["", "def", "b_cubed", "(", "clusters", ",", "mention_to_gold", ")", ":", "\n", "    ", "num", ",", "dem", "=", "0", ",", "0", "\n", "\n", "for", "c", "in", "clusters", ":", "\n", "        ", "if", "len", "(", "c", ")", "==", "1", ":", "\n", "            ", "continue", "\n", "\n", "", "gold_counts", "=", "Counter", "(", ")", "\n", "correct", "=", "0", "\n", "for", "m", "in", "c", ":", "\n", "            ", "if", "m", "in", "mention_to_gold", ":", "\n", "                ", "gold_counts", "[", "tuple", "(", "mention_to_gold", "[", "m", "]", ")", "]", "+=", "1", "\n", "", "", "for", "c2", ",", "count", "in", "gold_counts", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "c2", ")", "!=", "1", ":", "\n", "                ", "correct", "+=", "count", "*", "count", "\n", "\n", "", "", "num", "+=", "correct", "/", "float", "(", "len", "(", "c", ")", ")", "\n", "dem", "+=", "len", "(", "c", ")", "\n", "\n", "", "return", "num", ",", "dem", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.muc": [[100, 113], ["len", "set", "len", "len", "set.add"], "function", ["None"], ["", "def", "muc", "(", "clusters", ",", "mention_to_gold", ")", ":", "\n", "    ", "tp", ",", "p", "=", "0", ",", "0", "\n", "for", "c", "in", "clusters", ":", "\n", "        ", "p", "+=", "len", "(", "c", ")", "-", "1", "\n", "tp", "+=", "len", "(", "c", ")", "\n", "linked", "=", "set", "(", ")", "\n", "for", "m", "in", "c", ":", "\n", "            ", "if", "m", "in", "mention_to_gold", ":", "\n", "                ", "linked", ".", "add", "(", "mention_to_gold", "[", "m", "]", ")", "\n", "", "else", ":", "\n", "                ", "tp", "-=", "1", "\n", "", "", "tp", "-=", "len", "(", "linked", ")", "\n", "", "return", "tp", ",", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.phi4": [[115, 117], ["float", "len", "len", "len"], "function", ["None"], ["", "def", "phi4", "(", "c1", ",", "c2", ")", ":", "\n", "    ", "return", "2", "*", "len", "(", "[", "m", "for", "m", "in", "c1", "if", "m", "in", "c2", "]", ")", "/", "float", "(", "len", "(", "c1", ")", "+", "len", "(", "c2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.ceafe": [[119, 128], ["numpy.zeros", "range", "sklearn.utils.linear_assignment_.linear_assignment", "sum", "len", "range", "len", "len", "len", "len", "len", "metrics.phi4", "len"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.phi4"], ["", "def", "ceafe", "(", "clusters", ",", "gold_clusters", ")", ":", "\n", "    ", "clusters", "=", "[", "c", "for", "c", "in", "clusters", "if", "len", "(", "c", ")", "!=", "1", "]", "\n", "scores", "=", "np", ".", "zeros", "(", "(", "len", "(", "gold_clusters", ")", ",", "len", "(", "clusters", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "gold_clusters", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "clusters", ")", ")", ":", "\n", "            ", "scores", "[", "i", ",", "j", "]", "=", "phi4", "(", "gold_clusters", "[", "i", "]", ",", "clusters", "[", "j", "]", ")", "\n", "", "", "matching", "=", "linear_assignment", "(", "-", "scores", ")", "\n", "similarity", "=", "sum", "(", "scores", "[", "matching", "[", ":", ",", "0", "]", ",", "matching", "[", ":", ",", "1", "]", "]", ")", "\n", "return", "similarity", ",", "len", "(", "clusters", ")", ",", "similarity", ",", "len", "(", "gold_clusters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.lea": [[130, 149], ["enumerate", "len", "len", "float", "len", "len", "len"], "function", ["None"], ["", "def", "lea", "(", "clusters", ",", "mention_to_gold", ")", ":", "\n", "    ", "num", ",", "dem", "=", "0", ",", "0", "\n", "\n", "for", "c", "in", "clusters", ":", "\n", "        ", "if", "len", "(", "c", ")", "==", "1", ":", "\n", "            ", "continue", "\n", "\n", "", "common_links", "=", "0", "\n", "all_links", "=", "len", "(", "c", ")", "*", "(", "len", "(", "c", ")", "-", "1", ")", "/", "2.0", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "c", ")", ":", "\n", "            ", "if", "m", "in", "mention_to_gold", ":", "\n", "                ", "for", "m2", "in", "c", "[", "i", "+", "1", ":", "]", ":", "\n", "                    ", "if", "m2", "in", "mention_to_gold", "and", "mention_to_gold", "[", "m", "]", "==", "mention_to_gold", "[", "m2", "]", ":", "\n", "                        ", "common_links", "+=", "1", "\n", "\n", "", "", "", "", "num", "+=", "len", "(", "c", ")", "*", "common_links", "/", "float", "(", "all_links", ")", "\n", "dem", "+=", "len", "(", "c", ")", "\n", "\n", "", "return", "num", ",", "dem", "\n", "", ""]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.__init__": [[22, 76], ["util.EmbeddingDictionary", "util.EmbeddingDictionary", "util.load_char_dict", "h5py.File", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "input_props.append", "zip", "tensorflow.PaddingFIFOQueue", "tensorflow.PaddingFIFOQueue.enqueue", "tensorflow.PaddingFIFOQueue.dequeue", "coref_model.CorefModel.get_predictions_and_loss", "tensorflow.Variable", "tensorflow.assign", "tensorflow.train.exponential_decay", "tensorflow.trainable_variables", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "optimizer.apply_gradients", "tensorflow.placeholder", "zip", "enumerate"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.load_char_dict", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_predictions_and_loss"], ["  ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "self", ".", "config", "=", "config", "\n", "self", ".", "context_embeddings", "=", "util", ".", "EmbeddingDictionary", "(", "config", "[", "\"context_embeddings\"", "]", ")", "\n", "self", ".", "head_embeddings", "=", "util", ".", "EmbeddingDictionary", "(", "config", "[", "\"head_embeddings\"", "]", ",", "maybe_cache", "=", "self", ".", "context_embeddings", ")", "\n", "self", ".", "char_embedding_size", "=", "config", "[", "\"char_embedding_size\"", "]", "\n", "self", ".", "char_dict", "=", "util", ".", "load_char_dict", "(", "config", "[", "\"char_vocab_path\"", "]", ")", "\n", "self", ".", "max_span_width", "=", "config", "[", "\"max_span_width\"", "]", "\n", "self", ".", "genres", "=", "{", "g", ":", "i", "for", "i", ",", "g", "in", "enumerate", "(", "config", "[", "\"genres\"", "]", ")", "}", "\n", "self", ".", "lm_file", "=", "h5py", ".", "File", "(", "self", ".", "config", "[", "\"lm_path\"", "]", ",", "\"r\"", ")", "\n", "\n", "self", ".", "use_e2e_annealing", "=", "self", ".", "config", "[", "'use_e2e_annealing'", "]", "\n", "self", ".", "use_joint_coref", "=", "self", ".", "config", "[", "\"use_joint_coref\"", "]", "\n", "\n", "self", ".", "lm_layers", "=", "self", ".", "config", "[", "\"lm_layers\"", "]", "\n", "self", ".", "lm_size", "=", "self", ".", "config", "[", "\"lm_size\"", "]", "\n", "self", ".", "eval_data", "=", "None", "# Load eval data lazily.", "\n", "\n", "input_props", "=", "[", "]", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "string", ",", "[", "None", ",", "None", "]", ")", ")", "# Tokens.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "self", ".", "context_embeddings", ".", "size", "]", ")", ")", "# Context embeddings.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "self", ".", "head_embeddings", ".", "size", "]", ")", ")", "# Head embeddings.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "self", ".", "lm_size", ",", "self", ".", "lm_layers", "]", ")", ")", "# LM embeddings.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", ",", "None", ",", "None", "]", ")", ")", "# Character indices.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Text lengths.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Speaker IDs.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "]", ")", ")", "# Genre.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "bool", ",", "[", "]", ")", ")", "# Is training.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Gold starts.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Gold ends.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Cluster ids.", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Pred starts", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "int32", ",", "[", "None", "]", ")", ")", "# Pred ends", "\n", "input_props", ".", "append", "(", "(", "tf", ".", "bool", ",", "[", "]", ")", ")", "#use_pred_mention", "\n", "\n", "self", ".", "queue_input_tensors", "=", "[", "tf", ".", "placeholder", "(", "dtype", ",", "shape", ")", "for", "dtype", ",", "shape", "in", "input_props", "]", "\n", "dtypes", ",", "shapes", "=", "zip", "(", "*", "input_props", ")", "\n", "queue", "=", "tf", ".", "PaddingFIFOQueue", "(", "capacity", "=", "10", ",", "dtypes", "=", "dtypes", ",", "shapes", "=", "shapes", ")", "\n", "self", ".", "enqueue_op", "=", "queue", ".", "enqueue", "(", "self", ".", "queue_input_tensors", ")", "\n", "self", ".", "input_tensors", "=", "queue", ".", "dequeue", "(", ")", "\n", "\n", "self", ".", "predictions", ",", "self", ".", "loss", "=", "self", ".", "get_predictions_and_loss", "(", "*", "self", ".", "input_tensors", ")", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "\"global_step\"", ",", "trainable", "=", "False", ")", "\n", "self", ".", "reset_global_step", "=", "tf", ".", "assign", "(", "self", ".", "global_step", ",", "0", ")", "\n", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "config", "[", "\"learning_rate\"", "]", ",", "self", ".", "global_step", ",", "\n", "self", ".", "config", "[", "\"decay_frequency\"", "]", ",", "self", ".", "config", "[", "\"decay_rate\"", "]", ",", "staircase", "=", "True", ")", "\n", "trainable_params", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "trainable_params", ")", "\n", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "self", ".", "config", "[", "\"max_gradient_norm\"", "]", ")", "\n", "optimizers", "=", "{", "\n", "\"adam\"", ":", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "\"sgd\"", ":", "tf", ".", "train", ".", "GradientDescentOptimizer", "\n", "}", "\n", "optimizer", "=", "optimizers", "[", "self", ".", "config", "[", "\"optimizer\"", "]", "]", "(", "learning_rate", ")", "\n", "self", ".", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "zip", "(", "gradients", ",", "trainable_params", ")", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.start_enqueue_thread": [[77, 95], ["threading.Thread", "threading.Thread.start", "open", "json.loads", "random.shuffle", "f.readlines", "coref_model.CorefModel.tensorize_example", "dict", "session.run", "zip", "random.random"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.tensorize_example"], ["", "def", "start_enqueue_thread", "(", "self", ",", "session", ")", ":", "\n", "    ", "with", "open", "(", "self", ".", "config", "[", "\"train_path\"", "]", ")", "as", "f", ":", "\n", "      ", "train_examples", "=", "[", "json", ".", "loads", "(", "jsonline", ")", "for", "jsonline", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "def", "_enqueue_loop", "(", ")", ":", "\n", "      ", "max_step", "=", "self", ".", "config", "[", "\"max_step\"", "]", "\n", "curr_step", "=", "0", "\n", "while", "True", ":", "\n", "        ", "pred_ratio", "=", "0.0", "if", "not", "self", ".", "use_e2e_annealing", "else", "curr_step", "*", "1.0", "/", "max_step", "\n", "random", ".", "shuffle", "(", "train_examples", ")", "\n", "for", "example", "in", "train_examples", ":", "\n", "          ", "use_pred_mentions", "=", "True", "if", "not", "self", ".", "use_joint_coref", "else", "random", ".", "random", "(", ")", "<=", "pred_ratio", "\n", "tensorized_example", "=", "self", ".", "tensorize_example", "(", "example", ",", "is_training", "=", "True", ",", "use_pred_mentions", "=", "use_pred_mentions", ")", "\n", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "queue_input_tensors", ",", "tensorized_example", ")", ")", "\n", "session", ".", "run", "(", "self", ".", "enqueue_op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "curr_step", "+=", "1", "\n", "", "", "", "enqueue_thread", "=", "threading", ".", "Thread", "(", "target", "=", "_enqueue_loop", ")", "\n", "enqueue_thread", ".", "daemon", "=", "True", "\n", "enqueue_thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.restore": [[96, 104], ["tensorflow.train.Saver", "os.path.join", "print", "session.run", "tensorflow.train.Saver.restore", "tensorflow.global_variables_initializer", "tensorflow.global_variables"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.restore"], ["", "def", "restore", "(", "self", ",", "session", ")", ":", "\n", "# Don't try to restore unused variables from the TF-Hub ELMo module.", "\n", "    ", "vars_to_restore", "=", "[", "v", "for", "v", "in", "tf", ".", "global_variables", "(", ")", "if", "\"module/\"", "not", "in", "v", ".", "name", "]", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "vars_to_restore", ")", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "config", "[", "\"log_dir\"", "]", ",", "\"model.max.ckpt\"", ")", "\n", "print", "(", "\"Restoring from {}\"", ".", "format", "(", "checkpoint_path", ")", ")", "\n", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "saver", ".", "restore", "(", "session", ",", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.load_lm_embeddings": [[105, 118], ["doc_key.replace", "len", "numpy.zeros", "enumerate", "numpy.zeros", "list", "group.keys", "range", "max", "str"], "methods", ["None"], ["", "def", "load_lm_embeddings", "(", "self", ",", "doc_key", ")", ":", "\n", "    ", "if", "self", ".", "lm_file", "is", "None", ":", "\n", "      ", "return", "np", ".", "zeros", "(", "[", "0", ",", "0", ",", "self", ".", "lm_size", ",", "self", ".", "lm_layers", "]", ")", "\n", "", "file_key", "=", "doc_key", ".", "replace", "(", "\"/\"", ",", "\":\"", ")", "\n", "if", "not", "file_key", "in", "self", ".", "lm_file", "and", "file_key", "[", ":", "-", "2", "]", "in", "self", ".", "lm_file", ":", "\n", "      ", "file_key", "=", "file_key", "[", ":", "-", "2", "]", "\n", "", "group", "=", "self", ".", "lm_file", "[", "file_key", "]", "\n", "num_sentences", "=", "len", "(", "list", "(", "group", ".", "keys", "(", ")", ")", ")", "\n", "sentences", "=", "[", "group", "[", "str", "(", "i", ")", "]", "[", "...", "]", "for", "i", "in", "range", "(", "num_sentences", ")", "]", "\n", "lm_emb", "=", "np", ".", "zeros", "(", "[", "num_sentences", ",", "max", "(", "s", ".", "shape", "[", "0", "]", "for", "s", "in", "sentences", ")", ",", "self", ".", "lm_size", ",", "self", ".", "lm_layers", "]", ")", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "sentences", ")", ":", "\n", "      ", "lm_emb", "[", "i", ",", ":", "s", ".", "shape", "[", "0", "]", ",", ":", ",", ":", "]", "=", "s", "\n", "", "return", "lm_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.tensorize_mentions": [[119, 125], ["len", "zip", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "tensorize_mentions", "(", "self", ",", "mentions", ")", ":", "\n", "    ", "if", "len", "(", "mentions", ")", ">", "0", ":", "\n", "      ", "starts", ",", "ends", "=", "zip", "(", "*", "mentions", ")", "\n", "", "else", ":", "\n", "      ", "starts", ",", "ends", "=", "[", "]", ",", "[", "]", "\n", "", "return", "np", ".", "array", "(", "starts", ")", ",", "np", ".", "array", "(", "ends", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.tensorize_example": [[127, 178], ["sorted", "numpy.zeros", "enumerate", "sum", "util.flatten", "max", "max", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.array", "numpy.array", "coref_model.CorefModel.tensorize_mentions", "coref_model.CorefModel.load_lm_embeddings", "len", "len", "max", "max", "enumerate", "zip", "coref_model.CorefModel.truncate_example", "tuple", "enumerate", "len", "len", "len", "len", "len", "len", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "util.flatten", "max", "set", "len", "len", "tuple"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.flatten", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.tensorize_mentions", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.load_lm_embeddings", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.truncate_example", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.flatten"], ["", "def", "tensorize_example", "(", "self", ",", "example", ",", "is_training", ",", "use_pred_mentions", ")", ":", "\n", "    ", "clusters", "=", "example", "[", "\"clusters\"", "]", "\n", "\n", "gold_mentions", "=", "sorted", "(", "tuple", "(", "m", ")", "for", "m", "in", "util", ".", "flatten", "(", "clusters", ")", ")", "\n", "gold_mention_map", "=", "{", "m", ":", "i", "for", "i", ",", "m", "in", "enumerate", "(", "gold_mentions", ")", "}", "\n", "cluster_ids", "=", "np", ".", "zeros", "(", "len", "(", "gold_mentions", ")", ")", "\n", "for", "cluster_id", ",", "cluster", "in", "enumerate", "(", "clusters", ")", ":", "\n", "      ", "for", "mention", "in", "cluster", ":", "\n", "        ", "cluster_ids", "[", "gold_mention_map", "[", "tuple", "(", "mention", ")", "]", "]", "=", "cluster_id", "+", "1", "\n", "\n", "", "", "sentences", "=", "example", "[", "\"sentences\"", "]", "\n", "num_words", "=", "sum", "(", "len", "(", "s", ")", "for", "s", "in", "sentences", ")", "\n", "speakers", "=", "util", ".", "flatten", "(", "example", "[", "\"speakers\"", "]", ")", "\n", "\n", "assert", "num_words", "==", "len", "(", "speakers", ")", "\n", "\n", "max_sentence_length", "=", "max", "(", "len", "(", "s", ")", "for", "s", "in", "sentences", ")", "\n", "max_word_length", "=", "max", "(", "max", "(", "max", "(", "len", "(", "w", ")", "for", "w", "in", "s", ")", "for", "s", "in", "sentences", ")", ",", "max", "(", "self", ".", "config", "[", "\"filter_widths\"", "]", ")", ")", "\n", "text_len", "=", "np", ".", "array", "(", "[", "len", "(", "s", ")", "for", "s", "in", "sentences", "]", ")", "\n", "tokens", "=", "[", "[", "\"\"", "]", "*", "max_sentence_length", "for", "_", "in", "sentences", "]", "\n", "context_word_emb", "=", "np", ".", "zeros", "(", "[", "len", "(", "sentences", ")", ",", "max_sentence_length", ",", "self", ".", "context_embeddings", ".", "size", "]", ")", "\n", "head_word_emb", "=", "np", ".", "zeros", "(", "[", "len", "(", "sentences", ")", ",", "max_sentence_length", ",", "self", ".", "head_embeddings", ".", "size", "]", ")", "\n", "char_index", "=", "np", ".", "zeros", "(", "[", "len", "(", "sentences", ")", ",", "max_sentence_length", ",", "max_word_length", "]", ")", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "      ", "for", "j", ",", "word", "in", "enumerate", "(", "sentence", ")", ":", "\n", "        ", "tokens", "[", "i", "]", "[", "j", "]", "=", "word", "\n", "context_word_emb", "[", "i", ",", "j", "]", "=", "self", ".", "context_embeddings", "[", "word", "]", "\n", "head_word_emb", "[", "i", ",", "j", "]", "=", "self", ".", "head_embeddings", "[", "word", "]", "\n", "char_index", "[", "i", ",", "j", ",", ":", "len", "(", "word", ")", "]", "=", "[", "self", ".", "char_dict", "[", "c", "]", "for", "c", "in", "word", "]", "\n", "", "", "tokens", "=", "np", ".", "array", "(", "tokens", ")", "\n", "\n", "speaker_dict", "=", "{", "s", ":", "i", "for", "i", ",", "s", "in", "enumerate", "(", "set", "(", "speakers", ")", ")", "}", "\n", "speaker_ids", "=", "np", ".", "array", "(", "[", "speaker_dict", "[", "s", "]", "for", "s", "in", "speakers", "]", ")", "\n", "\n", "doc_key", "=", "example", "[", "\"doc_key\"", "]", "\n", "genre", "=", "self", ".", "genres", "[", "doc_key", "[", ":", "2", "]", "]", "\n", "\n", "gold_starts", ",", "gold_ends", "=", "self", ".", "tensorize_mentions", "(", "gold_mentions", ")", "\n", "if", "\"pred_mentions\"", "in", "example", ":", "\n", "      ", "pred_starts", ",", "pred_ends", "=", "zip", "(", "*", "example", "[", "\"pred_mentions\"", "]", ")", "\n", "pred_starts", ",", "pred_ends", "=", "np", ".", "array", "(", "pred_starts", ")", ",", "np", ".", "array", "(", "pred_ends", ")", "\n", "", "else", ":", "\n", "      ", "pred_starts", ",", "pred_ends", "=", "np", ".", "array", "(", "[", "]", ")", ",", "np", ".", "array", "(", "[", "]", ")", "\n", "", "lm_emb", "=", "self", ".", "load_lm_embeddings", "(", "doc_key", ")", "\n", "\n", "example_tensors", "=", "(", "tokens", ",", "context_word_emb", ",", "head_word_emb", ",", "lm_emb", ",", "char_index", ",", "text_len", ",", "speaker_ids", ",", "genre", ",", "is_training", ",", "gold_starts", ",", "gold_ends", ",", "cluster_ids", ",", "pred_starts", ",", "pred_ends", ",", "use_pred_mentions", ")", "\n", "\n", "if", "is_training", "and", "len", "(", "sentences", ")", ">", "self", ".", "config", "[", "\"max_training_sentences\"", "]", ":", "\n", "      ", "return", "self", ".", "truncate_example", "(", "*", "example_tensors", ")", "\n", "", "else", ":", "\n", "      ", "return", "example_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.truncate_example": [[179, 204], ["random.randint", "text_len[].sum", "text_len[].sum", "numpy.logical_and", "numpy.logical_and"], "methods", ["None"], ["", "", "def", "truncate_example", "(", "self", ",", "tokens", ",", "context_word_emb", ",", "head_word_emb", ",", "lm_emb", ",", "char_index", ",", "text_len", ",", "speaker_ids", ",", "genre", ",", "is_training", ",", "gold_starts", ",", "gold_ends", ",", "cluster_ids", ",", "pred_starts", ",", "pred_ends", ",", "use_pred_mentions", ")", ":", "\n", "    ", "max_training_sentences", "=", "self", ".", "config", "[", "\"max_training_sentences\"", "]", "\n", "num_sentences", "=", "context_word_emb", ".", "shape", "[", "0", "]", "\n", "assert", "num_sentences", ">", "max_training_sentences", "\n", "\n", "sentence_offset", "=", "random", ".", "randint", "(", "0", ",", "num_sentences", "-", "max_training_sentences", ")", "\n", "word_offset", "=", "text_len", "[", ":", "sentence_offset", "]", ".", "sum", "(", ")", "\n", "num_words", "=", "text_len", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", "]", ".", "sum", "(", ")", "\n", "tokens", "=", "tokens", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", ",", ":", "]", "\n", "context_word_emb", "=", "context_word_emb", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", ",", ":", ",", ":", "]", "\n", "head_word_emb", "=", "head_word_emb", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", ",", ":", ",", ":", "]", "\n", "lm_emb", "=", "lm_emb", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", ",", ":", ",", ":", ",", ":", "]", "\n", "char_index", "=", "char_index", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", ",", ":", ",", ":", "]", "\n", "text_len", "=", "text_len", "[", "sentence_offset", ":", "sentence_offset", "+", "max_training_sentences", "]", "\n", "\n", "speaker_ids", "=", "speaker_ids", "[", "word_offset", ":", "word_offset", "+", "num_words", "]", "\n", "gold_spans", "=", "np", ".", "logical_and", "(", "gold_ends", ">=", "word_offset", ",", "gold_starts", "<", "word_offset", "+", "num_words", ")", "\n", "gold_starts", "=", "gold_starts", "[", "gold_spans", "]", "-", "word_offset", "\n", "gold_ends", "=", "gold_ends", "[", "gold_spans", "]", "-", "word_offset", "\n", "cluster_ids", "=", "cluster_ids", "[", "gold_spans", "]", "\n", "pred_spans", "=", "np", ".", "logical_and", "(", "pred_ends", ">=", "word_offset", ",", "pred_starts", "<", "word_offset", "+", "num_words", ")", "\n", "pred_starts", "=", "pred_starts", "[", "pred_spans", "]", "-", "word_offset", "\n", "pred_ends", "=", "pred_ends", "[", "pred_spans", "]", "-", "word_offset", "\n", "\n", "return", "tokens", ",", "context_word_emb", ",", "head_word_emb", ",", "lm_emb", ",", "char_index", ",", "text_len", ",", "speaker_ids", ",", "genre", ",", "is_training", ",", "gold_starts", ",", "gold_ends", ",", "cluster_ids", ",", "pred_starts", ",", "pred_ends", ",", "use_pred_mentions", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_pred_mention_scores": [[206, 215], ["tensorflow.equal", "tensorflow.equal", "tensorflow.logical_and", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float"], "methods", ["None"], ["", "def", "get_pred_mention_scores", "(", "self", ",", "candidate_starts", ",", "candidate_ends", ",", "pred_mention_starts", ",", "pred_mention_ends", ",", "pred_mention_scores", ")", ":", "\n", "    ", "same_start", "=", "tf", ".", "equal", "(", "tf", ".", "expand_dims", "(", "pred_mention_starts", ",", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "candidate_starts", ",", "0", ")", ")", "# [num_labeled, num_candidates]", "\n", "same_end", "=", "tf", ".", "equal", "(", "tf", ".", "expand_dims", "(", "pred_mention_ends", ",", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "candidate_ends", ",", "0", ")", ")", "# [num_labeled, num_candidates]", "\n", "same_span", "=", "tf", ".", "logical_and", "(", "same_start", ",", "same_end", ")", "# [num_labeled, num_candidates]", "\n", "candidate_scores", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "pred_mention_scores", ",", "0", ")", ",", "tf", ".", "to_float", "(", "same_span", ")", ")", "# [1, num_candidates]", "\n", "candidate_scores", "=", "tf", ".", "squeeze", "(", "candidate_scores", ",", "0", ")", "# [num_candidates]", "\n", "return", "candidate_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_candidate_labels": [[216, 223], ["tensorflow.equal", "tensorflow.equal", "tensorflow.logical_and", "tensorflow.matmul", "tensorflow.squeeze", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_int32"], "methods", ["None"], ["", "def", "get_candidate_labels", "(", "self", ",", "candidate_starts", ",", "candidate_ends", ",", "labeled_starts", ",", "labeled_ends", ",", "labels", ")", ":", "\n", "    ", "same_start", "=", "tf", ".", "equal", "(", "tf", ".", "expand_dims", "(", "labeled_starts", ",", "1", ")", ",", "tf", ".", "expand_dims", "(", "candidate_starts", ",", "0", ")", ")", "# [num_labeled, num_candidates]", "\n", "same_end", "=", "tf", ".", "equal", "(", "tf", ".", "expand_dims", "(", "labeled_ends", ",", "1", ")", ",", "tf", ".", "expand_dims", "(", "candidate_ends", ",", "0", ")", ")", "# [num_labeled, num_candidates]", "\n", "same_span", "=", "tf", ".", "logical_and", "(", "same_start", ",", "same_end", ")", "# [num_labeled, num_candidates]", "\n", "candidate_labels", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", ",", "tf", ".", "to_int32", "(", "same_span", ")", ")", "# [1, num_candidates]", "\n", "candidate_labels", "=", "tf", ".", "squeeze", "(", "candidate_labels", ",", "0", ")", "# [num_candidates]", "\n", "return", "candidate_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_dropout": [[224, 226], ["tensorflow.to_float"], "methods", ["None"], ["", "def", "get_dropout", "(", "self", ",", "dropout_rate", ",", "is_training", ")", ":", "\n", "    ", "return", "1", "-", "(", "tf", ".", "to_float", "(", "is_training", ")", "*", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.coarse_to_fine_pruning": [[227, 242], ["util.shape", "tensorflow.range", "tensorflow.log", "coref_model.CorefModel.get_fast_antecedent_scores", "tensorflow.nn.top_k", "util.batch_gather", "util.batch_gather", "util.batch_gather", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.to_float"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_fast_antecedent_scores", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.batch_gather", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.batch_gather", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.batch_gather"], ["", "def", "coarse_to_fine_pruning", "(", "self", ",", "top_span_emb", ",", "top_span_mention_scores", ",", "c", ")", ":", "\n", "    ", "k", "=", "util", ".", "shape", "(", "top_span_emb", ",", "0", ")", "\n", "top_span_range", "=", "tf", ".", "range", "(", "k", ")", "# [k]", "\n", "antecedent_offsets", "=", "tf", ".", "expand_dims", "(", "top_span_range", ",", "1", ")", "-", "tf", ".", "expand_dims", "(", "top_span_range", ",", "0", ")", "# [k, k]", "\n", "antecedents_mask", "=", "antecedent_offsets", ">=", "1", "# [k, k]", "\n", "fast_antecedent_scores", "=", "tf", ".", "expand_dims", "(", "top_span_mention_scores", ",", "1", ")", "+", "tf", ".", "expand_dims", "(", "top_span_mention_scores", ",", "\n", "0", ")", "# [k, k]", "\n", "fast_antecedent_scores", "+=", "tf", ".", "log", "(", "tf", ".", "to_float", "(", "antecedents_mask", ")", ")", "# [k, k]", "\n", "fast_antecedent_scores", "+=", "self", ".", "get_fast_antecedent_scores", "(", "top_span_emb", ")", "# [k, k]", "\n", "\n", "_", ",", "top_antecedents", "=", "tf", ".", "nn", ".", "top_k", "(", "fast_antecedent_scores", ",", "c", ",", "sorted", "=", "False", ")", "# [k, c]", "\n", "top_antecedents_mask", "=", "util", ".", "batch_gather", "(", "antecedents_mask", ",", "top_antecedents", ")", "# [k, c]", "\n", "top_fast_antecedent_scores", "=", "util", ".", "batch_gather", "(", "fast_antecedent_scores", ",", "top_antecedents", ")", "# [k, c]", "\n", "top_antecedent_offsets", "=", "util", ".", "batch_gather", "(", "antecedent_offsets", ",", "top_antecedents", ")", "# [k, c]", "\n", "return", "top_antecedents", ",", "top_antecedents_mask", ",", "top_fast_antecedent_scores", ",", "top_antecedent_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.distance_pruning": [[243, 254], ["util.shape", "tensorflow.tile", "tensorflow.maximum", "tensorflow.log", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.gather", "tensorflow.to_float", "tensorflow.range", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "distance_pruning", "(", "self", ",", "top_span_emb", ",", "top_span_mention_scores", ",", "c", ")", ":", "\n", "    ", "k", "=", "util", ".", "shape", "(", "top_span_emb", ",", "0", ")", "\n", "top_antecedent_offsets", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "c", ")", "+", "1", ",", "0", ")", ",", "[", "k", ",", "1", "]", ")", "# [k, c]", "\n", "raw_top_antecedents", "=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "k", ")", ",", "1", ")", "-", "top_antecedent_offsets", "# [k, c]", "\n", "top_antecedents_mask", "=", "raw_top_antecedents", ">=", "0", "# [k, c]", "\n", "top_antecedents", "=", "tf", ".", "maximum", "(", "raw_top_antecedents", ",", "0", ")", "# [k, c]", "\n", "\n", "top_fast_antecedent_scores", "=", "tf", ".", "expand_dims", "(", "top_span_mention_scores", ",", "1", ")", "+", "tf", ".", "gather", "(", "top_span_mention_scores", ",", "\n", "top_antecedents", ")", "# [k, c]", "\n", "top_fast_antecedent_scores", "+=", "tf", ".", "log", "(", "tf", ".", "to_float", "(", "top_antecedents_mask", ")", ")", "# [k, c]", "\n", "return", "top_antecedents", ",", "top_antecedents_mask", ",", "top_fast_antecedent_scores", ",", "top_antecedent_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_predictions_and_loss": [[255, 400], ["coref_model.CorefModel.get_dropout", "coref_model.CorefModel.get_dropout", "coref_model.CorefModel.get_dropout", "util.shape", "util.shape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "context_emb_list.append", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.sequence_mask", "coref_model.CorefModel.lstm_contextualize", "util.shape", "tensorflow.gather", "tensorflow.tile", "coref_model.CorefModel.flatten_emb_by_sentence", "coref_model.CorefModel.flatten_emb_by_sentence", "tensorflow.tile", "tensorflow.gather", "tensorflow.gather", "tensorflow.logical_and", "tensorflow.reshape", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.cond", "tensorflow.cond", "coref_model.CorefModel.get_candidate_labels", "coref_model.CorefModel.get_span_emb", "coref_model.CorefModel.get_mention_scores", "tensorflow.squeeze", "tensorflow.minimum", "tensorflow.zeros", "range", "tensorflow.concat", "tensorflow.gather", "tensorflow.to_int32", "tensorflow.equal", "tensorflow.expand_dims", "tensorflow.logical_and", "tensorflow.logical_not", "tensorflow.concat", "coref_model.CorefModel.softmax_loss", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.gather", "tensorflow.reshape", "util.cnn", "tensorflow.reshape", "context_emb_list.append", "head_emb_list.append", "tensorflow.variable_scope", "tensorflow.nn.softmax", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.minimum", "tensorflow.equal", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.to_int32", "tensorflow.cond", "coref_ops.extract_spans", "tensorflow.squeeze.set_shape", "tensorflow.squeeze", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "util.shape", "tensorflow.gather", "coref_model.CorefModel.coarse_to_fine_pruning", "coref_model.CorefModel.distance_pruning", "tensorflow.log", "tensorflow.expand_dims", "tensorflow.reduce_any", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.range", "tensorflow.range", "tensorflow.range", "tensorflow.floor", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "util.shape", "tensorflow.variable_scope", "tensorflow.gather", "tensorflow.nn.softmax", "tensorflow.concat", "tensorflow.reduce_sum", "tensorflow.to_float", "util.shape", "util.shape", "util.shape", "tensorflow.constant_initializer", "len", "tensorflow.minimum", "coref_model.CorefModel.get_slow_antecedent_scores", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.sigmoid", "len", "tensorflow.constant_initializer", "tensorflow.to_float", "util.shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "util.projection", "tensorflow.concat", "util.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.lstm_contextualize", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.flatten_emb_by_sentence", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.flatten_emb_by_sentence", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_candidate_labels", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_span_emb", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_mention_scores", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.softmax_loss", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.cnn", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.coarse_to_fine_pruning", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.distance_pruning", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_slow_antecedent_scores", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "get_predictions_and_loss", "(", "self", ",", "tokens", ",", "context_word_emb", ",", "head_word_emb", ",", "lm_emb", ",", "char_index", ",", "text_len", ",", "speaker_ids", ",", "genre", ",", "is_training", ",", "gold_starts", ",", "gold_ends", ",", "cluster_ids", ",", "pred_starts", ",", "pred_ends", ",", "use_pred_mentions", ")", ":", "\n", "    ", "self", ".", "dropout", "=", "self", ".", "get_dropout", "(", "self", ".", "config", "[", "\"dropout_rate\"", "]", ",", "is_training", ")", "\n", "self", ".", "lexical_dropout", "=", "self", ".", "get_dropout", "(", "self", ".", "config", "[", "\"lexical_dropout_rate\"", "]", ",", "is_training", ")", "\n", "self", ".", "lstm_dropout", "=", "self", ".", "get_dropout", "(", "self", ".", "config", "[", "\"lstm_dropout_rate\"", "]", ",", "is_training", ")", "\n", "\n", "num_sentences", "=", "tf", ".", "shape", "(", "context_word_emb", ")", "[", "0", "]", "\n", "max_sentence_length", "=", "tf", ".", "shape", "(", "context_word_emb", ")", "[", "1", "]", "\n", "\n", "context_emb_list", "=", "[", "context_word_emb", "]", "\n", "head_emb_list", "=", "[", "head_word_emb", "]", "\n", "\n", "if", "self", ".", "config", "[", "\"char_embedding_size\"", "]", ">", "0", ":", "\n", "      ", "char_emb", "=", "tf", ".", "gather", "(", "tf", ".", "get_variable", "(", "\"char_embeddings\"", ",", "[", "len", "(", "self", ".", "char_dict", ")", ",", "self", ".", "config", "[", "\"char_embedding_size\"", "]", "]", ")", ",", "char_index", ")", "# [num_sentences, max_sentence_length, max_word_length, emb]", "\n", "flattened_char_emb", "=", "tf", ".", "reshape", "(", "char_emb", ",", "[", "num_sentences", "*", "max_sentence_length", ",", "util", ".", "shape", "(", "char_emb", ",", "2", ")", ",", "util", ".", "shape", "(", "char_emb", ",", "3", ")", "]", ")", "# [num_sentences * max_sentence_length, max_word_length, emb]", "\n", "flattened_aggregated_char_emb", "=", "util", ".", "cnn", "(", "flattened_char_emb", ",", "self", ".", "config", "[", "\"filter_widths\"", "]", ",", "self", ".", "config", "[", "\"filter_size\"", "]", ")", "# [num_sentences * max_sentence_length, emb]", "\n", "aggregated_char_emb", "=", "tf", ".", "reshape", "(", "flattened_aggregated_char_emb", ",", "[", "num_sentences", ",", "max_sentence_length", ",", "util", ".", "shape", "(", "flattened_aggregated_char_emb", ",", "1", ")", "]", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "context_emb_list", ".", "append", "(", "aggregated_char_emb", ")", "\n", "head_emb_list", ".", "append", "(", "aggregated_char_emb", ")", "\n", "\n", "\n", "", "lm_emb_size", "=", "util", ".", "shape", "(", "lm_emb", ",", "2", ")", "\n", "lm_num_layers", "=", "util", ".", "shape", "(", "lm_emb", ",", "3", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"lm_aggregation\"", ")", ":", "\n", "      ", "self", ".", "lm_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "get_variable", "(", "\"lm_scores\"", ",", "[", "lm_num_layers", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", ")", "\n", "self", ".", "lm_scaling", "=", "tf", ".", "get_variable", "(", "\"lm_scaling\"", ",", "[", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "", "flattened_lm_emb", "=", "tf", ".", "reshape", "(", "lm_emb", ",", "[", "num_sentences", "*", "max_sentence_length", "*", "lm_emb_size", ",", "lm_num_layers", "]", ")", "\n", "flattened_aggregated_lm_emb", "=", "tf", ".", "matmul", "(", "flattened_lm_emb", ",", "tf", ".", "expand_dims", "(", "self", ".", "lm_weights", ",", "1", ")", ")", "# [num_sentences * max_sentence_length * emb, 1]", "\n", "aggregated_lm_emb", "=", "tf", ".", "reshape", "(", "flattened_aggregated_lm_emb", ",", "[", "num_sentences", ",", "max_sentence_length", ",", "lm_emb_size", "]", ")", "\n", "aggregated_lm_emb", "*=", "self", ".", "lm_scaling", "\n", "context_emb_list", ".", "append", "(", "aggregated_lm_emb", ")", "\n", "\n", "context_emb", "=", "tf", ".", "concat", "(", "context_emb_list", ",", "2", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "head_emb", "=", "tf", ".", "concat", "(", "head_emb_list", ",", "2", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "context_emb", "=", "tf", ".", "nn", ".", "dropout", "(", "context_emb", ",", "self", ".", "lexical_dropout", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "head_emb", "=", "tf", ".", "nn", ".", "dropout", "(", "head_emb", ",", "self", ".", "lexical_dropout", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "\n", "text_len_mask", "=", "tf", ".", "sequence_mask", "(", "text_len", ",", "maxlen", "=", "max_sentence_length", ")", "# [num_sentence, max_sentence_length]", "\n", "\n", "context_outputs", "=", "self", ".", "lstm_contextualize", "(", "context_emb", ",", "text_len", ",", "text_len_mask", ")", "# [num_words, emb]", "\n", "num_words", "=", "util", ".", "shape", "(", "context_outputs", ",", "0", ")", "\n", "\n", "genre_emb", "=", "tf", ".", "gather", "(", "tf", ".", "get_variable", "(", "\"genre_embeddings\"", ",", "[", "len", "(", "self", ".", "genres", ")", ",", "self", ".", "config", "[", "\"feature_size\"", "]", "]", ")", ",", "genre", ")", "# [emb]", "\n", "\n", "sentence_indices", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_sentences", ")", ",", "1", ")", ",", "[", "1", ",", "max_sentence_length", "]", ")", "# [num_sentences, max_sentence_length]", "\n", "flattened_sentence_indices", "=", "self", ".", "flatten_emb_by_sentence", "(", "sentence_indices", ",", "text_len_mask", ")", "# [num_words]", "\n", "flattened_head_emb", "=", "self", ".", "flatten_emb_by_sentence", "(", "head_emb", ",", "text_len_mask", ")", "# [num_words]", "\n", "\n", "\n", "\n", "candidate_starts", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_words", ")", ",", "1", ")", ",", "\n", "[", "1", ",", "self", ".", "max_span_width", "]", ")", "# [num_words, max_span_width]", "\n", "candidate_ends", "=", "candidate_starts", "+", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "self", ".", "max_span_width", ")", ",", "0", ")", "# [num_words, max_span_width]", "\n", "candidate_start_sentence_indices", "=", "tf", ".", "gather", "(", "flattened_sentence_indices", ",", "\n", "candidate_starts", ")", "# [num_words, max_span_width]", "\n", "candidate_end_sentence_indices", "=", "tf", ".", "gather", "(", "flattened_sentence_indices", ",", "\n", "tf", ".", "minimum", "(", "candidate_ends", ",", "num_words", "-", "1", ")", ")", "# [num_words, max_span_width]", "\n", "candidate_mask", "=", "tf", ".", "logical_and", "(", "candidate_ends", "<", "num_words", ",", "tf", ".", "equal", "(", "candidate_start_sentence_indices", ",", "\n", "candidate_end_sentence_indices", ")", ")", "# [num_words, max_span_width]", "\n", "flattened_candidate_mask", "=", "tf", ".", "reshape", "(", "candidate_mask", ",", "[", "-", "1", "]", ")", "# [num_words * max_span_width]", "\n", "candidate_starts", "=", "tf", ".", "boolean_mask", "(", "tf", ".", "reshape", "(", "candidate_starts", ",", "[", "-", "1", "]", ")", ",", "flattened_candidate_mask", ")", "# [num_candidates]", "\n", "candidate_ends", "=", "tf", ".", "boolean_mask", "(", "tf", ".", "reshape", "(", "candidate_ends", ",", "[", "-", "1", "]", ")", ",", "flattened_candidate_mask", ")", "# [num_candidates]", "\n", "candidate_sentence_indices", "=", "tf", ".", "boolean_mask", "(", "tf", ".", "reshape", "(", "candidate_start_sentence_indices", ",", "[", "-", "1", "]", ")", ",", "\n", "flattened_candidate_mask", ")", "# [num_candidates]", "\n", "\n", "candidate_starts", "=", "tf", ".", "cond", "(", "use_pred_mentions", ",", "lambda", ":", "pred_starts", ",", "lambda", ":", "candidate_starts", ")", "\n", "candidate_ends", "=", "tf", ".", "cond", "(", "use_pred_mentions", ",", "lambda", ":", "pred_ends", ",", "lambda", ":", "candidate_ends", ")", "\n", "\n", "candidate_cluster_ids", "=", "self", ".", "get_candidate_labels", "(", "candidate_starts", ",", "candidate_ends", ",", "gold_starts", ",", "gold_ends", ",", "\n", "cluster_ids", ")", "# [num_candidates]", "\n", "\n", "candidate_span_emb", "=", "self", ".", "get_span_emb", "(", "flattened_head_emb", ",", "context_outputs", ",", "candidate_starts", ",", "\n", "candidate_ends", ")", "# [num_candidates, emb]", "\n", "candidate_mention_scores", "=", "self", ".", "get_mention_scores", "(", "candidate_span_emb", ")", "# [k, 1]", "\n", "candidate_mention_scores", "=", "tf", ".", "squeeze", "(", "candidate_mention_scores", ",", "1", ")", "# [k]", "\n", "\n", "\n", "\n", "if", "self", ".", "use_joint_coref", ":", "\n", "      ", "k", "=", "tf", ".", "to_int32", "(", "tf", ".", "floor", "(", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "context_outputs", ")", "[", "0", "]", ")", "*", "self", ".", "config", "[", "\"top_span_ratio\"", "]", ")", ")", "\n", "k", "=", "tf", ".", "cond", "(", "use_pred_mentions", ",", "lambda", ":", "tf", ".", "minimum", "(", "util", ".", "shape", "(", "candidate_starts", ",", "0", ")", ",", "k", ")", ",", "lambda", ":", "k", ")", "\n", "top_span_indices", "=", "coref_ops", ".", "extract_spans", "(", "tf", ".", "expand_dims", "(", "candidate_mention_scores", ",", "0", ")", ",", "\n", "tf", ".", "expand_dims", "(", "candidate_starts", ",", "0", ")", ",", "\n", "tf", ".", "expand_dims", "(", "candidate_ends", ",", "0", ")", ",", "\n", "tf", ".", "expand_dims", "(", "k", ",", "0", ")", ",", "\n", "util", ".", "shape", "(", "context_outputs", ",", "0", ")", ",", "\n", "True", ")", "# [1, k]", "\n", "top_span_indices", ".", "set_shape", "(", "[", "1", ",", "None", "]", ")", "\n", "top_span_indices", "=", "tf", ".", "squeeze", "(", "top_span_indices", ",", "0", ")", "# [k]", "\n", "\n", "top_span_starts", "=", "tf", ".", "gather", "(", "candidate_starts", ",", "top_span_indices", ")", "# [k]", "\n", "top_span_ends", "=", "tf", ".", "gather", "(", "candidate_ends", ",", "top_span_indices", ")", "# [k]", "\n", "top_span_emb", "=", "tf", ".", "gather", "(", "candidate_span_emb", ",", "top_span_indices", ")", "# [k, emb]", "\n", "top_span_cluster_ids", "=", "tf", ".", "gather", "(", "candidate_cluster_ids", ",", "top_span_indices", ")", "# [k]", "\n", "top_span_mention_scores", "=", "tf", ".", "gather", "(", "candidate_mention_scores", ",", "top_span_indices", ")", "# [k]", "\n", "top_span_speaker_ids", "=", "tf", ".", "gather", "(", "speaker_ids", ",", "top_span_starts", ")", "# [k]", "\n", "", "else", ":", "\n", "      ", "k", "=", "util", ".", "shape", "(", "candidate_starts", ",", "0", ")", "\n", "top_span_starts", "=", "candidate_starts", "\n", "top_span_ends", "=", "candidate_ends", "\n", "top_span_emb", "=", "candidate_span_emb", "\n", "top_span_cluster_ids", "=", "candidate_cluster_ids", "\n", "top_span_mention_scores", "=", "candidate_mention_scores", "\n", "top_span_speaker_ids", "=", "tf", ".", "gather", "(", "speaker_ids", ",", "top_span_starts", ")", "\n", "\n", "\n", "", "c", "=", "tf", ".", "minimum", "(", "self", ".", "config", "[", "\"max_top_antecedents\"", "]", ",", "k", ")", "\n", "\n", "if", "self", ".", "config", "[", "\"coarse_to_fine\"", "]", ":", "\n", "      ", "top_antecedents", ",", "top_antecedents_mask", ",", "top_fast_antecedent_scores", ",", "top_antecedent_offsets", "=", "self", ".", "coarse_to_fine_pruning", "(", "\n", "top_span_emb", ",", "top_span_mention_scores", ",", "c", ")", "\n", "", "else", ":", "\n", "      ", "top_antecedents", ",", "top_antecedents_mask", ",", "top_fast_antecedent_scores", ",", "top_antecedent_offsets", "=", "self", ".", "distance_pruning", "(", "\n", "top_span_emb", ",", "top_span_mention_scores", ",", "c", ")", "\n", "\n", "", "dummy_scores", "=", "tf", ".", "zeros", "(", "[", "k", ",", "1", "]", ")", "# [k, 1]", "\n", "for", "i", "in", "range", "(", "self", ".", "config", "[", "\"coref_depth\"", "]", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"coref_layer\"", ",", "reuse", "=", "(", "i", ">", "0", ")", ")", ":", "\n", "        ", "top_antecedent_emb", "=", "tf", ".", "gather", "(", "top_span_emb", ",", "top_antecedents", ")", "# [k, c, emb]", "\n", "top_antecedent_scores", "=", "top_fast_antecedent_scores", "+", "self", ".", "get_slow_antecedent_scores", "(", "top_span_emb", ",", "\n", "top_antecedents", ",", "\n", "top_antecedent_emb", ",", "\n", "top_antecedent_offsets", ",", "\n", "top_span_speaker_ids", ",", "\n", "genre_emb", ")", "# [k, c]", "\n", "top_antecedent_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "concat", "(", "[", "dummy_scores", ",", "top_antecedent_scores", "]", ",", "1", ")", ")", "# [k, c + 1]", "\n", "top_antecedent_emb", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "top_span_emb", ",", "1", ")", ",", "top_antecedent_emb", "]", ",", "1", ")", "# [k, c + 1, emb]", "\n", "attended_span_emb", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "top_antecedent_weights", ",", "2", ")", "*", "top_antecedent_emb", ",", "1", ")", "# [k, emb]", "\n", "with", "tf", ".", "variable_scope", "(", "\"f\"", ")", ":", "\n", "          ", "f", "=", "tf", ".", "sigmoid", "(", "\n", "util", ".", "projection", "(", "tf", ".", "concat", "(", "[", "top_span_emb", ",", "attended_span_emb", "]", ",", "1", ")", ",", "util", ".", "shape", "(", "top_span_emb", ",", "-", "1", ")", ")", ")", "# [k, emb]", "\n", "top_span_emb", "=", "f", "*", "attended_span_emb", "+", "(", "1", "-", "f", ")", "*", "top_span_emb", "# [k, emb]", "\n", "\n", "", "", "", "top_antecedent_scores", "=", "tf", ".", "concat", "(", "[", "dummy_scores", ",", "top_antecedent_scores", "]", ",", "1", ")", "# [k, c + 1]", "\n", "\n", "top_antecedent_cluster_ids", "=", "tf", ".", "gather", "(", "top_span_cluster_ids", ",", "top_antecedents", ")", "# [k, c]", "\n", "top_antecedent_cluster_ids", "+=", "tf", ".", "to_int32", "(", "tf", ".", "log", "(", "tf", ".", "to_float", "(", "top_antecedents_mask", ")", ")", ")", "# [k, c]", "\n", "same_cluster_indicator", "=", "tf", ".", "equal", "(", "top_antecedent_cluster_ids", ",", "tf", ".", "expand_dims", "(", "top_span_cluster_ids", ",", "1", ")", ")", "# [k, c]", "\n", "non_dummy_indicator", "=", "tf", ".", "expand_dims", "(", "top_span_cluster_ids", ">", "0", ",", "1", ")", "# [k, 1]", "\n", "pairwise_labels", "=", "tf", ".", "logical_and", "(", "same_cluster_indicator", ",", "non_dummy_indicator", ")", "# [k, c]", "\n", "dummy_labels", "=", "tf", ".", "logical_not", "(", "tf", ".", "reduce_any", "(", "pairwise_labels", ",", "1", ",", "keepdims", "=", "True", ")", ")", "# [k, 1]", "\n", "top_antecedent_labels", "=", "tf", ".", "concat", "(", "[", "dummy_labels", ",", "pairwise_labels", "]", ",", "1", ")", "# [k, c + 1]", "\n", "loss", "=", "self", ".", "softmax_loss", "(", "top_antecedent_scores", ",", "top_antecedent_labels", ")", "# [k]", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "loss", ")", "# []", "\n", "#loss = tf.Print(loss,[loss])", "\n", "return", "[", "top_span_starts", ",", "top_span_ends", ",", "top_antecedents", ",", "top_antecedent_scores", "]", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_span_emb": [[401, 436], ["tensorflow.gather", "span_emb_list.append", "tensorflow.gather", "span_emb_list.append", "tensorflow.maximum", "tensorflow.concat", "tensorflow.gather", "tensorflow.nn.dropout", "span_emb_list.append", "tensorflow.minimum", "tensorflow.gather", "tensorflow.gather", "tensorflow.expand_dims", "tensorflow.log", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "span_emb_list.append", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.variable_scope", "util.projection", "tensorflow.sequence_mask", "tensorflow.range", "util.shape"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "get_span_emb", "(", "self", ",", "head_emb", ",", "context_outputs", ",", "span_starts", ",", "span_ends", ")", ":", "\n", "    ", "span_emb_list", "=", "[", "]", "\n", "\n", "span_start_emb", "=", "tf", ".", "gather", "(", "context_outputs", ",", "span_starts", ")", "# [k, emb]", "\n", "span_emb_list", ".", "append", "(", "span_start_emb", ")", "\n", "\n", "span_end_emb", "=", "tf", ".", "gather", "(", "context_outputs", ",", "span_ends", ")", "# [k, emb]", "\n", "span_emb_list", ".", "append", "(", "span_end_emb", ")", "\n", "\n", "\n", "#in case the span from MD is longer than max_span_width,  we compute the head attentions for the last max_span_width tokens", "\n", "span_starts", "=", "tf", ".", "maximum", "(", "span_starts", ",", "1", "+", "span_ends", "-", "self", ".", "config", "[", "\"max_span_width\"", "]", ")", "#[k]", "\n", "span_width", "=", "1", "+", "span_ends", "-", "span_starts", "# [k]", "\n", "\n", "if", "self", ".", "config", "[", "\"use_features\"", "]", ":", "\n", "      ", "span_width_index", "=", "span_width", "-", "1", "# [k]", "\n", "span_width_emb", "=", "tf", ".", "gather", "(", "tf", ".", "get_variable", "(", "\"span_width_embeddings\"", ",", "[", "self", ".", "config", "[", "\"max_span_width\"", "]", ",", "self", ".", "config", "[", "\"feature_size\"", "]", "]", ")", ",", "span_width_index", ")", "# [k, emb]", "\n", "span_width_emb", "=", "tf", ".", "nn", ".", "dropout", "(", "span_width_emb", ",", "self", ".", "dropout", ")", "\n", "span_emb_list", ".", "append", "(", "span_width_emb", ")", "\n", "\n", "", "if", "self", ".", "config", "[", "\"model_heads\"", "]", ":", "\n", "      ", "span_indices", "=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "self", ".", "config", "[", "\"max_span_width\"", "]", ")", ",", "0", ")", "+", "tf", ".", "expand_dims", "(", "span_starts", ",", "1", ")", "# [k, max_span_width]", "\n", "span_indices", "=", "tf", ".", "minimum", "(", "util", ".", "shape", "(", "context_outputs", ",", "0", ")", "-", "1", ",", "span_indices", ")", "# [k, max_span_width]", "\n", "span_text_emb", "=", "tf", ".", "gather", "(", "head_emb", ",", "span_indices", ")", "# [k, max_span_width, emb]", "\n", "with", "tf", ".", "variable_scope", "(", "\"head_scores\"", ")", ":", "\n", "        ", "self", ".", "head_scores", "=", "util", ".", "projection", "(", "context_outputs", ",", "1", ")", "# [num_words, 1]", "\n", "", "span_head_scores", "=", "tf", ".", "gather", "(", "self", ".", "head_scores", ",", "span_indices", ")", "# [k, max_span_width, 1]", "\n", "span_mask", "=", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "span_width", ",", "self", ".", "config", "[", "\"max_span_width\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "2", ")", "# [k, max_span_width, 1]", "\n", "span_head_scores", "+=", "tf", ".", "log", "(", "span_mask", ")", "# [k, max_span_width, 1]", "\n", "span_attention", "=", "tf", ".", "nn", ".", "softmax", "(", "span_head_scores", ",", "1", ")", "# [k, max_span_width, 1]", "\n", "span_head_emb", "=", "tf", ".", "reduce_sum", "(", "span_attention", "*", "span_text_emb", ",", "1", ")", "# [k, emb]", "\n", "span_emb_list", ".", "append", "(", "span_head_emb", ")", "\n", "\n", "", "span_emb", "=", "tf", ".", "concat", "(", "span_emb_list", ",", "1", ")", "# [k, emb]", "\n", "return", "span_emb", "# [k, emb]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_mention_scores": [[437, 440], ["tensorflow.variable_scope", "util.ffnn"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.ffnn"], ["", "def", "get_mention_scores", "(", "self", ",", "span_emb", ",", "scope_name", "=", "'mention_scores'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope_name", ")", ":", "\n", "      ", "return", "util", ".", "ffnn", "(", "span_emb", ",", "self", ".", "config", "[", "\"ffnn_depth\"", "]", ",", "self", ".", "config", "[", "\"ffnn_size\"", "]", ",", "1", ",", "self", ".", "dropout", ")", "# [k, 1]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.softmax_loss": [[442, 447], ["tensorflow.reduce_logsumexp", "tensorflow.reduce_logsumexp", "tensorflow.log", "tensorflow.to_float"], "methods", ["None"], ["", "", "def", "softmax_loss", "(", "self", ",", "antecedent_scores", ",", "antecedent_labels", ")", ":", "\n", "    ", "gold_scores", "=", "antecedent_scores", "+", "tf", ".", "log", "(", "tf", ".", "to_float", "(", "antecedent_labels", ")", ")", "# [k, max_ant + 1]", "\n", "marginalized_gold_scores", "=", "tf", ".", "reduce_logsumexp", "(", "gold_scores", ",", "[", "1", "]", ")", "# [k]", "\n", "log_norm", "=", "tf", ".", "reduce_logsumexp", "(", "antecedent_scores", ",", "[", "1", "]", ")", "# [k]", "\n", "return", "log_norm", "-", "marginalized_gold_scores", "# [k]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.bucket_distance": [[449, 458], ["tensorflow.to_int32", "tensorflow.clip_by_value", "tensorflow.to_int32", "tensorflow.floor", "tensorflow.log", "math.log", "tensorflow.to_float"], "methods", ["None"], ["", "def", "bucket_distance", "(", "self", ",", "distances", ")", ":", "\n", "    ", "\"\"\"\n    Places the given values (designed for distances) into 10 semi-logscale buckets:\n    [0, 1, 2, 3, 4, 5-7, 8-15, 16-31, 32-63, 64+].\n    \"\"\"", "\n", "logspace_idx", "=", "tf", ".", "to_int32", "(", "tf", ".", "floor", "(", "tf", ".", "log", "(", "tf", ".", "to_float", "(", "distances", ")", ")", "/", "math", ".", "log", "(", "2", ")", ")", ")", "+", "3", "\n", "use_identity", "=", "tf", ".", "to_int32", "(", "distances", "<=", "4", ")", "\n", "combined_idx", "=", "use_identity", "*", "distances", "+", "(", "1", "-", "use_identity", ")", "*", "logspace_idx", "\n", "return", "tf", ".", "clip_by_value", "(", "combined_idx", ",", "0", ",", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_slow_antecedent_scores": [[459, 492], ["util.shape", "util.shape", "tensorflow.concat", "tensorflow.nn.dropout", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.concat", "tensorflow.squeeze", "tensorflow.gather", "tensorflow.equal", "tensorflow.gather", "feature_emb_list.append", "tensorflow.tile", "feature_emb_list.append", "coref_model.CorefModel.bucket_distance", "tensorflow.gather", "feature_emb_list.append", "tensorflow.variable_scope", "util.ffnn", "tensorflow.expand_dims", "tensorflow.get_variable", "tensorflow.to_int32", "tensorflow.expand_dims", "tensorflow.get_variable", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.bucket_distance", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.ffnn"], ["", "def", "get_slow_antecedent_scores", "(", "self", ",", "top_span_emb", ",", "top_antecedents", ",", "top_antecedent_emb", ",", "top_antecedent_offsets", ",", "top_span_speaker_ids", ",", "genre_emb", ")", ":", "\n", "    ", "k", "=", "util", ".", "shape", "(", "top_span_emb", ",", "0", ")", "\n", "c", "=", "util", ".", "shape", "(", "top_antecedents", ",", "1", ")", "\n", "\n", "feature_emb_list", "=", "[", "]", "\n", "\n", "if", "self", ".", "config", "[", "\"use_metadata\"", "]", ":", "\n", "      ", "top_antecedent_speaker_ids", "=", "tf", ".", "gather", "(", "top_span_speaker_ids", ",", "top_antecedents", ")", "# [k, c]", "\n", "same_speaker", "=", "tf", ".", "equal", "(", "tf", ".", "expand_dims", "(", "top_span_speaker_ids", ",", "1", ")", ",", "top_antecedent_speaker_ids", ")", "# [k, c]", "\n", "speaker_pair_emb", "=", "tf", ".", "gather", "(", "tf", ".", "get_variable", "(", "\"same_speaker_emb\"", ",", "[", "2", ",", "self", ".", "config", "[", "\"feature_size\"", "]", "]", ")", ",", "tf", ".", "to_int32", "(", "same_speaker", ")", ")", "# [k, c, emb]", "\n", "feature_emb_list", ".", "append", "(", "speaker_pair_emb", ")", "\n", "\n", "tiled_genre_emb", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "genre_emb", ",", "0", ")", ",", "0", ")", ",", "[", "k", ",", "c", ",", "1", "]", ")", "# [k, c, emb]", "\n", "feature_emb_list", ".", "append", "(", "tiled_genre_emb", ")", "\n", "\n", "", "if", "self", ".", "config", "[", "\"use_features\"", "]", ":", "\n", "      ", "antecedent_distance_buckets", "=", "self", ".", "bucket_distance", "(", "top_antecedent_offsets", ")", "# [k, c]", "\n", "antecedent_distance_emb", "=", "tf", ".", "gather", "(", "tf", ".", "get_variable", "(", "\"antecedent_distance_emb\"", ",", "[", "10", ",", "self", ".", "config", "[", "\"feature_size\"", "]", "]", ")", ",", "antecedent_distance_buckets", ")", "# [k, c]", "\n", "feature_emb_list", ".", "append", "(", "antecedent_distance_emb", ")", "\n", "\n", "", "feature_emb", "=", "tf", ".", "concat", "(", "feature_emb_list", ",", "2", ")", "# [k, c, emb]", "\n", "feature_emb", "=", "tf", ".", "nn", ".", "dropout", "(", "feature_emb", ",", "self", ".", "dropout", ")", "# [k, c, emb]", "\n", "\n", "target_emb", "=", "tf", ".", "expand_dims", "(", "top_span_emb", ",", "1", ")", "# [k, 1, emb]", "\n", "similarity_emb", "=", "top_antecedent_emb", "*", "target_emb", "# [k, c, emb]", "\n", "target_emb", "=", "tf", ".", "tile", "(", "target_emb", ",", "[", "1", ",", "c", ",", "1", "]", ")", "# [k, c, emb]", "\n", "\n", "pair_emb", "=", "tf", ".", "concat", "(", "[", "target_emb", ",", "top_antecedent_emb", ",", "similarity_emb", ",", "feature_emb", "]", ",", "2", ")", "# [k, c, emb]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"slow_antecedent_scores\"", ")", ":", "\n", "      ", "slow_antecedent_scores", "=", "util", ".", "ffnn", "(", "pair_emb", ",", "self", ".", "config", "[", "\"ffnn_depth\"", "]", ",", "self", ".", "config", "[", "\"ffnn_size\"", "]", ",", "1", ",", "self", ".", "dropout", ")", "# [k, c, 1]", "\n", "", "slow_antecedent_scores", "=", "tf", ".", "squeeze", "(", "slow_antecedent_scores", ",", "2", ")", "# [k, c]", "\n", "return", "slow_antecedent_scores", "# [k, c]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_fast_antecedent_scores": [[493, 498], ["tensorflow.nn.dropout", "tensorflow.matmul", "tensorflow.variable_scope", "tensorflow.nn.dropout", "util.projection", "util.shape"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "get_fast_antecedent_scores", "(", "self", ",", "top_span_emb", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"src_projection\"", ")", ":", "\n", "      ", "source_top_span_emb", "=", "tf", ".", "nn", ".", "dropout", "(", "util", ".", "projection", "(", "top_span_emb", ",", "util", ".", "shape", "(", "top_span_emb", ",", "-", "1", ")", ")", ",", "self", ".", "dropout", ")", "# [k, emb]", "\n", "", "target_top_span_emb", "=", "tf", ".", "nn", ".", "dropout", "(", "top_span_emb", ",", "self", ".", "dropout", ")", "# [k, emb]", "\n", "return", "tf", ".", "matmul", "(", "source_top_span_emb", ",", "target_top_span_emb", ",", "transpose_b", "=", "True", ")", "# [k, k]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.flatten_emb_by_sentence": [[499, 511], ["len", "tensorflow.boolean_mask", "tensorflow.shape", "tensorflow.shape", "emb.get_shape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "ValueError", "util.shape"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "flatten_emb_by_sentence", "(", "self", ",", "emb", ",", "text_len_mask", ")", ":", "\n", "    ", "num_sentences", "=", "tf", ".", "shape", "(", "emb", ")", "[", "0", "]", "\n", "max_sentence_length", "=", "tf", ".", "shape", "(", "emb", ")", "[", "1", "]", "\n", "\n", "emb_rank", "=", "len", "(", "emb", ".", "get_shape", "(", ")", ")", "\n", "if", "emb_rank", "==", "2", ":", "\n", "      ", "flattened_emb", "=", "tf", ".", "reshape", "(", "emb", ",", "[", "num_sentences", "*", "max_sentence_length", "]", ")", "\n", "", "elif", "emb_rank", "==", "3", ":", "\n", "      ", "flattened_emb", "=", "tf", ".", "reshape", "(", "emb", ",", "[", "num_sentences", "*", "max_sentence_length", ",", "util", ".", "shape", "(", "emb", ",", "2", ")", "]", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unsupported rank: {}\"", ".", "format", "(", "emb_rank", ")", ")", "\n", "", "return", "tf", ".", "boolean_mask", "(", "flattened_emb", ",", "tf", ".", "reshape", "(", "text_len_mask", ",", "[", "num_sentences", "*", "max_sentence_length", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.lstm_contextualize": [[512, 542], ["range", "coref_model.CorefModel.flatten_emb_by_sentence", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat", "tensorflow.nn.dropout", "tensorflow.variable_scope", "util.CustomLSTMCell", "tensorflow.variable_scope", "util.CustomLSTMCell", "tensorflow.tile", "tensorflow.tile", "tensorflow.tile", "tensorflow.tile", "tensorflow.sigmoid", "util.projection", "util.shape"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.flatten_emb_by_sentence", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "lstm_contextualize", "(", "self", ",", "text_emb", ",", "text_len", ",", "text_len_mask", ")", ":", "\n", "    ", "num_sentences", "=", "tf", ".", "shape", "(", "text_emb", ")", "[", "0", "]", "\n", "\n", "current_inputs", "=", "text_emb", "# [num_sentences, max_sentence_length, emb]", "\n", "\n", "for", "layer", "in", "range", "(", "self", ".", "config", "[", "\"contextualization_layers\"", "]", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"layer_{}\"", ".", "format", "(", "layer", ")", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"fw_cell\"", ")", ":", "\n", "          ", "cell_fw", "=", "util", ".", "CustomLSTMCell", "(", "self", ".", "config", "[", "\"contextualization_size\"", "]", ",", "num_sentences", ",", "self", ".", "lstm_dropout", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"bw_cell\"", ")", ":", "\n", "          ", "cell_bw", "=", "util", ".", "CustomLSTMCell", "(", "self", ".", "config", "[", "\"contextualization_size\"", "]", ",", "num_sentences", ",", "self", ".", "lstm_dropout", ")", "\n", "", "state_fw", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "tf", ".", "tile", "(", "cell_fw", ".", "initial_state", ".", "c", ",", "[", "num_sentences", ",", "1", "]", ")", ",", "tf", ".", "tile", "(", "cell_fw", ".", "initial_state", ".", "h", ",", "[", "num_sentences", ",", "1", "]", ")", ")", "\n", "state_bw", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "tf", ".", "tile", "(", "cell_bw", ".", "initial_state", ".", "c", ",", "[", "num_sentences", ",", "1", "]", ")", ",", "tf", ".", "tile", "(", "cell_bw", ".", "initial_state", ".", "h", ",", "[", "num_sentences", ",", "1", "]", ")", ")", "\n", "\n", "(", "fw_outputs", ",", "bw_outputs", ")", ",", "_", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", "=", "cell_fw", ",", "\n", "cell_bw", "=", "cell_bw", ",", "\n", "inputs", "=", "current_inputs", ",", "\n", "sequence_length", "=", "text_len", ",", "\n", "initial_state_fw", "=", "state_fw", ",", "\n", "initial_state_bw", "=", "state_bw", ")", "\n", "\n", "text_outputs", "=", "tf", ".", "concat", "(", "[", "fw_outputs", ",", "bw_outputs", "]", ",", "2", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "text_outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "text_outputs", ",", "self", ".", "lstm_dropout", ")", "\n", "if", "layer", ">", "0", ":", "\n", "          ", "highway_gates", "=", "tf", ".", "sigmoid", "(", "util", ".", "projection", "(", "text_outputs", ",", "util", ".", "shape", "(", "text_outputs", ",", "2", ")", ")", ")", "# [num_sentences, max_sentence_length, emb]", "\n", "text_outputs", "=", "highway_gates", "*", "text_outputs", "+", "(", "1", "-", "highway_gates", ")", "*", "current_inputs", "\n", "", "current_inputs", "=", "text_outputs", "\n", "\n", "", "", "return", "self", ".", "flatten_emb_by_sentence", "(", "text_outputs", ",", "text_len_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_predicted_antecedents": [[543, 551], ["enumerate", "numpy.argmax", "predicted_antecedents.append", "predicted_antecedents.append"], "methods", ["None"], ["", "def", "get_predicted_antecedents", "(", "self", ",", "antecedents", ",", "antecedent_scores", ")", ":", "\n", "    ", "predicted_antecedents", "=", "[", "]", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "np", ".", "argmax", "(", "antecedent_scores", ",", "axis", "=", "1", ")", "-", "1", ")", ":", "\n", "      ", "if", "index", "<", "0", ":", "\n", "        ", "predicted_antecedents", ".", "append", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "predicted_antecedents", ".", "append", "(", "antecedents", "[", "i", ",", "index", "]", ")", "\n", "", "", "return", "predicted_antecedents", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_predicted_clusters": [[552, 575], ["enumerate", "predicted_clusters[].append", "tuple", "int", "int", "len", "predicted_clusters.append", "int", "int", "mention_to_predicted.items"], "methods", ["None"], ["", "def", "get_predicted_clusters", "(", "self", ",", "top_span_starts", ",", "top_span_ends", ",", "predicted_antecedents", ")", ":", "\n", "    ", "mention_to_predicted", "=", "{", "}", "\n", "predicted_clusters", "=", "[", "]", "\n", "for", "i", ",", "predicted_index", "in", "enumerate", "(", "predicted_antecedents", ")", ":", "\n", "      ", "if", "predicted_index", "<", "0", ":", "\n", "        ", "continue", "\n", "", "assert", "i", ">", "predicted_index", "\n", "predicted_antecedent", "=", "(", "int", "(", "top_span_starts", "[", "predicted_index", "]", ")", ",", "int", "(", "top_span_ends", "[", "predicted_index", "]", ")", ")", "\n", "if", "predicted_antecedent", "in", "mention_to_predicted", ":", "\n", "        ", "predicted_cluster", "=", "mention_to_predicted", "[", "predicted_antecedent", "]", "\n", "", "else", ":", "\n", "        ", "predicted_cluster", "=", "len", "(", "predicted_clusters", ")", "\n", "predicted_clusters", ".", "append", "(", "[", "predicted_antecedent", "]", ")", "\n", "mention_to_predicted", "[", "predicted_antecedent", "]", "=", "predicted_cluster", "\n", "\n", "", "mention", "=", "(", "int", "(", "top_span_starts", "[", "i", "]", ")", ",", "int", "(", "top_span_ends", "[", "i", "]", ")", ")", "\n", "predicted_clusters", "[", "predicted_cluster", "]", ".", "append", "(", "mention", ")", "\n", "mention_to_predicted", "[", "mention", "]", "=", "predicted_cluster", "\n", "\n", "", "predicted_clusters", "=", "[", "tuple", "(", "pc", ")", "for", "pc", "in", "predicted_clusters", "]", "\n", "mention_to_predicted", "=", "{", "m", ":", "predicted_clusters", "[", "i", "]", "for", "m", ",", "i", "in", "mention_to_predicted", ".", "items", "(", ")", "}", "\n", "\n", "return", "predicted_clusters", ",", "mention_to_predicted", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.evaluate_coref": [[576, 586], ["coref_model.CorefModel.get_predicted_clusters", "evaluator.update", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_predicted_clusters", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update"], ["", "def", "evaluate_coref", "(", "self", ",", "top_span_starts", ",", "top_span_ends", ",", "predicted_antecedents", ",", "gold_clusters", ",", "evaluator", ")", ":", "\n", "    ", "gold_clusters", "=", "[", "tuple", "(", "tuple", "(", "m", ")", "for", "m", "in", "gc", ")", "for", "gc", "in", "gold_clusters", "]", "\n", "mention_to_gold", "=", "{", "}", "\n", "for", "gc", "in", "gold_clusters", ":", "\n", "      ", "for", "mention", "in", "gc", ":", "\n", "        ", "mention_to_gold", "[", "mention", "]", "=", "gc", "\n", "\n", "", "", "predicted_clusters", ",", "mention_to_predicted", "=", "self", ".", "get_predicted_clusters", "(", "top_span_starts", ",", "top_span_ends", ",", "predicted_antecedents", ")", "\n", "evaluator", ".", "update", "(", "predicted_clusters", ",", "gold_clusters", ",", "mention_to_predicted", ",", "mention_to_gold", ")", "\n", "return", "predicted_clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.load_eval_data": [[587, 596], ["print", "json.loads", "open", "coref_model.CorefModel.tensorize_example", "coref_model.CorefModel.load_eval_data.load_line"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.tensorize_example"], ["", "def", "load_eval_data", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "eval_data", "is", "None", ":", "\n", "      ", "def", "load_line", "(", "line", ")", ":", "\n", "        ", "example", "=", "json", ".", "loads", "(", "line", ")", "\n", "use_pred_mentions", "=", "True", "if", "not", "self", ".", "use_joint_coref", "or", "self", ".", "use_e2e_annealing", "else", "False", "\n", "return", "self", ".", "tensorize_example", "(", "example", ",", "False", ",", "use_pred_mentions", ")", ",", "example", "\n", "", "with", "open", "(", "self", ".", "config", "[", "\"eval_path\"", "]", ")", "as", "f", ":", "\n", "        ", "self", ".", "eval_data", "=", "[", "load_line", "(", "l", ")", "for", "l", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "print", "(", "\"Loaded {} eval examples.\"", ".", "format", "(", "len", "(", "self", ".", "eval_data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.evaluate": [[597, 642], ["coref_model.CorefModel.load_eval_data", "metrics.CorefEvaluator", "enumerate", "print", "print", "print", "metrics.CorefEvaluator.get_prf", "print", "print", "print", "session.run", "coref_model.CorefModel.get_predicted_antecedents", "coref_model.CorefModel.evaluate_coref", "set", "set", "len", "len", "len", "float", "float", "conll.evaluate_conll", "print", "util.make_summary", "print", "sum", "len", "zip", "zip", "len", "conll.evaluate_conll.values"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.load_eval_data", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.metrics.Evaluator.get_prf", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.get_predicted_antecedents", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.coref_model.CorefModel.evaluate_coref", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.conll.evaluate_conll", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.make_summary"], ["", "", "def", "evaluate", "(", "self", ",", "session", ",", "official_stdout", "=", "False", ")", ":", "\n", "    ", "self", ".", "load_eval_data", "(", ")", "\n", "\n", "tp", ",", "fn", ",", "fp", "=", "0", ",", "0", ",", "0", "\n", "coref_predictions", "=", "{", "}", "\n", "coref_evaluator", "=", "metrics", ".", "CorefEvaluator", "(", ")", "\n", "\n", "for", "example_num", ",", "(", "tensorized_example", ",", "example", ")", "in", "enumerate", "(", "self", ".", "eval_data", ")", ":", "\n", "      ", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "gold_starts", ",", "gold_ends", ",", "_", ",", "_", ",", "_", ",", "_", "=", "tensorized_example", "\n", "feed_dict", "=", "{", "i", ":", "t", "for", "i", ",", "t", "in", "zip", "(", "self", ".", "input_tensors", ",", "tensorized_example", ")", "}", "\n", "top_span_starts", ",", "top_span_ends", ",", "top_antecedents", ",", "top_antecedent_scores", "=", "session", ".", "run", "(", "self", ".", "predictions", ",", "feed_dict", "=", "feed_dict", ")", "\n", "predicted_antecedents", "=", "self", ".", "get_predicted_antecedents", "(", "top_antecedents", ",", "top_antecedent_scores", ")", "\n", "coref_predictions", "[", "example", "[", "\"doc_key\"", "]", "]", "=", "self", ".", "evaluate_coref", "(", "top_span_starts", ",", "top_span_ends", ",", "predicted_antecedents", ",", "example", "[", "\"clusters\"", "]", ",", "coref_evaluator", ")", "\n", "\n", "gold_mentions", "=", "set", "(", "[", "(", "s", ",", "e", ")", "for", "cl", "in", "example", "[", "\"clusters\"", "]", "for", "s", ",", "e", "in", "cl", "]", ")", "\n", "pred_mentions", "=", "set", "(", "[", "(", "s", ",", "e", ")", "for", "s", ",", "e", "in", "zip", "(", "top_span_starts", ",", "top_span_ends", ")", "]", ")", "\n", "tp", "+=", "len", "(", "gold_mentions", "&", "pred_mentions", ")", "\n", "fn", "+=", "len", "(", "gold_mentions", "-", "pred_mentions", ")", "\n", "fp", "+=", "len", "(", "pred_mentions", "-", "gold_mentions", ")", "\n", "if", "example_num", "%", "10", "==", "0", ":", "\n", "        ", "print", "(", "\"Evaluated {}/{} examples.\"", ".", "format", "(", "example_num", "+", "1", ",", "len", "(", "self", ".", "eval_data", ")", ")", ")", "\n", "\n", "", "", "m_r", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fn", ")", "\n", "m_p", "=", "float", "(", "tp", ")", "/", "(", "tp", "+", "fp", ")", "\n", "m_f1", "=", "2.0", "*", "m_r", "*", "m_p", "/", "(", "m_r", "+", "m_p", ")", "\n", "print", "(", "\"Mention F1: {:.2f}%\"", ".", "format", "(", "m_f1", "*", "100", ")", ")", "\n", "print", "(", "\"Mention recall: {:.2f}%\"", ".", "format", "(", "m_r", "*", "100", ")", ")", "\n", "print", "(", "\"Mention precision: {:.2f}%\"", ".", "format", "(", "m_p", "*", "100", ")", ")", "\n", "\n", "summary_dict", "=", "{", "}", "\n", "if", "official_stdout", ":", "\n", "      ", "conll_results", "=", "conll", ".", "evaluate_conll", "(", "self", ".", "config", "[", "\"conll_eval_path\"", "]", ",", "coref_predictions", ",", "official_stdout", ")", "\n", "average_f1", "=", "sum", "(", "results", "[", "\"f\"", "]", "for", "results", "in", "conll_results", ".", "values", "(", ")", ")", "/", "len", "(", "conll_results", ")", "\n", "summary_dict", "[", "\"Average F1 (conll)\"", "]", "=", "average_f1", "\n", "print", "(", "\"Average F1 (conll): {:.2f}%\"", ".", "format", "(", "average_f1", ")", ")", "\n", "\n", "", "p", ",", "r", ",", "f", "=", "coref_evaluator", ".", "get_prf", "(", ")", "\n", "summary_dict", "[", "\"Average F1 (py)\"", "]", "=", "f", "\n", "print", "(", "\"Average F1 (py): {:.2f}%\"", ".", "format", "(", "f", "*", "100", ")", ")", "\n", "summary_dict", "[", "\"Average precision (py)\"", "]", "=", "p", "\n", "print", "(", "\"Average precision (py): {:.2f}%\"", ".", "format", "(", "p", "*", "100", ")", ")", "\n", "summary_dict", "[", "\"Average recall (py)\"", "]", "=", "r", "\n", "print", "(", "\"Average recall (py): {:.2f}%\"", ".", "format", "(", "r", "*", "100", ")", ")", "\n", "average_f1", "=", "average_f1", "if", "official_stdout", "else", "f", "*", "100", "\n", "return", "util", ".", "make_summary", "(", "summary_dict", ")", ",", "average_f1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.__init__": [[143, 147], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "_num_correct", "=", "0", "\n", "self", ".", "_num_gold", "=", "0", "\n", "self", ".", "_num_predicted", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update": [[148, 152], ["len", "len", "len"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "gold_set", ",", "predicted_set", ")", ":", "\n", "    ", "self", ".", "_num_correct", "+=", "len", "(", "gold_set", "&", "predicted_set", ")", "\n", "self", ".", "_num_gold", "+=", "len", "(", "gold_set", ")", "\n", "self", ".", "_num_predicted", "+=", "len", "(", "predicted_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.recall": [[153, 155], ["util.maybe_divide"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.maybe_divide"], ["", "def", "recall", "(", "self", ")", ":", "\n", "    ", "return", "maybe_divide", "(", "self", ".", "_num_correct", ",", "self", ".", "_num_gold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.precision": [[156, 158], ["util.maybe_divide"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.maybe_divide"], ["", "def", "precision", "(", "self", ")", ":", "\n", "    ", "return", "maybe_divide", "(", "self", ".", "_num_correct", ",", "self", ".", "_num_predicted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.metrics": [[159, 164], ["util.RetrievalEvaluator.recall", "util.RetrievalEvaluator.precision", "util.maybe_divide"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.recall", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.precision", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.maybe_divide"], ["", "def", "metrics", "(", "self", ")", ":", "\n", "    ", "recall", "=", "self", ".", "recall", "(", ")", "\n", "precision", "=", "self", ".", "precision", "(", ")", "\n", "f1", "=", "maybe_divide", "(", "2", "*", "recall", "*", "precision", ",", "precision", "+", "recall", ")", "\n", "return", "recall", ",", "precision", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.__init__": [[166, 175], ["util.EmbeddingDictionary.load_embedding_dict"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.load_embedding_dict"], ["  ", "def", "__init__", "(", "self", ",", "info", ",", "normalize", "=", "True", ",", "maybe_cache", "=", "None", ")", ":", "\n", "    ", "self", ".", "_size", "=", "info", "[", "\"size\"", "]", "\n", "self", ".", "_normalize", "=", "normalize", "\n", "self", ".", "_path", "=", "info", "[", "\"path\"", "]", "\n", "if", "maybe_cache", "is", "not", "None", "and", "maybe_cache", ".", "_path", "==", "self", ".", "_path", ":", "\n", "      ", "assert", "self", ".", "_size", "==", "maybe_cache", ".", "_size", "\n", "self", ".", "_embeddings", "=", "maybe_cache", ".", "_embeddings", "\n", "", "else", ":", "\n", "      ", "self", ".", "_embeddings", "=", "self", ".", "load_embedding_dict", "(", "self", ".", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.size": [[176, 179], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.load_embedding_dict": [[180, 197], ["print", "numpy.zeros", "collections.defaultdict", "len", "print", "open", "enumerate", "f.readlines", "line.find", "numpy.fromstring", "len", "len"], "methods", ["None"], ["", "def", "load_embedding_dict", "(", "self", ",", "path", ")", ":", "\n", "    ", "print", "(", "\"Loading word embeddings from {}...\"", ".", "format", "(", "path", ")", ")", "\n", "default_embedding", "=", "np", ".", "zeros", "(", "self", ".", "size", ")", "\n", "embedding_dict", "=", "collections", ".", "defaultdict", "(", "lambda", ":", "default_embedding", ")", "\n", "if", "len", "(", "path", ")", ">", "0", ":", "\n", "      ", "vocab_size", "=", "None", "\n", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "          ", "word_end", "=", "line", ".", "find", "(", "\" \"", ")", "\n", "word", "=", "line", "[", ":", "word_end", "]", "\n", "embedding", "=", "np", ".", "fromstring", "(", "line", "[", "word_end", "+", "1", ":", "]", ",", "np", ".", "float32", ",", "sep", "=", "\" \"", ")", "\n", "assert", "len", "(", "embedding", ")", "==", "self", ".", "size", "\n", "embedding_dict", "[", "word", "]", "=", "embedding", "\n", "", "", "if", "vocab_size", "is", "not", "None", ":", "\n", "        ", "assert", "vocab_size", "==", "len", "(", "embedding_dict", ")", "\n", "", "print", "(", "\"Done loading word embeddings.\"", ")", "\n", "", "return", "embedding_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.__getitem__": [[198, 203], ["util.EmbeddingDictionary.normalize"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.normalize"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "    ", "embedding", "=", "self", ".", "_embeddings", "[", "key", "]", "\n", "if", "self", ".", "_normalize", ":", "\n", "      ", "embedding", "=", "self", ".", "normalize", "(", "embedding", ")", "\n", "", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.normalize": [[204, 210], ["numpy.linalg.norm"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "v", ")", ":", "\n", "    ", "norm", "=", "np", ".", "linalg", ".", "norm", "(", "v", ")", "\n", "if", "norm", ">", "0", ":", "\n", "      ", "return", "v", "/", "norm", "\n", "", "else", ":", "\n", "      ", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell.__init__": [[212, 220], ["tensorflow.nn.dropout", "util.CustomLSTMCell._block_orthonormal_initializer", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell._block_orthonormal_initializer"], ["  ", "def", "__init__", "(", "self", ",", "num_units", ",", "batch_size", ",", "dropout", ")", ":", "\n", "    ", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_dropout", "=", "dropout", "\n", "self", ".", "_dropout_mask", "=", "tf", ".", "nn", ".", "dropout", "(", "tf", ".", "ones", "(", "[", "batch_size", ",", "self", ".", "output_size", "]", ")", ",", "dropout", ")", "\n", "self", ".", "_initializer", "=", "self", ".", "_block_orthonormal_initializer", "(", "[", "self", ".", "output_size", "]", "*", "3", ")", "\n", "initial_cell_state", "=", "tf", ".", "get_variable", "(", "\"lstm_initial_cell_state\"", ",", "[", "1", ",", "self", ".", "output_size", "]", ")", "\n", "initial_hidden_state", "=", "tf", ".", "get_variable", "(", "\"lstm_initial_hidden_state\"", ",", "[", "1", ",", "self", ".", "output_size", "]", ")", "\n", "self", ".", "_initial_state", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "initial_cell_state", ",", "initial_hidden_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell.state_size": [[221, 224], ["tensorflow.contrib.rnn.LSTMStateTuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "self", ".", "output_size", ",", "self", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell.output_size": [[225, 228], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell.initial_state": [[229, 232], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "initial_state", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_initial_state", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell.__call__": [[233, 245], ["tensorflow.variable_scope", "util.projection", "tensorflow.split", "tensorflow.sigmoid", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.concat", "tensorflow.tanh", "tensorflow.sigmoid", "tensorflow.tanh", "type"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Long short-term memory cell (LSTM).\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"CustomLSTMCell\"", "\n", "      ", "c", ",", "h", "=", "state", "\n", "h", "*=", "self", ".", "_dropout_mask", "\n", "concat", "=", "projection", "(", "tf", ".", "concat", "(", "[", "inputs", ",", "h", "]", ",", "1", ")", ",", "3", "*", "self", ".", "output_size", ",", "initializer", "=", "self", ".", "_initializer", ")", "\n", "i", ",", "j", ",", "o", "=", "tf", ".", "split", "(", "concat", ",", "num_or_size_splits", "=", "3", ",", "axis", "=", "1", ")", "\n", "i", "=", "tf", ".", "sigmoid", "(", "i", ")", "\n", "new_c", "=", "(", "1", "-", "i", ")", "*", "c", "+", "i", "*", "tf", ".", "tanh", "(", "j", ")", "\n", "new_h", "=", "tf", ".", "tanh", "(", "new_c", ")", "*", "tf", ".", "sigmoid", "(", "o", ")", "\n", "new_state", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "new_c", ",", "new_h", ")", "\n", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell._orthonormal_initializer": [[246, 258], ["numpy.random.randn().astype", "numpy.random.randn().astype", "numpy.linalg.qr", "numpy.linalg.qr", "min", "numpy.sign", "numpy.sign", "numpy.dot", "numpy.random.randn", "numpy.random.randn", "numpy.diag", "numpy.diag"], "methods", ["None"], ["", "", "def", "_orthonormal_initializer", "(", "self", ",", "scale", "=", "1.0", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "      ", "M1", "=", "np", ".", "random", ".", "randn", "(", "shape", "[", "0", "]", ",", "shape", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "M2", "=", "np", ".", "random", ".", "randn", "(", "shape", "[", "1", "]", ",", "shape", "[", "1", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "Q1", ",", "R1", "=", "np", ".", "linalg", ".", "qr", "(", "M1", ")", "\n", "Q2", ",", "R2", "=", "np", ".", "linalg", ".", "qr", "(", "M2", ")", "\n", "Q1", "=", "Q1", "*", "np", ".", "sign", "(", "np", ".", "diag", "(", "R1", ")", ")", "\n", "Q2", "=", "Q2", "*", "np", ".", "sign", "(", "np", ".", "diag", "(", "R2", ")", ")", "\n", "n_min", "=", "min", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ")", "\n", "params", "=", "np", ".", "dot", "(", "Q1", "[", ":", ",", ":", "n_min", "]", ",", "Q2", "[", ":", "n_min", ",", ":", "]", ")", "*", "scale", "\n", "return", "params", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell._block_orthonormal_initializer": [[259, 267], ["util.CustomLSTMCell._orthonormal_initializer", "numpy.concatenate", "len", "sum", "util.CustomLSTMCell."], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.CustomLSTMCell._orthonormal_initializer"], ["", "def", "_block_orthonormal_initializer", "(", "self", ",", "output_sizes", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "np", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "      ", "assert", "len", "(", "shape", ")", "==", "2", "\n", "assert", "sum", "(", "output_sizes", ")", "==", "shape", "[", "1", "]", "\n", "initializer", "=", "self", ".", "_orthonormal_initializer", "(", ")", "\n", "params", "=", "np", ".", "concatenate", "(", "[", "initializer", "(", "[", "shape", "[", "0", "]", ",", "o", "]", ",", "dtype", ",", "partition_info", ")", "for", "o", "in", "output_sizes", "]", ",", "1", ")", "\n", "return", "params", "\n", "", "return", "_initializer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.initialize_from_env": [[19, 33], ["print", "util.mkdirs", "print", "pyhocon.ConfigFactory.parse_file", "os.path.join", "pyhocon.HOCONConverter.convert"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.mkdirs"], ["def", "initialize_from_env", "(", ")", ":", "\n", "#if \"GPU\" in os.environ:", "\n", "#  set_gpus(int(os.environ[\"GPU\"]))", "\n", "#else:", "\n", "#  set_gpus()", "\n", "\n", "  ", "name", "=", "sys", ".", "argv", "[", "1", "]", "\n", "print", "(", "\"Running experiment: {}\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "config", "=", "pyhocon", ".", "ConfigFactory", ".", "parse_file", "(", "\"experiments.conf\"", ")", "[", "name", "]", "\n", "config", "[", "\"log_dir\"", "]", "=", "mkdirs", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"log_root\"", "]", ",", "name", ")", ")", "\n", "\n", "print", "(", "pyhocon", ".", "HOCONConverter", ".", "convert", "(", "config", ",", "\"hocon\"", ")", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.copy_checkpoint": [[34, 37], ["shutil.copyfile"], "function", ["None"], ["", "def", "copy_checkpoint", "(", "source", ",", "target", ")", ":", "\n", "  ", "for", "ext", "in", "(", "\".index\"", ",", "\".data-00000-of-00001\"", ")", ":", "\n", "    ", "shutil", ".", "copyfile", "(", "source", "+", "ext", ",", "target", "+", "ext", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.make_summary": [[38, 40], ["tensorflow.Summary", "tensorflow.Summary.Value", "value_dict.items"], "function", ["None"], ["", "", "def", "make_summary", "(", "value_dict", ")", ":", "\n", "  ", "return", "tf", ".", "Summary", "(", "value", "=", "[", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "k", ",", "simple_value", "=", "v", ")", "for", "k", ",", "v", "in", "value_dict", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.flatten": [[41, 43], ["None"], "function", ["None"], ["", "def", "flatten", "(", "l", ")", ":", "\n", "  ", "return", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.set_gpus": [[44, 47], ["print", "str"], "function", ["None"], ["", "def", "set_gpus", "(", "*", "gpus", ")", ":", "\n", "  ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "\",\"", ".", "join", "(", "str", "(", "g", ")", "for", "g", "in", "gpus", ")", "\n", "print", "(", "\"Setting CUDA_VISIBLE_DEVICES to: {}\"", ".", "format", "(", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.mkdirs": [[48, 55], ["os.makedirs"], "function", ["None"], ["", "def", "mkdirs", "(", "path", ")", ":", "\n", "  ", "try", ":", "\n", "    ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", "as", "exception", ":", "\n", "    ", "if", "exception", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "      ", "raise", "\n", "", "", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.load_char_dict": [[56, 63], ["collections.defaultdict", "collections.defaultdict.update", "codecs.open", "vocab.extend", "l.strip", "enumerate", "f.readlines"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update"], ["", "def", "load_char_dict", "(", "char_vocab_path", ")", ":", "\n", "  ", "vocab", "=", "[", "u\"<unk>\"", "]", "\n", "with", "codecs", ".", "open", "(", "char_vocab_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "    ", "vocab", ".", "extend", "(", "l", ".", "strip", "(", ")", "for", "l", "in", "f", ".", "readlines", "(", ")", ")", "\n", "", "char_dict", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "char_dict", ".", "update", "(", "{", "c", ":", "i", "for", "i", ",", "c", "in", "enumerate", "(", "vocab", ")", "}", ")", "\n", "return", "char_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.maybe_divide": [[64, 66], ["float"], "function", ["None"], ["", "def", "maybe_divide", "(", "x", ",", "y", ")", ":", "\n", "  ", "return", "0", "if", "y", "==", "0", "else", "x", "/", "float", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection": [[67, 69], ["util.ffnn"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.ffnn"], ["", "def", "projection", "(", "inputs", ",", "output_size", ",", "initializer", "=", "None", ")", ":", "\n", "  ", "return", "ffnn", "(", "inputs", ",", "0", ",", "-", "1", ",", "output_size", ",", "dropout", "=", "None", ",", "output_weights_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.highway": [[70, 80], ["range", "tensorflow.variable_scope", "tensorflow.split", "tensorflow.sigmoid", "tensorflow.nn.relu", "util.projection", "tensorflow.nn.dropout", "util.shape"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.projection", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "highway", "(", "inputs", ",", "num_layers", ",", "dropout", ")", ":", "\n", "  ", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"highway_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "      ", "j", ",", "f", "=", "tf", ".", "split", "(", "projection", "(", "inputs", ",", "2", "*", "shape", "(", "inputs", ",", "-", "1", ")", ")", ",", "2", ",", "-", "1", ")", "\n", "f", "=", "tf", ".", "sigmoid", "(", "f", ")", "\n", "j", "=", "tf", ".", "nn", ".", "relu", "(", "j", ")", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "        ", "j", "=", "tf", ".", "nn", ".", "dropout", "(", "j", ",", "dropout", ")", "\n", "", "inputs", "=", "f", "*", "j", "+", "(", "1", "-", "f", ")", "*", "inputs", "\n", "", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape": [[81, 83], ["tensorflow.shape", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "shape", "(", "x", ",", "dim", ")", ":", "\n", "  ", "return", "x", ".", "get_shape", "(", ")", "[", "dim", "]", ".", "value", "or", "tf", ".", "shape", "(", "x", ")", "[", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.ffnn": [[84, 112], ["range", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.xw_plus_b", "len", "ValueError", "len", "util.shape", "util.shape", "util.shape", "tensorflow.reshape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "len", "tensorflow.reshape", "inputs.get_shape", "inputs.get_shape", "tensorflow.nn.xw_plus_b", "tensorflow.nn.dropout", "util.shape", "inputs.get_shape", "len", "util.shape", "inputs.get_shape"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "ffnn", "(", "inputs", ",", "num_hidden_layers", ",", "hidden_size", ",", "output_size", ",", "dropout", ",", "output_weights_initializer", "=", "None", ")", ":", "\n", "  ", "if", "len", "(", "inputs", ".", "get_shape", "(", ")", ")", ">", "3", ":", "\n", "    ", "raise", "ValueError", "(", "\"FFNN with rank {} not supported\"", ".", "format", "(", "len", "(", "inputs", ".", "get_shape", "(", ")", ")", ")", ")", "\n", "\n", "", "if", "len", "(", "inputs", ".", "get_shape", "(", ")", ")", "==", "3", ":", "\n", "    ", "batch_size", "=", "shape", "(", "inputs", ",", "0", ")", "\n", "seqlen", "=", "shape", "(", "inputs", ",", "1", ")", "\n", "emb_size", "=", "shape", "(", "inputs", ",", "2", ")", "\n", "current_inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "batch_size", "*", "seqlen", ",", "emb_size", "]", ")", "\n", "", "else", ":", "\n", "    ", "current_inputs", "=", "inputs", "\n", "\n", "", "for", "i", "in", "range", "(", "num_hidden_layers", ")", ":", "\n", "    ", "hidden_weights", "=", "tf", ".", "get_variable", "(", "\"hidden_weights_{}\"", ".", "format", "(", "i", ")", ",", "[", "shape", "(", "current_inputs", ",", "1", ")", ",", "hidden_size", "]", ")", "\n", "hidden_bias", "=", "tf", ".", "get_variable", "(", "\"hidden_bias_{}\"", ".", "format", "(", "i", ")", ",", "[", "hidden_size", "]", ")", "\n", "current_outputs", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "xw_plus_b", "(", "current_inputs", ",", "hidden_weights", ",", "hidden_bias", ")", ")", "\n", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "      ", "current_outputs", "=", "tf", ".", "nn", ".", "dropout", "(", "current_outputs", ",", "dropout", ")", "\n", "", "current_inputs", "=", "current_outputs", "\n", "\n", "", "output_weights", "=", "tf", ".", "get_variable", "(", "\"output_weights\"", ",", "[", "shape", "(", "current_inputs", ",", "1", ")", ",", "output_size", "]", ",", "initializer", "=", "output_weights_initializer", ")", "\n", "output_bias", "=", "tf", ".", "get_variable", "(", "\"output_bias\"", ",", "[", "output_size", "]", ")", "\n", "outputs", "=", "tf", ".", "nn", ".", "xw_plus_b", "(", "current_inputs", ",", "output_weights", ",", "output_bias", ")", "\n", "\n", "if", "len", "(", "inputs", ".", "get_shape", "(", ")", ")", "==", "3", ":", "\n", "    ", "outputs", "=", "tf", ".", "reshape", "(", "outputs", ",", "[", "batch_size", ",", "seqlen", ",", "output_size", "]", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.cnn": [[113, 127], ["util.shape", "util.shape", "util.shape", "enumerate", "tensorflow.concat", "tensorflow.nn.conv1d", "tensorflow.nn.relu", "tensorflow.reduce_max", "outputs.append", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.bias_add"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "cnn", "(", "inputs", ",", "filter_sizes", ",", "num_filters", ")", ":", "\n", "  ", "num_words", "=", "shape", "(", "inputs", ",", "0", ")", "\n", "num_chars", "=", "shape", "(", "inputs", ",", "1", ")", "\n", "input_size", "=", "shape", "(", "inputs", ",", "2", ")", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "filter_size", "in", "enumerate", "(", "filter_sizes", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"conv_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "      ", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "[", "filter_size", ",", "input_size", ",", "num_filters", "]", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "[", "num_filters", "]", ")", "\n", "", "conv", "=", "tf", ".", "nn", ".", "conv1d", "(", "inputs", ",", "w", ",", "stride", "=", "1", ",", "padding", "=", "\"VALID\"", ")", "# [num_words, num_chars - filter_size, num_filters]", "\n", "h", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "b", ")", ")", "# [num_words, num_chars - filter_size, num_filters]", "\n", "pooled", "=", "tf", ".", "reduce_max", "(", "h", ",", "1", ")", "# [num_words, num_filters]", "\n", "outputs", ".", "append", "(", "pooled", ")", "\n", "", "return", "tf", ".", "concat", "(", "outputs", ",", "1", ")", "# [num_words, num_filters * len(filter_sizes)]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.batch_gather": [[128, 141], ["util.shape", "util.shape", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.gather", "len", "util.shape", "len", "tensorflow.squeeze", "emb.get_shape", "tensorflow.range", "emb.get_shape"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape"], ["", "def", "batch_gather", "(", "emb", ",", "indices", ")", ":", "\n", "  ", "batch_size", "=", "shape", "(", "emb", ",", "0", ")", "\n", "seqlen", "=", "shape", "(", "emb", ",", "1", ")", "\n", "if", "len", "(", "emb", ".", "get_shape", "(", ")", ")", ">", "2", ":", "\n", "    ", "emb_size", "=", "shape", "(", "emb", ",", "2", ")", "\n", "", "else", ":", "\n", "    ", "emb_size", "=", "1", "\n", "", "flattened_emb", "=", "tf", ".", "reshape", "(", "emb", ",", "[", "batch_size", "*", "seqlen", ",", "emb_size", "]", ")", "# [batch_size * seqlen, emb]", "\n", "offset", "=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", "*", "seqlen", ",", "1", ")", "# [batch_size, 1]", "\n", "gathered", "=", "tf", ".", "gather", "(", "flattened_emb", ",", "indices", "+", "offset", ")", "# [batch_size, num_indices, emb]", "\n", "if", "len", "(", "emb", ".", "get_shape", "(", ")", ")", "==", "2", ":", "\n", "    ", "gathered", "=", "tf", ".", "squeeze", "(", "gathered", ",", "2", ")", "# [batch_size, num_indices]", "\n", "", "return", "gathered", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.__init__": [[33, 80], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "16", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n          vocab_size: Vocabulary size of `inputs_ids` in `BertModel`.\n          hidden_size: Size of the encoder layers and the pooler layer.\n          num_hidden_layers: Number of hidden layers in the Transformer encoder.\n          num_attention_heads: Number of attention heads for each attention layer in\n            the Transformer encoder.\n          intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n            layer in the Transformer encoder.\n          hidden_act: The non-linear activation function (function or string) in the\n            encoder and pooler.\n          hidden_dropout_prob: The dropout probability for all fully connected\n            layers in the embeddings, encoder, and pooler.\n          attention_probs_dropout_prob: The dropout ratio for the attention\n            probabilities.\n          max_position_embeddings: The maximum sequence length that this model might\n            ever be used with. Typically set this to something large just in case\n            (e.g., 512 or 1024 or 2048).\n          type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n            `BertModel`.\n          initializer_range: The stdev of the truncated_normal_initializer for\n            initializing all weight matrices.\n        \"\"\"", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.from_dict": [[81, 88], ["modeling.BertConfig", "six.iteritems"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size", "=", "None", ")", "\n", "for", "(", "key", ",", "value", ")", "in", "six", ".", "iteritems", "(", "json_object", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.from_json_file": [[89, 95], ["cls.from_dict", "tensorflow.gfile.GFile", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "json_file", ",", "\"r\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.to_dict": [[96, 100], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.to_json_string": [[101, 104], ["json.dumps", "modeling.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.__init__": [[130, 236], ["copy.deepcopy", "modeling.get_shape_list", "tensorflow.ones", "tensorflow.zeros", "tensorflow.variable_scope", "tensorflow.variable_scope", "modeling.embedding_lookup", "modeling.embedding_postprocessor", "tensorflow.variable_scope", "modeling.create_attention_mask_from_input_mask", "modeling.transformer_model", "tensorflow.variable_scope", "tensorflow.squeeze", "tensorflow.layers.dense", "modeling.get_activation", "modeling.create_initializer"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.embedding_lookup", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.embedding_postprocessor", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_attention_mask_from_input_mask", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.transformer_model", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_activation", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "is_training", ",", "\n", "input_ids", ",", "\n", "input_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "use_one_hot_embeddings", "=", "True", ",", "\n", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructor for BertModel.\n\n        Args:\n          config: `BertConfig` instance.\n          is_training: bool. true for training model, false for eval model. Controls\n            whether dropout will be applied.\n          input_ids: int32 Tensor of shape [batch_size, seq_length].\n          input_mask: (optional) int32 Tensor of shape [batch_size, seq_length].\n          token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length].\n          use_one_hot_embeddings: (optional) bool. Whether to use one-hot word\n            embeddings or tf.embedding_lookup() for the word embeddings. On the TPU,\n            it is much faster if this is True, on the CPU or GPU, it is faster if\n            this is False.\n          scope: (optional) variable scope. Defaults to \"bert\".\n\n        Raises:\n          ValueError: The config is invalid or one of the input tensor shapes\n            is invalid.\n        \"\"\"", "\n", "config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "# if not is_training:", "\n", "#     config.hidden_dropout_prob = 0.0", "\n", "#     config.attention_probs_dropout_prob = 0.0", "\n", "\n", "input_shape", "=", "get_shape_list", "(", "input_ids", ",", "expected_rank", "=", "2", ")", "\n", "batch_size", "=", "input_shape", "[", "0", "]", "\n", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "if", "input_mask", "is", "None", ":", "\n", "            ", "input_mask", "=", "tf", ".", "ones", "(", "shape", "=", "[", "batch_size", ",", "seq_length", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "seq_length", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "default_name", "=", "\"bert\"", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"embeddings\"", ")", ":", "\n", "# Perform embedding lookup on the word ids.", "\n", "                ", "(", "self", ".", "embedding_output", ",", "self", ".", "embedding_table", ")", "=", "embedding_lookup", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "vocab_size", "=", "config", ".", "vocab_size", ",", "\n", "embedding_size", "=", "config", ".", "hidden_size", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "word_embedding_name", "=", "\"word_embeddings\"", ",", "\n", "use_one_hot_embeddings", "=", "use_one_hot_embeddings", ")", "\n", "\n", "# Add positional embeddings and token type embeddings, then layer", "\n", "# normalize and perform dropout.", "\n", "self", ".", "embedding_output", "=", "embedding_postprocessor", "(", "\n", "input_tensor", "=", "self", ".", "embedding_output", ",", "\n", "use_token_type", "=", "True", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "token_type_vocab_size", "=", "config", ".", "type_vocab_size", ",", "\n", "token_type_embedding_name", "=", "\"token_type_embeddings\"", ",", "\n", "use_position_embeddings", "=", "True", ",", "\n", "position_embedding_name", "=", "\"position_embeddings\"", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "max_position_embeddings", "=", "config", ".", "max_position_embeddings", ",", "\n", "dropout_prob", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "# This converts a 2D mask of shape [batch_size, seq_length] to a 3D", "\n", "# mask of shape [batch_size, seq_length, seq_length] which is used", "\n", "# for the attention scores.", "\n", "                ", "attention_mask", "=", "create_attention_mask_from_input_mask", "(", "\n", "input_ids", ",", "input_mask", ")", "\n", "\n", "# Run the stacked transformer.", "\n", "# `sequence_output` shape = [batch_size, seq_length, hidden_size].", "\n", "self", ".", "all_encoder_layers", "=", "transformer_model", "(", "\n", "input_tensor", "=", "self", ".", "embedding_output", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "hidden_size", "=", "config", ".", "hidden_size", ",", "\n", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", ",", "\n", "num_attention_heads", "=", "config", ".", "num_attention_heads", ",", "\n", "intermediate_size", "=", "config", ".", "intermediate_size", ",", "\n", "intermediate_act_fn", "=", "get_activation", "(", "config", ".", "hidden_act", ")", ",", "\n", "hidden_dropout_prob", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "attention_probs_dropout_prob", "=", "config", ".", "attention_probs_dropout_prob", ",", "\n", "initializer_range", "=", "config", ".", "initializer_range", ",", "\n", "do_return_all_layers", "=", "True", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n", "", "self", ".", "sequence_output", "=", "self", ".", "all_encoder_layers", "[", "-", "1", "]", "\n", "# The \"pooler\" converts the encoded sequence tensor of shape", "\n", "# [batch_size, seq_length, hidden_size] to a tensor of shape", "\n", "# [batch_size, hidden_size]. This is necessary for segment-level", "\n", "# (or segment-pair-level) classification tasks where we need a fixed", "\n", "# dimensional representation of the segment.", "\n", "with", "tf", ".", "variable_scope", "(", "\"pooler\"", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token. We assume that this has been pre-trained", "\n", "                ", "first_token_tensor", "=", "tf", ".", "squeeze", "(", "self", ".", "sequence_output", "[", ":", ",", "0", ":", "1", ",", ":", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "pooled_output", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "first_token_tensor", ",", "\n", "config", ".", "hidden_size", ",", "\n", "activation", "=", "tf", ".", "tanh", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "config", ".", "initializer_range", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.get_pooled_output": [[237, 239], ["None"], "methods", ["None"], ["", "", "", "def", "get_pooled_output", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.get_sequence_output": [[240, 248], ["None"], "methods", ["None"], ["", "def", "get_sequence_output", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets final hidden layer of encoder.\n\n        Returns:\n          float Tensor of shape [batch_size, seq_length, hidden_size] corresponding\n          to the final hidden of the transformer encoder.\n        \"\"\"", "\n", "return", "self", ".", "sequence_output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.get_all_encoder_layers": [[249, 251], ["None"], "methods", ["None"], ["", "def", "get_all_encoder_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.get_embedding_output": [[252, 262], ["None"], "methods", ["None"], ["", "def", "get_embedding_output", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets output of the embedding lookup (i.e., input to the transformer).\n\n        Returns:\n          float Tensor of shape [batch_size, seq_length, hidden_size] corresponding\n          to the output of the embedding layer, after summing the word\n          embeddings with the positional embeddings and the token type embeddings,\n          then performing layer normalization. This is the input to the transformer.\n        \"\"\"", "\n", "return", "self", ".", "embedding_output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.get_embedding_table": [[263, 265], ["None"], "methods", ["None"], ["", "def", "get_embedding_table", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embedding_table", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.gelu": [[267, 281], ["tensorflow.erf", "tensorflow.sqrt"], "function", ["None"], ["", "", "def", "gelu", "(", "input_tensor", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n\n    Args:\n      input_tensor: float Tensor to perform activation.\n\n    Returns:\n      `input_tensor` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "erf", "(", "input_tensor", "/", "tf", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "input_tensor", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_activation": [[283, 318], ["activation_string.lower", "isinstance", "ValueError"], "function", ["None"], ["", "def", "get_activation", "(", "activation_string", ")", ":", "\n", "    ", "\"\"\"Maps a string to a Python function, e.g., \"relu\" => `tf.nn.relu`.\n\n    Args:\n      activation_string: String name of the activation function.\n\n    Returns:\n      A Python function corresponding to the activation function. If\n      `activation_string` is None, empty, or \"linear\", this will return None.\n      If `activation_string` is not a string, it will return `activation_string`.\n\n    Raises:\n      ValueError: The `activation_string` does not correspond to a known\n        activation.\n    \"\"\"", "\n", "\n", "# We assume that anything that\"s not a string is already an activation", "\n", "# function, so we just return it.", "\n", "if", "not", "isinstance", "(", "activation_string", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "return", "activation_string", "\n", "\n", "", "if", "not", "activation_string", ":", "\n", "        ", "return", "None", "\n", "\n", "", "act", "=", "activation_string", ".", "lower", "(", ")", "\n", "if", "act", "==", "\"linear\"", ":", "\n", "        ", "return", "None", "\n", "", "elif", "act", "==", "\"relu\"", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "relu", "\n", "", "elif", "act", "==", "\"gelu\"", ":", "\n", "        ", "return", "gelu", "\n", "", "elif", "act", "==", "\"tanh\"", ":", "\n", "        ", "return", "tf", ".", "tanh", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported activation: %s\"", "%", "act", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_assignment_map_from_checkpoint": [[320, 345], ["collections.OrderedDict", "tensorflow.train.list_variables", "collections.OrderedDict", "re.match", "re.match.group"], "function", ["None"], ["", "", "def", "get_assignment_map_from_checkpoint", "(", "tvars", ",", "init_checkpoint", ")", ":", "\n", "    ", "\"\"\"Compute the union of the current variables and checkpoint variables.\"\"\"", "\n", "assignment_map", "=", "{", "}", "\n", "initialized_variable_names", "=", "{", "}", "\n", "\n", "name_to_variable", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "var", "in", "tvars", ":", "\n", "        ", "name", "=", "var", ".", "name", "\n", "m", "=", "re", ".", "match", "(", "\"^(.*):\\\\d+$\"", ",", "name", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "            ", "name", "=", "m", ".", "group", "(", "1", ")", "\n", "", "name_to_variable", "[", "name", "]", "=", "var", "\n", "\n", "", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "init_checkpoint", ")", "\n", "\n", "assignment_map", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "x", "in", "init_vars", ":", "\n", "        ", "(", "name", ",", "var", ")", "=", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", "\n", "if", "name", "not", "in", "name_to_variable", ":", "\n", "            ", "continue", "\n", "", "assignment_map", "[", "name", "]", "=", "name", "\n", "initialized_variable_names", "[", "name", "]", "=", "1", "\n", "initialized_variable_names", "[", "name", "+", "\":0\"", "]", "=", "1", "\n", "\n", "", "return", "(", "assignment_map", ",", "initialized_variable_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout": [[347, 363], ["tensorflow.nn.dropout"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout"], ["", "def", "dropout", "(", "input_tensor", ",", "dropout_prob", ")", ":", "\n", "    ", "\"\"\"Perform dropout.\n\n    Args:\n      input_tensor: float Tensor.\n      dropout_prob: Python float. The probability of dropping out a value (NOT of\n        *keeping* a dimension as in `tf.nn.dropout`).\n\n    Returns:\n      A version of `input_tensor` with dropout applied.\n    \"\"\"", "\n", "if", "dropout_prob", "is", "None", "or", "dropout_prob", "==", "0.0", ":", "\n", "        ", "return", "input_tensor", "\n", "\n", "", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "input_tensor", ",", "1.0", "-", "dropout_prob", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm": [[365, 369], ["tensorflow.contrib.layers.layer_norm"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm"], ["", "def", "layer_norm", "(", "input_tensor", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run layer normalization on the last dimension of the tensor.\"\"\"", "\n", "return", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "\n", "inputs", "=", "input_tensor", ",", "begin_norm_axis", "=", "-", "1", ",", "begin_params_axis", "=", "-", "1", ",", "scope", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm_and_dropout": [[371, 376], ["modeling.layer_norm", "tensorflow.layers.dropout"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout"], ["", "def", "layer_norm_and_dropout", "(", "input_tensor", ",", "dropout_prob", ",", "is_training", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Runs layer normalization followed by dropout.\"\"\"", "\n", "output_tensor", "=", "layer_norm", "(", "input_tensor", ",", "name", ")", "\n", "output_tensor", "=", "tf", ".", "layers", ".", "dropout", "(", "output_tensor", ",", "dropout_prob", ",", "training", "=", "is_training", ")", "\n", "return", "output_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer": [[378, 381], ["tensorflow.truncated_normal_initializer"], "function", ["None"], ["", "def", "create_initializer", "(", "initializer_range", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Creates a `truncated_normal_initializer` with the given range.\"\"\"", "\n", "return", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.embedding_lookup": [[383, 430], ["tensorflow.get_variable", "modeling.get_shape_list", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.one_hot", "tensorflow.matmul", "tensorflow.nn.embedding_lookup", "modeling.create_initializer"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.embedding_lookup", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer"], ["", "def", "embedding_lookup", "(", "input_ids", ",", "\n", "vocab_size", ",", "\n", "embedding_size", "=", "128", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "word_embedding_name", "=", "\"word_embeddings\"", ",", "\n", "use_one_hot_embeddings", "=", "False", ")", ":", "\n", "    ", "\"\"\"Looks up words embeddings for id tensor.\n\n    Args:\n      input_ids: int32 Tensor of shape [batch_size, seq_length] containing word\n        ids.\n      vocab_size: int. Size of the embedding vocabulary.\n      embedding_size: int. Width of the word embeddings.\n      initializer_range: float. Embedding initialization range.\n      word_embedding_name: string. Name of the embedding table.\n      use_one_hot_embeddings: bool. If True, use one-hot method for word\n        embeddings. If False, use `tf.nn.embedding_lookup()`. One hot is better\n        for TPUs.\n\n    Returns:\n      float Tensor of shape [batch_size, seq_length, embedding_size].\n    \"\"\"", "\n", "# This function assumes that the input is of shape [batch_size, seq_length,", "\n", "# num_inputs].", "\n", "#", "\n", "# If the input is a 2D tensor of shape [batch_size, seq_length], we", "\n", "# reshape to [batch_size, seq_length, 1].", "\n", "if", "input_ids", ".", "shape", ".", "ndims", "==", "2", ":", "\n", "        ", "input_ids", "=", "tf", ".", "expand_dims", "(", "input_ids", ",", "axis", "=", "[", "-", "1", "]", ")", "\n", "\n", "", "embedding_table", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "word_embedding_name", ",", "\n", "shape", "=", "[", "vocab_size", ",", "embedding_size", "]", ",", "\n", "initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "\n", "if", "use_one_hot_embeddings", ":", "\n", "        ", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", "]", ")", "\n", "one_hot_input_ids", "=", "tf", ".", "one_hot", "(", "flat_input_ids", ",", "depth", "=", "vocab_size", ")", "\n", "output", "=", "tf", ".", "matmul", "(", "one_hot_input_ids", ",", "embedding_table", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding_table", ",", "input_ids", ")", "\n", "\n", "", "input_shape", "=", "get_shape_list", "(", "input_ids", ")", "\n", "\n", "output", "=", "tf", ".", "reshape", "(", "output", ",", "\n", "input_shape", "[", "0", ":", "-", "1", "]", "+", "[", "input_shape", "[", "-", "1", "]", "*", "embedding_size", "]", ")", "\n", "return", "(", "output", ",", "embedding_table", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.embedding_postprocessor": [[432, 527], ["modeling.get_shape_list", "modeling.layer_norm_and_dropout", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.one_hot", "tensorflow.matmul", "tensorflow.reshape", "tensorflow.assert_less_equal", "ValueError", "tensorflow.control_dependencies", "tensorflow.get_variable", "tensorflow.slice", "len", "range", "position_broadcast_shape.extend", "tensorflow.reshape", "modeling.create_initializer", "layer_norm_and_dropout.shape.as_list", "position_broadcast_shape.append", "modeling.create_initializer"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm_and_dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer"], ["", "def", "embedding_postprocessor", "(", "input_tensor", ",", "\n", "use_token_type", "=", "False", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "token_type_vocab_size", "=", "16", ",", "\n", "token_type_embedding_name", "=", "\"token_type_embeddings\"", ",", "\n", "use_position_embeddings", "=", "True", ",", "\n", "position_embedding_name", "=", "\"position_embeddings\"", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "dropout_prob", "=", "0.1", ",", "\n", "is_training", "=", "True", ")", ":", "\n", "    ", "\"\"\"Performs various post-processing on a word embedding tensor.\n\n    Args:\n      input_tensor: float Tensor of shape [batch_size, seq_length,\n        embedding_size].\n      use_token_type: bool. Whether to add embeddings for `token_type_ids`.\n      token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length].\n        Must be specified if `use_token_type` is True.\n      token_type_vocab_size: int. The vocabulary size of `token_type_ids`.\n      token_type_embedding_name: string. The name of the embedding table variable\n        for token type ids.\n      use_position_embeddings: bool. Whether to add position embeddings for the\n        position of each token in the sequence.\n      position_embedding_name: string. The name of the embedding table variable\n        for positional embeddings.\n      initializer_range: float. Range of the weight initialization.\n      max_position_embeddings: int. Maximum sequence length that might ever be\n        used with this model. This can be longer than the sequence length of\n        input_tensor, but cannot be shorter.\n      dropout_prob: float. Dropout probability applied to the final output tensor.\n\n    Returns:\n      float tensor with same shape as `input_tensor`.\n\n    Raises:\n      ValueError: One of the tensor shapes or input values is invalid.\n    \"\"\"", "\n", "input_shape", "=", "get_shape_list", "(", "input_tensor", ",", "expected_rank", "=", "3", ")", "\n", "batch_size", "=", "input_shape", "[", "0", "]", "\n", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "width", "=", "input_shape", "[", "2", "]", "\n", "\n", "output", "=", "input_tensor", "\n", "\n", "if", "use_token_type", ":", "\n", "        ", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"`token_type_ids` must be specified if\"", "\n", "\"`use_token_type` is True.\"", ")", "\n", "", "token_type_table", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "token_type_embedding_name", ",", "\n", "shape", "=", "[", "token_type_vocab_size", ",", "width", "]", ",", "\n", "initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "# This vocab will be small so we always do one-hot here, since it is always", "\n", "# faster for a small vocabulary.", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", "]", ")", "\n", "one_hot_ids", "=", "tf", ".", "one_hot", "(", "flat_token_type_ids", ",", "depth", "=", "token_type_vocab_size", ")", "\n", "token_type_embeddings", "=", "tf", ".", "matmul", "(", "one_hot_ids", ",", "token_type_table", ")", "\n", "token_type_embeddings", "=", "tf", ".", "reshape", "(", "token_type_embeddings", ",", "\n", "[", "batch_size", ",", "seq_length", ",", "width", "]", ")", "\n", "output", "+=", "token_type_embeddings", "\n", "\n", "", "if", "use_position_embeddings", ":", "\n", "        ", "assert_op", "=", "tf", ".", "assert_less_equal", "(", "seq_length", ",", "max_position_embeddings", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assert_op", "]", ")", ":", "\n", "            ", "full_position_embeddings", "=", "tf", ".", "get_variable", "(", "\n", "name", "=", "position_embedding_name", ",", "\n", "shape", "=", "[", "max_position_embeddings", ",", "width", "]", ",", "\n", "initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "# Since the position embedding table is a learned variable, we create it", "\n", "# using a (long) sequence length `max_position_embeddings`. The actual", "\n", "# sequence length might be shorter than this, for faster training of", "\n", "# tasks that do not have long sequences.", "\n", "#", "\n", "# So `full_position_embeddings` is effectively an embedding table", "\n", "# for position [0, 1, 2, ..., max_position_embeddings-1], and the current", "\n", "# sequence has positions [0, 1, 2, ... seq_length-1], so we can just", "\n", "# perform a slice.", "\n", "position_embeddings", "=", "tf", ".", "slice", "(", "full_position_embeddings", ",", "[", "0", ",", "0", "]", ",", "\n", "[", "seq_length", ",", "-", "1", "]", ")", "\n", "num_dims", "=", "len", "(", "output", ".", "shape", ".", "as_list", "(", ")", ")", "\n", "\n", "# Only the last two dimensions are relevant (`seq_length` and `width`), so", "\n", "# we broadcast among the first dimensions, which is typically just", "\n", "# the batch size.", "\n", "position_broadcast_shape", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_dims", "-", "2", ")", ":", "\n", "                ", "position_broadcast_shape", ".", "append", "(", "1", ")", "\n", "", "position_broadcast_shape", ".", "extend", "(", "[", "seq_length", ",", "width", "]", ")", "\n", "position_embeddings", "=", "tf", ".", "reshape", "(", "position_embeddings", ",", "\n", "position_broadcast_shape", ")", "\n", "output", "+=", "position_embeddings", "\n", "\n", "", "", "output", "=", "layer_norm_and_dropout", "(", "output", ",", "dropout_prob", ",", "is_training", "=", "is_training", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_attention_mask_from_input_mask": [[529, 561], ["modeling.get_shape_list", "modeling.get_shape_list", "tensorflow.cast", "tensorflow.ones", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list"], ["", "def", "create_attention_mask_from_input_mask", "(", "from_tensor", ",", "to_mask", ")", ":", "\n", "    ", "\"\"\"Create 3D attention mask from a 2D tensor mask.\n\n    Args:\n      from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].\n      to_mask: int32 Tensor of shape [batch_size, to_seq_length].\n\n    Returns:\n      float Tensor of shape [batch_size, from_seq_length, to_seq_length].\n    \"\"\"", "\n", "from_shape", "=", "get_shape_list", "(", "from_tensor", ",", "expected_rank", "=", "[", "2", ",", "3", "]", ")", "\n", "batch_size", "=", "from_shape", "[", "0", "]", "\n", "from_seq_length", "=", "from_shape", "[", "1", "]", "\n", "\n", "to_shape", "=", "get_shape_list", "(", "to_mask", ",", "expected_rank", "=", "2", ")", "\n", "to_seq_length", "=", "to_shape", "[", "1", "]", "\n", "\n", "to_mask", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "reshape", "(", "to_mask", ",", "[", "batch_size", ",", "1", ",", "to_seq_length", "]", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "# We don't assume that `from_tensor` is a mask (although it could be). We", "\n", "# don't actually care if we attend *from* padding tokens (only *to* padding)", "\n", "# tokens so we create a tensor of all ones.", "\n", "#", "\n", "# `broadcast_ones` = [batch_size, from_seq_length, 1]", "\n", "broadcast_ones", "=", "tf", ".", "ones", "(", "\n", "shape", "=", "[", "batch_size", ",", "from_seq_length", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Here we broadcast along two dimensions to create the mask.", "\n", "mask", "=", "broadcast_ones", "*", "to_mask", "\n", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.attention_scores_layer": [[563, 711], ["modeling.get_shape_list", "modeling.get_shape_list", "modeling.reshape_to_matrix", "modeling.reshape_to_matrix", "tensorflow.layers.dense", "modeling.attention_scores_layer.transpose_for_scores"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_to_matrix", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_to_matrix"], ["", "def", "attention_scores_layer", "(", "from_tensor", ",", "\n", "to_tensor", ",", "\n", "attention_mask", "=", "None", ",", "\n", "num_attention_heads", "=", "1", ",", "\n", "size_per_head", "=", "512", ",", "\n", "query_act", "=", "None", ",", "\n", "key_act", "=", "None", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "batch_size", "=", "None", ",", "\n", "from_seq_length", "=", "None", ",", "\n", "to_seq_length", "=", "None", ",", "\n", "query_equals_key", "=", "False", ",", "\n", "return_features", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate multi-headed attention probabilities from `from_tensor` to `to_tensor`.\n\n    This is an implementation of multi-headed attention based on \"Attention\n    is all you Need\". If `from_tensor` and `to_tensor` are the same, then\n    this is self-attention. Each timestep in `from_tensor` attends to the\n    corresponding sequence in `to_tensor`, and returns a fixed-with vector.\n\n    This function first projects `from_tensor` into a \"query\" tensor and\n    `to_tensor` into \"key\" and \"value\" tensors. These are (effectively) a list\n    of tensors of length `num_attention_heads`, where each tensor is of shape\n    [batch_size, seq_length, size_per_head].\n\n    Then, the query and key tensors are dot-producted and scaled. These are\n    softmaxed to obtain attention probabilities. The value tensors are then\n    interpolated by these probabilities, then concatenated back to a single\n    tensor and returned.\n\n    In practice, the multi-headed attention are done with transposes and\n    reshapes rather than actual separate tensors.\n\n    Args:\n      from_tensor: float Tensor of shape [batch_size, from_seq_length,\n        from_width].\n      to_tensor: float Tensor of shape [batch_size, to_seq_length, to_width].\n      attention_mask: (optional) int32 Tensor of shape [batch_size,\n        from_seq_length, to_seq_length]. The values should be 1 or 0. The\n        attention scores will effectively be set to -infinity for any positions in\n        the mask that are 0, and will be unchanged for positions that are 1.\n      num_attention_heads: int. Number of attention heads.\n      size_per_head: int. Size of each attention head.\n      query_act: (optional) Activation function for the query transform.\n      key_act: (optional) Activation function for the key transform.\n      initializer_range: float. Range of the weight initializer.\n      batch_size: (Optional) int. If the input is 2D, this might be the batch size\n        of the 3D version of the `from_tensor` and `to_tensor`.\n      from_seq_length: (Optional) If the input is 2D, this might be the seq length\n        of the 3D version of the `from_tensor`.\n      to_seq_length: (Optional) If the input is 2D, this might be the seq length\n        of the 3D version of the `to_tensor`.\n\n    Returns:\n      float Tensor of shape [batch_size, num_attention_heads, from_seq_length, to_seq_length].\n\n    Raises:\n      ValueError: Any of the arguments or tensor shapes are invalid.\n    \"\"\"", "\n", "\n", "def", "transpose_for_scores", "(", "input_tensor", ",", "batch_size", ",", "num_attention_heads", ",", "\n", "seq_length", ",", "width", ")", ":", "\n", "        ", "output_tensor", "=", "tf", ".", "reshape", "(", "\n", "input_tensor", ",", "[", "batch_size", ",", "seq_length", ",", "num_attention_heads", ",", "width", "]", ")", "\n", "\n", "output_tensor", "=", "tf", ".", "transpose", "(", "output_tensor", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "return", "output_tensor", "\n", "\n", "", "from_shape", "=", "get_shape_list", "(", "from_tensor", ",", "expected_rank", "=", "[", "2", ",", "3", "]", ")", "\n", "to_shape", "=", "get_shape_list", "(", "to_tensor", ",", "expected_rank", "=", "[", "2", ",", "3", "]", ")", "\n", "\n", "if", "len", "(", "from_shape", ")", "!=", "len", "(", "to_shape", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"The rank of `from_tensor` must match the rank of `to_tensor`.\"", ")", "\n", "\n", "", "if", "len", "(", "from_shape", ")", "==", "3", ":", "\n", "        ", "batch_size", "=", "from_shape", "[", "0", "]", "\n", "from_seq_length", "=", "from_shape", "[", "1", "]", "\n", "to_seq_length", "=", "to_shape", "[", "1", "]", "\n", "", "elif", "len", "(", "from_shape", ")", "==", "2", ":", "\n", "        ", "if", "(", "batch_size", "is", "None", "or", "from_seq_length", "is", "None", "or", "to_seq_length", "is", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"When passing in rank 2 tensors to attention_layer, the values \"", "\n", "\"for `batch_size`, `from_seq_length`, and `to_seq_length` \"", "\n", "\"must all be specified.\"", ")", "\n", "\n", "# Scalar dimensions referenced here:", "\n", "#   B = batch size (number of sequences)", "\n", "#   F = `from_tensor` sequence length", "\n", "#   T = `to_tensor` sequence length", "\n", "#   N = `num_attention_heads`", "\n", "#   H = `size_per_head`", "\n", "\n", "", "", "from_tensor_2d", "=", "reshape_to_matrix", "(", "from_tensor", ")", "\n", "to_tensor_2d", "=", "reshape_to_matrix", "(", "to_tensor", ")", "\n", "\n", "# `query_layer` = [B*F, N*H]", "\n", "query_layer", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "from_tensor_2d", ",", "\n", "num_attention_heads", "*", "size_per_head", ",", "\n", "activation", "=", "query_act", ",", "\n", "name", "=", "\"query\"", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "\n", "# `key_layer` = [B*T, N*H]", "\n", "if", "query_equals_key", ":", "\n", "        ", "key_layer", "=", "query_layer", "\n", "", "else", ":", "\n", "        ", "key_layer", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "to_tensor_2d", ",", "\n", "num_attention_heads", "*", "size_per_head", ",", "\n", "activation", "=", "key_act", ",", "\n", "name", "=", "\"key\"", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "\n", "# `query_layer` = [B, N, F, H]", "\n", "", "query_layer", "=", "transpose_for_scores", "(", "query_layer", ",", "batch_size", ",", "\n", "num_attention_heads", ",", "from_seq_length", ",", "\n", "size_per_head", ")", "\n", "\n", "# `key_layer` = [B, N, T, H]", "\n", "key_layer", "=", "transpose_for_scores", "(", "key_layer", ",", "batch_size", ",", "num_attention_heads", ",", "\n", "to_seq_length", ",", "size_per_head", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw", "\n", "# attention scores.", "\n", "# `attention_scores` = [B, N, F, T]", "\n", "attention_scores", "=", "tf", ".", "matmul", "(", "query_layer", ",", "key_layer", ",", "transpose_b", "=", "True", ")", "\n", "attention_scores", "=", "tf", ".", "multiply", "(", "attention_scores", ",", "\n", "1.0", "/", "math", ".", "sqrt", "(", "float", "(", "size_per_head", ")", ")", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# `attention_mask` = [B, 1, F, T]", "\n", "        ", "attention_mask", "=", "tf", ".", "expand_dims", "(", "attention_mask", ",", "axis", "=", "[", "1", "]", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "adder", "=", "(", "1.0", "-", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", ")", "*", "-", "10000.0", "\n", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_scores", "=", "attention_scores", "*", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "+", "adder", "\n", "\n", "", "if", "return_features", ":", "\n", "        ", "return", "attention_scores", ",", "query_layer", ",", "key_layer", "\n", "", "else", ":", "\n", "        ", "return", "attention_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.attention_layer": [[713, 843], ["modeling.reshape_to_matrix", "tensorflow.layers.dense", "modeling.attention_scores_layer", "tensorflow.nn.softmax", "tensorflow.layers.dropout", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "modeling.create_initializer"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_to_matrix", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.attention_scores_layer", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer"], ["", "", "def", "attention_layer", "(", "from_tensor", ",", "\n", "to_tensor", ",", "\n", "attention_mask", "=", "None", ",", "\n", "num_attention_heads", "=", "1", ",", "\n", "size_per_head", "=", "512", ",", "\n", "query_act", "=", "None", ",", "\n", "key_act", "=", "None", ",", "\n", "value_act", "=", "None", ",", "\n", "attention_probs_dropout_prob", "=", "0.0", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "do_return_2d_tensor", "=", "False", ",", "\n", "batch_size", "=", "None", ",", "\n", "from_seq_length", "=", "None", ",", "\n", "to_seq_length", "=", "None", ",", "\n", "is_training", "=", "True", ")", ":", "\n", "    ", "\"\"\"Performs multi-headed attention from `from_tensor` to `to_tensor`.\n\n    This is an implementation of multi-headed attention based on \"Attention\n    is all you Need\". If `from_tensor` and `to_tensor` are the same, then\n    this is self-attention. Each timestep in `from_tensor` attends to the\n    corresponding sequence in `to_tensor`, and returns a fixed-with vector.\n\n    This function first projects `from_tensor` into a \"query\" tensor and\n    `to_tensor` into \"key\" and \"value\" tensors. These are (effectively) a list\n    of tensors of length `num_attention_heads`, where each tensor is of shape\n    [batch_size, seq_length, size_per_head].\n\n    Then, the query and key tensors are dot-producted and scaled. These are\n    softmaxed to obtain attention probabilities. The value tensors are then\n    interpolated by these probabilities, then concatenated back to a single\n    tensor and returned.\n\n    In practice, the multi-headed attention are done with transposes and\n    reshapes rather than actual separate tensors.\n\n    Args:\n      from_tensor: float Tensor of shape [batch_size, from_seq_length,\n        from_width].\n      to_tensor: float Tensor of shape [batch_size, to_seq_length, to_width].\n      attention_mask: (optional) int32 Tensor of shape [batch_size,\n        from_seq_length, to_seq_length]. The values should be 1 or 0. The\n        attention scores will effectively be set to -infinity for any positions in\n        the mask that are 0, and will be unchanged for positions that are 1.\n      num_attention_heads: int. Number of attention heads.\n      size_per_head: int. Size of each attention head.\n      query_act: (optional) Activation function for the query transform.\n      key_act: (optional) Activation function for the key transform.\n      value_act: (optional) Activation function for the value transform.\n      attention_probs_dropout_prob: (optional) float. Dropout probability of the\n        attention probabilities.\n      initializer_range: float. Range of the weight initializer.\n      do_return_2d_tensor: bool. If True, the output will be of shape [batch_size\n        * from_seq_length, num_attention_heads * size_per_head]. If False, the\n        output will be of shape [batch_size, from_seq_length, num_attention_heads\n        * size_per_head].\n      batch_size: (Optional) int. If the input is 2D, this might be the batch size\n        of the 3D version of the `from_tensor` and `to_tensor`.\n      from_seq_length: (Optional) If the input is 2D, this might be the seq length\n        of the 3D version of the `from_tensor`.\n      to_seq_length: (Optional) If the input is 2D, this might be the seq length\n        of the 3D version of the `to_tensor`.\n\n    Returns:\n      float Tensor of shape [batch_size, from_seq_length,\n        num_attention_heads * size_per_head]. (If `do_return_2d_tensor` is\n        true, this will be of shape [batch_size * from_seq_length,\n        num_attention_heads * size_per_head]).\n\n    Raises:\n      ValueError: Any of the arguments or tensor shapes are invalid.\n    \"\"\"", "\n", "\n", "to_tensor_2d", "=", "reshape_to_matrix", "(", "to_tensor", ")", "\n", "\n", "# `value_layer` = [B*T, N*H]", "\n", "value_layer", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "to_tensor_2d", ",", "\n", "num_attention_heads", "*", "size_per_head", ",", "\n", "activation", "=", "value_act", ",", "\n", "name", "=", "\"value\"", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "# `attention_probs` = [B, N, F, T]", "\n", "attention_scores", "=", "attention_scores_layer", "(", "from_tensor", ",", "\n", "to_tensor", ",", "\n", "attention_mask", ",", "\n", "num_attention_heads", ",", "\n", "size_per_head", ",", "\n", "query_act", ",", "\n", "key_act", ",", "\n", "initializer_range", ",", "\n", "batch_size", ",", "\n", "from_seq_length", ",", "\n", "to_seq_length", ")", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "# `attention_probs` = [B, N, F, T]", "\n", "attention_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "tf", ".", "layers", ".", "dropout", "(", "attention_probs", ",", "attention_probs_dropout_prob", ",", "training", "=", "is_training", ")", "\n", "\n", "# `value_layer` = [B, T, N, H]", "\n", "value_layer", "=", "tf", ".", "reshape", "(", "\n", "value_layer", ",", "\n", "[", "batch_size", ",", "to_seq_length", ",", "num_attention_heads", ",", "size_per_head", "]", ")", "\n", "\n", "# `value_layer` = [B, N, T, H]", "\n", "value_layer", "=", "tf", ".", "transpose", "(", "value_layer", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n", "# `context_layer` = [B, N, F, H]", "\n", "context_layer", "=", "tf", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "# `context_layer` = [B, F, N, H]", "\n", "context_layer", "=", "tf", ".", "transpose", "(", "context_layer", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n", "if", "do_return_2d_tensor", ":", "\n", "# `context_layer` = [B*F, N*H]", "\n", "        ", "context_layer", "=", "tf", ".", "reshape", "(", "\n", "context_layer", ",", "\n", "[", "batch_size", "*", "from_seq_length", ",", "num_attention_heads", "*", "size_per_head", "]", ")", "\n", "", "else", ":", "\n", "# `context_layer` = [B, F, N*H]", "\n", "        ", "context_layer", "=", "tf", ".", "reshape", "(", "\n", "context_layer", ",", "\n", "[", "batch_size", ",", "from_seq_length", ",", "num_attention_heads", "*", "size_per_head", "]", ")", "\n", "\n", "", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.transformer_model": [[845, 986], ["int", "modeling.get_shape_list", "modeling.reshape_to_matrix", "range", "ValueError", "ValueError", "modeling.reshape_from_matrix", "tensorflow.variable_scope", "modeling.reshape_from_matrix", "final_outputs.append", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "modeling.layer_norm", "all_layer_outputs.append", "tensorflow.variable_scope", "modeling.attention_layer", "attention_heads.append", "len", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dropout", "modeling.layer_norm", "modeling.create_initializer", "modeling.create_initializer", "modeling.create_initializer"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_to_matrix", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_from_matrix", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_from_matrix", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.attention_layer", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.dropout", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.layer_norm", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.create_initializer"], ["", "def", "transformer_model", "(", "input_tensor", ",", "\n", "attention_mask", "=", "None", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "intermediate_act_fn", "=", "gelu", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "do_return_all_layers", "=", "False", ",", "\n", "is_training", "=", "True", ")", ":", "\n", "    ", "\"\"\"Multi-headed, multi-layer Transformer from \"Attention is All You Need\".\n\n    This is almost an exact implementation of the original Transformer encoder.\n\n    See the original paper:\n    https://arxiv.org/abs/1706.03762\n\n    Also see:\n    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py\n\n    Args:\n      input_tensor: float Tensor of shape [batch_size, seq_length, hidden_size].\n      attention_mask: (optional) int32 Tensor of shape [batch_size, seq_length,\n        seq_length], with 1 for positions that can be attended to and 0 in\n        positions that should not be.\n      hidden_size: int. Hidden size of the Transformer.\n      num_hidden_layers: int. Number of layers (blocks) in the Transformer.\n      num_attention_heads: int. Number of attention heads in the Transformer.\n      intermediate_size: int. The size of the \"intermediate\" (a.k.a., feed\n        forward) layer.\n      intermediate_act_fn: function. The non-linear activation function to apply\n        to the output of the intermediate/feed-forward layer.\n      hidden_dropout_prob: float. Dropout probability for the hidden layers.\n      attention_probs_dropout_prob: float. Dropout probability of the attention\n        probabilities.\n      initializer_range: float. Range of the initializer (stddev of truncated\n        normal).\n      do_return_all_layers: Whether to also return all layers or just the final\n        layer.\n\n    Returns:\n      float Tensor of shape [batch_size, seq_length, hidden_size], the final\n      hidden layer of the Transformer.\n\n    Raises:\n      ValueError: A Tensor shape or parameter is invalid.\n    \"\"\"", "\n", "if", "hidden_size", "%", "num_attention_heads", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "hidden_size", ",", "num_attention_heads", ")", ")", "\n", "\n", "", "attention_head_size", "=", "int", "(", "hidden_size", "/", "num_attention_heads", ")", "\n", "input_shape", "=", "get_shape_list", "(", "input_tensor", ",", "expected_rank", "=", "3", ")", "\n", "batch_size", "=", "input_shape", "[", "0", "]", "\n", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "input_width", "=", "input_shape", "[", "2", "]", "\n", "\n", "# The Transformer performs sum residuals on all layers so the input needs", "\n", "# to be the same as the hidden size.", "\n", "if", "input_width", "!=", "hidden_size", ":", "\n", "        ", "raise", "ValueError", "(", "\"The width of the input tensor (%d) != hidden size (%d)\"", "%", "\n", "(", "input_width", ",", "hidden_size", ")", ")", "\n", "\n", "# We keep the representation as a 2D tensor to avoid re-shaping it back and", "\n", "# forth from a 3D tensor to a 2D tensor. Re-shapes are normally free on", "\n", "# the GPU/CPU but may not be free on the TPU, so we want to minimize them to", "\n", "# help the optimizer.", "\n", "", "prev_output", "=", "reshape_to_matrix", "(", "input_tensor", ")", "\n", "\n", "all_layer_outputs", "=", "[", "]", "\n", "for", "layer_idx", "in", "range", "(", "num_hidden_layers", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "layer_idx", ")", ":", "\n", "            ", "layer_input", "=", "prev_output", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"attention\"", ")", ":", "\n", "                ", "attention_heads", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"self\"", ")", ":", "\n", "                    ", "attention_head", "=", "attention_layer", "(", "\n", "from_tensor", "=", "layer_input", ",", "\n", "to_tensor", "=", "layer_input", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "num_attention_heads", "=", "num_attention_heads", ",", "\n", "size_per_head", "=", "attention_head_size", ",", "\n", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", ",", "\n", "initializer_range", "=", "initializer_range", ",", "\n", "do_return_2d_tensor", "=", "True", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "from_seq_length", "=", "seq_length", ",", "\n", "to_seq_length", "=", "seq_length", ",", "\n", "is_training", "=", "is_training", ")", "\n", "attention_heads", ".", "append", "(", "attention_head", ")", "\n", "\n", "", "attention_output", "=", "None", "\n", "if", "len", "(", "attention_heads", ")", "==", "1", ":", "\n", "                    ", "attention_output", "=", "attention_heads", "[", "0", "]", "\n", "", "else", ":", "\n", "# In the case where we have other sequences, we just concatenate", "\n", "# them to the self-attention head before the projection.", "\n", "                    ", "attention_output", "=", "tf", ".", "concat", "(", "attention_heads", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Run a linear projection of `hidden_size` then add a residual", "\n", "# with `layer_input`.", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output\"", ")", ":", "\n", "                    ", "attention_output", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "attention_output", ",", "\n", "hidden_size", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "attention_output", "=", "tf", ".", "layers", ".", "dropout", "(", "attention_output", ",", "hidden_dropout_prob", ",", "training", "=", "is_training", ")", "\n", "attention_output", "=", "layer_norm", "(", "attention_output", "+", "layer_input", ")", "\n", "\n", "# The activation is only applied to the \"intermediate\" hidden layer.", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"intermediate\"", ")", ":", "\n", "                ", "intermediate_output", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "attention_output", ",", "\n", "intermediate_size", ",", "\n", "activation", "=", "intermediate_act_fn", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "\n", "# Down-project back to `hidden_size` then add the residual.", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"output\"", ")", ":", "\n", "                ", "layer_output", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "intermediate_output", ",", "\n", "hidden_size", ",", "\n", "kernel_initializer", "=", "create_initializer", "(", "initializer_range", ")", ")", "\n", "layer_output", "=", "tf", ".", "layers", ".", "dropout", "(", "layer_output", ",", "hidden_dropout_prob", ",", "training", "=", "is_training", ")", "\n", "layer_output", "=", "layer_norm", "(", "layer_output", "+", "attention_output", ")", "\n", "prev_output", "=", "layer_output", "\n", "all_layer_outputs", ".", "append", "(", "layer_output", ")", "\n", "\n", "", "", "", "if", "do_return_all_layers", ":", "\n", "        ", "final_outputs", "=", "[", "]", "\n", "for", "layer_output", "in", "all_layer_outputs", ":", "\n", "            ", "final_output", "=", "reshape_from_matrix", "(", "layer_output", ",", "input_shape", ")", "\n", "final_outputs", ".", "append", "(", "final_output", ")", "\n", "", "return", "final_outputs", "\n", "", "else", ":", "\n", "        ", "final_output", "=", "reshape_from_matrix", "(", "prev_output", ",", "input_shape", ")", "\n", "return", "final_output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list": [[988, 1023], ["tensor.shape.as_list", "enumerate", "tensorflow.shape", "modeling.assert_rank", "non_static_indexes.append"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.shape", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.assert_rank"], ["", "", "def", "get_shape_list", "(", "tensor", ",", "expected_rank", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n\n    Args:\n      tensor: A tf.Tensor object to find the shape of.\n      expected_rank: (optional) int. The expected rank of `tensor`. If this is\n        specified and the `tensor` has a different rank, and exception will be\n        thrown.\n      name: Optional name of the tensor for the error message.\n\n    Returns:\n      A list of dimensions of the shape of tensor. All static dimensions will\n      be returned as python integers, and dynamic dimensions will be returned\n      as tf.Tensor scalars.\n    \"\"\"", "\n", "if", "name", "is", "None", ":", "\n", "        ", "name", "=", "tensor", ".", "name", "\n", "\n", "", "if", "expected_rank", "is", "not", "None", ":", "\n", "        ", "assert_rank", "(", "tensor", ",", "expected_rank", ",", "name", ")", "\n", "\n", "", "shape", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "\n", "\n", "non_static_indexes", "=", "[", "]", "\n", "for", "(", "index", ",", "dim", ")", "in", "enumerate", "(", "shape", ")", ":", "\n", "        ", "if", "dim", "is", "None", ":", "\n", "            ", "non_static_indexes", ".", "append", "(", "index", ")", "\n", "\n", "", "", "if", "not", "non_static_indexes", ":", "\n", "        ", "return", "shape", "\n", "\n", "", "dyn_shape", "=", "tf", ".", "shape", "(", "tensor", ")", "\n", "for", "index", "in", "non_static_indexes", ":", "\n", "        ", "shape", "[", "index", "]", "=", "dyn_shape", "[", "index", "]", "\n", "", "return", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_to_matrix": [[1025, 1037], ["tensorflow.reshape", "ValueError"], "function", ["None"], ["", "def", "reshape_to_matrix", "(", "input_tensor", ")", ":", "\n", "    ", "\"\"\"Reshapes a >= rank 2 tensor to a rank 2 tensor (i.e., a matrix).\"\"\"", "\n", "ndims", "=", "input_tensor", ".", "shape", ".", "ndims", "\n", "if", "ndims", "<", "2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Input tensor must have at least rank 2. Shape = %s\"", "%", "\n", "(", "input_tensor", ".", "shape", ")", ")", "\n", "", "if", "ndims", "==", "2", ":", "\n", "        ", "return", "input_tensor", "\n", "\n", "", "width", "=", "input_tensor", ".", "shape", "[", "-", "1", "]", "\n", "output_tensor", "=", "tf", ".", "reshape", "(", "input_tensor", ",", "[", "-", "1", ",", "width", "]", ")", "\n", "return", "output_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.reshape_from_matrix": [[1039, 1050], ["modeling.get_shape_list", "tensorflow.reshape", "len"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_shape_list"], ["", "def", "reshape_from_matrix", "(", "output_tensor", ",", "orig_shape_list", ")", ":", "\n", "    ", "\"\"\"Reshapes a rank 2 tensor back to its original rank >= 2 tensor.\"\"\"", "\n", "if", "len", "(", "orig_shape_list", ")", "==", "2", ":", "\n", "        ", "return", "output_tensor", "\n", "\n", "", "output_shape", "=", "get_shape_list", "(", "output_tensor", ")", "\n", "\n", "orig_dims", "=", "orig_shape_list", "[", "0", ":", "-", "1", "]", "\n", "width", "=", "output_shape", "[", "-", "1", "]", "\n", "\n", "return", "tf", ".", "reshape", "(", "output_tensor", ",", "orig_dims", "+", "[", "width", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.assert_rank": [[1052, 1080], ["isinstance", "ValueError", "tensorflow.get_variable_scope", "str", "str"], "function", ["None"], ["", "def", "assert_rank", "(", "tensor", ",", "expected_rank", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Raises an exception if the tensor rank is not of the expected rank.\n\n    Args:\n      tensor: A tf.Tensor to check the rank of.\n      expected_rank: Python integer or list of integers, expected rank.\n      name: Optional name of the tensor for the error message.\n\n    Raises:\n      ValueError: If the expected shape doesn't match the actual shape.\n    \"\"\"", "\n", "if", "name", "is", "None", ":", "\n", "        ", "name", "=", "tensor", ".", "name", "\n", "\n", "", "expected_rank_dict", "=", "{", "}", "\n", "if", "isinstance", "(", "expected_rank", ",", "six", ".", "integer_types", ")", ":", "\n", "        ", "expected_rank_dict", "[", "expected_rank", "]", "=", "True", "\n", "", "else", ":", "\n", "        ", "for", "x", "in", "expected_rank", ":", "\n", "            ", "expected_rank_dict", "[", "x", "]", "=", "True", "\n", "\n", "", "", "actual_rank", "=", "tensor", ".", "shape", ".", "ndims", "\n", "if", "actual_rank", "not", "in", "expected_rank_dict", ":", "\n", "        ", "scope_name", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "raise", "ValueError", "(", "\n", "\"For the tensor `%s` in scope `%s`, the actual rank \"", "\n", "\"`%d` (shape = %s) is not equal to the expected rank `%s`\"", "%", "\n", "(", "name", ",", "scope_name", ",", "actual_rank", ",", "str", "(", "tensor", ".", "shape", ")", ",", "str", "(", "expected_rank", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features.input_fn_builder": [[93, 121], ["tensorflow.data.Dataset.from_generator", "d.batch.batch", "functools.partial", "dict", "dict", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape", "tensorflow.TensorShape"], "function", ["None"], ["def", "input_fn_builder", "(", "examples", ",", "window_size", ",", "stride", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"", "\n", "\n", "def", "input_fn", "(", "params", ")", ":", "\n", "        ", "\"\"\"The actual input function.\"\"\"", "\n", "batch_size", "=", "params", "[", "\"batch_size\"", "]", "\n", "\n", "d", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "functools", ".", "partial", "(", "convert_examples_to_features", ",", "\n", "examples", "=", "examples", ",", "\n", "window_size", "=", "window_size", ",", "\n", "stride", "=", "stride", ",", "\n", "tokenizer", "=", "tokenizer", ")", ",", "\n", "dict", "(", "unique_ids", "=", "tf", ".", "int32", ",", "\n", "input_ids", "=", "tf", ".", "int32", ",", "\n", "input_mask", "=", "tf", ".", "int32", ",", "\n", "input_type_ids", "=", "tf", ".", "int32", ",", "\n", "extract_indices", "=", "tf", ".", "int32", ")", ",", "\n", "dict", "(", "unique_ids", "=", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "input_ids", "=", "tf", ".", "TensorShape", "(", "[", "window_size", "]", ")", ",", "\n", "input_mask", "=", "tf", ".", "TensorShape", "(", "[", "window_size", "]", ")", ",", "\n", "input_type_ids", "=", "tf", ".", "TensorShape", "(", "[", "window_size", "]", ")", ",", "\n", "extract_indices", "=", "tf", ".", "TensorShape", "(", "[", "window_size", "]", ")", ")", ")", "\n", "\n", "d", "=", "d", ".", "batch", "(", "batch_size", "=", "batch_size", ",", "drop_remainder", "=", "False", ")", "\n", "return", "d", "\n", "\n", "", "return", "input_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features.model_fn_builder": [[123, 185], ["modeling.BertModel", "tensorflow.trainable_variables", "modeling.get_assignment_map_from_checkpoint", "tensorflow.logging.info", "modeling.BertModel.get_all_encoder_layers", "enumerate", "tensorflow.contrib.tpu.TPUEstimatorSpec", "ValueError", "tensorflow.train.init_from_checkpoint", "tensorflow.logging.info", "tensorflow.train.init_from_checkpoint", "tensorflow.train.Scaffold"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.get_assignment_map_from_checkpoint", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertModel.get_all_encoder_layers"], ["", "def", "model_fn_builder", "(", "bert_config", ",", "init_checkpoint", ",", "layer_indexes", ",", "use_tpu", ",", "\n", "use_one_hot_embeddings", ")", ":", "\n", "    ", "\"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"", "\n", "\n", "def", "model_fn", "(", "features", ",", "labels", ",", "mode", ",", "params", ")", ":", "# pylint: disable=unused-argument", "\n", "        ", "\"\"\"The `model_fn` for TPUEstimator.\"\"\"", "\n", "\n", "unique_ids", "=", "features", "[", "\"unique_ids\"", "]", "\n", "input_ids", "=", "features", "[", "\"input_ids\"", "]", "\n", "input_mask", "=", "features", "[", "\"input_mask\"", "]", "\n", "input_type_ids", "=", "features", "[", "\"input_type_ids\"", "]", "\n", "extract_indices", "=", "features", "[", "\"extract_indices\"", "]", "\n", "\n", "model", "=", "modeling", ".", "BertModel", "(", "\n", "config", "=", "bert_config", ",", "\n", "is_training", "=", "False", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "token_type_ids", "=", "input_type_ids", ",", "\n", "use_one_hot_embeddings", "=", "use_one_hot_embeddings", ")", "\n", "\n", "if", "mode", "!=", "tf", ".", "estimator", ".", "ModeKeys", ".", "PREDICT", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only PREDICT modes are supported: %s\"", "%", "(", "mode", ")", ")", "\n", "\n", "", "tvars", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "scaffold_fn", "=", "None", "\n", "(", "assignment_map", ",", "\n", "initialized_variable_names", ")", "=", "modeling", ".", "get_assignment_map_from_checkpoint", "(", "\n", "tvars", ",", "init_checkpoint", ")", "\n", "if", "use_tpu", ":", "\n", "\n", "            ", "def", "tpu_scaffold", "(", ")", ":", "\n", "                ", "tf", ".", "train", ".", "init_from_checkpoint", "(", "init_checkpoint", ",", "assignment_map", ")", "\n", "return", "tf", ".", "train", ".", "Scaffold", "(", ")", "\n", "\n", "", "scaffold_fn", "=", "tpu_scaffold", "\n", "", "else", ":", "\n", "            ", "tf", ".", "train", ".", "init_from_checkpoint", "(", "init_checkpoint", ",", "assignment_map", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"**** Trainable Variables ****\"", ")", "\n", "for", "var", "in", "tvars", ":", "\n", "            ", "init_string", "=", "\"\"", "\n", "if", "var", ".", "name", "in", "initialized_variable_names", ":", "\n", "                ", "init_string", "=", "\", *INIT_FROM_CKPT*\"", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"  name = %s, shape = %s%s\"", ",", "var", ".", "name", ",", "var", ".", "shape", ",", "\n", "init_string", ")", "\n", "\n", "", "all_layers", "=", "model", ".", "get_all_encoder_layers", "(", ")", "\n", "\n", "predictions", "=", "{", "\n", "\"unique_ids\"", ":", "unique_ids", ",", "\n", "\"extract_indices\"", ":", "extract_indices", "\n", "}", "\n", "\n", "for", "(", "i", ",", "layer_index", ")", "in", "enumerate", "(", "layer_indexes", ")", ":", "\n", "            ", "predictions", "[", "\"layer_output_%d\"", "%", "i", "]", "=", "all_layers", "[", "layer_index", "]", "\n", "\n", "", "output_spec", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "predictions", "=", "predictions", ",", "scaffold_fn", "=", "scaffold_fn", ")", "\n", "return", "output_spec", "\n", "\n", "", "return", "model_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features._convert_example_to_features": [[187, 222], ["tokenizer.convert_tokens_to_ids", "dict", "tokens.append", "input_type_ids.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "input_type_ids.append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_tokens_to_ids"], ["", "def", "_convert_example_to_features", "(", "example", ",", "window_start", ",", "window_end", ",", "tokens_ids_to_extract", ",", "tokenizer", ",", "seq_length", ")", ":", "\n", "    ", "window_tokens", "=", "example", ".", "tokens", "[", "window_start", ":", "window_end", "]", "\n", "\n", "tokens", "=", "[", "]", "\n", "input_type_ids", "=", "[", "]", "\n", "for", "token", "in", "window_tokens", ":", "\n", "        ", "tokens", ".", "append", "(", "token", ")", "\n", "input_type_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "seq_length", ":", "\n", "        ", "input_ids", ".", "append", "(", "0", ")", "\n", "input_mask", ".", "append", "(", "0", ")", "\n", "input_type_ids", ".", "append", "(", "0", ")", "\n", "\n", "", "extract_indices", "=", "[", "-", "1", "]", "*", "seq_length", "\n", "for", "i", "in", "tokens_ids_to_extract", ":", "\n", "        ", "assert", "i", "-", "window_start", ">=", "0", "\n", "extract_indices", "[", "i", "-", "window_start", "]", "=", "i", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "seq_length", "\n", "assert", "len", "(", "input_type_ids", ")", "==", "seq_length", "\n", "\n", "return", "dict", "(", "unique_ids", "=", "example", ".", "document_index", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "input_type_ids", "=", "input_type_ids", ",", "\n", "extract_indices", "=", "extract_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features.convert_examples_to_features": [[224, 253], ["range", "len", "int", "int", "token_ids_to_extract.extend", "numpy.clip", "numpy.clip", "token_ids_to_extract.extend", "range", "len", "token_ids_to_extract.extend", "extract_features._convert_example_to_features", "len", "len", "range", "range", "min", "len", "len"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features._convert_example_to_features"], ["", "def", "convert_examples_to_features", "(", "examples", ",", "window_size", ",", "stride", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "assert", "window_size", "%", "2", "==", "1", "\n", "assert", "stride", "%", "2", "==", "1", "\n", "\n", "for", "example", "in", "examples", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "example", ".", "tokens", ")", ",", "stride", ")", ":", "\n", "            ", "window_center", "=", "i", "+", "window_size", "//", "2", "\n", "token_ids_to_extract", "=", "[", "]", "\n", "extract_start", "=", "int", "(", "np", ".", "clip", "(", "window_center", "-", "stride", "//", "2", ",", "0", ",", "len", "(", "example", ".", "tokens", ")", ")", ")", "\n", "extract_end", "=", "int", "(", "np", ".", "clip", "(", "window_center", "+", "stride", "//", "2", "+", "1", ",", "extract_start", ",", "len", "(", "example", ".", "tokens", ")", ")", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "token_ids_to_extract", ".", "extend", "(", "range", "(", "extract_start", ")", ")", "\n", "\n", "", "token_ids_to_extract", ".", "extend", "(", "range", "(", "extract_start", ",", "extract_end", ")", ")", "\n", "\n", "if", "i", "+", "stride", ">=", "len", "(", "example", ".", "tokens", ")", ":", "\n", "                ", "token_ids_to_extract", ".", "extend", "(", "range", "(", "extract_end", ",", "len", "(", "example", ".", "tokens", ")", ")", ")", "\n", "\n", "", "token_ids_to_extract", "=", "[", "t", "for", "t", "in", "token_ids_to_extract", "if", "example", ".", "bert_to_orig_map", "[", "t", "]", ">=", "0", "]", "\n", "\n", "yield", "_convert_example_to_features", "(", "example", ",", "\n", "i", ",", "\n", "min", "(", "i", "+", "window_size", ",", "len", "(", "example", ".", "tokens", ")", ")", ",", "\n", "token_ids_to_extract", ",", "\n", "tokenizer", ",", "\n", "window_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features.main": [[255, 331], ["tensorflow.logging.set_verbosity", "modeling.BertConfig.from_json_file", "tokenization.FullTokenizer", "tensorflow.contrib.tpu.RunConfig", "FLAGS.input_file.split", "enumerate", "extract_features.model_fn_builder", "tensorflow.contrib.tpu.TPUEstimator", "extract_features.input_fn_builder", "h5py.File", "h5py.File.close", "int", "data.process_example", "orig_examples.append", "bert_examples.append", "tqdm.tqdm", "tf.contrib.tpu.TPUEstimator.predict", "FLAGS.layers.split", "tensorflow.contrib.tpu.TPUConfig", "open", "json_examples.extend", "data.process_example.bertify", "int", "bert_example.doc_key.replace", "t.update", "enumerate", "sum", "orig_example.unravel_token_index", "enumerate", "json.loads", "h5py.File.create_dataset", "f.readlines", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.modeling.BertConfig.from_json_file", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features.model_fn_builder", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.extract_features.input_fn_builder", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.process_example", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.Example.bertify", "home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.RetrievalEvaluator.update", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.Example.unravel_token_index"], ["", "", "", "def", "main", "(", "_", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "layer_indexes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "FLAGS", ".", "layers", ".", "split", "(", "\",\"", ")", "]", "\n", "\n", "bert_config", "=", "modeling", ".", "BertConfig", ".", "from_json_file", "(", "FLAGS", ".", "bert_config_file", ")", "\n", "\n", "tokenizer", "=", "tokenization", ".", "FullTokenizer", "(", "\n", "vocab_file", "=", "FLAGS", ".", "vocab_file", ",", "do_lower_case", "=", "FLAGS", ".", "do_lower_case", ")", "\n", "\n", "is_per_host", "=", "tf", ".", "contrib", ".", "tpu", ".", "InputPipelineConfig", ".", "PER_HOST_V2", "\n", "run_config", "=", "tf", ".", "contrib", ".", "tpu", ".", "RunConfig", "(", "\n", "master", "=", "FLAGS", ".", "master", ",", "\n", "tpu_config", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUConfig", "(", "\n", "num_shards", "=", "FLAGS", ".", "num_tpu_cores", ",", "\n", "per_host_input_for_training", "=", "is_per_host", ")", ")", "\n", "\n", "json_examples", "=", "[", "]", "\n", "for", "file", "in", "FLAGS", ".", "input_file", ".", "split", "(", "';'", ")", ":", "\n", "        ", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "json_examples", ".", "extend", "(", "(", "json", ".", "loads", "(", "jsonline", ")", "for", "jsonline", "in", "f", ".", "readlines", "(", ")", ")", ")", "\n", "\n", "", "", "orig_examples", "=", "[", "]", "\n", "bert_examples", "=", "[", "]", "\n", "for", "i", ",", "json_e", "in", "enumerate", "(", "json_examples", ")", ":", "\n", "        ", "e", "=", "process_example", "(", "json_e", ",", "i", ")", "\n", "orig_examples", ".", "append", "(", "e", ")", "\n", "bert_examples", ".", "append", "(", "e", ".", "bertify", "(", "tokenizer", ")", ")", "\n", "\n", "", "model_fn", "=", "model_fn_builder", "(", "\n", "bert_config", "=", "bert_config", ",", "\n", "init_checkpoint", "=", "FLAGS", ".", "init_checkpoint", ",", "\n", "layer_indexes", "=", "layer_indexes", ",", "\n", "use_tpu", "=", "FLAGS", ".", "use_tpu", ",", "\n", "use_one_hot_embeddings", "=", "FLAGS", ".", "use_one_hot_embeddings", ",", "\n", ")", "\n", "\n", "# If TPU is not available, this will fall back to normal Estimator on CPU", "\n", "# or GPU.", "\n", "estimator", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimator", "(", "\n", "use_tpu", "=", "FLAGS", ".", "use_tpu", ",", "\n", "model_fn", "=", "model_fn", ",", "\n", "config", "=", "run_config", ",", "\n", "predict_batch_size", "=", "FLAGS", ".", "batch_size", ")", "\n", "\n", "input_fn", "=", "input_fn_builder", "(", "\n", "examples", "=", "bert_examples", ",", "window_size", "=", "FLAGS", ".", "window_size", ",", "stride", "=", "FLAGS", ".", "stride", ",", "tokenizer", "=", "tokenizer", ")", "\n", "\n", "writer", "=", "h5py", ".", "File", "(", "FLAGS", ".", "output_file", ",", "'w'", ")", "\n", "with", "tqdm", "(", "total", "=", "sum", "(", "len", "(", "e", ".", "tokens", ")", "for", "e", "in", "orig_examples", ")", ")", "as", "t", ":", "\n", "        ", "for", "result", "in", "estimator", ".", "predict", "(", "input_fn", ",", "yield_single_examples", "=", "True", ")", ":", "\n", "            ", "document_index", "=", "int", "(", "result", "[", "\"unique_ids\"", "]", ")", "\n", "bert_example", "=", "bert_examples", "[", "document_index", "]", "\n", "orig_example", "=", "orig_examples", "[", "document_index", "]", "\n", "file_key", "=", "bert_example", ".", "doc_key", ".", "replace", "(", "'/'", ",", "':'", ")", "\n", "\n", "t", ".", "update", "(", "n", "=", "(", "result", "[", "'extract_indices'", "]", ">=", "0", ")", ".", "sum", "(", ")", ")", "\n", "\n", "for", "output_index", ",", "bert_token_index", "in", "enumerate", "(", "result", "[", "'extract_indices'", "]", ")", ":", "\n", "                ", "if", "bert_token_index", "<", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "token_index", "=", "bert_example", ".", "bert_to_orig_map", "[", "bert_token_index", "]", "\n", "sentence_index", ",", "token_index", "=", "orig_example", ".", "unravel_token_index", "(", "token_index", ")", "\n", "\n", "dataset_key", "=", "\"{}/{}\"", ".", "format", "(", "file_key", ",", "sentence_index", ")", "\n", "if", "dataset_key", "not", "in", "writer", ":", "\n", "                    ", "writer", ".", "create_dataset", "(", "dataset_key", ",", "\n", "(", "len", "(", "orig_example", ".", "sentence_tokens", "[", "sentence_index", "]", ")", ",", "bert_config", ".", "hidden_size", ",", "len", "(", "layer_indexes", ")", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "dset", "=", "writer", "[", "dataset_key", "]", "\n", "for", "j", ",", "layer_index", "in", "enumerate", "(", "layer_indexes", ")", ":", "\n", "                    ", "layer_output", "=", "result", "[", "\"layer_output_%d\"", "%", "j", "]", "\n", "dset", "[", "token_index", ",", ":", ",", "j", "]", "=", "layer_output", "[", "output_index", "]", "\n", "", "", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.Example.__init__": [[9, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "doc_key", ",", "tokens", ",", "sentence_tokens", ",", "document_index", ",", "\n", "offset", "=", "0", ",", "bert_to_orig_map", "=", "None", ")", ":", "\n", "        ", "self", ".", "doc_key", "=", "doc_key", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "sentence_tokens", "=", "sentence_tokens", "\n", "self", ".", "document_index", "=", "document_index", "\n", "self", ".", "offset", "=", "offset", "\n", "self", ".", "bert_to_orig_map", "=", "bert_to_orig_map", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.Example.bertify": [[19, 40], ["enumerate", "data.Example", "tokenizer.tokenize", "orig_to_bert_map.append", "orig_to_bert_end_map.append", "bert_tokens.extend", "tokenizer.tokenize", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "bertify", "(", "self", ",", "tokenizer", ")", ":", "\n", "        ", "assert", "self", ".", "offset", "==", "0", "\n", "\n", "bert_tokens", "=", "[", "]", "\n", "orig_to_bert_map", "=", "[", "]", "\n", "orig_to_bert_end_map", "=", "[", "]", "\n", "for", "t", "in", "self", ".", "tokens", ":", "\n", "            ", "bert_t", "=", "tokenizer", ".", "tokenize", "(", "t", ")", "\n", "orig_to_bert_map", ".", "append", "(", "len", "(", "bert_tokens", ")", ")", "\n", "orig_to_bert_end_map", ".", "append", "(", "len", "(", "bert_tokens", ")", "+", "len", "(", "bert_t", ")", "-", "1", ")", "\n", "bert_tokens", ".", "extend", "(", "bert_t", ")", "\n", "\n", "", "bert_sentence_tokens", "=", "[", "tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "s", ")", ")", "for", "s", "in", "self", ".", "sentence_tokens", "]", "\n", "\n", "bert_to_orig_map", "=", "[", "-", "1", "]", "*", "len", "(", "bert_tokens", ")", "\n", "for", "i", ",", "bert_i", "in", "enumerate", "(", "orig_to_bert_map", ")", ":", "\n", "            ", "bert_to_orig_map", "[", "bert_i", "]", "=", "i", "\n", "\n", "\n", "\n", "", "return", "Example", "(", "self", ".", "doc_key", ",", "bert_tokens", ",", "bert_sentence_tokens", ",", "self", ".", "document_index", ",", "bert_to_orig_map", "=", "bert_to_orig_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.Example.unravel_token_index": [[41, 50], ["enumerate", "ValueError", "len", "len", "len"], "methods", ["None"], ["", "def", "unravel_token_index", "(", "self", ",", "token_index", ")", ":", "\n", "        ", "prev_sentences_len", "=", "0", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "self", ".", "sentence_tokens", ")", ":", "\n", "            ", "if", "token_index", "<", "prev_sentences_len", "+", "len", "(", "s", ")", ":", "\n", "                ", "token_index_in_sentence", "=", "token_index", "-", "prev_sentences_len", "\n", "return", "i", ",", "token_index_in_sentence", "\n", "", "prev_sentences_len", "+=", "len", "(", "s", ")", "\n", "\n", "", "raise", "ValueError", "(", "'token_index is out of range ({} >= {})'", ",", "token_index", ",", "len", "(", "self", ".", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.data.process_example": [[54, 61], ["sum", "data.Example", "tokenization.convert_to_unicode"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_to_unicode"], ["", "", "def", "process_example", "(", "example", ",", "index", ")", ":", "\n", "    ", "sentences", "=", "example", "[", "\"sentences\"", "]", "\n", "sentence_tokens", "=", "[", "[", "tokenization", ".", "convert_to_unicode", "(", "w", ")", "for", "w", "in", "s", "]", "for", "s", "in", "sentences", "]", "\n", "tokens", "=", "sum", "(", "sentence_tokens", ",", "[", "]", ")", "\n", "doc_key", "=", "example", "[", "\"doc_key\"", "]", "\n", "\n", "return", "Example", "(", "doc_key", ",", "tokens", ",", "sentence_tokens", ",", "index", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.FullTokenizer.__init__": [[164, 169], ["tokenization.load_vocab", "tokenization.BasicTokenizer", "tokenization.WordpieceTokenizer", "tokenization.FullTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ")", ":", "\n", "    ", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "inv_vocab", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "items", "(", ")", "}", "\n", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.FullTokenizer.tokenize": [[170, 177], ["tokenization.FullTokenizer.basic_tokenizer.tokenize", "tokenization.FullTokenizer.wordpiece_tokenizer.tokenize", "split_tokens.append"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "    ", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", ":", "\n", "      ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "        ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.FullTokenizer.convert_tokens_to_ids": [[178, 180], ["tokenization.convert_by_vocab"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_by_vocab"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "    ", "return", "convert_by_vocab", "(", "self", ".", "vocab", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.FullTokenizer.convert_ids_to_tokens": [[181, 183], ["tokenization.convert_by_vocab"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_by_vocab"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "    ", "return", "convert_by_vocab", "(", "self", ".", "inv_vocab", ",", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer.__init__": [[188, 195], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "True", ")", ":", "\n", "    ", "\"\"\"Constructs a BasicTokenizer.\n\n    Args:\n      do_lower_case: Whether to lower case the input.\n    \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer.tokenize": [[196, 219], ["tokenization.convert_to_unicode", "tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "tokenization.whitespace_tokenize", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "convert_to_unicode", "(", "text", ")", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "      ", "if", "self", ".", "do_lower_case", ":", "\n", "        ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._run_strip_accents": [[220, 230], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.None.util.EmbeddingDictionary.normalize"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "      ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "        ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._run_split_on_punc": [[231, 250], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "      ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "        ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "        ", "if", "start_new_word", ":", "\n", "          ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._tokenize_chinese_chars": [[251, 263], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "      ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "        ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "        ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._is_chinese_char": [[264, 285], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "    ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "      ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.BasicTokenizer._clean_text": [[286, 298], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization._is_whitespace", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "      ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "        ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "        ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "        ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.WordpieceTokenizer.__init__": [[303, 307], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "200", ")", ":", "\n", "    ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.WordpieceTokenizer.tokenize": [[308, 360], ["tokenization.convert_to_unicode", "tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_to_unicode", "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n    This uses a greedy longest-match-first algorithm to perform tokenization\n    using the given vocabulary.\n\n    For example:\n      input = \"unaffable\"\n      output = [\"un\", \"##aff\", \"##able\"]\n\n    Args:\n      text: A single token or whitespace separated tokens. This should have\n        already been passed through `BasicTokenizer.\n\n    Returns:\n      A list of wordpiece tokens.\n    \"\"\"", "\n", "\n", "text", "=", "convert_to_unicode", "(", "text", ")", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "      ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "        ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "        ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "          ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "            ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "            ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "          ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "        ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "        ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.validate_case_matches_checkpoint": [[28, 76], ["re.match", "re.match.group", "ValueError"], "function", ["None"], ["def", "validate_case_matches_checkpoint", "(", "do_lower_case", ",", "init_checkpoint", ")", ":", "\n", "  ", "\"\"\"Checks whether the casing config is consistent with the checkpoint name.\"\"\"", "\n", "\n", "# The casing has to be passed in by the user and there is no explicit check", "\n", "# as to whether it matches the checkpoint. The casing information probably", "\n", "# should have been stored in the bert_config.json file, but it's not, so", "\n", "# we have to heuristically detect it to validate.", "\n", "\n", "if", "not", "init_checkpoint", ":", "\n", "    ", "return", "\n", "\n", "", "m", "=", "re", ".", "match", "(", "\"^.*?([A-Za-z0-9_-]+)/bert_model.ckpt\"", ",", "init_checkpoint", ")", "\n", "if", "m", "is", "None", ":", "\n", "    ", "return", "\n", "\n", "", "model_name", "=", "m", ".", "group", "(", "1", ")", "\n", "\n", "lower_models", "=", "[", "\n", "\"uncased_L-24_H-1024_A-16\"", ",", "\"uncased_L-12_H-768_A-12\"", ",", "\n", "\"multilingual_L-12_H-768_A-12\"", ",", "\"chinese_L-12_H-768_A-12\"", "\n", "]", "\n", "\n", "cased_models", "=", "[", "\n", "\"cased_L-12_H-768_A-12\"", ",", "\"cased_L-24_H-1024_A-16\"", ",", "\n", "\"multi_cased_L-12_H-768_A-12\"", "\n", "]", "\n", "\n", "is_bad_config", "=", "False", "\n", "if", "model_name", "in", "lower_models", "and", "not", "do_lower_case", ":", "\n", "    ", "is_bad_config", "=", "True", "\n", "actual_flag", "=", "\"False\"", "\n", "case_name", "=", "\"lowercased\"", "\n", "opposite_flag", "=", "\"True\"", "\n", "\n", "", "if", "model_name", "in", "cased_models", "and", "do_lower_case", ":", "\n", "    ", "is_bad_config", "=", "True", "\n", "actual_flag", "=", "\"True\"", "\n", "case_name", "=", "\"cased\"", "\n", "opposite_flag", "=", "\"False\"", "\n", "\n", "", "if", "is_bad_config", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"You passed in `--do_lower_case=%s` with `--init_checkpoint=%s`. \"", "\n", "\"However, `%s` seems to be a %s model, so you \"", "\n", "\"should pass in `--do_lower_case=%s` so that the fine-tuning matches \"", "\n", "\"how the model was pre-training. If this error is wrong, please \"", "\n", "\"just comment out this check.\"", "%", "(", "actual_flag", ",", "init_checkpoint", ",", "\n", "model_name", ",", "case_name", ",", "opposite_flag", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_to_unicode": [[78, 96], ["isinstance", "isinstance", "isinstance", "ValueError", "text.decode", "ValueError", "text.decode", "isinstance", "ValueError", "type", "type"], "function", ["None"], ["", "", "def", "convert_to_unicode", "(", "text", ")", ":", "\n", "  ", "\"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"", "\n", "if", "six", ".", "PY3", ":", "\n", "    ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "      ", "return", "text", "\n", "", "elif", "isinstance", "(", "text", ",", "bytes", ")", ":", "\n", "      ", "return", "text", ".", "decode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unsupported string type: %s\"", "%", "(", "type", "(", "text", ")", ")", ")", "\n", "", "", "elif", "six", ".", "PY2", ":", "\n", "    ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "      ", "return", "text", ".", "decode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "\n", "", "elif", "isinstance", "(", "text", ",", "unicode", ")", ":", "\n", "      ", "return", "text", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unsupported string type: %s\"", "%", "(", "type", "(", "text", ")", ")", ")", "\n", "", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Not running on Python2 or Python 3?\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.printable_text": [[98, 119], ["isinstance", "isinstance", "isinstance", "ValueError", "text.decode", "ValueError", "isinstance", "text.encode", "ValueError", "type", "type"], "function", ["None"], ["", "", "def", "printable_text", "(", "text", ")", ":", "\n", "  ", "\"\"\"Returns text encoded in a way suitable for print or `tf.logging`.\"\"\"", "\n", "\n", "# These functions want `str` for both Python2 and Python3, but in one case", "\n", "# it's a Unicode string and in the other it's a byte string.", "\n", "if", "six", ".", "PY3", ":", "\n", "    ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "      ", "return", "text", "\n", "", "elif", "isinstance", "(", "text", ",", "bytes", ")", ":", "\n", "      ", "return", "text", ".", "decode", "(", "\"utf-8\"", ",", "\"ignore\"", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unsupported string type: %s\"", "%", "(", "type", "(", "text", ")", ")", ")", "\n", "", "", "elif", "six", ".", "PY2", ":", "\n", "    ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "      ", "return", "text", "\n", "", "elif", "isinstance", "(", "text", ",", "unicode", ")", ":", "\n", "      ", "return", "text", ".", "encode", "(", "\"utf-8\"", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unsupported string type: %s\"", "%", "(", "type", "(", "text", ")", ")", ")", "\n", "", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Not running on Python2 or Python 3?\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.load_vocab": [[121, 134], ["collections.OrderedDict", "tensorflow.gfile.GFile", "tokenization.convert_to_unicode", "token.strip.strip", "reader.readline"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_to_unicode"], ["", "", "def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "  ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "vocab_file", ",", "\"r\"", ")", "as", "reader", ":", "\n", "    ", "while", "True", ":", "\n", "      ", "token", "=", "convert_to_unicode", "(", "reader", ".", "readline", "(", ")", ")", "\n", "if", "not", "token", ":", "\n", "        ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_by_vocab": [[136, 142], ["output.append"], "function", ["None"], ["", "def", "convert_by_vocab", "(", "vocab", ",", "items", ")", ":", "\n", "  ", "\"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "item", "in", "items", ":", "\n", "    ", "output", ".", "append", "(", "vocab", "[", "item", "]", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_tokens_to_ids": [[144, 146], ["tokenization.convert_by_vocab"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_by_vocab"], ["", "def", "convert_tokens_to_ids", "(", "vocab", ",", "tokens", ")", ":", "\n", "  ", "return", "convert_by_vocab", "(", "vocab", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_ids_to_tokens": [[148, 150], ["tokenization.convert_by_vocab"], "function", ["home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.convert_by_vocab"], ["", "def", "convert_ids_to_tokens", "(", "inv_vocab", ",", "ids", ")", ":", "\n", "  ", "return", "convert_by_vocab", "(", "inv_vocab", ",", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization.whitespace_tokenize": [[152, 159], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "  ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "    ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization._is_whitespace": [[362, 372], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "  ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "    ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "    ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization._is_control": [[374, 384], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "  ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "    ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "    ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.juntaoy_aracoref.extract_bert_features.tokenization._is_punctuation": [[386, 400], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "  ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "    ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "    ", "return", "True", "\n", "", "return", "False", "\n", "", ""]]}