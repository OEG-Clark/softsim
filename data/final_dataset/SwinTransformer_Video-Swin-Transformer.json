{"home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.None.setup.readme": [[4, 8], ["open", "f.read"], "function", ["None"], ["def", "readme", "(", ")", ":", "\n", "    ", "with", "open", "(", "'README.md'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "content", "=", "f", ".", "read", "(", ")", "\n", "", "return", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.None.setup.get_version": [[13, 17], ["open", "exec", "locals", "compile", "f.read"], "function", ["None"], ["def", "get_version", "(", ")", ":", "\n", "    ", "with", "open", "(", "version_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "exec", "(", "compile", "(", "f", ".", "read", "(", ")", ",", "version_file", ",", "'exec'", ")", ")", "\n", "", "return", "locals", "(", ")", "[", "'__version__'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.None.setup.parse_requirements": [[19, 95], ["list", "line.strip.startswith", "exists", "setup.parse_requirements.gen_packages_items"], "function", ["None"], ["", "def", "parse_requirements", "(", "fname", "=", "'requirements.txt'", ",", "with_version", "=", "True", ")", ":", "\n", "    ", "\"\"\"Parse the package dependencies listed in a requirements file but strips\n    specific versioning information.\n\n    Args:\n        fname (str): path to requirements file\n        with_version (bool, default=False): if True include version specs\n\n    Returns:\n        List[str]: list of requirements items\n\n    CommandLine:\n        python -c \"import setup; print(setup.parse_requirements())\"\n    \"\"\"", "\n", "import", "re", "\n", "import", "sys", "\n", "from", "os", ".", "path", "import", "exists", "\n", "require_fpath", "=", "fname", "\n", "\n", "def", "parse_line", "(", "line", ")", ":", "\n", "        ", "\"\"\"Parse information from a line in a requirements text file.\"\"\"", "\n", "if", "line", ".", "startswith", "(", "'-r '", ")", ":", "\n", "# Allow specifying requirements in other files", "\n", "            ", "target", "=", "line", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "for", "info", "in", "parse_require_file", "(", "target", ")", ":", "\n", "                ", "yield", "info", "\n", "", "", "else", ":", "\n", "            ", "info", "=", "{", "'line'", ":", "line", "}", "\n", "if", "line", ".", "startswith", "(", "'-e '", ")", ":", "\n", "                ", "info", "[", "'package'", "]", "=", "line", ".", "split", "(", "'#egg='", ")", "[", "1", "]", "\n", "", "elif", "'@git+'", "in", "line", ":", "\n", "                ", "info", "[", "'package'", "]", "=", "line", "\n", "", "else", ":", "\n", "# Remove versioning from the package", "\n", "                ", "pat", "=", "'('", "+", "'|'", ".", "join", "(", "[", "'>='", ",", "'=='", ",", "'>'", "]", ")", "+", "')'", "\n", "parts", "=", "re", ".", "split", "(", "pat", ",", "line", ",", "maxsplit", "=", "1", ")", "\n", "parts", "=", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "parts", "]", "\n", "\n", "info", "[", "'package'", "]", "=", "parts", "[", "0", "]", "\n", "if", "len", "(", "parts", ")", ">", "1", ":", "\n", "                    ", "op", ",", "rest", "=", "parts", "[", "1", ":", "]", "\n", "if", "';'", "in", "rest", ":", "\n", "# Handle platform specific dependencies", "\n", "# http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies", "\n", "                        ", "version", ",", "platform_deps", "=", "map", "(", "str", ".", "strip", ",", "\n", "rest", ".", "split", "(", "';'", ")", ")", "\n", "info", "[", "'platform_deps'", "]", "=", "platform_deps", "\n", "", "else", ":", "\n", "                        ", "version", "=", "rest", "# NOQA", "\n", "", "info", "[", "'version'", "]", "=", "(", "op", ",", "version", ")", "\n", "", "", "yield", "info", "\n", "\n", "", "", "def", "parse_require_file", "(", "fpath", ")", ":", "\n", "        ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "and", "not", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                    ", "for", "info", "in", "parse_line", "(", "line", ")", ":", "\n", "                        ", "yield", "info", "\n", "\n", "", "", "", "", "", "def", "gen_packages_items", "(", ")", ":", "\n", "        ", "if", "exists", "(", "require_fpath", ")", ":", "\n", "            ", "for", "info", "in", "parse_require_file", "(", "require_fpath", ")", ":", "\n", "                ", "parts", "=", "[", "info", "[", "'package'", "]", "]", "\n", "if", "with_version", "and", "'version'", "in", "info", ":", "\n", "                    ", "parts", ".", "extend", "(", "info", "[", "'version'", "]", ")", "\n", "", "if", "not", "sys", ".", "version", ".", "startswith", "(", "'3.4'", ")", ":", "\n", "# apparently package_deps are broken in 3.4", "\n", "                    ", "platform_deps", "=", "info", ".", "get", "(", "'platform_deps'", ")", "\n", "if", "platform_deps", "is", "not", "None", ":", "\n", "                        ", "parts", ".", "append", "(", "';'", "+", "platform_deps", ")", "\n", "", "", "item", "=", "''", ".", "join", "(", "parts", ")", "\n", "yield", "item", "\n", "\n", "", "", "", "packages", "=", "list", "(", "gen_packages_items", "(", ")", ")", "\n", "return", "packages", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.__init__": [[18, 38], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "batch_processor", "=", "None", ",", "\n", "optimizer", "=", "None", ",", "\n", "work_dir", "=", "None", ",", "\n", "logger", "=", "None", ",", "\n", "meta", "=", "None", ",", "\n", "max_iters", "=", "None", ",", "\n", "max_epochs", "=", "None", ",", "\n", "amp", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "model", ",", "\n", "batch_processor", ",", "\n", "optimizer", ",", "\n", "work_dir", ",", "\n", "logger", ",", "\n", "meta", ",", "\n", "max_iters", ",", "\n", "max_epochs", ")", "\n", "self", ".", "amp", "=", "amp", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.save_checkpoint": [[39, 82], ["filename_tmpl.format", "os.join", "os.join", "checkpoint.save_checkpoint", "dict", "isinstance", "dict.update", "os.join", "os.join", "dict.update", "TypeError", "mmcv.symlink", "shutil.copy", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.checkpoint.save_checkpoint", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "save_checkpoint", "(", "self", ",", "\n", "out_dir", ",", "\n", "filename_tmpl", "=", "'epoch_{}.pth'", ",", "\n", "save_optimizer", "=", "True", ",", "\n", "meta", "=", "None", ",", "\n", "create_symlink", "=", "True", ")", ":", "\n", "        ", "\"\"\"Save the checkpoint.\n\n        Args:\n            out_dir (str): The directory that checkpoints are saved.\n            filename_tmpl (str, optional): The checkpoint filename template,\n                which contains a placeholder for the epoch number.\n                Defaults to 'epoch_{}.pth'.\n            save_optimizer (bool, optional): Whether to save the optimizer to\n                the checkpoint. Defaults to True.\n            meta (dict, optional): The meta information to be saved in the\n                checkpoint. Defaults to None.\n            create_symlink (bool, optional): Whether to create a symlink\n                \"latest.pth\" to point to the latest checkpoint.\n                Defaults to True.\n        \"\"\"", "\n", "if", "meta", "is", "None", ":", "\n", "            ", "meta", "=", "dict", "(", "epoch", "=", "self", ".", "epoch", "+", "1", ",", "iter", "=", "self", ".", "iter", ")", "\n", "", "elif", "isinstance", "(", "meta", ",", "dict", ")", ":", "\n", "            ", "meta", ".", "update", "(", "epoch", "=", "self", ".", "epoch", "+", "1", ",", "iter", "=", "self", ".", "iter", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f'meta should be a dict or None, but got {type(meta)}'", ")", "\n", "", "if", "self", ".", "meta", "is", "not", "None", ":", "\n", "            ", "meta", ".", "update", "(", "self", ".", "meta", ")", "\n", "\n", "", "filename", "=", "filename_tmpl", ".", "format", "(", "self", ".", "epoch", "+", "1", ")", "\n", "filepath", "=", "osp", ".", "join", "(", "out_dir", ",", "filename", ")", "\n", "optimizer", "=", "self", ".", "optimizer", "if", "save_optimizer", "else", "None", "\n", "save_checkpoint", "(", "self", ".", "model", ",", "filepath", ",", "optimizer", "=", "optimizer", ",", "meta", "=", "meta", ",", "amp", "=", "self", ".", "amp", ")", "\n", "# in some environments, `os.symlink` is not supported, you may need to", "\n", "# set `create_symlink` to False", "\n", "if", "create_symlink", ":", "\n", "            ", "dst_file", "=", "osp", ".", "join", "(", "out_dir", ",", "'latest.pth'", ")", "\n", "try", ":", "\n", "                ", "mmcv", ".", "symlink", "(", "filename", ",", "dst_file", ")", "\n", "", "except", ":", "\n", "                ", "shutil", ".", "copy", "(", "filepath", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.resume": [[83, 121], ["epoch_based_runner.EpochBasedRunnerAmp.logger.info", "torch.cuda.empty_cache", "torch.cuda.is_available", "epoch_based_runner.EpochBasedRunnerAmp.load_checkpoint", "isinstance", "apex.amp.load_state_dict", "epoch_based_runner.EpochBasedRunnerAmp.logger.info", "torch.cuda.current_device", "epoch_based_runner.EpochBasedRunnerAmp.load_checkpoint", "epoch_based_runner.EpochBasedRunnerAmp.load_checkpoint", "epoch_based_runner.EpochBasedRunnerAmp.optimizer.load_state_dict", "isinstance", "epoch_based_runner.EpochBasedRunnerAmp.optimizer.keys", "TypeError", "epoch_based_runner.EpochBasedRunnerAmp.optimizer[].load_state_dict", "storage.cuda", "type"], "methods", ["None"], ["", "", "", "def", "resume", "(", "self", ",", "\n", "checkpoint", ",", "\n", "resume_optimizer", "=", "True", ",", "\n", "map_location", "=", "'cpu'", ",", "\n", "resume_amp", "=", "False", ")", ":", "\n", "        ", "if", "map_location", "==", "'default'", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "device_id", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "checkpoint", "=", "self", ".", "load_checkpoint", "(", "\n", "checkpoint", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ".", "cuda", "(", "device_id", ")", ")", "\n", "", "else", ":", "\n", "                ", "checkpoint", "=", "self", ".", "load_checkpoint", "(", "checkpoint", ")", "\n", "", "", "else", ":", "\n", "            ", "checkpoint", "=", "self", ".", "load_checkpoint", "(", "\n", "checkpoint", ",", "map_location", "=", "map_location", ")", "\n", "\n", "", "self", ".", "_epoch", "=", "checkpoint", "[", "'meta'", "]", "[", "'epoch'", "]", "\n", "self", ".", "_iter", "=", "checkpoint", "[", "'meta'", "]", "[", "'iter'", "]", "\n", "if", "'optimizer'", "in", "checkpoint", "and", "resume_optimizer", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "optimizer", ",", "Optimizer", ")", ":", "\n", "                ", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "optimizer", ",", "dict", ")", ":", "\n", "                ", "for", "k", "in", "self", ".", "optimizer", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "optimizer", "[", "k", "]", ".", "load_state_dict", "(", "\n", "checkpoint", "[", "'optimizer'", "]", "[", "k", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\n", "'Optimizer should be dict or torch.optim.Optimizer '", "\n", "f'but got {type(self.optimizer)}'", ")", "\n", "\n", "", "", "if", "'amp'", "in", "checkpoint", "and", "resume_amp", ":", "\n", "            ", "apex", ".", "amp", ".", "load_state_dict", "(", "checkpoint", "[", "'amp'", "]", ")", "\n", "self", ".", "logger", ".", "info", "(", "'load amp state dict'", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'resumed epoch %d, iter %d'", ",", "self", ".", "epoch", ",", "self", ".", "iter", ")", "\n", "del", "checkpoint", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.auto_resume": [[122, 127], ["os.join", "os.join", "os.exists", "os.exists", "epoch_based_runner.EpochBasedRunnerAmp.logger.info", "epoch_based_runner.EpochBasedRunnerAmp.resume"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.resume"], ["", "def", "auto_resume", "(", "self", ")", ":", "\n", "        ", "linkname", "=", "osp", ".", "join", "(", "self", ".", "work_dir", ",", "'latest.pth'", ")", "\n", "if", "osp", ".", "exists", "(", "linkname", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'latest checkpoint found'", ")", "\n", "self", ".", "resume", "(", "linkname", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.checkpoint.save_checkpoint": [[14, 81], ["meta.update", "mmcv.parallel.is_module_wrapper", "isinstance", "filename.startswith", "hasattr", "meta.update", "mmcv.runner.checkpoint.weights_to_cpu", "optimizer.state_dict", "isinstance", "apex.amp.state_dict", "modelcloud.Folder", "os.split", "mmcv.mkdir_or_exist", "isinstance", "TypeError", "time.asctime", "mmcv.runner.checkpoint.get_state_dict", "optimizer.items", "modelcloud.get", "tempfile.TemporaryDirectory", "os.join", "root.create_training_model.create_file", "os.dirname", "open", "torch.save", "f.flush", "optim.state_dict", "ImportError", "modelcloud.Folder.create_training_model", "open", "torch.save", "f.flush", "type"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "save_checkpoint", "(", "model", ",", "filename", ",", "optimizer", "=", "None", ",", "meta", "=", "None", ",", "amp", "=", "False", ")", ":", "\n", "    ", "\"\"\"Save checkpoint to file.\n\n    The checkpoint will have 3 fields: ``meta``, ``state_dict`` and\n    ``optimizer``. By default ``meta`` will contain version and time info.\n\n    Args:\n        model (Module): Module whose params are to be saved.\n        filename (str): Checkpoint filename.\n        optimizer (:obj:`Optimizer`, optional): Optimizer to be saved.\n        meta (dict, optional): Metadata to be saved in checkpoint.\n    \"\"\"", "\n", "if", "meta", "is", "None", ":", "\n", "        ", "meta", "=", "{", "}", "\n", "", "elif", "not", "isinstance", "(", "meta", ",", "dict", ")", ":", "\n", "        ", "raise", "TypeError", "(", "f'meta must be a dict or None, but got {type(meta)}'", ")", "\n", "", "meta", ".", "update", "(", "mmcv_version", "=", "mmcv", ".", "__version__", ",", "time", "=", "time", ".", "asctime", "(", ")", ")", "\n", "\n", "if", "is_module_wrapper", "(", "model", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "\n", "", "if", "hasattr", "(", "model", ",", "'CLASSES'", ")", "and", "model", ".", "CLASSES", "is", "not", "None", ":", "\n", "# save class name to the meta", "\n", "        ", "meta", ".", "update", "(", "CLASSES", "=", "model", ".", "CLASSES", ")", "\n", "\n", "", "checkpoint", "=", "{", "\n", "'meta'", ":", "meta", ",", "\n", "'state_dict'", ":", "weights_to_cpu", "(", "get_state_dict", "(", "model", ")", ")", "\n", "}", "\n", "# save optimizer state dict in the checkpoint", "\n", "if", "isinstance", "(", "optimizer", ",", "Optimizer", ")", ":", "\n", "        ", "checkpoint", "[", "'optimizer'", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "", "elif", "isinstance", "(", "optimizer", ",", "dict", ")", ":", "\n", "        ", "checkpoint", "[", "'optimizer'", "]", "=", "{", "}", "\n", "for", "name", ",", "optim", "in", "optimizer", ".", "items", "(", ")", ":", "\n", "            ", "checkpoint", "[", "'optimizer'", "]", "[", "name", "]", "=", "optim", ".", "state_dict", "(", ")", "\n", "\n", "# save amp state dict in the checkpoint", "\n", "", "", "if", "amp", ":", "\n", "        ", "checkpoint", "[", "'amp'", "]", "=", "apex", ".", "amp", ".", "state_dict", "(", ")", "\n", "\n", "", "if", "filename", ".", "startswith", "(", "'pavi://'", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "pavi", "import", "modelcloud", "\n", "from", "pavi", ".", "exception", "import", "NodeNotFoundError", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please install pavi to load checkpoint from modelcloud.'", ")", "\n", "", "model_path", "=", "filename", "[", "7", ":", "]", "\n", "root", "=", "modelcloud", ".", "Folder", "(", ")", "\n", "model_dir", ",", "model_name", "=", "osp", ".", "split", "(", "model_path", ")", "\n", "try", ":", "\n", "            ", "model", "=", "modelcloud", ".", "get", "(", "model_dir", ")", "\n", "", "except", "NodeNotFoundError", ":", "\n", "            ", "model", "=", "root", ".", "create_training_model", "(", "model_dir", ")", "\n", "", "with", "TemporaryDirectory", "(", ")", "as", "tmp_dir", ":", "\n", "            ", "checkpoint_file", "=", "osp", ".", "join", "(", "tmp_dir", ",", "model_name", ")", "\n", "with", "open", "(", "checkpoint_file", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "checkpoint", ",", "f", ")", "\n", "f", ".", "flush", "(", ")", "\n", "", "model", ".", "create_file", "(", "checkpoint_file", ",", "name", "=", "model_name", ")", "\n", "", "", "else", ":", "\n", "        ", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "dirname", "(", "filename", ")", ")", "\n", "# immediately flush buffer", "\n", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "checkpoint", ",", "f", ")", "\n", "f", ".", "flush", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceDistSamplerSeedHook.before_epoch": [[21, 29], ["hasattr", "data_loader.sampler.set_epoch", "hasattr", "data_loader.batch_sampler.sampler.set_epoch"], "methods", ["None"], ["    ", "def", "before_epoch", "(", "self", ",", "runner", ")", ":", "\n", "        ", "for", "data_loader", "in", "runner", ".", "data_loaders", ":", "\n", "            ", "if", "hasattr", "(", "data_loader", ".", "sampler", ",", "'set_epoch'", ")", ":", "\n", "# in case the data loader uses `SequentialSampler` in Pytorch", "\n", "                ", "data_loader", ".", "sampler", ".", "set_epoch", "(", "runner", ".", "epoch", ")", "\n", "", "elif", "hasattr", "(", "data_loader", ".", "batch_sampler", ".", "sampler", ",", "'set_epoch'", ")", ":", "\n", "# batch sampler in pytorch wraps the sampler as its attributes.", "\n", "                ", "data_loader", ".", "batch_sampler", ".", "sampler", ".", "set_epoch", "(", "runner", ".", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run_iter": [[38, 58], ["omnisource_runner.OmniSourceRunner.batch_processor", "isinstance", "TypeError", "omnisource_runner.OmniSourceRunner.log_buffer.update", "omnisource_runner.OmniSourceRunner.model.train_step", "omnisource_runner.OmniSourceRunner.model.val_step", "log_vars.items"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleModel.train_step", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.Model.val_step"], ["def", "run_iter", "(", "self", ",", "data_batch", ",", "train_mode", ",", "source", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "batch_processor", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "self", ".", "batch_processor", "(", "\n", "self", ".", "model", ",", "data_batch", ",", "train_mode", "=", "train_mode", ",", "**", "kwargs", ")", "\n", "", "elif", "train_mode", ":", "\n", "            ", "outputs", "=", "self", ".", "model", ".", "train_step", "(", "data_batch", ",", "self", ".", "optimizer", ",", "\n", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "self", ".", "model", ".", "val_step", "(", "data_batch", ",", "self", ".", "optimizer", ",", "**", "kwargs", ")", "\n", "", "if", "not", "isinstance", "(", "outputs", ",", "dict", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'\"batch_processor()\" or \"model.train_step()\"'", "\n", "'and \"model.val_step()\" must return a dict'", ")", "\n", "# Since we have multiple sources, we add a suffix to log_var names,", "\n", "# so that we can differentiate them.", "\n", "", "if", "'log_vars'", "in", "outputs", ":", "\n", "            ", "log_vars", "=", "outputs", "[", "'log_vars'", "]", "\n", "log_vars", "=", "{", "k", "+", "source", ":", "v", "for", "k", ",", "v", "in", "log_vars", ".", "items", "(", ")", "}", "\n", "self", ".", "log_buffer", ".", "update", "(", "log_vars", ",", "outputs", "[", "'num_samples'", "]", ")", "\n", "\n", "", "self", ".", "outputs", "=", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.train": [[59, 102], ["omnisource_runner.OmniSourceRunner.model.train", "omnisource_runner.OmniSourceRunner.call_hook", "time.sleep", "enumerate", "omnisource_runner.OmniSourceRunner.call_hook", "omnisource_runner.cycle", "len", "kwargs.pop", "len", "omnisource_runner.OmniSourceRunner.call_hook", "omnisource_runner.OmniSourceRunner.run_iter", "omnisource_runner.OmniSourceRunner.call_hook", "enumerate", "range", "next", "omnisource_runner.OmniSourceRunner.call_hook", "omnisource_runner.OmniSourceRunner.run_iter", "omnisource_runner.OmniSourceRunner.call_hook"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.cycle", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run_iter", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run_iter"], ["", "def", "train", "(", "self", ",", "data_loaders", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "mode", "=", "'train'", "\n", "self", ".", "data_loaders", "=", "data_loaders", "\n", "self", ".", "main_loader", "=", "self", ".", "data_loaders", "[", "0", "]", "\n", "# Add aliasing", "\n", "self", ".", "data_loader", "=", "self", ".", "main_loader", "\n", "self", ".", "aux_loaders", "=", "self", ".", "data_loaders", "[", "1", ":", "]", "\n", "self", ".", "aux_iters", "=", "[", "cycle", "(", "loader", ")", "for", "loader", "in", "self", ".", "aux_loaders", "]", "\n", "\n", "auxiliary_iter_times", "=", "[", "1", "]", "*", "len", "(", "self", ".", "aux_loaders", ")", "\n", "use_aux_per_niter", "=", "1", "\n", "if", "'train_ratio'", "in", "kwargs", ":", "\n", "            ", "train_ratio", "=", "kwargs", ".", "pop", "(", "'train_ratio'", ")", "\n", "use_aux_per_niter", "=", "train_ratio", "[", "0", "]", "\n", "auxiliary_iter_times", "=", "train_ratio", "[", "1", ":", "]", "\n", "\n", "", "self", ".", "_max_iters", "=", "self", ".", "_max_epochs", "*", "len", "(", "self", ".", "main_loader", ")", "\n", "\n", "self", ".", "call_hook", "(", "'before_train_epoch'", ")", "\n", "time", ".", "sleep", "(", "2", ")", "# Prevent possible deadlock during epoch transition", "\n", "\n", "for", "i", ",", "data_batch", "in", "enumerate", "(", "self", ".", "main_loader", ")", ":", "\n", "            ", "self", ".", "_inner_iter", "=", "i", "\n", "self", ".", "call_hook", "(", "'before_train_iter'", ")", "\n", "self", ".", "run_iter", "(", "data_batch", ",", "train_mode", "=", "True", ",", "source", "=", "''", ")", "\n", "self", ".", "call_hook", "(", "'after_train_iter'", ")", "\n", "\n", "if", "self", ".", "_iter", "%", "use_aux_per_niter", "!=", "0", ":", "\n", "                ", "self", ".", "_iter", "+=", "1", "\n", "continue", "\n", "\n", "", "for", "idx", ",", "n_times", "in", "enumerate", "(", "auxiliary_iter_times", ")", ":", "\n", "                ", "for", "_", "in", "range", "(", "n_times", ")", ":", "\n", "                    ", "data_batch", "=", "next", "(", "self", ".", "aux_iters", "[", "idx", "]", ")", "\n", "self", ".", "call_hook", "(", "'before_train_iter'", ")", "\n", "self", ".", "run_iter", "(", "\n", "data_batch", ",", "train_mode", "=", "True", ",", "source", "=", "f'/aux{idx}'", ")", "\n", "self", ".", "call_hook", "(", "'after_train_iter'", ")", "\n", "", "", "self", ".", "_iter", "+=", "1", "\n", "\n", "", "self", ".", "call_hook", "(", "'after_train_epoch'", ")", "\n", "self", ".", "_epoch", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.val": [[104, 106], ["None"], "methods", ["None"], ["", "def", "val", "(", "self", ",", "data_loader", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run": [[107, 163], ["isinstance", "mmcv.is_list_of", "omnisource_runner.OmniSourceRunner.logger.info", "omnisource_runner.OmniSourceRunner.logger.info", "omnisource_runner.OmniSourceRunner.call_hook", "time.sleep", "omnisource_runner.OmniSourceRunner.call_hook", "warnings.warn", "len", "mmcv.runner.utils.get_host_info", "isinstance", "range", "len", "getattr", "TypeError", "getattr.", "hasattr", "ValueError"], "methods", ["None"], ["", "def", "run", "(", "self", ",", "data_loaders", ",", "workflow", ",", "max_epochs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Start running.\n\n        Args:\n            data_loaders (list[:obj:`DataLoader`]): Dataloaders for training.\n                `data_loaders[0]` is the main data_loader, which contains\n                target datasets and determines the epoch length.\n                `data_loaders[1:]` are auxiliary data loaders, which contain\n                auxiliary web datasets.\n            workflow (list[tuple]): A list of (phase, epochs) to specify the\n                running order and epochs. E.g, [('train', 2)] means running 2\n                epochs for training iteratively. Note that val epoch is not\n                supported for this runner for simplicity.\n            max_epochs (int | None): The max epochs that training lasts,\n                deprecated now. Default: None.\n        \"\"\"", "\n", "assert", "isinstance", "(", "data_loaders", ",", "list", ")", "\n", "assert", "mmcv", ".", "is_list_of", "(", "workflow", ",", "tuple", ")", "\n", "assert", "len", "(", "workflow", ")", "==", "1", "and", "workflow", "[", "0", "]", "[", "0", "]", "==", "'train'", "\n", "if", "max_epochs", "is", "not", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'setting max_epochs in run is deprecated, '", "\n", "'please set max_epochs in runner_config'", ",", "DeprecationWarning", ")", "\n", "self", ".", "_max_epochs", "=", "max_epochs", "\n", "\n", "", "assert", "self", ".", "_max_epochs", "is", "not", "None", ",", "(", "\n", "'max_epochs must be specified during instantiation'", ")", "\n", "\n", "mode", ",", "epochs", "=", "workflow", "[", "0", "]", "\n", "self", ".", "_max_iters", "=", "self", ".", "_max_epochs", "*", "len", "(", "data_loaders", "[", "0", "]", ")", "\n", "\n", "work_dir", "=", "self", ".", "work_dir", "if", "self", ".", "work_dir", "is", "not", "None", "else", "'NONE'", "\n", "self", ".", "logger", ".", "info", "(", "'Start running, host: %s, work_dir: %s'", ",", "\n", "get_host_info", "(", ")", ",", "work_dir", ")", "\n", "self", ".", "logger", ".", "info", "(", "'workflow: %s, max: %d epochs'", ",", "workflow", ",", "\n", "self", ".", "_max_epochs", ")", "\n", "self", ".", "call_hook", "(", "'before_run'", ")", "\n", "\n", "while", "self", ".", "epoch", "<", "self", ".", "_max_epochs", ":", "\n", "            ", "if", "isinstance", "(", "mode", ",", "str", ")", ":", "# self.train()", "\n", "                ", "if", "not", "hasattr", "(", "self", ",", "mode", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "f'runner has no method named \"{mode}\" to run an '", "\n", "'epoch'", ")", "\n", "", "epoch_runner", "=", "getattr", "(", "self", ",", "mode", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\n", "f'mode in workflow must be a str, but got {mode}'", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "epochs", ")", ":", "\n", "                ", "if", "mode", "==", "'train'", "and", "self", ".", "epoch", ">=", "self", ".", "_max_epochs", ":", "\n", "                    ", "break", "\n", "", "epoch_runner", "(", "data_loaders", ",", "**", "kwargs", ")", "\n", "\n", "", "", "time", ".", "sleep", "(", "1", ")", "# wait for some hooks like loggers to finish", "\n", "self", ".", "call_hook", "(", "'after_run'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.cycle": [[10, 17], ["iter", "next", "iter"], "function", ["None"], ["def", "cycle", "(", "iterable", ")", ":", "\n", "    ", "iterator", "=", "iter", "(", "iterable", ")", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "yield", "next", "(", "iterator", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "iterator", "=", "iter", "(", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo.parse_args": [[15, 66], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'MMAction2 demo'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "'video'", ",", "help", "=", "'video file/url or rawframes directory'", ")", "\n", "parser", ".", "add_argument", "(", "'label'", ",", "help", "=", "'label file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use-frames'", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use rawframes as input'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'CPU/CUDA device option'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fps'", ",", "\n", "default", "=", "30", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'specify fps value of the output video when using rawframes to '", "\n", "'generate file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--font-scale'", ",", "\n", "default", "=", "0.5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "'font scale of the label in output video'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--font-color'", ",", "\n", "default", "=", "'white'", ",", "\n", "help", "=", "'font color of the label in output video'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--target-resolution'", ",", "\n", "nargs", "=", "2", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Target resolution (w, h) for resizing the frames when using a '", "\n", "'video as input. If either dimension is set to -1, the frames are '", "\n", "'resized by keeping the existing aspect ratio'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resize-algorithm'", ",", "\n", "default", "=", "'bicubic'", ",", "\n", "help", "=", "'resize algorithm applied to generate video'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-filename'", ",", "default", "=", "None", ",", "help", "=", "'output filename'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo.get_output": [[68, 151], ["video_path.startswith", "isinstance", "ImageSequenceClip", "sorted", "decord.VideoReader", "cv2.getTextSize", "numpy.array", "cv2.putText", "ImageSequenceClip.write_gif", "ImageSequenceClip.write_videofile", "ImportError", "cv2.imread", "int", "int", "cv2.resize", "webcolors.name_to_rgb", "os.splitext", "os.join", "x.asnumpy", "os.listdir", "os.listdir"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "get_output", "(", "video_path", ",", "\n", "out_filename", ",", "\n", "label", ",", "\n", "fps", "=", "30", ",", "\n", "font_scale", "=", "0.5", ",", "\n", "font_color", "=", "'white'", ",", "\n", "target_resolution", "=", "None", ",", "\n", "resize_algorithm", "=", "'bicubic'", ",", "\n", "use_frames", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get demo output using ``moviepy``.\n\n    This function will generate video file or gif file from raw video or\n    frames, by using ``moviepy``. For more information of some parameters,\n    you can refer to: https://github.com/Zulko/moviepy.\n\n    Args:\n        video_path (str): The video file path or the rawframes directory path.\n            If ``use_frames`` is set to True, it should be rawframes directory\n            path. Otherwise, it should be video file path.\n        out_filename (str): Output filename for the generated file.\n        label (str): Predicted label of the generated file.\n        fps (int): Number of picture frames to read per second. Default: 30.\n        font_scale (float): Font scale of the label. Default: 0.5.\n        font_color (str): Font color of the label. Default: 'white'.\n        target_resolution (None | tuple[int | None]): Set to\n            (desired_width desired_height) to have resized frames. If either\n            dimension is None, the frames are resized by keeping the existing\n            aspect ratio. Default: None.\n        resize_algorithm (str): Support \"bicubic\", \"bilinear\", \"neighbor\",\n            \"lanczos\", etc. Default: 'bicubic'. For more information,\n            see https://ffmpeg.org/ffmpeg-scaler.html\n        use_frames: Determine Whether to use rawframes as input. Default:False.\n    \"\"\"", "\n", "\n", "if", "video_path", ".", "startswith", "(", "(", "'http://'", ",", "'https://'", ")", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "try", ":", "\n", "        ", "from", "moviepy", ".", "editor", "import", "ImageSequenceClip", "\n", "", "except", "ImportError", ":", "\n", "        ", "raise", "ImportError", "(", "'Please install moviepy to enable output file.'", ")", "\n", "\n", "# Channel Order is BGR", "\n", "", "if", "use_frames", ":", "\n", "        ", "frame_list", "=", "sorted", "(", "\n", "[", "osp", ".", "join", "(", "video_path", ",", "x", ")", "for", "x", "in", "os", ".", "listdir", "(", "video_path", ")", "]", ")", "\n", "frames", "=", "[", "cv2", ".", "imread", "(", "x", ")", "for", "x", "in", "frame_list", "]", "\n", "", "else", ":", "\n", "        ", "video", "=", "decord", ".", "VideoReader", "(", "video_path", ")", "\n", "frames", "=", "[", "x", ".", "asnumpy", "(", ")", "[", "...", ",", ":", ":", "-", "1", "]", "for", "x", "in", "video", "]", "\n", "\n", "", "if", "target_resolution", ":", "\n", "        ", "w", ",", "h", "=", "target_resolution", "\n", "frame_h", ",", "frame_w", ",", "_", "=", "frames", "[", "0", "]", ".", "shape", "\n", "if", "w", "==", "-", "1", ":", "\n", "            ", "w", "=", "int", "(", "h", "/", "frame_h", "*", "frame_w", ")", "\n", "", "if", "h", "==", "-", "1", ":", "\n", "            ", "h", "=", "int", "(", "w", "/", "frame_w", "*", "frame_h", ")", "\n", "", "frames", "=", "[", "cv2", ".", "resize", "(", "f", ",", "(", "w", ",", "h", ")", ")", "for", "f", "in", "frames", "]", "\n", "\n", "", "textsize", "=", "cv2", ".", "getTextSize", "(", "label", ",", "cv2", ".", "FONT_HERSHEY_DUPLEX", ",", "font_scale", ",", "\n", "1", ")", "[", "0", "]", "\n", "textheight", "=", "textsize", "[", "1", "]", "\n", "padding", "=", "10", "\n", "location", "=", "(", "padding", ",", "padding", "+", "textheight", ")", "\n", "\n", "if", "isinstance", "(", "font_color", ",", "str", ")", ":", "\n", "        ", "font_color", "=", "webcolors", ".", "name_to_rgb", "(", "font_color", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "", "frames", "=", "[", "np", ".", "array", "(", "frame", ")", "for", "frame", "in", "frames", "]", "\n", "for", "frame", "in", "frames", ":", "\n", "        ", "cv2", ".", "putText", "(", "frame", ",", "label", ",", "location", ",", "cv2", ".", "FONT_HERSHEY_DUPLEX", ",", "\n", "font_scale", ",", "font_color", ",", "1", ")", "\n", "\n", "# RGB order", "\n", "", "frames", "=", "[", "x", "[", "...", ",", ":", ":", "-", "1", "]", "for", "x", "in", "frames", "]", "\n", "video_clips", "=", "ImageSequenceClip", "(", "frames", ",", "fps", "=", "fps", ")", "\n", "\n", "out_type", "=", "osp", ".", "splitext", "(", "out_filename", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "if", "out_type", "==", "'gif'", ":", "\n", "        ", "video_clips", ".", "write_gif", "(", "out_filename", ")", "\n", "", "else", ":", "\n", "        ", "video_clips", ".", "write_videofile", "(", "out_filename", ",", "remove_temp", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo.main": [[153, 205], ["demo.parse_args", "torch.device", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "mmaction.apis.init_recognizer", "print", "mmaction.apis.inference_recognizer", "mmaction.apis.inference_recognizer", "print", "demo.get_output", "tuple", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo.get_output"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "# assign the desired device.", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "# build the recognizer from a config file and checkpoint file/url", "\n", "model", "=", "init_recognizer", "(", "\n", "cfg", ",", "args", ".", "checkpoint", ",", "device", "=", "device", ",", "use_frames", "=", "args", ".", "use_frames", ")", "\n", "\n", "# e.g. use ('backbone', ) to return backbone feature", "\n", "output_layer_names", "=", "None", "\n", "\n", "# test a single video or rawframes of a single video", "\n", "if", "output_layer_names", ":", "\n", "        ", "results", ",", "returned_feature", "=", "inference_recognizer", "(", "\n", "model", ",", "\n", "args", ".", "video", ",", "\n", "args", ".", "label", ",", "\n", "use_frames", "=", "args", ".", "use_frames", ",", "\n", "outputs", "=", "output_layer_names", ")", "\n", "", "else", ":", "\n", "        ", "results", "=", "inference_recognizer", "(", "\n", "model", ",", "args", ".", "video", ",", "args", ".", "label", ",", "use_frames", "=", "args", ".", "use_frames", ")", "\n", "\n", "", "print", "(", "'The top-5 labels with corresponding scores are:'", ")", "\n", "for", "result", "in", "results", ":", "\n", "        ", "print", "(", "f'{result[0]}: '", ",", "result", "[", "1", "]", ")", "\n", "\n", "", "if", "args", ".", "out_filename", "is", "not", "None", ":", "\n", "\n", "        ", "if", "args", ".", "target_resolution", "is", "not", "None", ":", "\n", "            ", "if", "args", ".", "target_resolution", "[", "0", "]", "==", "-", "1", ":", "\n", "                ", "assert", "isinstance", "(", "args", ".", "target_resolution", "[", "1", "]", ",", "int", ")", "\n", "assert", "args", ".", "target_resolution", "[", "1", "]", ">", "0", "\n", "", "if", "args", ".", "target_resolution", "[", "1", "]", "==", "-", "1", ":", "\n", "                ", "assert", "isinstance", "(", "args", ".", "target_resolution", "[", "0", "]", ",", "int", ")", "\n", "assert", "args", ".", "target_resolution", "[", "0", "]", ">", "0", "\n", "", "args", ".", "target_resolution", "=", "tuple", "(", "args", ".", "target_resolution", ")", "\n", "\n", "", "get_output", "(", "\n", "args", ".", "video", ",", "\n", "args", ".", "out_filename", ",", "\n", "results", "[", "0", "]", "[", "0", "]", ",", "\n", "fps", "=", "args", ".", "fps", ",", "\n", "font_scale", "=", "args", ".", "font_scale", ",", "\n", "font_color", "=", "args", ".", "font_color", ",", "\n", "target_resolution", "=", "args", ".", "target_resolution", ",", "\n", "resize_algorithm", "=", "args", ".", "resize_algorithm", ",", "\n", "use_frames", "=", "args", ".", "use_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.hex2color": [[44, 47], ["int", "int", "int"], "function", ["None"], ["def", "hex2color", "(", "h", ")", ":", "\n", "    ", "\"\"\"Convert the 6-digit hex string to tuple of 3 int value (RGB)\"\"\"", "\n", "return", "(", "int", "(", "h", "[", ":", "2", "]", ",", "16", ")", ",", "int", "(", "h", "[", "2", ":", "4", "]", ",", "16", ")", ",", "int", "(", "h", "[", "4", ":", "]", ",", "16", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.visualize": [[57, 113], ["copy.deepcopy", "numpy.array", "range", "len", "len", "len", "len", "len", "range", "cv2.rectangle", "enumerate", "len", "tuple", "tuple", "demo_spatiotemporal_det.abbrev", "cv2.rectangle", "cv2.putText", "cv2.getTextSize", "str"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.abbrev"], ["def", "visualize", "(", "frames", ",", "annotations", ",", "plate", "=", "plate_blue", ",", "max_num", "=", "5", ")", ":", "\n", "    ", "\"\"\"Visualize frames with predicted annotations.\n\n    Args:\n        frames (list[np.ndarray]): Frames for visualization, note that\n            len(frames) % len(annotations) should be 0.\n        annotations (list[list[tuple]]): The predicted results.\n        plate (str): The plate used for visualization. Default: plate_blue.\n        max_num (int): Max number of labels to visualize for a person box.\n            Default: 5.\n\n    Returns:\n        list[np.ndarray]: Visualized frames.\n    \"\"\"", "\n", "\n", "assert", "max_num", "+", "1", "<=", "len", "(", "plate", ")", "\n", "plate", "=", "[", "x", "[", ":", ":", "-", "1", "]", "for", "x", "in", "plate", "]", "\n", "frames_", "=", "cp", ".", "deepcopy", "(", "frames", ")", "\n", "nf", ",", "na", "=", "len", "(", "frames", ")", ",", "len", "(", "annotations", ")", "\n", "assert", "nf", "%", "na", "==", "0", "\n", "nfpa", "=", "len", "(", "frames", ")", "//", "len", "(", "annotations", ")", "\n", "anno", "=", "None", "\n", "h", ",", "w", ",", "_", "=", "frames", "[", "0", "]", ".", "shape", "\n", "scale_ratio", "=", "np", ".", "array", "(", "[", "w", ",", "h", ",", "w", ",", "h", "]", ")", "\n", "for", "i", "in", "range", "(", "na", ")", ":", "\n", "        ", "anno", "=", "annotations", "[", "i", "]", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "continue", "\n", "", "for", "j", "in", "range", "(", "nfpa", ")", ":", "\n", "            ", "ind", "=", "i", "*", "nfpa", "+", "j", "\n", "frame", "=", "frames_", "[", "ind", "]", "\n", "for", "ann", "in", "anno", ":", "\n", "                ", "box", "=", "ann", "[", "0", "]", "\n", "label", "=", "ann", "[", "1", "]", "\n", "if", "not", "len", "(", "label", ")", ":", "\n", "                    ", "continue", "\n", "", "score", "=", "ann", "[", "2", "]", "\n", "box", "=", "(", "box", "*", "scale_ratio", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "st", ",", "ed", "=", "tuple", "(", "box", "[", ":", "2", "]", ")", ",", "tuple", "(", "box", "[", "2", ":", "]", ")", "\n", "cv2", ".", "rectangle", "(", "frame", ",", "st", ",", "ed", ",", "plate", "[", "0", "]", ",", "2", ")", "\n", "for", "k", ",", "lb", "in", "enumerate", "(", "label", ")", ":", "\n", "                    ", "if", "k", ">=", "max_num", ":", "\n", "                        ", "break", "\n", "", "text", "=", "abbrev", "(", "lb", ")", "\n", "text", "=", "': '", ".", "join", "(", "[", "text", ",", "str", "(", "score", "[", "k", "]", ")", "]", ")", "\n", "location", "=", "(", "0", "+", "st", "[", "0", "]", ",", "18", "+", "k", "*", "18", "+", "st", "[", "1", "]", ")", "\n", "textsize", "=", "cv2", ".", "getTextSize", "(", "text", ",", "FONTFACE", ",", "FONTSCALE", ",", "\n", "THICKNESS", ")", "[", "0", "]", "\n", "textwidth", "=", "textsize", "[", "0", "]", "\n", "diag0", "=", "(", "location", "[", "0", "]", "+", "textwidth", ",", "location", "[", "1", "]", "-", "14", ")", "\n", "diag1", "=", "(", "location", "[", "0", "]", ",", "location", "[", "1", "]", "+", "2", ")", "\n", "cv2", ".", "rectangle", "(", "frame", ",", "diag0", ",", "diag1", ",", "plate", "[", "k", "+", "1", "]", ",", "-", "1", ")", "\n", "cv2", ".", "putText", "(", "frame", ",", "text", ",", "location", ",", "FONTFACE", ",", "FONTSCALE", ",", "\n", "FONTCOLOR", ",", "THICKNESS", ",", "LINETYPE", ")", "\n", "\n", "", "", "", "", "return", "frames_", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.parse_args": [[115, 185], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'MMAction2 demo'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--config'", ",", "\n", "default", "=", "(", "'configs/detection/ava/'", "\n", "'slowonly_omnisource_pretrained_r101_8x8x1_20e_ava_rgb.py'", ")", ",", "\n", "help", "=", "'spatio temporal detection config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--checkpoint'", ",", "\n", "default", "=", "(", "'https://download.openmmlab.com/mmaction/detection/ava/'", "\n", "'slowonly_omnisource_pretrained_r101_8x8x1_20e_ava_rgb/'", "\n", "'slowonly_omnisource_pretrained_r101_8x8x1_20e_ava_rgb'", "\n", "'_20201217-16378594.pth'", ")", ",", "\n", "help", "=", "'spatio temporal detection checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-config'", ",", "\n", "default", "=", "'demo/faster_rcnn_r50_fpn_2x_coco.py'", ",", "\n", "help", "=", "'human detection config file path (from mmdet)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-checkpoint'", ",", "\n", "default", "=", "(", "'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/'", "\n", "'faster_rcnn_r50_fpn_2x_coco/'", "\n", "'faster_rcnn_r50_fpn_2x_coco_'", "\n", "'bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'", ")", ",", "\n", "help", "=", "'human detection checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.9", ",", "\n", "help", "=", "'the threshold of human detection score'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--action-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.5", ",", "\n", "help", "=", "'the threshold of human action score'", ")", "\n", "parser", ".", "add_argument", "(", "'--video'", ",", "help", "=", "'video file/url'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--label-map'", ",", "default", "=", "'demo/label_map_ava.txt'", ",", "help", "=", "'label map file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'CPU/CUDA device option'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--out-filename'", ",", "\n", "default", "=", "'demo/stdet_demo.mp4'", ",", "\n", "help", "=", "'output filename'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--predict-stepsize'", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'give out a prediction per n frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output-stepsize'", ",", "\n", "default", "=", "4", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "(", "'show one frame per n frames in the demo, we should have: '", "\n", "'predict_stepsize % output_stepsize == 0'", ")", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output-fps'", ",", "\n", "default", "=", "6", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'the fps of demo video output'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.frame_extraction": [[187, 211], ["os.join", "os.makedirs", "os.makedirs", "os.join", "cv2.VideoCapture", "cv2.VideoCapture.read", "os.basename", "frames.append", "osp.join.format", "frame_paths.append", "cv2.imwrite", "cv2.VideoCapture.read", "os.splitext"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "frame_extraction", "(", "video_path", ")", ":", "\n", "    ", "\"\"\"Extract frames given video_path.\n\n    Args:\n        video_path (str): The video_path.\n    \"\"\"", "\n", "# Load the video, extract frames into /tmp/video_name", "\n", "target_dir", "=", "osp", ".", "join", "(", "'./tmp'", ",", "osp", ".", "basename", "(", "osp", ".", "splitext", "(", "video_path", ")", "[", "0", "]", ")", ")", "\n", "os", ".", "makedirs", "(", "target_dir", ",", "exist_ok", "=", "True", ")", "\n", "# Should be able to handle videos up to several hours", "\n", "frame_tmpl", "=", "osp", ".", "join", "(", "target_dir", ",", "'img_{:06d}.jpg'", ")", "\n", "vid", "=", "cv2", ".", "VideoCapture", "(", "video_path", ")", "\n", "frames", "=", "[", "]", "\n", "frame_paths", "=", "[", "]", "\n", "flag", ",", "frame", "=", "vid", ".", "read", "(", ")", "\n", "cnt", "=", "0", "\n", "while", "flag", ":", "\n", "        ", "frames", ".", "append", "(", "frame", ")", "\n", "frame_path", "=", "frame_tmpl", ".", "format", "(", "cnt", "+", "1", ")", "\n", "frame_paths", ".", "append", "(", "frame_path", ")", "\n", "cv2", ".", "imwrite", "(", "frame_path", ",", "frame", ")", "\n", "cnt", "+=", "1", "\n", "flag", ",", "frame", "=", "vid", ".", "read", "(", ")", "\n", "", "return", "frame_paths", ",", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.detection_inference": [[213, 234], ["init_detector", "print", "tqdm.tqdm", "inference_detector", "results.append"], "function", ["None"], ["", "def", "detection_inference", "(", "args", ",", "frame_paths", ")", ":", "\n", "    ", "\"\"\"Detect human boxes given frame paths.\n\n    Args:\n        args (argparse.Namespace): The arguments.\n        frame_paths (list[str]): The paths of frames to do detection inference.\n\n    Returns:\n        list[np.ndarray]: The human detection results.\n    \"\"\"", "\n", "model", "=", "init_detector", "(", "args", ".", "det_config", ",", "args", ".", "det_checkpoint", ",", "args", ".", "device", ")", "\n", "assert", "model", ".", "CLASSES", "[", "0", "]", "==", "'person'", ",", "(", "'We require you to use a detector '", "\n", "'trained on COCO'", ")", "\n", "results", "=", "[", "]", "\n", "print", "(", "'Performing Human Detection for each frame'", ")", "\n", "for", "frame_path", "in", "tqdm", "(", "frame_paths", ")", ":", "\n", "        ", "result", "=", "inference_detector", "(", "model", ",", "frame_path", ")", "\n", "# We only keep human detections with score larger than det_score_thr", "\n", "result", "=", "result", "[", "0", "]", "[", "result", "[", "0", "]", "[", ":", ",", "4", "]", ">=", "args", ".", "det_score_thr", "]", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.load_label_map": [[236, 248], ["open().readlines", "x.strip().split", "int", "open", "x.strip"], "function", ["None"], ["", "def", "load_label_map", "(", "file_path", ")", ":", "\n", "    ", "\"\"\"Load Label Map.\n\n    Args:\n        file_path (str): The file path of label map.\n\n    Returns:\n        dict: The label map (int -> label name).\n    \"\"\"", "\n", "lines", "=", "open", "(", "file_path", ")", ".", "readlines", "(", ")", "\n", "lines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "': '", ")", "for", "x", "in", "lines", "]", "\n", "return", "{", "int", "(", "x", "[", "0", "]", ")", ":", "x", "[", "1", "]", "for", "x", "in", "lines", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.abbrev": [[250, 259], ["name.find", "name.find", "name.find"], "function", ["None"], ["", "def", "abbrev", "(", "name", ")", ":", "\n", "    ", "\"\"\"Get the abbreviation of label name:\n\n    'take (an object) from (a person)' -> 'take ... from ...'\n    \"\"\"", "\n", "while", "name", ".", "find", "(", "'('", ")", "!=", "-", "1", ":", "\n", "        ", "st", ",", "ed", "=", "name", ".", "find", "(", "'('", ")", ",", "name", ".", "find", "(", "')'", ")", "\n", "name", "=", "name", "[", ":", "st", "]", "+", "'...'", "+", "name", "[", "ed", "+", "1", ":", "]", "\n", "", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.pack_result": [[261, 284], ["zip", "res.sort", "results.append", "prop.data.cpu().numpy", "prop.data.cpu"], "function", ["None"], ["", "def", "pack_result", "(", "human_detection", ",", "result", ",", "img_h", ",", "img_w", ")", ":", "\n", "    ", "\"\"\"Short summary.\n\n    Args:\n        human_detection (np.ndarray): Human detection result.\n        result (type): The predicted label of each human proposal.\n        img_h (int): The image height.\n        img_w (int): The image width.\n\n    Returns:\n        tuple: Tuple of human proposal, label name and label score.\n    \"\"\"", "\n", "human_detection", "[", ":", ",", "0", ":", ":", "2", "]", "/=", "img_w", "\n", "human_detection", "[", ":", ",", "1", ":", ":", "2", "]", "/=", "img_h", "\n", "results", "=", "[", "]", "\n", "if", "result", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "for", "prop", ",", "res", "in", "zip", "(", "human_detection", ",", "result", ")", ":", "\n", "        ", "res", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "results", ".", "append", "(", "\n", "(", "prop", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "x", "[", "0", "]", "for", "x", "in", "res", "]", ",", "[", "x", "[", "1", "]", "\n", "for", "x", "in", "res", "]", ")", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.main": [[286, 418], ["demo_spatiotemporal_det.parse_args", "demo_spatiotemporal_det.frame_extraction", "len", "mmcv.rescale_size", "mmcv.Config.fromfile", "mmcv.Config.fromfile.merge_from_dict", "numpy.arange", "demo_spatiotemporal_det.load_label_map", "demo_spatiotemporal_det.detection_inference", "range", "numpy.array", "numpy.array", "mmaction.models.build_detector", "mmcv.runner.load_checkpoint", "mmaction.models.build_detector.to", "mmaction.models.build_detector.eval", "print", "tqdm.tqdm", "zip", "int", "print", "demo_spatiotemporal_det.visualize", "mpy.ImageSequenceClip", "mpy.ImageSequenceClip.write_videofile", "os.dirname", "shutil.rmtree", "mmcv.imresize", "len", "torch.from_numpy().to", "img_norm_cfg.pop", "zip", "list", "torch.from_numpy().to", "results.append", "new_frame_inds.astype", "cv2.imread", "mmcv.Config.fromfile.get", "predictions.append", "numpy.arange", "frames[].astype", "mmcv.imnormalize_", "numpy.stack().transpose", "torch.no_grad", "mmaction.models.build_detector.", "range", "range", "predictions.append", "demo_spatiotemporal_det.pack_result", "demo_spatiotemporal_det.main.dense_timestamps"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.frame_extraction", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.load_label_map", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.detection_inference", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.visualize", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.pack_result"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "frame_paths", ",", "original_frames", "=", "frame_extraction", "(", "args", ".", "video", ")", "\n", "num_frame", "=", "len", "(", "frame_paths", ")", "\n", "h", ",", "w", ",", "_", "=", "original_frames", "[", "0", "]", ".", "shape", "\n", "\n", "# resize frames to shortside 256", "\n", "new_w", ",", "new_h", "=", "mmcv", ".", "rescale_size", "(", "(", "w", ",", "h", ")", ",", "(", "256", ",", "np", ".", "Inf", ")", ")", "\n", "frames", "=", "[", "mmcv", ".", "imresize", "(", "img", ",", "(", "new_w", ",", "new_h", ")", ")", "for", "img", "in", "original_frames", "]", "\n", "w_ratio", ",", "h_ratio", "=", "new_w", "/", "w", ",", "new_h", "/", "h", "\n", "\n", "# Get clip_len, frame_interval and calculate center index of each clip", "\n", "config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "config", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "val_pipeline", "=", "config", ".", "data", ".", "val", ".", "pipeline", "\n", "\n", "sampler", "=", "[", "x", "for", "x", "in", "val_pipeline", "if", "x", "[", "'type'", "]", "==", "'SampleAVAFrames'", "]", "[", "0", "]", "\n", "clip_len", ",", "frame_interval", "=", "sampler", "[", "'clip_len'", "]", ",", "sampler", "[", "'frame_interval'", "]", "\n", "window_size", "=", "clip_len", "*", "frame_interval", "\n", "assert", "clip_len", "%", "2", "==", "0", ",", "'We would like to have an even clip_len'", "\n", "# Note that it's 1 based here", "\n", "timestamps", "=", "np", ".", "arange", "(", "window_size", "//", "2", ",", "num_frame", "+", "1", "-", "window_size", "//", "2", ",", "\n", "args", ".", "predict_stepsize", ")", "\n", "\n", "# Load label_map", "\n", "label_map", "=", "load_label_map", "(", "args", ".", "label_map", ")", "\n", "try", ":", "\n", "        ", "if", "config", "[", "'data'", "]", "[", "'train'", "]", "[", "'custom_classes'", "]", "is", "not", "None", ":", "\n", "            ", "label_map", "=", "{", "\n", "id", "+", "1", ":", "label_map", "[", "cls", "]", "\n", "for", "id", ",", "cls", "in", "enumerate", "(", "config", "[", "'data'", "]", "[", "'train'", "]", "\n", "[", "'custom_classes'", "]", ")", "\n", "}", "\n", "", "", "except", "KeyError", ":", "\n", "        ", "pass", "\n", "\n", "# Get Human detection results", "\n", "", "center_frames", "=", "[", "frame_paths", "[", "ind", "-", "1", "]", "for", "ind", "in", "timestamps", "]", "\n", "human_detections", "=", "detection_inference", "(", "args", ",", "center_frames", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "human_detections", ")", ")", ":", "\n", "        ", "det", "=", "human_detections", "[", "i", "]", "\n", "det", "[", ":", ",", "0", ":", "4", ":", "2", "]", "*=", "w_ratio", "\n", "det", "[", ":", ",", "1", ":", "4", ":", "2", "]", "*=", "h_ratio", "\n", "human_detections", "[", "i", "]", "=", "torch", ".", "from_numpy", "(", "det", "[", ":", ",", ":", "4", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Get img_norm_cfg", "\n", "", "img_norm_cfg", "=", "config", "[", "'img_norm_cfg'", "]", "\n", "if", "'to_rgb'", "not", "in", "img_norm_cfg", "and", "'to_bgr'", "in", "img_norm_cfg", ":", "\n", "        ", "to_bgr", "=", "img_norm_cfg", ".", "pop", "(", "'to_bgr'", ")", "\n", "img_norm_cfg", "[", "'to_rgb'", "]", "=", "to_bgr", "\n", "", "img_norm_cfg", "[", "'mean'", "]", "=", "np", ".", "array", "(", "img_norm_cfg", "[", "'mean'", "]", ")", "\n", "img_norm_cfg", "[", "'std'", "]", "=", "np", ".", "array", "(", "img_norm_cfg", "[", "'std'", "]", ")", "\n", "\n", "# Build STDET model", "\n", "try", ":", "\n", "# In our spatiotemporal detection demo, different actions should have", "\n", "# the same number of bboxes.", "\n", "        ", "config", "[", "'model'", "]", "[", "'test_cfg'", "]", "[", "'rcnn'", "]", "[", "'action_thr'", "]", "=", ".0", "\n", "", "except", "KeyError", ":", "\n", "        ", "pass", "\n", "\n", "", "config", ".", "model", ".", "backbone", ".", "pretrained", "=", "None", "\n", "model", "=", "build_detector", "(", "config", ".", "model", ",", "test_cfg", "=", "config", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "load_checkpoint", "(", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "args", ".", "device", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "\n", "print", "(", "'Performing SpatioTemporal Action Detection for each clip'", ")", "\n", "for", "timestamp", ",", "proposal", "in", "tqdm", "(", "zip", "(", "timestamps", ",", "human_detections", ")", ")", ":", "\n", "        ", "if", "proposal", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "predictions", ".", "append", "(", "None", ")", "\n", "continue", "\n", "\n", "", "start_frame", "=", "timestamp", "-", "(", "clip_len", "//", "2", "-", "1", ")", "*", "frame_interval", "\n", "frame_inds", "=", "start_frame", "+", "np", ".", "arange", "(", "0", ",", "window_size", ",", "frame_interval", ")", "\n", "frame_inds", "=", "list", "(", "frame_inds", "-", "1", ")", "\n", "imgs", "=", "[", "frames", "[", "ind", "]", ".", "astype", "(", "np", ".", "float32", ")", "for", "ind", "in", "frame_inds", "]", "\n", "_", "=", "[", "mmcv", ".", "imnormalize_", "(", "img", ",", "**", "img_norm_cfg", ")", "for", "img", "in", "imgs", "]", "\n", "# THWC -> CTHW -> 1CTHW", "\n", "input_array", "=", "np", ".", "stack", "(", "imgs", ")", ".", "transpose", "(", "(", "3", ",", "0", ",", "1", ",", "2", ")", ")", "[", "np", ".", "newaxis", "]", "\n", "input_tensor", "=", "torch", ".", "from_numpy", "(", "input_array", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "result", "=", "model", "(", "\n", "return_loss", "=", "False", ",", "\n", "img", "=", "[", "input_tensor", "]", ",", "\n", "img_metas", "=", "[", "[", "dict", "(", "img_shape", "=", "(", "new_h", ",", "new_w", ")", ")", "]", "]", ",", "\n", "proposals", "=", "[", "[", "proposal", "]", "]", ")", "\n", "result", "=", "result", "[", "0", "]", "\n", "prediction", "=", "[", "]", "\n", "# N proposals", "\n", "for", "i", "in", "range", "(", "proposal", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "prediction", ".", "append", "(", "[", "]", ")", "\n", "# Perform action score thr", "\n", "", "for", "i", "in", "range", "(", "len", "(", "result", ")", ")", ":", "\n", "                ", "if", "i", "+", "1", "not", "in", "label_map", ":", "\n", "                    ", "continue", "\n", "", "for", "j", "in", "range", "(", "proposal", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "if", "result", "[", "i", "]", "[", "j", ",", "4", "]", ">", "args", ".", "action_score_thr", ":", "\n", "                        ", "prediction", "[", "j", "]", ".", "append", "(", "(", "label_map", "[", "i", "+", "1", "]", ",", "result", "[", "i", "]", "[", "j", ",", "\n", "4", "]", ")", ")", "\n", "", "", "", "predictions", ".", "append", "(", "prediction", ")", "\n", "\n", "", "", "results", "=", "[", "]", "\n", "for", "human_detection", ",", "prediction", "in", "zip", "(", "human_detections", ",", "predictions", ")", ":", "\n", "        ", "results", ".", "append", "(", "pack_result", "(", "human_detection", ",", "prediction", ",", "new_h", ",", "new_w", ")", ")", "\n", "\n", "", "def", "dense_timestamps", "(", "timestamps", ",", "n", ")", ":", "\n", "        ", "\"\"\"Make it nx frames.\"\"\"", "\n", "old_frame_interval", "=", "(", "timestamps", "[", "1", "]", "-", "timestamps", "[", "0", "]", ")", "\n", "start", "=", "timestamps", "[", "0", "]", "-", "old_frame_interval", "/", "n", "*", "(", "n", "-", "1", ")", "/", "2", "\n", "new_frame_inds", "=", "np", ".", "arange", "(", "\n", "len", "(", "timestamps", ")", "*", "n", ")", "*", "old_frame_interval", "/", "n", "+", "start", "\n", "return", "new_frame_inds", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "", "dense_n", "=", "int", "(", "args", ".", "predict_stepsize", "/", "args", ".", "output_stepsize", ")", "\n", "frames", "=", "[", "\n", "cv2", ".", "imread", "(", "frame_paths", "[", "i", "-", "1", "]", ")", "\n", "for", "i", "in", "dense_timestamps", "(", "timestamps", ",", "dense_n", ")", "\n", "]", "\n", "print", "(", "'Performing visualization'", ")", "\n", "vis_frames", "=", "visualize", "(", "frames", ",", "results", ")", "\n", "vid", "=", "mpy", ".", "ImageSequenceClip", "(", "[", "x", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "for", "x", "in", "vis_frames", "]", ",", "\n", "fps", "=", "args", ".", "output_fps", ")", "\n", "vid", ".", "write_videofile", "(", "args", ".", "out_filename", ")", "\n", "\n", "tmp_frame_dir", "=", "osp", ".", "dirname", "(", "frame_paths", "[", "0", "]", ")", "\n", "shutil", ".", "rmtree", "(", "tmp_frame_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo.parse_args": [[29, 71], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'MMAction2 webcam demo'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'label'", ",", "help", "=", "'label file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'CPU/CUDA device option'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--camera-id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'camera device id'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--threshold'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.01", ",", "\n", "help", "=", "'recognition score threshold'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--average-size'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "'number of latest clips to be averaged for prediction'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--drawing-fps'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "20", ",", "\n", "help", "=", "'Set upper bound FPS value of the output drawing'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--inference-fps'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "4", ",", "\n", "help", "=", "'Set upper bound FPS value of model inference'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "assert", "args", ".", "drawing_fps", ">=", "0", "and", "args", ".", "inference_fps", ">=", "0", ",", "'upper bound FPS value of drawing and inference should be set as '", "'positive number, or zero for no limit'", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo.show_results": [[73, 117], ["print", "time.time", "camera.read", "frame_queue.append", "cv2.imshow", "cv2.waitKey", "numpy.array", "len", "result_queue.popleft", "enumerate", "time.time", "cv2.putText", "len", "text_info.items", "cv2.putText", "ord", "ord", "time.sleep", "str", "cv2.putText", "time.time", "round"], "function", ["None"], ["", "def", "show_results", "(", ")", ":", "\n", "    ", "print", "(", "'Press \"Esc\", \"q\" or \"Q\" to exit'", ")", "\n", "\n", "text_info", "=", "{", "}", "\n", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "while", "True", ":", "\n", "        ", "msg", "=", "'Waiting for action ...'", "\n", "_", ",", "frame", "=", "camera", ".", "read", "(", ")", "\n", "frame_queue", ".", "append", "(", "np", ".", "array", "(", "frame", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", ")", "\n", "\n", "if", "len", "(", "result_queue", ")", "!=", "0", ":", "\n", "            ", "text_info", "=", "{", "}", "\n", "results", "=", "result_queue", ".", "popleft", "(", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "results", ")", ":", "\n", "                ", "selected_label", ",", "score", "=", "result", "\n", "if", "score", "<", "threshold", ":", "\n", "                    ", "break", "\n", "", "location", "=", "(", "0", ",", "40", "+", "i", "*", "20", ")", "\n", "text", "=", "selected_label", "+", "': '", "+", "str", "(", "round", "(", "score", ",", "2", ")", ")", "\n", "text_info", "[", "location", "]", "=", "text", "\n", "cv2", ".", "putText", "(", "frame", ",", "text", ",", "location", ",", "FONTFACE", ",", "FONTSCALE", ",", "\n", "FONTCOLOR", ",", "THICKNESS", ",", "LINETYPE", ")", "\n", "\n", "", "", "elif", "len", "(", "text_info", ")", "!=", "0", ":", "\n", "            ", "for", "location", ",", "text", "in", "text_info", ".", "items", "(", ")", ":", "\n", "                ", "cv2", ".", "putText", "(", "frame", ",", "text", ",", "location", ",", "FONTFACE", ",", "FONTSCALE", ",", "\n", "FONTCOLOR", ",", "THICKNESS", ",", "LINETYPE", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "cv2", ".", "putText", "(", "frame", ",", "msg", ",", "(", "0", ",", "40", ")", ",", "FONTFACE", ",", "FONTSCALE", ",", "MSGCOLOR", ",", "\n", "THICKNESS", ",", "LINETYPE", ")", "\n", "\n", "", "cv2", ".", "imshow", "(", "'camera'", ",", "frame", ")", "\n", "ch", "=", "cv2", ".", "waitKey", "(", "1", ")", "\n", "\n", "if", "ch", "==", "27", "or", "ch", "==", "ord", "(", "'q'", ")", "or", "ch", "==", "ord", "(", "'Q'", ")", ":", "\n", "            ", "break", "\n", "\n", "", "if", "drawing_fps", ">", "0", ":", "\n", "# add a limiter for actual drawing fps <= drawing_fps", "\n", "            ", "sleep_time", "=", "1", "/", "drawing_fps", "-", "(", "time", ".", "time", "(", ")", "-", "cur_time", ")", "\n", "if", "sleep_time", ">", "0", ":", "\n", "                ", "time", ".", "sleep", "(", "sleep_time", ")", "\n", "", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo.inference": [[119, 166], ["collections.deque", "time.time", "camera.release", "cv2.destroyAllWindows", "data.copy", "test_pipeline", "mmcv.parallel.collate", "collections.deque.append", "len", "next", "torch.no_grad", "len", "min", "tuple", "sorted", "result_queue.append", "collections.deque.popleft", "time.time", "len", "list", "model.parameters", "mmcv.parallel.scatter", "model", "len", "zip", "time.sleep", "numpy.array", "operator.itemgetter", "time.time", "frame_queue.popleft"], "function", ["None"], ["", "", "", "def", "inference", "(", ")", ":", "\n", "    ", "score_cache", "=", "deque", "(", ")", "\n", "scores_sum", "=", "0", "\n", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "while", "True", ":", "\n", "        ", "cur_windows", "=", "[", "]", "\n", "\n", "while", "len", "(", "cur_windows", ")", "==", "0", ":", "\n", "            ", "if", "len", "(", "frame_queue", ")", "==", "sample_length", ":", "\n", "                ", "cur_windows", "=", "list", "(", "np", ".", "array", "(", "frame_queue", ")", ")", "\n", "if", "data", "[", "'img_shape'", "]", "is", "None", ":", "\n", "                    ", "data", "[", "'img_shape'", "]", "=", "frame_queue", ".", "popleft", "(", ")", ".", "shape", "[", ":", "2", "]", "\n", "\n", "", "", "", "cur_data", "=", "data", ".", "copy", "(", ")", "\n", "cur_data", "[", "'imgs'", "]", "=", "cur_windows", "\n", "cur_data", "=", "test_pipeline", "(", "cur_data", ")", "\n", "cur_data", "=", "collate", "(", "[", "cur_data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "            ", "cur_data", "=", "scatter", "(", "cur_data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "model", "(", "return_loss", "=", "False", ",", "**", "cur_data", ")", "[", "0", "]", "\n", "\n", "", "score_cache", ".", "append", "(", "scores", ")", "\n", "scores_sum", "+=", "scores", "\n", "\n", "if", "len", "(", "score_cache", ")", "==", "average_size", ":", "\n", "            ", "scores_avg", "=", "scores_sum", "/", "average_size", "\n", "num_selected_labels", "=", "min", "(", "len", "(", "label", ")", ",", "5", ")", "\n", "\n", "scores_tuples", "=", "tuple", "(", "zip", "(", "label", ",", "scores_avg", ")", ")", "\n", "scores_sorted", "=", "sorted", "(", "\n", "scores_tuples", ",", "key", "=", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "\n", "results", "=", "scores_sorted", "[", ":", "num_selected_labels", "]", "\n", "\n", "result_queue", ".", "append", "(", "results", ")", "\n", "scores_sum", "-=", "score_cache", ".", "popleft", "(", ")", "\n", "\n", "", "if", "inference_fps", ">", "0", ":", "\n", "# add a limiter for actual inference fps <= inference_fps", "\n", "            ", "sleep_time", "=", "1", "/", "inference_fps", "-", "(", "time", ".", "time", "(", ")", "-", "cur_time", ")", "\n", "if", "sleep_time", ">", "0", ":", "\n", "                ", "time", ".", "sleep", "(", "sleep_time", ")", "\n", "", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "camera", ".", "release", "(", ")", "\n", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo.main": [[168, 219], ["webcam_demo.parse_args", "torch.device", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "mmaction.apis.init_recognizer", "cv2.VideoCapture", "dict", "pipeline.copy", "mmaction.datasets.pipelines.Compose", "open", "collections.deque", "collections.deque", "threading.Thread", "threading.Thread", "threading.Thread.start", "threading.Thread.start", "threading.Thread.join", "line.strip", "pipeline.copy.remove", "pipeline.copy.remove"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "frame_queue", ",", "camera", ",", "frame", ",", "results", ",", "threshold", ",", "sample_length", ",", "data", ",", "test_pipeline", ",", "model", ",", "device", ",", "average_size", ",", "label", ",", "result_queue", ",", "drawing_fps", ",", "inference_fps", "\n", "\n", "args", "=", "parse_args", "(", ")", "\n", "average_size", "=", "args", ".", "average_size", "\n", "threshold", "=", "args", ".", "threshold", "\n", "drawing_fps", "=", "args", ".", "drawing_fps", "\n", "inference_fps", "=", "args", ".", "inference_fps", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "model", "=", "init_recognizer", "(", "cfg", ",", "args", ".", "checkpoint", ",", "device", "=", "device", ")", "\n", "camera", "=", "cv2", ".", "VideoCapture", "(", "args", ".", "camera_id", ")", "\n", "data", "=", "dict", "(", "img_shape", "=", "None", ",", "modality", "=", "'RGB'", ",", "label", "=", "-", "1", ")", "\n", "\n", "with", "open", "(", "args", ".", "label", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "# prepare test pipeline from non-camera pipeline", "\n", "", "cfg", "=", "model", ".", "cfg", "\n", "sample_length", "=", "0", "\n", "pipeline", "=", "cfg", ".", "data", ".", "test", ".", "pipeline", "\n", "pipeline_", "=", "pipeline", ".", "copy", "(", ")", "\n", "for", "step", "in", "pipeline", ":", "\n", "        ", "if", "'SampleFrames'", "in", "step", "[", "'type'", "]", ":", "\n", "            ", "sample_length", "=", "step", "[", "'clip_len'", "]", "*", "step", "[", "'num_clips'", "]", "\n", "data", "[", "'num_clips'", "]", "=", "step", "[", "'num_clips'", "]", "\n", "data", "[", "'clip_len'", "]", "=", "step", "[", "'clip_len'", "]", "\n", "pipeline_", ".", "remove", "(", "step", ")", "\n", "", "if", "step", "[", "'type'", "]", "in", "EXCLUED_STEPS", ":", "\n", "# remove step to decode frames", "\n", "            ", "pipeline_", ".", "remove", "(", "step", ")", "\n", "", "", "test_pipeline", "=", "Compose", "(", "pipeline_", ")", "\n", "\n", "assert", "sample_length", ">", "0", "\n", "\n", "try", ":", "\n", "        ", "frame_queue", "=", "deque", "(", "maxlen", "=", "sample_length", ")", "\n", "result_queue", "=", "deque", "(", "maxlen", "=", "1", ")", "\n", "pw", "=", "Thread", "(", "target", "=", "show_results", ",", "args", "=", "(", ")", ",", "daemon", "=", "True", ")", "\n", "pr", "=", "Thread", "(", "target", "=", "inference", ",", "args", "=", "(", ")", ",", "daemon", "=", "True", ")", "\n", "pw", ".", "start", "(", ")", "\n", "pr", ".", "start", "(", ")", "\n", "pw", ".", "join", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_gradcam.parse_args": [[16, 59], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'MMAction2 GradCAM demo'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "'video'", ",", "help", "=", "'video file/url or rawframes directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use-frames'", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use rawframes as input'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'CPU/CUDA device option'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--target-layer-name'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'backbone/layer4/1/relu'", ",", "\n", "help", "=", "'GradCAM target layer name'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-filename'", ",", "default", "=", "None", ",", "help", "=", "'output filename'", ")", "\n", "parser", ".", "add_argument", "(", "'--fps'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--target-resolution'", ",", "\n", "nargs", "=", "2", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Target resolution (w, h) for resizing the frames when using a '", "\n", "'video as input. If either dimension is set to -1, the frames are '", "\n", "'resized by keeping the existing aspect ratio'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resize-algorithm'", ",", "\n", "default", "=", "'bilinear'", ",", "\n", "help", "=", "'resize algorithm applied to generate video & gif'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_gradcam.build_inputs": [[61, 117], ["mmaction.datasets.pipelines.Compose", "mmaction.datasets.pipelines.Compose.", "mmcv.parallel.collate", "RuntimeError", "os.isfile", "RuntimeError", "os.isdir", "RuntimeError", "next", "cfg.data.test.get", "cfg.data.test.get", "cfg.data.test.get", "dict", "cfg.data.test.get", "dict", "next", "os.exists", "video_path.startswith", "model.parameters", "model.parameters", "mmcv.parallel.scatter", "len", "os.listdir", "os.listdir"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "build_inputs", "(", "model", ",", "video_path", ",", "use_frames", "=", "False", ")", ":", "\n", "    ", "\"\"\"build inputs for GradCAM.\n\n    Note that, building inputs for GradCAM is exactly the same as building\n    inputs for Recognizer test stage. Codes from `inference_recognizer`.\n\n    Args:\n        model (nn.Module): Recognizer model.\n        video_path (str): video file/url or rawframes directory.\n        use_frames (bool): whether to use rawframes as input.\n    Returns:\n        dict: Both GradCAM inputs and Recognizer test stage inputs,\n            including two keys, ``imgs`` and ``label``.\n    \"\"\"", "\n", "if", "not", "(", "osp", ".", "exists", "(", "video_path", ")", "or", "video_path", ".", "startswith", "(", "'http'", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"'{video_path}' is missing\"", ")", "\n", "\n", "", "if", "osp", ".", "isfile", "(", "video_path", ")", "and", "use_frames", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"'{video_path}' is a video file, not a rawframe directory\"", ")", "\n", "", "if", "osp", ".", "isdir", "(", "video_path", ")", "and", "not", "use_frames", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"'{video_path}' is a rawframe directory, not a video file\"", ")", "\n", "\n", "", "cfg", "=", "model", ".", "cfg", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# model device", "\n", "\n", "# build the data pipeline", "\n", "test_pipeline", "=", "cfg", ".", "data", ".", "test", ".", "pipeline", "\n", "test_pipeline", "=", "Compose", "(", "test_pipeline", ")", "\n", "# prepare data", "\n", "if", "use_frames", ":", "\n", "        ", "filename_tmpl", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'filename_tmpl'", ",", "'img_{:05}.jpg'", ")", "\n", "modality", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'modality'", ",", "'RGB'", ")", "\n", "start_index", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'start_index'", ",", "1", ")", "\n", "data", "=", "dict", "(", "\n", "frame_dir", "=", "video_path", ",", "\n", "total_frames", "=", "len", "(", "os", ".", "listdir", "(", "video_path", ")", ")", ",", "\n", "label", "=", "-", "1", ",", "\n", "start_index", "=", "start_index", ",", "\n", "filename_tmpl", "=", "filename_tmpl", ",", "\n", "modality", "=", "modality", ")", "\n", "", "else", ":", "\n", "        ", "start_index", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'start_index'", ",", "0", ")", "\n", "data", "=", "dict", "(", "\n", "filename", "=", "video_path", ",", "\n", "label", "=", "-", "1", ",", "\n", "start_index", "=", "start_index", ",", "\n", "modality", "=", "'RGB'", ")", "\n", "", "data", "=", "test_pipeline", "(", "data", ")", "\n", "data", "=", "collate", "(", "[", "data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "# scatter to specified GPU", "\n", "        ", "data", "=", "scatter", "(", "data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_gradcam._resize_frames": [[119, 164], ["tuple", "max", "min", "mmcv.rescale_size", "mmcv.imresize"], "function", ["None"], ["", "def", "_resize_frames", "(", "frame_list", ",", "\n", "scale", ",", "\n", "keep_ratio", "=", "True", ",", "\n", "interpolation", "=", "'bilinear'", ")", ":", "\n", "    ", "\"\"\"resize frames according to given scale.\n\n    Codes are modified from `mmaction2/datasets/pipelines/augmentation.py`,\n    `Resize` class.\n\n    Args:\n        frame_list (list[np.ndarray]): frames to be resized.\n        scale (tuple[int]): If keep_ratio is True, it serves as scaling\n            factor or maximum size: the image will be rescaled as large\n            as possible within the scale. Otherwise, it serves as (w, h)\n            of output size.\n        keep_ratio (bool): If set to True, Images will be resized without\n            changing the aspect ratio. Otherwise, it will resize images to a\n            given size. Default: True.\n        interpolation (str): Algorithm used for interpolation:\n            \"nearest\" | \"bilinear\". Default: \"bilinear\".\n    Returns:\n        list[np.ndarray]: Both GradCAM and Recognizer test stage inputs,\n            including two keys, ``imgs`` and ``label``.\n    \"\"\"", "\n", "if", "scale", "is", "None", "or", "(", "scale", "[", "0", "]", "==", "-", "1", "and", "scale", "[", "1", "]", "==", "-", "1", ")", ":", "\n", "        ", "return", "frame_list", "\n", "", "scale", "=", "tuple", "(", "scale", ")", "\n", "max_long_edge", "=", "max", "(", "scale", ")", "\n", "max_short_edge", "=", "min", "(", "scale", ")", "\n", "if", "max_short_edge", "==", "-", "1", ":", "\n", "        ", "scale", "=", "(", "np", ".", "inf", ",", "max_long_edge", ")", "\n", "\n", "", "img_h", ",", "img_w", ",", "_", "=", "frame_list", "[", "0", "]", ".", "shape", "\n", "\n", "if", "keep_ratio", ":", "\n", "        ", "new_w", ",", "new_h", "=", "mmcv", ".", "rescale_size", "(", "(", "img_w", ",", "img_h", ")", ",", "scale", ")", "\n", "", "else", ":", "\n", "        ", "new_w", ",", "new_h", "=", "scale", "\n", "\n", "", "frame_list", "=", "[", "\n", "mmcv", ".", "imresize", "(", "img", ",", "(", "new_w", ",", "new_h", ")", ",", "interpolation", "=", "interpolation", ")", "\n", "for", "img", "in", "frame_list", "\n", "]", "\n", "\n", "return", "frame_list", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_gradcam.main": [[166, 205], ["demo_gradcam.parse_args", "torch.device", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "mmaction.apis.init_recognizer", "demo_gradcam.build_inputs", "mmaction.utils.GradCAM", "mmaction.utils.GradCAM.", "frames_batches.reshape", "list", "demo_gradcam._resize_frames", "ImageSequenceClip", "ImageSequenceClip.write_gif", "ImageSequenceClip.write_videofile", "ImportError", "os.splitext"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_gradcam.build_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_gradcam._resize_frames"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "# assign the desired device.", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "# build the recognizer from a config file and checkpoint file/url", "\n", "model", "=", "init_recognizer", "(", "\n", "cfg", ",", "args", ".", "checkpoint", ",", "device", "=", "device", ",", "use_frames", "=", "args", ".", "use_frames", ")", "\n", "\n", "inputs", "=", "build_inputs", "(", "model", ",", "args", ".", "video", ",", "use_frames", "=", "args", ".", "use_frames", ")", "\n", "gradcam", "=", "GradCAM", "(", "model", ",", "args", ".", "target_layer_name", ")", "\n", "results", "=", "gradcam", "(", "inputs", ")", "\n", "\n", "if", "args", ".", "out_filename", "is", "not", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "moviepy", ".", "editor", "import", "ImageSequenceClip", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'Please install moviepy to enable output file.'", ")", "\n", "\n", "# frames_batches shape [B, T, H, W, 3], in RGB order", "\n", "", "frames_batches", "=", "(", "results", "[", "0", "]", "*", "255.", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "frames", "=", "frames_batches", ".", "reshape", "(", "-", "1", ",", "*", "frames_batches", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "frame_list", "=", "list", "(", "frames", ")", "\n", "frame_list", "=", "_resize_frames", "(", "\n", "frame_list", ",", "\n", "args", ".", "target_resolution", ",", "\n", "interpolation", "=", "args", ".", "resize_algorithm", ")", "\n", "\n", "video_clips", "=", "ImageSequenceClip", "(", "frame_list", ",", "fps", "=", "args", ".", "fps", ")", "\n", "out_type", "=", "osp", ".", "splitext", "(", "args", ".", "out_filename", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "if", "out_type", "==", "'gif'", ":", "\n", "            ", "video_clips", ".", "write_gif", "(", "args", ".", "out_filename", ")", "\n", "", "else", ":", "\n", "            ", "video_clips", ".", "write_videofile", "(", "args", ".", "out_filename", ",", "remove_temp", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.__init__": [[149, 172], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "id", "=", "-", "1", "\n", "\n", "# raw frames, used as human detector input, draw predictions input", "\n", "# and output, display input", "\n", "self", ".", "frames", "=", "None", "\n", "\n", "# stdet params", "\n", "self", ".", "processed_frames", "=", "None", "# model inputs", "\n", "self", ".", "frames_inds", "=", "None", "# select frames from processed frames", "\n", "self", ".", "img_shape", "=", "None", "# model inputs, processed frame shape", "\n", "# `action_preds` is `list[list[tuple]]`. The outter brackets indicate", "\n", "# different bboxes and the intter brackets indicate different action", "\n", "# results for the same bbox. tuple contains `class_name` and `score`.", "\n", "self", ".", "action_preds", "=", "None", "# stdet results", "\n", "\n", "# human bboxes with the format (xmin, ymin, xmax, ymax)", "\n", "self", ".", "display_bboxes", "=", "None", "# bboxes coords for self.frames", "\n", "self", ".", "stdet_bboxes", "=", "None", "# bboxes coords for self.processed_frames", "\n", "self", ".", "ratio", "=", "None", "# processed_frames.shape[1::-1]/frames.shape[1::-1]", "\n", "\n", "# for each clip, draw predictions on clip_vis_length frames", "\n", "self", ".", "clip_vis_length", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.add_frames": [[173, 186], ["None"], "methods", ["None"], ["", "def", "add_frames", "(", "self", ",", "idx", ",", "frames", ",", "processed_frames", ")", ":", "\n", "        ", "\"\"\"Add the clip and corresponding id.\n\n        Args:\n            idx (int): the current index of the clip.\n            frames (list[ndarray]): list of images in \"BGR\" format.\n            processed_frames (list[ndarray]): list of resize and normed images\n                in \"BGR\" format.\n        \"\"\"", "\n", "self", ".", "frames", "=", "frames", "\n", "self", ".", "processed_frames", "=", "processed_frames", "\n", "self", ".", "id", "=", "idx", "\n", "self", ".", "img_shape", "=", "processed_frames", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.add_bboxes": [[187, 193], ["display_bboxes.clone"], "methods", ["None"], ["", "def", "add_bboxes", "(", "self", ",", "display_bboxes", ")", ":", "\n", "        ", "\"\"\"Add correspondding bounding boxes.\"\"\"", "\n", "self", ".", "display_bboxes", "=", "display_bboxes", "\n", "self", ".", "stdet_bboxes", "=", "display_bboxes", ".", "clone", "(", ")", "\n", "self", ".", "stdet_bboxes", "[", ":", ",", ":", ":", "2", "]", "=", "self", ".", "stdet_bboxes", "[", ":", ",", ":", ":", "2", "]", "*", "self", ".", "ratio", "[", "0", "]", "\n", "self", ".", "stdet_bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "=", "self", ".", "stdet_bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "*", "self", ".", "ratio", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.add_action_preds": [[194, 197], ["None"], "methods", ["None"], ["", "def", "add_action_preds", "(", "self", ",", "preds", ")", ":", "\n", "        ", "\"\"\"Add the corresponding action predictions.\"\"\"", "\n", "self", ".", "action_preds", "=", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.get_model_inputs": [[198, 208], ["torch.from_numpy().to", "dict", "numpy.stack().transpose", "torch.from_numpy", "numpy.stack", "dict"], "methods", ["None"], ["", "def", "get_model_inputs", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\"Convert preprocessed images to MMAction2 STDet model inputs.\"\"\"", "\n", "cur_frames", "=", "[", "self", ".", "processed_frames", "[", "idx", "]", "for", "idx", "in", "self", ".", "frames_inds", "]", "\n", "input_array", "=", "np", ".", "stack", "(", "cur_frames", ")", ".", "transpose", "(", "(", "3", ",", "0", ",", "1", ",", "2", ")", ")", "[", "np", ".", "newaxis", "]", "\n", "input_tensor", "=", "torch", ".", "from_numpy", "(", "input_array", ")", ".", "to", "(", "device", ")", "\n", "return", "dict", "(", "\n", "return_loss", "=", "False", ",", "\n", "img", "=", "[", "input_tensor", "]", ",", "\n", "proposals", "=", "[", "[", "self", ".", "stdet_bboxes", "]", "]", ",", "\n", "img_metas", "=", "[", "[", "dict", "(", "img_shape", "=", "self", ".", "img_shape", ")", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseHumanDetector.__init__": [[217, 219], ["torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseHumanDetector._do_detect": [[220, 226], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_do_detect", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"Get human bboxes with shape [n, 4].\n\n        The format of bboxes is (xmin, ymin, xmax, ymax) in pixels.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseHumanDetector.predict": [[227, 245], ["webcam_demo_spatiotemporal_det.BaseHumanDetector._do_detect", "isinstance", "task.add_bboxes", "torch.from_numpy().to", "isinstance", "bboxes.to.to.to", "len", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.MmdetHumanDetector._do_detect", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.add_bboxes"], ["", "def", "predict", "(", "self", ",", "task", ")", ":", "\n", "        ", "\"\"\"Add keyframe bboxes to task.\"\"\"", "\n", "# keyframe idx == (clip_len * frame_interval) // 2", "\n", "keyframe", "=", "task", ".", "frames", "[", "len", "(", "task", ".", "frames", ")", "//", "2", "]", "\n", "\n", "# call detector", "\n", "bboxes", "=", "self", ".", "_do_detect", "(", "keyframe", ")", "\n", "\n", "# convert bboxes to torch.Tensor and move to target device", "\n", "if", "isinstance", "(", "bboxes", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "bboxes", "=", "torch", ".", "from_numpy", "(", "bboxes", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "elif", "isinstance", "(", "bboxes", ",", "torch", ".", "Tensor", ")", "and", "bboxes", ".", "device", "!=", "self", ".", "device", ":", "\n", "            ", "bboxes", "=", "bboxes", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# update task", "\n", "", "task", ".", "add_bboxes", "(", "bboxes", ")", "\n", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.MmdetHumanDetector.__init__": [[259, 264], ["webcam_demo_spatiotemporal_det.BaseHumanDetector.__init__", "init_detector"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "ckpt", ",", "device", ",", "score_thr", ",", "person_classid", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", ")", "\n", "self", ".", "model", "=", "init_detector", "(", "config", ",", "ckpt", ",", "device", ")", "\n", "self", ".", "person_classid", "=", "person_classid", "\n", "self", ".", "score_thr", "=", "score_thr", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.MmdetHumanDetector._do_detect": [[265, 270], ["inference_detector"], "methods", ["None"], ["", "def", "_do_detect", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"Get bboxes in shape [n, 4] and values in pixels.\"\"\"", "\n", "result", "=", "inference_detector", "(", "self", ".", "model", ",", "image", ")", "[", "self", ".", "person_classid", "]", "\n", "result", "=", "result", "[", "result", "[", ":", ",", "4", "]", ">=", "self", ".", "score_thr", "]", "[", ":", ",", ":", "4", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.StdetPredictor.__init__": [[284, 310], ["mmaction.models.build_detector", "mmcv.runner.load_checkpoint", "mmaction.models.build_detector.to", "mmaction.models.build_detector.eval", "open", "f.readlines", "x.strip().split", "int", "config.get", "x.strip", "enumerate"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["def", "__init__", "(", "self", ",", "config", ",", "checkpoint", ",", "device", ",", "score_thr", ",", "label_map_path", ")", ":", "\n", "        ", "self", ".", "score_thr", "=", "score_thr", "\n", "\n", "# load model", "\n", "config", ".", "model", ".", "backbone", ".", "pretrained", "=", "None", "\n", "model", "=", "build_detector", "(", "config", ".", "model", ",", "test_cfg", "=", "config", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "load_checkpoint", "(", "model", ",", "checkpoint", ",", "map_location", "=", "device", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# init label map, aka class_id to class_name dict", "\n", "with", "open", "(", "label_map_path", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "lines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "': '", ")", "for", "x", "in", "lines", "]", "\n", "self", ".", "label_map", "=", "{", "int", "(", "x", "[", "0", "]", ")", ":", "x", "[", "1", "]", "for", "x", "in", "lines", "}", "\n", "try", ":", "\n", "            ", "if", "config", "[", "'data'", "]", "[", "'train'", "]", "[", "'custom_classes'", "]", "is", "not", "None", ":", "\n", "                ", "self", ".", "label_map", "=", "{", "\n", "id", "+", "1", ":", "self", ".", "label_map", "[", "cls", "]", "\n", "for", "id", ",", "cls", "in", "enumerate", "(", "config", "[", "'data'", "]", "[", "'train'", "]", "\n", "[", "'custom_classes'", "]", ")", "\n", "}", "\n", "", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.StdetPredictor.predict": [[311, 339], ["range", "range", "task.add_action_preds", "len", "torch.no_grad", "preds.append", "len", "range", "webcam_demo_spatiotemporal_det.StdetPredictor.model", "preds[].append", "task.get_model_inputs"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.add_action_preds", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.get_model_inputs"], ["", "", "def", "predict", "(", "self", ",", "task", ")", ":", "\n", "        ", "\"\"\"Spatio-temporval Action Detection model inference.\"\"\"", "\n", "# No need to do inference if no one in keyframe", "\n", "if", "len", "(", "task", ".", "stdet_bboxes", ")", "==", "0", ":", "\n", "            ", "return", "task", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "result", "=", "self", ".", "model", "(", "**", "task", ".", "get_model_inputs", "(", "self", ".", "device", ")", ")", "[", "0", "]", "\n", "\n", "# pack results of human detector and stdet", "\n", "", "preds", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "task", ".", "stdet_bboxes", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "preds", ".", "append", "(", "[", "]", ")", "\n", "", "for", "class_id", "in", "range", "(", "len", "(", "result", ")", ")", ":", "\n", "            ", "if", "class_id", "+", "1", "not", "in", "self", ".", "label_map", ":", "\n", "                ", "continue", "\n", "", "for", "bbox_id", "in", "range", "(", "task", ".", "stdet_bboxes", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "result", "[", "class_id", "]", "[", "bbox_id", ",", "4", "]", ">", "self", ".", "score_thr", ":", "\n", "                    ", "preds", "[", "bbox_id", "]", ".", "append", "(", "(", "self", ".", "label_map", "[", "class_id", "+", "1", "]", ",", "\n", "result", "[", "class_id", "]", "[", "bbox_id", ",", "4", "]", ")", ")", "\n", "\n", "# update task", "\n", "# `preds` is `list[list[tuple]]`. The outter brackets indicate", "\n", "# different bboxes and the intter brackets indicate different action", "\n", "# results for the same bbox. tuple contains `class_name` and `score`.", "\n", "", "", "", "task", ".", "add_action_preds", "(", "preds", ")", "\n", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.__init__": [[344, 443], ["webcam_demo_spatiotemporal_det.ClipHelper.cap.isOpened", "int", "int", "mmcv.rescale_size", "numpy.array", "numpy.array", "tuple", "threading.Lock", "threading.Lock", "threading.Lock", "queue.Queue", "threading.Lock", "atexit.register", "cv2.VideoCapture", "webcam_demo_spatiotemporal_det.ClipHelper.cap.get", "webcam_demo_spatiotemporal_det.ClipHelper.cap.get", "img_norm_cfg.pop", "int", "webcam_demo_spatiotemporal_det.ClipHelper.get_output_video_writer", "int", "cv2.VideoCapture", "range", "mmcv.rescale_size", "webcam_demo_spatiotemporal_det.ClipHelper.cap.get", "range", "zip", "max"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.register", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.get_output_video_writer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["def", "__init__", "(", "self", ",", "\n", "config", ",", "\n", "display_height", "=", "0", ",", "\n", "display_width", "=", "0", ",", "\n", "input_video", "=", "0", ",", "\n", "predict_stepsize", "=", "40", ",", "\n", "output_fps", "=", "25", ",", "\n", "clip_vis_length", "=", "8", ",", "\n", "out_filename", "=", "None", ",", "\n", "show", "=", "True", ",", "\n", "stdet_input_shortside", "=", "256", ")", ":", "\n", "# stdet sampling strategy", "\n", "        ", "val_pipeline", "=", "config", ".", "data", ".", "val", ".", "pipeline", "\n", "sampler", "=", "[", "x", "for", "x", "in", "val_pipeline", "\n", "if", "x", "[", "'type'", "]", "==", "'SampleAVAFrames'", "]", "[", "0", "]", "\n", "clip_len", ",", "frame_interval", "=", "sampler", "[", "'clip_len'", "]", ",", "sampler", "[", "\n", "'frame_interval'", "]", "\n", "self", ".", "window_size", "=", "clip_len", "*", "frame_interval", "\n", "\n", "# asserts", "\n", "assert", "(", "out_filename", "or", "show", ")", ",", "'out_filename and show cannot both be None'", "\n", "assert", "clip_len", "%", "2", "==", "0", ",", "'We would like to have an even clip_len'", "\n", "assert", "clip_vis_length", "<=", "predict_stepsize", "\n", "assert", "0", "<", "predict_stepsize", "<=", "self", ".", "window_size", "\n", "\n", "# source params", "\n", "try", ":", "\n", "            ", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "int", "(", "input_video", ")", ")", "\n", "self", ".", "webcam", "=", "True", "\n", "", "except", "ValueError", ":", "\n", "            ", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "input_video", ")", "\n", "self", ".", "webcam", "=", "False", "\n", "", "assert", "self", ".", "cap", ".", "isOpened", "(", ")", "\n", "\n", "# stdet input preprocessing params", "\n", "h", "=", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "w", "=", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "self", ".", "stdet_input_size", "=", "mmcv", ".", "rescale_size", "(", "\n", "(", "w", ",", "h", ")", ",", "(", "stdet_input_shortside", ",", "np", ".", "Inf", ")", ")", "\n", "img_norm_cfg", "=", "config", "[", "'img_norm_cfg'", "]", "\n", "if", "'to_rgb'", "not", "in", "img_norm_cfg", "and", "'to_bgr'", "in", "img_norm_cfg", ":", "\n", "            ", "to_bgr", "=", "img_norm_cfg", ".", "pop", "(", "'to_bgr'", ")", "\n", "img_norm_cfg", "[", "'to_rgb'", "]", "=", "to_bgr", "\n", "", "img_norm_cfg", "[", "'mean'", "]", "=", "np", ".", "array", "(", "img_norm_cfg", "[", "'mean'", "]", ")", "\n", "img_norm_cfg", "[", "'std'", "]", "=", "np", ".", "array", "(", "img_norm_cfg", "[", "'std'", "]", ")", "\n", "self", ".", "img_norm_cfg", "=", "img_norm_cfg", "\n", "\n", "# task init params", "\n", "self", ".", "clip_vis_length", "=", "clip_vis_length", "\n", "self", ".", "predict_stepsize", "=", "predict_stepsize", "\n", "self", ".", "buffer_size", "=", "self", ".", "window_size", "-", "self", ".", "predict_stepsize", "\n", "frame_start", "=", "self", ".", "window_size", "//", "2", "-", "(", "clip_len", "//", "2", ")", "*", "frame_interval", "\n", "self", ".", "frames_inds", "=", "[", "\n", "frame_start", "+", "frame_interval", "*", "i", "for", "i", "in", "range", "(", "clip_len", ")", "\n", "]", "\n", "self", ".", "buffer", "=", "[", "]", "\n", "self", ".", "processed_buffer", "=", "[", "]", "\n", "\n", "# output/display params", "\n", "if", "display_height", ">", "0", "and", "display_width", ">", "0", ":", "\n", "            ", "self", ".", "display_size", "=", "(", "display_width", ",", "display_height", ")", "\n", "", "elif", "display_height", ">", "0", "or", "display_width", ">", "0", ":", "\n", "            ", "self", ".", "display_size", "=", "mmcv", ".", "rescale_size", "(", "\n", "(", "w", ",", "h", ")", ",", "(", "np", ".", "Inf", ",", "max", "(", "display_height", ",", "display_width", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "display_size", "=", "(", "w", ",", "h", ")", "\n", "", "self", ".", "ratio", "=", "tuple", "(", "\n", "n", "/", "o", "for", "n", ",", "o", "in", "zip", "(", "self", ".", "stdet_input_size", ",", "self", ".", "display_size", ")", ")", "\n", "if", "output_fps", "<=", "0", ":", "\n", "            ", "self", ".", "output_fps", "=", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_fps", "=", "output_fps", "\n", "", "self", ".", "show", "=", "show", "\n", "self", ".", "video_writer", "=", "None", "\n", "if", "out_filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "video_writer", "=", "self", ".", "get_output_video_writer", "(", "out_filename", ")", "\n", "", "display_start_idx", "=", "self", ".", "window_size", "//", "2", "-", "self", ".", "predict_stepsize", "//", "2", "\n", "self", ".", "display_inds", "=", "[", "\n", "display_start_idx", "+", "i", "for", "i", "in", "range", "(", "self", ".", "predict_stepsize", ")", "\n", "]", "\n", "\n", "# display multi-theading params", "\n", "self", ".", "display_id", "=", "-", "1", "# task.id for display queue", "\n", "self", ".", "display_queue", "=", "{", "}", "\n", "self", ".", "display_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "output_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n", "# read multi-theading params", "\n", "self", ".", "read_id", "=", "-", "1", "# task.id for read queue", "\n", "self", ".", "read_id_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "read_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "self", ".", "read_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "not_end", "=", "True", "# cap.read() flag", "\n", "\n", "# program state", "\n", "self", ".", "stopped", "=", "False", "\n", "\n", "atexit", ".", "register", "(", "self", ".", "clean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.read_fn": [[444, 506], ["time.time", "webcam_demo_spatiotemporal_det.TaskInfo", "webcam_demo_spatiotemporal_det.TaskInfo.add_frames", "webcam_demo_spatiotemporal_det.ClipHelper.read_queue.put", "time.time", "logger.debug", "len", "len", "time.time", "len", "webcam_demo_spatiotemporal_det.ClipHelper.cap.read", "copy.deepcopy", "len", "time.sleep", "frames.append", "mmcv.imresize().astype", "mmcv.imnormalize_", "processed_frames.append", "mmcv.imresize", "mmcv.imresize"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.TaskInfo.add_frames"], ["", "def", "read_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"Main function for read thread.\n\n        Contains three steps:\n\n        1) Read and preprocess (resize + norm) frames from source.\n        2) Create task by frames from previous step and buffer.\n        3) Put task into read queue.\n        \"\"\"", "\n", "was_read", "=", "True", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "while", "was_read", "and", "not", "self", ".", "stopped", ":", "\n", "# init task", "\n", "            ", "task", "=", "TaskInfo", "(", ")", "\n", "task", ".", "clip_vis_length", "=", "self", ".", "clip_vis_length", "\n", "task", ".", "frames_inds", "=", "self", ".", "frames_inds", "\n", "task", ".", "ratio", "=", "self", ".", "ratio", "\n", "\n", "# read buffer", "\n", "frames", "=", "[", "]", "\n", "processed_frames", "=", "[", "]", "\n", "if", "len", "(", "self", ".", "buffer", ")", "!=", "0", ":", "\n", "                ", "frames", "=", "self", ".", "buffer", "\n", "", "if", "len", "(", "self", ".", "processed_buffer", ")", "!=", "0", ":", "\n", "                ", "processed_frames", "=", "self", ".", "processed_buffer", "\n", "\n", "# read and preprocess frames from source and update task", "\n", "", "with", "self", ".", "read_lock", ":", "\n", "                ", "before_read", "=", "time", ".", "time", "(", ")", "\n", "read_frame_cnt", "=", "self", ".", "window_size", "-", "len", "(", "frames", ")", "\n", "while", "was_read", "and", "len", "(", "frames", ")", "<", "self", ".", "window_size", ":", "\n", "                    ", "was_read", ",", "frame", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "if", "not", "self", ".", "webcam", ":", "\n", "# Reading frames too fast may lead to unexpected", "\n", "# performance degradation. If you have enough", "\n", "# resource, this line could be commented.", "\n", "                        ", "time", ".", "sleep", "(", "1", "/", "self", ".", "output_fps", ")", "\n", "", "if", "was_read", ":", "\n", "                        ", "frames", ".", "append", "(", "mmcv", ".", "imresize", "(", "frame", ",", "self", ".", "display_size", ")", ")", "\n", "processed_frame", "=", "mmcv", ".", "imresize", "(", "\n", "frame", ",", "self", ".", "stdet_input_size", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "_", "=", "mmcv", ".", "imnormalize_", "(", "processed_frame", ",", "\n", "**", "self", ".", "img_norm_cfg", ")", "\n", "processed_frames", ".", "append", "(", "processed_frame", ")", "\n", "", "", "", "task", ".", "add_frames", "(", "self", ".", "read_id", "+", "1", ",", "frames", ",", "processed_frames", ")", "\n", "\n", "# update buffer", "\n", "if", "was_read", ":", "\n", "                ", "self", ".", "buffer", "=", "frames", "[", "-", "self", ".", "buffer_size", ":", "]", "\n", "self", ".", "processed_buffer", "=", "processed_frames", "[", "-", "self", ".", "buffer_size", ":", "]", "\n", "\n", "# update read state", "\n", "", "with", "self", ".", "read_id_lock", ":", "\n", "                ", "self", ".", "read_id", "+=", "1", "\n", "self", ".", "not_end", "=", "was_read", "\n", "\n", "", "self", ".", "read_queue", ".", "put", "(", "(", "was_read", ",", "copy", ".", "deepcopy", "(", "task", ")", ")", ")", "\n", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "debug", "(", "\n", "f'Read thread: {1000*(cur_time - start_time):.0f} ms, '", "\n", "f'{read_frame_cnt / (cur_time - before_read):.0f} fps'", ")", "\n", "start_time", "=", "cur_time", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.display_fn": [[507, 561], ["time.time", "time.time", "logger.debug", "time.sleep", "range", "len", "webcam_demo_spatiotemporal_det.ClipHelper.display_queue.get", "range", "cv2.imshow", "cv2.waitKey", "webcam_demo_spatiotemporal_det.ClipHelper.video_writer.write", "len", "int"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "", "def", "display_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"Main function for display thread.\n\n        Read data from display queue and display predictions.\n        \"\"\"", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "while", "not", "self", ".", "stopped", ":", "\n", "# get the state of the read thread", "\n", "            ", "with", "self", ".", "read_id_lock", ":", "\n", "                ", "read_id", "=", "self", ".", "read_id", "\n", "not_end", "=", "self", ".", "not_end", "\n", "\n", "", "with", "self", ".", "display_lock", ":", "\n", "# If video ended and we have display all frames.", "\n", "                ", "if", "not", "not_end", "and", "self", ".", "display_id", "==", "read_id", ":", "\n", "                    ", "break", "\n", "\n", "# If the next task are not available, wait.", "\n", "", "if", "(", "len", "(", "self", ".", "display_queue", ")", "==", "0", "or", "\n", "self", ".", "display_queue", ".", "get", "(", "self", ".", "display_id", "+", "1", ")", "is", "None", ")", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.02", ")", "\n", "continue", "\n", "\n", "# get display data and update state", "\n", "", "self", ".", "display_id", "+=", "1", "\n", "was_read", ",", "task", "=", "self", ".", "display_queue", "[", "self", ".", "display_id", "]", "\n", "del", "self", ".", "display_queue", "[", "self", ".", "display_id", "]", "\n", "display_id", "=", "self", ".", "display_id", "\n", "\n", "# do display predictions", "\n", "", "with", "self", ".", "output_lock", ":", "\n", "                ", "if", "was_read", "and", "task", ".", "id", "==", "0", ":", "\n", "# the first task", "\n", "                    ", "cur_display_inds", "=", "range", "(", "self", ".", "display_inds", "[", "-", "1", "]", "+", "1", ")", "\n", "", "elif", "not", "was_read", ":", "\n", "# the last task", "\n", "                    ", "cur_display_inds", "=", "range", "(", "self", ".", "display_inds", "[", "0", "]", ",", "\n", "len", "(", "task", ".", "frames", ")", ")", "\n", "", "else", ":", "\n", "                    ", "cur_display_inds", "=", "self", ".", "display_inds", "\n", "\n", "", "for", "frame_id", "in", "cur_display_inds", ":", "\n", "                    ", "frame", "=", "task", ".", "frames", "[", "frame_id", "]", "\n", "if", "self", ".", "show", ":", "\n", "                        ", "cv2", ".", "imshow", "(", "'Demo'", ",", "frame", ")", "\n", "cv2", ".", "waitKey", "(", "int", "(", "1000", "/", "self", ".", "output_fps", ")", ")", "\n", "", "if", "self", ".", "video_writer", ":", "\n", "                        ", "self", ".", "video_writer", ".", "write", "(", "frame", ")", "\n", "\n", "", "", "", "cur_time", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "debug", "(", "\n", "f'Display thread: {1000*(cur_time - start_time):.0f} ms, '", "\n", "f'read id {read_id}, display id {display_id}'", ")", "\n", "start_time", "=", "cur_time", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.__iter__": [[562, 564], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.__next__": [[565, 587], ["webcam_demo_spatiotemporal_det.ClipHelper.read_queue.get", "webcam_demo_spatiotemporal_det.ClipHelper.read_queue.qsize", "time.sleep", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get data from read queue.\n\n        This function is part of the main thread.\n        \"\"\"", "\n", "if", "self", ".", "read_queue", ".", "qsize", "(", ")", "==", "0", ":", "\n", "            ", "time", ".", "sleep", "(", "0.02", ")", "\n", "return", "not", "self", ".", "stopped", ",", "None", "\n", "\n", "", "was_read", ",", "task", "=", "self", ".", "read_queue", ".", "get", "(", ")", "\n", "if", "not", "was_read", ":", "\n", "# If we reach the end of the video, there aren't enough frames", "\n", "# in the task.processed_frames, so no need to model inference", "\n", "# and draw predictions. Put task into display queue.", "\n", "            ", "with", "self", ".", "read_id_lock", ":", "\n", "                ", "read_id", "=", "self", ".", "read_id", "\n", "", "with", "self", ".", "display_lock", ":", "\n", "                ", "self", ".", "display_queue", "[", "read_id", "]", "=", "was_read", ",", "copy", ".", "deepcopy", "(", "task", ")", "\n", "\n", "# main thread doesn't need to handle this task again", "\n", "", "task", "=", "None", "\n", "", "return", "was_read", ",", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start": [[588, 601], ["threading.Thread", "webcam_demo_spatiotemporal_det.ClipHelper.read_thread.start", "threading.Thread", "webcam_demo_spatiotemporal_det.ClipHelper.display_thread.start"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "\"\"\"Start read thread and display thread.\"\"\"", "\n", "self", ".", "read_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "read_fn", ",", "args", "=", "(", ")", ",", "name", "=", "'VidRead-Thread'", ",", "daemon", "=", "True", ")", "\n", "self", ".", "read_thread", ".", "start", "(", ")", "\n", "self", ".", "display_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "display_fn", ",", "\n", "args", "=", "(", ")", ",", "\n", "name", "=", "'VidDisplay-Thread'", ",", "\n", "daemon", "=", "True", ")", "\n", "self", ".", "display_thread", ".", "start", "(", ")", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.clean": [[602, 613], ["webcam_demo_spatiotemporal_det.ClipHelper.read_lock.acquire", "webcam_demo_spatiotemporal_det.ClipHelper.cap.release", "webcam_demo_spatiotemporal_det.ClipHelper.read_lock.release", "webcam_demo_spatiotemporal_det.ClipHelper.output_lock.acquire", "cv2.destroyAllWindows", "webcam_demo_spatiotemporal_det.ClipHelper.output_lock.release", "webcam_demo_spatiotemporal_det.ClipHelper.video_writer.release"], "methods", ["None"], ["", "def", "clean", "(", "self", ")", ":", "\n", "        ", "\"\"\"Close all threads and release all resources.\"\"\"", "\n", "self", ".", "stopped", "=", "True", "\n", "self", ".", "read_lock", ".", "acquire", "(", ")", "\n", "self", ".", "cap", ".", "release", "(", ")", "\n", "self", ".", "read_lock", ".", "release", "(", ")", "\n", "self", ".", "output_lock", ".", "acquire", "(", ")", "\n", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "if", "self", ".", "video_writer", ":", "\n", "            ", "self", ".", "video_writer", ".", "release", "(", ")", "\n", "", "self", ".", "output_lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join": [[614, 618], ["webcam_demo_spatiotemporal_det.ClipHelper.read_thread.join", "webcam_demo_spatiotemporal_det.ClipHelper.display_thread.join"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "join", "(", "self", ")", ":", "\n", "        ", "\"\"\"Waiting for the finalization of read and display thread.\"\"\"", "\n", "self", ".", "read_thread", ".", "join", "(", ")", "\n", "self", ".", "display_thread", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.display": [[619, 628], ["None"], "methods", ["None"], ["", "def", "display", "(", "self", ",", "task", ")", ":", "\n", "        ", "\"\"\"Add the visualized task to the display queue.\n\n        Args:\n            task (TaskInfo object): task object that contain the necessary\n            information for prediction visualization.\n        \"\"\"", "\n", "with", "self", ".", "display_lock", ":", "\n", "            ", "self", ".", "display_queue", "[", "task", ".", "id", "]", "=", "(", "True", ",", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.get_output_video_writer": [[629, 641], ["cv2.VideoWriter", "cv2.VideoWriter_fourcc", "float"], "methods", ["None"], ["", "", "def", "get_output_video_writer", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Return a video writer object.\n\n        Args:\n            path (str): path to the output video file.\n        \"\"\"", "\n", "return", "cv2", ".", "VideoWriter", "(", "\n", "filename", "=", "path", ",", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'mp4v'", ")", ",", "\n", "fps", "=", "float", "(", "self", ".", "output_fps", ")", ",", "\n", "frameSize", "=", "self", ".", "display_size", ",", "\n", "isColor", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.__init__": [[646, 648], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_labels_per_bbox", ")", ":", "\n", "        ", "self", ".", "max_labels_per_bbox", "=", "max_labels_per_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.draw_predictions": [[649, 665], ["task.display_bboxes.cpu().numpy", "webcam_demo_spatiotemporal_det.BaseVisualizer.draw_clip_range", "len", "task.display_bboxes.cpu", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.draw_clip_range"], ["", "def", "draw_predictions", "(", "self", ",", "task", ")", ":", "\n", "        ", "\"\"\"Visualize stdet predictions on raw frames.\"\"\"", "\n", "# read bboxes from task", "\n", "bboxes", "=", "task", ".", "display_bboxes", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# draw predictions and update task", "\n", "keyframe_idx", "=", "len", "(", "task", ".", "frames", ")", "//", "2", "\n", "draw_range", "=", "[", "\n", "keyframe_idx", "-", "task", ".", "clip_vis_length", "//", "2", ",", "\n", "keyframe_idx", "+", "(", "task", ".", "clip_vis_length", "-", "1", ")", "//", "2", "\n", "]", "\n", "assert", "draw_range", "[", "0", "]", ">=", "0", "and", "draw_range", "[", "1", "]", "<", "len", "(", "task", ".", "frames", ")", "\n", "task", ".", "frames", "=", "self", ".", "draw_clip_range", "(", "task", ".", "frames", ",", "task", ".", "action_preds", ",", "\n", "bboxes", ",", "draw_range", ")", "\n", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.draw_clip_range": [[666, 683], ["webcam_demo_spatiotemporal_det.BaseVisualizer.draw_one_image", "list", "len", "list"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.DefaultVisualizer.draw_one_image"], ["", "def", "draw_clip_range", "(", "self", ",", "frames", ",", "preds", ",", "bboxes", ",", "draw_range", ")", ":", "\n", "        ", "\"\"\"Draw a range of frames with the same bboxes and predictions.\"\"\"", "\n", "# no predictions to be draw", "\n", "if", "bboxes", "is", "None", "or", "len", "(", "bboxes", ")", "==", "0", ":", "\n", "            ", "return", "frames", "\n", "\n", "# draw frames in `draw_range`", "\n", "", "left_frames", "=", "frames", "[", ":", "draw_range", "[", "0", "]", "]", "\n", "right_frames", "=", "frames", "[", "draw_range", "[", "1", "]", "+", "1", ":", "]", "\n", "draw_frames", "=", "frames", "[", "draw_range", "[", "0", "]", ":", "draw_range", "[", "1", "]", "+", "1", "]", "\n", "\n", "# get labels(texts) and draw predictions", "\n", "draw_frames", "=", "[", "\n", "self", ".", "draw_one_image", "(", "frame", ",", "bboxes", ",", "preds", ")", "for", "frame", "in", "draw_frames", "\n", "]", "\n", "\n", "return", "list", "(", "left_frames", ")", "+", "draw_frames", "+", "list", "(", "right_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.draw_one_image": [[684, 687], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "draw_one_image", "(", "self", ",", "frame", ",", "bboxes", ",", "preds", ")", ":", "\n", "        ", "\"\"\"Draw bboxes and corresponding texts on one frame.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.abbrev": [[688, 698], ["name.find", "name.find", "name.find"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "abbrev", "(", "name", ")", ":", "\n", "        ", "\"\"\"Get the abbreviation of label name:\n\n        'take (an object) from (a person)' -> 'take ... from ...'\n        \"\"\"", "\n", "while", "name", ".", "find", "(", "'('", ")", "!=", "-", "1", ":", "\n", "            ", "st", ",", "ed", "=", "name", ".", "find", "(", "'('", ")", ",", "name", ".", "find", "(", "')'", ")", "\n", "name", "=", "name", "[", ":", "st", "]", "+", "'...'", "+", "name", "[", "ed", "+", "1", ":", "]", "\n", "", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.DefaultVisualizer.__init__": [[723, 745], ["webcam_demo_spatiotemporal_det.BaseVisualizer.__init__", "plate.split.split.split", "webcam_demo_spatiotemporal_det.DefaultVisualizer.__init__.hex2color"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.demo_spatiotemporal_det.hex2color"], ["def", "__init__", "(", "\n", "self", ",", "\n", "max_labels_per_bbox", "=", "5", ",", "\n", "plate", "=", "'03045e-023e8a-0077b6-0096c7-00b4d8-48cae4'", ",", "\n", "text_fontface", "=", "cv2", ".", "FONT_HERSHEY_DUPLEX", ",", "\n", "text_fontscale", "=", "0.5", ",", "\n", "text_fontcolor", "=", "(", "255", ",", "255", ",", "255", ")", ",", "# white", "\n", "text_thickness", "=", "1", ",", "\n", "text_linetype", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "max_labels_per_bbox", "=", "max_labels_per_bbox", ")", "\n", "self", ".", "text_fontface", "=", "text_fontface", "\n", "self", ".", "text_fontscale", "=", "text_fontscale", "\n", "self", ".", "text_fontcolor", "=", "text_fontcolor", "\n", "self", ".", "text_thickness", "=", "text_thickness", "\n", "self", ".", "text_linetype", "=", "text_linetype", "\n", "\n", "def", "hex2color", "(", "h", ")", ":", "\n", "            ", "\"\"\"Convert the 6-digit hex string to tuple of 3 int value (RGB)\"\"\"", "\n", "return", "(", "int", "(", "h", "[", ":", "2", "]", ",", "16", ")", ",", "int", "(", "h", "[", "2", ":", "4", "]", ",", "16", ")", ",", "int", "(", "h", "[", "4", ":", "]", ",", "16", ")", ")", "\n", "\n", "", "plate", "=", "plate", ".", "split", "(", "'-'", ")", "\n", "self", ".", "plate", "=", "[", "hex2color", "(", "h", ")", "for", "h", "in", "plate", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.DefaultVisualizer.draw_one_image": [[746, 772], ["zip", "bbox.astype", "cv2.rectangle", "enumerate", "tuple", "tuple", "cv2.rectangle", "cv2.putText", "cv2.getTextSize", "webcam_demo_spatiotemporal_det.DefaultVisualizer.abbrev"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.abbrev"], ["", "def", "draw_one_image", "(", "self", ",", "frame", ",", "bboxes", ",", "preds", ")", ":", "\n", "        ", "\"\"\"Draw predictions on one image.\"\"\"", "\n", "for", "bbox", ",", "pred", "in", "zip", "(", "bboxes", ",", "preds", ")", ":", "\n", "# draw bbox", "\n", "            ", "box", "=", "bbox", ".", "astype", "(", "np", ".", "int64", ")", "\n", "st", ",", "ed", "=", "tuple", "(", "box", "[", ":", "2", "]", ")", ",", "tuple", "(", "box", "[", "2", ":", "]", ")", "\n", "cv2", ".", "rectangle", "(", "frame", ",", "st", ",", "ed", ",", "(", "0", ",", "0", ",", "255", ")", ",", "2", ")", "\n", "\n", "# draw texts", "\n", "for", "k", ",", "(", "label", ",", "score", ")", "in", "enumerate", "(", "pred", ")", ":", "\n", "                ", "if", "k", ">=", "self", ".", "max_labels_per_bbox", ":", "\n", "                    ", "break", "\n", "", "text", "=", "f'{self.abbrev(label)}: {score:.4f}'", "\n", "location", "=", "(", "0", "+", "st", "[", "0", "]", ",", "18", "+", "k", "*", "18", "+", "st", "[", "1", "]", ")", "\n", "textsize", "=", "cv2", ".", "getTextSize", "(", "text", ",", "self", ".", "text_fontface", ",", "\n", "self", ".", "text_fontscale", ",", "\n", "self", ".", "text_thickness", ")", "[", "0", "]", "\n", "textwidth", "=", "textsize", "[", "0", "]", "\n", "diag0", "=", "(", "location", "[", "0", "]", "+", "textwidth", ",", "location", "[", "1", "]", "-", "14", ")", "\n", "diag1", "=", "(", "location", "[", "0", "]", ",", "location", "[", "1", "]", "+", "2", ")", "\n", "cv2", ".", "rectangle", "(", "frame", ",", "diag0", ",", "diag1", ",", "self", ".", "plate", "[", "k", "+", "1", "]", ",", "-", "1", ")", "\n", "cv2", ".", "putText", "(", "frame", ",", "text", ",", "location", ",", "self", ".", "text_fontface", ",", "\n", "self", ".", "text_fontscale", ",", "self", ".", "text_fontcolor", ",", "\n", "self", ".", "text_thickness", ",", "self", ".", "text_linetype", ")", "\n", "\n", "", "", "return", "frame", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.parse_args": [[42, 133], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'MMAction2 webcam spatio-temporal detection demo'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--config'", ",", "\n", "default", "=", "(", "'configs/detection/ava/'", "\n", "'slowonly_omnisource_pretrained_r101_8x8x1_20e_ava_rgb.py'", ")", ",", "\n", "help", "=", "'spatio temporal detection config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--checkpoint'", ",", "\n", "default", "=", "(", "'https://download.openmmlab.com/mmaction/detection/ava/'", "\n", "'slowonly_omnisource_pretrained_r101_8x8x1_20e_ava_rgb/'", "\n", "'slowonly_omnisource_pretrained_r101_8x8x1_20e_ava_rgb'", "\n", "'_20201217-16378594.pth'", ")", ",", "\n", "help", "=", "'spatio temporal detection checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--action-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.4", ",", "\n", "help", "=", "'the threshold of human action score'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-config'", ",", "\n", "default", "=", "'demo/faster_rcnn_r50_fpn_2x_coco.py'", ",", "\n", "help", "=", "'human detection config file path (from mmdet)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-checkpoint'", ",", "\n", "default", "=", "(", "'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/'", "\n", "'faster_rcnn_r50_fpn_2x_coco/'", "\n", "'faster_rcnn_r50_fpn_2x_coco_'", "\n", "'bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'", ")", ",", "\n", "help", "=", "'human detection checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-score-thr'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.9", ",", "\n", "help", "=", "'the threshold of human detection score'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--input-video'", ",", "\n", "default", "=", "'0'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'webcam id or input video file/url'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--label-map'", ",", "default", "=", "'demo/label_map_ava.txt'", ",", "help", "=", "'label map file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'CPU/CUDA device option'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output-fps'", ",", "\n", "default", "=", "15", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'the fps of demo video output'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--out-filename'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'the filename of output video'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--show'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to show results with cv2.imshow'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--display-height'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "'Image height for human detector and draw frames.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--display-width'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "'Image width for human detector and draw frames.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--predict-stepsize'", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'give out a prediction per n frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--clip-vis-length'", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Number of draw frames per clip.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.main": [[774, 857], ["webcam_demo_spatiotemporal_det.MmdetHumanDetector", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "webcam_demo_spatiotemporal_det.StdetPredictor", "webcam_demo_spatiotemporal_det.ClipHelper", "webcam_demo_spatiotemporal_det.DefaultVisualizer", "webcam_demo_spatiotemporal_det.ClipHelper.start", "webcam_demo_spatiotemporal_det.ClipHelper.join", "webcam_demo_spatiotemporal_det.ClipHelper.clean", "time.time", "webcam_demo_spatiotemporal_det.BaseHumanDetector.predict", "webcam_demo_spatiotemporal_det.StdetPredictor.predict", "webcam_demo_spatiotemporal_det.BaseVisualizer.draw_predictions", "logger.info", "webcam_demo_spatiotemporal_det.ClipHelper.display", "logger.debug", "time.sleep", "time.time"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.clean", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.StdetPredictor.predict", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.StdetPredictor.predict", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.BaseVisualizer.draw_predictions", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.display"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "# init human detector", "\n", "    ", "human_detector", "=", "MmdetHumanDetector", "(", "args", ".", "det_config", ",", "args", ".", "det_checkpoint", ",", "\n", "args", ".", "device", ",", "args", ".", "det_score_thr", ")", "\n", "\n", "# init action detector", "\n", "config", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "config", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "try", ":", "\n", "# In our spatiotemporal detection demo, different actions should have", "\n", "# the same number of bboxes.", "\n", "        ", "config", "[", "'model'", "]", "[", "'test_cfg'", "]", "[", "'rcnn'", "]", "[", "'action_thr'", "]", "=", ".0", "\n", "", "except", "KeyError", ":", "\n", "        ", "pass", "\n", "", "stdet_predictor", "=", "StdetPredictor", "(", "\n", "config", "=", "config", ",", "\n", "checkpoint", "=", "args", ".", "checkpoint", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", "score_thr", "=", "args", ".", "action_score_thr", ",", "\n", "label_map_path", "=", "args", ".", "label_map", ")", "\n", "\n", "# init clip helper", "\n", "clip_helper", "=", "ClipHelper", "(", "\n", "config", "=", "config", ",", "\n", "display_height", "=", "args", ".", "display_height", ",", "\n", "display_width", "=", "args", ".", "display_width", ",", "\n", "input_video", "=", "args", ".", "input_video", ",", "\n", "predict_stepsize", "=", "args", ".", "predict_stepsize", ",", "\n", "output_fps", "=", "args", ".", "output_fps", ",", "\n", "clip_vis_length", "=", "args", ".", "clip_vis_length", ",", "\n", "out_filename", "=", "args", ".", "out_filename", ",", "\n", "show", "=", "args", ".", "show", ")", "\n", "\n", "# init visualizer", "\n", "vis", "=", "DefaultVisualizer", "(", ")", "\n", "\n", "# start read and display thread", "\n", "clip_helper", ".", "start", "(", ")", "\n", "\n", "try", ":", "\n", "# Main thread main function contains:", "\n", "# 1) get data from read queue", "\n", "# 2) get human bboxes and stdet predictions", "\n", "# 3) draw stdet predictions and update task", "\n", "# 4) put task into display queue", "\n", "        ", "for", "able_to_read", ",", "task", "in", "clip_helper", ":", "\n", "# get data from read queue", "\n", "\n", "            ", "if", "not", "able_to_read", ":", "\n", "# read thread is dead and all tasks are processed", "\n", "                ", "break", "\n", "\n", "", "if", "task", "is", "None", ":", "\n", "# when no data in read queue, wait", "\n", "                ", "time", ".", "sleep", "(", "0.01", ")", "\n", "continue", "\n", "\n", "", "inference_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# get human bboxes", "\n", "human_detector", ".", "predict", "(", "task", ")", "\n", "\n", "# get stdet predictions", "\n", "stdet_predictor", ".", "predict", "(", "task", ")", "\n", "\n", "# draw stdet predictions in raw frames", "\n", "vis", ".", "draw_predictions", "(", "task", ")", "\n", "logger", ".", "info", "(", "f'Stdet Results: {task.action_preds}'", ")", "\n", "\n", "# add draw frames to display queue", "\n", "clip_helper", ".", "display", "(", "task", ")", "\n", "\n", "logger", ".", "debug", "(", "'Main thread inference time '", "\n", "f'{1000*(time.time() - inference_start):.0f} ms'", ")", "\n", "\n", "# wait for display thread", "\n", "", "clip_helper", ".", "join", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "\n", "", "finally", ":", "\n", "# close read & display thread, release all resources", "\n", "        ", "clip_helper", ".", "clean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.parse_args": [[28, 79], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'MMAction2 predict different labels in a long video demo'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file/url'", ")", "\n", "parser", ".", "add_argument", "(", "'video_path'", ",", "help", "=", "'video file/url'", ")", "\n", "parser", ".", "add_argument", "(", "'label'", ",", "help", "=", "'label file'", ")", "\n", "parser", ".", "add_argument", "(", "'out_file'", ",", "help", "=", "'output result file in video/json'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--input-step'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "'input step for sampling frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ",", "help", "=", "'CPU/CUDA device option'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--threshold'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.01", ",", "\n", "help", "=", "'recognition score threshold'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--stride'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "(", "'the prediction stride equals to stride * sample_length '", "\n", "'(sample_length indicates the size of temporal window from '", "\n", "'which you sample frames, which equals to '", "\n", "'clip_len x frame_interval), if set as 0, the '", "\n", "'prediction stride is 1'", ")", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--label-color'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "(", "255", ",", "255", ",", "255", ")", ",", "\n", "help", "=", "'font color (B, G, R) of the labels in output video'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--msg-color'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "(", "128", ",", "128", ",", "128", ")", ",", "\n", "help", "=", "'font color (B, G, R) of the messages in output video'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.show_results_video": [[81, 110], ["video_writer.write", "len", "result_queue.popleft", "enumerate", "len", "cv2.putText", "text_info.items", "cv2.putText", "str", "cv2.putText", "round"], "function", ["None"], ["", "def", "show_results_video", "(", "result_queue", ",", "\n", "text_info", ",", "\n", "thr", ",", "\n", "msg", ",", "\n", "frame", ",", "\n", "video_writer", ",", "\n", "label_color", "=", "(", "255", ",", "255", ",", "255", ")", ",", "\n", "msg_color", "=", "(", "128", ",", "128", ",", "128", ")", ")", ":", "\n", "    ", "if", "len", "(", "result_queue", ")", "!=", "0", ":", "\n", "        ", "text_info", "=", "{", "}", "\n", "results", "=", "result_queue", ".", "popleft", "(", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "selected_label", ",", "score", "=", "result", "\n", "if", "score", "<", "thr", ":", "\n", "                ", "break", "\n", "", "location", "=", "(", "0", ",", "40", "+", "i", "*", "20", ")", "\n", "text", "=", "selected_label", "+", "': '", "+", "str", "(", "round", "(", "score", ",", "2", ")", ")", "\n", "text_info", "[", "location", "]", "=", "text", "\n", "cv2", ".", "putText", "(", "frame", ",", "text", ",", "location", ",", "FONTFACE", ",", "FONTSCALE", ",", "\n", "label_color", ",", "THICKNESS", ",", "LINETYPE", ")", "\n", "", "", "elif", "len", "(", "text_info", ")", ":", "\n", "        ", "for", "location", ",", "text", "in", "text_info", ".", "items", "(", ")", ":", "\n", "            ", "cv2", ".", "putText", "(", "frame", ",", "text", ",", "location", ",", "FONTFACE", ",", "FONTSCALE", ",", "\n", "label_color", ",", "THICKNESS", ",", "LINETYPE", ")", "\n", "", "", "else", ":", "\n", "        ", "cv2", ".", "putText", "(", "frame", ",", "msg", ",", "(", "0", ",", "40", ")", ",", "FONTFACE", ",", "FONTSCALE", ",", "msg_color", ",", "\n", "THICKNESS", ",", "LINETYPE", ")", "\n", "", "video_writer", ".", "write", "(", "frame", ")", "\n", "return", "text_info", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.get_results_json": [[112, 127], ["len", "result_queue.popleft", "enumerate", "len", "str", "round"], "function", ["None"], ["", "def", "get_results_json", "(", "result_queue", ",", "text_info", ",", "thr", ",", "msg", ",", "ind", ",", "out_json", ")", ":", "\n", "    ", "if", "len", "(", "result_queue", ")", "!=", "0", ":", "\n", "        ", "text_info", "=", "{", "}", "\n", "results", "=", "result_queue", ".", "popleft", "(", ")", "\n", "for", "i", ",", "result", "in", "enumerate", "(", "results", ")", ":", "\n", "            ", "selected_label", ",", "score", "=", "result", "\n", "if", "score", "<", "thr", ":", "\n", "                ", "break", "\n", "", "text_info", "[", "i", "+", "1", "]", "=", "selected_label", "+", "': '", "+", "str", "(", "round", "(", "score", ",", "2", ")", ")", "\n", "", "out_json", "[", "ind", "]", "=", "text_info", "\n", "", "elif", "len", "(", "text_info", ")", ":", "\n", "        ", "out_json", "[", "ind", "]", "=", "text_info", "\n", "", "else", ":", "\n", "        ", "out_json", "[", "ind", "]", "=", "msg", "\n", "", "return", "text_info", ",", "out_json", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.show_results": [[129, 196], ["collections.deque", "collections.deque", "cv2.VideoCapture", "int", "int", "int", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "mmcv.ProgressBar", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "args.out_file.endswith", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "args.out_file.endswith", "cv2.VideoWriter", "mmcv.ProgressBar.update", "cv2.VideoCapture.read", "backup_frames.append", "long_video_demo.inference", "args.out_file.endswith", "collections.deque.extend", "min", "tuple", "sorted", "collections.deque.append", "long_video_demo.get_results_json", "long_video_demo.show_results_video", "open", "json.dump", "numpy.array", "random.choice", "collections.deque.append", "len", "zip", "operator.itemgetter", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.inference", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.get_results_json", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.show_results_video"], ["", "def", "show_results", "(", "model", ",", "data", ",", "label", ",", "args", ")", ":", "\n", "    ", "frame_queue", "=", "deque", "(", "maxlen", "=", "args", ".", "sample_length", ")", "\n", "result_queue", "=", "deque", "(", "maxlen", "=", "1", ")", "\n", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "args", ".", "video_path", ")", "\n", "num_frames", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "frame_width", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "frame_height", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "\n", "msg", "=", "'Preparing action recognition ...'", "\n", "text_info", "=", "{", "}", "\n", "out_json", "=", "{", "}", "\n", "fourcc", "=", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'mp4v'", ")", "\n", "frame_size", "=", "(", "frame_width", ",", "frame_height", ")", "\n", "\n", "ind", "=", "0", "\n", "video_writer", "=", "None", "if", "args", ".", "out_file", ".", "endswith", "(", "'.json'", ")", "else", "cv2", ".", "VideoWriter", "(", "args", ".", "out_file", ",", "fourcc", ",", "fps", ",", "frame_size", ")", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "num_frames", ")", "\n", "backup_frames", "=", "[", "]", "\n", "\n", "while", "ind", "<", "num_frames", ":", "\n", "        ", "ind", "+=", "1", "\n", "prog_bar", ".", "update", "(", ")", "\n", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "if", "frame", "is", "None", ":", "\n", "# drop it when encounting None", "\n", "            ", "continue", "\n", "", "backup_frames", ".", "append", "(", "np", ".", "array", "(", "frame", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "if", "ind", "==", "args", ".", "sample_length", ":", "\n", "# provide a quick show at the beginning", "\n", "            ", "frame_queue", ".", "extend", "(", "backup_frames", ")", "\n", "backup_frames", "=", "[", "]", "\n", "", "elif", "(", "(", "len", "(", "backup_frames", ")", "==", "args", ".", "input_step", "\n", "and", "ind", ">", "args", ".", "sample_length", ")", "or", "ind", "==", "num_frames", ")", ":", "\n", "# pick a frame from the backup", "\n", "# when the backup is full or reach the last frame", "\n", "            ", "chosen_frame", "=", "random", ".", "choice", "(", "backup_frames", ")", "\n", "backup_frames", "=", "[", "]", "\n", "frame_queue", ".", "append", "(", "chosen_frame", ")", "\n", "\n", "", "ret", ",", "scores", "=", "inference", "(", "model", ",", "data", ",", "args", ",", "frame_queue", ")", "\n", "\n", "if", "ret", ":", "\n", "            ", "num_selected_labels", "=", "min", "(", "len", "(", "label", ")", ",", "5", ")", "\n", "scores_tuples", "=", "tuple", "(", "zip", "(", "label", ",", "scores", ")", ")", "\n", "scores_sorted", "=", "sorted", "(", "\n", "scores_tuples", ",", "key", "=", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "\n", "results", "=", "scores_sorted", "[", ":", "num_selected_labels", "]", "\n", "result_queue", ".", "append", "(", "results", ")", "\n", "\n", "", "if", "args", ".", "out_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "            ", "text_info", ",", "out_json", "=", "get_results_json", "(", "result_queue", ",", "text_info", ",", "\n", "args", ".", "threshold", ",", "msg", ",", "ind", ",", "\n", "out_json", ")", "\n", "", "else", ":", "\n", "            ", "text_info", "=", "show_results_video", "(", "result_queue", ",", "text_info", ",", "\n", "args", ".", "threshold", ",", "msg", ",", "frame", ",", "\n", "video_writer", ",", "args", ".", "label_color", ",", "\n", "args", ".", "msg_color", ")", "\n", "\n", "", "", "cap", ".", "release", "(", ")", "\n", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "if", "args", ".", "out_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "        ", "with", "open", "(", "args", ".", "out_file", ",", "'w'", ")", "as", "js", ":", "\n", "            ", "json", ".", "dump", "(", "out_json", ",", "js", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.inference": [[198, 225], ["list", "data.copy", "args.test_pipeline", "mmcv.parallel.collate", "len", "numpy.array", "next", "torch.no_grad", "int", "range", "model.parameters", "mmcv.parallel.scatter", "model", "frame_queue.popleft"], "function", ["None"], ["", "", "", "def", "inference", "(", "model", ",", "data", ",", "args", ",", "frame_queue", ")", ":", "\n", "    ", "if", "len", "(", "frame_queue", ")", "!=", "args", ".", "sample_length", ":", "\n", "# Do no inference when there is no enough frames", "\n", "        ", "return", "False", ",", "None", "\n", "\n", "", "cur_windows", "=", "list", "(", "np", ".", "array", "(", "frame_queue", ")", ")", "\n", "if", "data", "[", "'img_shape'", "]", "is", "None", ":", "\n", "        ", "data", "[", "'img_shape'", "]", "=", "frame_queue", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "", "cur_data", "=", "data", ".", "copy", "(", ")", "\n", "cur_data", "[", "'imgs'", "]", "=", "cur_windows", "\n", "cur_data", "=", "args", ".", "test_pipeline", "(", "cur_data", ")", "\n", "cur_data", "=", "collate", "(", "[", "cur_data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "        ", "cur_data", "=", "scatter", "(", "cur_data", ",", "[", "args", ".", "device", "]", ")", "[", "0", "]", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "scores", "=", "model", "(", "return_loss", "=", "False", ",", "**", "cur_data", ")", "[", "0", "]", "\n", "\n", "", "if", "args", ".", "stride", ">", "0", ":", "\n", "        ", "pred_stride", "=", "int", "(", "args", ".", "sample_length", "*", "args", ".", "stride", ")", "\n", "for", "_", "in", "range", "(", "pred_stride", ")", ":", "\n", "            ", "frame_queue", ".", "popleft", "(", ")", "\n", "\n", "# for case ``args.stride=0``", "\n", "# deque will automatically popleft one element", "\n", "\n", "", "", "return", "True", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.main": [[227, 261], ["long_video_demo.parse_args", "torch.device", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "mmaction.apis.init_recognizer", "dict", "pipeline.copy", "mmaction.datasets.pipelines.Compose", "long_video_demo.show_results", "open", "line.strip", "pipeline.copy.remove", "pipeline.copy.remove"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.long_video_demo.show_results", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "model", "=", "init_recognizer", "(", "cfg", ",", "args", ".", "checkpoint", ",", "device", "=", "args", ".", "device", ")", "\n", "data", "=", "dict", "(", "img_shape", "=", "None", ",", "modality", "=", "'RGB'", ",", "label", "=", "-", "1", ")", "\n", "with", "open", "(", "args", ".", "label", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "# prepare test pipeline from non-camera pipeline", "\n", "", "cfg", "=", "model", ".", "cfg", "\n", "sample_length", "=", "0", "\n", "pipeline", "=", "cfg", ".", "data", ".", "test", ".", "pipeline", "\n", "pipeline_", "=", "pipeline", ".", "copy", "(", ")", "\n", "for", "step", "in", "pipeline", ":", "\n", "        ", "if", "'SampleFrames'", "in", "step", "[", "'type'", "]", ":", "\n", "            ", "sample_length", "=", "step", "[", "'clip_len'", "]", "*", "step", "[", "'num_clips'", "]", "\n", "data", "[", "'num_clips'", "]", "=", "step", "[", "'num_clips'", "]", "\n", "data", "[", "'clip_len'", "]", "=", "step", "[", "'clip_len'", "]", "\n", "pipeline_", ".", "remove", "(", "step", ")", "\n", "", "if", "step", "[", "'type'", "]", "in", "EXCLUED_STEPS", ":", "\n", "# remove step to decode frames", "\n", "            ", "pipeline_", ".", "remove", "(", "step", ")", "\n", "", "", "test_pipeline", "=", "Compose", "(", "pipeline_", ")", "\n", "\n", "assert", "sample_length", ">", "0", "\n", "args", ".", "sample_length", "=", "sample_length", "\n", "args", ".", "test_pipeline", "=", "test_pipeline", "\n", "\n", "show_results", "(", "model", ",", "data", ",", "label", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.train.parse_args": [[21, 76], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_mutually_exclusive_group", "parser.add_mutually_exclusive_group.add_argument", "parser.add_mutually_exclusive_group.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a recognizer'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'train config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--work-dir'", ",", "help", "=", "'the dir to save logs and models'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume-from'", ",", "help", "=", "'the checkpoint file to resume from'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--validate'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to evaluate the checkpoint during training'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test-last'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to test the checkpoint after training'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test-best'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "(", "'whether to test the best checkpoint (if applicable) after '", "\n", "'training'", ")", ")", "\n", "group_gpus", "=", "parser", ".", "add_mutually_exclusive_group", "(", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpus'", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'number of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpu-ids'", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'ids of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--deterministic'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to set deterministic options for CUDNN backend.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.train.main": [[78, 196], ["train.parse_args", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "Config.fromfile.get", "Config.fromfile.setdefault", "Config.fromfile.setdefault", "mmcv.mkdir_or_exist", "Config.fromfile.dump", "time.strftime", "os.join", "mmaction.utils.get_root_logger", "dict", "mmaction.utils.collect_env", "mmaction.utils.get_root_logger.info", "mmaction.utils.get_root_logger.info", "mmaction.utils.get_root_logger.info", "os.basename", "os.basename", "mmaction.models.build_model", "dict", "mmaction.apis.train_model", "mmcv.runner.init_dist", "mmcv.runner.get_dist_info", "range", "os.abspath", "os.join", "time.localtime", "mmaction.utils.get_root_logger.info", "mmcv.runner.set_random_seed", "Config.fromfile.work_dir.rstrip", "len", "mmaction.utils.register_module_hooks", "isinstance", "len", "copy.deepcopy", "datasets.append", "dict", "Config.fromfile.get", "os.join", "range", "range", "os.basename", "Config.fromfile.get", "Config.fromfile.get", "mmaction.datasets.build_dataset", "mmaction.datasets.build_dataset", "warnings.warn", "mmaction.datasets.build_dataset", "mmaction.utils.collect_env.items", "os.splitext", "mmcv.utils.get_git_hash", "os.basename"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.collect_env.collect_env", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "# set cudnn_benchmark", "\n", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# work_dir is determined in this priority:", "\n", "# CLI > config file > default (base filename)", "\n", "", "if", "args", ".", "work_dir", "is", "not", "None", ":", "\n", "# update configs according to CLI args if args.work_dir is not None", "\n", "        ", "cfg", ".", "work_dir", "=", "args", ".", "work_dir", "\n", "", "elif", "cfg", ".", "get", "(", "'work_dir'", ",", "None", ")", "is", "None", ":", "\n", "# use config filename as default work_dir if cfg.work_dir is None", "\n", "        ", "cfg", ".", "work_dir", "=", "osp", ".", "join", "(", "'./work_dirs'", ",", "\n", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", "[", "0", "]", ")", "\n", "", "if", "args", ".", "resume_from", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "resume_from", "=", "args", ".", "resume_from", "\n", "", "if", "args", ".", "gpu_ids", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "args", ".", "gpu_ids", "\n", "", "else", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "range", "(", "1", ")", "if", "args", ".", "gpus", "is", "None", "else", "range", "(", "args", ".", "gpus", ")", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "_", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "cfg", ".", "gpu_ids", "=", "range", "(", "world_size", ")", "\n", "\n", "# The flag is used to determine whether it is omnisource training", "\n", "", "cfg", ".", "setdefault", "(", "'omnisource'", ",", "False", ")", "\n", "\n", "# The flag is used to register module's hooks", "\n", "cfg", ".", "setdefault", "(", "'module_hooks'", ",", "[", "]", ")", "\n", "\n", "# create work_dir", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "abspath", "(", "cfg", ".", "work_dir", ")", ")", "\n", "# dump config", "\n", "cfg", ".", "dump", "(", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", ")", "\n", "# init logger before other steps", "\n", "timestamp", "=", "time", ".", "strftime", "(", "'%Y%m%d_%H%M%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "log_file", "=", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "f'{timestamp}.log'", ")", "\n", "logger", "=", "get_root_logger", "(", "log_file", "=", "log_file", ",", "log_level", "=", "cfg", ".", "log_level", ")", "\n", "\n", "# init the meta dict to record some important information such as", "\n", "# environment info and seed, which will be logged", "\n", "meta", "=", "dict", "(", ")", "\n", "# log env info", "\n", "env_info_dict", "=", "collect_env", "(", ")", "\n", "env_info", "=", "'\\n'", ".", "join", "(", "[", "f'{k}: {v}'", "for", "k", ",", "v", "in", "env_info_dict", ".", "items", "(", ")", "]", ")", "\n", "dash_line", "=", "'-'", "*", "60", "+", "'\\n'", "\n", "logger", ".", "info", "(", "'Environment info:\\n'", "+", "dash_line", "+", "env_info", "+", "'\\n'", "+", "\n", "dash_line", ")", "\n", "meta", "[", "'env_info'", "]", "=", "env_info", "\n", "\n", "# log some basic info", "\n", "logger", ".", "info", "(", "f'Distributed training: {distributed}'", ")", "\n", "logger", ".", "info", "(", "f'Config: {cfg.pretty_text}'", ")", "\n", "\n", "# set random seeds", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "f'Set random seed to {args.seed}, '", "\n", "f'deterministic: {args.deterministic}'", ")", "\n", "set_random_seed", "(", "args", ".", "seed", ",", "deterministic", "=", "args", ".", "deterministic", ")", "\n", "", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "meta", "[", "'seed'", "]", "=", "args", ".", "seed", "\n", "meta", "[", "'config_name'", "]", "=", "osp", ".", "basename", "(", "args", ".", "config", ")", "\n", "meta", "[", "'work_dir'", "]", "=", "osp", ".", "basename", "(", "cfg", ".", "work_dir", ".", "rstrip", "(", "'/\\\\'", ")", ")", "\n", "\n", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "\n", "train_cfg", "=", "cfg", ".", "get", "(", "'train_cfg'", ")", ",", "\n", "test_cfg", "=", "cfg", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "if", "len", "(", "cfg", ".", "module_hooks", ")", ">", "0", ":", "\n", "        ", "register_module_hooks", "(", "model", ",", "cfg", ".", "module_hooks", ")", "\n", "\n", "", "if", "cfg", ".", "omnisource", ":", "\n", "# If omnisource flag is set, cfg.data.train should be a list", "\n", "        ", "assert", "isinstance", "(", "cfg", ".", "data", ".", "train", ",", "list", ")", "\n", "datasets", "=", "[", "build_dataset", "(", "dataset", ")", "for", "dataset", "in", "cfg", ".", "data", ".", "train", "]", "\n", "", "else", ":", "\n", "        ", "datasets", "=", "[", "build_dataset", "(", "cfg", ".", "data", ".", "train", ")", "]", "\n", "\n", "", "if", "len", "(", "cfg", ".", "workflow", ")", "==", "2", ":", "\n", "# For simplicity, omnisource is not compatiable with val workflow,", "\n", "# we recommend you to use `--validate`", "\n", "        ", "assert", "not", "cfg", ".", "omnisource", "\n", "if", "args", ".", "validate", ":", "\n", "            ", "warnings", ".", "warn", "(", "'val workflow is duplicated with `--validate`, '", "\n", "'it is recommended to use `--validate`. see '", "\n", "'https://github.com/open-mmlab/mmaction2/pull/123'", ")", "\n", "", "val_dataset", "=", "copy", ".", "deepcopy", "(", "cfg", ".", "data", ".", "val", ")", "\n", "datasets", ".", "append", "(", "build_dataset", "(", "val_dataset", ")", ")", "\n", "", "if", "cfg", ".", "checkpoint_config", "is", "not", "None", ":", "\n", "# save mmaction version, config file content and class names in", "\n", "# checkpoints as meta data", "\n", "        ", "cfg", ".", "checkpoint_config", ".", "meta", "=", "dict", "(", "\n", "mmaction_version", "=", "__version__", "+", "get_git_hash", "(", "digits", "=", "7", ")", ",", "\n", "config", "=", "cfg", ".", "pretty_text", ")", "\n", "\n", "", "test_option", "=", "dict", "(", "test_last", "=", "args", ".", "test_last", ",", "test_best", "=", "args", ".", "test_best", ")", "\n", "train_model", "(", "\n", "model", ",", "\n", "datasets", ",", "\n", "cfg", ",", "\n", "distributed", "=", "distributed", ",", "\n", "validate", "=", "args", ".", "validate", ",", "\n", "test", "=", "test_option", ",", "\n", "timestamp", "=", "timestamp", ",", "\n", "meta", "=", "meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.parse_args": [[30, 112], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str", "ValueError", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'MMAction2 test (and eval) a model'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--out'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'output result file in pkl/yaml/json format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'evaluation metrics, which depends on the dataset, e.g.,'", "\n", "' \"top_k_accuracy\", \"mean_class_accuracy\" for video dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gpu-collect'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use gpu to collect results'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tmpdir'", ",", "\n", "help", "=", "'tmp directory used for collecting results from multiple '", "\n", "'workers, available when gpu-collect is not specified'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function (deprecate), '", "\n", "'change to --eval-options instead.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--average-clips'", ",", "\n", "choices", "=", "[", "'score'", ",", "'prob'", ",", "None", "]", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'average type when averaging test clips'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--onnx'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to test with onnx model or not'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tensorrt'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to test with TensorRT engine or not'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "\n", "", "if", "args", ".", "options", "and", "args", ".", "eval_options", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'--options and --eval-options cannot be both '", "\n", "'specified, --options is deprecated in favor of --eval-options'", ")", "\n", "", "if", "args", ".", "options", ":", "\n", "        ", "warnings", ".", "warn", "(", "'--options is deprecated in favor of --eval-options'", ")", "\n", "args", ".", "eval_options", "=", "args", ".", "options", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.turn_off_pretrained": [[114, 124], ["cfg.values", "isinstance", "test.turn_off_pretrained"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.turn_off_pretrained"], ["", "def", "turn_off_pretrained", "(", "cfg", ")", ":", "\n", "# recursively find all pretrained in the model config,", "\n", "# and set them None to avoid redundant pretrain steps for testing", "\n", "    ", "if", "'pretrained'", "in", "cfg", ":", "\n", "        ", "cfg", ".", "pretrained", "=", "None", "\n", "\n", "# recursively turn off pretrained value", "\n", "", "for", "sub_cfg", "in", "cfg", ".", "values", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "sub_cfg", ",", "dict", ")", ":", "\n", "            ", "turn_off_pretrained", "(", "sub_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.inference_pytorch": [[126, 170], ["test.turn_off_pretrained", "mmaction.models.build_model", "cfg.get", "mmcv.runner.load_checkpoint", "len", "mmaction.utils.register_module_hooks", "mmcv.runner.fp16_utils.wrap_fp16_model", "mmcv.cnn.fuse_conv_bn", "mmcv.parallel.MMDataParallel", "single_gpu_test", "mmcv.parallel.MMDistributedDataParallel", "multi_gpu_test", "cfg.model.setdefault", "cfg.get", "mmcv.parallel.MMDistributedDataParallel.cuda", "cfg.model.get", "cfg.get", "dict", "cfg.model.get", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.turn_off_pretrained", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "", "", "def", "inference_pytorch", "(", "args", ",", "cfg", ",", "distributed", ",", "data_loader", ")", ":", "\n", "    ", "\"\"\"Get predictions by pytorch models.\"\"\"", "\n", "if", "args", ".", "average_clips", "is", "not", "None", ":", "\n", "# You can set average_clips during testing, it will override the", "\n", "# original setting", "\n", "        ", "if", "cfg", ".", "model", ".", "get", "(", "'test_cfg'", ")", "is", "None", "and", "cfg", ".", "get", "(", "'test_cfg'", ")", "is", "None", ":", "\n", "            ", "cfg", ".", "model", ".", "setdefault", "(", "'test_cfg'", ",", "\n", "dict", "(", "average_clips", "=", "args", ".", "average_clips", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "cfg", ".", "model", ".", "get", "(", "'test_cfg'", ")", "is", "not", "None", ":", "\n", "                ", "cfg", ".", "model", ".", "test_cfg", ".", "average_clips", "=", "args", ".", "average_clips", "\n", "", "else", ":", "\n", "                ", "cfg", ".", "test_cfg", ".", "average_clips", "=", "args", ".", "average_clips", "\n", "\n", "# remove redundant pretrain steps for testing", "\n", "", "", "", "turn_off_pretrained", "(", "cfg", ".", "model", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "None", ",", "test_cfg", "=", "cfg", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "if", "len", "(", "cfg", ".", "module_hooks", ")", ">", "0", ":", "\n", "        ", "register_module_hooks", "(", "model", ",", "cfg", ".", "module_hooks", ")", "\n", "\n", "", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "load_checkpoint", "(", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "if", "not", "distributed", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "outputs", "=", "single_gpu_test", "(", "model", ",", "data_loader", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ")", "\n", "outputs", "=", "multi_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "tmpdir", ",", "\n", "args", ".", "gpu_collect", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.inference_tensorrt": [[172, 220], ["runtime.deserialize_cuda_engine.create_execution_context", "torch_dtype_from_trt", "tuple", "torch_device_from_trt", "torch.empty", "mmcv.ProgressBar", "trt.Logger", "trt.Runtime", "runtime.deserialize_cuda_engine", "runtime.deserialize_cuda_engine.get_binding_shape", "runtime.deserialize_cuda_engine.get_binding_dtype", "engine.create_execution_context.get_binding_shape", "runtime.deserialize_cuda_engine.get_location", "len", "engine.create_execution_context.execute_async_v2", "results.extend", "len", "range", "open", "f.read", "data[].contiguous().data_ptr", "torch.empty.contiguous().data_ptr", "torch.empty.cpu().numpy", "next", "mmcv.ProgressBar.update", "torch.cuda.current_stream", "iter", "data[].contiguous", "torch.empty.contiguous", "torch.empty.cpu", "data.values"], "function", ["None"], ["", "def", "inference_tensorrt", "(", "ckpt_path", ",", "distributed", ",", "data_loader", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"Get predictions by TensorRT engine.\n\n    For now, multi-gpu mode and dynamic tensor shape are not supported.\n    \"\"\"", "\n", "assert", "not", "distributed", ",", "'TensorRT engine inference only supports single gpu mode.'", "\n", "import", "tensorrt", "as", "trt", "\n", "from", "mmcv", ".", "tensorrt", ".", "tensorrt_utils", "import", "(", "torch_dtype_from_trt", ",", "\n", "torch_device_from_trt", ")", "\n", "\n", "# load engine", "\n", "with", "trt", ".", "Logger", "(", ")", "as", "logger", ",", "trt", ".", "Runtime", "(", "logger", ")", "as", "runtime", ":", "\n", "        ", "with", "open", "(", "ckpt_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "            ", "engine_bytes", "=", "f", ".", "read", "(", ")", "\n", "", "engine", "=", "runtime", ".", "deserialize_cuda_engine", "(", "engine_bytes", ")", "\n", "\n", "# For now, only support fixed input tensor", "\n", "", "cur_batch_size", "=", "engine", ".", "get_binding_shape", "(", "0", ")", "[", "0", "]", "\n", "assert", "batch_size", "==", "cur_batch_size", ",", "(", "'Dataset and TensorRT model should share the same batch size, '", "\n", "f'but get {batch_size} and {cur_batch_size}'", ")", "\n", "\n", "context", "=", "engine", ".", "create_execution_context", "(", ")", "\n", "\n", "# get output tensor", "\n", "dtype", "=", "torch_dtype_from_trt", "(", "engine", ".", "get_binding_dtype", "(", "1", ")", ")", "\n", "shape", "=", "tuple", "(", "context", ".", "get_binding_shape", "(", "1", ")", ")", "\n", "device", "=", "torch_device_from_trt", "(", "engine", ".", "get_location", "(", "1", ")", ")", "\n", "output", "=", "torch", ".", "empty", "(", "\n", "size", "=", "shape", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# get predictions", "\n", "results", "=", "[", "]", "\n", "dataset", "=", "data_loader", ".", "dataset", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "dataset", ")", ")", "\n", "for", "data", "in", "data_loader", ":", "\n", "        ", "bindings", "=", "[", "\n", "data", "[", "'imgs'", "]", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "output", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "\n", "]", "\n", "context", ".", "execute_async_v2", "(", "bindings", ",", "\n", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "cuda_stream", ")", "\n", "results", ".", "extend", "(", "output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "batch_size", "=", "len", "(", "next", "(", "iter", "(", "data", ".", "values", "(", ")", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "prog_bar", ".", "update", "(", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.inference_onnx": [[222, 263], ["onnx.load", "list", "rt.InferenceSession", "mmcv.ProgressBar", "len", "len", "data[].cpu().numpy", "results.extend", "len", "range", "set", "set", "rt.InferenceSession.run", "next", "mmcv.ProgressBar.update", "data[].cpu", "iter", "data.values"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["", "def", "inference_onnx", "(", "ckpt_path", ",", "distributed", ",", "data_loader", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"Get predictions by ONNX.\n\n    For now, multi-gpu mode and dynamic tensor shape are not supported.\n    \"\"\"", "\n", "assert", "not", "distributed", ",", "'ONNX inference only supports single gpu mode.'", "\n", "\n", "import", "onnx", "\n", "import", "onnxruntime", "as", "rt", "\n", "\n", "# get input tensor name", "\n", "onnx_model", "=", "onnx", ".", "load", "(", "ckpt_path", ")", "\n", "input_all", "=", "[", "node", ".", "name", "for", "node", "in", "onnx_model", ".", "graph", ".", "input", "]", "\n", "input_initializer", "=", "[", "node", ".", "name", "for", "node", "in", "onnx_model", ".", "graph", ".", "initializer", "]", "\n", "net_feed_input", "=", "list", "(", "set", "(", "input_all", ")", "-", "set", "(", "input_initializer", ")", ")", "\n", "assert", "len", "(", "net_feed_input", ")", "==", "1", "\n", "\n", "# For now, only support fixed tensor shape", "\n", "input_tensor", "=", "None", "\n", "for", "tensor", "in", "onnx_model", ".", "graph", ".", "input", ":", "\n", "        ", "if", "tensor", ".", "name", "==", "net_feed_input", "[", "0", "]", ":", "\n", "            ", "input_tensor", "=", "tensor", "\n", "break", "\n", "", "", "cur_batch_size", "=", "input_tensor", ".", "type", ".", "tensor_type", ".", "shape", ".", "dim", "[", "0", "]", ".", "dim_value", "\n", "assert", "batch_size", "==", "cur_batch_size", ",", "(", "'Dataset and ONNX model should share the same batch size, '", "\n", "f'but get {batch_size} and {cur_batch_size}'", ")", "\n", "\n", "# get predictions", "\n", "sess", "=", "rt", ".", "InferenceSession", "(", "ckpt_path", ")", "\n", "results", "=", "[", "]", "\n", "dataset", "=", "data_loader", ".", "dataset", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "dataset", ")", ")", "\n", "for", "data", "in", "data_loader", ":", "\n", "        ", "imgs", "=", "data", "[", "'imgs'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "onnx_result", "=", "sess", ".", "run", "(", "None", ",", "{", "net_feed_input", "[", "0", "]", ":", "imgs", "}", ")", "[", "0", "]", "\n", "results", ".", "extend", "(", "onnx_result", ")", "\n", "batch_size", "=", "len", "(", "next", "(", "iter", "(", "data", ".", "values", "(", ")", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "prog_bar", ".", "update", "(", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.main": [[265, 361], ["test.parse_args", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "Config.fromfile.get", "Config.fromfile.get", "Config._merge_a_into_b.get", "Config.fromfile.get", "Config.fromfile.setdefault", "mmaction.datasets.build_dataset", "dict", "dict", "mmaction.datasets.build_dataloader", "mmcv.runner.get_dist_info", "ValueError", "mmcv.Config._merge_a_into_b", "mmcv.Config._merge_a_into_b", "mmcv.Config._merge_a_into_b", "mmcv.runner.init_dist", "dict", "test.inference_tensorrt", "Config._merge_a_into_b.get", "dict", "dict", "warnings.warn", "mmcv.mkdir_or_exist", "os.splitext", "Config.fromfile.data.get", "Config.fromfile.data.get", "Config.fromfile.data.get", "test.inference_onnx", "test.inference_pytorch", "print", "mmaction.datasets.build_dataset.dump_results", "mmaction.datasets.build_dataset.evaluate", "dataset.evaluate.items", "os.dirname", "print"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.inference_tensorrt", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.tools.test.inference_onnx", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.inference_pytorch", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.dump_results", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "tensorrt", "and", "args", ".", "onnx", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'Cannot set onnx mode and tensorrt mode at the same time.'", ")", "\n", "\n", "", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "# Load output_config from cfg", "\n", "output_config", "=", "cfg", ".", "get", "(", "'output_config'", ",", "{", "}", ")", "\n", "if", "args", ".", "out", ":", "\n", "# Overwrite output_config from args.out", "\n", "        ", "output_config", "=", "Config", ".", "_merge_a_into_b", "(", "\n", "dict", "(", "out", "=", "args", ".", "out", ")", ",", "output_config", ")", "\n", "\n", "# Load eval_config from cfg", "\n", "", "eval_config", "=", "cfg", ".", "get", "(", "'eval_config'", ",", "{", "}", ")", "\n", "if", "args", ".", "eval", ":", "\n", "# Overwrite eval_config from args.eval", "\n", "        ", "eval_config", "=", "Config", ".", "_merge_a_into_b", "(", "\n", "dict", "(", "metrics", "=", "args", ".", "eval", ")", ",", "eval_config", ")", "\n", "", "if", "args", ".", "eval_options", ":", "\n", "# Add options from args.eval_options", "\n", "        ", "eval_config", "=", "Config", ".", "_merge_a_into_b", "(", "args", ".", "eval_options", ",", "eval_config", ")", "\n", "\n", "", "assert", "output_config", "or", "eval_config", ",", "(", "'Please specify at least one operation (save or eval the '", "\n", "'results) with the argument \"--out\" or \"--eval\"'", ")", "\n", "\n", "dataset_type", "=", "cfg", ".", "data", ".", "test", ".", "type", "\n", "if", "output_config", ".", "get", "(", "'out'", ",", "None", ")", ":", "\n", "        ", "if", "'output_format'", "in", "output_config", ":", "\n", "# ugly workround to make recognition and localization the same", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'Skip checking `output_format` in localization task.'", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "output_config", "[", "'out'", "]", "\n", "# make sure the dirname of the output path exists", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "dirname", "(", "out", ")", ")", "\n", "_", ",", "suffix", "=", "osp", ".", "splitext", "(", "out", ")", "\n", "if", "dataset_type", "==", "'AVADataset'", ":", "\n", "                ", "assert", "suffix", "[", "1", ":", "]", "==", "'csv'", ",", "(", "'For AVADataset, the format of '", "\n", "'the output file should be csv'", ")", "\n", "", "else", ":", "\n", "                ", "assert", "suffix", "[", "1", ":", "]", "in", "file_handlers", ",", "(", "\n", "'The format of the output '", "\n", "'file should be json, pickle or yaml'", ")", "\n", "\n", "# set cudnn benchmark", "\n", "", "", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "# The flag is used to register module's hooks", "\n", "", "cfg", ".", "setdefault", "(", "'module_hooks'", ",", "[", "]", ")", "\n", "\n", "# build the dataloader", "\n", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ",", "dict", "(", "test_mode", "=", "True", ")", ")", "\n", "dataloader_setting", "=", "dict", "(", "\n", "videos_per_gpu", "=", "cfg", ".", "data", ".", "get", "(", "'videos_per_gpu'", ",", "1", ")", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "get", "(", "'workers_per_gpu'", ",", "1", ")", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "dataloader_setting", "=", "dict", "(", "dataloader_setting", ",", "\n", "**", "cfg", ".", "data", ".", "get", "(", "'test_dataloader'", ",", "{", "}", ")", ")", "\n", "data_loader", "=", "build_dataloader", "(", "dataset", ",", "**", "dataloader_setting", ")", "\n", "\n", "if", "args", ".", "tensorrt", ":", "\n", "        ", "outputs", "=", "inference_tensorrt", "(", "args", ".", "checkpoint", ",", "distributed", ",", "data_loader", ",", "\n", "dataloader_setting", "[", "'videos_per_gpu'", "]", ")", "\n", "", "elif", "args", ".", "onnx", ":", "\n", "        ", "outputs", "=", "inference_onnx", "(", "args", ".", "checkpoint", ",", "distributed", ",", "data_loader", ",", "\n", "dataloader_setting", "[", "'videos_per_gpu'", "]", ")", "\n", "", "else", ":", "\n", "        ", "outputs", "=", "inference_pytorch", "(", "args", ",", "cfg", ",", "distributed", ",", "data_loader", ")", "\n", "\n", "", "rank", ",", "_", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "if", "output_config", ".", "get", "(", "'out'", ",", "None", ")", ":", "\n", "            ", "out", "=", "output_config", "[", "'out'", "]", "\n", "print", "(", "f'\\nwriting results to {out}'", ")", "\n", "dataset", ".", "dump_results", "(", "outputs", ",", "**", "output_config", ")", "\n", "", "if", "eval_config", ":", "\n", "            ", "eval_res", "=", "dataset", ".", "evaluate", "(", "outputs", ",", "**", "eval_config", ")", "\n", "for", "name", ",", "val", "in", "eval_res", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "f'{name}: {val:.04f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.print_config.parse_args": [[6, 14], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Print the whole config'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--options'", ",", "nargs", "=", "'+'", ",", "action", "=", "DictAction", ",", "help", "=", "'arguments in dict'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.print_config.main": [[16, 23], ["print_config.parse_args", "mmcv.Config.fromfile", "print", "Config.fromfile.merge_from_dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "if", "args", ".", "options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "options", ")", "\n", "", "print", "(", "f'Config:\\n{cfg.pretty_text}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.bench_processing.main": [[22, 60], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmcv.Config.fromfile", "mmaction.utils.get_root_logger", "mmaction.utils.get_root_logger.info", "mmaction.utils.get_root_logger.info", "mmaction.datasets.build_dataset", "mmaction.datasets.build_dataloader", "mmcv.ProgressBar", "enumerate", "os.path.exists", "open", "len", "mmcv.ProgressBar.start", "mmcv.ProgressBar.update", "f.readlines", "open", "f1.writelines"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Benchmark dataloading'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'train config file path'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "# init logger before other steps", "\n", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'MMAction2 Version: {__version__}'", ")", "\n", "logger", ".", "info", "(", "f'Config: {cfg.text}'", ")", "\n", "\n", "# create bench data list", "\n", "ann_file_bench", "=", "'benchlist.txt'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "ann_file_bench", ")", ":", "\n", "        ", "with", "open", "(", "cfg", ".", "ann_file_train", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "[", ":", "256", "]", "\n", "with", "open", "(", "ann_file_bench", ",", "'w'", ")", "as", "f1", ":", "\n", "                ", "f1", ".", "writelines", "(", "lines", ")", "\n", "", "", "", "cfg", ".", "data", ".", "train", ".", "ann_file", "=", "ann_file_bench", "\n", "\n", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "train", ")", "\n", "data_loader", "=", "build_dataloader", "(", "\n", "dataset", ",", "\n", "videos_per_gpu", "=", "cfg", ".", "data", ".", "videos_per_gpu", ",", "\n", "workers_per_gpu", "=", "0", ",", "\n", "num_gpus", "=", "1", ",", "\n", "dist", "=", "False", ")", "\n", "\n", "# Start progress bar after first 5 batches", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "\n", "len", "(", "dataset", ")", "-", "5", "*", "cfg", ".", "data", ".", "videos_per_gpu", ",", "start", "=", "False", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "if", "i", "==", "5", ":", "\n", "            ", "prog_bar", ".", "start", "(", ")", "\n", "", "for", "_", "in", "data", "[", "'imgs'", "]", ":", "\n", "            ", "if", "i", "<", "5", ":", "\n", "                ", "continue", "\n", "", "prog_bar", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.get_flops.parse_args": [[13, 24], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a recognizer'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'train config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shape'", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "'+'", ",", "\n", "default", "=", "[", "340", ",", "256", "]", ",", "\n", "help", "=", "'input image size'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.get_flops.main": [[26, 67], ["get_flops.parse_args", "mmcv.Config.fromfile", "mmaction.models.build_recognizer", "model.cuda.cuda", "model.cuda.eval", "hasattr", "get_model_complexity_info", "print", "print", "len", "NotImplementedError", "len", "Config.fromfile.get", "Config.fromfile.get", "tuple", "len", "tuple", "len", "tuple", "ValueError"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "if", "len", "(", "args", ".", "shape", ")", "==", "1", ":", "\n", "        ", "input_shape", "=", "(", "1", ",", "3", ",", "args", ".", "shape", "[", "0", "]", ",", "args", ".", "shape", "[", "0", "]", ")", "\n", "", "elif", "len", "(", "args", ".", "shape", ")", "==", "2", ":", "\n", "        ", "input_shape", "=", "(", "\n", "1", ",", "\n", "3", ",", "\n", ")", "+", "tuple", "(", "args", ".", "shape", ")", "\n", "", "elif", "len", "(", "args", ".", "shape", ")", "==", "4", ":", "\n", "# n, c, h, w = args.shape", "\n", "        ", "input_shape", "=", "tuple", "(", "args", ".", "shape", ")", "\n", "", "elif", "len", "(", "args", ".", "shape", ")", "==", "5", ":", "\n", "# n, c, t, h, w = args.shape", "\n", "        ", "input_shape", "=", "tuple", "(", "args", ".", "shape", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid input shape'", ")", "\n", "\n", "", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "model", "=", "build_recognizer", "(", "\n", "cfg", ".", "model", ",", "\n", "train_cfg", "=", "cfg", ".", "get", "(", "'train_cfg'", ")", ",", "\n", "test_cfg", "=", "cfg", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "hasattr", "(", "model", ",", "'forward_dummy'", ")", ":", "\n", "        ", "model", ".", "forward", "=", "model", ".", "forward_dummy", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "'FLOPs counter is currently not currently supported with {}'", ".", "\n", "format", "(", "model", ".", "__class__", ".", "__name__", ")", ")", "\n", "\n", "", "flops", ",", "params", "=", "get_model_complexity_info", "(", "model", ",", "input_shape", ")", "\n", "split_line", "=", "'='", "*", "30", "\n", "print", "(", "f'{split_line}\\nInput shape: {input_shape}\\n'", "\n", "f'Flops: {flops}\\nParams: {params}\\n{split_line}'", ")", "\n", "print", "(", "'!!!Please be cautious if you use the results in papers. '", "\n", "'You may need to check if all ops are supported and verify that the '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.cal_train_time": [[10, 31], ["enumerate", "print", "log_dict.keys", "numpy.array", "np.array.mean", "all_times.mean.argmax", "all_times.mean.argmin", "all_times.mean.std", "print", "print", "print", "print", "print", "np.array.append", "np.array.append", "numpy.mean"], "function", ["None"], ["def", "cal_train_time", "(", "log_dicts", ",", "args", ")", ":", "\n", "    ", "for", "i", ",", "log_dict", "in", "enumerate", "(", "log_dicts", ")", ":", "\n", "        ", "print", "(", "f'{\"-\" * 5}Analyze train time of {args.json_logs[i]}{\"-\" * 5}'", ")", "\n", "all_times", "=", "[", "]", "\n", "for", "epoch", "in", "log_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "args", ".", "include_outliers", ":", "\n", "                ", "all_times", ".", "append", "(", "log_dict", "[", "epoch", "]", "[", "'time'", "]", ")", "\n", "", "else", ":", "\n", "                ", "all_times", ".", "append", "(", "log_dict", "[", "epoch", "]", "[", "'time'", "]", "[", "1", ":", "]", ")", "\n", "", "", "all_times", "=", "np", ".", "array", "(", "all_times", ")", "\n", "epoch_ave_time", "=", "all_times", ".", "mean", "(", "-", "1", ")", "\n", "slowest_epoch", "=", "epoch_ave_time", ".", "argmax", "(", ")", "\n", "fastest_epoch", "=", "epoch_ave_time", ".", "argmin", "(", ")", "\n", "std_over_epoch", "=", "epoch_ave_time", ".", "std", "(", ")", "\n", "print", "(", "f'slowest epoch {slowest_epoch + 1}, '", "\n", "f'average time is {epoch_ave_time[slowest_epoch]:.4f}'", ")", "\n", "print", "(", "f'fastest epoch {fastest_epoch + 1}, '", "\n", "f'average time is {epoch_ave_time[fastest_epoch]:.4f}'", ")", "\n", "print", "(", "f'time std over epochs is {std_over_epoch:.4f}'", ")", "\n", "print", "(", "f'average iter time: {np.mean(all_times):.4f} s/iter'", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.plot_curve": [[33, 77], ["seaborn.set_style", "len", "enumerate", "matplotlib.switch_backend", "len", "list", "enumerate", "matplotlib.show", "print", "matplotlib.savefig", "matplotlib.cla", "len", "len", "log_dict.keys", "print", "numpy.concatenate", "numpy.concatenate", "matplotlib.xlabel", "matplotlib.plot", "matplotlib.legend", "matplotlib.title", "legend.append", "KeyError", "np.concatenate.append", "np.concatenate.append", "numpy.array", "numpy.array", "len"], "function", ["None"], ["", "", "def", "plot_curve", "(", "log_dicts", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "backend", "is", "not", "None", ":", "\n", "        ", "plt", ".", "switch_backend", "(", "args", ".", "backend", ")", "\n", "", "sns", ".", "set_style", "(", "args", ".", "style", ")", "\n", "# if legend is None, use {filename}_{key} as legend", "\n", "legend", "=", "args", ".", "legend", "\n", "if", "legend", "is", "None", ":", "\n", "        ", "legend", "=", "[", "]", "\n", "for", "json_log", "in", "args", ".", "json_logs", ":", "\n", "            ", "for", "metric", "in", "args", ".", "keys", ":", "\n", "                ", "legend", ".", "append", "(", "f'{json_log}_{metric}'", ")", "\n", "", "", "", "assert", "len", "(", "legend", ")", "==", "(", "len", "(", "args", ".", "json_logs", ")", "*", "len", "(", "args", ".", "keys", ")", ")", "\n", "metrics", "=", "args", ".", "keys", "\n", "\n", "num_metrics", "=", "len", "(", "metrics", ")", "\n", "for", "i", ",", "log_dict", "in", "enumerate", "(", "log_dicts", ")", ":", "\n", "        ", "epochs", "=", "list", "(", "log_dict", ".", "keys", "(", ")", ")", "\n", "for", "j", ",", "metric", "in", "enumerate", "(", "metrics", ")", ":", "\n", "            ", "print", "(", "f'plot curve of {args.json_logs[i]}, metric is {metric}'", ")", "\n", "if", "metric", "not", "in", "log_dict", "[", "epochs", "[", "0", "]", "]", ":", "\n", "                ", "raise", "KeyError", "(", "\n", "f'{args.json_logs[i]} does not contain metric {metric}'", ")", "\n", "", "xs", "=", "[", "]", "\n", "ys", "=", "[", "]", "\n", "num_iters_per_epoch", "=", "log_dict", "[", "epochs", "[", "0", "]", "]", "[", "'iter'", "]", "[", "-", "1", "]", "\n", "for", "epoch", "in", "epochs", ":", "\n", "                ", "iters", "=", "log_dict", "[", "epoch", "]", "[", "'iter'", "]", "\n", "if", "log_dict", "[", "epoch", "]", "[", "'mode'", "]", "[", "-", "1", "]", "==", "'val'", ":", "\n", "                    ", "iters", "=", "iters", "[", ":", "-", "1", "]", "\n", "", "xs", ".", "append", "(", "np", ".", "array", "(", "iters", ")", "+", "(", "epoch", "-", "1", ")", "*", "num_iters_per_epoch", ")", "\n", "ys", ".", "append", "(", "np", ".", "array", "(", "log_dict", "[", "epoch", "]", "[", "metric", "]", "[", ":", "len", "(", "iters", ")", "]", ")", ")", "\n", "", "xs", "=", "np", ".", "concatenate", "(", "xs", ")", "\n", "ys", "=", "np", ".", "concatenate", "(", "ys", ")", "\n", "plt", ".", "xlabel", "(", "'iter'", ")", "\n", "plt", ".", "plot", "(", "xs", ",", "ys", ",", "label", "=", "legend", "[", "i", "*", "num_metrics", "+", "j", "]", ",", "linewidth", "=", "0.5", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "", "if", "args", ".", "title", "is", "not", "None", ":", "\n", "            ", "plt", ".", "title", "(", "args", ".", "title", ")", "\n", "", "", "if", "args", ".", "out", "is", "None", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f'save curve to: {args.out}'", ")", "\n", "plt", ".", "savefig", "(", "args", ".", "out", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.add_plot_parser": [[79, 105], ["subparsers.add_parser", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument"], "function", ["None"], ["", "", "def", "add_plot_parser", "(", "subparsers", ")", ":", "\n", "    ", "parser_plt", "=", "subparsers", ".", "add_parser", "(", "\n", "'plot_curve'", ",", "help", "=", "'parser for plotting curves'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'json_logs'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'path of train log in json format'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--keys'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "default", "=", "[", "'top1_acc'", "]", ",", "\n", "help", "=", "'the metric that you want to plot'", ")", "\n", "parser_plt", ".", "add_argument", "(", "'--title'", ",", "type", "=", "str", ",", "help", "=", "'title of figure'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--legend'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'legend of each plot'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--backend'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'backend of plt'", ")", "\n", "parser_plt", ".", "add_argument", "(", "\n", "'--style'", ",", "type", "=", "str", ",", "default", "=", "'dark'", ",", "help", "=", "'style of plt'", ")", "\n", "parser_plt", ".", "add_argument", "(", "'--out'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.add_time_parser": [[107, 120], ["subparsers.add_parser", "subparsers.add_parser.add_argument", "subparsers.add_parser.add_argument"], "function", ["None"], ["", "def", "add_time_parser", "(", "subparsers", ")", ":", "\n", "    ", "parser_time", "=", "subparsers", ".", "add_parser", "(", "\n", "'cal_train_time'", ",", "\n", "help", "=", "'parser for computing the average time per training iteration'", ")", "\n", "parser_time", ".", "add_argument", "(", "\n", "'json_logs'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'path of train log in json format'", ")", "\n", "parser_time", ".", "add_argument", "(", "\n", "'--include-outliers'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'include the first value of every epoch when computing '", "\n", "'the average time'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.parse_args": [[123, 131], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_subparsers", "analyze_logs.add_plot_parser", "analyze_logs.add_time_parser", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.add_plot_parser", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.add_time_parser", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Analyze Json Log'", ")", "\n", "# currently only support plot curve and calculate average train time", "\n", "subparsers", "=", "parser", ".", "add_subparsers", "(", "dest", "=", "'task'", ",", "help", "=", "'task parser'", ")", "\n", "add_plot_parser", "(", "subparsers", ")", "\n", "add_time_parser", "(", "subparsers", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.load_json_logs": [[133, 151], ["zip", "dict", "open", "json.loads", "json.loads.pop", "json.loads.items", "line.strip", "collections.defaultdict", "[].append"], "function", ["None"], ["", "def", "load_json_logs", "(", "json_logs", ")", ":", "\n", "# load and convert json_logs to log_dict, key is epoch, value is a sub dict", "\n", "# keys of sub dict is different metrics, e.g. memory, top1_acc", "\n", "# value of sub dict is a list of corresponding values of all iterations", "\n", "    ", "log_dicts", "=", "[", "dict", "(", ")", "for", "_", "in", "json_logs", "]", "\n", "for", "json_log", ",", "log_dict", "in", "zip", "(", "json_logs", ",", "log_dicts", ")", ":", "\n", "        ", "with", "open", "(", "json_log", ",", "'r'", ")", "as", "log_file", ":", "\n", "            ", "for", "line", "in", "log_file", ":", "\n", "                ", "log", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "# skip lines without `epoch` field", "\n", "if", "'epoch'", "not", "in", "log", ":", "\n", "                    ", "continue", "\n", "", "epoch", "=", "log", ".", "pop", "(", "'epoch'", ")", "\n", "if", "epoch", "not", "in", "log_dict", ":", "\n", "                    ", "log_dict", "[", "epoch", "]", "=", "defaultdict", "(", "list", ")", "\n", "", "for", "k", ",", "v", "in", "log", ".", "items", "(", ")", ":", "\n", "                    ", "log_dict", "[", "epoch", "]", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "", "", "", "", "return", "log_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.main": [[153, 163], ["analyze_logs.parse_args", "analyze_logs.load_json_logs", "json_log.endswith", "eval"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.analyze_logs.load_json_logs"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "json_logs", "=", "args", ".", "json_logs", "\n", "for", "json_log", "in", "json_logs", ":", "\n", "        ", "assert", "json_log", ".", "endswith", "(", "'.json'", ")", "\n", "\n", "", "log_dicts", "=", "load_json_logs", "(", "json_logs", ")", "\n", "\n", "eval", "(", "args", ".", "task", ")", "(", "log_dicts", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.report_accuracy.parse_args": [[10, 30], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Fusing multiple scores'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--scores'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'list of scores'", ",", "\n", "default", "=", "[", "'demo/fuse/rgb.pkl'", ",", "'demo/fuse/flow.pkl'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--coefficients'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "'coefficients of each score file'", ",", "\n", "default", "=", "[", "1.0", ",", "1.0", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--datalist'", ",", "\n", "help", "=", "'list of testing data'", ",", "\n", "default", "=", "'demo/fuse/data_list.txt'", ")", "\n", "parser", ".", "add_argument", "(", "'--apply-softmax'", ",", "action", "=", "'store_true'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.report_accuracy.main": [[32, 53], ["report_accuracy.parse_args", "mmaction.core.evaluation.get_weighted_score", "open().readlines", "mmaction.core.evaluation.mean_class_accuracy", "mmaction.core.evaluation.top_k_accuracy", "print", "print", "print", "len", "len", "mmcv.load", "int", "report_accuracy.main.apply_softmax"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.get_weighted_score", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "assert", "len", "(", "args", ".", "scores", ")", "==", "len", "(", "args", ".", "coefficients", ")", "\n", "score_list", "=", "args", ".", "scores", "\n", "score_list", "=", "[", "load", "(", "f", ")", "for", "f", "in", "score_list", "]", "\n", "if", "args", ".", "apply_softmax", ":", "\n", "\n", "        ", "def", "apply_softmax", "(", "scores", ")", ":", "\n", "            ", "return", "[", "softmax", "(", "score", ")", "for", "score", "in", "scores", "]", "\n", "\n", "", "score_list", "=", "[", "apply_softmax", "(", "scores", ")", "for", "scores", "in", "score_list", "]", "\n", "\n", "", "weighted_scores", "=", "get_weighted_score", "(", "score_list", ",", "args", ".", "coefficients", ")", "\n", "data", "=", "open", "(", "args", ".", "datalist", ")", ".", "readlines", "(", ")", "\n", "labels", "=", "[", "int", "(", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "-", "1", "]", ")", "for", "x", "in", "data", "]", "\n", "\n", "mean_class_acc", "=", "mean_class_accuracy", "(", "weighted_scores", ",", "labels", ")", "\n", "top_1_acc", ",", "top_5_acc", "=", "top_k_accuracy", "(", "weighted_scores", ",", "labels", ",", "(", "1", ",", "5", ")", ")", "\n", "print", "(", "f'Mean Class Accuracy: {mean_class_acc:.04f}'", ")", "\n", "print", "(", "f'Top 1 Accuracy: {top_1_acc:.04f}'", ")", "\n", "print", "(", "f'Top 5 Accuracy: {top_5_acc:.04f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.benchmark.parse_args": [[14, 27], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'MMAction2 benchmark a recognizer'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--log-interval'", ",", "default", "=", "10", ",", "help", "=", "'interval of logging'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.benchmark.main": [[29, 89], ["benchmark.parse_args", "mmcv.Config.fromfile", "Config.fromfile.get", "mmaction.datasets.build_dataset", "mmaction.datasets.build_dataloader", "mmaction.models.build_model", "Config.fromfile.get", "mmcv.parallel.MMDataParallel", "mmcv.cnn.fuse_conv_bn.eval", "enumerate", "dict", "mmcv.runner.fp16_utils.wrap_fp16_model", "mmcv.cnn.fuse_conv_bn", "torch.cuda.synchronize", "time.perf_counter", "torch.cuda.synchronize", "Config.fromfile.get", "torch.no_grad", "mmcv.cnn.fuse_conv_bn.", "time.perf_counter", "print", "print"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "# set cudnn_benchmark", "\n", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "cfg", ".", "model", ".", "backbone", ".", "pretrained", "=", "None", "\n", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "# build the dataloader", "\n", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ",", "dict", "(", "test_mode", "=", "True", ")", ")", "\n", "data_loader", "=", "build_dataloader", "(", "\n", "dataset", ",", "\n", "videos_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "False", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "None", ",", "test_cfg", "=", "cfg", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# the first several iterations may be very slow so skip them", "\n", "num_warmup", "=", "5", "\n", "pure_inf_time", "=", "0", "\n", "\n", "# benchmark with 2000 video and take the average", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model", "(", "return_loss", "=", "False", ",", "**", "data", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "elapsed", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "\n", "if", "i", ">=", "num_warmup", ":", "\n", "            ", "pure_inf_time", "+=", "elapsed", "\n", "if", "(", "i", "+", "1", ")", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "                ", "fps", "=", "(", "i", "+", "1", "-", "num_warmup", ")", "/", "pure_inf_time", "\n", "print", "(", "\n", "f'Done video [{i + 1:<3}/ 2000], fps: {fps:.1f} video / s'", ")", "\n", "\n", "", "", "if", "(", "i", "+", "1", ")", "==", "200", ":", "\n", "            ", "pure_inf_time", "+=", "elapsed", "\n", "fps", "=", "(", "i", "+", "1", "-", "num_warmup", ")", "/", "pure_inf_time", "\n", "print", "(", "f'Overall fps: {fps:.1f} video / s'", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.eval_metric.parse_args": [[9, 36], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluate metric of the '", "\n", "'results saved in pkl/yaml/json format'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'Config of the model'", ")", "\n", "parser", ".", "add_argument", "(", "'results'", ",", "help", "=", "'Results in pkl/yaml/json format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval'", ",", "\n", "type", "=", "str", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'evaluation metrics, which depends on the dataset, e.g.,'", "\n", "' \"top_k_accuracy\", \"mean_class_accuracy\" for video dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--eval-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.eval_metric.main": [[38, 62], ["eval_metric.parse_args", "mmcv.Config.fromfile", "mmaction.datasets.build_dataset", "mmcv.load", "Config.fromfile.get().copy", "cfg.get().copy.update", "print", "Config.fromfile.merge_from_dict", "cfg.get().copy.pop", "dict", "mmaction.datasets.build_dataset.evaluate", "Config.fromfile.get"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "assert", "args", ".", "eval", "is", "not", "None", "\n", "\n", "if", "args", ".", "cfg_options", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "\n", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ")", "\n", "outputs", "=", "mmcv", ".", "load", "(", "args", ".", "results", ")", "\n", "\n", "kwargs", "=", "{", "}", "if", "args", ".", "eval_options", "is", "None", "else", "args", ".", "eval_options", "\n", "eval_kwargs", "=", "cfg", ".", "get", "(", "'evaluation'", ",", "{", "}", ")", ".", "copy", "(", ")", "\n", "# hard-code way to remove EvalHook args", "\n", "for", "key", "in", "[", "\n", "'interval'", ",", "'tmpdir'", ",", "'start'", ",", "'gpu_collect'", ",", "'save_best'", ",", "'rule'", ",", "\n", "'by_epoch'", "\n", "]", ":", "\n", "        ", "eval_kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "", "eval_kwargs", ".", "update", "(", "dict", "(", "metrics", "=", "args", ".", "eval", ",", "**", "kwargs", ")", ")", "\n", "print", "(", "dataset", ".", "evaluate", "(", "outputs", ",", "**", "eval_kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.check_videos.RandomSampleFrames.__call__": [[71, 93], ["numpy.array", "numpy.concatenate", "numpy.random.randint"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Select frames to verify.\n\n        Select the first, last and three random frames, Required key is\n        \"total_frames\", added or modified key is \"frame_inds\".\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "assert", "results", "[", "'total_frames'", "]", ">", "0", "\n", "\n", "# first and last frames", "\n", "results", "[", "'frame_inds'", "]", "=", "np", ".", "array", "(", "[", "0", ",", "results", "[", "'total_frames'", "]", "-", "1", "]", ")", "\n", "\n", "# choose 3 random frames", "\n", "if", "results", "[", "'total_frames'", "]", ">", "2", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "concatenate", "(", "[", "\n", "results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "random", ".", "randint", "(", "1", ",", "results", "[", "'total_frames'", "]", "-", "1", ",", "3", ")", "\n", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.check_videos.parse_args": [[14, 66], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "ValueError", "warnings.warn", "multiprocessing.cpu_count"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'MMAction2 check datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'custom options for evaluation, the key-value pair in xxx=yyy '", "\n", "'format will be kwargs for dataset.evaluate() function (deprecate), '", "\n", "'change to --eval-options instead.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output-file'", ",", "\n", "default", "=", "'invalid-video.txt'", ",", "\n", "help", "=", "'Output file path which keeps corrupted/missing video file paths'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--split'", ",", "\n", "default", "=", "'train'", ",", "\n", "choices", "=", "[", "'train'", ",", "'val'", ",", "'test'", "]", ",", "\n", "help", "=", "'Dataset split'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--decoder'", ",", "\n", "default", "=", "'decord'", ",", "\n", "choices", "=", "[", "'decord'", ",", "'opencv'", ",", "'pyav'", "]", ",", "\n", "help", "=", "'Video decoder type, should be one of [decord, opencv, pyav]'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num-processes'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "(", "cpu_count", "(", ")", "-", "1", "or", "1", ")", ",", "\n", "help", "=", "'Number of processes to check videos'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--remove-corrupted-videos'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to delete all corrupted videos'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "options", "and", "args", ".", "eval_options", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'--options and --eval-options cannot be both '", "\n", "'specified, --options is deprecated in favor of --eval-options'", ")", "\n", "", "if", "args", ".", "options", ":", "\n", "        ", "warnings", ".", "warn", "(", "'--options is deprecated in favor of --eval-options'", ")", "\n", "args", ".", "eval_options", "=", "args", ".", "options", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.check_videos._do_check_videos": [[95, 104], ["lock.acquire", "lock.release", "open", "f.write"], "function", ["None"], ["", "", "def", "_do_check_videos", "(", "lock", ",", "dataset", ",", "output_file", ",", "idx", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "dataset", "[", "idx", "]", "\n", "", "except", ":", "# noqa", "\n", "# save invalid video path to output file", "\n", "        ", "lock", ".", "acquire", "(", ")", "\n", "with", "open", "(", "output_file", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "dataset", ".", "video_infos", "[", "idx", "]", "[", "'filename'", "]", "+", "'\\n'", ")", "\n", "", "lock", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.report_map.cuhk17_top1": [[13, 39], ["mmcv.load", "results.items", "mmcv.dump", "os.exists", "os.system", "os.system", "mmcv.load", "preds.sort", "report_map.cuhk17_top1.get_topk"], "function", ["None"], ["def", "cuhk17_top1", "(", ")", ":", "\n", "    ", "\"\"\"Assign label for each proposal with the cuhk17 result, which is the #2\n    entry in http://activity-net.org/challenges/2017/evaluation.html.\"\"\"", "\n", "if", "not", "osp", ".", "exists", "(", "'cuhk_anet17_pred.json'", ")", ":", "\n", "        ", "os", ".", "system", "(", "'wget https://download.openmmlab.com/'", "\n", "'mmaction/localization/cuhk_anet17_pred.json'", ")", "\n", "", "proposal", "=", "mmcv", ".", "load", "(", "args", ".", "proposal", ")", "\n", "results", "=", "proposal", "[", "'results'", "]", "\n", "cuhk_pred", "=", "mmcv", ".", "load", "(", "'cuhk_anet17_pred.json'", ")", "[", "'results'", "]", "\n", "\n", "def", "get_topk", "(", "preds", ",", "k", ")", ":", "\n", "        ", "preds", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ")", "\n", "return", "preds", "[", "-", "k", ":", "]", "\n", "\n", "", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "        ", "action_pred", "=", "cuhk_pred", "[", "k", "]", "\n", "top1", "=", "get_topk", "(", "action_pred", ",", "1", ")", "\n", "top1_label", "=", "top1", "[", "0", "]", "[", "'label'", "]", "\n", "new_value", "=", "[", "]", "\n", "for", "item", "in", "v", ":", "\n", "            ", "x", "=", "dict", "(", "label", "=", "top1_label", ")", "\n", "x", ".", "update", "(", "item", ")", "\n", "new_value", ".", "append", "(", "x", ")", "\n", "", "results", "[", "k", "]", "=", "new_value", "\n", "", "proposal", "[", "'results'", "]", "=", "results", "\n", "mmcv", ".", "dump", "(", "proposal", ",", "args", ".", "det_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.report_map.parse_args": [[44, 68], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Report detection mAP for'", "\n", "'ActivityNet proposal file'", ")", "\n", "parser", ".", "add_argument", "(", "'--proposal'", ",", "type", "=", "str", ",", "help", "=", "'proposal file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gt'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'data/ActivityNet/'", "\n", "'anet_anno_val.json'", ",", "\n", "help", "=", "'groundtruth file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cls'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'cuhk17_top1'", ",", "\n", "choices", "=", "[", "'cuhk17_top1'", "]", ",", "\n", "help", "=", "'the way to assign label for each '", "\n", "'proposal'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--det-output'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'det_result.json'", ",", "\n", "help", "=", "'the path to store detection results'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.analysis.report_map.main": [[70, 82], ["report_map.parse_args", "func", "mmaction.core.ActivityNetLocalization", "mmaction.core.ActivityNetLocalization.evaluate", "print", "numpy.linspace"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "args", ",", "cls_funcs", "\n", "args", "=", "parse_args", "(", ")", "\n", "func", "=", "cls_funcs", "[", "args", ".", "cls", "]", "\n", "func", "(", ")", "\n", "anet_detection", "=", "ActivityNetLocalization", "(", "\n", "args", ".", "gt", ",", "\n", "args", ".", "det_output", ",", "\n", "tiou_thresholds", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "10", ")", ",", "\n", "verbose", "=", "True", ")", "\n", "mAP", ",", "average_mAP", "=", "anet_detection", ".", "evaluate", "(", ")", "\n", "print", "(", "'[RESULTS] Performance on ActivityNet detection task.\\n'", "\n", "f'mAP: {mAP}\\nAverage-mAP: {average_mAP}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.extract_audio.extract_audio_wav": [[10, 25], ["os.splitext", "os.dirname", "os.relpath", "os.join", "os.popen", "os.popen", "os.basename", "os.exists", "os.popen", "os.popen", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "extract_audio_wav", "(", "line", ")", ":", "\n", "    ", "\"\"\"Extract the audio wave from video streams using FFMPEG.\"\"\"", "\n", "video_id", ",", "_", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "line", ")", ")", "\n", "video_dir", "=", "osp", ".", "dirname", "(", "line", ")", "\n", "video_rel_dir", "=", "osp", ".", "relpath", "(", "video_dir", ",", "args", ".", "root", ")", "\n", "dst_dir", "=", "osp", ".", "join", "(", "args", ".", "dst_root", ",", "video_rel_dir", ")", "\n", "os", ".", "popen", "(", "f'mkdir -p {dst_dir}'", ")", "\n", "try", ":", "\n", "        ", "if", "osp", ".", "exists", "(", "f'{dst_dir}/{video_id}.wav'", ")", ":", "\n", "            ", "return", "\n", "", "cmd", "=", "f'ffmpeg -i ./{line}  -map 0:a  -y {dst_dir}/{video_id}.wav'", "\n", "os", ".", "popen", "(", "cmd", ")", "\n", "", "except", "BaseException", ":", "\n", "        ", "with", "open", "(", "'extract_wav_err_file.txt'", ",", "'a+'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f'{line}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.extract_audio.parse_args": [[27, 44], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extract audios'", ")", "\n", "parser", ".", "add_argument", "(", "'root'", ",", "type", "=", "str", ",", "help", "=", "'source video directory'", ")", "\n", "parser", ".", "add_argument", "(", "'dst_root'", ",", "type", "=", "str", ",", "help", "=", "'output audio directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--level'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'directory level of data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ext'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'mp4'", ",", "\n", "choices", "=", "[", "'avi'", ",", "'mp4'", ",", "'webm'", "]", ",", "\n", "help", "=", "'video file extensions'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num-worker'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'number of workers'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_videos.encode_video": [[9, 36], ["os.join", "os.join", "os.join", "os.system", "os.system", "print", "sys.stdout.flush"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "encode_video", "(", "frame_dir_item", ")", ":", "\n", "    ", "\"\"\"Encode frames to video using ffmpeg.\n\n    Args:\n        frame_dir_item (list): Rawframe item containing raw frame directory\n            full path, rawframe directory (short) path, rawframe directory id.\n\n    Returns:\n        bool: Whether synthesize video successfully.\n    \"\"\"", "\n", "full_path", ",", "frame_dir_path", ",", "frame_dir_id", "=", "frame_dir_item", "\n", "out_full_path", "=", "args", ".", "out_dir", "\n", "\n", "img_name_tmpl", "=", "args", ".", "filename_tmpl", "+", "'.'", "+", "args", ".", "in_format", "\n", "img_path", "=", "osp", ".", "join", "(", "full_path", ",", "img_name_tmpl", ")", "\n", "\n", "out_vid_name", "=", "frame_dir_path", "+", "'.'", "+", "args", ".", "ext", "\n", "out_vid_path", "=", "osp", ".", "join", "(", "out_full_path", ",", "out_vid_name", ")", "\n", "\n", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"ffmpeg -start_number {args.start_idx} -r {args.fps} -i '{img_path}' \"", "\n", "f\"-vcodec {args.vcodec} '{out_vid_path}'\"", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "print", "(", "f'{frame_dir_id} {frame_dir_path} done'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_videos.parse_args": [[38, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'synthesize videos'", ")", "\n", "parser", ".", "add_argument", "(", "'src_dir'", ",", "type", "=", "str", ",", "help", "=", "'source rawframe directory'", ")", "\n", "parser", ".", "add_argument", "(", "'out_dir'", ",", "type", "=", "str", ",", "help", "=", "'output video directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fps'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "'fps of videos to be synthesized'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--level'", ",", "\n", "type", "=", "int", ",", "\n", "choices", "=", "[", "1", ",", "2", "]", ",", "\n", "default", "=", "2", ",", "\n", "help", "=", "'directory level of data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num-worker'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "8", ",", "\n", "help", "=", "'number of workers to build videos'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--in-format'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'jpg'", ",", "\n", "choices", "=", "[", "'jpg'", ",", "'png'", "]", ",", "\n", "help", "=", "'input format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--start-idx'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'starting index of rawframes'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--filename-tmpl'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'img_%05d'", ",", "\n", "help", "=", "'filename template of rawframes'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vcodec'", ",", "type", "=", "str", ",", "default", "=", "'mpeg4'", ",", "help", "=", "'coding method of videos'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ext'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'mp4'", ",", "\n", "choices", "=", "[", "'mp4'", ",", "'avi'", "]", ",", "\n", "help", "=", "'video file extensions'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'number of GPU'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "'resume optical flow extraction instead of overwriting'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_file_list.parse_args": [[18, 86], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Build file list'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'dataset'", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\n", "'ucf101'", ",", "'kinetics400'", ",", "'kinetics600'", ",", "'kinetics700'", ",", "'thumos14'", ",", "\n", "'sthv1'", ",", "'sthv2'", ",", "'mit'", ",", "'mmit'", ",", "'activitynet'", ",", "'hmdb51'", ",", "'jester'", ",", "\n", "'diving48'", "\n", "]", ",", "\n", "help", "=", "'dataset to be built file list'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'src_folder'", ",", "type", "=", "str", ",", "help", "=", "'root directory for the frames or videos'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--rgb-prefix'", ",", "type", "=", "str", ",", "default", "=", "'img_'", ",", "help", "=", "'prefix of rgb frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--flow-x-prefix'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'flow_x_'", ",", "\n", "help", "=", "'prefix of flow x frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--flow-y-prefix'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'flow_y_'", ",", "\n", "help", "=", "'prefix of flow y frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num-split'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "3", ",", "\n", "help", "=", "'number of split to file list'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--subset'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'train'", ",", "\n", "choices", "=", "[", "'train'", ",", "'val'", ",", "'test'", "]", ",", "\n", "help", "=", "'subset to generate file list'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--level'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "\n", "choices", "=", "[", "1", ",", "2", "]", ",", "\n", "help", "=", "'directory level of data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--format'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'rawframes'", ",", "\n", "choices", "=", "[", "'rawframes'", ",", "'videos'", "]", ",", "\n", "help", "=", "'data format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--out-root-path'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'data/'", ",", "\n", "help", "=", "'root path for output'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output-format'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'txt'", ",", "\n", "choices", "=", "[", "'txt'", ",", "'json'", "]", ",", "\n", "help", "=", "'built file list format'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shuffle'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "'whether to shuffle the file list'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_file_list.build_file_list": [[88, 161], ["build_file_list.build_file_list.build_list"], "function", ["None"], ["", "def", "build_file_list", "(", "splits", ",", "frame_info", ",", "shuffle", "=", "False", ")", ":", "\n", "    ", "\"\"\"Build file list for a certain data split.\n\n    Args:\n        splits (tuple): Data split to generate file list.\n        frame_info (dict): Dict mapping from frames to path. e.g.,\n            'Skiing/v_Skiing_g18_c02': ('data/ucf101/rawframes/Skiing/v_Skiing_g18_c02', 0, 0).  # noqa: E501\n        shuffle (bool): Whether to shuffle the file list.\n\n    Returns:\n        tuple: RGB file list for training and testing, together with\n            Flow file list for training and testing.\n    \"\"\"", "\n", "\n", "def", "build_list", "(", "split", ")", ":", "\n", "        ", "\"\"\"Build RGB and Flow file list with a given split.\n\n        Args:\n            split (list): Split to be generate file list.\n\n        Returns:\n            tuple[list, list]: (rgb_list, flow_list), rgb_list is the\n                generated file list for rgb, flow_list is the generated\n                file list for flow.\n        \"\"\"", "\n", "rgb_list", ",", "flow_list", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "item", "in", "split", ":", "\n", "            ", "if", "item", "[", "0", "]", "not", "in", "frame_info", ":", "\n", "                ", "continue", "\n", "", "if", "frame_info", "[", "item", "[", "0", "]", "]", "[", "1", "]", ">", "0", ":", "\n", "# rawframes", "\n", "                ", "rgb_cnt", "=", "frame_info", "[", "item", "[", "0", "]", "]", "[", "1", "]", "\n", "flow_cnt", "=", "frame_info", "[", "item", "[", "0", "]", "]", "[", "2", "]", "\n", "if", "isinstance", "(", "item", "[", "1", "]", ",", "int", ")", ":", "\n", "                    ", "rgb_list", ".", "append", "(", "f'{item[0]} {rgb_cnt} {item[1]}\\n'", ")", "\n", "flow_list", ".", "append", "(", "f'{item[0]} {flow_cnt} {item[1]}\\n'", ")", "\n", "", "elif", "isinstance", "(", "item", "[", "1", "]", ",", "list", ")", ":", "\n", "# only for multi-label datasets like mmit", "\n", "                    ", "rgb_list", ".", "append", "(", "f'{item[0]} {rgb_cnt} '", "+", "\n", "' '", ".", "join", "(", "[", "str", "(", "digit", ")", "\n", "for", "digit", "in", "item", "[", "1", "]", "]", ")", "+", "'\\n'", ")", "\n", "rgb_list", ".", "append", "(", "f'{item[0]} {flow_cnt} '", "+", "\n", "' '", ".", "join", "(", "[", "str", "(", "digit", ")", "\n", "for", "digit", "in", "item", "[", "1", "]", "]", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'frame_info should be '", "+", "\n", "'[`video`(str), `label`(int)|`labels(list[int])`'", ")", "\n", "", "", "else", ":", "\n", "# videos", "\n", "                ", "if", "isinstance", "(", "item", "[", "1", "]", ",", "int", ")", ":", "\n", "                    ", "rgb_list", ".", "append", "(", "f'{frame_info[item[0]][0]} {item[1]}\\n'", ")", "\n", "flow_list", ".", "append", "(", "f'{frame_info[item[0]][0]} {item[1]}\\n'", ")", "\n", "", "elif", "isinstance", "(", "item", "[", "1", "]", ",", "list", ")", ":", "\n", "# only for multi-label datasets like mmit", "\n", "                    ", "rgb_list", ".", "append", "(", "f'{frame_info[item[0]][0]} '", "+", "\n", "' '", ".", "join", "(", "[", "str", "(", "digit", ")", "\n", "for", "digit", "in", "item", "[", "1", "]", "]", ")", "+", "'\\n'", ")", "\n", "flow_list", ".", "append", "(", "\n", "f'{frame_info[item[0]][0]} '", "+", "\n", "' '", ".", "join", "(", "[", "str", "(", "digit", ")", "for", "digit", "in", "item", "[", "1", "]", "]", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'frame_info should be '", "+", "\n", "'[`video`(str), `label`(int)|`labels(list[int])`'", ")", "\n", "", "", "", "if", "shuffle", ":", "\n", "            ", "random", ".", "shuffle", "(", "rgb_list", ")", "\n", "random", ".", "shuffle", "(", "flow_list", ")", "\n", "", "return", "rgb_list", ",", "flow_list", "\n", "\n", "", "train_rgb_list", ",", "train_flow_list", "=", "build_list", "(", "splits", "[", "0", "]", ")", "\n", "test_rgb_list", ",", "test_flow_list", "=", "build_list", "(", "splits", "[", "1", "]", ")", "\n", "return", "(", "train_rgb_list", ",", "test_rgb_list", ")", ",", "(", "train_flow_list", ",", "test_flow_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_file_list.main": [[163, 264], ["build_file_list.parse_args", "print", "mmcv.runner.set_random_seed", "tools.data.parse_file_list.parse_directory", "tools.data.parse_file_list.parse_ucf101_splits", "len", "len", "enumerate", "build_file_list.build_file_list", "NotImplementedError", "tools.data.parse_file_list.parse_sthv1_splits", "build_file_list.build_file_list", "glob.glob", "os.relpath", "tools.data.parse_file_list.parse_sthv2_splits", "open", "f.writelines", "tools.data.anno_txt2json.lines2dictlist", "filename.replace.replace", "os.join", "glob.glob", "ValueError", "tools.data.parse_file_list.parse_mit_splits", "open", "f.writelines", "open", "f.writelines", "tools.data.anno_txt2json.lines2dictlist", "tools.data.anno_txt2json.lines2dictlist", "train_name.replace.replace", "val_name.replace.replace", "ValueError", "os.join", "open", "json.dump", "os.join", "tools.data.parse_file_list.parse_mmit_splits", "os.join", "os.join", "open", "json.dump", "open", "json.dump", "os.join", "os.splitext", "tools.data.parse_file_list.parse_kinetics_splits", "os.join", "os.join", "tools.data.parse_file_list.parse_hmdb51_split", "tools.data.parse_file_list.parse_jester_splits", "tools.data.parse_file_list.parse_diving48_splits", "ValueError"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.generate_file_list.parse_directory", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_ucf101_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_file_list.build_file_list", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_sthv1_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_file_list.build_file_list", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_sthv2_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.anno_txt2json.lines2dictlist", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_mit_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.anno_txt2json.lines2dictlist", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.anno_txt2json.lines2dictlist", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_mmit_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_kinetics_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_hmdb51_split", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_jester_splits", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_diving48_splits"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "print", "(", "f'Set random seed to {args.seed}'", ")", "\n", "set_random_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "args", ".", "format", "==", "'rawframes'", ":", "\n", "        ", "frame_info", "=", "parse_directory", "(", "\n", "args", ".", "src_folder", ",", "\n", "rgb_prefix", "=", "args", ".", "rgb_prefix", ",", "\n", "flow_x_prefix", "=", "args", ".", "flow_x_prefix", ",", "\n", "flow_y_prefix", "=", "args", ".", "flow_y_prefix", ",", "\n", "level", "=", "args", ".", "level", ")", "\n", "", "elif", "args", ".", "format", "==", "'videos'", ":", "\n", "        ", "if", "args", ".", "level", "==", "1", ":", "\n", "# search for one-level directory", "\n", "            ", "video_list", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "args", ".", "src_folder", ",", "'*'", ")", ")", "\n", "", "elif", "args", ".", "level", "==", "2", ":", "\n", "# search for two-level directory", "\n", "            ", "video_list", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "args", ".", "src_folder", ",", "'*'", ",", "'*'", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'level must be 1 or 2, but got {args.level}'", ")", "\n", "", "frame_info", "=", "{", "}", "\n", "for", "video", "in", "video_list", ":", "\n", "            ", "video_path", "=", "osp", ".", "relpath", "(", "video", ",", "args", ".", "src_folder", ")", "\n", "# video_id: (video_relative_path, -1, -1)", "\n", "frame_info", "[", "osp", ".", "splitext", "(", "video_path", ")", "[", "0", "]", "]", "=", "(", "video_path", ",", "-", "1", ",", "-", "1", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'only rawframes and videos are supported'", ")", "\n", "\n", "", "if", "args", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "splits", "=", "parse_ucf101_splits", "(", "args", ".", "level", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'sthv1'", ":", "\n", "        ", "splits", "=", "parse_sthv1_splits", "(", "args", ".", "level", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'sthv2'", ":", "\n", "        ", "splits", "=", "parse_sthv2_splits", "(", "args", ".", "level", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'mit'", ":", "\n", "        ", "splits", "=", "parse_mit_splits", "(", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'mmit'", ":", "\n", "        ", "splits", "=", "parse_mmit_splits", "(", ")", "\n", "", "elif", "args", ".", "dataset", "in", "[", "'kinetics400'", ",", "'kinetics600'", ",", "'kinetics700'", "]", ":", "\n", "        ", "splits", "=", "parse_kinetics_splits", "(", "args", ".", "level", ",", "args", ".", "dataset", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "splits", "=", "parse_hmdb51_split", "(", "args", ".", "level", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'jester'", ":", "\n", "        ", "splits", "=", "parse_jester_splits", "(", "args", ".", "level", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'diving48'", ":", "\n", "        ", "splits", "=", "parse_diving48_splits", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Supported datasets are 'ucf101, sthv1, sthv2', 'jester', \"", "\n", "f\"'mmit', 'mit', 'kinetics400', 'kinetics600', 'kinetics700', but \"", "\n", "f'got {args.dataset}'", ")", "\n", "\n", "", "assert", "len", "(", "splits", ")", "==", "args", ".", "num_split", "\n", "\n", "out_path", "=", "args", ".", "out_root_path", "+", "args", ".", "dataset", "\n", "\n", "if", "len", "(", "splits", ")", ">", "1", ":", "\n", "        ", "for", "i", ",", "split", "in", "enumerate", "(", "splits", ")", ":", "\n", "            ", "file_lists", "=", "build_file_list", "(", "\n", "split", ",", "frame_info", ",", "shuffle", "=", "args", ".", "shuffle", ")", "\n", "train_name", "=", "f'{args.dataset}_train_split_{i+1}_{args.format}.txt'", "\n", "val_name", "=", "f'{args.dataset}_val_split_{i+1}_{args.format}.txt'", "\n", "if", "args", ".", "output_format", "==", "'txt'", ":", "\n", "                ", "with", "open", "(", "osp", ".", "join", "(", "out_path", ",", "train_name", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "writelines", "(", "file_lists", "[", "0", "]", "[", "0", "]", ")", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "out_path", ",", "val_name", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "writelines", "(", "file_lists", "[", "0", "]", "[", "1", "]", ")", "\n", "", "", "elif", "args", ".", "output_format", "==", "'json'", ":", "\n", "                ", "train_list", "=", "lines2dictlist", "(", "file_lists", "[", "0", "]", "[", "0", "]", ",", "args", ".", "format", ")", "\n", "val_list", "=", "lines2dictlist", "(", "file_lists", "[", "0", "]", "[", "1", "]", ",", "args", ".", "format", ")", "\n", "train_name", "=", "train_name", ".", "replace", "(", "'.txt'", ",", "'.json'", ")", "\n", "val_name", "=", "val_name", ".", "replace", "(", "'.txt'", ",", "'.json'", ")", "\n", "with", "open", "(", "osp", ".", "join", "(", "out_path", ",", "train_name", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "train_list", ",", "f", ")", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "out_path", ",", "val_name", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "val_list", ",", "f", ")", "\n", "", "", "", "", "else", ":", "\n", "        ", "lists", "=", "build_file_list", "(", "splits", "[", "0", "]", ",", "frame_info", ",", "shuffle", "=", "args", ".", "shuffle", ")", "\n", "\n", "if", "args", ".", "subset", "==", "'train'", ":", "\n", "            ", "ind", "=", "0", "\n", "", "elif", "args", ".", "subset", "==", "'val'", ":", "\n", "            ", "ind", "=", "1", "\n", "", "elif", "args", ".", "subset", "==", "'test'", ":", "\n", "            ", "ind", "=", "2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"subset must be in ['train', 'val', 'test'], \"", "\n", "f'but got {args.subset}.'", ")", "\n", "\n", "", "filename", "=", "f'{args.dataset}_{args.subset}_list_{args.format}.txt'", "\n", "if", "args", ".", "output_format", "==", "'txt'", ":", "\n", "            ", "with", "open", "(", "osp", ".", "join", "(", "out_path", ",", "filename", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "f", ".", "writelines", "(", "lists", "[", "0", "]", "[", "ind", "]", ")", "\n", "", "", "elif", "args", ".", "output_format", "==", "'json'", ":", "\n", "            ", "data_list", "=", "lines2dictlist", "(", "lists", "[", "0", "]", "[", "ind", "]", ",", "args", ".", "format", ")", "\n", "filename", "=", "filename", ".", "replace", "(", "'.txt'", ",", "'.json'", ")", "\n", "with", "open", "(", "osp", ".", "join", "(", "out_path", ",", "filename", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "data_list", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.resize_video.resize_videos": [[9, 47], ["os.join", "os.dirname", "os.join", "os.popen", "os.popen", "os.popen", "os.popen", "print", "sys.stdout.flush", "os.exists", "os.makedirs", "os.makedirs", "int", "os.popen.readline().rstrip().split", "os.popen.readline().rstrip", "os.popen.readline"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "resize_videos", "(", "vid_item", ")", ":", "\n", "    ", "\"\"\"Generate resized video cache.\n\n    Args:\n        vid_item (list): Video item containing video full path,\n            video relative path.\n\n    Returns:\n        bool: Whether generate video cache successfully.\n    \"\"\"", "\n", "full_path", ",", "vid_path", "=", "vid_item", "\n", "out_full_path", "=", "osp", ".", "join", "(", "args", ".", "out_dir", ",", "vid_path", ")", "\n", "dir_name", "=", "osp", ".", "dirname", "(", "vid_path", ")", "\n", "out_dir", "=", "osp", ".", "join", "(", "args", ".", "out_dir", ",", "dir_name", ")", "\n", "if", "not", "osp", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "result", "=", "os", ".", "popen", "(", "\n", "f'ffprobe -hide_banner -loglevel error -select_streams v:0 -show_entries stream=width,height -of csv=p=0 {full_path}'", "# noqa:E501", "\n", ")", "\n", "w", ",", "h", "=", "[", "int", "(", "d", ")", "for", "d", "in", "result", ".", "readline", "(", ")", ".", "rstrip", "(", ")", ".", "split", "(", "','", ")", "]", "\n", "if", "w", ">", "h", ":", "\n", "        ", "cmd", "=", "(", "f'ffmpeg -hide_banner -loglevel error -i {full_path} '", "\n", "f'-vf {\"mpdecimate,\" if args.remove_dup else \"\"}'", "\n", "f'scale=-2:{args.scale} '", "\n", "f'{\"-vsync vfr\" if args.remove_dup else \"\"} '", "\n", "f'-c:v libx264 {\"-g 16\" if args.dense else \"\"} '", "\n", "f'-an {out_full_path} -y'", ")", "\n", "", "else", ":", "\n", "        ", "cmd", "=", "(", "f'ffmpeg -hide_banner -loglevel error -i {full_path} '", "\n", "f'-vf {\"mpdecimate,\" if args.remove_dup else \"\"}'", "\n", "f'scale={args.scale}:-2 '", "\n", "f'{\"-vsync vfr\" if args.remove_dup else \"\"} '", "\n", "f'-c:v libx264 {\"-g 16\" if args.dense else \"\"} '", "\n", "f'-an {out_full_path} -y'", ")", "\n", "", "os", ".", "popen", "(", "cmd", ")", "\n", "print", "(", "f'{vid_path} done'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.resize_video.parse_args": [[49, 84], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Generate the resized cache of original videos'", ")", "\n", "parser", ".", "add_argument", "(", "'src_dir'", ",", "type", "=", "str", ",", "help", "=", "'source video directory'", ")", "\n", "parser", ".", "add_argument", "(", "'out_dir'", ",", "type", "=", "str", ",", "help", "=", "'output video directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dense'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to generate a faster cache'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--level'", ",", "\n", "type", "=", "int", ",", "\n", "choices", "=", "[", "1", ",", "2", "]", ",", "\n", "default", "=", "2", ",", "\n", "help", "=", "'directory level of data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--remove-dup'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to remove duplicated frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ext'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'mp4'", ",", "\n", "choices", "=", "[", "'avi'", ",", "'mp4'", ",", "'webm'", "]", ",", "\n", "help", "=", "'video file extensions'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--scale'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "256", ",", "\n", "help", "=", "'resize image short side length keeping ratio'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num-worker'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'number of workers'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.anno_txt2json.parse_args": [[6, 27], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Convert txt annotation list to json'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'annofile'", ",", "type", "=", "str", ",", "help", "=", "'the txt annotation file to convert'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--format'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'rawframes'", ",", "\n", "choices", "=", "[", "'rawframes'", ",", "'videos'", "]", ",", "\n", "help", "=", "'the format of the txt annotation file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "(", "\n", "'the output file name, use annofile.replace(\\'.txt\\', \\'.json\\') '", "\n", "'if the arg value is None'", ")", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.anno_txt2json.lines2dictlist": [[29, 92], ["x.split", "dict", "dict", "int", "int", "int"], "function", ["None"], ["", "def", "lines2dictlist", "(", "lines", ",", "format", ")", ":", "\n", "    ", "\"\"\"Convert lines in 'txt' format to dictionaries in 'json' format.\n    Currently support single-label and multi-label.\n\n    Example of a single-label rawframes annotation txt file:\n\n    .. code-block:: txt\n\n        (frame_dir num_frames label)\n        some/directory-1 163 1\n        some/directory-2 122 1\n        some/directory-3 258 2\n\n    Example of a multi-label rawframes annotation txt file:\n\n    .. code-block:: txt\n\n        (frame_dir num_frames label1 label2 ...)\n        some/directory-1 163 1 3 5\n        some/directory-2 122 1 2\n        some/directory-3 258 2\n\n    Example of a single-label videos annotation txt file:\n\n    .. code-block:: txt\n\n        (filename label)\n        some/path/000.mp4 1\n        some/path/001.mp4 1\n        some/path/002.mp4 2\n\n    Example of a multi-label videos annotation txt file:\n\n    .. code-block:: txt\n\n        (filename label1 label2 ...)\n        some/path/000.mp4 1 3 5\n        some/path/001.mp4 1 4 8\n        some/path/002.mp4 2 4 9\n\n    Args:\n        lines (list): List of lines in 'txt' label format.\n        format (str): Data format, choices are 'rawframes' and 'videos'.\n\n    Returns:\n        list[dict]: For rawframes format, each dict has keys: frame_dir,\n            total_frames, label; for videos format, each diction has keys:\n            filename, label.\n    \"\"\"", "\n", "lines", "=", "[", "x", ".", "split", "(", ")", "for", "x", "in", "lines", "]", "\n", "if", "format", "==", "'rawframes'", ":", "\n", "        ", "data", "=", "[", "\n", "dict", "(", "\n", "frame_dir", "=", "line", "[", "0", "]", ",", "\n", "total_frames", "=", "int", "(", "line", "[", "1", "]", ")", ",", "\n", "label", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line", "[", "2", ":", "]", "]", ")", "for", "line", "in", "lines", "\n", "]", "\n", "", "elif", "format", "==", "'videos'", ":", "\n", "        ", "data", "=", "[", "\n", "dict", "(", "filename", "=", "line", "[", "0", "]", ",", "label", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line", "[", "1", ":", "]", "]", ")", "\n", "for", "line", "in", "lines", "\n", "]", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_directory": [[9, 81], ["print", "enumerate", "print", "glob.glob", "os.listdir", "os.listdir", "parse_file_list.parse_directory.count_files"], "function", ["None"], ["def", "parse_directory", "(", "path", ",", "\n", "rgb_prefix", "=", "'img_'", ",", "\n", "flow_x_prefix", "=", "'flow_x_'", ",", "\n", "flow_y_prefix", "=", "'flow_y_'", ",", "\n", "level", "=", "1", ")", ":", "\n", "    ", "\"\"\"Parse directories holding extracted frames from standard benchmarks.\n\n    Args:\n        path (str): Directory path to parse frames.\n        rgb_prefix (str): Prefix of generated rgb frames name.\n            default: 'img_'.\n        flow_x_prefix (str): Prefix of generated flow x name.\n            default: `flow_x_`.\n        flow_y_prefix (str): Prefix of generated flow y name.\n            default: `flow_y_`.\n        level (int): Directory level for glob searching. Options are 1 and 2.\n            default: 1.\n\n    Returns:\n        dict: frame info dict with video id as key and tuple(path(str),\n            rgb_num(int), flow_x_num(int)) as value.\n    \"\"\"", "\n", "print", "(", "f'parse frames under directory {path}'", ")", "\n", "if", "level", "==", "1", ":", "\n", "# Only search for one-level directory", "\n", "        ", "def", "locate_directory", "(", "x", ")", ":", "\n", "            ", "return", "osp", ".", "basename", "(", "x", ")", "\n", "\n", "", "frame_dirs", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "path", ",", "'*'", ")", ")", "\n", "\n", "", "elif", "level", "==", "2", ":", "\n", "# search for two-level directory", "\n", "        ", "def", "locate_directory", "(", "x", ")", ":", "\n", "            ", "return", "osp", ".", "join", "(", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "x", ")", ")", ",", "osp", ".", "basename", "(", "x", ")", ")", "\n", "\n", "", "frame_dirs", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "path", ",", "'*'", ",", "'*'", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'level can be only 1 or 2'", ")", "\n", "\n", "", "def", "count_files", "(", "directory", ",", "prefix_list", ")", ":", "\n", "        ", "\"\"\"Count file number with a given directory and prefix.\n\n        Args:\n            directory (str): Data directory to be search.\n            prefix_list (list): List or prefix.\n\n        Returns:\n            list (int): Number list of the file with the prefix.\n        \"\"\"", "\n", "lst", "=", "os", ".", "listdir", "(", "directory", ")", "\n", "cnt_list", "=", "[", "len", "(", "fnmatch", ".", "filter", "(", "lst", ",", "x", "+", "'*'", ")", ")", "for", "x", "in", "prefix_list", "]", "\n", "return", "cnt_list", "\n", "\n", "# check RGB", "\n", "", "frame_dict", "=", "{", "}", "\n", "for", "i", ",", "frame_dir", "in", "enumerate", "(", "frame_dirs", ")", ":", "\n", "        ", "total_num", "=", "count_files", "(", "frame_dir", ",", "\n", "(", "rgb_prefix", ",", "flow_x_prefix", ",", "flow_y_prefix", ")", ")", "\n", "dir_name", "=", "locate_directory", "(", "frame_dir", ")", "\n", "\n", "num_x", "=", "total_num", "[", "1", "]", "\n", "num_y", "=", "total_num", "[", "2", "]", "\n", "if", "num_x", "!=", "num_y", ":", "\n", "            ", "raise", "ValueError", "(", "f'x and y direction have different number '", "\n", "f'of flow images in video directory: {frame_dir}'", ")", "\n", "", "if", "i", "%", "200", "==", "0", ":", "\n", "            ", "print", "(", "f'{i} videos parsed'", ")", "\n", "", "frame_dict", "[", "dir_name", "]", "=", "(", "frame_dir", ",", "total_num", "[", "0", "]", ",", "num_x", ")", "\n", "\n", "", "print", "(", "'frame directory analysis done'", ")", "\n", "return", "frame_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_ucf101_splits": [[83, 132], ["range", "open", "line.strip().split", "splits.append", "x.strip().split", "int", "os.splitext", "os.basename", "open", "open", "line.strip", "os.join", "train_file_template.format", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "parse_ucf101_splits", "(", "level", ")", ":", "\n", "    ", "\"\"\"Parse UCF-101 dataset into \"train\", \"val\", \"test\" splits.\n\n    Args:\n        level (int): Directory level of data. 1 for the single-level directory,\n            2 for the two-level directory.\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of UCF-101.\n    \"\"\"", "\n", "class_index_file", "=", "'data/ucf101/annotations/classInd.txt'", "\n", "train_file_template", "=", "'data/ucf101/annotations/trainlist{:02d}.txt'", "\n", "test_file_template", "=", "'data/ucf101/annotations/testlist{:02d}.txt'", "\n", "\n", "with", "open", "(", "class_index_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "class_index", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "x", "in", "fin", "]", "\n", "", "class_mapping", "=", "{", "x", "[", "1", "]", ":", "int", "(", "x", "[", "0", "]", ")", "-", "1", "for", "x", "in", "class_index", "}", "\n", "\n", "def", "line_to_map", "(", "line", ")", ":", "\n", "        ", "\"\"\"A function to map line string to video and label.\n\n        Args:\n            line (str): A long directory path, which is a text path.\n\n        Returns:\n            tuple[str, str]: (video, label), video is the video id,\n                label is the video label.\n        \"\"\"", "\n", "items", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video", "=", "osp", ".", "splitext", "(", "items", "[", "0", "]", ")", "[", "0", "]", "\n", "if", "level", "==", "1", ":", "\n", "            ", "video", "=", "osp", ".", "basename", "(", "video", ")", "\n", "label", "=", "items", "[", "0", "]", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "video", "=", "osp", ".", "join", "(", "\n", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "video", ")", ")", ",", "osp", ".", "basename", "(", "video", ")", ")", "\n", "label", "=", "class_mapping", "[", "osp", ".", "dirname", "(", "items", "[", "0", "]", ")", "]", "\n", "", "return", "video", ",", "label", "\n", "\n", "", "splits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "4", ")", ":", "\n", "        ", "with", "open", "(", "train_file_template", ".", "format", "(", "i", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "with", "open", "(", "test_file_template", ".", "format", "(", "i", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "test_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "", "splits", ".", "append", "(", "(", "train_list", ",", "test_list", ")", ")", "\n", "\n", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_jester_splits": [[134, 179], ["open", "line.strip().split", "open", "open", "open", "x.strip", "range", "os.basename", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["None"], ["", "def", "parse_jester_splits", "(", "level", ")", ":", "\n", "    ", "\"\"\"Parse Jester into \"train\", \"val\" splits.\n\n    Args:\n        level (int): Directory level of data. 1 for the single-level directory,\n            2 for the two-level directory.\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of Jester dataset.\n    \"\"\"", "\n", "# Read the annotations", "\n", "class_index_file", "=", "'data/jester/annotations/jester-v1-labels.csv'", "\n", "train_file", "=", "'data/jester/annotations/jester-v1-train.csv'", "\n", "val_file", "=", "'data/jester/annotations/jester-v1-validation.csv'", "\n", "test_file", "=", "'data/jester/annotations/jester-v1-test.csv'", "\n", "\n", "with", "open", "(", "class_index_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "class_index", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "fin", "]", "\n", "", "class_mapping", "=", "{", "class_index", "[", "idx", "]", ":", "idx", "for", "idx", "in", "range", "(", "len", "(", "class_index", ")", ")", "}", "\n", "\n", "def", "line_to_map", "(", "line", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "items", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "';'", ")", "\n", "video", "=", "items", "[", "0", "]", "\n", "if", "level", "==", "1", ":", "\n", "            ", "video", "=", "osp", ".", "basename", "(", "video", ")", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "video", "=", "osp", ".", "join", "(", "\n", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "video", ")", ")", ",", "osp", ".", "basename", "(", "video", ")", ")", "\n", "", "if", "test_mode", ":", "\n", "            ", "return", "video", "\n", "\n", "", "label", "=", "class_mapping", "[", "items", "[", "1", "]", "]", "\n", "return", "video", ",", "label", "\n", "\n", "", "with", "open", "(", "train_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "with", "open", "(", "val_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "val_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "with", "open", "(", "test_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "test_list", "=", "[", "line_to_map", "(", "x", ",", "test_mode", "=", "True", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "splits", "=", "(", "(", "train_list", ",", "val_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_sthv1_splits": [[181, 228], ["open", "line.strip().split", "open", "open", "open", "x.strip", "range", "os.basename", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["None"], ["", "def", "parse_sthv1_splits", "(", "level", ")", ":", "\n", "    ", "\"\"\"Parse Something-Something dataset V1 into \"train\", \"val\" splits.\n\n    Args:\n        level (int): Directory level of data. 1 for the single-level directory,\n            2 for the two-level directory.\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of Something-Something V1 dataset.\n    \"\"\"", "\n", "# Read the annotations", "\n", "# yapf: disable", "\n", "class_index_file", "=", "'data/sthv1/annotations/something-something-v1-labels.csv'", "# noqa", "\n", "# yapf: enable", "\n", "train_file", "=", "'data/sthv1/annotations/something-something-v1-train.csv'", "\n", "val_file", "=", "'data/sthv1/annotations/something-something-v1-validation.csv'", "\n", "test_file", "=", "'data/sthv1/annotations/something-something-v1-test.csv'", "\n", "\n", "with", "open", "(", "class_index_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "class_index", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "fin", "]", "\n", "", "class_mapping", "=", "{", "class_index", "[", "idx", "]", ":", "idx", "for", "idx", "in", "range", "(", "len", "(", "class_index", ")", ")", "}", "\n", "\n", "def", "line_to_map", "(", "line", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "items", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "';'", ")", "\n", "video", "=", "items", "[", "0", "]", "\n", "if", "level", "==", "1", ":", "\n", "            ", "video", "=", "osp", ".", "basename", "(", "video", ")", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "video", "=", "osp", ".", "join", "(", "\n", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "video", ")", ")", ",", "osp", ".", "basename", "(", "video", ")", ")", "\n", "", "if", "test_mode", ":", "\n", "            ", "return", "video", "\n", "\n", "", "label", "=", "class_mapping", "[", "items", "[", "1", "]", "]", "\n", "return", "video", ",", "label", "\n", "\n", "", "with", "open", "(", "train_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "with", "open", "(", "val_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "val_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "with", "open", "(", "test_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "test_list", "=", "[", "line_to_map", "(", "x", ",", "test_mode", "=", "True", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "splits", "=", "(", "(", "train_list", ",", "val_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_sthv2_splits": [[230, 280], ["open", "json.loads", "item[].replace", "template.replace.replace", "int", "open", "json.loads", "open", "json.loads", "open", "json.loads", "fin.read", "os.basename", "fin.read", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["None"], ["", "def", "parse_sthv2_splits", "(", "level", ")", ":", "\n", "    ", "\"\"\"Parse Something-Something dataset V2 into \"train\", \"val\" splits.\n\n    Args:\n        level (int): Directory level of data. 1 for the single-level directory,\n            2 for the two-level directory.\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of Something-Something V2 dataset.\n    \"\"\"", "\n", "# Read the annotations", "\n", "# yapf: disable", "\n", "class_index_file", "=", "'data/sthv2/annotations/something-something-v2-labels.json'", "# noqa", "\n", "# yapf: enable", "\n", "train_file", "=", "'data/sthv2/annotations/something-something-v2-train.json'", "\n", "val_file", "=", "'data/sthv2/annotations/something-something-v2-validation.json'", "\n", "test_file", "=", "'data/sthv2/annotations/something-something-v2-test.json'", "\n", "\n", "with", "open", "(", "class_index_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "class_mapping", "=", "json", ".", "loads", "(", "fin", ".", "read", "(", ")", ")", "\n", "\n", "", "def", "line_to_map", "(", "item", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "video", "=", "item", "[", "'id'", "]", "\n", "if", "level", "==", "1", ":", "\n", "            ", "video", "=", "osp", ".", "basename", "(", "video", ")", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "video", "=", "osp", ".", "join", "(", "\n", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "video", ")", ")", ",", "osp", ".", "basename", "(", "video", ")", ")", "\n", "", "if", "test_mode", ":", "\n", "            ", "return", "video", "\n", "\n", "", "template", "=", "item", "[", "'template'", "]", ".", "replace", "(", "'['", ",", "''", ")", "\n", "template", "=", "template", ".", "replace", "(", "']'", ",", "''", ")", "\n", "label", "=", "int", "(", "class_mapping", "[", "template", "]", ")", "\n", "return", "video", ",", "label", "\n", "\n", "", "with", "open", "(", "train_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "items", "=", "json", ".", "loads", "(", "fin", ".", "read", "(", ")", ")", "\n", "train_list", "=", "[", "line_to_map", "(", "item", ")", "for", "item", "in", "items", "]", "\n", "\n", "", "with", "open", "(", "val_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "items", "=", "json", ".", "loads", "(", "fin", ".", "read", "(", ")", ")", "\n", "val_list", "=", "[", "line_to_map", "(", "item", ")", "for", "item", "in", "items", "]", "\n", "\n", "", "with", "open", "(", "test_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "items", "=", "json", ".", "loads", "(", "fin", ".", "read", "(", ")", ")", "\n", "test_list", "=", "[", "line_to_map", "(", "item", ",", "test_mode", "=", "True", ")", "for", "item", "in", "items", "]", "\n", "\n", "", "splits", "=", "(", "(", "train_list", ",", "val_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_mmit_splits": [[282, 305], ["csv.reader", "csv.reader", "open", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["None"], ["", "def", "parse_mmit_splits", "(", ")", ":", "\n", "    ", "\"\"\"Parse Multi-Moments in Time dataset into \"train\", \"val\" splits.\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of Multi-Moments in Time.\n    \"\"\"", "\n", "\n", "# Read the annotations", "\n", "def", "line_to_map", "(", "x", ")", ":", "\n", "        ", "video", "=", "osp", ".", "splitext", "(", "x", "[", "0", "]", ")", "[", "0", "]", "\n", "labels", "=", "[", "int", "(", "digit", ")", "for", "digit", "in", "x", "[", "1", ":", "]", "]", "\n", "return", "video", ",", "labels", "\n", "\n", "", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "'data/mmit/annotations/trainingSet.csv'", ")", ")", "\n", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "'data/mmit/annotations/validationSet.csv'", ")", ")", "\n", "val_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "test_list", "=", "val_list", "# not test for mit", "\n", "\n", "splits", "=", "(", "(", "train_list", ",", "val_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_kinetics_splits": [[307, 388], ["csv.reader", "next", "sorted", "csv.reader", "next", "csv.reader", "next", "csv.reader", "next", "s.replace", "open", "open", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["None"], ["", "def", "parse_kinetics_splits", "(", "level", ",", "dataset", ")", ":", "\n", "    ", "\"\"\"Parse Kinetics dataset into \"train\", \"val\", \"test\" splits.\n\n    Args:\n        level (int): Directory level of data. 1 for the single-level directory,\n            2 for the two-level directory.\n        dataset (str): Denotes the version of Kinetics that needs to be parsed,\n            choices are \"kinetics400\", \"kinetics600\" and \"kinetics700\".\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of Kinetics.\n    \"\"\"", "\n", "\n", "def", "convert_label", "(", "s", ",", "keep_whitespaces", "=", "False", ")", ":", "\n", "        ", "\"\"\"Convert label name to a formal string.\n\n        Remove redundant '\"' and convert whitespace to '_'.\n\n        Args:\n            s (str): String to be converted.\n            keep_whitespaces(bool): Whether to keep whitespace. Default: False.\n\n        Returns:\n            str: Converted string.\n        \"\"\"", "\n", "if", "not", "keep_whitespaces", ":", "\n", "            ", "return", "s", ".", "replace", "(", "'\"'", ",", "''", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "\n", "", "return", "s", ".", "replace", "(", "'\"'", ",", "''", ")", "\n", "\n", "", "def", "line_to_map", "(", "x", ",", "test", "=", "False", ")", ":", "\n", "        ", "\"\"\"A function to map line string to video and label.\n\n        Args:\n            x (str): A single line from Kinetics csv file.\n            test (bool): Indicate whether the line comes from test\n                annotation file.\n\n        Returns:\n            tuple[str, str]: (video, label), video is the video id,\n                label is the video label.\n        \"\"\"", "\n", "if", "test", ":", "\n", "# video = f'{x[0]}_{int(x[1]):06d}_{int(x[2]):06d}'", "\n", "            ", "video", "=", "f'{x[1]}_{int(float(x[2])):06d}_{int(float(x[3])):06d}'", "\n", "label", "=", "-", "1", "# label unknown", "\n", "return", "video", ",", "label", "\n", "\n", "", "video", "=", "f'{x[1]}_{int(float(x[2])):06d}_{int(float(x[3])):06d}'", "\n", "if", "level", "==", "2", ":", "\n", "            ", "video", "=", "f'{convert_label(x[0])}/{video}'", "\n", "", "else", ":", "\n", "            ", "assert", "level", "==", "1", "\n", "", "label", "=", "class_mapping", "[", "convert_label", "(", "x", "[", "0", "]", ")", "]", "\n", "return", "video", ",", "label", "\n", "\n", "", "train_file", "=", "f'data/{dataset}/annotations/kinetics_train.csv'", "\n", "val_file", "=", "f'data/{dataset}/annotations/kinetics_val.csv'", "\n", "test_file", "=", "f'data/{dataset}/annotations/kinetics_test.csv'", "\n", "\n", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "train_file", ")", ")", "\n", "# skip the first line", "\n", "next", "(", "csv_reader", ")", "\n", "\n", "labels_sorted", "=", "sorted", "(", "{", "convert_label", "(", "row", "[", "0", "]", ")", "for", "row", "in", "csv_reader", "}", ")", "\n", "class_mapping", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "labels_sorted", ")", "}", "\n", "\n", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "train_file", ")", ")", "\n", "next", "(", "csv_reader", ")", "\n", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "val_file", ")", ")", "\n", "next", "(", "csv_reader", ")", "\n", "val_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "test_file", ")", ")", "\n", "next", "(", "csv_reader", ")", "\n", "test_list", "=", "[", "line_to_map", "(", "x", ",", "test", "=", "True", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "splits", "=", "(", "(", "train_list", ",", "val_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_mit_splits": [[390, 418], ["csv.reader", "csv.reader", "open", "f_cat.readlines", "open", "parse_file_list.parse_ucf101_splits.line_to_map"], "function", ["None"], ["", "def", "parse_mit_splits", "(", ")", ":", "\n", "    ", "\"\"\"Parse Moments in Time dataset into \"train\", \"val\" splits.\n\n    Returns:\n        list: \"train\", \"val\", \"test\" splits of Moments in Time.\n    \"\"\"", "\n", "# Read the annotations", "\n", "class_mapping", "=", "{", "}", "\n", "with", "open", "(", "'data/mit/annotations/moments_categories.txt'", ")", "as", "f_cat", ":", "\n", "        ", "for", "line", "in", "f_cat", ".", "readlines", "(", ")", ":", "\n", "            ", "cat", ",", "digit", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "','", ")", "\n", "class_mapping", "[", "cat", "]", "=", "int", "(", "digit", ")", "\n", "\n", "", "", "def", "line_to_map", "(", "x", ")", ":", "\n", "        ", "video", "=", "osp", ".", "splitext", "(", "x", "[", "0", "]", ")", "[", "0", "]", "\n", "label", "=", "class_mapping", "[", "osp", ".", "dirname", "(", "x", "[", "0", "]", ")", "]", "\n", "return", "video", ",", "label", "\n", "\n", "", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "'data/mit/annotations/trainingSet.csv'", ")", ")", "\n", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "csv_reader", "=", "csv", ".", "reader", "(", "open", "(", "'data/mit/annotations/validationSet.csv'", ")", ")", "\n", "val_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "csv_reader", "]", "\n", "\n", "test_list", "=", "val_list", "# no test for mit", "\n", "\n", "splits", "=", "(", "(", "train_list", ",", "val_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_hmdb51_split": [[420, 507], ["parse_file_list.parse_hmdb51_split.generate_class_index_file"], "function", ["None"], ["", "def", "parse_hmdb51_split", "(", "level", ")", ":", "\n", "    ", "train_file_template", "=", "'data/hmdb51/annotations/trainlist{:02d}.txt'", "\n", "test_file_template", "=", "'data/hmdb51/annotations/testlist{:02d}.txt'", "\n", "class_index_file", "=", "'data/hmdb51/annotations/classInd.txt'", "\n", "\n", "def", "generate_class_index_file", "(", ")", ":", "\n", "        ", "\"\"\"This function will generate a `ClassInd.txt` for HMDB51 in a format\n        like UCF101, where class id starts with 1.\"\"\"", "\n", "frame_path", "=", "'data/hmdb51/rawframes'", "\n", "annotation_dir", "=", "'data/hmdb51/annotations'", "\n", "\n", "class_list", "=", "sorted", "(", "os", ".", "listdir", "(", "frame_path", ")", ")", "\n", "class_dict", "=", "dict", "(", ")", "\n", "if", "not", "osp", ".", "exists", "(", "class_index_file", ")", ":", "\n", "            ", "with", "open", "(", "class_index_file", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "content", "=", "[", "]", "\n", "for", "class_id", ",", "class_name", "in", "enumerate", "(", "class_list", ")", ":", "\n", "# like `ClassInd.txt` in UCF-101,", "\n", "# the class_id begins with 1", "\n", "                    ", "class_dict", "[", "class_name", "]", "=", "class_id", "+", "1", "\n", "cur_line", "=", "' '", ".", "join", "(", "[", "str", "(", "class_id", "+", "1", ")", ",", "class_name", "]", ")", "\n", "content", ".", "append", "(", "cur_line", ")", "\n", "", "content", "=", "'\\n'", ".", "join", "(", "content", ")", "\n", "f", ".", "write", "(", "content", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "f'{class_index_file} has been generated before.'", ")", "\n", "class_dict", "=", "{", "\n", "class_name", ":", "class_id", "+", "1", "\n", "for", "class_id", ",", "class_name", "in", "enumerate", "(", "class_list", ")", "\n", "}", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "4", ")", ":", "\n", "            ", "train_content", "=", "[", "]", "\n", "test_content", "=", "[", "]", "\n", "for", "class_name", "in", "class_dict", ":", "\n", "                ", "filename", "=", "class_name", "+", "f'_test_split{i}.txt'", "\n", "filename_path", "=", "osp", ".", "join", "(", "annotation_dir", ",", "filename", ")", "\n", "with", "open", "(", "filename_path", ",", "'r'", ")", "as", "fin", ":", "\n", "                    ", "for", "line", "in", "fin", ":", "\n", "                        ", "video_info", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video_name", "=", "video_info", "[", "0", "]", "\n", "if", "video_info", "[", "1", "]", "==", "'1'", ":", "\n", "                            ", "target_line", "=", "' '", ".", "join", "(", "[", "\n", "osp", ".", "join", "(", "class_name", ",", "video_name", ")", ",", "\n", "str", "(", "class_dict", "[", "class_name", "]", ")", "\n", "]", ")", "\n", "train_content", ".", "append", "(", "target_line", ")", "\n", "", "elif", "video_info", "[", "1", "]", "==", "'2'", ":", "\n", "                            ", "target_line", "=", "' '", ".", "join", "(", "[", "\n", "osp", ".", "join", "(", "class_name", ",", "video_name", ")", ",", "\n", "str", "(", "class_dict", "[", "class_name", "]", ")", "\n", "]", ")", "\n", "test_content", ".", "append", "(", "target_line", ")", "\n", "", "", "", "", "train_content", "=", "'\\n'", ".", "join", "(", "train_content", ")", "\n", "test_content", "=", "'\\n'", ".", "join", "(", "test_content", ")", "\n", "with", "open", "(", "train_file_template", ".", "format", "(", "i", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "fout", ".", "write", "(", "train_content", ")", "\n", "", "with", "open", "(", "test_file_template", ".", "format", "(", "i", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "fout", ".", "write", "(", "test_content", ")", "\n", "\n", "", "", "", "generate_class_index_file", "(", ")", "\n", "\n", "with", "open", "(", "class_index_file", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "class_index", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "x", "in", "fin", "]", "\n", "", "class_mapping", "=", "{", "x", "[", "1", "]", ":", "int", "(", "x", "[", "0", "]", ")", "-", "1", "for", "x", "in", "class_index", "}", "\n", "\n", "def", "line_to_map", "(", "line", ")", ":", "\n", "        ", "items", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video", "=", "osp", ".", "splitext", "(", "items", "[", "0", "]", ")", "[", "0", "]", "\n", "if", "level", "==", "1", ":", "\n", "            ", "video", "=", "osp", ".", "basename", "(", "video", ")", "\n", "", "elif", "level", "==", "2", ":", "\n", "            ", "video", "=", "osp", ".", "join", "(", "\n", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "video", ")", ")", ",", "osp", ".", "basename", "(", "video", ")", ")", "\n", "", "label", "=", "class_mapping", "[", "osp", ".", "dirname", "(", "items", "[", "0", "]", ")", "]", "\n", "return", "video", ",", "label", "\n", "\n", "", "splits", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "4", ")", ":", "\n", "        ", "with", "open", "(", "train_file_template", ".", "format", "(", "i", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "train_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "\n", "", "with", "open", "(", "test_file_template", ".", "format", "(", "i", ")", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "test_list", "=", "[", "line_to_map", "(", "x", ")", "for", "x", "in", "fin", "]", "\n", "", "splits", ".", "append", "(", "(", "train_list", ",", "test_list", ")", ")", "\n", "\n", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.parse_file_list.parse_diving48_splits": [[509, 535], ["json.load", "json.load", "open", "open", "train_list.append", "test_list.append"], "function", ["None"], ["", "def", "parse_diving48_splits", "(", ")", ":", "\n", "\n", "    ", "train_file", "=", "'data/diving48/annotations/Diving48_V2_train.json'", "\n", "test_file", "=", "'data/diving48/annotations/Diving48_V2_test.json'", "\n", "\n", "train", "=", "json", ".", "load", "(", "open", "(", "train_file", ")", ")", "\n", "test", "=", "json", ".", "load", "(", "open", "(", "test_file", ")", ")", "\n", "\n", "# class_index_file = 'data/diving48/annotations/Diving48_vocab.json'", "\n", "# class_list = json.load(open(class_index_file))", "\n", "\n", "train_list", "=", "[", "]", "\n", "test_list", "=", "[", "]", "\n", "\n", "for", "item", "in", "train", ":", "\n", "        ", "vid_name", "=", "item", "[", "'vid_name'", "]", "\n", "label", "=", "item", "[", "'label'", "]", "\n", "train_list", ".", "append", "(", "(", "vid_name", ",", "label", ")", ")", "\n", "\n", "", "for", "item", "in", "test", ":", "\n", "        ", "vid_name", "=", "item", "[", "'vid_name'", "]", "\n", "label", "=", "item", "[", "'label'", "]", "\n", "test_list", ".", "append", "(", "(", "vid_name", ",", "label", ")", ")", "\n", "\n", "", "splits", "=", "(", "(", "train_list", ",", "test_list", ")", ",", ")", "\n", "return", "splits", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.__init__": [[47, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "frame_rate", "=", "30", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "num_mels", "=", "80", ",", "\n", "fft_size", "=", "1280", ",", "\n", "hop_size", "=", "320", ",", "\n", "spectrogram_type", "=", "'lws'", ")", ":", "\n", "        ", "self", ".", "frame_rate", "=", "frame_rate", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "silence_threshold", "=", "SILENCE_THRESHOLD", "\n", "self", ".", "num_mels", "=", "num_mels", "\n", "self", ".", "fmin", "=", "FMIN", "\n", "self", ".", "fmax", "=", "FMAX", "\n", "self", ".", "fft_size", "=", "fft_size", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "frame_shift_ms", "=", "FRAME_SHIFT_MS", "\n", "self", ".", "min_level_db", "=", "MIN_LEVEL_DB", "\n", "self", ".", "ref_level_db", "=", "REF_LEVEL_DB", "\n", "self", ".", "rescaling", "=", "RESCALING", "\n", "self", ".", "rescaling_max", "=", "RESCALING_MAX", "\n", "self", ".", "allow_clipping_in_normalization", "=", "ALLOW_CLIPPING_IN_NORMALIZATION", "\n", "self", ".", "log_scale_min", "=", "LOG_SCALE_MIN", "\n", "self", ".", "norm_audio", "=", "NORM_AUDIO", "\n", "self", ".", "spectrogram_type", "=", "spectrogram_type", "\n", "assert", "spectrogram_type", "in", "[", "'lws'", ",", "'librosa'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.load_wav": [[73, 76], ["librosa.core.load"], "methods", ["None"], ["", "def", "load_wav", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Load an audio file into numpy array.\"\"\"", "\n", "return", "librosa", ".", "core", ".", "load", "(", "path", ",", "sr", "=", "self", ".", "sample_rate", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.audio_normalize": [[77, 83], ["numpy.maximum", "numpy.sqrt", "numpy.mean"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "audio_normalize", "(", "samples", ",", "desired_rms", "=", "0.1", ",", "eps", "=", "1e-4", ")", ":", "\n", "        ", "\"\"\"RMS normalize the audio data.\"\"\"", "\n", "rms", "=", "np", ".", "maximum", "(", "eps", ",", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "samples", "**", "2", ")", ")", ")", "\n", "samples", "=", "samples", "*", "(", "desired_rms", "/", "rms", ")", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.generate_spectrogram_magphase": [[84, 110], ["librosa.core.stft", "librosa.core.magphase", "numpy.expand_dims", "numpy.expand_dims", "build_audio_features.AudioTools.get_hop_size", "numpy.angle"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.get_hop_size"], ["", "def", "generate_spectrogram_magphase", "(", "self", ",", "audio", ",", "with_phase", "=", "False", ")", ":", "\n", "        ", "\"\"\"Separate a complex-valued spectrogram D into its magnitude (S)\n\n            and phase (P) components, so that D = S * P.\n\n        Args:\n            audio (np.ndarray): The input audio signal.\n            with_phase (bool): Determines whether to output the\n                phase components. Default: False.\n\n        Returns:\n            np.ndarray: magnitude and phase component of the complex-valued\n                spectrogram.\n        \"\"\"", "\n", "spectro", "=", "librosa", ".", "core", ".", "stft", "(", "\n", "audio", ",", "\n", "hop_length", "=", "self", ".", "get_hop_size", "(", ")", ",", "\n", "n_fft", "=", "self", ".", "fft_size", ",", "\n", "center", "=", "True", ")", "\n", "spectro_mag", ",", "spectro_phase", "=", "librosa", ".", "core", ".", "magphase", "(", "spectro", ")", "\n", "spectro_mag", "=", "np", ".", "expand_dims", "(", "spectro_mag", ",", "axis", "=", "0", ")", "\n", "if", "with_phase", ":", "\n", "            ", "spectro_phase", "=", "np", ".", "expand_dims", "(", "np", ".", "angle", "(", "spectro_phase", ")", ",", "axis", "=", "0", ")", "\n", "return", "spectro_mag", ",", "spectro_phase", "\n", "\n", "", "return", "spectro_mag", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.save_wav": [[111, 116], ["scipy.io.wavfile.write", "max", "wav.astype", "numpy.max", "numpy.abs"], "methods", ["None"], ["", "def", "save_wav", "(", "self", ",", "wav", ",", "path", ")", ":", "\n", "        ", "\"\"\"Save the wav to disk.\"\"\"", "\n", "# 32767 = (2 ^ 15 - 1) maximum of int16", "\n", "wav", "*=", "32767", "/", "max", "(", "0.01", ",", "np", ".", "max", "(", "np", ".", "abs", "(", "wav", ")", ")", ")", "\n", "wavfile", ".", "write", "(", "path", ",", "self", ".", "sample_rate", ",", "wav", ".", "astype", "(", "np", ".", "int16", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.trim": [[117, 122], ["build_audio_features.AudioTools.start_and_end_indices"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.start_and_end_indices"], ["", "def", "trim", "(", "self", ",", "quantized", ")", ":", "\n", "        ", "\"\"\"Trim the audio wavfile.\"\"\"", "\n", "start", ",", "end", "=", "self", ".", "start_and_end_indices", "(", "quantized", ",", "\n", "self", ".", "silence_threshold", ")", "\n", "return", "quantized", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.adjust_time_resolution": [[123, 149], ["numpy.repeat", "build_audio_features.AudioTools.start_and_end_indices", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.start_and_end_indices"], ["", "def", "adjust_time_resolution", "(", "self", ",", "quantized", ",", "mel", ")", ":", "\n", "        ", "\"\"\"Adjust time resolution by repeating features.\n\n        Args:\n            quantized (np.ndarray): (T,)\n            mel (np.ndarray): (N, D)\n\n        Returns:\n            tuple: Tuple of (T,) and (T, D)\n        \"\"\"", "\n", "assert", "quantized", ".", "ndim", "==", "1", "\n", "assert", "mel", ".", "ndim", "==", "2", "\n", "\n", "upsample_factor", "=", "quantized", ".", "size", "//", "mel", ".", "shape", "[", "0", "]", "\n", "mel", "=", "np", ".", "repeat", "(", "mel", ",", "upsample_factor", ",", "axis", "=", "0", ")", "\n", "n_pad", "=", "quantized", ".", "size", "-", "mel", ".", "shape", "[", "0", "]", "\n", "if", "n_pad", "!=", "0", ":", "\n", "            ", "assert", "n_pad", ">", "0", "\n", "mel", "=", "np", ".", "pad", "(", "\n", "mel", ",", "[", "(", "0", ",", "n_pad", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "\n", "# trim", "\n", "", "start", ",", "end", "=", "self", ".", "start_and_end_indices", "(", "quantized", ",", "\n", "self", ".", "silence_threshold", ")", "\n", "\n", "return", "quantized", "[", "start", ":", "end", "]", ",", "mel", "[", "start", ":", "end", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.start_and_end_indices": [[150, 164], ["range", "range", "abs", "abs", "abs", "abs"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "start_and_end_indices", "(", "quantized", ",", "silence_threshold", "=", "2", ")", ":", "\n", "        ", "\"\"\"Trim the audio file when reaches the silence threshold.\"\"\"", "\n", "for", "start", "in", "range", "(", "quantized", ".", "size", ")", ":", "\n", "            ", "if", "abs", "(", "quantized", "[", "start", "]", "-", "127", ")", ">", "silence_threshold", ":", "\n", "                ", "break", "\n", "", "", "for", "end", "in", "range", "(", "quantized", ".", "size", "-", "1", ",", "1", ",", "-", "1", ")", ":", "\n", "            ", "if", "abs", "(", "quantized", "[", "end", "]", "-", "127", ")", ">", "silence_threshold", ":", "\n", "                ", "break", "\n", "\n", "", "", "assert", "abs", "(", "quantized", "[", "start", "]", "-", "127", ")", ">", "silence_threshold", "\n", "assert", "abs", "(", "quantized", "[", "end", "]", "-", "127", ")", ">", "silence_threshold", "\n", "\n", "return", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.melspectrogram": [[165, 172], ["build_audio_features.AudioTools._normalize", "build_audio_features.AudioTools._lws_processor().stft", "build_audio_features.AudioTools._amp_to_db", "build_audio_features.AudioTools._linear_to_mel", "build_audio_features.AudioTools._lws_processor", "numpy.abs", "S.max", "S.min"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._normalize", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._amp_to_db", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._linear_to_mel", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._lws_processor"], ["", "def", "melspectrogram", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"Generate the melspectrogram.\"\"\"", "\n", "D", "=", "self", ".", "_lws_processor", "(", ")", ".", "stft", "(", "y", ")", ".", "T", "\n", "S", "=", "self", ".", "_amp_to_db", "(", "self", ".", "_linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "-", "self", ".", "ref_level_db", "\n", "if", "not", "self", ".", "allow_clipping_in_normalization", ":", "\n", "            ", "assert", "S", ".", "max", "(", ")", "<=", "0", "and", "S", ".", "min", "(", ")", "-", "self", ".", "min_level_db", ">=", "0", "\n", "", "return", "self", ".", "_normalize", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.get_hop_size": [[173, 180], ["int"], "methods", ["None"], ["", "def", "get_hop_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the hop size.\"\"\"", "\n", "hop_size", "=", "self", ".", "hop_size", "\n", "if", "hop_size", "is", "None", ":", "\n", "            ", "assert", "self", ".", "frame_shift_ms", "is", "not", "None", "\n", "hop_size", "=", "int", "(", "self", ".", "frame_shift_ms", "/", "1000", "*", "self", ".", "sample_rate", ")", "\n", "", "return", "hop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._lws_processor": [[181, 187], ["lws.lws", "build_audio_features.AudioTools.get_hop_size"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.get_hop_size"], ["", "def", "_lws_processor", "(", "self", ")", ":", "\n", "        ", "\"\"\"Perform local weighted sum.\n\n        Please refer to <https://pypi.org/project/lws/1.2.6/>`_.\n        \"\"\"", "\n", "return", "lws", ".", "lws", "(", "self", ".", "fft_size", ",", "self", ".", "get_hop_size", "(", ")", ",", "mode", "=", "'speech'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.lws_num_frames": [[188, 200], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "lws_num_frames", "(", "length", ",", "fsize", ",", "fshift", ")", ":", "\n", "        ", "\"\"\"Compute number of time frames of lws spectrogram.\n\n        Please refer to <https://pypi.org/project/lws/1.2.6/>`_.\n        \"\"\"", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "if", "length", "%", "fshift", "==", "0", ":", "\n", "            ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "1", "\n", "", "else", ":", "\n", "            ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "2", "\n", "", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.lws_pad_lr": [[201, 211], ["build_audio_features.AudioTools.lws_num_frames", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.lws_num_frames"], ["", "def", "lws_pad_lr", "(", "self", ",", "x", ",", "fsize", ",", "fshift", ")", ":", "\n", "        ", "\"\"\"Compute left and right padding lws internally uses.\n\n        Please refer to <https://pypi.org/project/lws/1.2.6/>`_.\n        \"\"\"", "\n", "M", "=", "self", ".", "lws_num_frames", "(", "len", "(", "x", ")", ",", "fsize", ",", "fshift", ")", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "T", "=", "len", "(", "x", ")", "+", "2", "*", "pad", "\n", "r", "=", "(", "M", "-", "1", ")", "*", "fshift", "+", "fsize", "-", "T", "\n", "return", "pad", ",", "pad", "+", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._linear_to_mel": [[212, 220], ["build_audio_features.AudioTools._build_mel_basis", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._build_mel_basis"], ["", "def", "_linear_to_mel", "(", "self", ",", "spectrogram", ")", ":", "\n", "        ", "\"\"\"Warp linear scale spectrograms to the mel scale.\n\n        Please refer to <https://github.com/r9y9/deepvoice3_pytorch>`_\n        \"\"\"", "\n", "global", "_mel_basis", "\n", "_mel_basis", "=", "self", ".", "_build_mel_basis", "(", ")", "\n", "return", "np", ".", "dot", "(", "_mel_basis", ",", "spectrogram", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._build_mel_basis": [[221, 233], ["librosa.filters.mel"], "methods", ["None"], ["", "def", "_build_mel_basis", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build mel filters.\n\n        Please refer to <https://github.com/r9y9/deepvoice3_pytorch>`_\n        \"\"\"", "\n", "assert", "self", ".", "fmax", "<=", "self", ".", "sample_rate", "//", "2", "\n", "return", "librosa", ".", "filters", ".", "mel", "(", "\n", "self", ".", "sample_rate", ",", "\n", "self", ".", "fft_size", ",", "\n", "fmin", "=", "self", ".", "fmin", ",", "\n", "fmax", "=", "self", ".", "fmax", ",", "\n", "n_mels", "=", "self", ".", "num_mels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._amp_to_db": [[234, 237], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "methods", ["None"], ["", "def", "_amp_to_db", "(", "self", ",", "x", ")", ":", "\n", "        ", "min_level", "=", "np", ".", "exp", "(", "self", ".", "min_level_db", "/", "20", "*", "np", ".", "log", "(", "10", ")", ")", "\n", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "min_level", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._db_to_amp": [[238, 241], ["numpy.power"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_db_to_amp", "(", "x", ")", ":", "\n", "        ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._normalize": [[242, 244], ["numpy.clip"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "S", ")", ":", "\n", "        ", "return", "np", ".", "clip", "(", "(", "S", "-", "self", ".", "min_level_db", ")", "/", "-", "self", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools._denormalize": [[245, 247], ["numpy.clip"], "methods", ["None"], ["", "def", "_denormalize", "(", "self", ",", "S", ")", ":", "\n", "        ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "self", ".", "min_level_db", ")", "+", "self", ".", "min_level_db", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.read_audio": [[248, 256], ["build_audio_features.AudioTools.load_wav", "build_audio_features.AudioTools.audio_normalize", "numpy.abs().max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.load_wav", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.audio_normalize"], ["", "def", "read_audio", "(", "self", ",", "audio_path", ")", ":", "\n", "        ", "wav", "=", "self", ".", "load_wav", "(", "audio_path", ")", "\n", "if", "self", ".", "norm_audio", ":", "\n", "            ", "wav", "=", "self", ".", "audio_normalize", "(", "wav", ")", "\n", "", "else", ":", "\n", "            ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "\n", "\n", "", "return", "wav", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.audio_to_spectrogram": [[257, 263], ["build_audio_features.AudioTools.melspectrogram().astype", "build_audio_features.AudioTools.generate_spectrogram_magphase", "build_audio_features.AudioTools.melspectrogram"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.generate_spectrogram_magphase", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.melspectrogram"], ["", "def", "audio_to_spectrogram", "(", "self", ",", "wav", ")", ":", "\n", "        ", "if", "self", ".", "spectrogram_type", "==", "'lws'", ":", "\n", "            ", "spectrogram", "=", "self", ".", "melspectrogram", "(", "wav", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "", "elif", "self", ".", "spectrogram_type", "==", "'librosa'", ":", "\n", "            ", "spectrogram", "=", "self", ".", "generate_spectrogram_magphase", "(", "wav", ")", "\n", "", "return", "spectrogram", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.extract_audio_feature": [[265, 282], ["os.splitext", "os.path.join", "os.path.join", "os.basename", "os.path.exists", "os.path.exists", "audio_tools.read_audio", "audio_tools.audio_to_spectrogram", "numpy.save", "audio_tools.audio_to_spectrogram.astype", "print"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.read_audio", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.audio_to_spectrogram"], ["", "", "def", "extract_audio_feature", "(", "wav_path", ",", "audio_tools", ",", "mel_out_dir", ")", ":", "\n", "    ", "file_name", ",", "_", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "wav_path", ")", ")", "\n", "# Write the spectrograms to disk:", "\n", "mel_filename", "=", "os", ".", "path", ".", "join", "(", "mel_out_dir", ",", "file_name", "+", "'.npy'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "mel_filename", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "wav", "=", "audio_tools", ".", "read_audio", "(", "wav_path", ")", "\n", "\n", "spectrogram", "=", "audio_tools", ".", "audio_to_spectrogram", "(", "wav", ")", "\n", "\n", "np", ".", "save", "(", "\n", "mel_filename", ",", "\n", "spectrogram", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "allow_pickle", "=", "False", ")", "\n", "\n", "", "except", "BaseException", ":", "\n", "            ", "print", "(", "f'Read audio [{wav_path}] failed.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.denormalize_proposal_file.process_norm_proposal_file": [[9, 52], ["norm_proposal_file.replace", "mmaction.localization.load_localize_proposal_file", "enumerate", "os.basename", "processed_proposal_list.append", "open", "f.writelines", "len", "len", "int", "int", "int", "int", "float", "float", "int", "int", "len", "len", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.load_localize_proposal_file"], ["def", "process_norm_proposal_file", "(", "norm_proposal_file", ",", "frame_dict", ")", ":", "\n", "    ", "\"\"\"Process the normalized proposal file and denormalize it.\n\n    Args:\n        norm_proposal_file (str): Name of normalized proposal file.\n        frame_dict (dict): Information of frame folders.\n    \"\"\"", "\n", "proposal_file", "=", "norm_proposal_file", ".", "replace", "(", "'normalized_'", ",", "''", ")", "\n", "norm_proposals", "=", "load_localize_proposal_file", "(", "norm_proposal_file", ")", "\n", "\n", "processed_proposal_list", "=", "[", "]", "\n", "for", "idx", ",", "norm_proposal", "in", "enumerate", "(", "norm_proposals", ")", ":", "\n", "        ", "video_id", "=", "norm_proposal", "[", "0", "]", "\n", "frame_info", "=", "frame_dict", "[", "video_id", "]", "\n", "num_frames", "=", "frame_info", "[", "1", "]", "\n", "frame_path", "=", "osp", ".", "basename", "(", "frame_info", "[", "0", "]", ")", "\n", "\n", "gt", "=", "[", "[", "\n", "int", "(", "x", "[", "0", "]", ")", ",", "\n", "int", "(", "float", "(", "x", "[", "1", "]", ")", "*", "num_frames", ")", ",", "\n", "int", "(", "float", "(", "x", "[", "2", "]", ")", "*", "num_frames", ")", "\n", "]", "for", "x", "in", "norm_proposal", "[", "2", "]", "]", "\n", "\n", "proposal", "=", "[", "[", "\n", "int", "(", "x", "[", "0", "]", ")", ",", "\n", "float", "(", "x", "[", "1", "]", ")", ",", "\n", "float", "(", "x", "[", "2", "]", ")", ",", "\n", "int", "(", "float", "(", "x", "[", "3", "]", ")", "*", "num_frames", ")", ",", "\n", "int", "(", "float", "(", "x", "[", "4", "]", ")", "*", "num_frames", ")", "\n", "]", "for", "x", "in", "norm_proposal", "[", "3", "]", "]", "\n", "\n", "gt_dump", "=", "'\\n'", ".", "join", "(", "[", "'{} {} {}'", ".", "format", "(", "*", "x", ")", "for", "x", "in", "gt", "]", ")", "\n", "gt_dump", "+=", "'\\n'", "if", "len", "(", "gt", ")", "else", "''", "\n", "proposal_dump", "=", "'\\n'", ".", "join", "(", "\n", "[", "'{} {:.04f} {:.04f} {} {}'", ".", "format", "(", "*", "x", ")", "for", "x", "in", "proposal", "]", ")", "\n", "proposal_dump", "+=", "'\\n'", "if", "len", "(", "proposal", ")", "else", "''", "\n", "\n", "processed_proposal_list", ".", "append", "(", "\n", "f'# {idx}\\n{frame_path}\\n{num_frames}\\n1'", "\n", "f'\\n{len(gt)}\\n{gt_dump}{len(proposal)}\\n{proposal_dump}'", ")", "\n", "\n", "", "with", "open", "(", "proposal_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "writelines", "(", "processed_proposal_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.denormalize_proposal_file.parse_args": [[54, 71], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Denormalize proposal file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'dataset'", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "'thumos14'", "]", ",", "\n", "help", "=", "'dataset to be denormalize proposal file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--norm-proposal-file'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'normalized proposal file to be denormalize'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--data-prefix'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'path to a directory where rawframes are held'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.denormalize_proposal_file.main": [[73, 79], ["denormalize_proposal_file.parse_args", "print", "tools.data.parse_file_list.parse_directory", "denormalize_proposal_file.process_norm_proposal_file"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.generate_file_list.parse_directory", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.denormalize_proposal_file.process_norm_proposal_file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "print", "(", "f'Converting from {args.norm_proposal_file}.'", ")", "\n", "frame_dict", "=", "parse_directory", "(", "args", ".", "data_prefix", ")", "\n", "process_norm_proposal_file", "(", "args", ".", "norm_proposal_file", ",", "frame_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_rawframes.extract_frame": [[13, 116], ["print", "sys.stdout.flush", "os.basename", "os.join", "os.dirname", "os.join", "mmcv.VideoReader", "enumerate", "os.system", "os.system", "os.system", "os.system", "os.system", "os.system", "os.system", "os.system", "os.splitext", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.basename", "numpy.shape", "mmcv.imwrite", "warnings.warn", "os.join", "os.join", "os.join", "os.join", "mmcv.imresize", "mmcv.imresize", "min", "int", "int", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "extract_frame", "(", "vid_item", ")", ":", "\n", "    ", "\"\"\"Generate optical flow using dense flow.\n\n    Args:\n        vid_item (list): Video item containing video full path,\n            video (short) path, video id.\n\n    Returns:\n        bool: Whether generate optical flow successfully.\n    \"\"\"", "\n", "full_path", ",", "vid_path", ",", "vid_id", ",", "method", ",", "task", "=", "vid_item", "\n", "if", "'/'", "in", "vid_path", ":", "\n", "        ", "act_name", "=", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "vid_path", ")", ")", "\n", "out_full_path", "=", "osp", ".", "join", "(", "args", ".", "out_dir", ",", "act_name", ")", "\n", "", "else", ":", "\n", "        ", "out_full_path", "=", "args", ".", "out_dir", "\n", "\n", "", "if", "task", "==", "'rgb'", ":", "\n", "        ", "if", "args", ".", "use_opencv", ":", "\n", "# Not like using denseflow,", "\n", "# Use OpenCV will not make a sub directory with the video name", "\n", "            ", "video_name", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "vid_path", ")", ")", "[", "0", "]", "\n", "out_full_path", "=", "osp", ".", "join", "(", "out_full_path", ",", "video_name", ")", "\n", "\n", "vr", "=", "mmcv", ".", "VideoReader", "(", "full_path", ")", "\n", "# for i in range(len(vr)):", "\n", "for", "i", ",", "vr_frame", "in", "enumerate", "(", "vr", ")", ":", "\n", "                ", "if", "vr_frame", "is", "not", "None", ":", "\n", "                    ", "w", ",", "h", ",", "_", "=", "np", ".", "shape", "(", "vr_frame", ")", "\n", "if", "args", ".", "new_short", "==", "0", ":", "\n", "                        ", "if", "args", ".", "new_width", "==", "0", "or", "args", ".", "new_height", "==", "0", ":", "\n", "# Keep original shape", "\n", "                            ", "out_img", "=", "vr_frame", "\n", "", "else", ":", "\n", "                            ", "out_img", "=", "mmcv", ".", "imresize", "(", "vr_frame", ",", "\n", "(", "args", ".", "new_width", ",", "\n", "args", ".", "new_height", ")", ")", "\n", "", "", "else", ":", "\n", "                        ", "if", "min", "(", "h", ",", "w", ")", "==", "h", ":", "\n", "                            ", "new_h", "=", "args", ".", "new_short", "\n", "new_w", "=", "int", "(", "(", "new_h", "/", "h", ")", "*", "w", ")", "\n", "", "else", ":", "\n", "                            ", "new_w", "=", "args", ".", "new_short", "\n", "new_h", "=", "int", "(", "(", "new_w", "/", "w", ")", "*", "h", ")", "\n", "", "out_img", "=", "mmcv", ".", "imresize", "(", "vr_frame", ",", "(", "new_h", ",", "new_w", ")", ")", "\n", "", "mmcv", ".", "imwrite", "(", "out_img", ",", "\n", "f'{out_full_path}/img_{i + 1:05d}.jpg'", ")", "\n", "", "else", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "'Length inconsistent!'", "\n", "f'Early stop with {i + 1} out of {len(vr)} frames.'", ")", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "if", "args", ".", "new_short", "==", "0", ":", "\n", "                ", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -b=20 -s=0 -o='{out_full_path}'\"", "\n", "f' -nw={args.new_width} -nh={args.new_height} -v'", ")", "\n", "", "else", ":", "\n", "                ", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -b=20 -s=0 -o='{out_full_path}'\"", "\n", "f' -ns={args.new_short} -v'", ")", "\n", "", "os", ".", "system", "(", "cmd", ")", "\n", "", "", "elif", "task", "==", "'flow'", ":", "\n", "        ", "if", "args", ".", "input_frames", ":", "\n", "            ", "if", "args", ".", "new_short", "==", "0", ":", "\n", "                ", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -a={method} -b=20 -s=1 -o='{out_full_path}'\"", "# noqa: E501", "\n", "f' -nw={args.new_width} --nh={args.new_height} -v --if'", ")", "\n", "", "else", ":", "\n", "                ", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -a={method} -b=20 -s=1 -o='{out_full_path}'\"", "# noqa: E501", "\n", "f' -ns={args.new_short} -v --if'", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "new_short", "==", "0", ":", "\n", "                ", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -a={method} -b=20 -s=1 -o='{out_full_path}'\"", "# noqa: E501", "\n", "f' -nw={args.new_width} --nh={args.new_height} -v'", ")", "\n", "", "else", ":", "\n", "                ", "cmd", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -a={method} -b=20 -s=1 -o='{out_full_path}'\"", "# noqa: E501", "\n", "f' -ns={args.new_short} -v'", ")", "\n", "", "", "os", ".", "system", "(", "cmd", ")", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "new_short", "==", "0", ":", "\n", "            ", "cmd_rgb", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -b=20 -s=0 -o='{out_full_path}'\"", "\n", "f' -nw={args.new_width} -nh={args.new_height} -v'", ")", "\n", "cmd_flow", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -a={method} -b=20 -s=1 -o='{out_full_path}'\"", "# noqa: E501", "\n", "f' -nw={args.new_width} -nh={args.new_height} -v'", ")", "\n", "", "else", ":", "\n", "            ", "cmd_rgb", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -b=20 -s=0 -o='{out_full_path}'\"", "\n", "f' -ns={args.new_short} -v'", ")", "\n", "cmd_flow", "=", "osp", ".", "join", "(", "\n", "f\"denseflow '{full_path}' -a={method} -b=20 -s=1 -o='{out_full_path}'\"", "# noqa: E501", "\n", "f' -ns={args.new_short} -v'", ")", "\n", "", "os", ".", "system", "(", "cmd_rgb", ")", "\n", "os", ".", "system", "(", "cmd_flow", ")", "\n", "\n", "", "print", "(", "f'{task} {vid_id} {vid_path} {method} done'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_rawframes.parse_args": [[118, 187], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'extract optical flows'", ")", "\n", "parser", ".", "add_argument", "(", "'src_dir'", ",", "type", "=", "str", ",", "help", "=", "'source video directory'", ")", "\n", "parser", ".", "add_argument", "(", "'out_dir'", ",", "type", "=", "str", ",", "help", "=", "'output rawframe directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--task'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'flow'", ",", "\n", "choices", "=", "[", "'rgb'", ",", "'flow'", ",", "'both'", "]", ",", "\n", "help", "=", "'which type of frames to be extracted'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--level'", ",", "\n", "type", "=", "int", ",", "\n", "choices", "=", "[", "1", ",", "2", "]", ",", "\n", "default", "=", "2", ",", "\n", "help", "=", "'directory level of data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num-worker'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "8", ",", "\n", "help", "=", "'number of workers to build rawframes'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--flow-type'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "choices", "=", "[", "None", ",", "'tvl1'", ",", "'warp_tvl1'", ",", "'farn'", ",", "'brox'", "]", ",", "\n", "help", "=", "'flow type to be generated'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--out-format'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'jpg'", ",", "\n", "choices", "=", "[", "'jpg'", ",", "'h5'", ",", "'png'", "]", ",", "\n", "help", "=", "'output format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ext'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'avi'", ",", "\n", "choices", "=", "[", "'avi'", ",", "'mp4'", ",", "'webm'", "]", ",", "\n", "help", "=", "'video file extensions'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mixed-ext'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'process video files with mixed extensions'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--new-width'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'resize image width'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--new-height'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'resize image height'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--new-short'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "'resize image short side length keeping ratio'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-gpu'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'number of GPU'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "'resume optical flow extraction instead of overwriting'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use-opencv'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to use opencv to extract rgb frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--input-frames'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to extract flow frames based on rgb frames'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.generate_sub_file_list.main": [[7, 27], ["mmcv.load", "os.basename", "os.dirname", "basename.replace.replace", "os.join", "mmcv.dump", "result.append"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "main", "(", "annotation_file", ",", "category", ")", ":", "\n", "    ", "assert", "category", "in", "[", "\n", "'action'", ",", "'attribute'", ",", "'concept'", ",", "'event'", ",", "'object'", ",", "'scene'", "\n", "]", "\n", "\n", "data", "=", "mmcv", ".", "load", "(", "annotation_file", ")", "\n", "basename", "=", "osp", ".", "basename", "(", "annotation_file", ")", "\n", "dirname", "=", "osp", ".", "dirname", "(", "annotation_file", ")", "\n", "basename", "=", "basename", ".", "replace", "(", "'hvu'", ",", "f'hvu_{category}'", ")", "\n", "\n", "target_file", "=", "osp", ".", "join", "(", "dirname", ",", "basename", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "item", "in", "data", ":", "\n", "        ", "label", "=", "item", "[", "'label'", "]", "\n", "if", "category", "in", "label", ":", "\n", "            ", "item", "[", "'label'", "]", "=", "label", "[", "category", "]", "\n", "result", ".", "append", "(", "item", ")", "\n", "\n", "", "", "mmcv", ".", "dump", "(", "data", ",", "target_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.create_video_folders": [[21, 26], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "create_video_folders", "(", "output_dir", ",", "tmp_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "tmp_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.construct_video_filename": [[28, 37], ["os.path.join", "int", "int"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Given a dataset row, this function constructs the output filename for a\n    given video.\"\"\"", "\n", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "start_time", ",", "end_time", "=", "int", "(", "start_time", "*", "10", ")", ",", "int", "(", "end_time", "*", "10", ")", "\n", "basename", "=", "'%s_%s_%s.mp4'", "%", "(", "youtube_id", ",", "trim_format", "%", "start_time", ",", "\n", "trim_format", "%", "end_time", ")", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "basename", ")", "\n", "return", "output_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.download_clip": [[39, 110], ["isinstance", "isinstance", "os.path.join", "os.path.exists", "os.remove", "len", "os.path.exists", "uuid.uuid4", "os.path.exists", "print", "glob.glob", "str", "str", "subprocess.check_output", "subprocess.check_output", "os.path.join.split"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove"], ["", "def", "download_clip", "(", "video_identifier", ",", "\n", "output_filename", ",", "\n", "start_time", ",", "\n", "end_time", ",", "\n", "tmp_dir", "=", "'/tmp/hvu'", ",", "\n", "num_attempts", "=", "5", ",", "\n", "url_base", "=", "'https://www.youtube.com/watch?v='", ")", ":", "\n", "    ", "\"\"\"Download a video from youtube if exists and is not blocked.\n    arguments:\n    ---------\n    video_identifier: str\n        Unique YouTube video identifier (11 characters)\n    output_filename: str\n        File path where the video will be stored.\n    start_time: float\n        Indicates the begining time in seconds from where the video\n        will be trimmed.\n    end_time: float\n        Indicates the ending time in seconds of the trimmed video.\n    \"\"\"", "\n", "# Defensive argument checking.", "\n", "assert", "isinstance", "(", "video_identifier", ",", "str", ")", ",", "'video_identifier must be string'", "\n", "assert", "isinstance", "(", "output_filename", ",", "str", ")", ",", "'output_filename must be string'", "\n", "assert", "len", "(", "video_identifier", ")", "==", "11", ",", "'video_identifier must have length 11'", "\n", "\n", "status", "=", "False", "\n", "tmp_filename", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'%s.%%(ext)s'", "%", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_filename", ")", ":", "\n", "            ", "command", "=", "[", "\n", "'youtube-dl'", ",", "'--quiet'", ",", "'--no-warnings'", ",", "\n", "'--no-check-certificate'", ",", "'-f'", ",", "'mp4'", ",", "'-o'", ",", "\n", "'\"%s\"'", "%", "tmp_filename", ",", "\n", "'\"%s\"'", "%", "(", "url_base", "+", "video_identifier", ")", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "print", "(", "command", ")", "\n", "attempts", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "                    ", "attempts", "+=", "1", "\n", "if", "attempts", "==", "num_attempts", ":", "\n", "                        ", "return", "status", ",", "'Downloading Failed'", "\n", "", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "tmp_filename", "=", "glob", ".", "glob", "(", "'%s*'", "%", "tmp_filename", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "[", "0", "]", "\n", "# Construct command to trim the videos (ffmpeg required).", "\n", "command", "=", "[", "\n", "'ffmpeg'", ",", "'-i'", ",", "\n", "'\"%s\"'", "%", "tmp_filename", ",", "'-ss'", ",", "\n", "str", "(", "start_time", ")", ",", "'-t'", ",", "\n", "str", "(", "end_time", "-", "start_time", ")", ",", "'-c:v'", ",", "'libx264'", ",", "'-c:a'", ",", "'copy'", ",", "\n", "'-threads'", ",", "'1'", ",", "'-loglevel'", ",", "'panic'", ",", "\n", "'\"%s\"'", "%", "output_filename", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "try", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "return", "status", ",", "'Trimming Failed'", "\n", "\n", "# Check if the video was successfully saved.", "\n", "", "", "status", "=", "os", ".", "path", ".", "exists", "(", "output_filename", ")", "\n", "os", ".", "remove", "(", "tmp_filename", ")", "\n", "return", "status", ",", "'Downloaded'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.download_clip_wrapper": [[112, 126], ["download.construct_video_filename", "os.path.exists", "download.download_clip", "tuple", "os.path.basename().split", "tuple", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.construct_video_filename", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip"], ["", "def", "download_clip_wrapper", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Wrapper for parallel processing purposes.\"\"\"", "\n", "output_filename", "=", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", "\n", "clip_id", "=", "os", ".", "path", ".", "basename", "(", "output_filename", ")", ".", "split", "(", "'.mp4'", ")", "[", "0", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "status", "=", "tuple", "(", "[", "clip_id", ",", "True", ",", "'Exists'", "]", ")", "\n", "return", "status", "\n", "\n", "", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "downloaded", ",", "log", "=", "download_clip", "(", "\n", "youtube_id", ",", "output_filename", ",", "start_time", ",", "end_time", ",", "tmp_dir", "=", "tmp_dir", ")", "\n", "\n", "status", "=", "tuple", "(", "[", "clip_id", ",", "downloaded", ",", "log", "]", ")", "\n", "return", "status", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.parse_hvu_annotations": [[128, 146], ["open().readlines", "open", "x.strip().split", "float", "float", "x.strip"], "function", ["None"], ["", "def", "parse_hvu_annotations", "(", "input_csv", ")", ":", "\n", "    ", "\"\"\"Returns a parsed DataFrame.\n    arguments:\n    ---------\n    input_csv: str\n        Path to CSV file containing the following columns:\n          'Tags, youtube_id, time_start, time_end'\n    returns:\n    -------\n    dataset: List of tuples. Each tuple consists of\n        (youtube_id, time_start, time_end). The type of time is float.\n    \"\"\"", "\n", "lines", "=", "open", "(", "input_csv", ")", ".", "readlines", "(", ")", "\n", "lines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "[", "1", ":", "]", "for", "x", "in", "lines", "[", "1", ":", "]", "]", "\n", "\n", "lines", "=", "[", "(", "x", "[", "0", "]", ",", "float", "(", "x", "[", "1", "]", ")", ",", "float", "(", "x", "[", "2", "]", ")", ")", "for", "x", "in", "lines", "]", "\n", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.main": [[148, 174], ["download.parse_hvu_annotations", "download.create_video_folders", "shutil.rmtree", "mmcv.dump", "status_lst.append", "joblib.Parallel", "download.download_clip_wrapper", "joblib.delayed"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.download.parse_hvu_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.create_video_folders", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip_wrapper"], ["", "def", "main", "(", "input_csv", ",", "\n", "output_dir", ",", "\n", "trim_format", "=", "'%06d'", ",", "\n", "num_jobs", "=", "24", ",", "\n", "tmp_dir", "=", "'/tmp/hvu'", ")", ":", "\n", "# Reading and parsing HVU.", "\n", "    ", "dataset", "=", "parse_hvu_annotations", "(", "input_csv", ")", "\n", "\n", "# Creates folders where videos will be saved later.", "\n", "create_video_folders", "(", "output_dir", ",", "tmp_dir", ")", "\n", "\n", "# Download all clips.", "\n", "if", "num_jobs", "==", "1", ":", "\n", "        ", "status_lst", "=", "[", "]", "\n", "for", "item", "in", "dataset", ":", "\n", "            ", "status_lst", ".", "append", "(", "\n", "download_clip_wrapper", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "output_dir", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "status_lst", "=", "Parallel", "(", "n_jobs", "=", "num_jobs", ")", "(", "\n", "delayed", "(", "download_clip_wrapper", ")", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "\n", "output_dir", ")", "for", "item", "in", "dataset", ")", "\n", "\n", "# Clean tmp dir.", "\n", "", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "# Save download report.", "\n", "mmcv", ".", "dump", "(", "status_lst", ",", "'download_report.json'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.generate_file_list.parse_directory": [[14, 87], ["print", "enumerate", "print", "glob.glob", "os.listdir", "os.listdir", "generate_file_list.parse_directory.count_files"], "function", ["None"], ["def", "parse_directory", "(", "path", ",", "\n", "rgb_prefix", "=", "'img_'", ",", "\n", "flow_x_prefix", "=", "'flow_x_'", ",", "\n", "flow_y_prefix", "=", "'flow_y_'", ",", "\n", "level", "=", "1", ")", ":", "\n", "    ", "\"\"\"Parse directories holding extracted frames from standard benchmarks.\n\n    Args:\n        path (str): Directory path to parse frames.\n        rgb_prefix (str): Prefix of generated rgb frames name.\n            default: 'img_'.\n        flow_x_prefix (str): Prefix of generated flow x name.\n            default: `flow_x_`.\n        flow_y_prefix (str): Prefix of generated flow y name.\n            default: `flow_y_`.\n        level (int): Directory level for glob searching. Options are 1 and 2.\n            default: 1.\n\n    Returns:\n        dict: frame info dict with video id as key and tuple(path(str),\n            rgb_num(int), flow_x_num(int)) as value.\n    \"\"\"", "\n", "print", "(", "f'parse frames under directory {path}'", ")", "\n", "if", "level", "==", "1", ":", "\n", "# Only search for one-level directory", "\n", "        ", "def", "locate_directory", "(", "x", ")", ":", "\n", "            ", "return", "osp", ".", "basename", "(", "x", ")", "\n", "\n", "", "frame_dirs", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "path", ",", "'*'", ")", ")", "\n", "\n", "", "elif", "level", "==", "2", ":", "\n", "# search for two-level directory", "\n", "        ", "def", "locate_directory", "(", "x", ")", ":", "\n", "            ", "return", "osp", ".", "join", "(", "osp", ".", "basename", "(", "osp", ".", "dirname", "(", "x", ")", ")", ",", "osp", ".", "basename", "(", "x", ")", ")", "\n", "\n", "", "frame_dirs", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "path", ",", "'*'", ",", "'*'", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'level can be only 1 or 2'", ")", "\n", "\n", "", "def", "count_files", "(", "directory", ",", "prefix_list", ")", ":", "\n", "        ", "\"\"\"Count file number with a given directory and prefix.\n\n        Args:\n            directory (str): Data directory to be search.\n            prefix_list (list): List or prefix.\n\n        Returns:\n            list (int): Number list of the file with the prefix.\n        \"\"\"", "\n", "lst", "=", "os", ".", "listdir", "(", "directory", ")", "\n", "cnt_list", "=", "[", "len", "(", "fnmatch", ".", "filter", "(", "lst", ",", "x", "+", "'*'", ")", ")", "for", "x", "in", "prefix_list", "]", "\n", "return", "cnt_list", "\n", "\n", "# check RGB", "\n", "", "frame_dict", "=", "{", "}", "\n", "for", "i", ",", "frame_dir", "in", "enumerate", "(", "frame_dirs", ")", ":", "\n", "        ", "total_num", "=", "count_files", "(", "frame_dir", ",", "\n", "(", "rgb_prefix", ",", "flow_x_prefix", ",", "flow_y_prefix", ")", ")", "\n", "dir_name", "=", "locate_directory", "(", "frame_dir", ")", "\n", "\n", "num_x", "=", "total_num", "[", "1", "]", "\n", "num_y", "=", "total_num", "[", "2", "]", "\n", "if", "num_x", "!=", "num_y", ":", "\n", "            ", "raise", "ValueError", "(", "f'x and y direction have different number '", "\n", "f'of flow images in video directory: {frame_dir}'", ")", "\n", "", "if", "i", "%", "200", "==", "0", ":", "\n", "            ", "print", "(", "f'{i} videos parsed'", ")", "\n", "\n", "", "frame_dict", "[", "dir_name", "]", "=", "(", "frame_dir", ",", "total_num", "[", "0", "]", ",", "num_x", ")", "\n", "\n", "", "print", "(", "'frame directory analysis done'", ")", "\n", "return", "frame_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hvu.generate_file_list.parse_args": [[89, 107], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'build file list for HVU'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_csv'", ",", "type", "=", "str", ",", "help", "=", "'path of input csv file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--src_dir'", ",", "type", "=", "str", ",", "help", "=", "'source video / frames directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'output filename, should \\\n        ends with .json'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mode'", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "'frames'", ",", "'videos'", "]", ",", "\n", "help", "=", "'generate file list for frames or videos'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.create_video_folders": [[21, 41], ["dataset[].unique", "os.path.join", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.join", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "create_video_folders", "(", "output_dir", ",", "tmp_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "tmp_dir", ")", "\n", "\n", "\n", "", "", "def", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Given a dataset row, this function constructs the output filename for a\n    given video.\"\"\"", "\n", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "start_time", ",", "end_time", "=", "int", "(", "start_time", "*", "10", ")", ",", "int", "(", "end_time", "*", "10", ")", "\n", "basename", "=", "'%s_%s_%s.mp4'", "%", "(", "youtube_id", ",", "trim_format", "%", "start_time", ",", "\n", "trim_format", "%", "end_time", ")", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "basename", ")", "\n", "return", "output_filename", "\n", "\n", "\n", "", "def", "download_clip", "(", "video_identifier", ",", "\n", "output_filename", ",", "\n", "start_time", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.construct_video_filename": [[43, 55], ["os.path.join", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["tmp_dir", "=", "'/tmp/hvu'", ",", "\n", "num_attempts", "=", "5", ",", "\n", "url_base", "=", "'https://www.youtube.com/watch?v='", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.download_clip": [[57, 129], ["isinstance", "isinstance", "os.path.join", "os.path.exists", "os.remove", "len", "os.path.exists", "uuid.uuid4", "os.path.exists", "print", "glob.glob", "str", "str", "subprocess.check_output", "subprocess.check_output", "os.path.join.split"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove"], ["\n", "# Defensive argument checking.", "\n", "assert", "isinstance", "(", "video_identifier", ",", "str", ")", ",", "'video_identifier must be string'", "\n", "assert", "isinstance", "(", "output_filename", ",", "str", ")", ",", "'output_filename must be string'", "\n", "assert", "len", "(", "video_identifier", ")", "==", "11", ",", "'video_identifier must have length 11'", "\n", "\n", "status", "=", "False", "\n", "tmp_filename", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'%s.%%(ext)s'", "%", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_filename", ")", ":", "\n", "            ", "command", "=", "[", "\n", "'youtube-dl'", ",", "'--quiet'", ",", "'--no-warnings'", ",", "\n", "'--no-check-certificate'", ",", "'-f'", ",", "'mp4'", ",", "'-o'", ",", "\n", "'\"%s\"'", "%", "tmp_filename", ",", "\n", "'\"%s\"'", "%", "(", "url_base", "+", "video_identifier", ")", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "print", "(", "command", ")", "\n", "attempts", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "                    ", "attempts", "+=", "1", "\n", "if", "attempts", "==", "num_attempts", ":", "\n", "                        ", "return", "status", ",", "'Downloading Failed'", "\n", "", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "tmp_filename", "=", "glob", ".", "glob", "(", "'%s*'", "%", "tmp_filename", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "[", "0", "]", "\n", "# Construct command to trim the videos (ffmpeg required).", "\n", "command", "=", "[", "\n", "'ffmpeg'", ",", "'-i'", ",", "\n", "'\"%s\"'", "%", "tmp_filename", ",", "'-ss'", ",", "\n", "str", "(", "start_time", ")", ",", "'-t'", ",", "\n", "str", "(", "end_time", "-", "start_time", ")", ",", "'-c:v'", ",", "'libx264'", ",", "'-c:a'", ",", "'copy'", ",", "\n", "'-threads'", ",", "'1'", ",", "'-loglevel'", ",", "'panic'", ",", "\n", "'\"%s\"'", "%", "output_filename", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "try", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "return", "status", ",", "'Trimming Failed'", "\n", "\n", "# Check if the video was successfully saved.", "\n", "", "", "status", "=", "os", ".", "path", ".", "exists", "(", "output_filename", ")", "\n", "os", ".", "remove", "(", "tmp_filename", ")", "\n", "return", "status", ",", "'Downloaded'", "\n", "\n", "\n", "", "def", "download_clip_wrapper", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Wrapper for parallel processing purposes.\"\"\"", "\n", "output_filename", "=", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", "\n", "clip_id", "=", "os", ".", "path", ".", "basename", "(", "output_filename", ")", ".", "split", "(", "'.mp4'", ")", "[", "0", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "status", "=", "tuple", "(", "[", "clip_id", ",", "True", ",", "'Exists'", "]", ")", "\n", "return", "status", "\n", "\n", "", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "downloaded", ",", "log", "=", "download_clip", "(", "\n", "youtube_id", ",", "output_filename", ",", "start_time", ",", "end_time", ",", "tmp_dir", "=", "tmp_dir", ")", "\n", "\n", "status", "=", "tuple", "(", "[", "clip_id", ",", "downloaded", ",", "log", "]", ")", "\n", "return", "status", "\n", "\n", "\n", "", "def", "parse_hvu_annotations", "(", "input_csv", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.download_clip_wrapper": [[131, 147], ["download.construct_video_filename", "os.path.exists", "download.download_clip", "tuple", "os.path.basename().split", "tuple", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.construct_video_filename", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip"], ["\n", "lines", "=", "open", "(", "input_csv", ")", ".", "readlines", "(", ")", "\n", "lines", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "[", "1", ":", "]", "for", "x", "in", "lines", "[", "1", ":", "]", "]", "\n", "\n", "lines", "=", "[", "(", "x", "[", "0", "]", ",", "float", "(", "x", "[", "1", "]", ")", ",", "float", "(", "x", "[", "2", "]", ")", ")", "for", "x", "in", "lines", "]", "\n", "\n", "return", "lines", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.parse_kinetics_annotations": [[149, 172], ["pandas.read_csv", "collections.OrderedDict", "pd.read_csv.rename", "pd.read_csv.columns.tolist"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_csv"], ["output_dir", ",", "\n", "trim_format", "=", "'%06d'", ",", "\n", "num_jobs", "=", "24", ",", "\n", "tmp_dir", "=", "'/tmp/hvu'", ")", ":", "\n", "# Reading and parsing HVU.", "\n", "    ", "dataset", "=", "parse_hvu_annotations", "(", "input_csv", ")", "\n", "\n", "# Creates folders where videos will be saved later.", "\n", "create_video_folders", "(", "output_dir", ",", "tmp_dir", ")", "\n", "\n", "# Download all clips.", "\n", "if", "num_jobs", "==", "1", ":", "\n", "        ", "status_lst", "=", "[", "]", "\n", "for", "item", "in", "dataset", ":", "\n", "            ", "status_lst", ".", "append", "(", "\n", "download_clip_wrapper", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "output_dir", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "status_lst", "=", "Parallel", "(", "n_jobs", "=", "num_jobs", ")", "(", "\n", "delayed", "(", "download_clip_wrapper", ")", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "\n", "output_dir", ")", "for", "item", "in", "dataset", ")", "\n", "\n", "# Clean tmp dir.", "\n", "", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "# Save download report.", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.main": [[174, 203], ["download.parse_kinetics_annotations", "download.create_video_folders", "shutil.rmtree", "parse_kinetics_annotations.iterrows", "open", "fobj.write", "status_list.append", "joblib.Parallel", "json.dumps", "download.download_clip_wrapper", "joblib.delayed", "parse_kinetics_annotations.iterrows"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.parse_kinetics_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.kinetics.download.create_video_folders", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip_wrapper"], ["\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "description", "=", "'Helper script for downloading and trimming HVU videos.'", "\n", "p", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "description", ")", "\n", "p", ".", "add_argument", "(", "\n", "'input_csv'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "(", "'CSV file containing the following format: '", "\n", "'Tags, youtube_id, time_start, time_end'", ")", ")", "\n", "p", ".", "add_argument", "(", "\n", "'output_dir'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Output directory where videos will be saved.'", ")", "\n", "p", ".", "add_argument", "(", "\n", "'-f'", ",", "\n", "'--trim-format'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'%06d'", ",", "\n", "help", "=", "(", "'This will be the format for the '", "\n", "'filename of trimmed videos: '", "\n", "'videoid_%0xd(start_time)_%0xd(end_time).mp4. '", "\n", "'Note that the start_time is multiplied by 10 since '", "\n", "'decimal exists somewhere. '", ")", ")", "\n", "p", ".", "add_argument", "(", "'-n'", ",", "'--num-jobs'", ",", "type", "=", "int", ",", "default", "=", "24", ")", "\n", "p", ".", "add_argument", "(", "'-t'", ",", "'--tmp-dir'", ",", "type", "=", "str", ",", "default", "=", "'/tmp/hvu'", ")", "\n", "main", "(", "**", "vars", "(", "p", ".", "parse_args", "(", ")", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.gym.download.download": [[15, 57], ["isinstance", "isinstance", "os.path.exists", "len", "os.path.exists", "print", "subprocess.check_output"], "function", ["None"], ["from", "joblib", "import", "Parallel", ",", "delayed", "\n", "\n", "ssl", ".", "_create_default_https_context", "=", "ssl", ".", "_create_unverified_context", "\n", "args", "=", "None", "\n", "\n", "\n", "def", "create_video_folders", "(", "output_dir", ",", "tmp_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "tmp_dir", ")", "\n", "\n", "\n", "", "", "def", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Given a dataset row, this function constructs the output filename for a\n    given video.\"\"\"", "\n", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "start_time", ",", "end_time", "=", "int", "(", "start_time", "*", "10", ")", ",", "int", "(", "end_time", "*", "10", ")", "\n", "basename", "=", "'%s_%s_%s.mp4'", "%", "(", "youtube_id", ",", "trim_format", "%", "start_time", ",", "\n", "trim_format", "%", "end_time", ")", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "basename", ")", "\n", "return", "output_filename", "\n", "\n", "\n", "", "def", "download_clip", "(", "video_identifier", ",", "\n", "output_filename", ",", "\n", "start_time", ",", "\n", "end_time", ",", "\n", "tmp_dir", "=", "'/tmp/hvu'", ",", "\n", "num_attempts", "=", "5", ",", "\n", "url_base", "=", "'https://www.youtube.com/watch?v='", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.gym.download.download_wrapper": [[59, 70], ["os.path.join", "os.path.exists", "download.download", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.gym.download.download"], ["# Defensive argument checking.", "\n", "assert", "isinstance", "(", "video_identifier", ",", "str", ")", ",", "'video_identifier must be string'", "\n", "assert", "isinstance", "(", "output_filename", ",", "str", ")", ",", "'output_filename must be string'", "\n", "assert", "len", "(", "video_identifier", ")", "==", "11", ",", "'video_identifier must have length 11'", "\n", "\n", "status", "=", "False", "\n", "tmp_filename", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'%s.%%(ext)s'", "%", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_filename", ")", ":", "\n", "            ", "command", "=", "[", "\n", "'youtube-dl'", ",", "'--quiet'", ",", "'--no-warnings'", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.gym.download.main": [[72, 90], ["mmcv.load().keys", "mmcv.dump", "os.path.exists", "os.makedirs", "mmcv.load", "status_list.append", "joblib.Parallel", "download.download_wrapper", "joblib.delayed"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.gym.download.download_wrapper"], ["'\"%s\"'", "%", "tmp_filename", ",", "\n", "'\"%s\"'", "%", "(", "url_base", "+", "video_identifier", ")", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "print", "(", "command", ")", "\n", "attempts", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "                    ", "attempts", "+=", "1", "\n", "if", "attempts", "==", "num_attempts", ":", "\n", "                        ", "return", "status", ",", "'Downloading Failed'", "\n", "", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "tmp_filename", "=", "glob", ".", "glob", "(", "'%s*'", "%", "tmp_filename", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "[", "0", "]", "\n", "# Construct command to trim the videos (ffmpeg required).", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava.download_videos_parallel.download_video": [[11, 35], ["os.basename", "os.join", "os.exists", "os.exists", "print", "subprocess.check_output"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "download_video", "(", "video_url", ",", "output_dir", ",", "num_attempts", "=", "5", ")", ":", "\n", "    ", "video_file", "=", "osp", ".", "basename", "(", "video_url", ")", "\n", "output_file", "=", "osp", ".", "join", "(", "output_dir", ",", "video_file", ")", "\n", "\n", "status", "=", "False", "\n", "\n", "if", "not", "osp", ".", "exists", "(", "output_file", ")", ":", "\n", "        ", "command", "=", "[", "'wget'", ",", "'-c'", ",", "video_url", ",", "'-P'", ",", "output_dir", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "print", "(", "command", ")", "\n", "attempts", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "                ", "attempts", "+=", "1", "\n", "if", "attempts", "==", "num_attempts", ":", "\n", "                    ", "return", "status", ",", "'Downloading Failed'", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "status", "=", "osp", ".", "exists", "(", "output_file", ")", "\n", "return", "status", ",", "'Downloaded'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava.download_videos_parallel.main": [[37, 52], ["mmcv.mkdir_or_exist", "open().read().strip().split", "mmcv.dump", "os.join", "open().read().strip", "open().read().strip().split.append", "joblib.Parallel", "download_videos_parallel.download_video", "open().read", "joblib.delayed", "open"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava.download_videos_parallel.download_video"], ["", "def", "main", "(", "source_file", ",", "output_dir", ",", "num_jobs", "=", "24", ",", "num_attempts", "=", "5", ")", ":", "\n", "    ", "mmcv", ".", "mkdir_or_exist", "(", "output_dir", ")", "\n", "video_list", "=", "open", "(", "source_file", ")", ".", "read", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "video_list", "=", "[", "osp", ".", "join", "(", "URL_PREFIX", ",", "video", ")", "for", "video", "in", "video_list", "]", "\n", "\n", "if", "num_jobs", "==", "1", ":", "\n", "        ", "status_list", "=", "[", "]", "\n", "for", "video", "in", "video_list", ":", "\n", "            ", "video_list", ".", "append", "(", "download_video", "(", "video", ",", "output_dir", ",", "num_attempts", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "status_list", "=", "Parallel", "(", "n_jobs", "=", "num_jobs", ")", "(", "\n", "delayed", "(", "download_video", ")", "(", "video", ",", "output_dir", ",", "num_attempts", ")", "\n", "for", "video", "in", "video_list", ")", "\n", "\n", "", "mmcv", ".", "dump", "(", "status_list", ",", "'download_report.json'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.process_annotations.load_json": [[8, 12], ["open", "json.load"], "function", ["None"], ["def", "load_json", "(", "file", ")", ":", "\n", "    ", "with", "open", "(", "file", ")", "as", "json_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "json_file", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.convert_proposal_format.load_annotations": [[12, 21], ["mmcv.load", "video_infos.append"], "function", ["None"], ["def", "load_annotations", "(", "ann_file", ")", ":", "\n", "    ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "video_infos", "=", "[", "]", "\n", "anno_database", "=", "mmcv", ".", "load", "(", "ann_file", ")", "\n", "for", "video_name", "in", "anno_database", ":", "\n", "        ", "video_info", "=", "anno_database", "[", "video_name", "]", "\n", "video_info", "[", "'video_name'", "]", "=", "video_name", "\n", "video_infos", ".", "append", "(", "video_info", ")", "\n", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.convert_proposal_format.import_ground_truth": [[23, 35], ["numpy.array", "this_video_ground_truths.append"], "function", ["None"], ["", "def", "import_ground_truth", "(", "video_infos", ",", "activity_index", ")", ":", "\n", "    ", "\"\"\"Read ground truth data from video_infos.\"\"\"", "\n", "ground_truth", "=", "{", "}", "\n", "for", "video_info", "in", "video_infos", ":", "\n", "        ", "video_id", "=", "video_info", "[", "'video_name'", "]", "[", "2", ":", "]", "\n", "this_video_ground_truths", "=", "[", "]", "\n", "for", "ann", "in", "video_info", "[", "'annotations'", "]", ":", "\n", "            ", "t_start", ",", "t_end", "=", "ann", "[", "'segment'", "]", "\n", "label", "=", "activity_index", "[", "ann", "[", "'label'", "]", "]", "\n", "this_video_ground_truths", ".", "append", "(", "[", "t_start", ",", "t_end", ",", "label", "]", ")", "\n", "", "ground_truth", "[", "video_id", "]", "=", "np", ".", "array", "(", "this_video_ground_truths", ")", "\n", "", "return", "ground_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.convert_proposal_format.import_proposals": [[37, 51], ["numpy.array", "this_video_proposals.append"], "function", ["None"], ["", "def", "import_proposals", "(", "result_dict", ")", ":", "\n", "    ", "\"\"\"Read predictions from result dict.\"\"\"", "\n", "proposals", "=", "{", "}", "\n", "num_proposals", "=", "0", "\n", "for", "video_id", "in", "result_dict", ":", "\n", "        ", "result", "=", "result_dict", "[", "video_id", "]", "\n", "this_video_proposals", "=", "[", "]", "\n", "for", "proposal", "in", "result", ":", "\n", "            ", "t_start", ",", "t_end", "=", "proposal", "[", "'segment'", "]", "\n", "score", "=", "proposal", "[", "'score'", "]", "\n", "this_video_proposals", ".", "append", "(", "[", "t_start", ",", "t_end", ",", "score", "]", ")", "\n", "num_proposals", "+=", "1", "\n", "", "proposals", "[", "video_id", "]", "=", "np", ".", "array", "(", "this_video_proposals", ")", "\n", "", "return", "proposals", ",", "num_proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.convert_proposal_format.dump_formatted_proposal": [[53, 99], ["formatted_proposal_file.write", "formatted_proposal_file.write", "numpy.amax", "numpy.argmax", "numpy.amax", "numpy.argmax", "range", "formatted_proposal_file.write", "formatted_proposal_file.write", "formatted_proposal_file.write", "int", "int"], "function", ["None"], ["", "def", "dump_formatted_proposal", "(", "video_idx", ",", "video_id", ",", "num_frames", ",", "fps", ",", "gts", ",", "\n", "proposals", ",", "tiou", ",", "t_overlap_self", ",", "\n", "formatted_proposal_file", ")", ":", "\n", "    ", "\"\"\"dump the formatted proposal file, which is the input proposal file of\n    action classifier (e.g: SSN).\n\n    Args:\n        video_idx (int): Index of video.\n        video_id (str): ID of video.\n        num_frames (int): Total frames of the video.\n        fps (float): Fps of the video.\n        gts (np.ndarray[float]): t_start, t_end and label of groundtruths.\n        proposals (np.ndarray[float]): t_start, t_end and score of proposals.\n        tiou (np.ndarray[float]): 2-dim array with IoU ratio.\n        t_overlap_self (np.ndarray[float]): 2-dim array with overlap_self\n            (union / self_len) ratio.\n        formatted_proposal_file (open file object): Open file object of\n            formatted_proposal_file.\n    \"\"\"", "\n", "\n", "formatted_proposal_file", ".", "write", "(", "\n", "f'#{video_idx}\\n{video_id}\\n{num_frames}\\n{fps}\\n{gts.shape[0]}\\n'", ")", "\n", "for", "gt", "in", "gts", ":", "\n", "        ", "formatted_proposal_file", ".", "write", "(", "f'{int(gt[2])} {gt[0]} {gt[1]}\\n'", ")", "\n", "", "formatted_proposal_file", ".", "write", "(", "f'{proposals.shape[0]}\\n'", ")", "\n", "\n", "best_iou", "=", "np", ".", "amax", "(", "tiou", ",", "axis", "=", "0", ")", "\n", "best_iou_index", "=", "np", ".", "argmax", "(", "tiou", ",", "axis", "=", "0", ")", "\n", "best_overlap", "=", "np", ".", "amax", "(", "t_overlap_self", ",", "axis", "=", "0", ")", "\n", "best_overlap_index", "=", "np", ".", "argmax", "(", "t_overlap_self", ",", "axis", "=", "0", ")", "\n", "\n", "for", "i", "in", "range", "(", "proposals", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "index_iou", "=", "best_iou_index", "[", "i", "]", "\n", "index_overlap", "=", "best_overlap_index", "[", "i", "]", "\n", "label_iou", "=", "gts", "[", "index_iou", "]", "[", "2", "]", "\n", "label_overlap", "=", "gts", "[", "index_overlap", "]", "[", "2", "]", "\n", "if", "label_iou", "!=", "label_overlap", ":", "\n", "            ", "label", "=", "label_iou", "if", "label_iou", "!=", "0", "else", "label_overlap", "\n", "", "else", ":", "\n", "            ", "label", "=", "label_iou", "\n", "", "if", "best_iou", "[", "i", "]", "==", "0", "and", "best_overlap", "[", "i", "]", "==", "0", ":", "\n", "            ", "formatted_proposal_file", ".", "write", "(", "\n", "f'0 0 0 {proposals[i][0]} {proposals[i][1]}\\n'", ")", "\n", "", "else", ":", "\n", "            ", "formatted_proposal_file", ".", "write", "(", "\n", "f'{int(label)} {best_iou[i]} {best_overlap[i]} '", "\n", "f'{proposals[i][0]} {proposals[i][1]}\\n'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.convert_proposal_format.parse_args": [[102, 129], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'convert proposal format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ann-file'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'../../../data/ActivityNet/anet_anno_val.json'", ",", "\n", "help", "=", "'name of annotation file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--activity-index-file'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'../../../data/ActivityNet/anet_activity_indexes_val.txt'", ",", "\n", "help", "=", "'name of activity index file'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--proposal-file'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'../../../results.json'", ",", "\n", "help", "=", "'name of proposal file, which is the'", "\n", "'output of proposal generator (BMN)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--formatted-proposal-file'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'../../../anet_val_formatted_proposal.txt'", ",", "\n", "help", "=", "'name of formatted proposal file, which is the'", "\n", "'input of action classifier (SSN)'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.tsn_feature_extraction.parse_args": [[14, 38], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extract TSN Feature'", ")", "\n", "parser", ".", "add_argument", "(", "'--data-prefix'", ",", "default", "=", "''", ",", "help", "=", "'dataset prefix'", ")", "\n", "parser", ".", "add_argument", "(", "'--output-prefix'", ",", "default", "=", "''", ",", "help", "=", "'output prefix'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--data-list'", ",", "\n", "help", "=", "'video list of the dataset, the format should be '", "\n", "'`frame_dir num_frames output_file`'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--frame-interval'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "16", ",", "\n", "help", "=", "'the sampling frequency of frame in the untrimed video'", ")", "\n", "parser", ".", "add_argument", "(", "'--modality'", ",", "default", "=", "'RGB'", ",", "choices", "=", "[", "'RGB'", ",", "'Flow'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt'", ",", "help", "=", "'checkpoint for feature extraction'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--part'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "'which part of dataset to forward(alldata[part::total])'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--total'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'how many parts exist'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.tsn_feature_extraction.main": [[40, 145], ["tsn_feature_extraction.parse_args", "dict", "dict", "mmaction.datasets.pipelines.Compose", "dict", "mmaction.models.build_model", "model.cuda.load_state_dict", "model.cuda.cuda", "model.cuda.eval", "open().readlines", "mmcv.ProgressBar", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "torch.load", "x.strip", "len", "os.exists", "os.system", "os.system", "item.split", "os.join", "os.join", "osp.join.endswith", "int", "dict", "mmaction.datasets.pipelines.Compose.", "imgs.cuda.reshape", "imgs.cuda.cuda", "tsn_feature_extraction.main.forward_data"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "args", ".", "is_rgb", "=", "args", ".", "modality", "==", "'RGB'", "\n", "args", ".", "clip_len", "=", "1", "if", "args", ".", "is_rgb", "else", "5", "\n", "args", ".", "input_format", "=", "'NCHW'", "if", "args", ".", "is_rgb", "else", "'NCHW_Flow'", "\n", "rgb_norm_cfg", "=", "dict", "(", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ",", "\n", "to_bgr", "=", "False", ")", "\n", "flow_norm_cfg", "=", "dict", "(", "mean", "=", "[", "128", ",", "128", "]", ",", "std", "=", "[", "128", ",", "128", "]", ")", "\n", "args", ".", "img_norm_cfg", "=", "rgb_norm_cfg", "if", "args", ".", "is_rgb", "else", "flow_norm_cfg", "\n", "args", ".", "f_tmpl", "=", "'img_{:05d}.jpg'", "if", "args", ".", "is_rgb", "else", "'flow_{}_{:05d}.jpg'", "\n", "args", ".", "in_channels", "=", "args", ".", "clip_len", "*", "(", "3", "if", "args", ".", "is_rgb", "else", "2", ")", "\n", "# max batch_size for one forward", "\n", "args", ".", "batch_size", "=", "200", "\n", "\n", "# define the data pipeline for Untrimmed Videos", "\n", "data_pipeline", "=", "[", "\n", "dict", "(", "\n", "type", "=", "'UntrimmedSampleFrames'", ",", "\n", "clip_len", "=", "args", ".", "clip_len", ",", "\n", "frame_interval", "=", "args", ".", "frame_interval", ",", "\n", "start_index", "=", "0", ")", ",", "\n", "dict", "(", "type", "=", "'FrameSelector'", ")", ",", "\n", "dict", "(", "type", "=", "'Resize'", ",", "scale", "=", "(", "-", "1", ",", "256", ")", ")", ",", "\n", "dict", "(", "type", "=", "'CenterCrop'", ",", "crop_size", "=", "256", ")", ",", "\n", "dict", "(", "type", "=", "'Normalize'", ",", "**", "args", ".", "img_norm_cfg", ")", ",", "\n", "dict", "(", "type", "=", "'FormatShape'", ",", "input_format", "=", "args", ".", "input_format", ")", ",", "\n", "dict", "(", "type", "=", "'Collect'", ",", "keys", "=", "[", "'imgs'", "]", ",", "meta_keys", "=", "[", "]", ")", ",", "\n", "dict", "(", "type", "=", "'ToTensor'", ",", "keys", "=", "[", "'imgs'", "]", ")", "\n", "]", "\n", "data_pipeline", "=", "Compose", "(", "data_pipeline", ")", "\n", "\n", "# define TSN R50 model, the model is used as the feature extractor", "\n", "model_cfg", "=", "dict", "(", "\n", "type", "=", "'Recognizer2D'", ",", "\n", "backbone", "=", "dict", "(", "\n", "type", "=", "'ResNet'", ",", "\n", "depth", "=", "50", ",", "\n", "in_channels", "=", "args", ".", "in_channels", ",", "\n", "norm_eval", "=", "False", ")", ",", "\n", "cls_head", "=", "dict", "(", "\n", "type", "=", "'TSNHead'", ",", "\n", "num_classes", "=", "200", ",", "\n", "in_channels", "=", "2048", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "consensus", "=", "dict", "(", "type", "=", "'AvgConsensus'", ",", "dim", "=", "1", ")", ")", ",", "\n", "test_cfg", "=", "dict", "(", "average_clips", "=", "None", ")", ")", "\n", "model", "=", "build_model", "(", "model_cfg", ")", "\n", "# load pretrained weight into the feature extractor", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "ckpt", ")", "[", "'state_dict'", "]", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "data", "=", "open", "(", "args", ".", "data_list", ")", ".", "readlines", "(", ")", "\n", "data", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "data", "]", "\n", "data", "=", "data", "[", "args", ".", "part", ":", ":", "args", ".", "total", "]", "\n", "\n", "# enumerate Untrimmed videos, extract feature from each of them", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "data", ")", ")", "\n", "if", "not", "osp", ".", "exists", "(", "args", ".", "output_prefix", ")", ":", "\n", "        ", "os", ".", "system", "(", "f'mkdir -p {args.output_prefix}'", ")", "\n", "\n", "", "for", "item", "in", "data", ":", "\n", "        ", "frame_dir", ",", "length", ",", "_", "=", "item", ".", "split", "(", ")", "\n", "output_file", "=", "osp", ".", "basename", "(", "frame_dir", ")", "+", "'.pkl'", "\n", "frame_dir", "=", "osp", ".", "join", "(", "args", ".", "data_prefix", ",", "frame_dir", ")", "\n", "output_file", "=", "osp", ".", "join", "(", "args", ".", "output_prefix", ",", "output_file", ")", "\n", "assert", "output_file", ".", "endswith", "(", "'.pkl'", ")", "\n", "length", "=", "int", "(", "length", ")", "\n", "\n", "# prepare a psuedo sample", "\n", "tmpl", "=", "dict", "(", "\n", "frame_dir", "=", "frame_dir", ",", "\n", "total_frames", "=", "length", ",", "\n", "filename_tmpl", "=", "args", ".", "f_tmpl", ",", "\n", "start_index", "=", "0", ",", "\n", "modality", "=", "args", ".", "modality", ")", "\n", "sample", "=", "data_pipeline", "(", "tmpl", ")", "\n", "imgs", "=", "sample", "[", "'imgs'", "]", "\n", "shape", "=", "imgs", ".", "shape", "\n", "# the original shape should be N_seg * C * H * W, resize it to N_seg *", "\n", "# 1 * C * H * W so that the network return feature of each frame (No", "\n", "# score average among segments)", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "shape", "[", "0", "]", ",", "1", ")", "+", "shape", "[", "1", ":", "]", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "\n", "def", "forward_data", "(", "model", ",", "data", ")", ":", "\n", "# chop large data into pieces and extract feature from them", "\n", "            ", "results", "=", "[", "]", "\n", "start_idx", "=", "0", "\n", "num_clip", "=", "data", ".", "shape", "[", "0", "]", "\n", "while", "start_idx", "<", "num_clip", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "part", "=", "data", "[", "start_idx", ":", "start_idx", "+", "args", ".", "batch_size", "]", "\n", "feat", "=", "model", ".", "forward", "(", "part", ",", "return_loss", "=", "False", ")", "\n", "results", ".", "append", "(", "feat", ")", "\n", "start_idx", "+=", "args", ".", "batch_size", "\n", "", "", "return", "np", ".", "concatenate", "(", "results", ")", "\n", "\n", "", "feat", "=", "forward_data", "(", "model", ",", "imgs", ")", "\n", "with", "open", "(", "output_file", ",", "'wb'", ")", "as", "fout", ":", "\n", "            ", "pickle", ".", "dump", "(", "feat", ",", "fout", ")", "\n", "", "prog_bar", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.activitynet_feature_postprocessing.parse_args": [[13, 21], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'ANet Feature Prepare'", ")", "\n", "parser", ".", "add_argument", "(", "'--rgb'", ",", "default", "=", "''", ",", "help", "=", "'rgb feature root'", ")", "\n", "parser", ".", "add_argument", "(", "'--flow'", ",", "default", "=", "''", ",", "help", "=", "'flow feature root'", ")", "\n", "parser", ".", "add_argument", "(", "'--dest'", ",", "default", "=", "''", ",", "help", "=", "'dest root'", ")", "\n", "parser", ".", "add_argument", "(", "'--output-format'", ",", "default", "=", "'csv'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.activitynet_feature_postprocessing.pool_feature": [[23, 63], ["list", "scipy.interpolate.interp1d", "range", "numpy.stack", "len", "numpy.concatenate", "range", "scipy.interpolate.interp1d.", "np.stack.append", "len", "numpy.mean", "len", "range", "numpy.max", "NotImplementedError"], "function", ["None"], ["", "def", "pool_feature", "(", "data", ",", "num_proposals", "=", "100", ",", "num_sample_bins", "=", "3", ",", "pool_type", "=", "'mean'", ")", ":", "\n", "    ", "\"\"\"Pool features with arbitrary temporal length.\n\n    Args:\n        data (list[np.ndarray] | np.ndarray): Features of an untrimmed video,\n            with arbitrary temporal length.\n        num_proposals (int): The temporal dim of pooled feature. Default: 100.\n        num_sample_bins (int): How many points to sample to get the feature\n            vector at one timestamp. Default: 3.\n        pool_type (str): Type of pooling to pool features. Choices are\n            ['mean', 'max']. Default: 'mean'.\n\n    Returns:\n        np.ndarray: The pooled feature with shape num_proposals x feature_dim.\n    \"\"\"", "\n", "if", "len", "(", "data", ")", "==", "1", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "[", "data", "]", "*", "num_proposals", ")", "\n", "", "x_range", "=", "list", "(", "range", "(", "len", "(", "data", ")", ")", ")", "\n", "f", "=", "scipy", ".", "interpolate", ".", "interp1d", "(", "x_range", ",", "data", ",", "axis", "=", "0", ")", "\n", "eps", "=", "1e-4", "\n", "start", ",", "end", "=", "eps", ",", "len", "(", "data", ")", "-", "1", "-", "eps", "\n", "anchor_size", "=", "(", "end", "-", "start", ")", "/", "num_proposals", "\n", "ptr", "=", "start", "\n", "feature", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_proposals", ")", ":", "\n", "        ", "x_new", "=", "[", "\n", "ptr", "+", "i", "/", "num_sample_bins", "*", "anchor_size", "\n", "for", "i", "in", "range", "(", "num_sample_bins", ")", "\n", "]", "\n", "y_new", "=", "f", "(", "x_new", ")", "\n", "if", "pool_type", "==", "'mean'", ":", "\n", "            ", "y_new", "=", "np", ".", "mean", "(", "y_new", ",", "axis", "=", "0", ")", "\n", "", "elif", "pool_type", "==", "'max'", ":", "\n", "            ", "y_new", "=", "np", ".", "max", "(", "y_new", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Unsupported pool type'", ")", "\n", "", "feature", ".", "append", "(", "y_new", ")", "\n", "ptr", "+=", "anchor_size", "\n", "", "feature", "=", "np", ".", "stack", "(", "feature", ")", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.activitynet_feature_postprocessing.merge_feat": [[65, 85], ["mmcv.load", "mmcv.load", "activitynet_feature_postprocessing.pool_feature", "activitynet_feature_postprocessing.pool_feature", "numpy.concatenate", "os.join", "os.join", "os.exists", "os.system", "os.system", "mmcv.dump", "os.join", "feat.tolist.tolist", "lines.append", "lines.append", "open", "f.write", "os.join", "range", "name.replace"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.activitynet_feature_postprocessing.pool_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.activitynet_feature_postprocessing.pool_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "merge_feat", "(", "name", ")", ":", "\n", "# concatenate rgb feat and flow feat for a single sample", "\n", "    ", "rgb_feat", "=", "load", "(", "osp", ".", "join", "(", "args", ".", "rgb", ",", "name", ")", ")", "\n", "flow_feat", "=", "load", "(", "osp", ".", "join", "(", "args", ".", "flow", ",", "name", ")", ")", "\n", "rgb_feat", "=", "pool_feature", "(", "rgb_feat", ")", "\n", "flow_feat", "=", "pool_feature", "(", "flow_feat", ")", "\n", "feat", "=", "np", ".", "concatenate", "(", "[", "rgb_feat", ",", "flow_feat", "]", ",", "axis", "=", "-", "1", ")", "\n", "if", "not", "osp", ".", "exists", "(", "args", ".", "dest", ")", ":", "\n", "        ", "os", ".", "system", "(", "f'mkdir -p {args.dest}'", ")", "\n", "", "if", "args", ".", "output_format", "==", "'pkl'", ":", "\n", "        ", "dump", "(", "feat", ",", "osp", ".", "join", "(", "args", ".", "dest", ",", "name", ")", ")", "\n", "", "elif", "args", ".", "output_format", "==", "'csv'", ":", "\n", "        ", "feat", "=", "feat", ".", "tolist", "(", ")", "\n", "lines", "=", "[", "]", "\n", "line0", "=", "','", ".", "join", "(", "[", "f'f{i}'", "for", "i", "in", "range", "(", "400", ")", "]", ")", "\n", "lines", ".", "append", "(", "line0", ")", "\n", "for", "line", "in", "feat", ":", "\n", "            ", "lines", ".", "append", "(", "','", ".", "join", "(", "[", "f'{x:.4f}'", "for", "x", "in", "line", "]", ")", ")", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "args", ".", "dest", ",", "name", ".", "replace", "(", "'.pkl'", ",", "'.csv'", ")", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.activitynet_feature_postprocessing.main": [[87, 95], ["activitynet_feature_postprocessing.parse_args", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "multiprocessing.Pool", "multiprocessing.Pool.map", "set", "set"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "global", "args", "\n", "args", "=", "parse_args", "(", ")", "\n", "rgb_feat", "=", "os", ".", "listdir", "(", "args", ".", "rgb", ")", "\n", "flow_feat", "=", "os", ".", "listdir", "(", "args", ".", "flow", ")", "\n", "assert", "set", "(", "rgb_feat", ")", "==", "set", "(", "flow_feat", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "32", ")", "\n", "pool", ".", "map", "(", "merge_feat", ",", "rgb_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.parse_args": [[17, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["ssl", ".", "_create_default_https_context", "=", "ssl", ".", "_create_unverified_context", "\n", "args", "=", "None", "\n", "\n", "\n", "def", "create_video_folders", "(", "output_dir", ",", "tmp_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "tmp_dir", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip": [[27, 69], ["isinstance", "isinstance", "os.path.exists", "len", "os.path.exists", "print", "subprocess.check_output"], "function", ["None"], ["\n", "", "", "def", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Given a dataset row, this function constructs the output filename for a\n    given video.\"\"\"", "\n", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "start_time", ",", "end_time", "=", "int", "(", "start_time", "*", "10", ")", ",", "int", "(", "end_time", "*", "10", ")", "\n", "basename", "=", "'%s_%s_%s.mp4'", "%", "(", "youtube_id", ",", "trim_format", "%", "start_time", ",", "\n", "trim_format", "%", "end_time", ")", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "basename", ")", "\n", "return", "output_filename", "\n", "\n", "\n", "", "def", "download_clip", "(", "video_identifier", ",", "\n", "output_filename", ",", "\n", "start_time", ",", "\n", "end_time", ",", "\n", "tmp_dir", "=", "'/tmp/hvu'", ",", "\n", "num_attempts", "=", "5", ",", "\n", "url_base", "=", "'https://www.youtube.com/watch?v='", ")", ":", "\n", "    ", "\"\"\"Download a video from youtube if exists and is not blocked.\n    arguments:\n    ---------\n    video_identifier: str\n        Unique YouTube video identifier (11 characters)\n    output_filename: str\n        File path where the video will be stored.\n    start_time: float\n        Indicates the begining time in seconds from where the video\n        will be trimmed.\n    end_time: float\n        Indicates the ending time in seconds of the trimmed video.\n    \"\"\"", "\n", "# Defensive argument checking.", "\n", "assert", "isinstance", "(", "video_identifier", ",", "str", ")", ",", "'video_identifier must be string'", "\n", "assert", "isinstance", "(", "output_filename", ",", "str", ")", ",", "'output_filename must be string'", "\n", "assert", "len", "(", "video_identifier", ")", "==", "11", ",", "'video_identifier must have length 11'", "\n", "\n", "status", "=", "False", "\n", "tmp_filename", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'%s.%%(ext)s'", "%", "uuid", ".", "uuid4", "(", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_filename", ")", ":", "\n", "            ", "command", "=", "[", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip_wrapper": [[71, 82], ["os.path.join", "os.path.exists", "download.download_clip", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip"], ["'--no-check-certificate'", ",", "'-f'", ",", "'mp4'", ",", "'-o'", ",", "\n", "'\"%s\"'", "%", "tmp_filename", ",", "\n", "'\"%s\"'", "%", "(", "url_base", "+", "video_identifier", ")", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "print", "(", "command", ")", "\n", "attempts", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.parse_activitynet_annotations": [[84, 107], ["open().readlines", "list", "mmcv.load", "data.keys", "open", "x.split"], "function", ["None"], ["if", "attempts", "==", "num_attempts", ":", "\n", "                        ", "return", "status", ",", "'Downloading Failed'", "\n", "", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "tmp_filename", "=", "glob", ".", "glob", "(", "'%s*'", "%", "tmp_filename", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "[", "0", "]", "\n", "# Construct command to trim the videos (ffmpeg required).", "\n", "command", "=", "[", "\n", "'ffmpeg'", ",", "'-i'", ",", "\n", "'\"%s\"'", "%", "tmp_filename", ",", "'-ss'", ",", "\n", "str", "(", "start_time", ")", ",", "'-t'", ",", "\n", "str", "(", "end_time", "-", "start_time", ")", ",", "'-c:v'", ",", "'libx264'", ",", "'-c:a'", ",", "'copy'", ",", "\n", "'-threads'", ",", "'1'", ",", "'-loglevel'", ",", "'panic'", ",", "\n", "'\"%s\"'", "%", "output_filename", "\n", "]", "\n", "command", "=", "' '", ".", "join", "(", "command", ")", "\n", "try", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "\n", "command", ",", "shell", "=", "True", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "            ", "return", "status", ",", "'Trimming Failed'", "\n", "\n", "# Check if the video was successfully saved.", "\n", "", "", "status", "=", "os", ".", "path", ".", "exists", "(", "output_filename", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.main": [[109, 136], ["download.parse_activitynet_annotations", "mmcv.dump", "mmcv.load", "os.path.exists", "os.makedirs", "anno_file.replace", "os.system", "mmcv.dump", "status_list.append", "joblib.Parallel", "mmcv.load.items", "download.download_clip_wrapper", "joblib.delayed"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.parse_activitynet_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.download.download_clip_wrapper"], ["return", "status", ",", "'Downloaded'", "\n", "\n", "\n", "", "def", "download_clip_wrapper", "(", "item", ",", "trim_format", ",", "tmp_dir", ",", "output_dir", ")", ":", "\n", "    ", "\"\"\"Wrapper for parallel processing purposes.\"\"\"", "\n", "output_filename", "=", "construct_video_filename", "(", "item", ",", "trim_format", ",", "output_dir", ")", "\n", "clip_id", "=", "os", ".", "path", ".", "basename", "(", "output_filename", ")", ".", "split", "(", "'.mp4'", ")", "[", "0", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "output_filename", ")", ":", "\n", "        ", "status", "=", "tuple", "(", "[", "clip_id", ",", "True", ",", "'Exists'", "]", ")", "\n", "return", "status", "\n", "\n", "", "youtube_id", ",", "start_time", ",", "end_time", "=", "item", "\n", "downloaded", ",", "log", "=", "download_clip", "(", "\n", "youtube_id", ",", "output_filename", ",", "start_time", ",", "end_time", ",", "tmp_dir", "=", "tmp_dir", ")", "\n", "\n", "status", "=", "tuple", "(", "[", "clip_id", ",", "downloaded", ",", "log", "]", ")", "\n", "return", "status", "\n", "\n", "\n", "", "def", "parse_hvu_annotations", "(", "input_csv", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.activitynet.generate_rawframes_filelist.generate_rawframes_filelist": [[17, 109], ["json.load", "open().readlines", "open", "x.strip", "os.join", "os.join", "open().readlines.index", "generate_rawframes_filelist.generate_rawframes_filelist.count_frames"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "generate_rawframes_filelist", "(", ")", ":", "\n", "    ", "load_dict", "=", "json", ".", "load", "(", "open", "(", "json_file", ")", ")", "\n", "\n", "anet_labels", "=", "open", "(", "action_name_list", ")", ".", "readlines", "(", ")", "\n", "anet_labels", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "anet_labels", "[", "1", ":", "]", "]", "\n", "\n", "train_dir_list", "=", "[", "\n", "osp", ".", "join", "(", "train_rawframe_dir", ",", "x", ")", "for", "x", "in", "os", ".", "listdir", "(", "train_rawframe_dir", ")", "\n", "]", "\n", "val_dir_list", "=", "[", "\n", "osp", ".", "join", "(", "val_rawframe_dir", ",", "x", ")", "for", "x", "in", "os", ".", "listdir", "(", "val_rawframe_dir", ")", "\n", "]", "\n", "\n", "def", "simple_label", "(", "anno", ")", ":", "\n", "        ", "label", "=", "anno", "[", "0", "]", "[", "'label'", "]", "\n", "return", "anet_labels", ".", "index", "(", "label", ")", "\n", "\n", "", "def", "count_frames", "(", "dir_list", ",", "video", ")", ":", "\n", "        ", "for", "dir_name", "in", "dir_list", ":", "\n", "            ", "if", "video", "in", "dir_name", ":", "\n", "                ", "return", "osp", ".", "basename", "(", "dir_name", ")", ",", "len", "(", "os", ".", "listdir", "(", "dir_name", ")", ")", "\n", "", "", "return", "None", ",", "None", "\n", "\n", "", "database", "=", "load_dict", "[", "'database'", "]", "\n", "training", "=", "{", "}", "\n", "validation", "=", "{", "}", "\n", "key_dict", "=", "{", "}", "\n", "\n", "for", "k", "in", "database", ":", "\n", "        ", "data", "=", "database", "[", "k", "]", "\n", "subset", "=", "data", "[", "'subset'", "]", "\n", "\n", "if", "subset", "in", "[", "'training'", ",", "'validation'", "]", ":", "\n", "            ", "annotations", "=", "data", "[", "'annotations'", "]", "\n", "label", "=", "simple_label", "(", "annotations", ")", "\n", "if", "subset", "==", "'training'", ":", "\n", "                ", "dir_list", "=", "train_dir_list", "\n", "data_dict", "=", "training", "\n", "", "else", ":", "\n", "                ", "dir_list", "=", "val_dir_list", "\n", "data_dict", "=", "validation", "\n", "\n", "", "", "else", ":", "\n", "            ", "continue", "\n", "\n", "", "gt_dir_name", ",", "num_frames", "=", "count_frames", "(", "dir_list", ",", "k", ")", "\n", "if", "gt_dir_name", "is", "None", ":", "\n", "            ", "continue", "\n", "", "data_dict", "[", "gt_dir_name", "]", "=", "[", "num_frames", ",", "label", "]", "\n", "key_dict", "[", "gt_dir_name", "]", "=", "k", "\n", "\n", "", "train_lines", "=", "[", "\n", "k", "+", "' '", "+", "str", "(", "training", "[", "k", "]", "[", "0", "]", ")", "+", "' '", "+", "str", "(", "training", "[", "k", "]", "[", "1", "]", ")", "\n", "for", "k", "in", "training", "\n", "]", "\n", "val_lines", "=", "[", "\n", "k", "+", "' '", "+", "str", "(", "validation", "[", "k", "]", "[", "0", "]", ")", "+", "' '", "+", "str", "(", "validation", "[", "k", "]", "[", "1", "]", ")", "\n", "for", "k", "in", "validation", "\n", "]", "\n", "\n", "with", "open", "(", "osp", ".", "join", "(", "data_file", ",", "'anet_train_video.txt'", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "train_lines", ")", ")", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "data_file", ",", "'anet_val_video.txt'", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "val_lines", ")", ")", "\n", "\n", "", "def", "clip_list", "(", "k", ",", "anno", ",", "video_anno", ")", ":", "\n", "        ", "duration", "=", "anno", "[", "'duration'", "]", "\n", "num_frames", "=", "video_anno", "[", "0", "]", "\n", "fps", "=", "num_frames", "/", "duration", "\n", "segs", "=", "anno", "[", "'annotations'", "]", "\n", "lines", "=", "[", "]", "\n", "for", "seg", "in", "segs", ":", "\n", "            ", "segment", "=", "seg", "[", "'segment'", "]", "\n", "label", "=", "seg", "[", "'label'", "]", "\n", "label", "=", "anet_labels", ".", "index", "(", "label", ")", "\n", "start", ",", "end", "=", "int", "(", "segment", "[", "0", "]", "*", "fps", ")", ",", "int", "(", "segment", "[", "1", "]", "*", "fps", ")", "\n", "if", "end", ">", "num_frames", "-", "1", ":", "\n", "                ", "end", "=", "num_frames", "-", "1", "\n", "", "newline", "=", "f'{k} {start} {end - start + 1} {label}'", "\n", "lines", ".", "append", "(", "newline", ")", "\n", "", "return", "lines", "\n", "\n", "", "train_clips", ",", "val_clips", "=", "[", "]", ",", "[", "]", "\n", "for", "k", "in", "training", ":", "\n", "        ", "train_clips", ".", "extend", "(", "clip_list", "(", "k", ",", "database", "[", "key_dict", "[", "k", "]", "]", ",", "training", "[", "k", "]", ")", ")", "\n", "", "for", "k", "in", "validation", ":", "\n", "        ", "val_clips", ".", "extend", "(", "clip_list", "(", "k", ",", "database", "[", "key_dict", "[", "k", "]", "]", ",", "validation", "[", "k", "]", ")", ")", "\n", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "data_file", ",", "'anet_train_clip.txt'", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "train_clips", ")", ")", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "data_file", ",", "'anet_val_clip.txt'", ")", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "val_clips", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.omnisource.trim_raw_video.get_duration": [[9, 16], ["str", "[].strip", "[].strip.split", "subprocess.check_output", "float", "[].split", "int", "int", "[].strip.split"], "function", ["None"], ["def", "get_duration", "(", "vid_name", ")", ":", "\n", "    ", "command", "=", "f'ffprobe -i {vid_name} 2>&1 | grep \"Duration\"'", "\n", "output", "=", "str", "(", "check_output", "(", "command", ",", "shell", "=", "True", ")", ")", "\n", "output", "=", "output", ".", "split", "(", "','", ")", "[", "0", "]", ".", "split", "(", "'Duration:'", ")", "[", "1", "]", ".", "strip", "(", ")", "\n", "h", ",", "m", ",", "s", "=", "output", ".", "split", "(", "':'", ")", "\n", "duration", "=", "int", "(", "h", ")", "*", "3600", "+", "int", "(", "m", ")", "*", "60", "+", "float", "(", "s", ")", "\n", "return", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.omnisource.trim_raw_video.trim": [[18, 40], ["os.splitext", "mmcv.mkdir_or_exist", "os.remove", "os.remove", "trim_raw_video.get_duration", "os.system", "os.system", "print", "command_tmpl.format"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.omnisource.trim_raw_video.get_duration"], ["", "def", "trim", "(", "vid_name", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "lt", "=", "get_duration", "(", "vid_name", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "print", "(", "f'get_duration failed for video {vid_name}'", ",", "flush", "=", "True", ")", "\n", "return", "\n", "\n", "", "i", "=", "0", "\n", "name", ",", "_", "=", "osp", ".", "splitext", "(", "vid_name", ")", "\n", "\n", "# We output 10-second clips into the folder `name`", "\n", "dest", "=", "name", "\n", "mmcv", ".", "mkdir_or_exist", "(", "dest", ")", "\n", "\n", "command_tmpl", "=", "(", "'ffmpeg -y loglevel error -i {} -ss {} -t {} -crf 18 '", "\n", "'-c:v libx264 {}/part_{}.mp4'", ")", "\n", "while", "i", "*", "10", "<", "lt", ":", "\n", "        ", "os", ".", "system", "(", "command_tmpl", ".", "format", "(", "vid_name", ",", "i", "*", "10", ",", "10", ",", "dest", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "# remove a raw video after decomposing it into 10-second clip to save space", "\n", "", "os", ".", "remove", "(", "vid_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.pytorch2onnx._convert_batchnorm": [[22, 42], ["isinstance", "module.named_children", "torch.nn.BatchNorm3d", "torch.nn.BatchNorm3d.add_module", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "pytorch2onnx._convert_batchnorm", "module.weight.data.clone", "module.bias.data.clone"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.pytorch2onnx._convert_batchnorm"], ["", "def", "_convert_batchnorm", "(", "module", ")", ":", "\n", "    ", "\"\"\"Convert the syncBNs into normal BN3ds.\"\"\"", "\n", "module_output", "=", "module", "\n", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "SyncBatchNorm", ")", ":", "\n", "        ", "module_output", "=", "torch", ".", "nn", ".", "BatchNorm3d", "(", "module", ".", "num_features", ",", "module", ".", "eps", ",", "\n", "module", ".", "momentum", ",", "module", ".", "affine", ",", "\n", "module", ".", "track_running_stats", ")", "\n", "if", "module", ".", "affine", ":", "\n", "            ", "module_output", ".", "weight", ".", "data", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "module_output", ".", "bias", ".", "data", "=", "module", ".", "bias", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "# keep requires_grad unchanged", "\n", "module_output", ".", "weight", ".", "requires_grad", "=", "module", ".", "weight", ".", "requires_grad", "\n", "module_output", ".", "bias", ".", "requires_grad", "=", "module", ".", "bias", ".", "requires_grad", "\n", "", "module_output", ".", "running_mean", "=", "module", ".", "running_mean", "\n", "module_output", ".", "running_var", "=", "module", ".", "running_var", "\n", "module_output", ".", "num_batches_tracked", "=", "module", ".", "num_batches_tracked", "\n", "", "for", "name", ",", "child", "in", "module", ".", "named_children", "(", ")", ":", "\n", "        ", "module_output", ".", "add_module", "(", "name", ",", "_convert_batchnorm", "(", "child", ")", ")", "\n", "", "del", "module", "\n", "return", "module_output", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.pytorch2onnx.pytorch2onnx": [[44, 102], ["model.cpu().eval", "torch.randn", "register_extra_symbolics", "torch.onnx.export", "print", "onnx.load", "onnx.checker.check_model", "[].detach().numpy", "list", "rt.InferenceSession", "numpy.random.randint", "numpy.allclose", "print", "model.cpu", "len", "rt.InferenceSession.run", "[].detach", "set", "set", "torch.randn.detach().numpy", "model", "torch.randn.detach"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["", "def", "pytorch2onnx", "(", "model", ",", "\n", "input_shape", ",", "\n", "opset_version", "=", "11", ",", "\n", "show", "=", "False", ",", "\n", "output_file", "=", "'tmp.onnx'", ",", "\n", "verify", "=", "False", ")", ":", "\n", "    ", "\"\"\"Convert pytorch model to onnx model.\n\n    Args:\n        model (:obj:`nn.Module`): The pytorch model to be exported.\n        input_shape (tuple[int]): The input tensor shape of the model.\n        opset_version (int): Opset version of onnx used. Default: 11.\n        show (bool): Determines whether to print the onnx model architecture.\n            Default: False.\n        output_file (str): Output onnx model name. Default: 'tmp.onnx'.\n        verify (bool): Determines whether to verify the onnx model.\n            Default: False.\n    \"\"\"", "\n", "model", ".", "cpu", "(", ")", ".", "eval", "(", ")", "\n", "\n", "input_tensor", "=", "torch", ".", "randn", "(", "input_shape", ")", "\n", "\n", "register_extra_symbolics", "(", "opset_version", ")", "\n", "torch", ".", "onnx", ".", "export", "(", "\n", "model", ",", "\n", "input_tensor", ",", "\n", "output_file", ",", "\n", "export_params", "=", "True", ",", "\n", "keep_initializers_as_inputs", "=", "True", ",", "\n", "verbose", "=", "show", ",", "\n", "opset_version", "=", "opset_version", ")", "\n", "\n", "print", "(", "f'Successfully exported ONNX model: {output_file}'", ")", "\n", "if", "verify", ":", "\n", "# check by onnx", "\n", "        ", "onnx_model", "=", "onnx", ".", "load", "(", "output_file", ")", "\n", "onnx", ".", "checker", ".", "check_model", "(", "onnx_model", ")", "\n", "\n", "# check the numerical value", "\n", "# get pytorch output", "\n", "pytorch_result", "=", "model", "(", "input_tensor", ")", "[", "0", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# get onnx output", "\n", "input_all", "=", "[", "node", ".", "name", "for", "node", "in", "onnx_model", ".", "graph", ".", "input", "]", "\n", "input_initializer", "=", "[", "\n", "node", ".", "name", "for", "node", "in", "onnx_model", ".", "graph", ".", "initializer", "\n", "]", "\n", "net_feed_input", "=", "list", "(", "set", "(", "input_all", ")", "-", "set", "(", "input_initializer", ")", ")", "\n", "assert", "len", "(", "net_feed_input", ")", "==", "1", "\n", "sess", "=", "rt", ".", "InferenceSession", "(", "output_file", ")", "\n", "onnx_result", "=", "sess", ".", "run", "(", "\n", "None", ",", "{", "net_feed_input", "[", "0", "]", ":", "input_tensor", ".", "detach", "(", ")", ".", "numpy", "(", ")", "}", ")", "[", "0", "]", "\n", "# only compare part of results", "\n", "random_class", "=", "np", ".", "random", ".", "randint", "(", "pytorch_result", ".", "shape", "[", "1", "]", ")", "\n", "assert", "np", ".", "allclose", "(", "\n", "pytorch_result", "[", ":", ",", "random_class", "]", ",", "onnx_result", "[", ":", ",", "random_class", "]", "\n", ")", ",", "'The outputs are different between Pytorch and ONNX'", "\n", "print", "(", "'The numerical values are same between Pytorch and ONNX'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.pytorch2onnx.parse_args": [[104, 132], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Convert MMAction2 models to ONNX'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'--show'", ",", "action", "=", "'store_true'", ",", "help", "=", "'show onnx graph'", ")", "\n", "parser", ".", "add_argument", "(", "'--output-file'", ",", "type", "=", "str", ",", "default", "=", "'tmp.onnx'", ")", "\n", "parser", ".", "add_argument", "(", "'--opset-version'", ",", "type", "=", "int", ",", "default", "=", "11", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verify'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'verify the onnx model output against pytorch output'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--is-localizer'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether it is a localizer'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shape'", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "'+'", ",", "\n", "default", "=", "[", "1", ",", "3", ",", "8", ",", "224", ",", "224", "]", ",", "\n", "help", "=", "'input video size'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--softmax'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'wheter to add softmax layer at the end of recognizers'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.publish_model.parse_args": [[7, 14], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Process a checkpoint to be published'", ")", "\n", "parser", ".", "add_argument", "(", "'in_file'", ",", "help", "=", "'input checkpoint filename'", ")", "\n", "parser", ".", "add_argument", "(", "'out_file'", ",", "help", "=", "'output checkpoint filename'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.publish_model.process_checkpoint": [[16, 31], ["torch.load", "torch.save", "subprocess.check_output().decode", "out_file.endswith", "subprocess.Popen", "subprocess.check_output"], "function", ["None"], ["", "def", "process_checkpoint", "(", "in_file", ",", "out_file", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "in_file", ",", "map_location", "=", "'cpu'", ")", "\n", "# remove optimizer for smaller file size", "\n", "if", "'optimizer'", "in", "checkpoint", ":", "\n", "        ", "del", "checkpoint", "[", "'optimizer'", "]", "\n", "# if it is necessary to remove some sensitive data in checkpoint['meta'],", "\n", "# add the code here.", "\n", "", "torch", ".", "save", "(", "checkpoint", ",", "out_file", ")", "\n", "sha", "=", "subprocess", ".", "check_output", "(", "[", "'sha256sum'", ",", "out_file", "]", ")", ".", "decode", "(", ")", "\n", "if", "out_file", ".", "endswith", "(", "'.pth'", ")", ":", "\n", "        ", "out_file_name", "=", "out_file", "[", ":", "-", "4", "]", "\n", "", "else", ":", "\n", "        ", "out_file_name", "=", "out_file", "\n", "", "final_file", "=", "out_file_name", "+", "f'-{sha[:8]}.pth'", "\n", "subprocess", ".", "Popen", "(", "[", "'mv'", ",", "out_file", ",", "final_file", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.publish_model.main": [[33, 36], ["publish_model.parse_args", "publish_model.process_checkpoint"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.publish_model.process_checkpoint"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "process_checkpoint", "(", "args", ".", "in_file", ",", "args", ".", "out_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.flow_to_img": [[9, 25], ["numpy.clip", "flow.astype.astype", "float"], "function", ["None"], ["def", "flow_to_img", "(", "raw_flow", ",", "bound", "=", "20.", ")", ":", "\n", "    ", "\"\"\"Convert flow to gray image.\n\n    Args:\n        raw_flow (np.ndarray[float]): Estimated flow with the shape (w, h).\n        bound (float): Bound for the flow-to-image normalization. Default: 20.\n\n    Returns:\n        np.ndarray[uint8]: The result list of np.ndarray[uint8], with shape\n                        (w, h).\n    \"\"\"", "\n", "flow", "=", "np", ".", "clip", "(", "raw_flow", ",", "-", "bound", ",", "bound", ")", "\n", "flow", "+=", "bound", "\n", "flow", "*=", "(", "255", "/", "float", "(", "2", "*", "bound", ")", ")", "\n", "flow", "=", "flow", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "return", "flow", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.generate_flow": [[27, 59], ["cv2.cvtColor", "cv2.optflow.DualTVL1OpticalFlow_create", "flow_extraction.generate_flow.op"], "function", ["None"], ["", "def", "generate_flow", "(", "frames", ",", "method", "=", "'tvl1'", ")", ":", "\n", "    ", "\"\"\"Estimate flow with given frames.\n\n    Args:\n        frames (list[np.ndarray[uint8]]): List of rgb frames, with shape\n                                        (w, h, 3).\n        method (str): Use which method to generate flow. Options are 'tvl1'\n                    and 'farneback'. Default: 'tvl1'.\n\n    Returns:\n        list[np.ndarray[float]]: The result list of np.ndarray[float], with\n                                shape (w, h, 2).\n    \"\"\"", "\n", "assert", "method", "in", "[", "'tvl1'", ",", "'farneback'", "]", "\n", "gray_frames", "=", "[", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "for", "frame", "in", "frames", "]", "\n", "\n", "if", "method", "==", "'tvl1'", ":", "\n", "        ", "tvl1", "=", "cv2", ".", "optflow", ".", "DualTVL1OpticalFlow_create", "(", ")", "\n", "\n", "def", "op", "(", "x", ",", "y", ")", ":", "\n", "            ", "return", "tvl1", ".", "calc", "(", "x", ",", "y", ",", "None", ")", "\n", "", "", "elif", "method", "==", "'farneback'", ":", "\n", "\n", "        ", "def", "op", "(", "x", ",", "y", ")", ":", "\n", "            ", "return", "cv2", ".", "calcOpticalFlowFarneback", "(", "x", ",", "y", ",", "None", ",", "0.5", ",", "3", ",", "15", ",", "3", ",", "5", ",", "\n", "1.2", ",", "0", ")", "\n", "\n", "", "", "gray_st", "=", "gray_frames", "[", ":", "-", "1", "]", "\n", "gray_ed", "=", "gray_frames", "[", "1", ":", "]", "\n", "\n", "flow", "=", "[", "op", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "zip", "(", "gray_st", ",", "gray_ed", ")", "]", "\n", "return", "flow", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.extract_dense_flow": [[61, 123], ["os.exists", "cv2.VideoCapture", "cv2.VideoCapture.read", "flow_extraction.generate_flow", "len", "range", "frames.append", "cv2.VideoCapture.read", "flow_extraction.flow_to_img", "flow_extraction.flow_to_img", "os.exists", "os.system", "os.system", "os.join", "os.join", "cv2.imwrite", "cv2.imwrite", "zip", "flow_tmpl.format", "range", "flow_tmpl.format", "range", "os.join", "cv2.imwrite", "len", "len", "rgb_tmpl.format", "range", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.generate_flow", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.flow_to_img", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.flow_to_img", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "extract_dense_flow", "(", "path", ",", "\n", "dest", ",", "\n", "bound", "=", "20.", ",", "\n", "save_rgb", "=", "False", ",", "\n", "start_idx", "=", "0", ",", "\n", "rgb_tmpl", "=", "'img_{:05d}.jpg'", ",", "\n", "flow_tmpl", "=", "'{}_{:05d}.jpg'", ",", "\n", "method", "=", "'tvl1'", ")", ":", "\n", "    ", "\"\"\"Extract dense flow given video or frames, save them as gray-scale\n    images.\n\n    Args:\n        path (str): Location of the input video.\n        dest (str): The directory to store the extracted flow images.\n        bound (float): Bound for the flow-to-image normalization. Default: 20.\n        save_rgb (bool): Save extracted RGB frames. Default: False.\n        start_idx (int): The starting frame index if use frames as input, the\n            first image is path.format(start_idx). Default: 0.\n        rgb_tmpl (str): The template of RGB frame names, Default:\n            'img_{:05d}.jpg'.\n        flow_tmpl (str): The template of Flow frame names, Default:\n            '{}_{:05d}.jpg'.\n        method (str): Use which method to generate flow. Options are 'tvl1'\n            and 'farneback'. Default: 'tvl1'.\n    \"\"\"", "\n", "\n", "frames", "=", "[", "]", "\n", "assert", "osp", ".", "exists", "(", "path", ")", "\n", "video", "=", "cv2", ".", "VideoCapture", "(", "path", ")", "\n", "flag", ",", "f", "=", "video", ".", "read", "(", ")", "\n", "while", "flag", ":", "\n", "        ", "frames", ".", "append", "(", "f", ")", "\n", "flag", ",", "f", "=", "video", ".", "read", "(", ")", "\n", "\n", "", "flow", "=", "generate_flow", "(", "frames", ",", "method", "=", "method", ")", "\n", "\n", "flow_x", "=", "[", "flow_to_img", "(", "x", "[", ":", ",", ":", ",", "0", "]", ",", "bound", ")", "for", "x", "in", "flow", "]", "\n", "flow_y", "=", "[", "flow_to_img", "(", "x", "[", ":", ",", ":", ",", "1", "]", ",", "bound", ")", "for", "x", "in", "flow", "]", "\n", "\n", "if", "not", "osp", ".", "exists", "(", "dest", ")", ":", "\n", "        ", "os", ".", "system", "(", "'mkdir -p '", "+", "dest", ")", "\n", "", "flow_x_names", "=", "[", "\n", "osp", ".", "join", "(", "dest", ",", "flow_tmpl", ".", "format", "(", "'x'", ",", "ind", "+", "start_idx", ")", ")", "\n", "for", "ind", "in", "range", "(", "len", "(", "flow_x", ")", ")", "\n", "]", "\n", "flow_y_names", "=", "[", "\n", "osp", ".", "join", "(", "dest", ",", "flow_tmpl", ".", "format", "(", "'y'", ",", "ind", "+", "start_idx", ")", ")", "\n", "for", "ind", "in", "range", "(", "len", "(", "flow_y", ")", ")", "\n", "]", "\n", "\n", "num_frames", "=", "len", "(", "flow", ")", "\n", "for", "i", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "cv2", ".", "imwrite", "(", "flow_x_names", "[", "i", "]", ",", "flow_x", "[", "i", "]", ")", "\n", "cv2", ".", "imwrite", "(", "flow_y_names", "[", "i", "]", ",", "flow_y", "[", "i", "]", ")", "\n", "\n", "", "if", "save_rgb", ":", "\n", "        ", "img_names", "=", "[", "\n", "osp", ".", "join", "(", "dest", ",", "rgb_tmpl", ".", "format", "(", "ind", "+", "start_idx", ")", ")", "\n", "for", "ind", "in", "range", "(", "len", "(", "frames", ")", ")", "\n", "]", "\n", "for", "frame", ",", "name", "in", "zip", "(", "frames", ",", "img_names", ")", ":", "\n", "            ", "cv2", ".", "imwrite", "(", "name", ",", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.flow_extraction.parse_args": [[125, 170], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extract flow and RGB images'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "\n", "help", "=", "'videos for frame extraction, can be'", "\n", "'single video or a video list, the video list should be a txt file '", "\n", "'and just consists of filenames without directories'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--prefix'", ",", "\n", "default", "=", "''", ",", "\n", "help", "=", "'the prefix of input '", "\n", "'videos, used when input is a video list'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dest'", ",", "\n", "default", "=", "''", ",", "\n", "help", "=", "'the destination to save '", "\n", "'extracted frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--save-rgb'", ",", "action", "=", "'store_true'", ",", "help", "=", "'also save '", "\n", "'rgb frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--rgb-tmpl'", ",", "\n", "default", "=", "'img_{:05d}.jpg'", ",", "\n", "help", "=", "'template filename of rgb frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--flow-tmpl'", ",", "\n", "default", "=", "'{}_{:05d}.jpg'", ",", "\n", "help", "=", "'template filename of flow frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--start-idx'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "'the start '", "\n", "'index of extracted frames'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--method'", ",", "\n", "default", "=", "'tvl1'", ",", "\n", "help", "=", "'use which method to '", "\n", "'generate flow'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--bound'", ",", "type", "=", "float", ",", "default", "=", "20", ",", "help", "=", "'maximum of '", "\n", "'optical flow'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.load_video_infos": [[13, 29], ["mmcv.load", "video_infos.append"], "function", ["None"], ["def", "load_video_infos", "(", "ann_file", ")", ":", "\n", "    ", "\"\"\"Load the video annotations.\n\n    Args:\n        ann_file (str): A json file path of the annotation file.\n\n    Returns:\n        list[dict]: A list containing annotations for videos.\n    \"\"\"", "\n", "video_infos", "=", "[", "]", "\n", "anno_database", "=", "mmcv", ".", "load", "(", "ann_file", ")", "\n", "for", "video_name", "in", "anno_database", ":", "\n", "        ", "video_info", "=", "anno_database", "[", "video_name", "]", "\n", "video_info", "[", "'video_name'", "]", "=", "video_name", "\n", "video_infos", ".", "append", "(", "video_info", ")", "\n", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.generate_proposals": [[31, 94], ["bsn_proposal_generation.load_video_infos", "len", "torch.Manager", "mp.Manager.dict", "range", "range", "torch.Process", "mp.Process.start", "processes.append", "os.makedirs", "os.makedirs", "mmcv.ProgressBar", "range", "torch.Process", "mp.Process.start", "processes.append", "mp.Process.join", "os.join", "numpy.savetxt", "mmcv.ProgressBar.update"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.load_video_infos", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "generate_proposals", "(", "ann_file", ",", "tem_results_dir", ",", "pgm_proposals_dir", ",", "\n", "pgm_proposals_thread", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Generate proposals using multi-process.\n\n    Args:\n        ann_file (str): A json file path of the annotation file for\n            all videos to be processed.\n        tem_results_dir (str): Directory to read tem results\n        pgm_proposals_dir (str): Directory to save generated proposals.\n        pgm_proposals_thread (int): Total number of threads.\n        kwargs (dict): Keyword arguments for \"generate_candidate_proposals\".\n    \"\"\"", "\n", "video_infos", "=", "load_video_infos", "(", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "num_videos_per_thread", "=", "num_videos", "//", "pgm_proposals_thread", "\n", "processes", "=", "[", "]", "\n", "manager", "=", "mp", ".", "Manager", "(", ")", "\n", "result_dict", "=", "manager", ".", "dict", "(", ")", "\n", "kwargs", "[", "'result_dict'", "]", "=", "result_dict", "\n", "for", "tid", "in", "range", "(", "pgm_proposals_thread", "-", "1", ")", ":", "\n", "        ", "tmp_video_list", "=", "range", "(", "tid", "*", "num_videos_per_thread", ",", "\n", "(", "tid", "+", "1", ")", "*", "num_videos_per_thread", ")", "\n", "p", "=", "mp", ".", "Process", "(", "\n", "target", "=", "generate_candidate_proposals", ",", "\n", "args", "=", "(", "\n", "tmp_video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", ")", ",", "\n", "kwargs", "=", "kwargs", ")", "\n", "p", ".", "start", "(", ")", "\n", "processes", ".", "append", "(", "p", ")", "\n", "\n", "", "tmp_video_list", "=", "range", "(", "(", "pgm_proposals_thread", "-", "1", ")", "*", "num_videos_per_thread", ",", "\n", "num_videos", ")", "\n", "p", "=", "mp", ".", "Process", "(", "\n", "target", "=", "generate_candidate_proposals", ",", "\n", "args", "=", "(", "\n", "tmp_video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", ")", ",", "\n", "kwargs", "=", "kwargs", ")", "\n", "p", ".", "start", "(", ")", "\n", "processes", ".", "append", "(", "p", ")", "\n", "\n", "for", "p", "in", "processes", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n", "# save results", "\n", "", "os", ".", "makedirs", "(", "pgm_proposals_dir", ",", "exist_ok", "=", "True", ")", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "num_videos", ")", "\n", "header", "=", "'tmin,tmax,tmin_score,tmax_score,score,match_iou,match_ioa'", "\n", "for", "video_name", "in", "result_dict", ":", "\n", "        ", "proposals", "=", "result_dict", "[", "video_name", "]", "\n", "proposal_path", "=", "osp", ".", "join", "(", "pgm_proposals_dir", ",", "video_name", "+", "'.csv'", ")", "\n", "np", ".", "savetxt", "(", "\n", "proposal_path", ",", "\n", "proposals", ",", "\n", "header", "=", "header", ",", "\n", "delimiter", "=", "','", ",", "\n", "comments", "=", "''", ")", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.generate_features": [[96, 155], ["bsn_proposal_generation.load_video_infos", "len", "torch.Manager", "mp.Manager.dict", "range", "range", "torch.Process", "mp.Process.start", "processes.append", "os.makedirs", "os.makedirs", "mmcv.ProgressBar", "manager.dict.keys", "range", "torch.Process", "mp.Process.start", "processes.append", "mp.Process.join", "os.join", "numpy.save", "mmcv.ProgressBar.update"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.load_video_infos", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.start", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "generate_features", "(", "ann_file", ",", "tem_results_dir", ",", "pgm_proposals_dir", ",", "\n", "pgm_features_dir", ",", "pgm_features_thread", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Generate proposals features using multi-process.\n\n    Args:\n        ann_file (str): A json file path of the annotation file for\n            all videos to be processed.\n        tem_results_dir (str): Directory to read tem results.\n        pgm_proposals_dir (str): Directory to read generated proposals.\n        pgm_features_dir (str): Directory to save generated features.\n        pgm_features_thread (int): Total number of threads.\n        kwargs (dict): Keyword arguments for \"generate_bsp_feature\".\n    \"\"\"", "\n", "video_infos", "=", "load_video_infos", "(", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "num_videos_per_thread", "=", "num_videos", "//", "pgm_features_thread", "\n", "processes", "=", "[", "]", "\n", "manager", "=", "mp", ".", "Manager", "(", ")", "\n", "feature_return_dict", "=", "manager", ".", "dict", "(", ")", "\n", "kwargs", "[", "'result_dict'", "]", "=", "feature_return_dict", "\n", "for", "tid", "in", "range", "(", "pgm_features_thread", "-", "1", ")", ":", "\n", "        ", "tmp_video_list", "=", "range", "(", "tid", "*", "num_videos_per_thread", ",", "\n", "(", "tid", "+", "1", ")", "*", "num_videos_per_thread", ")", "\n", "p", "=", "mp", ".", "Process", "(", "\n", "target", "=", "generate_bsp_feature", ",", "\n", "args", "=", "(", "\n", "tmp_video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "\n", ")", ",", "\n", "kwargs", "=", "kwargs", ")", "\n", "p", ".", "start", "(", ")", "\n", "processes", ".", "append", "(", "p", ")", "\n", "", "tmp_video_list", "=", "range", "(", "(", "pgm_features_thread", "-", "1", ")", "*", "num_videos_per_thread", ",", "\n", "num_videos", ")", "\n", "p", "=", "mp", ".", "Process", "(", "\n", "target", "=", "generate_bsp_feature", ",", "\n", "args", "=", "(", "\n", "tmp_video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "\n", ")", ",", "\n", "kwargs", "=", "kwargs", ")", "\n", "p", ".", "start", "(", ")", "\n", "processes", ".", "append", "(", "p", ")", "\n", "\n", "for", "p", "in", "processes", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n", "# save results", "\n", "", "os", ".", "makedirs", "(", "pgm_features_dir", ",", "exist_ok", "=", "True", ")", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "num_videos", ")", "\n", "for", "video_name", "in", "feature_return_dict", ".", "keys", "(", ")", ":", "\n", "        ", "bsp_feature", "=", "feature_return_dict", "[", "video_name", "]", "\n", "feature_path", "=", "osp", ".", "join", "(", "pgm_features_dir", ",", "video_name", "+", "'.npy'", ")", "\n", "np", ".", "save", "(", "feature_path", ",", "bsp_feature", ")", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.parse_args": [[157, 167], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Proposal generation module'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mode'", ",", "\n", "choices", "=", "[", "'train'", ",", "'test'", "]", ",", "\n", "default", "=", "'test'", ",", "\n", "help", "=", "'train or test'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.main": [[169, 194], ["print", "bsn_proposal_generation.parse_args", "mmcv.Config.fromfile", "print", "bsn_proposal_generation.generate_proposals", "print", "bsn_proposal_generation.generate_features", "print", "bsn_proposal_generation.generate_proposals", "print", "bsn_proposal_generation.generate_features", "print"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.generate_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.generate_features", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.generate_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.bsn_proposal_generation.generate_features"], ["", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "'Begin Proposal Generation Module'", ")", "\n", "args", "=", "parse_args", "(", ")", "\n", "cfg", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "tem_results_dir", "=", "cfg", ".", "tem_results_dir", "\n", "pgm_proposals_dir", "=", "cfg", ".", "pgm_proposals_dir", "\n", "pgm_features_dir", "=", "cfg", ".", "pgm_features_dir", "\n", "if", "args", ".", "mode", "==", "'test'", ":", "\n", "        ", "generate_proposals", "(", "cfg", ".", "ann_file_val", ",", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "**", "cfg", ".", "pgm_proposals_cfg", ")", "\n", "print", "(", "'\\nFinish proposal generation'", ")", "\n", "generate_features", "(", "cfg", ".", "ann_file_val", ",", "tem_results_dir", ",", "pgm_proposals_dir", ",", "\n", "pgm_features_dir", ",", "**", "cfg", ".", "pgm_features_test_cfg", ")", "\n", "print", "(", "'\\nFinish feature generation'", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "'train'", ":", "\n", "        ", "generate_proposals", "(", "cfg", ".", "ann_file_train", ",", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "**", "cfg", ".", "pgm_proposals_cfg", ")", "\n", "print", "(", "'\\nFinish proposal generation'", ")", "\n", "generate_features", "(", "cfg", ".", "ann_file_train", ",", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "pgm_features_dir", ",", "\n", "**", "cfg", ".", "pgm_features_train_cfg", ")", "\n", "print", "(", "'\\nFinish feature generation'", ")", "\n", "\n", "", "print", "(", "'Finish Proposal Generation Module'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args": [[24, 67], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'MMAction2 clip-level feature extraction'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'test config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'checkpoint'", ",", "help", "=", "'checkpoint file'", ")", "\n", "parser", ".", "add_argument", "(", "'--video-list'", ",", "help", "=", "'video file list'", ")", "\n", "parser", ".", "add_argument", "(", "'--video-root'", ",", "help", "=", "'video root directory'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--out'", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'output result file in pkl/yaml/json format'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--fuse-conv-bn'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Whether to fuse conv and bn, this will slightly increase'", "\n", "'the inference speed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--gpu-collect'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to use gpu to collect results'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tmpdir'", ",", "\n", "help", "=", "'tmp directory used for collecting results from multiple '", "\n", "'workers, available when gpu-collect is not specified'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.turn_off_pretrained": [[69, 79], ["cfg.values", "isinstance", "clip_feature_extraction.turn_off_pretrained"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.turn_off_pretrained"], ["", "def", "turn_off_pretrained", "(", "cfg", ")", ":", "\n", "# recursively find all pretrained in the model config,", "\n", "# and set them None to avoid redundant pretrain steps for testing", "\n", "    ", "if", "'pretrained'", "in", "cfg", ":", "\n", "        ", "cfg", ".", "pretrained", "=", "None", "\n", "\n", "# recursively turn off pretrained value", "\n", "", "for", "sub_cfg", "in", "cfg", ".", "values", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "sub_cfg", ",", "dict", ")", ":", "\n", "            ", "turn_off_pretrained", "(", "sub_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.text2tensor": [[81, 87], ["np.array.extend", "numpy.array", "torch.from_numpy", "torch.from_numpy", "ord", "len", "len"], "function", ["None"], ["", "", "", "def", "text2tensor", "(", "text", ",", "size", "=", "256", ")", ":", "\n", "    ", "nums", "=", "[", "ord", "(", "x", ")", "for", "x", "in", "text", "]", "\n", "assert", "len", "(", "nums", ")", "<", "size", "\n", "nums", ".", "extend", "(", "[", "0", "]", "*", "(", "size", "-", "len", "(", "nums", ")", ")", ")", "\n", "nums", "=", "np", ".", "array", "(", "nums", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "return", "torch", ".", "from_numpy", "(", "nums", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.tensor2text": [[89, 93], ["chr"], "function", ["None"], ["", "def", "tensor2text", "(", "tensor", ")", ":", "\n", "# 0 may not occur in a string", "\n", "    ", "chars", "=", "[", "chr", "(", "x", ")", "for", "x", "in", "tensor", "if", "x", "!=", "0", "]", "\n", "return", "''", ".", "join", "(", "chars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.inference_pytorch": [[95, 127], ["clip_feature_extraction.turn_off_pretrained", "mmaction.models.build_model", "cfg.get", "mmcv.runner.load_checkpoint", "len", "mmaction.utils.register_module_hooks", "mmcv.runner.fp16_utils.wrap_fp16_model", "mmcv.cnn.fuse_conv_bn", "mmcv.parallel.MMDataParallel", "mmaction.apis.single_gpu_test", "mmcv.parallel.MMDistributedDataParallel", "mmaction.apis.multi_gpu_test", "cfg.get", "mmcv.parallel.MMDistributedDataParallel.cuda", "torch.cuda.current_device", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.turn_off_pretrained", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "inference_pytorch", "(", "args", ",", "cfg", ",", "distributed", ",", "data_loader", ")", ":", "\n", "    ", "\"\"\"Get predictions by pytorch models.\"\"\"", "\n", "# remove redundant pretrain steps for testing", "\n", "turn_off_pretrained", "(", "cfg", ".", "model", ")", "\n", "\n", "# build the model and load checkpoint", "\n", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "train_cfg", "=", "None", ",", "test_cfg", "=", "cfg", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "if", "len", "(", "cfg", ".", "module_hooks", ")", ">", "0", ":", "\n", "        ", "register_module_hooks", "(", "model", ",", "cfg", ".", "module_hooks", ")", "\n", "\n", "", "fp16_cfg", "=", "cfg", ".", "get", "(", "'fp16'", ",", "None", ")", "\n", "if", "fp16_cfg", "is", "not", "None", ":", "\n", "        ", "wrap_fp16_model", "(", "model", ")", "\n", "", "load_checkpoint", "(", "model", ",", "args", ".", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "if", "args", ".", "fuse_conv_bn", ":", "\n", "        ", "model", "=", "fuse_conv_bn", "(", "model", ")", "\n", "\n", "", "if", "not", "distributed", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "model", ",", "device_ids", "=", "[", "0", "]", ")", "\n", "outputs", "=", "single_gpu_test", "(", "model", ",", "data_loader", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ")", "\n", "outputs", "=", "multi_gpu_test", "(", "model", ",", "data_loader", ",", "args", ".", "tmpdir", ",", "\n", "args", ".", "gpu_collect", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.main": [[129, 225], ["clip_feature_extraction.parse_args", "mmcv.Config.fromfile", "Config.fromfile.merge_from_dict", "Config.fromfile.get", "Config._merge_a_into_b.get", "Config.fromfile.get", "mmcv.runner.get_dist_info", "torch.zeros().cuda", "torch.zeros().cuda", "clip_feature_extraction.tensor2text", "Config.fromfile.setdefault", "mmaction.datasets.build_dataset", "dict", "dict", "mmaction.datasets.build_dataloader", "clip_feature_extraction.inference_pytorch", "dict", "mmcv.Config._merge_a_into_b", "mmcv.runner.init_dist", "open().readlines", "datetime.datetime.now().strftime", "text2tensor().cuda", "torch.broadcast", "dict", "Config._merge_a_into_b.get", "os.remove", "os.remove", "dict", "warnings.warn", "mmcv.mkdir_or_exist", "os.splitext", "torch.zeros", "torch.zeros", "x.strip", "open", "fout.write", "text2tensor().cuda.cuda", "Config.fromfile.data.get", "Config.fromfile.data.get", "Config.fromfile.data.get", "print", "mmaction.datasets.build_dataset.dump_results", "os.dirname", "open", "datetime.datetime.now", "clip_feature_extraction.text2tensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.parse_args", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.tensor2text", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.inference_pytorch", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.dump_results", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.misc.clip_feature_extraction.text2tensor"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "if", "cfg", ".", "model", "[", "'test_cfg'", "]", "is", "None", ":", "\n", "        ", "cfg", ".", "model", "[", "'test_cfg'", "]", "=", "dict", "(", "feature_extraction", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "cfg", ".", "model", "[", "'test_cfg'", "]", "[", "'feature_extraction'", "]", "=", "True", "\n", "\n", "# Load output_config from cfg", "\n", "", "output_config", "=", "cfg", ".", "get", "(", "'output_config'", ",", "{", "}", ")", "\n", "if", "args", ".", "out", ":", "\n", "# Overwrite output_config from args.out", "\n", "        ", "output_config", "=", "Config", ".", "_merge_a_into_b", "(", "\n", "dict", "(", "out", "=", "args", ".", "out", ")", ",", "output_config", ")", "\n", "\n", "", "assert", "output_config", ",", "'Please specify output filename with --out.'", "\n", "\n", "dataset_type", "=", "cfg", ".", "data", ".", "test", ".", "type", "\n", "if", "output_config", ".", "get", "(", "'out'", ",", "None", ")", ":", "\n", "        ", "if", "'output_format'", "in", "output_config", ":", "\n", "# ugly workround to make recognition and localization the same", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'Skip checking `output_format` in localization task.'", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "output_config", "[", "'out'", "]", "\n", "# make sure the dirname of the output path exists", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "dirname", "(", "out", ")", ")", "\n", "_", ",", "suffix", "=", "osp", ".", "splitext", "(", "out", ")", "\n", "assert", "dataset_type", "==", "'VideoDataset'", "\n", "\n", "assert", "suffix", "[", "1", ":", "]", "in", "file_handlers", ",", "(", "\n", "'The format of the output '", "\n", "'file should be json, pickle or yaml'", ")", "\n", "\n", "# set cudnn benchmark", "\n", "", "", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "cfg", ".", "data", ".", "test", ".", "test_mode", "=", "True", "\n", "cfg", ".", "data", ".", "test", ".", "data_prefix", "=", "args", ".", "video_root", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "\n", "", "rank", ",", "_", "=", "get_dist_info", "(", ")", "\n", "\n", "size", "=", "256", "\n", "fname_tensor", "=", "torch", ".", "zeros", "(", "size", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "cuda", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "videos", "=", "open", "(", "args", ".", "video_list", ")", ".", "readlines", "(", ")", "\n", "videos", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "videos", "]", "\n", "\n", "timestamp", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y%m%d_%H%M%S'", ")", "\n", "fake_anno", "=", "f'fake_anno_{timestamp}.txt'", "\n", "with", "open", "(", "fake_anno", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "lines", "=", "[", "x", "+", "' 0'", "for", "x", "in", "videos", "]", "\n", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", ")", "\n", "", "fname_tensor", "=", "text2tensor", "(", "fake_anno", ",", "size", ")", ".", "cuda", "(", ")", "\n", "\n", "", "if", "distributed", ":", "\n", "        ", "dist", ".", "broadcast", "(", "fname_tensor", ".", "cuda", "(", ")", ",", "src", "=", "0", ")", "\n", "\n", "", "fname", "=", "tensor2text", "(", "fname_tensor", ")", "\n", "cfg", ".", "data", ".", "test", ".", "ann_file", "=", "fname", "\n", "\n", "# The flag is used to register module's hooks", "\n", "cfg", ".", "setdefault", "(", "'module_hooks'", ",", "[", "]", ")", "\n", "\n", "# build the dataloader", "\n", "dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "test", ",", "dict", "(", "test_mode", "=", "True", ")", ")", "\n", "dataloader_setting", "=", "dict", "(", "\n", "videos_per_gpu", "=", "cfg", ".", "data", ".", "get", "(", "'videos_per_gpu'", ",", "1", ")", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "get", "(", "'workers_per_gpu'", ",", "1", ")", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n", "dataloader_setting", "=", "dict", "(", "dataloader_setting", ",", "\n", "**", "cfg", ".", "data", ".", "get", "(", "'test_dataloader'", ",", "{", "}", ")", ")", "\n", "data_loader", "=", "build_dataloader", "(", "dataset", ",", "**", "dataloader_setting", ")", "\n", "\n", "outputs", "=", "inference_pytorch", "(", "args", ",", "cfg", ",", "distributed", ",", "data_loader", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "if", "output_config", ".", "get", "(", "'out'", ",", "None", ")", ":", "\n", "            ", "out", "=", "output_config", "[", "'out'", "]", "\n", "print", "(", "f'\\nwriting results to {out}'", ")", "\n", "dataset", ".", "dump_results", "(", "outputs", ",", "**", "output_config", ")", "\n", "# remove the temporary file", "\n", "", "os", ".", "remove", "(", "fake_anno", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs.conf.get_version": [[27, 31], ["open", "exec", "locals", "compile", "f.read"], "function", ["None"], ["def", "get_version", "(", ")", ":", "\n", "    ", "with", "open", "(", "version_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "exec", "(", "compile", "(", "f", ".", "read", "(", ")", ",", "version_file", ",", "'exec'", ")", ")", "\n", "", "return", "locals", "(", ")", "[", "'__version__'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs.conf.builder_inited_handler": [[75, 78], ["subprocess.run", "subprocess.run"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["def", "builder_inited_handler", "(", "app", ")", ":", "\n", "    ", "subprocess", ".", "run", "(", "[", "'./merge_docs.sh'", "]", ")", "\n", "subprocess", ".", "run", "(", "[", "'./stat.py'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs.conf.setup": [[80, 82], ["app.connect"], "function", ["None"], ["", "def", "setup", "(", "app", ")", ":", "\n", "    ", "app", ".", "connect", "(", "'builder-inited'", ",", "builder_inited_handler", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs.stat.anchor": [[11, 14], ["re.sub().strip", "re.sub", "re.sub", "name.strip().lower", "name.strip"], "function", ["None"], ["def", "anchor", "(", "name", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "r'-+'", ",", "'-'", ",", "re", ".", "sub", "(", "r'[^a-zA-Z0-9]'", ",", "'-'", ",", "\n", "name", ".", "strip", "(", ")", ".", "lower", "(", ")", ")", ")", ".", "strip", "(", "'-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.mmaction.version.parse_version_info": [[6, 16], ["version_str.split", "tuple", "x.isdigit", "version_info.append", "int", "x.find", "x.split", "version_info.append", "version_info.append", "int"], "function", ["None"], [""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.decorators.import_module_error_func": [[4, 17], ["ImportError"], "function", ["None"], ["def", "import_module_error_func", "(", "module_name", ")", ":", "\n", "    ", "\"\"\"When a function is imported incorrectly due to a missing module, raise\n    an import error when the function is called.\"\"\"", "\n", "\n", "def", "decorate", "(", "func", ")", ":", "\n", "\n", "        ", "def", "new_func", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "f'Please install {module_name} to use {func.__name__}.'", ")", "\n", "\n", "", "return", "new_func", "\n", "\n", "", "return", "decorate", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.decorators.import_module_error_class": [[19, 33], ["types.MethodType", "ImportError"], "function", ["None"], ["", "def", "import_module_error_class", "(", "module_name", ")", ":", "\n", "    ", "\"\"\"When a class is imported incorrectly due to a missing module, raise an\n    import error when the class is instantiated.\"\"\"", "\n", "\n", "def", "decorate", "(", "cls", ")", ":", "\n", "\n", "        ", "def", "import_error_init", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "f'Please install {module_name} to use {cls.__name__}.'", ")", "\n", "\n", "", "cls", ".", "__init__", "=", "MethodType", "(", "import_error_init", ",", "cls", ")", "\n", "return", "cls", "\n", "\n", "", "return", "decorate", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM.__init__": [[15, 46], ["isinstance", "gradcam_utils.GradCAM.model.eval", "plt.get_cmap", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "gradcam_utils.GradCAM._register_hooks", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM._register_hooks"], ["def", "__init__", "(", "self", ",", "model", ",", "target_layer_name", ",", "colormap", "=", "'viridis'", ")", ":", "\n", "        ", "\"\"\"Create GradCAM class with recognizer, target layername & colormap.\n\n        Args:\n            model (nn.Module): the recognizer model to be used.\n            target_layer_name (str): name of convolutional layer to\n                be used to get gradients and feature maps from for creating\n                localization maps.\n            colormap (Optional[str]): matplotlib colormap used to create\n                heatmap. Default: 'viridis'. For more information, please visit\n                https://matplotlib.org/3.3.0/tutorials/colors/colormaps.html\n        \"\"\"", "\n", "from", ".", ".", "models", ".", "recognizers", "import", "Recognizer2D", ",", "Recognizer3D", "\n", "if", "isinstance", "(", "model", ",", "Recognizer2D", ")", ":", "\n", "            ", "self", ".", "is_recognizer2d", "=", "True", "\n", "", "elif", "isinstance", "(", "model", ",", "Recognizer3D", ")", ":", "\n", "            ", "self", ".", "is_recognizer2d", "=", "False", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'GradCAM utils only support Recognizer2D & Recognizer3D.'", ")", "\n", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "target_gradients", "=", "None", "\n", "self", ".", "target_activations", "=", "None", "\n", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "self", ".", "colormap", "=", "plt", ".", "get_cmap", "(", "colormap", ")", "\n", "self", ".", "data_mean", "=", "torch", ".", "tensor", "(", "model", ".", "cfg", ".", "img_norm_cfg", "[", "'mean'", "]", ")", "\n", "self", ".", "data_std", "=", "torch", ".", "tensor", "(", "model", ".", "cfg", ".", "img_norm_cfg", "[", "'std'", "]", ")", "\n", "self", ".", "_register_hooks", "(", "target_layer_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM._register_hooks": [[47, 69], ["layer_name.split", "target_layer.register_forward_hook", "target_layer.register_backward_hook", "grad_output[].detach", "output.clone().detach", "output.clone"], "methods", ["None"], ["", "def", "_register_hooks", "(", "self", ",", "layer_name", ")", ":", "\n", "        ", "\"\"\"Register forward and backward hook to a layer, given layer_name, to\n        obtain gradients and activations.\n\n        Args:\n            layer_name (str): name of the layer.\n        \"\"\"", "\n", "\n", "def", "get_gradients", "(", "module", ",", "grad_input", ",", "grad_output", ")", ":", "\n", "            ", "self", ".", "target_gradients", "=", "grad_output", "[", "0", "]", ".", "detach", "(", ")", "\n", "\n", "", "def", "get_activations", "(", "module", ",", "input", ",", "output", ")", ":", "\n", "            ", "self", ".", "target_activations", "=", "output", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "", "layer_ls", "=", "layer_name", ".", "split", "(", "'/'", ")", "\n", "prev_module", "=", "self", ".", "model", "\n", "for", "layer", "in", "layer_ls", ":", "\n", "            ", "prev_module", "=", "prev_module", ".", "_modules", "[", "layer", "]", "\n", "\n", "", "target_layer", "=", "prev_module", "\n", "target_layer", ".", "register_forward_hook", "(", "get_activations", ")", "\n", "target_layer", ".", "register_backward_hook", "(", "get_gradients", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM._calculate_localization_map": [[70, 152], ["inputs[].clone", "gradcam_utils.GradCAM.model", "gradcam_utils.GradCAM.model.zero_grad", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.gather.backward", "torch.gather.backward", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "weights.view.view.view", "activations.permute.permute.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.relu", "torch.relu", "torch.interpolate.permute", "torch.interpolate", "torch.interpolate", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "inputs[].size", "inputs[].size", "gradients.permute.permute.size", "gradients.permute.permute.size", "gradients.permute.permute.permute", "activations.permute.permute.permute", "gradients.permute.permute.view", "torch.interpolate.squeeze", "labels.unsqueeze.unsqueeze.unsqueeze", "torch.max", "torch.max", "torch.max", "torch.max", "list", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.interpolate.view", "torch.interpolate.view", "activations.permute.permute.size"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.backward", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.backward"], ["", "def", "_calculate_localization_map", "(", "self", ",", "inputs", ",", "use_labels", ",", "delta", "=", "1e-20", ")", ":", "\n", "        ", "\"\"\"Calculate localization map for all inputs with Grad-CAM.\n\n        Args:\n            inputs (dict): model inputs, generated by test pipeline,\n                at least including two keys, ``imgs`` and ``label``.\n            use_labels (bool): Whether to use given labels to generate\n                localization map. Labels are in ``inputs['label']``.\n            delta (float): used in localization map normalization,\n                must be small enough. Please make sure\n                `localization_map_max - localization_map_min >> delta`\n        Returns:\n            tuple[torch.Tensor, torch.Tensor]: (localization_map, preds)\n                localization_map (torch.Tensor): the localization map for\n                    input imgs.\n                preds (torch.Tensor): Model predictions for `inputs` with\n                    shape (batch_size, num_classes).\n        \"\"\"", "\n", "inputs", "[", "'imgs'", "]", "=", "inputs", "[", "'imgs'", "]", ".", "clone", "(", ")", "\n", "\n", "# model forward & backward", "\n", "preds", "=", "self", ".", "model", "(", "gradcam", "=", "True", ",", "**", "inputs", ")", "\n", "if", "use_labels", ":", "\n", "            ", "labels", "=", "inputs", "[", "'label'", "]", "\n", "if", "labels", ".", "ndim", "==", "1", ":", "\n", "                ", "labels", "=", "labels", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "score", "=", "torch", ".", "gather", "(", "preds", ",", "dim", "=", "1", ",", "index", "=", "labels", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "torch", ".", "max", "(", "preds", ",", "dim", "=", "-", "1", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "score", "=", "torch", ".", "sum", "(", "score", ")", "\n", "score", ".", "backward", "(", ")", "\n", "\n", "if", "self", ".", "is_recognizer2d", ":", "\n", "# [batch_size, num_segments, 3, H, W]", "\n", "            ", "b", ",", "t", ",", "_", ",", "h", ",", "w", "=", "inputs", "[", "'imgs'", "]", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "# [batch_size, num_crops*num_clips, 3, clip_len, H, W]", "\n", "            ", "b1", ",", "b2", ",", "_", ",", "t", ",", "h", ",", "w", "=", "inputs", "[", "'imgs'", "]", ".", "size", "(", ")", "\n", "b", "=", "b1", "*", "b2", "\n", "\n", "", "gradients", "=", "self", ".", "target_gradients", "\n", "activations", "=", "self", ".", "target_activations", "\n", "if", "self", ".", "is_recognizer2d", ":", "\n", "# [B*Tg, C', H', W']", "\n", "            ", "b_tg", ",", "c", ",", "_", ",", "_", "=", "gradients", ".", "size", "(", ")", "\n", "tg", "=", "b_tg", "//", "b", "\n", "", "else", ":", "\n", "# source shape: [B, C', Tg, H', W']", "\n", "            ", "_", ",", "c", ",", "tg", ",", "_", ",", "_", "=", "gradients", ".", "size", "(", ")", "\n", "# target shape: [B, Tg, C', H', W']", "\n", "gradients", "=", "gradients", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "activations", "=", "activations", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "\n", "# calculate & resize to [B, 1, T, H, W]", "\n", "", "weights", "=", "torch", ".", "mean", "(", "gradients", ".", "view", "(", "b", ",", "tg", ",", "c", ",", "-", "1", ")", ",", "dim", "=", "3", ")", "\n", "weights", "=", "weights", ".", "view", "(", "b", ",", "tg", ",", "c", ",", "1", ",", "1", ")", "\n", "activations", "=", "activations", ".", "view", "(", "[", "b", ",", "tg", ",", "c", "]", "+", "\n", "list", "(", "activations", ".", "size", "(", ")", "[", "-", "2", ":", "]", ")", ")", "\n", "localization_map", "=", "torch", ".", "sum", "(", "\n", "weights", "*", "activations", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "localization_map", "=", "F", ".", "relu", "(", "localization_map", ")", "\n", "localization_map", "=", "localization_map", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "localization_map", "=", "F", ".", "interpolate", "(", "\n", "localization_map", ",", "\n", "size", "=", "(", "t", ",", "h", ",", "w", ")", ",", "\n", "mode", "=", "'trilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "\n", "# Normalize the localization map.", "\n", "localization_map_min", ",", "localization_map_max", "=", "(", "\n", "torch", ".", "min", "(", "localization_map", ".", "view", "(", "b", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", ",", "\n", "torch", ".", "max", "(", "localization_map", ".", "view", "(", "b", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", "\n", "localization_map_min", "=", "torch", ".", "reshape", "(", "\n", "localization_map_min", ",", "shape", "=", "(", "b", ",", "1", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "localization_map_max", "=", "torch", ".", "reshape", "(", "\n", "localization_map_max", ",", "shape", "=", "(", "b", ",", "1", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "localization_map", "=", "(", "localization_map", "-", "localization_map_min", ")", "/", "(", "\n", "localization_map_max", "-", "localization_map_min", "+", "delta", ")", "\n", "localization_map", "=", "localization_map", ".", "data", "\n", "\n", "return", "localization_map", ".", "squeeze", "(", "dim", "=", "1", ")", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM._alpha_blending": [[153, 195], ["localization_map.cpu.cpu.cpu", "gradcam_utils.GradCAM.colormap", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "curr_inp.permute.permute.cpu", "localization_map.cpu.cpu.detach().numpy", "input_imgs.permute", "input_imgs.view", "curr_inp.permute.permute.permute", "localization_map.cpu.cpu.detach", "list", "input_imgs.size"], "methods", ["None"], ["", "def", "_alpha_blending", "(", "self", ",", "localization_map", ",", "input_imgs", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Blend heatmaps and model input images and get visulization results.\n\n        Args:\n            localization_map (torch.Tensor): localization map for all inputs,\n                generated with Grad-CAM\n            input_imgs (torch.Tensor): model inputs, normed images.\n            alpha (float): transparency level of the heatmap,\n                in the range [0, 1].\n        Returns:\n            torch.Tensor: blending results for localization map and input\n                images, with shape [B, T, H, W, 3] and pixel values in\n                RGB order within range [0, 1].\n        \"\"\"", "\n", "# localization_map shape [B, T, H, W]", "\n", "localization_map", "=", "localization_map", ".", "cpu", "(", ")", "\n", "\n", "# heatmap shape [B, T, H, W, 3] in RGB order", "\n", "heatmap", "=", "self", ".", "colormap", "(", "localization_map", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "heatmap", "=", "heatmap", "[", ":", ",", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "heatmap", "=", "torch", ".", "from_numpy", "(", "heatmap", ")", "\n", "\n", "# Permute input imgs to [B, T, H, W, 3], like heatmap", "\n", "if", "self", ".", "is_recognizer2d", ":", "\n", "# Recognizer2D input (B, T, C, H, W)", "\n", "            ", "curr_inp", "=", "input_imgs", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "", "else", ":", "\n", "# Recognizer3D input (B', num_clips*num_crops, C, T, H, W)", "\n", "# B = B' * num_clips * num_crops", "\n", "            ", "curr_inp", "=", "input_imgs", ".", "view", "(", "[", "-", "1", "]", "+", "list", "(", "input_imgs", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", "\n", "curr_inp", "=", "curr_inp", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "4", ",", "1", ")", "\n", "\n", "# renormalize input imgs to [0, 1]", "\n", "", "curr_inp", "=", "curr_inp", ".", "cpu", "(", ")", "\n", "curr_inp", "*=", "self", ".", "data_std", "\n", "curr_inp", "+=", "self", ".", "data_mean", "\n", "curr_inp", "/=", "255.", "\n", "\n", "# alpha blending", "\n", "blended_imgs", "=", "alpha", "*", "heatmap", "+", "(", "1", "-", "alpha", ")", "*", "curr_inp", "\n", "\n", "return", "blended_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM.__call__": [[196, 232], ["gradcam_utils.GradCAM._calculate_localization_map", "gradcam_utils.GradCAM._alpha_blending"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM._calculate_localization_map", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.gradcam_utils.GradCAM._alpha_blending"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "use_labels", "=", "False", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"Visualize the localization maps on their corresponding inputs as\n        heatmap, using Grad-CAM.\n\n        Generate visualization results for **ALL CROPS**.\n        For example, for I3D model, if `clip_len=32, num_clips=10` and\n        use `ThreeCrop` in test pipeline, then for every model inputs,\n        there are 960(32*10*3) images generated.\n\n        Args:\n            inputs (dict): model inputs, generated by test pipeline,\n                at least including two keys, ``imgs`` and ``label``.\n            use_labels (bool): Whether to use given labels to generate\n                localization map. Labels are in ``inputs['label']``.\n            alpha (float): transparency level of the heatmap,\n                in the range [0, 1].\n        Returns:\n            blended_imgs (torch.Tensor): Visualization results, blended by\n                localization maps and model inputs.\n            preds (torch.Tensor): Model predictions for inputs.\n        \"\"\"", "\n", "\n", "# localization_map shape [B, T, H, W]", "\n", "# preds shape [batch_size, num_classes]", "\n", "localization_map", ",", "preds", "=", "self", ".", "_calculate_localization_map", "(", "\n", "inputs", ",", "use_labels", "=", "use_labels", ")", "\n", "\n", "# blended_imgs shape [B, T, H, W, 3]", "\n", "blended_imgs", "=", "self", ".", "_alpha_blending", "(", "localization_map", ",", "inputs", "[", "'imgs'", "]", ",", "\n", "alpha", ")", "\n", "\n", "# blended_imgs shape [B, T, H, W, 3]", "\n", "# preds shape [batch_size, num_classes]", "\n", "# Recognizer2D: B = batch_size, T = num_segments", "\n", "# Recognizer3D: B = batch_size * num_crops * num_clips, T = clip_len", "\n", "return", "blended_imgs", ",", "preds", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger": [[6, 25], ["mmcv.utils.get_logger", "__name__.split"], "function", ["None"], ["def", "get_root_logger", "(", "log_file", "=", "None", ",", "log_level", "=", "logging", ".", "INFO", ")", ":", "\n", "    ", "\"\"\"Use ``get_logger`` method in mmcv to get the root logger.\n\n    The logger will be initialized if it has not been initialized. By default a\n    StreamHandler will be added. If ``log_file`` is specified, a FileHandler\n    will also be added. The name of the root logger is the top-level package\n    name, e.g., \"mmaction\".\n\n    Args:\n        log_file (str | None): The log filename. If specified, a FileHandler\n            will be added to the root logger.\n        log_level (int): The root logger level. Note that only the process of\n            rank 0 is affected, while other processes will set the level to\n            \"Error\" and be silent most of the time.\n\n    Returns:\n        :obj:`logging.Logger`: The root logger.\n    \"\"\"", "\n", "return", "get_logger", "(", "__name__", ".", "split", "(", "'.'", ")", "[", "0", "]", ",", "log_file", ",", "log_level", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_random_string": [[6, 15], ["random.choice", "range"], "function", ["None"], ["def", "get_random_string", "(", "length", "=", "15", ")", ":", "\n", "    ", "\"\"\"Get random string with letters and digits.\n\n    Args:\n        length (int): Length of random string. Default: 15.\n    \"\"\"", "\n", "return", "''", ".", "join", "(", "\n", "random", ".", "choice", "(", "string", ".", "ascii_letters", "+", "string", ".", "digits", ")", "\n", "for", "_", "in", "range", "(", "length", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_thread_id": [[17, 22], ["ctypes.CDLL().syscall", "ctypes.CDLL"], "function", ["None"], ["", "def", "get_thread_id", "(", ")", ":", "\n", "    ", "\"\"\"Get current thread id.\"\"\"", "\n", "# use ctype to find thread id", "\n", "thread_id", "=", "ctypes", ".", "CDLL", "(", "'libc.so.6'", ")", ".", "syscall", "(", "186", ")", "\n", "return", "thread_id", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_shm_dir": [[24, 27], ["None"], "function", ["None"], ["", "def", "get_shm_dir", "(", ")", ":", "\n", "    ", "\"\"\"Get shm dir for temporary usage.\"\"\"", "\n", "return", "'/dev/shm'", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.precise_bn.PreciseBNHook.__init__": [[133, 140], ["isinstance", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataloader", ",", "num_iters", "=", "200", ",", "interval", "=", "1", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "dataloader", ",", "DataLoader", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'dataloader must be a pytorch DataLoader, but got'", "\n", "f' {type(dataloader)}'", ")", "\n", "", "self", ".", "dataloader", "=", "dataloader", "\n", "self", ".", "interval", "=", "interval", "\n", "self", ".", "num_iters", "=", "num_iters", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.precise_bn.PreciseBNHook.after_train_epoch": [[141, 156], ["precise_bn.PreciseBNHook.every_n_epochs", "time.sleep", "mmcv.utils.print_log", "precise_bn.update_bn_stats", "mmcv.utils.print_log", "time.sleep"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.precise_bn.update_bn_stats"], ["", "def", "after_train_epoch", "(", "self", ",", "runner", ")", ":", "\n", "        ", "if", "self", ".", "every_n_epochs", "(", "runner", ",", "self", ".", "interval", ")", ":", "\n", "# sleep to avoid possible deadlock", "\n", "            ", "time", ".", "sleep", "(", "2.", ")", "\n", "print_log", "(", "\n", "f'Running Precise BN for {self.num_iters} iterations'", ",", "\n", "logger", "=", "runner", ".", "logger", ")", "\n", "update_bn_stats", "(", "\n", "runner", ".", "model", ",", "\n", "self", ".", "dataloader", ",", "\n", "self", ".", "num_iters", ",", "\n", "logger", "=", "runner", ".", "logger", ")", "\n", "print_log", "(", "'BN stats updated'", ",", "logger", "=", "runner", ".", "logger", ")", "\n", "# sleep to avoid possible deadlock", "\n", "time", ".", "sleep", "(", "2.", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.precise_bn.is_parallel_module": [[19, 34], ["bool", "isinstance"], "function", ["None"], ["def", "is_parallel_module", "(", "module", ")", ":", "\n", "    ", "\"\"\"Check if a module is a parallel module.\n\n    The following 3 modules (and their subclasses) are regarded as parallel\n    modules: DataParallel, DistributedDataParallel,\n    MMDistributedDataParallel (the deprecated version).\n\n    Args:\n        module (nn.Module): The module to be checked.\n    Returns:\n        bool: True if the input module is a parallel module.\n    \"\"\"", "\n", "parallels", "=", "(", "DataParallel", ",", "DistributedDataParallel", ",", "\n", "MMDistributedDataParallel", ")", "\n", "return", "bool", "(", "isinstance", "(", "module", ",", "parallels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.precise_bn.update_bn_stats": [[36, 121], ["torch.no_grad", "model.train", "precise_bn.is_parallel_module", "mmcv.utils.print_log", "model.modules", "mmcv.ProgressBar", "enumerate", "enumerate", "len", "len", "mmcv.utils.print_log", "torch.zeros_like", "torch.zeros_like", "len", "mmcv.ProgressBar.update", "enumerate", "len", "model.modules", "isinstance", "mmcv.utils.print_log", "torch.no_grad", "parallel_module", "isinstance", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.precise_bn.is_parallel_module"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "update_bn_stats", "(", "model", ",", "data_loader", ",", "num_iters", "=", "200", ",", "logger", "=", "None", ")", ":", "\n", "    ", "\"\"\"Recompute and update the batch norm stats to make them more precise.\n\n    During\n    training both BN stats and the weight are changing after every iteration,\n    so the running average can not precisely reflect the actual stats of the\n    current model.\n    In this function, the BN stats are recomputed with fixed weights, to make\n    the running average more precise. Specifically, it computes the true\n    average of per-batch mean/variance instead of the running average.\n\n    Args:\n        model (nn.Module): The model whose bn stats will be recomputed.\n        data_loader (iterator): The DataLoader iterator.\n        num_iters (int): number of iterations to compute the stats.\n        logger (:obj:`logging.Logger` | None): Logger for logging.\n            Default: None.\n    \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "assert", "len", "(", "data_loader", ")", ">=", "num_iters", ",", "(", "\n", "f'length of dataloader {len(data_loader)} must be greater than '", "\n", "f'iteration number {num_iters}'", ")", "\n", "\n", "if", "is_parallel_module", "(", "model", ")", ":", "\n", "        ", "parallel_module", "=", "model", "\n", "model", "=", "model", ".", "module", "\n", "", "else", ":", "\n", "        ", "parallel_module", "=", "model", "\n", "# Finds all the bn layers with training=True.", "\n", "", "bn_layers", "=", "[", "\n", "m", "for", "m", "in", "model", ".", "modules", "(", ")", "if", "m", ".", "training", "and", "isinstance", "(", "m", ",", "_BatchNorm", ")", "\n", "]", "\n", "\n", "if", "len", "(", "bn_layers", ")", "==", "0", ":", "\n", "        ", "print_log", "(", "'No BN found in model'", ",", "logger", "=", "logger", ",", "level", "=", "logging", ".", "WARNING", ")", "\n", "return", "\n", "", "print_log", "(", "f'{len(bn_layers)} BN found'", ",", "logger", "=", "logger", ")", "\n", "\n", "# Finds all the other norm layers with training=True.", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "m", ".", "training", "and", "isinstance", "(", "m", ",", "(", "_InstanceNorm", ",", "GroupNorm", ")", ")", ":", "\n", "            ", "print_log", "(", "\n", "'IN/GN stats will be updated like training.'", ",", "\n", "logger", "=", "logger", ",", "\n", "level", "=", "logging", ".", "WARNING", ")", "\n", "\n", "# In order to make the running stats only reflect the current batch, the", "\n", "# momentum is disabled.", "\n", "# bn.running_mean = (1 - momentum) * bn.running_mean + momentum *", "\n", "# batch_mean", "\n", "# Setting the momentum to 1.0 to compute the stats without momentum.", "\n", "", "", "momentum_actual", "=", "[", "bn", ".", "momentum", "for", "bn", "in", "bn_layers", "]", "# pyre-ignore", "\n", "for", "bn", "in", "bn_layers", ":", "\n", "        ", "bn", ".", "momentum", "=", "1.0", "\n", "\n", "# Note that running_var actually means \"running average of variance\"", "\n", "", "running_mean", "=", "[", "torch", ".", "zeros_like", "(", "bn", ".", "running_mean", ")", "for", "bn", "in", "bn_layers", "]", "\n", "running_var", "=", "[", "torch", ".", "zeros_like", "(", "bn", ".", "running_var", ")", "for", "bn", "in", "bn_layers", "]", "\n", "\n", "finish_before_loader", "=", "False", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "data_loader", ")", ")", "\n", "for", "ind", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "parallel_module", "(", "**", "data", ",", "return_loss", "=", "False", ")", "\n", "", "prog_bar", ".", "update", "(", ")", "\n", "for", "i", ",", "bn", "in", "enumerate", "(", "bn_layers", ")", ":", "\n", "# Accumulates the bn stats.", "\n", "            ", "running_mean", "[", "i", "]", "+=", "(", "bn", ".", "running_mean", "-", "running_mean", "[", "i", "]", ")", "/", "(", "ind", "+", "1", ")", "\n", "# running var is actually", "\n", "running_var", "[", "i", "]", "+=", "(", "bn", ".", "running_var", "-", "running_var", "[", "i", "]", ")", "/", "(", "ind", "+", "1", ")", "\n", "\n", "", "if", "(", "ind", "+", "1", ")", ">=", "num_iters", ":", "\n", "            ", "finish_before_loader", "=", "True", "\n", "break", "\n", "", "", "assert", "finish_before_loader", ",", "'Dataloader stopped before '", "f'iteration {num_iters}'", "\n", "\n", "for", "i", ",", "bn", "in", "enumerate", "(", "bn_layers", ")", ":", "\n", "# Sets the precise bn stats.", "\n", "        ", "bn", ".", "running_mean", "=", "running_mean", "[", "i", "]", "\n", "bn", ".", "running_var", "=", "running_var", "[", "i", "]", "\n", "bn", ".", "momentum", "=", "momentum_actual", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.collect_env.collect_env": [[7, 12], ["mmcv.utils.collect_env", "mmcv.utils.get_git_hash"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.collect_env.collect_env"], ["import", "locale", "\n", "import", "re", "\n", "import", "subprocess", "\n", "import", "sys", "\n", "import", "os", "\n", "from", "collections", "import", "namedtuple", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.optimizer.DistOptimizerHook.__init__": [[12, 18], ["None"], "methods", ["None"], ["from", "caffe2", ".", "python", ".", "modeling", "import", "parameter_info", "\n", "from", "past", ".", "builtins", "import", "basestring", "\n", "\n", "\n", "_LEARNING_RATE_INJECTION", "=", "\"lr_injection\"", "\n", "\n", "AuxOptimizerParams", "=", "namedtuple", "(", "\"AuxOptimizerParams\"", ",", "[", "\"local\"", ",", "\"shared\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.optimizer.DistOptimizerHook.before_run": [[19, 21], ["runner.optimizer.zero_grad"], "methods", ["None"], ["_optimizer_instance_count", "=", "defaultdict", "(", "int", ")", "\n", "\n", "FP16_ENGINES", "=", "[", "\"SIMD_Q_FP16\"", ",", "\"SIMD_Q_STOC_FP16\"", ",", "\"SIMD_Q_STOC_MKL_FP16\"", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.optimizer.DistOptimizerHook.after_train_iter": [[22, 34], ["optimizer.DistOptimizerHook.every_n_iters", "runner.outputs[].backward", "runner.optimizer.step", "runner.optimizer.zero_grad", "apex.amp.scale_loss", "scaled_loss.backward", "optimizer.DistOptimizerHook.clip_grads", "runner.model.parameters"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.backward", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.backward"], ["\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "def", "reset_optimizer_instance_count", "(", ")", ":", "\n", "    ", "\"\"\"\n    This function clears the _optimizer_instance_count. And keeps it\n    empty. This functionality is needed in some situations where\n    optimizer instance count might not reset even though the workplace is reset.\n    \"\"\"", "\n", "_optimizer_instance_count", ".", "clear", "(", ")", "\n", "\n", "\n", "", "class", "Optimizer", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.GPUNormalize.__init__": [[50, 70], ["torch.tensor", "torch.tensor", "ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_format", ",", "mean", ",", "std", ")", ":", "\n", "        ", "if", "input_format", "not", "in", "[", "'NCTHW'", ",", "'NCHW'", ",", "'NCHW_Flow'", ",", "'NPTCHW'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'The input format {input_format} is invalid.'", ")", "\n", "", "self", ".", "input_format", "=", "input_format", "\n", "_mean", "=", "torch", ".", "tensor", "(", "mean", ")", "\n", "_std", "=", "torch", ".", "tensor", "(", "std", ")", "\n", "if", "input_format", "==", "'NCTHW'", ":", "\n", "            ", "self", ".", "_mean", "=", "_mean", "[", "None", ",", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "self", ".", "_std", "=", "_std", "[", "None", ",", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "", "elif", "input_format", "==", "'NCHW'", ":", "\n", "            ", "self", ".", "_mean", "=", "_mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "self", ".", "_std", "=", "_std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "input_format", "==", "'NCHW_Flow'", ":", "\n", "            ", "self", ".", "_mean", "=", "_mean", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "self", ".", "_std", "=", "_std", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "input_format", "==", "'NPTCHW'", ":", "\n", "            ", "self", ".", "_mean", "=", "_mean", "[", "None", ",", "None", ",", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "self", ".", "_std", "=", "_std", "[", "None", ",", "None", ",", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'The input format {input_format} is invalid.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.GPUNormalize.hook_func": [[71, 88], ["module_hooks.GPUNormalize._mean.to", "module_hooks.GPUNormalize._std.to", "torch.no_grad", "x.float().sub_().div_.float().sub_().div_.float().sub_().div_", "x.float().sub_().div_.float().sub_().div_.float().sub_", "x.float().sub_().div_.float().sub_().div_.float"], "methods", ["None"], ["", "", "def", "hook_func", "(", "self", ")", ":", "\n", "\n", "        ", "def", "normalize_hook", "(", "Module", ",", "input", ")", ":", "\n", "            ", "x", "=", "input", "[", "0", "]", "\n", "assert", "x", ".", "dtype", "==", "torch", ".", "uint8", ",", "(", "\n", "f'The previous augmentation should use uint8 data type to '", "\n", "f'speed up computation, but get {x.dtype}'", ")", "\n", "\n", "mean", "=", "self", ".", "_mean", ".", "to", "(", "x", ".", "device", ")", "\n", "std", "=", "self", ".", "_std", ".", "to", "(", "x", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x", "=", "x", ".", "float", "(", ")", ".", "sub_", "(", "mean", ")", ".", "div_", "(", "std", ")", "\n", "\n", "", "return", "(", "x", ",", "*", "input", "[", "1", ":", "]", ")", "\n", "\n", "", "return", "normalize_hook", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks": [[7, 32], ["module_hook_cfg.pop", "getattr", "module_hook_cfg.pop", "handles.append", "hasattr", "ValueError", "getattr.register_forward_pre_hook", "mmcv.utils.build_from_cfg().hook_func", "getattr.register_forward_hook", "mmcv.utils.build_from_cfg().hook_func", "getattr.register_backward_hook", "ValueError", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg().hook_func", "mmcv.utils.build_from_cfg", "mmcv.utils.build_from_cfg"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.GPUNormalize.hook_func", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.GPUNormalize.hook_func", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.GPUNormalize.hook_func"], ["def", "register_module_hooks", "(", "Module", ",", "module_hooks_list", ")", ":", "\n", "    ", "handles", "=", "[", "]", "\n", "for", "module_hook_cfg", "in", "module_hooks_list", ":", "\n", "        ", "hooked_module_name", "=", "module_hook_cfg", ".", "pop", "(", "'hooked_module'", ",", "'backbone'", ")", "\n", "if", "not", "hasattr", "(", "Module", ",", "hooked_module_name", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'{Module.__class__} has no {hooked_module_name}!'", ")", "\n", "", "hooked_module", "=", "getattr", "(", "Module", ",", "hooked_module_name", ")", "\n", "hook_pos", "=", "module_hook_cfg", ".", "pop", "(", "'hook_pos'", ",", "'forward_pre'", ")", "\n", "\n", "if", "hook_pos", "==", "'forward_pre'", ":", "\n", "            ", "handle", "=", "hooked_module", ".", "register_forward_pre_hook", "(", "\n", "build_from_cfg", "(", "module_hook_cfg", ",", "MODULE_HOOKS", ")", ".", "hook_func", "(", ")", ")", "\n", "", "elif", "hook_pos", "==", "'forward'", ":", "\n", "            ", "handle", "=", "hooked_module", ".", "register_forward_hook", "(", "\n", "build_from_cfg", "(", "module_hook_cfg", ",", "MODULE_HOOKS", ")", ".", "hook_func", "(", ")", ")", "\n", "", "elif", "hook_pos", "==", "'backward'", ":", "\n", "            ", "handle", "=", "hooked_module", ".", "register_backward_hook", "(", "\n", "build_from_cfg", "(", "module_hook_cfg", ",", "MODULE_HOOKS", ")", ".", "hook_func", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'hook_pos must be `forward_pre`, `forward` or `backward`, '", "\n", "f'but get {hook_pos}'", ")", "\n", "", "handles", ".", "append", "(", "handle", ")", "\n", "", "return", "handles", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.post_processing.post_processing": [[4, 45], ["range", "len", "mmaction.localization.soft_nms", "min", "float", "proposal_list.append", "float", "len", "result[].argsort", "max", "min"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.soft_nms"], ["def", "post_processing", "(", "result", ",", "video_info", ",", "soft_nms_alpha", ",", "soft_nms_low_threshold", ",", "\n", "soft_nms_high_threshold", ",", "post_process_top_k", ",", "\n", "feature_extraction_interval", ")", ":", "\n", "    ", "\"\"\"Post process for temporal proposals generation.\n\n    Args:\n        result (np.ndarray): Proposals generated by network.\n        video_info (dict): Meta data of video. Required keys are\n            'duration_frame', 'duration_second'.\n        soft_nms_alpha (float): Alpha value of Gaussian decaying function.\n        soft_nms_low_threshold (float): Low threshold for soft nms.\n        soft_nms_high_threshold (float): High threshold for soft nms.\n        post_process_top_k (int): Top k values to be considered.\n        feature_extraction_interval (int): Interval used in feature extraction.\n\n    Returns:\n        list[dict]: The updated proposals, e.g.\n            [{'score': 0.9, 'segment': [0, 1]},\n             {'score': 0.8, 'segment': [0, 2]},\n            ...].\n    \"\"\"", "\n", "if", "len", "(", "result", ")", ">", "1", ":", "\n", "        ", "result", "=", "soft_nms", "(", "result", ",", "soft_nms_alpha", ",", "soft_nms_low_threshold", ",", "\n", "soft_nms_high_threshold", ",", "post_process_top_k", ")", "\n", "\n", "", "result", "=", "result", "[", "result", "[", ":", ",", "-", "1", "]", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "video_duration", "=", "float", "(", "\n", "video_info", "[", "'duration_frame'", "]", "//", "feature_extraction_interval", "*", "\n", "feature_extraction_interval", "\n", ")", "/", "video_info", "[", "'duration_frame'", "]", "*", "video_info", "[", "'duration_second'", "]", "\n", "proposal_list", "=", "[", "]", "\n", "\n", "for", "j", "in", "range", "(", "min", "(", "post_process_top_k", ",", "len", "(", "result", ")", ")", ")", ":", "\n", "        ", "proposal", "=", "{", "}", "\n", "proposal", "[", "'score'", "]", "=", "float", "(", "result", "[", "j", ",", "-", "1", "]", ")", "\n", "proposal", "[", "'segment'", "]", "=", "[", "\n", "max", "(", "0", ",", "result", "[", "j", ",", "0", "]", ")", "*", "video_duration", ",", "\n", "min", "(", "1", ",", "result", "[", "j", ",", "1", "]", ")", "*", "video_duration", "\n", "]", "\n", "proposal_list", ".", "append", "(", "proposal", ")", "\n", "", "return", "proposal_list", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.image_dataset.ImageDataset.__init__": [[43, 45], ["video_dataset.VideoDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "ann_file", ",", "pipeline", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "start_index", "=", "None", ",", "**", "kwargs", ")", "\n", "# use `start_index=None` to indicate it is for `ImageDataset`", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.audio_visual_dataset.AudioVisualDataset.__init__": [[30, 35], ["kwargs.pop", "kwargs.get", "rawframe_dataset.RawframeDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "ann_file", ",", "pipeline", ",", "audio_prefix", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "audio_prefix", "=", "audio_prefix", "\n", "self", ".", "video_prefix", "=", "kwargs", ".", "pop", "(", "'video_prefix'", ",", "None", ")", "\n", "self", ".", "data_prefix", "=", "kwargs", ".", "get", "(", "'data_prefix'", ",", "None", ")", "\n", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.audio_visual_dataset.AudioVisualDataset.load_annotations": [[36, 77], ["open", "line.strip().split", "video_infos.append", "os.join", "os.join", "os.join", "int", "int", "int", "int", "len", "line.strip", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "video_infos", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video_info", "=", "{", "}", "\n", "idx", "=", "0", "\n", "# idx for frame_dir", "\n", "frame_dir", "=", "line_split", "[", "idx", "]", "\n", "if", "self", ".", "audio_prefix", "is", "not", "None", ":", "\n", "                    ", "audio_path", "=", "osp", ".", "join", "(", "self", ".", "audio_prefix", ",", "\n", "frame_dir", "+", "'.npy'", ")", "\n", "video_info", "[", "'audio_path'", "]", "=", "audio_path", "\n", "", "if", "self", ".", "video_prefix", ":", "\n", "                    ", "video_path", "=", "osp", ".", "join", "(", "self", ".", "video_prefix", ",", "\n", "frame_dir", "+", "'.mp4'", ")", "\n", "video_info", "[", "'filename'", "]", "=", "video_path", "\n", "", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                    ", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "frame_dir", ")", "\n", "video_info", "[", "'frame_dir'", "]", "=", "frame_dir", "\n", "", "idx", "+=", "1", "\n", "if", "self", ".", "with_offset", ":", "\n", "# idx for offset and total_frames", "\n", "                    ", "video_info", "[", "'offset'", "]", "=", "int", "(", "line_split", "[", "idx", "]", ")", "\n", "video_info", "[", "'total_frames'", "]", "=", "int", "(", "line_split", "[", "idx", "+", "1", "]", ")", "\n", "idx", "+=", "2", "\n", "", "else", ":", "\n", "# idx for total_frames", "\n", "                    ", "video_info", "[", "'total_frames'", "]", "=", "int", "(", "line_split", "[", "idx", "]", ")", "\n", "idx", "+=", "1", "\n", "# idx for label[s]", "\n", "", "label", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line_split", "[", "idx", ":", "]", "]", "\n", "assert", "len", "(", "label", ")", "!=", "0", ",", "f'missing label in line: {line}'", "\n", "if", "self", ".", "multi_class", ":", "\n", "                    ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "video_info", "[", "'label'", "]", "=", "label", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "label", ")", "==", "1", "\n", "video_info", "[", "'label'", "]", "=", "label", "[", "0", "]", "\n", "", "video_infos", ".", "append", "(", "video_info", ")", "\n", "", "", "return", "video_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.audio_feature_dataset.AudioFeatureDataset.__init__": [[31, 34], ["base.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "ann_file", ",", "pipeline", ",", "suffix", "=", "'.npy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "suffix", "=", "suffix", "\n", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "modality", "=", "'Audio'", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.audio_feature_dataset.AudioFeatureDataset.load_annotations": [[35, 71], ["audio_feature_dataset.AudioFeatureDataset.ann_file.endswith", "audio_feature_dataset.AudioFeatureDataset.load_json_annotations", "open", "line.strip().split", "int", "video_infos.append", "int", "torch.zeros", "line.strip", "os.join.endswith", "os.join", "len", "os.join"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "if", "self", ".", "ann_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "            ", "return", "self", ".", "load_json_annotations", "(", ")", "\n", "", "video_infos", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video_info", "=", "{", "}", "\n", "idx", "=", "0", "\n", "filename", "=", "line_split", "[", "idx", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                    ", "if", "not", "filename", ".", "endswith", "(", "self", ".", "suffix", ")", ":", "\n", "                        ", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "\n", "filename", ")", "+", "self", ".", "suffix", "\n", "", "else", ":", "\n", "                        ", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "filename", ")", "\n", "", "", "video_info", "[", "'audio_path'", "]", "=", "filename", "\n", "idx", "+=", "1", "\n", "# idx for total_frames", "\n", "video_info", "[", "'total_frames'", "]", "=", "int", "(", "line_split", "[", "idx", "]", ")", "\n", "idx", "+=", "1", "\n", "# idx for label[s]", "\n", "label", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line_split", "[", "idx", ":", "]", "]", "\n", "assert", "label", ",", "f'missing label in line: {line}'", "\n", "if", "self", ".", "multi_class", ":", "\n", "                    ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "label", "]", "=", "1.0", "\n", "video_info", "[", "'label'", "]", "=", "onehot", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "label", ")", "==", "1", "\n", "video_info", "[", "'label'", "]", "=", "label", "[", "0", "]", "\n", "", "video_infos", ".", "append", "(", "video_info", ")", "\n", "\n", "", "", "return", "video_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.__init__": [[58, 101], ["torch.utils.data.Dataset.__init__", "pipelines.Compose", "base.BaseDataset.load_annotations", "os.realpath", "base.BaseDataset.parse_by_class", "base.BaseDataset.video_infos_by_class.items", "sum", "dict", "os.isdir", "class_prob.append", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.load_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.parse_by_class"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n", "                ", "class_prob", ".", "append", "(", "len", "(", "samples", ")", "/", "len", "(", "self", ".", "video_infos", ")", ")", "\n", "", "class_prob", "=", "[", "x", "**", "self", ".", "power", "for", "x", "in", "class_prob", "]", "\n", "\n", "summ", "=", "sum", "(", "class_prob", ")", "\n", "class_prob", "=", "[", "x", "/", "summ", "for", "x", "in", "class_prob", "]", "\n", "\n", "self", ".", "class_prob", "=", "dict", "(", "zip", "(", "self", ".", "video_infos_by_class", ",", "class_prob", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.load_annotations": [[102, 105], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.load_json_annotations": [[108, 124], ["mmcv.load", "len", "range", "os.join", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "path_key", "=", "'frame_dir'", "if", "'frame_dir'", "in", "video_infos", "[", "0", "]", "else", "'filename'", "\n", "for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n", "if", "self", ".", "multi_class", ":", "\n", "                ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "video_infos", "[", "i", "]", "[", "'label'", "]", ")", "==", "1", "\n", "video_infos", "[", "i", "]", "[", "'label'", "]", "=", "video_infos", "[", "i", "]", "[", "'label'", "]", "[", "0", "]", "\n", "", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.parse_by_class": [[125, 131], ["collections.defaultdict", "video_infos_by_class[].append"], "methods", ["None"], ["", "def", "parse_by_class", "(", "self", ")", ":", "\n", "        ", "video_infos_by_class", "=", "defaultdict", "(", "list", ")", "\n", "for", "item", "in", "self", ".", "video_infos", ":", "\n", "            ", "label", "=", "item", "[", "'label'", "]", "\n", "video_infos_by_class", "[", "label", "]", ".", "append", "(", "item", ")", "\n", "", "return", "video_infos_by_class", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.label2array": [[132, 137], ["numpy.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "label2array", "(", "num", ",", "label", ")", ":", "\n", "        ", "arr", "=", "np", ".", "zeros", "(", "num", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr", "[", "label", "]", "=", "1.", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.evaluate": [[138, 242], ["dict", "copy.deepcopy", "collections.OrderedDict", "warnings.warn", "dict", "isinstance", "TypeError", "len", "len", "isinstance", "mmcv.utils.print_log", "dict", "len", "len", "KeyError", "copy.deepcopy.setdefault().setdefault", "isinstance", "core.top_k_accuracy", "zip", "mmcv.utils.print_log", "core.mean_class_accuracy", "mmcv.utils.print_log", "mmcv.utils.print_log", "isinstance", "TypeError", "log_msg.append", "base.BaseDataset.label2array", "core.mean_average_precision", "type", "copy.deepcopy.setdefault", "core.mmit_mean_average_precision", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.label2array", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_average_precision", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mmit_mean_average_precision"], ["", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'top_k_accuracy'", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "(", "1", ",", "5", ")", ")", ")", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        ", "\"\"\"Perform evaluation for common datasets.\n\n        Args:\n            results (list): Output results.\n            metrics (str | sequence[str]): Metrics to be performed.\n                Defaults: 'top_k_accuracy'.\n            metric_options (dict): Dict for metric options. Options are\n                ``topk`` for ``top_k_accuracy``.\n                Default: ``dict(top_k_accuracy=dict(topk=(1, 5)))``.\n            logger (logging.Logger | None): Logger for recording.\n                Default: None.\n            deprecated_kwargs (dict): Used for containing deprecated arguments.\n                See 'https://github.com/open-mmlab/mmaction2/pull/286'.\n\n        Returns:\n            dict: Evaluation results dict.\n        \"\"\"", "\n", "# Protect ``metric_options`` since it uses mutable value as default", "\n", "metric_options", "=", "copy", ".", "deepcopy", "(", "metric_options", ")", "\n", "\n", "if", "deprecated_kwargs", "!=", "{", "}", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'Option arguments for metrics has been changed to '", "\n", "\"`metric_options`, See 'https://github.com/open-mmlab/mmaction2/pull/286' \"", "# noqa: E501", "\n", "'for more details'", ")", "\n", "metric_options", "[", "'top_k_accuracy'", "]", "=", "dict", "(", "\n", "metric_options", "[", "'top_k_accuracy'", "]", ",", "**", "deprecated_kwargs", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'results must be a list, but got {type(results)}'", ")", "\n", "", "assert", "len", "(", "results", ")", "==", "len", "(", "self", ")", ",", "(", "\n", "f'The length of results is not equal to the dataset len: '", "\n", "f'{len(results)} != {len(self)}'", ")", "\n", "\n", "metrics", "=", "metrics", "if", "isinstance", "(", "metrics", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "metrics", "]", "\n", "allowed_metrics", "=", "[", "\n", "'top_k_accuracy'", ",", "'mean_class_accuracy'", ",", "'mean_average_precision'", ",", "\n", "'mmit_mean_average_precision'", "\n", "]", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported'", ")", "\n", "\n", "", "", "eval_results", "=", "OrderedDict", "(", ")", "\n", "gt_labels", "=", "[", "ann", "[", "'label'", "]", "for", "ann", "in", "self", ".", "video_infos", "]", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "msg", "=", "f'Evaluating {metric} ...'", "\n", "if", "logger", "is", "None", ":", "\n", "                ", "msg", "=", "'\\n'", "+", "msg", "\n", "", "print_log", "(", "msg", ",", "logger", "=", "logger", ")", "\n", "\n", "if", "metric", "==", "'top_k_accuracy'", ":", "\n", "                ", "topk", "=", "metric_options", ".", "setdefault", "(", "'top_k_accuracy'", ",", "\n", "{", "}", ")", ".", "setdefault", "(", "\n", "'topk'", ",", "(", "1", ",", "5", ")", ")", "\n", "if", "not", "isinstance", "(", "topk", ",", "(", "int", ",", "tuple", ")", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "'topk must be int or tuple of int, '", "\n", "f'but got {type(topk)}'", ")", "\n", "", "if", "isinstance", "(", "topk", ",", "int", ")", ":", "\n", "                    ", "topk", "=", "(", "topk", ",", ")", "\n", "\n", "", "top_k_acc", "=", "top_k_accuracy", "(", "results", ",", "gt_labels", ",", "topk", ")", "\n", "log_msg", "=", "[", "]", "\n", "for", "k", ",", "acc", "in", "zip", "(", "topk", ",", "top_k_acc", ")", ":", "\n", "                    ", "eval_results", "[", "f'top{k}_acc'", "]", "=", "acc", "\n", "log_msg", ".", "append", "(", "f'\\ntop{k}_acc\\t{acc:.4f}'", ")", "\n", "", "log_msg", "=", "''", ".", "join", "(", "log_msg", ")", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "continue", "\n", "\n", "", "if", "metric", "==", "'mean_class_accuracy'", ":", "\n", "                ", "mean_acc", "=", "mean_class_accuracy", "(", "results", ",", "gt_labels", ")", "\n", "eval_results", "[", "'mean_class_accuracy'", "]", "=", "mean_acc", "\n", "log_msg", "=", "f'\\nmean_acc\\t{mean_acc:.4f}'", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "continue", "\n", "\n", "", "if", "metric", "in", "[", "\n", "'mean_average_precision'", ",", "'mmit_mean_average_precision'", "\n", "]", ":", "\n", "                ", "gt_labels", "=", "[", "\n", "self", ".", "label2array", "(", "self", ".", "num_classes", ",", "label", ")", "\n", "for", "label", "in", "gt_labels", "\n", "]", "\n", "if", "metric", "==", "'mean_average_precision'", ":", "\n", "                    ", "mAP", "=", "mean_average_precision", "(", "results", ",", "gt_labels", ")", "\n", "eval_results", "[", "'mean_average_precision'", "]", "=", "mAP", "\n", "log_msg", "=", "f'\\nmean_average_precision\\t{mAP:.4f}'", "\n", "", "elif", "metric", "==", "'mmit_mean_average_precision'", ":", "\n", "                    ", "mAP", "=", "mmit_mean_average_precision", "(", "results", ",", "gt_labels", ")", "\n", "eval_results", "[", "'mmit_mean_average_precision'", "]", "=", "mAP", "\n", "log_msg", "=", "f'\\nmmit_mean_average_precision\\t{mAP:.4f}'", "\n", "", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "continue", "\n", "\n", "", "", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.dump_results": [[243, 247], ["mmcv.dump"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dump_results", "(", "results", ",", "out", ")", ":", "\n", "        ", "\"\"\"Dump data to json/yaml/pickle strings or files.\"\"\"", "\n", "return", "mmcv", ".", "dump", "(", "results", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.prepare_train_frames": [[248, 262], ["copy.deepcopy", "base.BaseDataset.pipeline", "isinstance", "torch.zeros"], "methods", ["None"], ["", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "# prepare tensor in getitem", "\n", "# If HVU, type(results['label']) is dict", "\n", "if", "self", ".", "multi_class", "and", "isinstance", "(", "results", "[", "'label'", "]", ",", "list", ")", ":", "\n", "            ", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "results", "[", "'label'", "]", "]", "=", "1.", "\n", "results", "[", "'label'", "]", "=", "onehot", "\n", "\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.prepare_test_frames": [[263, 277], ["copy.deepcopy", "base.BaseDataset.pipeline", "isinstance", "torch.zeros"], "methods", ["None"], ["", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "# prepare tensor in getitem", "\n", "# If HVU, type(results['label']) is dict", "\n", "if", "self", ".", "multi_class", "and", "isinstance", "(", "results", "[", "'label'", "]", ",", "list", ")", ":", "\n", "            ", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "results", "[", "'label'", "]", "]", "=", "1.", "\n", "results", "[", "'label'", "]", "=", "onehot", "\n", "\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.__len__": [[278, 281], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the size of the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "video_infos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.base.BaseDataset.__getitem__": [[282, 288], ["base.BaseDataset.prepare_train_frames", "base.BaseDataset.prepare_test_frames"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.prepare_train_frames", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.prepare_test_frames"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get the sample for either training or testing given index.\"\"\"", "\n", "if", "self", ".", "test_mode", ":", "\n", "            ", "return", "self", ".", "prepare_test_frames", "(", "idx", ")", "\n", "\n", "", "return", "self", ".", "prepare_train_frames", "(", "idx", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.video_dataset.VideoDataset.__init__": [[38, 40], ["base.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "ann_file", ",", "pipeline", ",", "start_index", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "start_index", "=", "start_index", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.video_dataset.VideoDataset.load_annotations": [[41, 61], ["video_dataset.VideoDataset.ann_file.endswith", "video_dataset.VideoDataset.load_json_annotations", "open", "line.strip().split", "video_infos.append", "list", "int", "os.join", "dict", "line.strip", "map"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "if", "self", ".", "ann_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "            ", "return", "self", ".", "load_json_annotations", "(", ")", "\n", "\n", "", "video_infos", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "self", ".", "multi_class", ":", "\n", "                    ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "filename", ",", "label", "=", "line_split", "[", "0", "]", ",", "line_split", "[", "1", ":", "]", "\n", "label", "=", "list", "(", "map", "(", "int", ",", "label", ")", ")", "\n", "", "else", ":", "\n", "                    ", "filename", ",", "label", "=", "line_split", "\n", "label", "=", "int", "(", "label", ")", "\n", "", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                    ", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "filename", ")", "\n", "", "video_infos", ".", "append", "(", "dict", "(", "filename", "=", "filename", ",", "label", "=", "label", ")", ")", "\n", "", "", "return", "video_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.__init__": [[66, 89], ["len", "sum", "dict", "range", "dict", "kwargs.pop", "base.BaseDataset.__init__", "len", "len", "zip", "hvu_dataset.HVUDataset.start_idx.append", "zip"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "tag_categories", ",", "\n", "tag_category_nums", ",", "\n", "filename_tmpl", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "tag_categories", ")", "==", "len", "(", "tag_category_nums", ")", "\n", "self", ".", "tag_categories", "=", "tag_categories", "\n", "self", ".", "tag_category_nums", "=", "tag_category_nums", "\n", "self", ".", "filename_tmpl", "=", "filename_tmpl", "\n", "self", ".", "num_categories", "=", "len", "(", "self", ".", "tag_categories", ")", "\n", "self", ".", "num_tags", "=", "sum", "(", "self", ".", "tag_category_nums", ")", "\n", "self", ".", "category2num", "=", "dict", "(", "zip", "(", "tag_categories", ",", "tag_category_nums", ")", ")", "\n", "self", ".", "start_idx", "=", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_categories", "-", "1", ")", ":", "\n", "            ", "self", ".", "start_idx", ".", "append", "(", "self", ".", "start_idx", "[", "-", "1", "]", "+", "\n", "self", ".", "tag_category_nums", "[", "i", "]", ")", "\n", "", "self", ".", "category2startidx", "=", "dict", "(", "zip", "(", "tag_categories", ",", "self", ".", "start_idx", ")", ")", "\n", "self", ".", "start_index", "=", "kwargs", ".", "pop", "(", "'start_index'", ",", "0", ")", "\n", "self", ".", "dataset_type", "=", "None", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "ann_file", ",", "pipeline", ",", "start_index", "=", "self", ".", "start_index", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.load_annotations": [[90, 94], ["hvu_dataset.HVUDataset.ann_file.endswith", "hvu_dataset.HVUDataset.load_json_annotations"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "assert", "self", ".", "ann_file", ".", "endswith", "(", "'.json'", ")", "\n", "return", "self", ".", "load_json_annotations", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.load_json_annotations": [[95, 121], ["mmcv.load", "len", "range", "os.join"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "\n", "video_info0", "=", "video_infos", "[", "0", "]", "\n", "assert", "(", "'filename'", "in", "video_info0", ")", "!=", "(", "'frame_dir'", "in", "video_info0", ")", "\n", "path_key", "=", "'filename'", "if", "'filename'", "in", "video_info0", "else", "'frame_dir'", "\n", "self", ".", "dataset_type", "=", "'video'", "if", "path_key", "==", "'filename'", "else", "'rawframe'", "\n", "if", "self", ".", "dataset_type", "==", "'rawframe'", ":", "\n", "            ", "assert", "self", ".", "filename_tmpl", "is", "not", "None", "\n", "\n", "", "for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n", "\n", "# We will convert label to torch tensors in the pipeline", "\n", "video_infos", "[", "i", "]", "[", "'categories'", "]", "=", "self", ".", "tag_categories", "\n", "video_infos", "[", "i", "]", "[", "'category_nums'", "]", "=", "self", ".", "tag_category_nums", "\n", "if", "self", ".", "dataset_type", "==", "'rawframe'", ":", "\n", "                ", "video_infos", "[", "i", "]", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "video_infos", "[", "i", "]", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "video_infos", "[", "i", "]", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "\n", "", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.label2array": [[122, 127], ["numpy.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "label2array", "(", "num", ",", "label", ")", ":", "\n", "        ", "arr", "=", "np", ".", "zeros", "(", "num", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr", "[", "label", "]", "=", "1.", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.evaluate": [[128, 192], ["copy.deepcopy", "collections.OrderedDict", "isinstance", "TypeError", "len", "len", "isinstance", "len", "core.mean_average_precision", "mmcv.utils.print_log", "len", "len", "hvu_dataset.HVUDataset.label2array", "enumerate", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_average_precision", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.hvu_dataset.HVUDataset.label2array"], ["", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'mean_average_precision'", ",", "\n", "metric_options", "=", "None", ",", "\n", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Evaluation in HVU Video Dataset. We only support evaluating mAP for\n        each tag categories. Since some tag categories are missing for some\n        videos, we can not evaluate mAP for all tags.\n\n        Args:\n            results (list): Output results.\n            metrics (str | sequence[str]): Metrics to be performed.\n                Defaults: 'mean_average_precision'.\n            metric_options (dict | None): Dict for metric options.\n                Default: None.\n            logger (logging.Logger | None): Logger for recording.\n                Default: None.\n\n        Returns:\n            dict: Evaluation results dict.\n        \"\"\"", "\n", "# Protect ``metric_options`` since it uses mutable value as default", "\n", "metric_options", "=", "copy", ".", "deepcopy", "(", "metric_options", ")", "\n", "\n", "if", "not", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'results must be a list, but got {type(results)}'", ")", "\n", "", "assert", "len", "(", "results", ")", "==", "len", "(", "self", ")", ",", "(", "\n", "f'The length of results is not equal to the dataset len: '", "\n", "f'{len(results)} != {len(self)}'", ")", "\n", "\n", "metrics", "=", "metrics", "if", "isinstance", "(", "metrics", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "metrics", "]", "\n", "\n", "# There should be only one metric in the metrics list:", "\n", "# 'mean_average_precision'", "\n", "assert", "len", "(", "metrics", ")", "==", "1", "\n", "metric", "=", "metrics", "[", "0", "]", "\n", "assert", "metric", "==", "'mean_average_precision'", "\n", "\n", "gt_labels", "=", "[", "ann", "[", "'label'", "]", "for", "ann", "in", "self", ".", "video_infos", "]", "\n", "\n", "eval_results", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "category", "in", "self", ".", "tag_categories", ":", "\n", "\n", "            ", "start_idx", "=", "self", ".", "category2startidx", "[", "category", "]", "\n", "num", "=", "self", ".", "category2num", "[", "category", "]", "\n", "preds", "=", "[", "\n", "result", "[", "start_idx", ":", "start_idx", "+", "num", "]", "\n", "for", "video_idx", ",", "result", "in", "enumerate", "(", "results", ")", "\n", "if", "category", "in", "gt_labels", "[", "video_idx", "]", "\n", "]", "\n", "gts", "=", "[", "\n", "gt_label", "[", "category", "]", "for", "gt_label", "in", "gt_labels", "\n", "if", "category", "in", "gt_label", "\n", "]", "\n", "\n", "gts", "=", "[", "self", ".", "label2array", "(", "num", ",", "item", ")", "for", "item", "in", "gts", "]", "\n", "\n", "mAP", "=", "mean_average_precision", "(", "preds", ",", "gts", ")", "\n", "eval_results", "[", "f'{category}_mAP'", "]", "=", "mAP", "\n", "log_msg", "=", "f'\\n{category}_mAP\\t{mAP:.4f}'", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "\n", "", "return", "eval_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.BaseMiniBatchBlending.__init__": [[19, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "smoothing", "=", "0.", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "off_value", "=", "smoothing", "/", "self", ".", "num_classes", "\n", "self", ".", "on_value", "=", "1.", "-", "smoothing", "+", "self", ".", "off_value", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.BaseMiniBatchBlending.do_blending": [[24, 27], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "do_blending", "(", "self", ",", "imgs", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.BaseMiniBatchBlending.__call__": [[28, 62], ["blending_utils.one_hot", "blending_utils.BaseMiniBatchBlending.do_blending"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.one_hot", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.LabelSmoothing.do_blending"], ["", "def", "__call__", "(", "self", ",", "imgs", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Blending data in a mini-batch.\n\n        Images are float tensors with the shape of (B, N, C, H, W) for 2D\n        recognizers or (B, N, C, T, H, W) for 3D recognizers.\n\n        Besides, labels are converted from hard labels to soft labels.\n        Hard labels are integer tensors with the shape of (B, 1) and all of the\n        elements are in the range [0, num_classes - 1].\n        Soft labels (probablity distribution over classes) are float tensors\n        with the shape of (B, 1, num_classes) and all of the elements are in\n        the range [0, 1].\n\n        Args:\n            imgs (torch.Tensor): Model input images, float tensor with the\n                shape of (B, N, C, H, W) or (B, N, C, T, H, W).\n            label (torch.Tensor): Hard labels, integer tensor with the shape\n                of (B, 1) and all elements are in range [0, num_classes).\n            kwargs (dict, optional): Other keyword argument to be used to\n                blending imgs and labels in a mini-batch.\n\n        Returns:\n            mixed_imgs (torch.Tensor): Blending images, float tensor with the\n                same shape of the input imgs.\n            mixed_label (torch.Tensor): Blended soft labels, float tensor with\n                the shape of (B, 1, num_classes) and all elements are in range\n                [0, 1].\n        \"\"\"", "\n", "one_hot_label", "=", "one_hot", "(", "label", ",", "num_classes", "=", "self", ".", "num_classes", ",", "on_value", "=", "self", ".", "on_value", ",", "off_value", "=", "self", ".", "off_value", ",", "device", "=", "label", ".", "device", ")", "\n", "\n", "mixed_imgs", ",", "mixed_label", "=", "self", ".", "do_blending", "(", "imgs", ",", "one_hot_label", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "mixed_imgs", ",", "mixed_label", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.MixupBlending.__init__": [[77, 80], ["blending_utils.BaseMiniBatchBlending.__init__", "torch.distributions.beta.Beta", "torch.distributions.beta.Beta"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "alpha", "=", ".2", ",", "smoothing", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", "=", "num_classes", ",", "smoothing", "=", "smoothing", ")", "\n", "self", ".", "beta", "=", "Beta", "(", "alpha", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.MixupBlending.do_blending": [[81, 93], ["blending_utils.MixupBlending.beta.sample", "imgs.size", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len"], "methods", ["None"], ["", "def", "do_blending", "(", "self", ",", "imgs", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Blending images with mixup.\"\"\"", "\n", "assert", "len", "(", "kwargs", ")", "==", "0", ",", "f'unexpected kwargs for mixup {kwargs}'", "\n", "\n", "lam", "=", "self", ".", "beta", ".", "sample", "(", ")", "\n", "batch_size", "=", "imgs", ".", "size", "(", "0", ")", "\n", "rand_index", "=", "torch", ".", "randperm", "(", "batch_size", ")", "\n", "\n", "mixed_imgs", "=", "lam", "*", "imgs", "+", "(", "1", "-", "lam", ")", "*", "imgs", "[", "rand_index", ",", ":", "]", "\n", "mixed_label", "=", "lam", "*", "label", "+", "(", "1", "-", "lam", ")", "*", "label", "[", "rand_index", ",", ":", "]", "\n", "\n", "return", "mixed_imgs", ",", "mixed_label", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.CutmixBlending.__init__": [[106, 109], ["blending_utils.BaseMiniBatchBlending.__init__", "torch.distributions.beta.Beta", "torch.distributions.beta.Beta"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "alpha", "=", ".2", ",", "smoothing", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", "=", "num_classes", ",", "smoothing", "=", "smoothing", ")", "\n", "self", ".", "beta", "=", "Beta", "(", "alpha", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.CutmixBlending.rand_bbox": [[110, 129], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "int", "int", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rand_bbox", "(", "img_size", ",", "lam", ")", ":", "\n", "        ", "\"\"\"Generate a random boudning box.\"\"\"", "\n", "w", "=", "img_size", "[", "-", "1", "]", "\n", "h", "=", "img_size", "[", "-", "2", "]", "\n", "cut_rat", "=", "torch", ".", "sqrt", "(", "1.", "-", "lam", ")", "\n", "cut_w", "=", "torch", ".", "tensor", "(", "int", "(", "w", "*", "cut_rat", ")", ")", "\n", "cut_h", "=", "torch", ".", "tensor", "(", "int", "(", "h", "*", "cut_rat", ")", ")", "\n", "\n", "# uniform", "\n", "cx", "=", "torch", ".", "randint", "(", "w", ",", "(", "1", ",", ")", ")", "[", "0", "]", "\n", "cy", "=", "torch", ".", "randint", "(", "h", ",", "(", "1", ",", ")", ")", "[", "0", "]", "\n", "\n", "bbx1", "=", "torch", ".", "clamp", "(", "cx", "-", "cut_w", "//", "2", ",", "0", ",", "w", ")", "\n", "bby1", "=", "torch", ".", "clamp", "(", "cy", "-", "cut_h", "//", "2", ",", "0", ",", "h", ")", "\n", "bbx2", "=", "torch", ".", "clamp", "(", "cx", "+", "cut_w", "//", "2", ",", "0", ",", "w", ")", "\n", "bby2", "=", "torch", ".", "clamp", "(", "cy", "+", "cut_h", "//", "2", ",", "0", ",", "h", ")", "\n", "\n", "return", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.CutmixBlending.do_blending": [[130, 147], ["imgs.size", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "blending_utils.CutmixBlending.beta.sample", "blending_utils.CutmixBlending.rand_bbox", "len", "imgs.size", "imgs.size", "imgs.size"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.CutmixBlending.rand_bbox"], ["", "def", "do_blending", "(", "self", ",", "imgs", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Blending images with cutmix.\"\"\"", "\n", "assert", "len", "(", "kwargs", ")", "==", "0", ",", "f'unexpected kwargs for cutmix {kwargs}'", "\n", "\n", "batch_size", "=", "imgs", ".", "size", "(", "0", ")", "\n", "rand_index", "=", "torch", ".", "randperm", "(", "batch_size", ")", "\n", "lam", "=", "self", ".", "beta", ".", "sample", "(", ")", "\n", "\n", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "=", "self", ".", "rand_bbox", "(", "imgs", ".", "size", "(", ")", ",", "lam", ")", "\n", "imgs", "[", ":", ",", "...", ",", "bby1", ":", "bby2", ",", "bbx1", ":", "bbx2", "]", "=", "imgs", "[", "rand_index", ",", "...", ",", "bby1", ":", "bby2", ",", "\n", "bbx1", ":", "bbx2", "]", "\n", "lam", "=", "1", "-", "(", "1.0", "*", "(", "bbx2", "-", "bbx1", ")", "*", "(", "bby2", "-", "bby1", ")", "/", "\n", "(", "imgs", ".", "size", "(", ")", "[", "-", "1", "]", "*", "imgs", ".", "size", "(", ")", "[", "-", "2", "]", ")", ")", "\n", "\n", "label", "=", "lam", "*", "label", "+", "(", "1", "-", "lam", ")", "*", "label", "[", "rand_index", ",", ":", "]", "\n", "\n", "return", "imgs", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.LabelSmoothing.do_blending": [[151, 153], ["None"], "methods", ["None"], ["    ", "def", "do_blending", "(", "self", ",", "imgs", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "imgs", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.one_hot": [[11, 14], ["x.long().view.long().view", "torch.full().scatter_", "torch.full().scatter_", "x.long().view.long", "torch.full", "torch.full", "x.long().view.size"], "function", ["None"], ["def", "one_hot", "(", "x", ",", "num_classes", ",", "on_value", "=", "1.", ",", "off_value", "=", "0.", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "x", "=", "x", ".", "long", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "return", "torch", ".", "full", "(", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "num_classes", ")", ",", "off_value", ",", "device", "=", "device", ")", ".", "scatter_", "(", "1", ",", "x", ",", "on_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset": [[26, 44], ["RepeatDataset", "mmcv.utils.build_from_cfg", "builder.build_dataset"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset"], ["def", "build_dataset", "(", "cfg", ",", "default_args", "=", "None", ")", ":", "\n", "    ", "\"\"\"Build a dataset from config dict.\n\n    Args:\n        cfg (dict): Config dict. It should at least contain the key \"type\".\n        default_args (dict | None, optional): Default initialization arguments.\n            Default: None.\n\n    Returns:\n        Dataset: The constructed dataset.\n    \"\"\"", "\n", "if", "cfg", "[", "'type'", "]", "==", "'RepeatDataset'", ":", "\n", "        ", "from", ".", "dataset_wrappers", "import", "RepeatDataset", "\n", "dataset", "=", "RepeatDataset", "(", "\n", "build_dataset", "(", "cfg", "[", "'dataset'", "]", ",", "default_args", ")", ",", "cfg", "[", "'times'", "]", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "build_from_cfg", "(", "cfg", ",", "DATASETS", ",", "default_args", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader": [[46, 124], ["mmcv.runner.get_dist_info", "getattr", "torch.utils.data.DataLoader", "functools.partial", "getattr", "samplers.ClassSpecificDistributedSampler", "samplers.DistributedSampler", "functools.partial"], "function", ["None"], ["", "def", "build_dataloader", "(", "dataset", ",", "\n", "videos_per_gpu", ",", "\n", "workers_per_gpu", ",", "\n", "num_gpus", "=", "1", ",", "\n", "dist", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "drop_last", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Build PyTorch DataLoader.\n\n    In distributed training, each GPU/process has a dataloader.\n    In non-distributed training, there is only one dataloader for all GPUs.\n\n    Args:\n        dataset (:obj:`Dataset`): A PyTorch dataset.\n        videos_per_gpu (int): Number of videos on each GPU, i.e.,\n            batch size of each GPU.\n        workers_per_gpu (int): How many subprocesses to use for data\n            loading for each GPU.\n        num_gpus (int): Number of GPUs. Only used in non-distributed\n            training. Default: 1.\n        dist (bool): Distributed training/test or not. Default: True.\n        shuffle (bool): Whether to shuffle the data at every epoch.\n            Default: True.\n        seed (int | None): Seed to be used. Default: None.\n        drop_last (bool): Whether to drop the last incomplete batch in epoch.\n            Default: False\n        pin_memory (bool): Whether to use pin_memory in DataLoader.\n            Default: True\n        kwargs (dict, optional): Any keyword argument to be used to initialize\n            DataLoader.\n\n    Returns:\n        DataLoader: A PyTorch dataloader.\n    \"\"\"", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "sample_by_class", "=", "getattr", "(", "dataset", ",", "'sample_by_class'", ",", "False", ")", "\n", "\n", "if", "dist", ":", "\n", "        ", "if", "sample_by_class", ":", "\n", "            ", "dynamic_length", "=", "getattr", "(", "dataset", ",", "'dynamic_length'", ",", "True", ")", "\n", "sampler", "=", "ClassSpecificDistributedSampler", "(", "\n", "dataset", ",", "\n", "world_size", ",", "\n", "rank", ",", "\n", "dynamic_length", "=", "dynamic_length", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "DistributedSampler", "(", "\n", "dataset", ",", "world_size", ",", "rank", ",", "shuffle", "=", "shuffle", ",", "seed", "=", "seed", ")", "\n", "", "shuffle", "=", "False", "\n", "batch_size", "=", "videos_per_gpu", "\n", "num_workers", "=", "workers_per_gpu", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "None", "\n", "batch_size", "=", "num_gpus", "*", "videos_per_gpu", "\n", "num_workers", "=", "num_gpus", "*", "workers_per_gpu", "\n", "\n", "", "init_fn", "=", "partial", "(", "\n", "worker_init_fn", ",", "num_workers", "=", "num_workers", ",", "rank", "=", "rank", ",", "\n", "seed", "=", "seed", ")", "if", "seed", "is", "not", "None", "else", "None", "\n", "\n", "data_loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "partial", "(", "collate", ",", "samples_per_gpu", "=", "videos_per_gpu", ")", ",", "\n", "pin_memory", "=", "pin_memory", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "worker_init_fn", "=", "init_fn", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", "**", "kwargs", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.worker_init_fn": [[126, 133], ["numpy.random.seed", "random.seed"], "function", ["None"], ["", "def", "worker_init_fn", "(", "worker_id", ",", "num_workers", ",", "rank", ",", "seed", ")", ":", "\n", "    ", "\"\"\"Init the random seed for various workers.\"\"\"", "\n", "# The seed of each worker equals to", "\n", "# num_worker * rank + worker_id + user_seed", "\n", "worker_seed", "=", "num_workers", "*", "rank", "+", "worker_id", "+", "seed", "\n", "np", ".", "random", ".", "seed", "(", "worker_seed", ")", "\n", "random", ".", "seed", "(", "worker_seed", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.pose_dataset.PoseDataset.__init__": [[39, 85], ["base.BaseDataset.__init__", "utils.get_root_logger", "utils.get_root_logger.info", "isinstance", "float", "len", "numpy.array", "enumerate"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "valid_ratio", "=", "None", ",", "\n", "box_thr", "=", "None", ",", "\n", "class_prob", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "modality", "=", "'Pose'", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "ann_file", ",", "pipeline", ",", "start_index", "=", "0", ",", "modality", "=", "modality", ",", "**", "kwargs", ")", "\n", "\n", "# box_thr, which should be a string", "\n", "self", ".", "box_thr", "=", "box_thr", "\n", "if", "self", ".", "box_thr", "is", "not", "None", ":", "\n", "            ", "assert", "box_thr", "in", "[", "'0.5'", ",", "'0.6'", ",", "'0.7'", ",", "'0.8'", ",", "'0.9'", "]", "\n", "\n", "# Thresholding Training Examples", "\n", "", "self", ".", "valid_ratio", "=", "valid_ratio", "\n", "if", "self", ".", "valid_ratio", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "self", ".", "valid_ratio", ",", "float", ")", "\n", "if", "self", ".", "box_thr", "is", "None", ":", "\n", "                ", "self", ".", "video_infos", "=", "self", ".", "video_infos", "=", "[", "\n", "x", "for", "x", "in", "self", ".", "video_infos", "\n", "if", "x", "[", "'valid_frames'", "]", "/", "x", "[", "'total_frames'", "]", ">=", "valid_ratio", "\n", "]", "\n", "", "else", ":", "\n", "                ", "key", "=", "f'valid@{self.box_thr}'", "\n", "self", ".", "video_infos", "=", "[", "\n", "x", "for", "x", "in", "self", ".", "video_infos", "\n", "if", "x", "[", "key", "]", "/", "x", "[", "'total_frames'", "]", ">=", "valid_ratio", "\n", "]", "\n", "if", "self", ".", "box_thr", "!=", "'0.5'", ":", "\n", "                    ", "box_thr", "=", "float", "(", "self", ".", "box_thr", ")", "\n", "for", "item", "in", "self", ".", "video_infos", ":", "\n", "                        ", "inds", "=", "[", "\n", "i", "for", "i", ",", "score", "in", "enumerate", "(", "item", "[", "'box_score'", "]", ")", "\n", "if", "score", ">=", "box_thr", "\n", "]", "\n", "item", "[", "'anno_inds'", "]", "=", "np", ".", "array", "(", "inds", ")", "\n", "\n", "", "", "", "", "if", "class_prob", "is", "not", "None", ":", "\n", "            ", "self", ".", "class_prob", "=", "class_prob", "\n", "\n", "", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'{len(self)} videos remain after valid thresholding'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.pose_dataset.PoseDataset.load_annotations": [[86, 90], ["pose_dataset.PoseDataset.ann_file.endswith", "pose_dataset.PoseDataset.load_pkl_annotations"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.pose_dataset.PoseDataset.load_pkl_annotations"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "assert", "self", ".", "ann_file", ".", "endswith", "(", "'.pkl'", ")", "\n", "return", "self", ".", "load_pkl_annotations", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.pose_dataset.PoseDataset.load_pkl_annotations": [[91, 99], ["mmcv.load", "os.join"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_pkl_annotations", "(", "self", ")", ":", "\n", "        ", "data", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "\n", "for", "item", "in", "data", ":", "\n", "# Sometimes we may need to load anno from the file", "\n", "            ", "if", "'filename'", "in", "item", ":", "\n", "                ", "item", "[", "'filename'", "]", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "item", "[", "'filename'", "]", ")", "\n", "", "", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.dataset_wrappers.RepeatDataset.__init__": [[18, 23], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "times", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "times", "=", "times", "\n", "\n", "self", ".", "_ori_len", "=", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.dataset_wrappers.RepeatDataset.__getitem__": [[24, 27], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get data.\"\"\"", "\n", "return", "self", ".", "dataset", "[", "idx", "%", "self", ".", "_ori_len", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.dataset_wrappers.RepeatDataset.__len__": [[28, 31], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Length after repetition.\"\"\"", "\n", "return", "self", ".", "times", "*", "self", ".", "_ori_len", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.__init__": [[76, 78], ["base.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "ann_file", ",", "pipeline", ",", "data_prefix", "=", "None", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "data_prefix", ",", "test_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.load_annotations": [[79, 88], ["mmcv.load", "video_infos.append"], "methods", ["None"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "video_infos", "=", "[", "]", "\n", "anno_database", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "for", "video_name", "in", "anno_database", ":", "\n", "            ", "video_info", "=", "anno_database", "[", "video_name", "]", "\n", "video_info", "[", "'video_name'", "]", "=", "video_name", "\n", "video_infos", ".", "append", "(", "video_info", ")", "\n", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.prepare_test_frames": [[89, 94], ["copy.deepcopy", "activitynet_dataset.ActivityNetDataset.pipeline"], "methods", ["None"], ["", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'data_prefix'", "]", "=", "self", ".", "data_prefix", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.prepare_train_frames": [[95, 100], ["copy.deepcopy", "activitynet_dataset.ActivityNetDataset.pipeline"], "methods", ["None"], ["", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'data_prefix'", "]", "=", "self", ".", "data_prefix", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.__len__": [[101, 104], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the size of the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "video_infos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset._import_ground_truth": [[105, 117], ["numpy.array", "this_video_ground_truths.append"], "methods", ["None"], ["", "def", "_import_ground_truth", "(", "self", ")", ":", "\n", "        ", "\"\"\"Read ground truth data from video_infos.\"\"\"", "\n", "ground_truth", "=", "{", "}", "\n", "for", "video_info", "in", "self", ".", "video_infos", ":", "\n", "            ", "video_id", "=", "video_info", "[", "'video_name'", "]", "[", "2", ":", "]", "\n", "this_video_ground_truths", "=", "[", "]", "\n", "for", "ann", "in", "video_info", "[", "'annotations'", "]", ":", "\n", "                ", "t_start", ",", "t_end", "=", "ann", "[", "'segment'", "]", "\n", "label", "=", "ann", "[", "'label'", "]", "\n", "this_video_ground_truths", ".", "append", "(", "[", "t_start", ",", "t_end", ",", "label", "]", ")", "\n", "", "ground_truth", "[", "video_id", "]", "=", "np", ".", "array", "(", "this_video_ground_truths", ")", "\n", "", "return", "ground_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.proposals2json": [[118, 145], ["print", "mmcv.ProgressBar", "len", "mmcv.ProgressBar.update"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "proposals2json", "(", "results", ",", "show_progress", "=", "False", ")", ":", "\n", "        ", "\"\"\"Convert all proposals to a final dict(json) format.\n\n        Args:\n            results (list[dict]): All proposals.\n            show_progress (bool): Whether to show the progress bar.\n                Defaults: False.\n\n        Returns:\n            dict: The final result dict. E.g.\n\n            .. code-block:: Python\n\n                dict(video-1=[dict(segment=[1.1,2.0]. score=0.9),\n                              dict(segment=[50.1, 129.3], score=0.6)])\n        \"\"\"", "\n", "result_dict", "=", "{", "}", "\n", "print", "(", "'Convert proposals to json format'", ")", "\n", "if", "show_progress", ":", "\n", "            ", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "results", ")", ")", "\n", "", "for", "result", "in", "results", ":", "\n", "            ", "video_name", "=", "result", "[", "'video_name'", "]", "\n", "result_dict", "[", "video_name", "[", "2", ":", "]", "]", "=", "result", "[", "'proposal_list'", "]", "\n", "if", "show_progress", ":", "\n", "                ", "prog_bar", ".", "update", "(", ")", "\n", "", "", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset._import_proposals": [[146, 161], ["numpy.array", "this_video_proposals.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_import_proposals", "(", "results", ")", ":", "\n", "        ", "\"\"\"Read predictions from results.\"\"\"", "\n", "proposals", "=", "{", "}", "\n", "num_proposals", "=", "0", "\n", "for", "result", "in", "results", ":", "\n", "            ", "video_id", "=", "result", "[", "'video_name'", "]", "[", "2", ":", "]", "\n", "this_video_proposals", "=", "[", "]", "\n", "for", "proposal", "in", "result", "[", "'proposal_list'", "]", ":", "\n", "                ", "t_start", ",", "t_end", "=", "proposal", "[", "'segment'", "]", "\n", "score", "=", "proposal", "[", "'score'", "]", "\n", "this_video_proposals", ".", "append", "(", "[", "t_start", ",", "t_end", ",", "score", "]", ")", "\n", "num_proposals", "+=", "1", "\n", "", "proposals", "[", "video_id", "]", "=", "np", ".", "array", "(", "this_video_proposals", ")", "\n", "", "return", "proposals", ",", "num_proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.dump_results": [[162, 188], ["activitynet_dataset.ActivityNetDataset.proposals2json", "mmcv.dump", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "ValueError", "os.join", "os.join", "numpy.savetxt"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.proposals2json", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "dump_results", "(", "self", ",", "results", ",", "out", ",", "output_format", ",", "version", "=", "'VERSION 1.3'", ")", ":", "\n", "        ", "\"\"\"Dump data to json/csv files.\"\"\"", "\n", "if", "output_format", "==", "'json'", ":", "\n", "            ", "result_dict", "=", "self", ".", "proposals2json", "(", "results", ")", "\n", "output_dict", "=", "{", "\n", "'version'", ":", "version", ",", "\n", "'results'", ":", "result_dict", ",", "\n", "'external_data'", ":", "{", "}", "\n", "}", "\n", "mmcv", ".", "dump", "(", "output_dict", ",", "out", ")", "\n", "", "elif", "output_format", "==", "'csv'", ":", "\n", "# TODO: add csv handler to mmcv and use mmcv.dump", "\n", "            ", "os", ".", "makedirs", "(", "out", ",", "exist_ok", "=", "True", ")", "\n", "header", "=", "'action,start,end,tmin,tmax'", "\n", "for", "result", "in", "results", ":", "\n", "                ", "video_name", ",", "outputs", "=", "result", "\n", "output_path", "=", "osp", ".", "join", "(", "out", ",", "video_name", "+", "'.csv'", ")", "\n", "np", ".", "savetxt", "(", "\n", "output_path", ",", "\n", "outputs", ",", "\n", "header", "=", "header", ",", "\n", "delimiter", "=", "','", ",", "\n", "comments", "=", "''", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'The output format {output_format} is not supported.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.evaluate": [[189, 270], ["copy.deepcopy", "collections.OrderedDict", "activitynet_dataset.ActivityNetDataset._import_ground_truth", "activitynet_dataset.ActivityNetDataset._import_proposals", "dict", "warnings.warn", "dict", "isinstance", "TypeError", "len", "len", "isinstance", "len", "len", "KeyError", "copy.deepcopy.setdefault().setdefault", "copy.deepcopy.setdefault().setdefault", "isinstance", "core.average_recall_at_avg_proposals", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.linspace", "numpy.linspace", "numpy.array", "type", "copy.deepcopy.setdefault", "copy.deepcopy.setdefault"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization._import_ground_truth", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset._import_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_recall_at_avg_proposals"], ["", "", "def", "evaluate", "(", "\n", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'AR@AN'", ",", "\n", "metric_options", "=", "{", "\n", "'AR@AN'", ":", "\n", "dict", "(", "\n", "max_avg_proposals", "=", "100", ",", "\n", "temporal_iou_thresholds", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "10", ")", ")", "\n", "}", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        ", "\"\"\"Evaluation in feature dataset.\n\n        Args:\n            results (list[dict]): Output results.\n            metrics (str | sequence[str]): Metrics to be performed.\n                Defaults: 'AR@AN'.\n            metric_options (dict): Dict for metric options. Options are\n                ``max_avg_proposals``, ``temporal_iou_thresholds`` for\n                ``AR@AN``.\n                default: ``{'AR@AN': dict(max_avg_proposals=100,\n                temporal_iou_thresholds=np.linspace(0.5, 0.95, 10))}``.\n            logger (logging.Logger | None): Training logger. Defaults: None.\n            deprecated_kwargs (dict): Used for containing deprecated arguments.\n                See 'https://github.com/open-mmlab/mmaction2/pull/286'.\n\n        Returns:\n            dict: Evaluation results for evaluation metrics.\n        \"\"\"", "\n", "# Protect ``metric_options`` since it uses mutable value as default", "\n", "metric_options", "=", "copy", ".", "deepcopy", "(", "metric_options", ")", "\n", "\n", "if", "deprecated_kwargs", "!=", "{", "}", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'Option arguments for metrics has been changed to '", "\n", "\"`metric_options`, See 'https://github.com/open-mmlab/mmaction2/pull/286' \"", "# noqa: E501", "\n", "'for more details'", ")", "\n", "metric_options", "[", "'AR@AN'", "]", "=", "dict", "(", "metric_options", "[", "'AR@AN'", "]", ",", "\n", "**", "deprecated_kwargs", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'results must be a list, but got {type(results)}'", ")", "\n", "", "assert", "len", "(", "results", ")", "==", "len", "(", "self", ")", ",", "(", "\n", "f'The length of results is not equal to the dataset len: '", "\n", "f'{len(results)} != {len(self)}'", ")", "\n", "\n", "metrics", "=", "metrics", "if", "isinstance", "(", "metrics", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "metrics", "]", "\n", "allowed_metrics", "=", "[", "'AR@AN'", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported'", ")", "\n", "\n", "", "", "eval_results", "=", "OrderedDict", "(", ")", "\n", "ground_truth", "=", "self", ".", "_import_ground_truth", "(", ")", "\n", "proposal", ",", "num_proposals", "=", "self", ".", "_import_proposals", "(", "results", ")", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "==", "'AR@AN'", ":", "\n", "                ", "temporal_iou_thresholds", "=", "metric_options", ".", "setdefault", "(", "\n", "'AR@AN'", ",", "{", "}", ")", ".", "setdefault", "(", "'temporal_iou_thresholds'", ",", "\n", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "10", ")", ")", "\n", "max_avg_proposals", "=", "metric_options", ".", "setdefault", "(", "\n", "'AR@AN'", ",", "{", "}", ")", ".", "setdefault", "(", "'max_avg_proposals'", ",", "100", ")", "\n", "if", "isinstance", "(", "temporal_iou_thresholds", ",", "list", ")", ":", "\n", "                    ", "temporal_iou_thresholds", "=", "np", ".", "array", "(", "temporal_iou_thresholds", ")", "\n", "\n", "", "recall", ",", "_", ",", "_", ",", "auc", "=", "(", "\n", "average_recall_at_avg_proposals", "(", "\n", "ground_truth", ",", "\n", "proposal", ",", "\n", "num_proposals", ",", "\n", "max_avg_proposals", "=", "max_avg_proposals", ",", "\n", "temporal_iou_thresholds", "=", "temporal_iou_thresholds", ")", ")", "\n", "eval_results", "[", "'auc'", "]", "=", "auc", "\n", "eval_results", "[", "'AR@1'", "]", "=", "np", ".", "mean", "(", "recall", "[", ":", ",", "0", "]", ")", "\n", "eval_results", "[", "'AR@5'", "]", "=", "np", ".", "mean", "(", "recall", "[", ":", ",", "4", "]", ")", "\n", "eval_results", "[", "'AR@10'", "]", "=", "np", ".", "mean", "(", "recall", "[", ":", ",", "9", "]", ")", "\n", "eval_results", "[", "'AR@100'", "]", "=", "np", ".", "mean", "(", "recall", "[", ":", ",", "99", "]", ")", "\n", "\n", "", "", "return", "eval_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNInstance.__init__": [[32, 49], ["min"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "start_frame", ",", "\n", "end_frame", ",", "\n", "num_video_frames", ",", "\n", "label", "=", "None", ",", "\n", "best_iou", "=", "0", ",", "\n", "overlap_self", "=", "0", ")", ":", "\n", "        ", "self", ".", "start_frame", "=", "start_frame", "\n", "self", ".", "end_frame", "=", "min", "(", "end_frame", ",", "num_video_frames", ")", "\n", "self", ".", "num_video_frames", "=", "num_video_frames", "\n", "self", ".", "label", "=", "label", "if", "label", "is", "not", "None", "else", "-", "1", "\n", "self", ".", "coverage", "=", "(", "end_frame", "-", "start_frame", ")", "/", "num_video_frames", "\n", "self", ".", "best_iou", "=", "best_iou", "\n", "self", ".", "overlap_self", "=", "overlap_self", "\n", "self", ".", "loc_reg", "=", "None", "\n", "self", ".", "size_reg", "=", "None", "\n", "self", ".", "regression_targets", "=", "[", "0.", ",", "0.", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNInstance.compute_regression_targets": [[50, 79], ["numpy.log", "localization.temporal_iou", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou"], ["", "def", "compute_regression_targets", "(", "self", ",", "gt_list", ")", ":", "\n", "        ", "\"\"\"Compute regression targets of positive proposals.\n\n        Args:\n            gt_list (list): The list of groundtruth instances.\n        \"\"\"", "\n", "# Find the groundtruth instance with the highest IOU.", "\n", "ious", "=", "[", "\n", "temporal_iou", "(", "self", ".", "start_frame", ",", "self", ".", "end_frame", ",", "gt", ".", "start_frame", ",", "\n", "gt", ".", "end_frame", ")", "for", "gt", "in", "gt_list", "\n", "]", "\n", "best_gt", "=", "gt_list", "[", "np", ".", "argmax", "(", "ious", ")", "]", "\n", "\n", "# interval: [start_frame, end_frame)", "\n", "proposal_center", "=", "(", "self", ".", "start_frame", "+", "self", ".", "end_frame", "-", "1", ")", "/", "2", "\n", "gt_center", "=", "(", "best_gt", ".", "start_frame", "+", "best_gt", ".", "end_frame", "-", "1", ")", "/", "2", "\n", "proposal_size", "=", "self", ".", "end_frame", "-", "self", ".", "start_frame", "\n", "gt_size", "=", "best_gt", ".", "end_frame", "-", "best_gt", ".", "start_frame", "\n", "\n", "# Get regression targets:", "\n", "# (1). Localization regression target:", "\n", "#     center shift proportional to the proposal duration", "\n", "# (2). Duration/Size regression target:", "\n", "#     logarithm of the groundtruth duration over proposal duration", "\n", "\n", "self", ".", "loc_reg", "=", "(", "gt_center", "-", "proposal_center", ")", "/", "proposal_size", "\n", "self", ".", "size_reg", "=", "np", ".", "log", "(", "gt_size", "/", "proposal_size", ")", "\n", "self", ".", "regression_targets", "=", "(", "[", "self", ".", "loc_reg", ",", "self", ".", "size_reg", "]", "\n", "if", "self", ".", "loc_reg", "is", "not", "None", "else", "[", "0.", ",", "0.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.__init__": [[162, 277], ["utils.get_root_logger", "base.BaseDataset.__init__", "ssn_dataset.SSNDataset.logger.info", "ssn_dataset.SSNDataset.construct_proposal_pools", "torch.nn.modules.utils._pair", "int", "int", "ssn_dataset.SSNDataset._compute_reg_normalize_constants", "mmcv.is_tuple_of", "TypeError", "len", "ssn_dataset.SSNDataset.logger.info", "ssn_dataset.SSNDataset.logger.info", "enumerate", "len", "len", "len", "type", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.construct_proposal_pools", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._compute_reg_normalize_constants"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "train_cfg", ",", "\n", "test_cfg", ",", "\n", "data_prefix", ",", "\n", "test_mode", "=", "False", ",", "\n", "filename_tmpl", "=", "'img_{:05d}.jpg'", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "video_centric", "=", "True", ",", "\n", "reg_normalize_constants", "=", "None", ",", "\n", "body_segments", "=", "5", ",", "\n", "aug_segments", "=", "(", "2", ",", "2", ")", ",", "\n", "aug_ratio", "=", "(", "0.5", ",", "0.5", ")", ",", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "filter_gt", "=", "True", ",", "\n", "use_regression", "=", "True", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "        ", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "data_prefix", ",", "\n", "test_mode", "=", "test_mode", ",", "\n", "start_index", "=", "start_index", ",", "\n", "modality", "=", "modality", ")", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "self", ".", "assigner", "=", "train_cfg", ".", "ssn", ".", "assigner", "\n", "self", ".", "sampler", "=", "train_cfg", ".", "ssn", ".", "sampler", "\n", "self", ".", "evaluater", "=", "test_cfg", ".", "ssn", ".", "evaluater", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "filename_tmpl", "=", "filename_tmpl", "\n", "\n", "if", "filter_gt", "or", "not", "test_mode", ":", "\n", "            ", "valid_inds", "=", "[", "\n", "i", "for", "i", ",", "video_info", "in", "enumerate", "(", "self", ".", "video_infos", ")", "\n", "if", "len", "(", "video_info", "[", "'gts'", "]", ")", ">", "0", "\n", "]", "\n", "", "self", ".", "logger", ".", "info", "(", "f'{len(valid_inds)} out of {len(self.video_infos)} '", "\n", "f'videos are valid.'", ")", "\n", "self", ".", "video_infos", "=", "[", "self", ".", "video_infos", "[", "i", "]", "for", "i", "in", "valid_inds", "]", "\n", "\n", "# construct three pools:", "\n", "# 1. Positive(Foreground)", "\n", "# 2. Background", "\n", "# 3. Incomplete", "\n", "self", ".", "positive_pool", "=", "[", "]", "\n", "self", ".", "background_pool", "=", "[", "]", "\n", "self", ".", "incomplete_pool", "=", "[", "]", "\n", "self", ".", "construct_proposal_pools", "(", ")", "\n", "\n", "if", "reg_normalize_constants", "is", "None", ":", "\n", "            ", "self", ".", "reg_norm_consts", "=", "self", ".", "_compute_reg_normalize_constants", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "reg_norm_consts", "=", "reg_normalize_constants", "\n", "", "self", ".", "video_centric", "=", "video_centric", "\n", "self", ".", "body_segments", "=", "body_segments", "\n", "self", ".", "aug_segments", "=", "aug_segments", "\n", "self", ".", "aug_ratio", "=", "_pair", "(", "aug_ratio", ")", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "aug_ratio", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'aug_ratio should be int, float'", "\n", "f'or tuple of int and float, '", "\n", "f'but got {type(aug_ratio)}'", ")", "\n", "", "assert", "len", "(", "self", ".", "aug_ratio", ")", "==", "2", "\n", "\n", "total_ratio", "=", "(", "\n", "self", ".", "sampler", ".", "positive_ratio", "+", "self", ".", "sampler", ".", "background_ratio", "+", "\n", "self", ".", "sampler", ".", "incomplete_ratio", ")", "\n", "self", ".", "positive_per_video", "=", "int", "(", "\n", "self", ".", "sampler", ".", "num_per_video", "*", "\n", "(", "self", ".", "sampler", ".", "positive_ratio", "/", "total_ratio", ")", ")", "\n", "self", ".", "background_per_video", "=", "int", "(", "\n", "self", ".", "sampler", ".", "num_per_video", "*", "\n", "(", "self", ".", "sampler", ".", "background_ratio", "/", "total_ratio", ")", ")", "\n", "self", ".", "incomplete_per_video", "=", "(", "\n", "self", ".", "sampler", ".", "num_per_video", "-", "self", ".", "positive_per_video", "-", "\n", "self", ".", "background_per_video", ")", "\n", "\n", "self", ".", "test_interval", "=", "self", ".", "test_cfg", ".", "ssn", ".", "sampler", ".", "test_interval", "\n", "# number of consecutive frames", "\n", "self", ".", "clip_len", "=", "clip_len", "\n", "# number of steps (sparse sampling for efficiency of io)", "\n", "self", ".", "frame_interval", "=", "frame_interval", "\n", "\n", "# test mode or not", "\n", "self", ".", "filter_gt", "=", "filter_gt", "\n", "self", ".", "use_regression", "=", "use_regression", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "\n", "# yapf: disable", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "f\"\"\"\n            SSNDataset: proposal file {self.proposal_file} parsed.\n\n            There are {len(self.positive_pool) + len(self.background_pool) +\n                len(self.incomplete_pool)} usable proposals from {len(self.video_infos)} videos.\n            {len(self.positive_pool)} positive proposals\n            {len(self.incomplete_pool)} incomplete proposals\n            {len(self.background_pool)} background proposals\n\n            Sample config:\n            FG/BG/INCOMP: {self.positive_per_video}/{self.background_per_video}/{self.incomplete_per_video}  # noqa:E501\n            Video Centric: {self.video_centric}\n\n            Regression Normalization Constants:\n            Location: mean {self.reg_norm_consts[0][0]:.05f} std {self.reg_norm_consts[1][0]:.05f} # noqa: E501\n            Duration: mean {self.reg_norm_consts[0][1]:.05f} std {self.reg_norm_consts[1][1]:.05f} # noqa: E501\n            \"\"\"", ")", "\n", "# yapf: enable", "\n", "", "else", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\n", "f'SSNDataset: proposal file {self.proposal_file} parsed.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.load_annotations": [[278, 329], ["localization.load_localize_proposal_file", "ssn_dataset.SSNDataset.ann_file.replace", "int", "video_infos.append", "os.exists", "Exception", "os.join", "dict", "ssn_dataset.SSNInstance", "gts.append", "ssn_dataset.SSNInstance", "proposals.append", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.load_localize_proposal_file", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "[", "]", "\n", "if", "'normalized_'", "in", "self", ".", "ann_file", ":", "\n", "            ", "self", ".", "proposal_file", "=", "self", ".", "ann_file", ".", "replace", "(", "'normalized_'", ",", "''", ")", "\n", "if", "not", "osp", ".", "exists", "(", "self", ".", "proposal_file", ")", ":", "\n", "                ", "raise", "Exception", "(", "f'Please refer to `$MMACTION2/tools/data` to'", "\n", "f'denormalize {self.ann_file}.'", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "proposal_file", "=", "self", ".", "ann_file", "\n", "", "proposal_infos", "=", "load_localize_proposal_file", "(", "self", ".", "proposal_file", ")", "\n", "# proposal_info:[video_id, num_frames, gt_list, proposal_list]", "\n", "# gt_list member: [label, start_frame, end_frame]", "\n", "# proposal_list member: [label, best_iou, overlap_self,", "\n", "#                        start_frame, end_frame]", "\n", "for", "proposal_info", "in", "proposal_infos", ":", "\n", "            ", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "proposal_info", "[", "0", "]", ")", "\n", "", "num_frames", "=", "int", "(", "proposal_info", "[", "1", "]", ")", "\n", "# gts:start, end, num_frames, class_label, tIoU=1", "\n", "gts", "=", "[", "]", "\n", "for", "x", "in", "proposal_info", "[", "2", "]", ":", "\n", "                ", "if", "int", "(", "x", "[", "2", "]", ")", ">", "int", "(", "x", "[", "1", "]", ")", "and", "int", "(", "x", "[", "1", "]", ")", "<", "num_frames", ":", "\n", "                    ", "ssn_instance", "=", "SSNInstance", "(", "\n", "int", "(", "x", "[", "1", "]", ")", ",", "\n", "int", "(", "x", "[", "2", "]", ")", ",", "\n", "num_frames", ",", "\n", "label", "=", "int", "(", "x", "[", "0", "]", ")", ",", "\n", "best_iou", "=", "1.0", ")", "\n", "gts", ".", "append", "(", "ssn_instance", ")", "\n", "# proposals:start, end, num_frames, class_label", "\n", "# tIoU=best_iou, overlap_self", "\n", "", "", "proposals", "=", "[", "]", "\n", "for", "x", "in", "proposal_info", "[", "3", "]", ":", "\n", "                ", "if", "int", "(", "x", "[", "4", "]", ")", ">", "int", "(", "x", "[", "3", "]", ")", "and", "int", "(", "x", "[", "3", "]", ")", "<", "num_frames", ":", "\n", "                    ", "ssn_instance", "=", "SSNInstance", "(", "\n", "int", "(", "x", "[", "3", "]", ")", ",", "\n", "int", "(", "x", "[", "4", "]", ")", ",", "\n", "num_frames", ",", "\n", "label", "=", "int", "(", "x", "[", "0", "]", ")", ",", "\n", "best_iou", "=", "float", "(", "x", "[", "1", "]", ")", ",", "\n", "overlap_self", "=", "float", "(", "x", "[", "2", "]", ")", ")", "\n", "proposals", ".", "append", "(", "ssn_instance", ")", "\n", "", "", "video_infos", ".", "append", "(", "\n", "dict", "(", "\n", "frame_dir", "=", "frame_dir", ",", "\n", "video_id", "=", "proposal_info", "[", "0", "]", ",", "\n", "total_frames", "=", "num_frames", ",", "\n", "gts", "=", "gts", ",", "\n", "proposals", "=", "proposals", ")", ")", "\n", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.results_to_detections": [[330, 393], ["range", "dict", "len", "numpy.zeros.reshape", "range", "len", "numpy.squeeze", "numpy.zeros", "range", "core.softmax", "numpy.exp", "numpy.concatenate", "core.softmax", "numpy.exp", "numpy.argsort", "len", "combined_scores.ravel", "numpy.array", "numpy.vstack"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["", "def", "results_to_detections", "(", "self", ",", "results", ",", "top_k", "=", "2000", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Convert prediction results into detections.\n\n        Args:\n            results (list): Prediction results.\n            top_k (int): Number of top results. Default: 2000.\n\n        Returns:\n            list: Detection results.\n        \"\"\"", "\n", "num_classes", "=", "results", "[", "0", "]", "[", "'activity_scores'", "]", ".", "shape", "[", "1", "]", "-", "1", "\n", "detections", "=", "[", "dict", "(", ")", "for", "_", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "video_id", "=", "self", ".", "video_infos", "[", "idx", "]", "[", "'video_id'", "]", "\n", "relative_proposals", "=", "results", "[", "idx", "]", "[", "'relative_proposal_list'", "]", "\n", "if", "len", "(", "relative_proposals", "[", "0", "]", ".", "shape", ")", "==", "3", ":", "\n", "                ", "relative_proposals", "=", "np", ".", "squeeze", "(", "relative_proposals", ",", "0", ")", "\n", "\n", "", "activity_scores", "=", "results", "[", "idx", "]", "[", "'activity_scores'", "]", "\n", "completeness_scores", "=", "results", "[", "idx", "]", "[", "'completeness_scores'", "]", "\n", "regression_scores", "=", "results", "[", "idx", "]", "[", "'bbox_preds'", "]", "\n", "if", "regression_scores", "is", "None", ":", "\n", "                ", "regression_scores", "=", "np", ".", "zeros", "(", "\n", "(", "len", "(", "relative_proposals", ")", ",", "num_classes", ",", "2", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "", "regression_scores", "=", "regression_scores", ".", "reshape", "(", "(", "-", "1", ",", "num_classes", ",", "2", ")", ")", "\n", "\n", "if", "top_k", "<=", "0", ":", "\n", "                ", "combined_scores", "=", "(", "\n", "softmax", "(", "activity_scores", "[", ":", ",", "1", ":", "]", ",", "dim", "=", "1", ")", "*", "\n", "np", ".", "exp", "(", "completeness_scores", ")", ")", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "                    ", "center_scores", "=", "regression_scores", "[", ":", ",", "i", ",", "0", "]", "[", ":", ",", "None", "]", "\n", "duration_scores", "=", "regression_scores", "[", ":", ",", "i", ",", "1", "]", "[", ":", ",", "None", "]", "\n", "detections", "[", "i", "]", "[", "video_id", "]", "=", "np", ".", "concatenate", "(", "\n", "(", "relative_proposals", ",", "combined_scores", "[", ":", ",", "i", "]", "[", ":", ",", "None", "]", ",", "\n", "center_scores", ",", "duration_scores", ")", ",", "\n", "axis", "=", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "combined_scores", "=", "(", "\n", "softmax", "(", "activity_scores", "[", ":", ",", "1", ":", "]", ",", "dim", "=", "1", ")", "*", "\n", "np", ".", "exp", "(", "completeness_scores", ")", ")", "\n", "keep_idx", "=", "np", ".", "argsort", "(", "combined_scores", ".", "ravel", "(", ")", ")", "[", "-", "top_k", ":", "]", "\n", "for", "k", "in", "keep_idx", ":", "\n", "                    ", "class_idx", "=", "k", "%", "num_classes", "\n", "proposal_idx", "=", "k", "//", "num_classes", "\n", "new_item", "=", "[", "\n", "relative_proposals", "[", "proposal_idx", ",", "0", "]", ",", "\n", "relative_proposals", "[", "proposal_idx", ",", "\n", "1", "]", ",", "combined_scores", "[", "proposal_idx", ",", "\n", "class_idx", "]", ",", "\n", "regression_scores", "[", "proposal_idx", ",", "class_idx", ",", "\n", "0", "]", ",", "regression_scores", "[", "proposal_idx", ",", "\n", "class_idx", ",", "1", "]", "\n", "]", "\n", "if", "video_id", "not", "in", "detections", "[", "class_idx", "]", ":", "\n", "                        ", "detections", "[", "class_idx", "]", "[", "video_id", "]", "=", "np", ".", "array", "(", "[", "new_item", "]", ")", "\n", "", "else", ":", "\n", "                        ", "detections", "[", "class_idx", "]", "[", "video_id", "]", "=", "np", ".", "vstack", "(", "\n", "[", "detections", "[", "class_idx", "]", "[", "video_id", "]", ",", "new_item", "]", ")", "\n", "\n", "", "", "", "", "return", "detections", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.evaluate": [[394, 489], ["dict", "copy.deepcopy", "ssn_dataset.SSNDataset.results_to_detections", "ssn_dataset.SSNDataset.logger.info", "enumerate", "ssn_dataset.SSNDataset.logger.info", "ssn_dataset.SSNDataset.get_all_gts", "enumerate", "enumerate", "collections.OrderedDict", "warnings.warn", "dict", "isinstance", "TypeError", "len", "len", "isinstance", "ssn_dataset.SSNDataset.logger.info", "enumerate", "ssn_dataset.SSNDataset.logger.info", "detections[].items", "dict", "len", "len", "KeyError", "localization.temporal_nms", "dict", "detection_list.extend", "copy.deepcopy.setdefault().setdefault", "localization.perform_regression", "detections[].items", "numpy.arange", "localization.eval_ap", "localization.eval_ap.mean", "ssn_dataset.SSNDataset.logger.info", "zip", "type", "detections[].items", "copy.deepcopy.setdefault", "dets.tolist"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.results_to_detections", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_all_gts", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.temporal_nms", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.perform_regression", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.eval_ap"], ["", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'mAP'", ",", "\n", "metric_options", "=", "dict", "(", "mAP", "=", "dict", "(", "eval_dataset", "=", "'thumos14'", ")", ")", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        ", "\"\"\"Evaluation in SSN proposal dataset.\n\n        Args:\n            results (list[dict]): Output results.\n            metrics (str | sequence[str]): Metrics to be performed.\n                Defaults: 'mAP'.\n            metric_options (dict): Dict for metric options. Options are\n                ``eval_dataset`` for ``mAP``.\n                Default: ``dict(mAP=dict(eval_dataset='thumos14'))``.\n            logger (logging.Logger | None): Logger for recording.\n                Default: None.\n            deprecated_kwargs (dict): Used for containing deprecated arguments.\n                See 'https://github.com/open-mmlab/mmaction2/pull/286'.\n\n        Returns:\n            dict: Evaluation results for evaluation metrics.\n        \"\"\"", "\n", "# Protect ``metric_options`` since it uses mutable value as default", "\n", "metric_options", "=", "copy", ".", "deepcopy", "(", "metric_options", ")", "\n", "\n", "if", "deprecated_kwargs", "!=", "{", "}", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'Option arguments for metrics has been changed to '", "\n", "\"`metric_options`, See 'https://github.com/open-mmlab/mmaction2/pull/286' \"", "# noqa: E501", "\n", "'for more details'", ")", "\n", "metric_options", "[", "'mAP'", "]", "=", "dict", "(", "metric_options", "[", "'mAP'", "]", ",", "\n", "**", "deprecated_kwargs", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'results must be a list, but got {type(results)}'", ")", "\n", "", "assert", "len", "(", "results", ")", "==", "len", "(", "self", ")", ",", "(", "\n", "f'The length of results is not equal to the dataset len: '", "\n", "f'{len(results)} != {len(self)}'", ")", "\n", "\n", "metrics", "=", "metrics", "if", "isinstance", "(", "metrics", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "metrics", "]", "\n", "allowed_metrics", "=", "[", "'mAP'", "]", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported'", ")", "\n", "\n", "", "", "detections", "=", "self", ".", "results_to_detections", "(", "results", ",", "**", "self", ".", "evaluater", ")", "\n", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Performing location regression'", ")", "\n", "for", "class_idx", ",", "_", "in", "enumerate", "(", "detections", ")", ":", "\n", "                ", "detections", "[", "class_idx", "]", "=", "{", "\n", "k", ":", "perform_regression", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "detections", "[", "class_idx", "]", ".", "items", "(", ")", "\n", "}", "\n", "", "self", ".", "logger", ".", "info", "(", "'Regression finished'", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "'Performing NMS'", ")", "\n", "for", "class_idx", ",", "_", "in", "enumerate", "(", "detections", ")", ":", "\n", "            ", "detections", "[", "class_idx", "]", "=", "{", "\n", "k", ":", "temporal_nms", "(", "v", ",", "self", ".", "evaluater", ".", "nms", ")", "\n", "for", "k", ",", "v", "in", "detections", "[", "class_idx", "]", ".", "items", "(", ")", "\n", "}", "\n", "", "self", ".", "logger", ".", "info", "(", "'NMS finished'", ")", "\n", "\n", "# get gts", "\n", "all_gts", "=", "self", ".", "get_all_gts", "(", ")", "\n", "for", "class_idx", ",", "_", "in", "enumerate", "(", "detections", ")", ":", "\n", "            ", "if", "class_idx", "not", "in", "all_gts", ":", "\n", "                ", "all_gts", "[", "class_idx", "]", "=", "dict", "(", ")", "\n", "\n", "# get predictions", "\n", "", "", "plain_detections", "=", "{", "}", "\n", "for", "class_idx", ",", "_", "in", "enumerate", "(", "detections", ")", ":", "\n", "            ", "detection_list", "=", "[", "]", "\n", "for", "video", ",", "dets", "in", "detections", "[", "class_idx", "]", ".", "items", "(", ")", ":", "\n", "                ", "detection_list", ".", "extend", "(", "[", "[", "video", ",", "class_idx", "]", "+", "x", "[", ":", "3", "]", "\n", "for", "x", "in", "dets", ".", "tolist", "(", ")", "]", ")", "\n", "", "plain_detections", "[", "class_idx", "]", "=", "detection_list", "\n", "\n", "", "eval_results", "=", "OrderedDict", "(", ")", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "==", "'mAP'", ":", "\n", "                ", "eval_dataset", "=", "metric_options", ".", "setdefault", "(", "'mAP'", ",", "{", "}", ")", ".", "setdefault", "(", "\n", "'eval_dataset'", ",", "'thumos14'", ")", "\n", "if", "eval_dataset", "==", "'thumos14'", ":", "\n", "                    ", "iou_range", "=", "np", ".", "arange", "(", "0.1", ",", "1.0", ",", ".1", ")", "\n", "ap_values", "=", "eval_ap", "(", "plain_detections", ",", "all_gts", ",", "iou_range", ")", "\n", "map_ious", "=", "ap_values", ".", "mean", "(", "axis", "=", "0", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Evaluation finished'", ")", "\n", "\n", "for", "iou", ",", "map_iou", "in", "zip", "(", "iou_range", ",", "map_ious", ")", ":", "\n", "                        ", "eval_results", "[", "f'mAP@{iou:.02f}'", "]", "=", "map_iou", "\n", "\n", "", "", "", "", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.construct_proposal_pools": [[490, 511], ["ssn_dataset.SSNDataset.get_positives", "ssn_dataset.SSNDataset.positive_pool.extend", "ssn_dataset.SSNDataset.get_negatives", "ssn_dataset.SSNDataset.incomplete_pool.extend", "ssn_dataset.SSNDataset.background_pool.extend"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_positives", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_negatives"], ["", "def", "construct_proposal_pools", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct positve proposal pool, incomplete proposal pool and\n        background proposal pool of the entire dataset.\"\"\"", "\n", "for", "video_info", "in", "self", ".", "video_infos", ":", "\n", "            ", "positives", "=", "self", ".", "get_positives", "(", "\n", "video_info", "[", "'gts'", "]", ",", "video_info", "[", "'proposals'", "]", ",", "\n", "self", ".", "assigner", ".", "positive_iou_threshold", ",", "\n", "self", ".", "sampler", ".", "add_gt_as_proposals", ")", "\n", "self", ".", "positive_pool", ".", "extend", "(", "[", "(", "video_info", "[", "'video_id'", "]", ",", "proposal", ")", "\n", "for", "proposal", "in", "positives", "]", ")", "\n", "\n", "incompletes", ",", "backgrounds", "=", "self", ".", "get_negatives", "(", "\n", "video_info", "[", "'proposals'", "]", ",", "\n", "self", ".", "assigner", ".", "incomplete_iou_threshold", ",", "\n", "self", ".", "assigner", ".", "background_iou_threshold", ",", "\n", "self", ".", "assigner", ".", "background_coverage_threshold", ",", "\n", "self", ".", "assigner", ".", "incomplete_overlap_threshold", ")", "\n", "self", ".", "incomplete_pool", ".", "extend", "(", "[", "(", "video_info", "[", "'video_id'", "]", ",", "proposal", ")", "\n", "for", "proposal", "in", "incompletes", "]", ")", "\n", "self", ".", "background_pool", ".", "extend", "(", "[", "video_info", "[", "'video_id'", "]", ",", "proposal", "]", "\n", "for", "proposal", "in", "backgrounds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_all_gts": [[512, 528], ["gts.setdefault().setdefault().append", "gts.setdefault().setdefault", "gts.setdefault"], "methods", ["None"], ["", "", "def", "get_all_gts", "(", "self", ")", ":", "\n", "        ", "\"\"\"Fetch groundtruth instances of the entire dataset.\"\"\"", "\n", "gts", "=", "{", "}", "\n", "for", "video_info", "in", "self", ".", "video_infos", ":", "\n", "            ", "video", "=", "video_info", "[", "'video_id'", "]", "\n", "for", "gt", "in", "video_info", "[", "'gts'", "]", ":", "\n", "                ", "class_idx", "=", "gt", ".", "label", "-", "1", "\n", "# gt_info: [relative_start, relative_end]", "\n", "gt_info", "=", "[", "\n", "gt", ".", "start_frame", "/", "video_info", "[", "'total_frames'", "]", ",", "\n", "gt", ".", "end_frame", "/", "video_info", "[", "'total_frames'", "]", "\n", "]", "\n", "gts", ".", "setdefault", "(", "class_idx", ",", "{", "}", ")", ".", "setdefault", "(", "video", ",", "\n", "[", "]", ")", ".", "append", "(", "gt_info", ")", "\n", "\n", "", "", "return", "gts", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_positives": [[529, 557], ["positives.extend", "proposal.compute_regression_targets"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNInstance.compute_regression_targets"], ["", "@", "staticmethod", "\n", "def", "get_positives", "(", "gts", ",", "proposals", ",", "positive_threshold", ",", "with_gt", "=", "True", ")", ":", "\n", "        ", "\"\"\"Get positive/foreground proposals.\n\n        Args:\n            gts (list): List of groundtruth instances(:obj:`SSNInstance`).\n            proposals (list): List of proposal instances(:obj:`SSNInstance`).\n            positive_threshold (float): Minimum threshold of overlap of\n                positive/foreground proposals and groundtruths.\n            with_gt (bool): Whether to include groundtruth instances in\n                positive proposals. Default: True.\n\n        Returns:\n            list[:obj:`SSNInstance`]: (positives), positives is a list\n                comprised of positive proposal instances.\n        \"\"\"", "\n", "positives", "=", "[", "\n", "proposal", "for", "proposal", "in", "proposals", "\n", "if", "proposal", ".", "best_iou", ">", "positive_threshold", "\n", "]", "\n", "\n", "if", "with_gt", ":", "\n", "            ", "positives", ".", "extend", "(", "gts", ")", "\n", "\n", "", "for", "proposal", "in", "positives", ":", "\n", "            ", "proposal", ".", "compute_regression_targets", "(", "gts", ")", "\n", "\n", "", "return", "positives", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_negatives": [[558, 596], ["incompletes.append", "backgrounds.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_negatives", "(", "proposals", ",", "\n", "incomplete_iou_threshold", ",", "\n", "background_iou_threshold", ",", "\n", "background_coverage_threshold", "=", "0.01", ",", "\n", "incomplete_overlap_threshold", "=", "0.7", ")", ":", "\n", "        ", "\"\"\"Get negative proposals, including incomplete proposals and\n        background proposals.\n\n        Args:\n            proposals (list): List of proposal instances(:obj:`SSNInstance`).\n            incomplete_iou_threshold (float): Maximum threshold of overlap\n                of incomplete proposals and groundtruths.\n            background_iou_threshold (float): Maximum threshold of overlap\n                of background proposals and groundtruths.\n            background_coverage_threshold (float): Minimum coverage\n                of background proposals in video duration. Default: 0.01.\n            incomplete_overlap_threshold (float): Minimum percent of incomplete\n                proposals' own span contained in a groundtruth instance.\n                Default: 0.7.\n\n        Returns:\n            list[:obj:`SSNInstance`]: (incompletes, backgrounds), incompletes\n                and backgrounds are lists comprised of incomplete\n                proposal instances and background proposal instances.\n        \"\"\"", "\n", "incompletes", "=", "[", "]", "\n", "backgrounds", "=", "[", "]", "\n", "\n", "for", "proposal", "in", "proposals", ":", "\n", "            ", "if", "(", "proposal", ".", "best_iou", "<", "incomplete_iou_threshold", "\n", "and", "proposal", ".", "overlap_self", ">", "incomplete_overlap_threshold", ")", ":", "\n", "                ", "incompletes", ".", "append", "(", "proposal", ")", "\n", "", "elif", "(", "proposal", ".", "best_iou", "<", "background_iou_threshold", "\n", "and", "proposal", ".", "coverage", ">", "background_coverage_threshold", ")", ":", "\n", "                ", "backgrounds", ".", "append", "(", "proposal", ")", "\n", "\n", "", "", "return", "incompletes", ",", "backgrounds", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._video_centric_sampling": [[597, 665], ["ssn_dataset.SSNDataset.get_positives", "ssn_dataset.SSNDataset.get_negatives", "out_proposals.extend", "out_proposals.extend", "out_proposals.extend", "numpy.random.choice", "ssn_dataset.SSNDataset._video_centric_sampling.sample_video_proposals"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_positives", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_negatives"], ["", "def", "_video_centric_sampling", "(", "self", ",", "record", ")", ":", "\n", "        ", "\"\"\"Sample proposals from the this video instance.\n\n        Args:\n            record (dict): Information of the video instance(video_info[idx]).\n                key: frame_dir, video_id, total_frames,\n                gts: List of groundtruth instances(:obj:`SSNInstance`).\n                proposals: List of proposal instances(:obj:`SSNInstance`).\n        \"\"\"", "\n", "positives", "=", "self", ".", "get_positives", "(", "record", "[", "'gts'", "]", ",", "record", "[", "'proposals'", "]", ",", "\n", "self", ".", "assigner", ".", "positive_iou_threshold", ",", "\n", "self", ".", "sampler", ".", "add_gt_as_proposals", ")", "\n", "incompletes", ",", "backgrounds", "=", "self", ".", "get_negatives", "(", "\n", "record", "[", "'proposals'", "]", ",", "self", ".", "assigner", ".", "incomplete_iou_threshold", ",", "\n", "self", ".", "assigner", ".", "background_iou_threshold", ",", "\n", "self", ".", "assigner", ".", "background_coverage_threshold", ",", "\n", "self", ".", "assigner", ".", "incomplete_overlap_threshold", ")", "\n", "\n", "def", "sample_video_proposals", "(", "proposal_type", ",", "video_id", ",", "video_pool", ",", "\n", "num_requested_proposals", ",", "dataset_pool", ")", ":", "\n", "            ", "\"\"\"This method will sample proposals from the this video pool. If\n            the video pool is empty, it will fetch from the dataset pool\n            (collect proposal of the entire dataset).\n\n            Args:\n                proposal_type (int): Type id of proposal.\n                    Positive/Foreground: 0\n                    Negative:\n                        Incomplete: 1\n                        Background: 2\n                video_id (str): Name of the video.\n                video_pool (list): Pool comprised of proposals in this video.\n                num_requested_proposals (int): Number of proposals\n                    to be sampled.\n                dataset_pool (list): Proposals of the entire dataset.\n\n            Returns:\n                list[(str, :obj:`SSNInstance`), int]:\n                    video_id (str): Name of the video.\n                    :obj:`SSNInstance`: Instance of class SSNInstance.\n                    proposal_type (int): Type of proposal.\n            \"\"\"", "\n", "\n", "if", "len", "(", "video_pool", ")", "==", "0", ":", "\n", "                ", "idx", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "dataset_pool", ")", ",", "num_requested_proposals", ",", "replace", "=", "False", ")", "\n", "return", "[", "(", "dataset_pool", "[", "x", "]", ",", "proposal_type", ")", "for", "x", "in", "idx", "]", "\n", "\n", "", "replicate", "=", "len", "(", "video_pool", ")", "<", "num_requested_proposals", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "video_pool", ")", ",", "num_requested_proposals", ",", "replace", "=", "replicate", ")", "\n", "return", "[", "(", "(", "video_id", ",", "video_pool", "[", "x", "]", ")", ",", "proposal_type", ")", "for", "x", "in", "idx", "]", "\n", "\n", "", "out_proposals", "=", "[", "]", "\n", "out_proposals", ".", "extend", "(", "\n", "sample_video_proposals", "(", "0", ",", "record", "[", "'video_id'", "]", ",", "positives", ",", "\n", "self", ".", "positive_per_video", ",", "\n", "self", ".", "positive_pool", ")", ")", "\n", "out_proposals", ".", "extend", "(", "\n", "sample_video_proposals", "(", "1", ",", "record", "[", "'video_id'", "]", ",", "incompletes", ",", "\n", "self", ".", "incomplete_per_video", ",", "\n", "self", ".", "incomplete_pool", ")", ")", "\n", "out_proposals", ".", "extend", "(", "\n", "sample_video_proposals", "(", "2", ",", "record", "[", "'video_id'", "]", ",", "backgrounds", ",", "\n", "self", ".", "background_per_video", ",", "\n", "self", ".", "background_pool", ")", ")", "\n", "\n", "return", "out_proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._random_sampling": [[666, 690], ["numpy.random.choice", "out_proposals.extend", "numpy.random.choice", "out_proposals.extend", "numpy.random.choice", "out_proposals.extend", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_random_sampling", "(", "self", ")", ":", "\n", "        ", "\"\"\"Randomly sample proposals from the entire dataset.\"\"\"", "\n", "out_proposals", "=", "[", "]", "\n", "\n", "positive_idx", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "positive_pool", ")", ",", "\n", "self", ".", "positive_per_video", ",", "\n", "replace", "=", "len", "(", "self", ".", "positive_pool", ")", "<", "self", ".", "positive_per_video", ")", "\n", "out_proposals", ".", "extend", "(", "[", "(", "self", ".", "positive_pool", "[", "x", "]", ",", "0", ")", "\n", "for", "x", "in", "positive_idx", "]", ")", "\n", "incomplete_idx", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "incomplete_pool", ")", ",", "\n", "self", ".", "incomplete_per_video", ",", "\n", "replace", "=", "len", "(", "self", ".", "incomplete_pool", ")", "<", "self", ".", "incomplete_per_video", ")", "\n", "out_proposals", ".", "extend", "(", "[", "(", "self", ".", "incomplete_pool", "[", "x", "]", ",", "1", ")", "\n", "for", "x", "in", "incomplete_idx", "]", ")", "\n", "background_idx", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "background_pool", ")", ",", "\n", "self", ".", "background_per_video", ",", "\n", "replace", "=", "len", "(", "self", ".", "background_pool", ")", "<", "self", ".", "background_per_video", ")", "\n", "out_proposals", ".", "extend", "(", "[", "(", "self", ".", "background_pool", "[", "x", "]", ",", "2", ")", "\n", "for", "x", "in", "background_idx", "]", ")", "\n", "\n", "return", "out_proposals", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._get_stage": [[691, 736], ["max", "min", "int", "int"], "methods", ["None"], ["", "def", "_get_stage", "(", "self", ",", "proposal", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Fetch the scale factor of starting and ending stage and get the\n        stage split.\n\n        Args:\n            proposal (:obj:`SSNInstance`): Proposal instance.\n            num_frames (int): Total frames of the video.\n\n        Returns:\n            tuple[float, float, list]: (starting_scale_factor,\n                ending_scale_factor, stage_split), starting_scale_factor is\n                the ratio of the effective sampling length to augment length\n                in starting stage, ending_scale_factor is the ratio of the\n                effective sampling length to augment length in ending stage,\n                stage_split is  ending segment id of starting, course and\n                ending stage.\n        \"\"\"", "\n", "# proposal interval: [start_frame, end_frame)", "\n", "start_frame", "=", "proposal", ".", "start_frame", "\n", "end_frame", "=", "proposal", ".", "end_frame", "\n", "ori_clip_len", "=", "self", ".", "clip_len", "*", "self", ".", "frame_interval", "\n", "\n", "duration", "=", "end_frame", "-", "start_frame", "\n", "assert", "duration", "!=", "0", "\n", "\n", "valid_starting", "=", "max", "(", "0", ",", "\n", "start_frame", "-", "int", "(", "duration", "*", "self", ".", "aug_ratio", "[", "0", "]", ")", ")", "\n", "valid_ending", "=", "min", "(", "num_frames", "-", "ori_clip_len", "+", "1", ",", "\n", "end_frame", "-", "1", "+", "int", "(", "duration", "*", "self", ".", "aug_ratio", "[", "1", "]", ")", ")", "\n", "\n", "valid_starting_length", "=", "start_frame", "-", "valid_starting", "-", "ori_clip_len", "\n", "valid_ending_length", "=", "(", "valid_ending", "-", "end_frame", "+", "1", ")", "-", "ori_clip_len", "\n", "\n", "starting_scale_factor", "=", "(", "(", "valid_starting_length", "+", "ori_clip_len", "+", "1", ")", "/", "\n", "(", "duration", "*", "self", ".", "aug_ratio", "[", "0", "]", ")", ")", "\n", "ending_scale_factor", "=", "(", "valid_ending_length", "+", "ori_clip_len", "+", "1", ")", "/", "(", "\n", "duration", "*", "self", ".", "aug_ratio", "[", "1", "]", ")", "\n", "\n", "aug_start", ",", "aug_end", "=", "self", ".", "aug_segments", "\n", "stage_split", "=", "[", "\n", "aug_start", ",", "aug_start", "+", "self", ".", "body_segments", ",", "\n", "aug_start", "+", "self", ".", "body_segments", "+", "aug_end", "\n", "]", "\n", "\n", "return", "starting_scale_factor", ",", "ending_scale_factor", ",", "stage_split", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._compute_reg_normalize_constants": [[737, 750], ["numpy.array", "ssn_dataset.SSNDataset.logger.info", "ssn_dataset.SSNDataset.get_positives", "targets.append", "numpy.mean", "numpy.std", "list"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.get_positives"], ["", "def", "_compute_reg_normalize_constants", "(", "self", ")", ":", "\n", "        ", "\"\"\"Compute regression target normalized constants.\"\"\"", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "'Compute regression target normalized constants'", ")", "\n", "", "targets", "=", "[", "]", "\n", "for", "video_info", "in", "self", ".", "video_infos", ":", "\n", "            ", "positives", "=", "self", ".", "get_positives", "(", "\n", "video_info", "[", "'gts'", "]", ",", "video_info", "[", "'proposals'", "]", ",", "\n", "self", ".", "assigner", ".", "positive_iou_threshold", ",", "False", ")", "\n", "for", "positive", "in", "positives", ":", "\n", "                ", "targets", ".", "append", "(", "list", "(", "positive", ".", "regression_targets", ")", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "(", "np", ".", "mean", "(", "targets", ",", "axis", "=", "0", ")", ",", "np", ".", "std", "(", "targets", ",", "axis", "=", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.prepare_train_frames": [[751, 820], ["copy.deepcopy", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "ssn_dataset.SSNDataset.pipeline", "ssn_dataset.SSNDataset._video_centric_sampling", "ssn_dataset.SSNDataset._random_sampling", "ssn_dataset.SSNDataset._get_stage", "out_proposal_scale_factor.append", "out_proposal_labels.append", "out_proposal_type.append", "out_proposal_reg_targets.append", "isinstance", "TypeError", "ValueError", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._video_centric_sampling", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._random_sampling", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset._get_stage"], ["", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "if", "self", ".", "video_centric", ":", "\n", "# yapf: disable", "\n", "            ", "results", "[", "'out_proposals'", "]", "=", "self", ".", "_video_centric_sampling", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "# noqa: E501", "\n", "# yapf: enable", "\n", "", "else", ":", "\n", "            ", "results", "[", "'out_proposals'", "]", "=", "self", ".", "_random_sampling", "(", ")", "\n", "\n", "", "out_proposal_scale_factor", "=", "[", "]", "\n", "out_proposal_type", "=", "[", "]", "\n", "out_proposal_labels", "=", "[", "]", "\n", "out_proposal_reg_targets", "=", "[", "]", "\n", "\n", "for", "_", ",", "proposal", "in", "enumerate", "(", "results", "[", "'out_proposals'", "]", ")", ":", "\n", "# proposal: [(video_id, SSNInstance), proposal_type]", "\n", "            ", "num_frames", "=", "proposal", "[", "0", "]", "[", "1", "]", ".", "num_video_frames", "\n", "\n", "(", "starting_scale_factor", ",", "ending_scale_factor", ",", "\n", "_", ")", "=", "self", ".", "_get_stage", "(", "proposal", "[", "0", "]", "[", "1", "]", ",", "num_frames", ")", "\n", "\n", "# proposal[1]: Type id of proposal.", "\n", "# Positive/Foreground: 0", "\n", "# Negative:", "\n", "#   Incomplete: 1", "\n", "#   Background: 2", "\n", "\n", "# Positivte/Foreground proposal", "\n", "if", "proposal", "[", "1", "]", "==", "0", ":", "\n", "                ", "label", "=", "proposal", "[", "0", "]", "[", "1", "]", ".", "label", "\n", "# Incomplete proposal", "\n", "", "elif", "proposal", "[", "1", "]", "==", "1", ":", "\n", "                ", "label", "=", "proposal", "[", "0", "]", "[", "1", "]", ".", "label", "\n", "# Background proposal", "\n", "", "elif", "proposal", "[", "1", "]", "==", "2", ":", "\n", "                ", "label", "=", "0", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Proposal type should be 0, 1, or 2,'", "\n", "f'but got {proposal[1]}'", ")", "\n", "", "out_proposal_scale_factor", ".", "append", "(", "\n", "[", "starting_scale_factor", ",", "ending_scale_factor", "]", ")", "\n", "if", "not", "isinstance", "(", "label", ",", "int", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f'proposal_label must be an int,'", "\n", "f'but got {type(label)}'", ")", "\n", "", "out_proposal_labels", ".", "append", "(", "label", ")", "\n", "out_proposal_type", ".", "append", "(", "proposal", "[", "1", "]", ")", "\n", "\n", "reg_targets", "=", "proposal", "[", "0", "]", "[", "1", "]", ".", "regression_targets", "\n", "if", "proposal", "[", "1", "]", "==", "0", ":", "\n", "# Normalize regression targets of positive proposals.", "\n", "                ", "reg_targets", "=", "(", "(", "reg_targets", "[", "0", "]", "-", "self", ".", "reg_norm_consts", "[", "0", "]", "[", "0", "]", ")", "/", "\n", "self", ".", "reg_norm_consts", "[", "1", "]", "[", "0", "]", ",", "\n", "(", "reg_targets", "[", "1", "]", "-", "self", ".", "reg_norm_consts", "[", "0", "]", "[", "1", "]", ")", "/", "\n", "self", ".", "reg_norm_consts", "[", "1", "]", "[", "1", "]", ")", "\n", "", "out_proposal_reg_targets", ".", "append", "(", "reg_targets", ")", "\n", "\n", "", "results", "[", "'reg_targets'", "]", "=", "np", ".", "array", "(", "\n", "out_proposal_reg_targets", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "results", "[", "'proposal_scale_factor'", "]", "=", "np", ".", "array", "(", "\n", "out_proposal_scale_factor", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "results", "[", "'proposal_labels'", "]", "=", "np", ".", "array", "(", "out_proposal_labels", ")", "\n", "results", "[", "'proposal_type'", "]", "=", "np", ".", "array", "(", "out_proposal_type", ")", "\n", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ssn_dataset.SSNDataset.prepare_test_frames": [[821, 882], ["copy.deepcopy", "len", "numpy.array", "numpy.array", "numpy.array", "ssn_dataset.SSNDataset.pipeline", "numpy.arange", "len", "proposals.append", "max", "min", "relative_proposal_list.append", "proposal_tick_list.append", "scale_factor_list.append", "ssn_dataset.SSNInstance", "numpy.array"], "methods", ["None"], ["", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "proposals", "=", "results", "[", "'proposals'", "]", "\n", "num_frames", "=", "results", "[", "'total_frames'", "]", "\n", "ori_clip_len", "=", "self", ".", "clip_len", "*", "self", ".", "frame_interval", "\n", "frame_ticks", "=", "np", ".", "arange", "(", "\n", "0", ",", "num_frames", "-", "ori_clip_len", ",", "self", ".", "test_interval", ",", "dtype", "=", "int", ")", "+", "1", "\n", "\n", "num_sampled_frames", "=", "len", "(", "frame_ticks", ")", "\n", "\n", "if", "len", "(", "proposals", ")", "==", "0", ":", "\n", "            ", "proposals", ".", "append", "(", "SSNInstance", "(", "0", ",", "num_frames", "-", "1", ",", "num_frames", ")", ")", "\n", "\n", "", "relative_proposal_list", "=", "[", "]", "\n", "proposal_tick_list", "=", "[", "]", "\n", "scale_factor_list", "=", "[", "]", "\n", "\n", "for", "proposal", "in", "proposals", ":", "\n", "            ", "relative_proposal", "=", "(", "proposal", ".", "start_frame", "/", "num_frames", ",", "\n", "proposal", ".", "end_frame", "/", "num_frames", ")", "\n", "relative_duration", "=", "relative_proposal", "[", "1", "]", "-", "relative_proposal", "[", "0", "]", "\n", "relative_starting_duration", "=", "relative_duration", "*", "self", ".", "aug_ratio", "[", "0", "]", "\n", "relative_ending_duration", "=", "relative_duration", "*", "self", ".", "aug_ratio", "[", "1", "]", "\n", "relative_starting", "=", "(", "\n", "relative_proposal", "[", "0", "]", "-", "relative_starting_duration", ")", "\n", "relative_ending", "=", "relative_proposal", "[", "1", "]", "+", "relative_ending_duration", "\n", "\n", "real_relative_starting", "=", "max", "(", "0.0", ",", "relative_starting", ")", "\n", "real_relative_ending", "=", "min", "(", "1.0", ",", "relative_ending", ")", "\n", "\n", "starting_scale_factor", "=", "(", "\n", "(", "relative_proposal", "[", "0", "]", "-", "real_relative_starting", ")", "/", "\n", "relative_starting_duration", ")", "\n", "ending_scale_factor", "=", "(", "\n", "(", "real_relative_ending", "-", "relative_proposal", "[", "1", "]", ")", "/", "\n", "relative_ending_duration", ")", "\n", "\n", "proposal_ranges", "=", "(", "real_relative_starting", ",", "*", "relative_proposal", ",", "\n", "real_relative_ending", ")", "\n", "proposal_ticks", "=", "(", "np", ".", "array", "(", "proposal_ranges", ")", "*", "\n", "num_sampled_frames", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "relative_proposal_list", ".", "append", "(", "relative_proposal", ")", "\n", "proposal_tick_list", ".", "append", "(", "proposal_ticks", ")", "\n", "scale_factor_list", ".", "append", "(", "\n", "(", "starting_scale_factor", ",", "ending_scale_factor", ")", ")", "\n", "\n", "", "results", "[", "'relative_proposal_list'", "]", "=", "np", ".", "array", "(", "\n", "relative_proposal_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "results", "[", "'scale_factor_list'", "]", "=", "np", ".", "array", "(", "\n", "scale_factor_list", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "results", "[", "'proposal_tick_list'", "]", "=", "np", ".", "array", "(", "\n", "proposal_tick_list", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "results", "[", "'reg_norm_consts'", "]", "=", "self", ".", "reg_norm_consts", "\n", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.__init__": [[58, 73], ["base.BaseDataset.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "clipname_tmpl", "=", "'part_{}.mp4'", ",", "\n", "sampling_strategy", "=", "'positive'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "start_index", "=", "0", ",", "**", "kwargs", ")", "\n", "assert", "self", ".", "multi_class", "is", "False", "\n", "self", ".", "sampling_strategy", "=", "sampling_strategy", "\n", "self", ".", "clipname_tmpl", "=", "clipname_tmpl", "\n", "# If positive, we should only keep those raw videos with positive", "\n", "# clips", "\n", "if", "self", ".", "sampling_strategy", "==", "'positive'", ":", "\n", "            ", "self", ".", "video_infos", "=", "[", "\n", "x", "for", "x", "in", "self", ".", "video_infos", "if", "len", "(", "x", "[", "'positive_clip_inds'", "]", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_annotations": [[76, 99], ["rawvideo_dataset.RawVideoDataset.ann_file.endswith", "rawvideo_dataset.RawVideoDataset.load_json_annotations", "open", "line.strip().split", "int", "int", "video_infos.append", "int", "os.join", "dict", "line.strip"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "if", "self", ".", "ann_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "            ", "return", "self", ".", "load_json_annotations", "(", ")", "\n", "\n", "", "video_infos", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video_dir", "=", "line_split", "[", "0", "]", "\n", "label", "=", "int", "(", "line_split", "[", "1", "]", ")", "\n", "num_clips", "=", "int", "(", "line_split", "[", "2", "]", ")", "\n", "positive_clip_inds", "=", "[", "int", "(", "ind", ")", "for", "ind", "in", "line_split", "[", "3", ":", "]", "]", "\n", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                    ", "video_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "video_dir", ")", "\n", "", "video_infos", ".", "append", "(", "\n", "dict", "(", "\n", "video_dir", "=", "video_dir", ",", "\n", "label", "=", "label", ",", "\n", "num_clips", "=", "num_clips", ",", "\n", "positive_clip_inds", "=", "positive_clip_inds", ")", ")", "\n", "", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations": [[101, 112], ["mmcv.load", "len", "range", "os.join"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "path_key", "=", "'video_dir'", "\n", "for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n", "", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.sample_clip": [[113, 131], ["rawvideo_dataset.RawVideoDataset.clipname_tmpl.format", "rawvideo_dataset.RawVideoDataset.clipname_tmpl[].isalpha", "random.choice", "random.randint", "os.join"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "sample_clip", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Sample a clip from the raw video given the sampling strategy.\"\"\"", "\n", "assert", "self", ".", "sampling_strategy", "in", "[", "'positive'", ",", "'random'", "]", "\n", "if", "self", ".", "sampling_strategy", "==", "'positive'", ":", "\n", "            ", "assert", "results", "[", "'positive_clip_inds'", "]", "\n", "ind", "=", "random", ".", "choice", "(", "results", "[", "'positive_clip_inds'", "]", ")", "\n", "", "else", ":", "\n", "            ", "ind", "=", "random", ".", "randint", "(", "0", ",", "results", "[", "'num_clips'", "]", "-", "1", ")", "\n", "", "clipname", "=", "self", ".", "clipname_tmpl", ".", "format", "(", "ind", ")", "\n", "\n", "# if the first char of self.clipname_tmpl is a letter, use osp.join;", "\n", "# otherwise, directly concat them", "\n", "if", "self", ".", "clipname_tmpl", "[", "0", "]", ".", "isalpha", "(", ")", ":", "\n", "            ", "filename", "=", "osp", ".", "join", "(", "results", "[", "'video_dir'", "]", ",", "clipname", ")", "\n", "", "else", ":", "\n", "            ", "filename", "=", "results", "[", "'video_dir'", "]", "+", "clipname", "\n", "", "results", "[", "'filename'", "]", "=", "filename", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.prepare_train_frames": [[132, 139], ["copy.deepcopy", "rawvideo_dataset.RawVideoDataset.sample_clip", "rawvideo_dataset.RawVideoDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.sample_clip"], ["", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "=", "self", ".", "sample_clip", "(", "results", ")", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.prepare_test_frames": [[140, 147], ["copy.deepcopy", "rawvideo_dataset.RawVideoDataset.sample_clip", "rawvideo_dataset.RawVideoDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.sample_clip"], ["", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "=", "self", ".", "sample_clip", "(", "results", ")", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawframe_dataset.RawframeDataset.__init__": [[88, 116], ["base.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "filename_tmpl", "=", "'img_{:05}.jpg'", ",", "\n", "with_offset", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0.", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "self", ".", "filename_tmpl", "=", "filename_tmpl", "\n", "self", ".", "with_offset", "=", "with_offset", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", ",", "\n", "test_mode", ",", "\n", "multi_class", ",", "\n", "num_classes", ",", "\n", "start_index", ",", "\n", "modality", ",", "\n", "sample_by_class", "=", "sample_by_class", ",", "\n", "power", "=", "power", ",", "\n", "dynamic_length", "=", "dynamic_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawframe_dataset.RawframeDataset.load_annotations": [[117, 154], ["rawframe_dataset.RawframeDataset.ann_file.endswith", "rawframe_dataset.RawframeDataset.load_json_annotations", "open", "line.strip().split", "video_infos.append", "os.join", "int", "int", "int", "int", "line.strip", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "if", "self", ".", "ann_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "            ", "return", "self", ".", "load_json_annotations", "(", ")", "\n", "", "video_infos", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video_info", "=", "{", "}", "\n", "idx", "=", "0", "\n", "# idx for frame_dir", "\n", "frame_dir", "=", "line_split", "[", "idx", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                    ", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "frame_dir", ")", "\n", "", "video_info", "[", "'frame_dir'", "]", "=", "frame_dir", "\n", "idx", "+=", "1", "\n", "if", "self", ".", "with_offset", ":", "\n", "# idx for offset and total_frames", "\n", "                    ", "video_info", "[", "'offset'", "]", "=", "int", "(", "line_split", "[", "idx", "]", ")", "\n", "video_info", "[", "'total_frames'", "]", "=", "int", "(", "line_split", "[", "idx", "+", "1", "]", ")", "\n", "idx", "+=", "2", "\n", "", "else", ":", "\n", "# idx for total_frames", "\n", "                    ", "video_info", "[", "'total_frames'", "]", "=", "int", "(", "line_split", "[", "idx", "]", ")", "\n", "idx", "+=", "1", "\n", "# idx for label[s]", "\n", "", "label", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line_split", "[", "idx", ":", "]", "]", "\n", "assert", "label", ",", "f'missing label in line: {line}'", "\n", "if", "self", ".", "multi_class", ":", "\n", "                    ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "video_info", "[", "'label'", "]", "=", "label", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "label", ")", "==", "1", "\n", "video_info", "[", "'label'", "]", "=", "label", "[", "0", "]", "\n", "", "video_infos", ".", "append", "(", "video_info", ")", "\n", "\n", "", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawframe_dataset.RawframeDataset.prepare_train_frames": [[155, 169], ["copy.deepcopy", "rawframe_dataset.RawframeDataset.pipeline", "torch.zeros"], "methods", ["None"], ["", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "# prepare tensor in getitem", "\n", "if", "self", ".", "multi_class", ":", "\n", "            ", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "results", "[", "'label'", "]", "]", "=", "1.", "\n", "results", "[", "'label'", "]", "=", "onehot", "\n", "\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawframe_dataset.RawframeDataset.prepare_test_frames": [[170, 184], ["copy.deepcopy", "rawframe_dataset.RawframeDataset.pipeline", "torch.zeros"], "methods", ["None"], ["", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "# prepare tensor in getitem", "\n", "if", "self", ".", "multi_class", ":", "\n", "            ", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "results", "[", "'label'", "]", "]", "=", "1.", "\n", "results", "[", "'label'", "]", "=", "onehot", "\n", "\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.audio_dataset.AudioDataset.__init__": [[30, 33], ["base.BaseDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "ann_file", ",", "pipeline", ",", "suffix", "=", "'.wav'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "suffix", "=", "suffix", "\n", "super", "(", ")", ".", "__init__", "(", "ann_file", ",", "pipeline", ",", "modality", "=", "'Audio'", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.audio_dataset.AudioDataset.load_annotations": [[34, 70], ["audio_dataset.AudioDataset.ann_file.endswith", "audio_dataset.AudioDataset.load_json_annotations", "open", "line.strip().split", "int", "video_infos.append", "int", "torch.zeros", "line.strip", "os.join.endswith", "os.join", "os.join", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.rawvideo_dataset.RawVideoDataset.load_json_annotations", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load annotation file to get video information.\"\"\"", "\n", "if", "self", ".", "ann_file", ".", "endswith", "(", "'.json'", ")", ":", "\n", "            ", "return", "self", ".", "load_json_annotations", "(", ")", "\n", "", "video_infos", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "video_info", "=", "{", "}", "\n", "idx", "=", "0", "\n", "filename", "=", "line_split", "[", "idx", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                    ", "if", "not", "filename", ".", "endswith", "(", "self", ".", "suffix", ")", ":", "\n", "                        ", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "\n", "filename", "+", "self", ".", "suffix", ")", "\n", "", "else", ":", "\n", "                        ", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "filename", ")", "\n", "", "", "video_info", "[", "'audio_path'", "]", "=", "filename", "\n", "idx", "+=", "1", "\n", "# idx for total_frames", "\n", "video_info", "[", "'total_frames'", "]", "=", "int", "(", "line_split", "[", "idx", "]", ")", "\n", "idx", "+=", "1", "\n", "# idx for label[s]", "\n", "label", "=", "[", "int", "(", "x", ")", "for", "x", "in", "line_split", "[", "idx", ":", "]", "]", "\n", "assert", "label", ",", "f'missing label in line: {line}'", "\n", "if", "self", ".", "multi_class", ":", "\n", "                    ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "label", "]", "=", "1.0", "\n", "video_info", "[", "'label'", "]", "=", "onehot", "\n", "", "else", ":", "\n", "                    ", "assert", "len", "(", "label", ")", "==", "1", "\n", "video_info", "[", "'label'", "]", "=", "label", "[", "0", "]", "\n", "", "video_infos", ".", "append", "(", "video_info", ")", "\n", "\n", "", "", "return", "video_infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.__init__": [[93, 151], ["utils.get_root_logger", "base.BaseDataset.__init__", "core.evaluation.ava_utils.read_labelmap", "set().issubset", "tuple", "mmcv.load", "ava_dataset.AVADataset.filter_exclude_file", "ava_dataset.AVADataset.logger.info", "open", "len", "set", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_labelmap", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.filter_exclude_file"], ["def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "exclude_file", ",", "\n", "pipeline", ",", "\n", "label_file", "=", "None", ",", "\n", "filename_tmpl", "=", "'img_{:05}.jpg'", ",", "\n", "proposal_file", "=", "None", ",", "\n", "person_det_score_thr", "=", "0.9", ",", "\n", "num_classes", "=", "81", ",", "\n", "custom_classes", "=", "None", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "num_max_proposals", "=", "1000", ",", "\n", "timestamp_start", "=", "900", ",", "\n", "timestamp_end", "=", "1800", ")", ":", "\n", "# since it inherits from `BaseDataset`, some arguments", "\n", "# should be assigned before performing `load_annotations()`", "\n", "        ", "self", ".", "custom_classes", "=", "custom_classes", "\n", "if", "custom_classes", "is", "not", "None", ":", "\n", "            ", "assert", "num_classes", "==", "len", "(", "custom_classes", ")", "+", "1", "\n", "assert", "0", "not", "in", "custom_classes", "\n", "_", ",", "class_whitelist", "=", "read_labelmap", "(", "open", "(", "label_file", ")", ")", "\n", "assert", "set", "(", "custom_classes", ")", ".", "issubset", "(", "class_whitelist", ")", "\n", "\n", "self", ".", "custom_classes", "=", "tuple", "(", "[", "0", "]", "+", "custom_classes", ")", "\n", "", "self", ".", "exclude_file", "=", "exclude_file", "\n", "self", ".", "label_file", "=", "label_file", "\n", "self", ".", "proposal_file", "=", "proposal_file", "\n", "assert", "0", "<=", "person_det_score_thr", "<=", "1", ",", "(", "\n", "'The value of '", "\n", "'person_det_score_thr should in [0, 1]. '", ")", "\n", "self", ".", "person_det_score_thr", "=", "person_det_score_thr", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "filename_tmpl", "=", "filename_tmpl", "\n", "self", ".", "num_max_proposals", "=", "num_max_proposals", "\n", "self", ".", "timestamp_start", "=", "timestamp_start", "\n", "self", ".", "timestamp_end", "=", "timestamp_end", "\n", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", ",", "\n", "test_mode", ",", "\n", "modality", "=", "modality", ",", "\n", "num_classes", "=", "num_classes", ")", "\n", "\n", "if", "self", ".", "proposal_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "proposals", "=", "mmcv", ".", "load", "(", "self", ".", "proposal_file", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proposals", "=", "None", "\n", "\n", "", "if", "not", "test_mode", ":", "\n", "            ", "valid_indexes", "=", "self", ".", "filter_exclude_file", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "f'{len(valid_indexes)} out of {len(self.video_infos)} '", "\n", "f'frames are valid.'", ")", "\n", "self", ".", "video_infos", "=", "[", "self", ".", "video_infos", "[", "i", "]", "for", "i", "in", "valid_indexes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.parse_img_record": [[152, 195], ["numpy.stack", "numpy.stack", "numpy.stack", "len", "len", "list", "len", "list", "numpy.stack.append", "numpy.array", "numpy.zeros", "numpy.stack.append", "numpy.stack.append", "filter", "filter", "len", "numpy.array_equal", "numpy.array_equal"], "methods", ["None"], ["", "", "def", "parse_img_record", "(", "self", ",", "img_records", ")", ":", "\n", "        ", "\"\"\"Merge image records of the same entity at the same time.\n\n        Args:\n            img_records (list[dict]): List of img_records (lines in AVA\n                annotations).\n\n        Returns:\n            tuple(list): A tuple consists of lists of bboxes, action labels and\n                entity_ids\n        \"\"\"", "\n", "bboxes", ",", "labels", ",", "entity_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "while", "len", "(", "img_records", ")", ">", "0", ":", "\n", "            ", "img_record", "=", "img_records", "[", "0", "]", "\n", "num_img_records", "=", "len", "(", "img_records", ")", "\n", "selected_records", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "x", ":", "np", ".", "array_equal", "(", "x", "[", "'entity_box'", "]", ",", "img_record", "[", "\n", "'entity_box'", "]", ")", ",", "img_records", ")", ")", "\n", "num_selected_records", "=", "len", "(", "selected_records", ")", "\n", "img_records", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "x", ":", "not", "np", ".", "array_equal", "(", "x", "[", "'entity_box'", "]", ",", "img_record", "[", "\n", "'entity_box'", "]", ")", ",", "img_records", ")", ")", "\n", "assert", "len", "(", "img_records", ")", "+", "num_selected_records", "==", "num_img_records", "\n", "\n", "bboxes", ".", "append", "(", "img_record", "[", "'entity_box'", "]", ")", "\n", "valid_labels", "=", "np", ".", "array", "(", "[", "\n", "selected_record", "[", "'label'", "]", "\n", "for", "selected_record", "in", "selected_records", "\n", "]", ")", "\n", "\n", "# The format can be directly used by BCELossWithLogits", "\n", "label", "=", "np", ".", "zeros", "(", "self", ".", "num_classes", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "label", "[", "valid_labels", "]", "=", "1.", "\n", "\n", "labels", ".", "append", "(", "label", ")", "\n", "entity_ids", ".", "append", "(", "img_record", "[", "'entity_id'", "]", ")", "\n", "\n", "", "bboxes", "=", "np", ".", "stack", "(", "bboxes", ")", "\n", "labels", "=", "np", ".", "stack", "(", "labels", ")", "\n", "entity_ids", "=", "np", ".", "stack", "(", "entity_ids", ")", "\n", "return", "bboxes", ",", "labels", ",", "entity_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.filter_exclude_file": [[196, 213], ["list", "enumerate", "range", "x.strip().split", "list.append", "len", "open", "x.strip", "list.pop", "int"], "methods", ["None"], ["", "def", "filter_exclude_file", "(", "self", ")", ":", "\n", "        ", "\"\"\"Filter out records in the exclude_file.\"\"\"", "\n", "valid_indexes", "=", "[", "]", "\n", "if", "self", ".", "exclude_file", "is", "None", ":", "\n", "            ", "valid_indexes", "=", "list", "(", "range", "(", "len", "(", "self", ".", "video_infos", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "exclude_video_infos", "=", "[", "\n", "x", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "for", "x", "in", "open", "(", "self", ".", "exclude_file", ")", "\n", "]", "\n", "for", "i", ",", "video_info", "in", "enumerate", "(", "self", ".", "video_infos", ")", ":", "\n", "                ", "valid_indexes", ".", "append", "(", "i", ")", "\n", "for", "video_id", ",", "timestamp", "in", "exclude_video_infos", ":", "\n", "                    ", "if", "(", "video_info", "[", "'video_id'", "]", "==", "video_id", "\n", "and", "video_info", "[", "'timestamp'", "]", "==", "int", "(", "timestamp", ")", ")", ":", "\n", "                        ", "valid_indexes", ".", "pop", "(", ")", "\n", "break", "\n", "", "", "", "", "return", "valid_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.load_annotations": [[214, 266], ["collections.defaultdict", "open", "img_key.split", "ava_dataset.AVADataset.parse_img_record", "dict", "dict", "video_infos.append", "line.strip().split", "int", "int", "numpy.array", "int", "dict", "records_dict_by_img[].append", "os.join", "os.join", "ava_dataset.AVADataset.custom_classes.index", "list", "int", "line.strip", "map"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.parse_img_record", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load AVA annotations.\"\"\"", "\n", "video_infos", "=", "[", "]", "\n", "records_dict_by_img", "=", "defaultdict", "(", "list", ")", "\n", "with", "open", "(", "self", ".", "ann_file", ",", "'r'", ")", "as", "fin", ":", "\n", "            ", "for", "line", "in", "fin", ":", "\n", "                ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "\n", "label", "=", "int", "(", "line_split", "[", "6", "]", ")", "\n", "if", "self", ".", "custom_classes", "is", "not", "None", ":", "\n", "                    ", "if", "label", "not", "in", "self", ".", "custom_classes", ":", "\n", "                        ", "continue", "\n", "", "label", "=", "self", ".", "custom_classes", ".", "index", "(", "label", ")", "\n", "\n", "", "video_id", "=", "line_split", "[", "0", "]", "\n", "timestamp", "=", "int", "(", "line_split", "[", "1", "]", ")", "\n", "img_key", "=", "f'{video_id},{timestamp:04d}'", "\n", "\n", "entity_box", "=", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "line_split", "[", "2", ":", "6", "]", ")", ")", ")", "\n", "entity_id", "=", "int", "(", "line_split", "[", "7", "]", ")", "\n", "shot_info", "=", "(", "0", ",", "(", "self", ".", "timestamp_end", "-", "self", ".", "timestamp_start", ")", "*", "\n", "self", ".", "_FPS", ")", "\n", "\n", "video_info", "=", "dict", "(", "\n", "video_id", "=", "video_id", ",", "\n", "timestamp", "=", "timestamp", ",", "\n", "entity_box", "=", "entity_box", ",", "\n", "label", "=", "label", ",", "\n", "entity_id", "=", "entity_id", ",", "\n", "shot_info", "=", "shot_info", ")", "\n", "records_dict_by_img", "[", "img_key", "]", ".", "append", "(", "video_info", ")", "\n", "\n", "", "", "for", "img_key", "in", "records_dict_by_img", ":", "\n", "            ", "video_id", ",", "timestamp", "=", "img_key", ".", "split", "(", "','", ")", "\n", "bboxes", ",", "labels", ",", "entity_ids", "=", "self", ".", "parse_img_record", "(", "\n", "records_dict_by_img", "[", "img_key", "]", ")", "\n", "ann", "=", "dict", "(", "\n", "gt_bboxes", "=", "bboxes", ",", "gt_labels", "=", "labels", ",", "entity_ids", "=", "entity_ids", ")", "\n", "frame_dir", "=", "video_id", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "frame_dir", ")", "\n", "", "video_info", "=", "dict", "(", "\n", "frame_dir", "=", "frame_dir", ",", "\n", "video_id", "=", "video_id", ",", "\n", "timestamp", "=", "int", "(", "timestamp", ")", ",", "\n", "img_key", "=", "img_key", ",", "\n", "shot_info", "=", "shot_info", ",", "\n", "fps", "=", "self", ".", "_FPS", ",", "\n", "ann", "=", "ann", ")", "\n", "video_infos", ".", "append", "(", "video_info", ")", "\n", "\n", "", "return", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.prepare_train_frames": [[267, 302], ["copy.deepcopy", "copy.deepcopy.pop", "ava_dataset.AVADataset.pipeline", "numpy.array", "numpy.array", "min", "max"], "methods", ["None"], ["", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "img_key", "=", "results", "[", "'img_key'", "]", "\n", "\n", "results", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "results", "[", "'timestamp_start'", "]", "=", "self", ".", "timestamp_start", "\n", "results", "[", "'timestamp_end'", "]", "=", "self", ".", "timestamp_end", "\n", "\n", "if", "self", ".", "proposals", "is", "not", "None", ":", "\n", "            ", "if", "img_key", "not", "in", "self", ".", "proposals", ":", "\n", "                ", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "results", "[", "'scores'", "]", "=", "np", ".", "array", "(", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "proposals", "=", "self", ".", "proposals", "[", "img_key", "]", "\n", "assert", "proposals", ".", "shape", "[", "-", "1", "]", "in", "[", "4", ",", "5", "]", "\n", "if", "proposals", ".", "shape", "[", "-", "1", "]", "==", "5", ":", "\n", "                    ", "thr", "=", "min", "(", "self", ".", "person_det_score_thr", ",", "max", "(", "proposals", "[", ":", ",", "4", "]", ")", ")", "\n", "positive_inds", "=", "(", "proposals", "[", ":", ",", "4", "]", ">=", "thr", ")", "\n", "proposals", "=", "proposals", "[", "positive_inds", "]", "\n", "proposals", "=", "proposals", "[", ":", "self", ".", "num_max_proposals", "]", "\n", "results", "[", "'proposals'", "]", "=", "proposals", "[", ":", ",", ":", "4", "]", "\n", "results", "[", "'scores'", "]", "=", "proposals", "[", ":", ",", "4", "]", "\n", "", "else", ":", "\n", "                    ", "proposals", "=", "proposals", "[", ":", "self", ".", "num_max_proposals", "]", "\n", "results", "[", "'proposals'", "]", "=", "proposals", "\n", "\n", "", "", "", "ann", "=", "results", ".", "pop", "(", "'ann'", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "ann", "[", "'gt_bboxes'", "]", "\n", "results", "[", "'gt_labels'", "]", "=", "ann", "[", "'gt_labels'", "]", "\n", "results", "[", "'entity_ids'", "]", "=", "ann", "[", "'entity_ids'", "]", "\n", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.prepare_test_frames": [[303, 339], ["copy.deepcopy", "copy.deepcopy.pop", "ava_dataset.AVADataset.pipeline", "numpy.array", "numpy.array", "min", "max"], "methods", ["None"], ["", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "img_key", "=", "results", "[", "'img_key'", "]", "\n", "\n", "results", "[", "'filename_tmpl'", "]", "=", "self", ".", "filename_tmpl", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "results", "[", "'timestamp_start'", "]", "=", "self", ".", "timestamp_start", "\n", "results", "[", "'timestamp_end'", "]", "=", "self", ".", "timestamp_end", "\n", "\n", "if", "self", ".", "proposals", "is", "not", "None", ":", "\n", "            ", "if", "img_key", "not", "in", "self", ".", "proposals", ":", "\n", "                ", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "results", "[", "'scores'", "]", "=", "np", ".", "array", "(", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "proposals", "=", "self", ".", "proposals", "[", "img_key", "]", "\n", "assert", "proposals", ".", "shape", "[", "-", "1", "]", "in", "[", "4", ",", "5", "]", "\n", "if", "proposals", ".", "shape", "[", "-", "1", "]", "==", "5", ":", "\n", "                    ", "thr", "=", "min", "(", "self", ".", "person_det_score_thr", ",", "max", "(", "proposals", "[", ":", ",", "4", "]", ")", ")", "\n", "positive_inds", "=", "(", "proposals", "[", ":", ",", "4", "]", ">=", "thr", ")", "\n", "proposals", "=", "proposals", "[", "positive_inds", "]", "\n", "proposals", "=", "proposals", "[", ":", "self", ".", "num_max_proposals", "]", "\n", "results", "[", "'proposals'", "]", "=", "proposals", "[", ":", ",", ":", "4", "]", "\n", "results", "[", "'scores'", "]", "=", "proposals", "[", ":", ",", "4", "]", "\n", "", "else", ":", "\n", "                    ", "proposals", "=", "proposals", "[", ":", "self", ".", "num_max_proposals", "]", "\n", "results", "[", "'proposals'", "]", "=", "proposals", "\n", "\n", "", "", "", "ann", "=", "results", ".", "pop", "(", "'ann'", ")", "\n", "# Follow the mmdet variable naming style.", "\n", "results", "[", "'gt_bboxes'", "]", "=", "ann", "[", "'gt_bboxes'", "]", "\n", "results", "[", "'gt_labels'", "]", "=", "ann", "[", "'gt_labels'", "]", "\n", "results", "[", "'entity_ids'", "]", "=", "ann", "[", "'entity_ids'", "]", "\n", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.dump_results": [[340, 344], ["out.endswith", "core.evaluation.ava_utils.results2csv"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.results2csv"], ["", "def", "dump_results", "(", "self", ",", "results", ",", "out", ")", ":", "\n", "        ", "\"\"\"Dump predictions into a csv file.\"\"\"", "\n", "assert", "out", ".", "endswith", "(", "'csv'", ")", "\n", "results2csv", "(", "self", ",", "results", ",", "out", ",", "self", ".", "custom_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.evaluate": [[345, 383], ["datetime.datetime.datetime.now().strftime", "core.evaluation.ava_utils.results2csv", "os.remove", "os.remove", "os.remove", "os.remove", "mmcv.utils.print_log", "core.evaluation.ava_utils.ava_eval", "core.evaluation.ava_utils.ava_eval.items", "mmcv.utils.print_log", "ret.update", "len", "datetime.datetime.datetime.now", "log_msg.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.results2csv", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.ava_eval"], ["", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "(", "'mAP'", ",", ")", ",", "\n", "metric_options", "=", "None", ",", "\n", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"Evaluate the prediction results and report mAP.\"\"\"", "\n", "assert", "len", "(", "metrics", ")", "==", "1", "and", "metrics", "[", "0", "]", "==", "'mAP'", ",", "(", "\n", "'For evaluation on AVADataset, you need to use metrics \"mAP\" '", "\n", "'See https://github.com/open-mmlab/mmaction2/pull/567 '", "\n", "'for more info.'", ")", "\n", "time_now", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y%m%d_%H%M%S'", ")", "\n", "temp_file", "=", "f'AVA_{time_now}_result.csv'", "\n", "results2csv", "(", "self", ",", "results", ",", "temp_file", ",", "self", ".", "custom_classes", ")", "\n", "\n", "ret", "=", "{", "}", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "msg", "=", "f'Evaluating {metric} ...'", "\n", "if", "logger", "is", "None", ":", "\n", "                ", "msg", "=", "'\\n'", "+", "msg", "\n", "", "print_log", "(", "msg", ",", "logger", "=", "logger", ")", "\n", "\n", "eval_result", "=", "ava_eval", "(", "\n", "temp_file", ",", "\n", "metric", ",", "\n", "self", ".", "label_file", ",", "\n", "self", ".", "ann_file", ",", "\n", "self", ".", "exclude_file", ",", "\n", "custom_classes", "=", "self", ".", "custom_classes", ")", "\n", "log_msg", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "eval_result", ".", "items", "(", ")", ":", "\n", "                ", "log_msg", ".", "append", "(", "f'\\n{k}\\t{v: .4f}'", ")", "\n", "", "log_msg", "=", "''", ".", "join", "(", "log_msg", ")", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "ret", ".", "update", "(", "eval_result", ")", "\n", "\n", "", "os", ".", "remove", "(", "temp_file", ")", "\n", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.samplers.distributed_sampler.DistributedSampler.__init__": [[16, 26], ["torch.utils.data.DistributedSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "num_replicas", "=", "None", ",", "\n", "rank", "=", "None", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "dataset", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ",", "shuffle", "=", "shuffle", ")", "\n", "# for the compatibility from PyTorch 1.3+", "\n", "self", ".", "seed", "=", "seed", "if", "seed", "is", "not", "None", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.samplers.distributed_sampler.DistributedSampler.__iter__": [[27, 44], ["iter", "torch.Generator", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.arange().tolist", "len", "len", "torch.randperm", "torch.arange", "len", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "# deterministically shuffle based on epoch", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "epoch", "+", "self", ".", "seed", ")", "\n", "indices", "=", "torch", ".", "randperm", "(", "len", "(", "self", ".", "dataset", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "indices", "=", "torch", ".", "arange", "(", "len", "(", "self", ".", "dataset", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "# add extra samples to make it evenly divisible", "\n", "", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "\n", "# subsample", "\n", "indices", "=", "indices", "[", "self", ".", "rank", ":", "self", ".", "total_size", ":", "self", ".", "num_replicas", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.samplers.distributed_sampler.ClassSpecificDistributedSampler.__init__": [[61, 80], ["torch.utils.data.DistributedSampler.__init__", "hasattr", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "num_replicas", "=", "None", ",", "\n", "rank", "=", "None", ",", "\n", "dynamic_length", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "dataset", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "if", "type", "(", "dataset", ")", ".", "__name__", "==", "'RepeatDataset'", ":", "\n", "            ", "dataset", "=", "dataset", ".", "dataset", "\n", "\n", "", "assert", "hasattr", "(", "dataset", ",", "'class_prob'", ")", "\n", "\n", "self", ".", "class_prob", "=", "dataset", ".", "class_prob", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "# for the compatibility from PyTorch 1.3+", "\n", "self", ".", "seed", "=", "seed", "if", "seed", "is", "not", "None", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.samplers.distributed_sampler.ClassSpecificDistributedSampler.__iter__": [[81, 135], ["torch.Generator", "torch.Generator.manual_seed", "collections.defaultdict", "enumerate", "iter", "class_indices[].append", "distributed_sampler.ClassSpecificDistributedSampler.class_prob.items", "math.ceil", "torch.multinomial", "indices.data.numpy().tolist.data.numpy().tolist.data.numpy().tolist", "len", "len", "type", "range", "int", "indices.data.numpy().tolist.data.numpy().tolist.extend", "torch.randperm().tolist", "torch.Tensor", "int", "indices.data.numpy().tolist.data.numpy().tolist.extend", "torch.randperm().tolist", "len", "len", "indices.data.numpy().tolist.data.numpy().tolist.data.numpy", "len", "len", "torch.randperm", "torch.randperm", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "seed", "+", "self", ".", "epoch", ")", "\n", "\n", "class_indices", "=", "defaultdict", "(", "list", ")", "\n", "\n", "# To be compatible with RepeatDataset", "\n", "times", "=", "1", "\n", "dataset", "=", "self", ".", "dataset", "\n", "if", "type", "(", "dataset", ")", ".", "__name__", "==", "'RepeatDataset'", ":", "\n", "            ", "times", "=", "dataset", ".", "times", "\n", "dataset", "=", "dataset", ".", "dataset", "\n", "", "for", "i", ",", "item", "in", "enumerate", "(", "dataset", ".", "video_infos", ")", ":", "\n", "            ", "class_indices", "[", "item", "[", "'label'", "]", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "if", "self", ".", "dynamic_length", ":", "\n", "            ", "indices", "=", "[", "]", "\n", "for", "k", ",", "prob", "in", "self", ".", "class_prob", ".", "items", "(", ")", ":", "\n", "                ", "prob", "=", "prob", "*", "times", "\n", "for", "i", "in", "range", "(", "int", "(", "prob", "//", "1", ")", ")", ":", "\n", "                    ", "indices", ".", "extend", "(", "class_indices", "[", "k", "]", ")", "\n", "", "rem", "=", "int", "(", "(", "prob", "%", "1", ")", "*", "len", "(", "class_indices", "[", "k", "]", ")", ")", "\n", "rem_indices", "=", "torch", ".", "randperm", "(", "\n", "len", "(", "class_indices", "[", "k", "]", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "[", ":", "rem", "]", "\n", "indices", ".", "extend", "(", "rem_indices", ")", "\n", "", "if", "self", ".", "shuffle", ":", "\n", "                ", "shuffle", "=", "torch", ".", "randperm", "(", "len", "(", "indices", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "indices", "=", "[", "indices", "[", "i", "]", "for", "i", "in", "shuffle", "]", "\n", "\n", "# re-calc num_samples & total_size", "\n", "", "self", ".", "num_samples", "=", "math", ".", "ceil", "(", "len", "(", "indices", ")", "/", "self", ".", "num_replicas", ")", "\n", "self", ".", "total_size", "=", "self", ".", "num_samples", "*", "self", ".", "num_replicas", "\n", "", "else", ":", "\n", "# We want to keep the dataloader length same as original", "\n", "            ", "video_labels", "=", "[", "x", "[", "'label'", "]", "for", "x", "in", "dataset", ".", "video_infos", "]", "\n", "probs", "=", "[", "\n", "self", ".", "class_prob", "[", "lb", "]", "/", "len", "(", "class_indices", "[", "lb", "]", ")", "\n", "for", "lb", "in", "video_labels", "\n", "]", "\n", "\n", "indices", "=", "torch", ".", "multinomial", "(", "\n", "torch", ".", "Tensor", "(", "probs", ")", ",", "\n", "self", ".", "total_size", ",", "\n", "replacement", "=", "True", ",", "\n", "generator", "=", "g", ")", "\n", "indices", "=", "indices", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "\n", "# retrieve indices for current process", "\n", "indices", "=", "indices", "[", "self", ".", "rank", ":", "self", ".", "total_size", ":", "self", ".", "num_replicas", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "return", "iter", "(", "indices", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadHVULabel.__init__": [[26, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "hvu_initialized", "=", "False", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadHVULabel.init_hvu_info": [[30, 42], ["len", "sum", "dict", "range", "dict", "len", "len", "zip", "loading.LoadHVULabel.start_idx.append", "zip"], "methods", ["None"], ["", "def", "init_hvu_info", "(", "self", ",", "categories", ",", "category_nums", ")", ":", "\n", "        ", "assert", "len", "(", "categories", ")", "==", "len", "(", "category_nums", ")", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "category_nums", "=", "category_nums", "\n", "self", ".", "num_categories", "=", "len", "(", "self", ".", "categories", ")", "\n", "self", ".", "num_tags", "=", "sum", "(", "self", ".", "category_nums", ")", "\n", "self", ".", "category2num", "=", "dict", "(", "zip", "(", "categories", ",", "category_nums", ")", ")", "\n", "self", ".", "start_idx", "=", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_categories", "-", "1", ")", ":", "\n", "            ", "self", ".", "start_idx", ".", "append", "(", "self", ".", "start_idx", "[", "-", "1", "]", "+", "self", ".", "category_nums", "[", "i", "]", ")", "\n", "", "self", ".", "category2startidx", "=", "dict", "(", "zip", "(", "categories", ",", "self", ".", "start_idx", ")", ")", "\n", "self", ".", "hvu_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadHVULabel.__call__": [[43, 71], ["torch.zeros", "torch.zeros", "torch.zeros", "results[].items", "loading.LoadHVULabel.init_hvu_info", "loading.LoadHVULabel.categories.index"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadHVULabel.init_hvu_info"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Convert the label dictionary to 3 tensors: \"label\", \"mask\" and\n        \"category_mask\".\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "hvu_initialized", ":", "\n", "            ", "self", ".", "init_hvu_info", "(", "results", "[", "'categories'", "]", ",", "results", "[", "'category_nums'", "]", ")", "\n", "\n", "", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_tags", ")", "\n", "onehot_mask", "=", "torch", ".", "zeros", "(", "self", ".", "num_tags", ")", "\n", "category_mask", "=", "torch", ".", "zeros", "(", "self", ".", "num_categories", ")", "\n", "\n", "for", "category", ",", "tags", "in", "results", "[", "'label'", "]", ".", "items", "(", ")", ":", "\n", "            ", "category_mask", "[", "self", ".", "categories", ".", "index", "(", "category", ")", "]", "=", "1.", "\n", "start_idx", "=", "self", ".", "category2startidx", "[", "category", "]", "\n", "category_num", "=", "self", ".", "category2num", "[", "category", "]", "\n", "tags", "=", "[", "idx", "+", "start_idx", "for", "idx", "in", "tags", "]", "\n", "onehot", "[", "tags", "]", "=", "1.", "\n", "onehot_mask", "[", "start_idx", ":", "category_num", "+", "start_idx", "]", "=", "1.", "\n", "\n", "", "results", "[", "'label'", "]", "=", "onehot", "\n", "results", "[", "'mask'", "]", "=", "onehot_mask", "\n", "results", "[", "'category_mask'", "]", "=", "category_mask", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadHVULabel.__repr__": [[72, 76], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'hvu_initialized={self.hvu_initialized})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames.__init__": [[105, 128], ["warnings.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "clip_len", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "1", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "twice_sample", "=", "False", ",", "\n", "out_of_bound_opt", "=", "'loop'", ",", "\n", "test_mode", "=", "False", ",", "\n", "start_index", "=", "None", ",", "\n", "frame_uniform", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "clip_len", "=", "clip_len", "\n", "self", ".", "frame_interval", "=", "frame_interval", "\n", "self", ".", "num_clips", "=", "num_clips", "\n", "self", ".", "temporal_jitter", "=", "temporal_jitter", "\n", "self", ".", "twice_sample", "=", "twice_sample", "\n", "self", ".", "out_of_bound_opt", "=", "out_of_bound_opt", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "frame_uniform", "=", "frame_uniform", "\n", "assert", "self", ".", "out_of_bound_opt", "in", "[", "'loop'", ",", "'repeat_last'", "]", "\n", "\n", "if", "start_index", "is", "not", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "'No longer support \"start_index\" in \"SampleFrames\", '", "\n", "'it should be set in dataset class, see this pr: '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames._get_train_clips": [[131, 163], ["numpy.arange", "numpy.random.randint", "max", "numpy.sort", "numpy.random.randint", "numpy.around", "numpy.zeros", "numpy.arange"], "methods", ["None"], ["", "", "def", "_get_train_clips", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Get clip offsets in train mode.\n\n        It will calculate the average interval for selected frames,\n        and randomly shift them within offsets between [0, avg_interval].\n        If the total number of frames is smaller than clips num or origin\n        frames length, it will return all zero indices.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices in train mode.\n        \"\"\"", "\n", "ori_clip_len", "=", "self", ".", "clip_len", "*", "self", ".", "frame_interval", "\n", "avg_interval", "=", "(", "num_frames", "-", "ori_clip_len", "+", "1", ")", "//", "self", ".", "num_clips", "\n", "\n", "if", "avg_interval", ">", "0", ":", "\n", "            ", "base_offsets", "=", "np", ".", "arange", "(", "self", ".", "num_clips", ")", "*", "avg_interval", "\n", "clip_offsets", "=", "base_offsets", "+", "np", ".", "random", ".", "randint", "(", "\n", "avg_interval", ",", "size", "=", "self", ".", "num_clips", ")", "\n", "", "elif", "num_frames", ">", "max", "(", "self", ".", "num_clips", ",", "ori_clip_len", ")", ":", "\n", "            ", "clip_offsets", "=", "np", ".", "sort", "(", "\n", "np", ".", "random", ".", "randint", "(", "\n", "num_frames", "-", "ori_clip_len", "+", "1", ",", "size", "=", "self", ".", "num_clips", ")", ")", "\n", "", "elif", "avg_interval", "==", "0", ":", "\n", "            ", "ratio", "=", "(", "num_frames", "-", "ori_clip_len", "+", "1.0", ")", "/", "self", ".", "num_clips", "\n", "clip_offsets", "=", "np", ".", "around", "(", "np", ".", "arange", "(", "self", ".", "num_clips", ")", "*", "ratio", ")", "\n", "", "else", ":", "\n", "            ", "clip_offsets", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_clips", ",", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames._get_test_clips": [[164, 188], ["float", "numpy.zeros", "numpy.arange", "numpy.concatenate"], "methods", ["None"], ["", "def", "_get_test_clips", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Get clip offsets in test mode.\n\n        Calculate the average interval for selected frames, and shift them\n        fixedly by avg_interval/2. If set twice_sample True, it will sample\n        frames together without fixed shift. If the total number of frames is\n        not enough, it will return all zero indices.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices in test mode.\n        \"\"\"", "\n", "ori_clip_len", "=", "self", ".", "clip_len", "*", "self", ".", "frame_interval", "\n", "avg_interval", "=", "(", "num_frames", "-", "ori_clip_len", "+", "1", ")", "/", "float", "(", "self", ".", "num_clips", ")", "\n", "if", "num_frames", ">", "ori_clip_len", "-", "1", ":", "\n", "            ", "base_offsets", "=", "np", ".", "arange", "(", "self", ".", "num_clips", ")", "*", "avg_interval", "\n", "clip_offsets", "=", "(", "base_offsets", "+", "avg_interval", "/", "2.0", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "if", "self", ".", "twice_sample", ":", "\n", "                ", "clip_offsets", "=", "np", ".", "concatenate", "(", "[", "clip_offsets", ",", "base_offsets", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "clip_offsets", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_clips", ",", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames._sample_clips": [[189, 204], ["loading.SampleFrames._get_test_clips", "loading.SampleFrames._get_train_clips"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_test_clips", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_train_clips"], ["", "def", "_sample_clips", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Choose clip offsets for the video in a given mode.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices.\n        \"\"\"", "\n", "if", "self", ".", "test_mode", ":", "\n", "            ", "clip_offsets", "=", "self", ".", "_get_test_clips", "(", "num_frames", ")", "\n", "", "else", ":", "\n", "            ", "clip_offsets", "=", "self", ".", "_get_train_clips", "(", "num_frames", ")", "\n", "\n", "", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames.get_seq_frames": [[205, 225], ["range", "numpy.array", "float", "int", "int", "numpy.round", "numpy.round", "seq.append", "seq.append", "random.randint"], "methods", ["None"], ["", "def", "get_seq_frames", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"\n        Modified from https://github.com/facebookresearch/SlowFast/blob/64abcc90ccfdcbb11cf91d6e525bed60e92a8796/slowfast/datasets/ssv2.py#L159\n        Given the video index, return the list of sampled frame indexes.\n        Args:\n            num_frames (int): Total number of frame in the video.\n        Returns:\n            seq (list): the indexes of frames of sampled from the video.\n        \"\"\"", "\n", "seg_size", "=", "float", "(", "num_frames", "-", "1", ")", "/", "self", ".", "clip_len", "\n", "seq", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "clip_len", ")", ":", "\n", "            ", "start", "=", "int", "(", "np", ".", "round", "(", "seg_size", "*", "i", ")", ")", "\n", "end", "=", "int", "(", "np", ".", "round", "(", "seg_size", "*", "(", "i", "+", "1", ")", ")", ")", "\n", "if", "not", "self", ".", "test_mode", ":", "\n", "                ", "seq", ".", "append", "(", "random", ".", "randint", "(", "start", ",", "end", ")", ")", "\n", "", "else", ":", "\n", "                ", "seq", ".", "append", "(", "(", "start", "+", "end", ")", "//", "2", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames.__call__": [[226, 268], ["numpy.mod.astype", "loading.SampleFrames.get_seq_frames", "loading.SampleFrames._sample_clips", "numpy.concatenate", "numpy.mod.reshape", "numpy.random.randint", "numpy.mod", "numpy.concatenate", "numpy.max", "ValueError", "numpy.arange", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames.get_seq_frames", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._sample_clips"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the SampleFrames loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "total_frames", "=", "results", "[", "'total_frames'", "]", "\n", "if", "self", ".", "frame_uniform", ":", "# sthv2 sampling strategy", "\n", "            ", "assert", "results", "[", "'start_index'", "]", "==", "0", "\n", "frame_inds", "=", "self", ".", "get_seq_frames", "(", "total_frames", ")", "\n", "", "else", ":", "\n", "            ", "clip_offsets", "=", "self", ".", "_sample_clips", "(", "total_frames", ")", "\n", "frame_inds", "=", "clip_offsets", "[", ":", ",", "None", "]", "+", "np", ".", "arange", "(", "\n", "self", ".", "clip_len", ")", "[", "None", ",", ":", "]", "*", "self", ".", "frame_interval", "\n", "frame_inds", "=", "np", ".", "concatenate", "(", "frame_inds", ")", "\n", "\n", "if", "self", ".", "temporal_jitter", ":", "\n", "                ", "perframe_offsets", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "frame_interval", ",", "size", "=", "len", "(", "frame_inds", ")", ")", "\n", "frame_inds", "+=", "perframe_offsets", "\n", "\n", "", "frame_inds", "=", "frame_inds", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "clip_len", ")", ")", "\n", "if", "self", ".", "out_of_bound_opt", "==", "'loop'", ":", "\n", "                ", "frame_inds", "=", "np", ".", "mod", "(", "frame_inds", ",", "total_frames", ")", "\n", "", "elif", "self", ".", "out_of_bound_opt", "==", "'repeat_last'", ":", "\n", "                ", "safe_inds", "=", "frame_inds", "<", "total_frames", "\n", "unsafe_inds", "=", "1", "-", "safe_inds", "\n", "last_ind", "=", "np", ".", "max", "(", "safe_inds", "*", "frame_inds", ",", "axis", "=", "1", ")", "\n", "new_inds", "=", "(", "safe_inds", "*", "frame_inds", "+", "(", "unsafe_inds", ".", "T", "*", "last_ind", ")", ".", "T", ")", "\n", "frame_inds", "=", "new_inds", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Illegal out_of_bound option.'", ")", "\n", "\n", "", "start_index", "=", "results", "[", "'start_index'", "]", "\n", "frame_inds", "=", "np", ".", "concatenate", "(", "frame_inds", ")", "+", "start_index", "\n", "\n", "", "results", "[", "'frame_inds'", "]", "=", "frame_inds", ".", "astype", "(", "np", ".", "int", ")", "\n", "results", "[", "'clip_len'", "]", "=", "self", ".", "clip_len", "\n", "results", "[", "'frame_interval'", "]", "=", "self", ".", "frame_interval", "\n", "results", "[", "'num_clips'", "]", "=", "self", ".", "num_clips", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleFrames.__repr__": [[269, 279], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'clip_len={self.clip_len}, '", "\n", "f'frame_interval={self.frame_interval}, '", "\n", "f'num_clips={self.num_clips}, '", "\n", "f'temporal_jitter={self.temporal_jitter}, '", "\n", "f'twice_sample={self.twice_sample}, '", "\n", "f'out_of_bound_opt={self.out_of_bound_opt}, '", "\n", "f'test_mode={self.test_mode})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.UntrimmedSampleFrames.__init__": [[297, 304], ["warnings.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "clip_len", "=", "1", ",", "frame_interval", "=", "16", ",", "start_index", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "clip_len", "=", "clip_len", "\n", "self", ".", "frame_interval", "=", "frame_interval", "\n", "\n", "if", "start_index", "is", "not", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "'No longer support \"start_index\" in \"SampleFrames\", '", "\n", "'it should be set in dataset class, see this pr: '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.UntrimmedSampleFrames.__call__": [[307, 332], ["numpy.arange", "numpy.clip", "numpy.clip.astype", "numpy.concatenate", "numpy.arange"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the SampleFrames loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "total_frames", "=", "results", "[", "'total_frames'", "]", "\n", "start_index", "=", "results", "[", "'start_index'", "]", "\n", "\n", "clip_centers", "=", "np", ".", "arange", "(", "self", ".", "frame_interval", "//", "2", ",", "total_frames", ",", "\n", "self", ".", "frame_interval", ")", "\n", "num_clips", "=", "clip_centers", ".", "shape", "[", "0", "]", "\n", "frame_inds", "=", "clip_centers", "[", ":", ",", "None", "]", "+", "np", ".", "arange", "(", "\n", "-", "(", "self", ".", "clip_len", "//", "2", ")", ",", "self", ".", "clip_len", "-", "\n", "(", "self", ".", "clip_len", "//", "2", ")", ")", "[", "None", ",", ":", "]", "\n", "# clip frame_inds to legal range", "\n", "frame_inds", "=", "np", ".", "clip", "(", "frame_inds", ",", "0", ",", "total_frames", "-", "1", ")", "\n", "\n", "frame_inds", "=", "np", ".", "concatenate", "(", "frame_inds", ")", "+", "start_index", "\n", "results", "[", "'frame_inds'", "]", "=", "frame_inds", ".", "astype", "(", "np", ".", "int", ")", "\n", "results", "[", "'clip_len'", "]", "=", "self", ".", "clip_len", "\n", "results", "[", "'frame_interval'", "]", "=", "self", ".", "frame_interval", "\n", "results", "[", "'num_clips'", "]", "=", "num_clips", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.UntrimmedSampleFrames.__repr__": [[333, 338], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'clip_len={self.clip_len}, '", "\n", "f'frame_interval={self.frame_interval})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DenseSampleFrames.__init__": [[363, 381], ["loading.SampleFrames.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "clip_len", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "1", ",", "\n", "sample_range", "=", "64", ",", "\n", "num_sample_positions", "=", "10", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "out_of_bound_opt", "=", "'loop'", ",", "\n", "test_mode", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "clip_len", ",", "\n", "frame_interval", ",", "\n", "num_clips", ",", "\n", "temporal_jitter", ",", "\n", "out_of_bound_opt", "=", "out_of_bound_opt", ",", "\n", "test_mode", "=", "test_mode", ")", "\n", "self", ".", "sample_range", "=", "sample_range", "\n", "self", ".", "num_sample_positions", "=", "num_sample_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DenseSampleFrames._get_train_clips": [[382, 403], ["max", "numpy.random.randint", "numpy.arange"], "methods", ["None"], ["", "def", "_get_train_clips", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Get clip offsets by dense sample strategy in train mode.\n\n        It will calculate a sample position and sample interval and set\n        start index 0 when sample_pos == 1 or randomly choose from\n        [0, sample_pos - 1]. Then it will shift the start index by each\n        base offset.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices in train mode.\n        \"\"\"", "\n", "sample_position", "=", "max", "(", "1", ",", "1", "+", "num_frames", "-", "self", ".", "sample_range", ")", "\n", "interval", "=", "self", ".", "sample_range", "//", "self", ".", "num_clips", "\n", "start_idx", "=", "0", "if", "sample_position", "==", "1", "else", "np", ".", "random", ".", "randint", "(", "\n", "0", ",", "sample_position", "-", "1", ")", "\n", "base_offsets", "=", "np", ".", "arange", "(", "self", ".", "num_clips", ")", "*", "interval", "\n", "clip_offsets", "=", "(", "base_offsets", "+", "start_idx", ")", "%", "num_frames", "\n", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DenseSampleFrames._get_test_clips": [[404, 428], ["max", "numpy.linspace", "list", "numpy.array", "numpy.arange", "numpy.array.extend"], "methods", ["None"], ["", "def", "_get_test_clips", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Get clip offsets by dense sample strategy in test mode.\n\n        It will calculate a sample position and sample interval and evenly\n        sample several start indexes as start positions between\n        [0, sample_position-1]. Then it will shift each start index by the\n        base offsets.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices in train mode.\n        \"\"\"", "\n", "sample_position", "=", "max", "(", "1", ",", "1", "+", "num_frames", "-", "self", ".", "sample_range", ")", "\n", "interval", "=", "self", ".", "sample_range", "//", "self", ".", "num_clips", "\n", "start_list", "=", "np", ".", "linspace", "(", "\n", "0", ",", "sample_position", "-", "1", ",", "num", "=", "self", ".", "num_sample_positions", ",", "dtype", "=", "int", ")", "\n", "base_offsets", "=", "np", ".", "arange", "(", "self", ".", "num_clips", ")", "*", "interval", "\n", "clip_offsets", "=", "list", "(", ")", "\n", "for", "start_idx", "in", "start_list", ":", "\n", "            ", "clip_offsets", ".", "extend", "(", "(", "base_offsets", "+", "start_idx", ")", "%", "num_frames", ")", "\n", "", "clip_offsets", "=", "np", ".", "array", "(", "clip_offsets", ")", "\n", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DenseSampleFrames.__repr__": [[429, 440], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'clip_len={self.clip_len}, '", "\n", "f'frame_interval={self.frame_interval}, '", "\n", "f'num_clips={self.num_clips}, '", "\n", "f'sample_range={self.sample_range}, '", "\n", "f'num_sample_positions={self.num_sample_positions}, '", "\n", "f'temporal_jitter={self.temporal_jitter}, '", "\n", "f'out_of_bound_opt={self.out_of_bound_opt}, '", "\n", "f'test_mode={self.test_mode})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleAVAFrames.__init__": [[445, 448], ["loading.SampleFrames.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "clip_len", ",", "frame_interval", "=", "2", ",", "test_mode", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "clip_len", ",", "frame_interval", ",", "test_mode", "=", "test_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleAVAFrames._get_clips": [[449, 457], ["list", "numpy.clip", "range"], "methods", ["None"], ["", "def", "_get_clips", "(", "self", ",", "center_index", ",", "skip_offsets", ",", "shot_info", ")", ":", "\n", "        ", "start", "=", "center_index", "-", "(", "self", ".", "clip_len", "//", "2", ")", "*", "self", ".", "frame_interval", "\n", "end", "=", "center_index", "+", "(", "(", "self", ".", "clip_len", "+", "1", ")", "//", "2", ")", "*", "self", ".", "frame_interval", "\n", "frame_inds", "=", "list", "(", "range", "(", "start", ",", "end", ",", "self", ".", "frame_interval", ")", ")", "\n", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "frame_inds", "=", "frame_inds", "+", "skip_offsets", "\n", "", "frame_inds", "=", "np", ".", "clip", "(", "frame_inds", ",", "shot_info", "[", "0", "]", ",", "shot_info", "[", "1", "]", "-", "1", ")", "\n", "return", "frame_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleAVAFrames.__call__": [[458, 477], ["numpy.random.randint", "loading.SampleAVAFrames._get_clips", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleAVAFrames._get_clips"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "fps", "=", "results", "[", "'fps'", "]", "\n", "timestamp", "=", "results", "[", "'timestamp'", "]", "\n", "timestamp_start", "=", "results", "[", "'timestamp_start'", "]", "\n", "shot_info", "=", "results", "[", "'shot_info'", "]", "\n", "\n", "center_index", "=", "fps", "*", "(", "timestamp", "-", "timestamp_start", ")", "+", "1", "\n", "\n", "skip_offsets", "=", "np", ".", "random", ".", "randint", "(", "\n", "-", "self", ".", "frame_interval", "//", "2", ",", "(", "self", ".", "frame_interval", "+", "1", ")", "//", "2", ",", "\n", "size", "=", "self", ".", "clip_len", ")", "\n", "frame_inds", "=", "self", ".", "_get_clips", "(", "center_index", ",", "skip_offsets", ",", "shot_info", ")", "\n", "\n", "results", "[", "'frame_inds'", "]", "=", "np", ".", "array", "(", "frame_inds", ",", "dtype", "=", "np", ".", "int", ")", "\n", "results", "[", "'clip_len'", "]", "=", "self", ".", "clip_len", "\n", "results", "[", "'frame_interval'", "]", "=", "self", ".", "frame_interval", "\n", "results", "[", "'num_clips'", "]", "=", "1", "\n", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleAVAFrames.__repr__": [[478, 484], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'clip_len={self.clip_len}, '", "\n", "f'frame_interval={self.frame_interval}, '", "\n", "f'test_mode={self.test_mode})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames.__init__": [[511, 535], ["loading.SampleFrames.__init__", "torch.nn.modules.utils._pair", "mmcv.is_tuple_of", "TypeError", "len", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "clip_len", ",", "\n", "body_segments", ",", "\n", "aug_segments", ",", "\n", "aug_ratio", ",", "\n", "frame_interval", "=", "1", ",", "\n", "test_interval", "=", "6", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "mode", "=", "'train'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "clip_len", ",", "\n", "frame_interval", "=", "frame_interval", ",", "\n", "temporal_jitter", "=", "temporal_jitter", ")", "\n", "self", ".", "body_segments", "=", "body_segments", "\n", "self", ".", "aug_segments", "=", "aug_segments", "\n", "self", ".", "aug_ratio", "=", "_pair", "(", "aug_ratio", ")", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "aug_ratio", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'aug_ratio should be int, float'", "\n", "f'or tuple of int and float, '", "\n", "f'but got {type(aug_ratio)}'", ")", "\n", "", "assert", "len", "(", "self", ".", "aug_ratio", ")", "==", "2", "\n", "assert", "mode", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "test_interval", "=", "test_interval", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_train_indices": [[536, 562], ["numpy.zeros", "numpy.arange", "numpy.random.randint"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_train_indices", "(", "valid_length", ",", "num_segments", ")", ":", "\n", "        ", "\"\"\"Get indices of different stages of proposals in train mode.\n\n        It will calculate the average interval for each segment,\n        and randomly shift them within offsets between [0, average_duration].\n        If the total number of frames is smaller than num segments, it will\n        return all zero indices.\n\n        Args:\n            valid_length (int): The length of the starting point's\n                valid interval.\n            num_segments (int): Total number of segments.\n\n        Returns:\n            np.ndarray: Sampled frame indices in train mode.\n        \"\"\"", "\n", "avg_interval", "=", "(", "valid_length", "+", "1", ")", "//", "num_segments", "\n", "if", "avg_interval", ">", "0", ":", "\n", "            ", "base_offsets", "=", "np", ".", "arange", "(", "num_segments", ")", "*", "avg_interval", "\n", "offsets", "=", "base_offsets", "+", "np", ".", "random", ".", "randint", "(", "\n", "avg_interval", ",", "size", "=", "num_segments", ")", "\n", "", "else", ":", "\n", "            ", "offsets", "=", "np", ".", "zeros", "(", "(", "num_segments", ",", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "", "return", "offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_val_indices": [[563, 587], ["numpy.zeros", "float", "numpy.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_val_indices", "(", "valid_length", ",", "num_segments", ")", ":", "\n", "        ", "\"\"\"Get indices of different stages of proposals in validation mode.\n\n        It will calculate the average interval for each segment.\n        If the total number of valid length is smaller than num segments,\n        it will return all zero indices.\n\n        Args:\n            valid_length (int): The length of the starting point's\n                valid interval.\n            num_segments (int): Total number of segments.\n\n        Returns:\n            np.ndarray: Sampled frame indices in validation mode.\n        \"\"\"", "\n", "if", "valid_length", ">=", "num_segments", ":", "\n", "            ", "avg_interval", "=", "valid_length", "/", "float", "(", "num_segments", ")", "\n", "base_offsets", "=", "np", ".", "arange", "(", "num_segments", ")", "*", "avg_interval", "\n", "offsets", "=", "(", "base_offsets", "+", "avg_interval", "/", "2.0", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "", "else", ":", "\n", "            ", "offsets", "=", "np", ".", "zeros", "(", "(", "num_segments", ",", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "", "return", "offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_proposal_clips": [[588, 639], ["max", "min", "numpy.concatenate", "loading.SampleProposalFrames._get_train_indices", "loading.SampleProposalFrames._get_train_indices", "loading.SampleProposalFrames._get_train_indices", "int", "int", "loading.SampleProposalFrames._get_val_indices", "loading.SampleProposalFrames._get_val_indices", "loading.SampleProposalFrames._get_val_indices"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_train_indices", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_train_indices", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_train_indices", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_val_indices", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_val_indices", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_val_indices"], ["", "def", "_get_proposal_clips", "(", "self", ",", "proposal", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Get clip offsets in train mode.\n\n        It will calculate sampled frame indices in the proposal's three\n        stages: starting, course and ending stage.\n\n        Args:\n            proposal (obj): The proposal object.\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices in train mode.\n        \"\"\"", "\n", "# proposal interval: [start_frame, end_frame)", "\n", "start_frame", "=", "proposal", ".", "start_frame", "\n", "end_frame", "=", "proposal", ".", "end_frame", "\n", "ori_clip_len", "=", "self", ".", "clip_len", "*", "self", ".", "frame_interval", "\n", "\n", "duration", "=", "end_frame", "-", "start_frame", "\n", "assert", "duration", "!=", "0", "\n", "valid_length", "=", "duration", "-", "ori_clip_len", "\n", "\n", "valid_starting", "=", "max", "(", "0", ",", "\n", "start_frame", "-", "int", "(", "duration", "*", "self", ".", "aug_ratio", "[", "0", "]", ")", ")", "\n", "valid_ending", "=", "min", "(", "num_frames", "-", "ori_clip_len", "+", "1", ",", "\n", "end_frame", "-", "1", "+", "int", "(", "duration", "*", "self", ".", "aug_ratio", "[", "1", "]", ")", ")", "\n", "\n", "valid_starting_length", "=", "start_frame", "-", "valid_starting", "-", "ori_clip_len", "\n", "valid_ending_length", "=", "(", "valid_ending", "-", "end_frame", "+", "1", ")", "-", "ori_clip_len", "\n", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "starting_offsets", "=", "self", ".", "_get_train_indices", "(", "valid_starting_length", ",", "\n", "self", ".", "aug_segments", "[", "0", "]", ")", "\n", "course_offsets", "=", "self", ".", "_get_train_indices", "(", "valid_length", ",", "\n", "self", ".", "body_segments", ")", "\n", "ending_offsets", "=", "self", ".", "_get_train_indices", "(", "valid_ending_length", ",", "\n", "self", ".", "aug_segments", "[", "1", "]", ")", "\n", "", "elif", "self", ".", "mode", "==", "'val'", ":", "\n", "            ", "starting_offsets", "=", "self", ".", "_get_val_indices", "(", "valid_starting_length", ",", "\n", "self", ".", "aug_segments", "[", "0", "]", ")", "\n", "course_offsets", "=", "self", ".", "_get_val_indices", "(", "valid_length", ",", "\n", "self", ".", "body_segments", ")", "\n", "ending_offsets", "=", "self", ".", "_get_val_indices", "(", "valid_ending_length", ",", "\n", "self", ".", "aug_segments", "[", "1", "]", ")", "\n", "", "starting_offsets", "+=", "valid_starting", "\n", "course_offsets", "+=", "start_frame", "\n", "ending_offsets", "+=", "end_frame", "\n", "\n", "offsets", "=", "np", ".", "concatenate", "(", "\n", "(", "starting_offsets", ",", "course_offsets", ",", "ending_offsets", ")", ")", "\n", "return", "offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_train_clips": [[640, 661], ["loading.SampleProposalFrames._get_proposal_clips", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_proposal_clips"], ["", "def", "_get_train_clips", "(", "self", ",", "num_frames", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"Get clip offsets in train mode.\n\n        It will calculate sampled frame indices of each proposal, and then\n        assemble them.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n            proposals (list): Proposals fetched.\n\n        Returns:\n            np.ndarray: Sampled frame indices in train mode.\n        \"\"\"", "\n", "clip_offsets", "=", "[", "]", "\n", "for", "proposal", "in", "proposals", ":", "\n", "            ", "proposal_clip_offsets", "=", "self", ".", "_get_proposal_clips", "(", "\n", "proposal", "[", "0", "]", "[", "1", "]", ",", "num_frames", ")", "\n", "clip_offsets", "=", "np", ".", "concatenate", "(", "\n", "[", "clip_offsets", ",", "proposal_clip_offsets", "]", ")", "\n", "\n", "", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._get_test_clips": [[662, 676], ["numpy.arange"], "methods", ["None"], ["", "def", "_get_test_clips", "(", "self", ",", "num_frames", ")", ":", "\n", "        ", "\"\"\"Get clip offsets in test mode.\n\n        It will calculate sampled frame indices based on test interval.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n\n        Returns:\n            np.ndarray: Sampled frame indices in test mode.\n        \"\"\"", "\n", "ori_clip_len", "=", "self", ".", "clip_len", "*", "self", ".", "frame_interval", "\n", "return", "np", ".", "arange", "(", "\n", "0", ",", "num_frames", "-", "ori_clip_len", ",", "self", ".", "test_interval", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._sample_clips": [[677, 695], ["loading.SampleProposalFrames._get_test_clips", "loading.SampleProposalFrames._get_train_clips"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_test_clips", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_train_clips"], ["", "def", "_sample_clips", "(", "self", ",", "num_frames", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"Choose clip offsets for the video in a given mode.\n\n        Args:\n            num_frames (int): Total number of frame in the video.\n            proposals (list | None): Proposals fetched.\n                It is set to None in test mode.\n\n        Returns:\n            np.ndarray: Sampled frame indices.\n        \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "clip_offsets", "=", "self", ".", "_get_test_clips", "(", "num_frames", ")", "\n", "", "else", ":", "\n", "            ", "assert", "proposals", "is", "not", "None", "\n", "clip_offsets", "=", "self", ".", "_get_train_clips", "(", "num_frames", ",", "proposals", ")", "\n", "\n", "", "return", "clip_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames.__call__": [[696, 728], ["results.get", "loading.SampleProposalFrames._sample_clips", "numpy.concatenate", "numpy.array().astype", "numpy.random.randint", "numpy.mod", "len", "numpy.array", "numpy.arange", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames._sample_clips"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the SampleFrames loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "total_frames", "=", "results", "[", "'total_frames'", "]", "\n", "\n", "out_proposals", "=", "results", ".", "get", "(", "'out_proposals'", ",", "None", ")", "\n", "clip_offsets", "=", "self", ".", "_sample_clips", "(", "total_frames", ",", "out_proposals", ")", "\n", "frame_inds", "=", "clip_offsets", "[", ":", ",", "None", "]", "+", "np", ".", "arange", "(", "\n", "self", ".", "clip_len", ")", "[", "None", ",", ":", "]", "*", "self", ".", "frame_interval", "\n", "frame_inds", "=", "np", ".", "concatenate", "(", "frame_inds", ")", "\n", "\n", "if", "self", ".", "temporal_jitter", ":", "\n", "            ", "perframe_offsets", "=", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "frame_interval", ",", "size", "=", "len", "(", "frame_inds", ")", ")", "\n", "frame_inds", "+=", "perframe_offsets", "\n", "\n", "", "start_index", "=", "results", "[", "'start_index'", "]", "\n", "frame_inds", "=", "np", ".", "mod", "(", "frame_inds", ",", "total_frames", ")", "+", "start_index", "\n", "\n", "results", "[", "'frame_inds'", "]", "=", "np", ".", "array", "(", "frame_inds", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "results", "[", "'clip_len'", "]", "=", "self", ".", "clip_len", "\n", "results", "[", "'frame_interval'", "]", "=", "self", ".", "frame_interval", "\n", "results", "[", "'num_clips'", "]", "=", "(", "\n", "self", ".", "body_segments", "+", "self", ".", "aug_segments", "[", "0", "]", "+", "self", ".", "aug_segments", "[", "1", "]", ")", "\n", "if", "self", ".", "mode", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "            ", "results", "[", "'num_proposals'", "]", "=", "len", "(", "results", "[", "'out_proposals'", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.SampleProposalFrames.__repr__": [[729, 740], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'clip_len={self.clip_len}, '", "\n", "f'body_segments={self.body_segments}, '", "\n", "f'aug_segments={self.aug_segments}, '", "\n", "f'aug_ratio={self.aug_ratio}, '", "\n", "f'frame_interval={self.frame_interval}, '", "\n", "f'test_interval={self.test_interval}, '", "\n", "f'temporal_jitter={self.temporal_jitter}, '", "\n", "f'mode={self.mode})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVInit.__init__": [[757, 761], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "io_backend", "=", "'disk'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVInit.__call__": [[762, 785], ["io.BytesIO", "av.open", "mmcv.fileio.FileClient", "loading.PyAVInit.file_client.get", "ImportError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the PyAV initialization.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "av", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'Please run \"conda install av -c conda-forge\" '", "\n", "'or \"pip install av\" to install PyAV first.'", ")", "\n", "\n", "", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "\n", "", "file_obj", "=", "io", ".", "BytesIO", "(", "self", ".", "file_client", ".", "get", "(", "results", "[", "'filename'", "]", ")", ")", "\n", "container", "=", "av", ".", "open", "(", "file_obj", ")", "\n", "\n", "results", "[", "'video_reader'", "]", "=", "container", "\n", "results", "[", "'total_frames'", "]", "=", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "frames", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVInit.__repr__": [[786, 789], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "f'{self.__class__.__name__}(io_backend=disk)'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVDecode.__init__": [[805, 807], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "multi_thread", "=", "False", ")", ":", "\n", "        ", "self", ".", "multi_thread", "=", "multi_thread", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVDecode.__call__": [[808, 843], ["list", "max", "container.decode", "numpy.squeeze", "list.append", "frame.to_rgb().to_ndarray", "frame.to_rgb", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the PyAV decoding.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "container", "=", "results", "[", "'video_reader'", "]", "\n", "imgs", "=", "list", "(", ")", "\n", "\n", "if", "self", ".", "multi_thread", ":", "\n", "            ", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "thread_type", "=", "'AUTO'", "\n", "", "if", "results", "[", "'frame_inds'", "]", ".", "ndim", "!=", "1", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "squeeze", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "\n", "# set max indice to make early stop", "\n", "", "max_inds", "=", "max", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "i", "=", "0", "\n", "for", "frame", "in", "container", ".", "decode", "(", "video", "=", "0", ")", ":", "\n", "            ", "if", "i", ">", "max_inds", "+", "1", ":", "\n", "                ", "break", "\n", "", "imgs", ".", "append", "(", "frame", ".", "to_rgb", "(", ")", ".", "to_ndarray", "(", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "results", "[", "'video_reader'", "]", "=", "None", "\n", "del", "container", "\n", "\n", "# the available frame in pyav may be less than its length,", "\n", "# which may raise error", "\n", "results", "[", "'imgs'", "]", "=", "[", "imgs", "[", "i", "%", "len", "(", "imgs", ")", "]", "for", "i", "in", "results", "[", "'frame_inds'", "]", "]", "\n", "\n", "results", "[", "'original_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "results", "[", "'img_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVDecode.__repr__": [[844, 848], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(multi_thread={self.multi_thread})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVDecodeMotionVector._parse_vectors": [[865, 883], ["zip"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "_parse_vectors", "(", "mv", ",", "vectors", ",", "height", ",", "width", ")", ":", "\n", "        ", "\"\"\"Parse the returned vectors.\"\"\"", "\n", "(", "w", ",", "h", ",", "src_x", ",", "src_y", ",", "dst_x", ",", "\n", "dst_y", ")", "=", "(", "vectors", "[", "'w'", "]", ",", "vectors", "[", "'h'", "]", ",", "vectors", "[", "'src_x'", "]", ",", "\n", "vectors", "[", "'src_y'", "]", ",", "vectors", "[", "'dst_x'", "]", ",", "vectors", "[", "'dst_y'", "]", ")", "\n", "val_x", "=", "dst_x", "-", "src_x", "\n", "val_y", "=", "dst_y", "-", "src_y", "\n", "start_x", "=", "dst_x", "-", "w", "//", "2", "\n", "start_y", "=", "dst_y", "-", "h", "//", "2", "\n", "end_x", "=", "start_x", "+", "w", "\n", "end_y", "=", "start_y", "+", "h", "\n", "for", "sx", ",", "ex", ",", "sy", ",", "ey", ",", "vx", ",", "vy", "in", "zip", "(", "start_x", ",", "end_x", ",", "start_y", ",", "end_y", ",", "\n", "val_x", ",", "val_y", ")", ":", "\n", "            ", "if", "(", "sx", ">=", "0", "and", "ex", "<", "width", "and", "sy", ">=", "0", "and", "ey", "<", "height", ")", ":", "\n", "                ", "mv", "[", "sy", ":", "ey", ",", "sx", ":", "ex", "]", "=", "(", "vx", ",", "vy", ")", "\n", "\n", "", "", "return", "mv", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVDecodeMotionVector.__call__": [[884, 930], ["list", "max", "container.demux", "numpy.array", "numpy.squeeze", "packet.decode", "numpy.zeros", "frame.side_data.get", "list.append", "loading.PyAVDecodeMotionVector._parse_vectors", "len", "frame.side_data.get.to_ndarray", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.PyAVDecodeMotionVector._parse_vectors"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the PyAV motion vector decoding.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "container", "=", "results", "[", "'video_reader'", "]", "\n", "imgs", "=", "list", "(", ")", "\n", "\n", "if", "self", ".", "multi_thread", ":", "\n", "            ", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "thread_type", "=", "'AUTO'", "\n", "", "if", "results", "[", "'frame_inds'", "]", ".", "ndim", "!=", "1", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "squeeze", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "\n", "# set max index to make early stop", "\n", "", "max_idx", "=", "max", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "i", "=", "0", "\n", "stream", "=", "container", ".", "streams", ".", "video", "[", "0", "]", "\n", "codec_context", "=", "stream", ".", "codec_context", "\n", "codec_context", ".", "options", "=", "{", "'flags2'", ":", "'+export_mvs'", "}", "\n", "for", "packet", "in", "container", ".", "demux", "(", "stream", ")", ":", "\n", "            ", "for", "frame", "in", "packet", ".", "decode", "(", ")", ":", "\n", "                ", "if", "i", ">", "max_idx", "+", "1", ":", "\n", "                    ", "break", "\n", "", "i", "+=", "1", "\n", "height", "=", "frame", ".", "height", "\n", "width", "=", "frame", ".", "width", "\n", "mv", "=", "np", ".", "zeros", "(", "(", "height", ",", "width", ",", "2", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "vectors", "=", "frame", ".", "side_data", ".", "get", "(", "'MOTION_VECTORS'", ")", "\n", "if", "frame", ".", "key_frame", ":", "\n", "# Key frame don't have motion vectors", "\n", "                    ", "assert", "vectors", "is", "None", "\n", "", "if", "vectors", "is", "not", "None", "and", "len", "(", "vectors", ")", ">", "0", ":", "\n", "                    ", "mv", "=", "self", ".", "_parse_vectors", "(", "mv", ",", "vectors", ".", "to_ndarray", "(", ")", ",", "height", ",", "\n", "width", ")", "\n", "", "imgs", ".", "append", "(", "mv", ")", "\n", "\n", "", "", "results", "[", "'video_reader'", "]", "=", "None", "\n", "del", "container", "\n", "\n", "# the available frame in pyav may be less than its length,", "\n", "# which may raise error", "\n", "results", "[", "'motion_vectors'", "]", "=", "np", ".", "array", "(", "\n", "[", "imgs", "[", "i", "%", "len", "(", "imgs", ")", "]", "for", "i", "in", "results", "[", "'frame_inds'", "]", "]", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DecordInit.__init__": [[942, 947], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "io_backend", "=", "'disk'", ",", "num_threads", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "num_threads", "=", "num_threads", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DecordInit.__call__": [[948, 969], ["io.BytesIO", "decord.VideoReader", "len", "mmcv.fileio.FileClient", "loading.DecordInit.file_client.get", "ImportError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the Decord initialization.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "decord", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "'Please run \"pip install decord\" to install Decord first.'", ")", "\n", "\n", "", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "\n", "", "file_obj", "=", "io", ".", "BytesIO", "(", "self", ".", "file_client", ".", "get", "(", "results", "[", "'filename'", "]", ")", ")", "\n", "container", "=", "decord", ".", "VideoReader", "(", "file_obj", ",", "num_threads", "=", "self", ".", "num_threads", ")", "\n", "results", "[", "'video_reader'", "]", "=", "container", "\n", "results", "[", "'total_frames'", "]", "=", "len", "(", "container", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DecordInit.__repr__": [[970, 975], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'io_backend={self.io_backend}, '", "\n", "f'num_threads={self.num_threads})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.DecordDecode.__call__": [[987, 1016], ["numpy.squeeze", "container[].asnumpy", "numpy.unique"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the Decord decoding.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "container", "=", "results", "[", "'video_reader'", "]", "\n", "\n", "if", "results", "[", "'frame_inds'", "]", ".", "ndim", "!=", "1", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "squeeze", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "\n", "", "frame_inds", "=", "results", "[", "'frame_inds'", "]", "\n", "# Generate frame index mapping in order", "\n", "frame_dict", "=", "{", "\n", "idx", ":", "container", "[", "idx", "]", ".", "asnumpy", "(", ")", "\n", "for", "idx", "in", "np", ".", "unique", "(", "frame_inds", ")", "\n", "}", "\n", "\n", "imgs", "=", "[", "frame_dict", "[", "idx", "]", "for", "idx", "in", "frame_inds", "]", "\n", "\n", "results", "[", "'video_reader'", "]", "=", "None", "\n", "del", "container", "\n", "\n", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "results", "[", "'original_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "results", "[", "'img_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.OpenCVInit.__init__": [[1026, 1037], ["utils.get_random_string", "utils.get_thread_id", "os.join", "os.join", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "utils.get_shm_dir"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_random_string", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_thread_id", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_shm_dir"], ["def", "__init__", "(", "self", ",", "io_backend", "=", "'disk'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "self", ".", "tmp_folder", "=", "None", "\n", "if", "self", ".", "io_backend", "!=", "'disk'", ":", "\n", "            ", "random_string", "=", "get_random_string", "(", ")", "\n", "thread_id", "=", "get_thread_id", "(", ")", "\n", "self", ".", "tmp_folder", "=", "osp", ".", "join", "(", "get_shm_dir", "(", ")", ",", "\n", "f'{random_string}_{thread_id}'", ")", "\n", "os", ".", "mkdir", "(", "self", ".", "tmp_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.OpenCVInit.__call__": [[1038, 1063], ["mmcv.VideoReader", "len", "utils.get_thread_id", "os.join", "os.join", "mmcv.fileio.FileClient", "open", "f.write", "loading.OpenCVInit.file_client.get"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.misc.get_thread_id", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the OpenCV initialization.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "if", "self", ".", "io_backend", "==", "'disk'", ":", "\n", "            ", "new_path", "=", "results", "[", "'filename'", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "file_client", "is", "None", ":", "\n", "                ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "\n", "", "thread_id", "=", "get_thread_id", "(", ")", "\n", "# save the file of same thread at the same place", "\n", "new_path", "=", "osp", ".", "join", "(", "self", ".", "tmp_folder", ",", "f'tmp_{thread_id}.mp4'", ")", "\n", "with", "open", "(", "new_path", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "self", ".", "file_client", ".", "get", "(", "results", "[", "'filename'", "]", ")", ")", "\n", "\n", "", "", "container", "=", "mmcv", ".", "VideoReader", "(", "new_path", ")", "\n", "results", "[", "'new_path'", "]", "=", "new_path", "\n", "results", "[", "'video_reader'", "]", "=", "container", "\n", "results", "[", "'total_frames'", "]", "=", "len", "(", "container", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.OpenCVInit.__del__": [[1064, 1067], ["os.exists", "os.exists", "shutil.rmtree"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "tmp_folder", "and", "osp", ".", "exists", "(", "self", ".", "tmp_folder", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "self", ".", "tmp_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.OpenCVInit.__repr__": [[1068, 1072], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'io_backend={self.io_backend})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.OpenCVDecode.__call__": [[1082, 1114], ["list", "numpy.array", "list", "numpy.squeeze", "isinstance", "numpy.array.append", "type"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the OpenCV decoding.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "container", "=", "results", "[", "'video_reader'", "]", "\n", "imgs", "=", "list", "(", ")", "\n", "\n", "if", "results", "[", "'frame_inds'", "]", ".", "ndim", "!=", "1", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "squeeze", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "\n", "", "for", "frame_ind", "in", "results", "[", "'frame_inds'", "]", ":", "\n", "            ", "cur_frame", "=", "container", "[", "frame_ind", "]", "\n", "# last frame may be None in OpenCV", "\n", "while", "isinstance", "(", "cur_frame", ",", "type", "(", "None", ")", ")", ":", "\n", "                ", "frame_ind", "-=", "1", "\n", "cur_frame", "=", "container", "[", "frame_ind", "]", "\n", "", "imgs", ".", "append", "(", "cur_frame", ")", "\n", "\n", "", "results", "[", "'video_reader'", "]", "=", "None", "\n", "del", "container", "\n", "\n", "imgs", "=", "np", ".", "array", "(", "imgs", ")", "\n", "# The default channel order of OpenCV is BGR, thus we change it to RGB", "\n", "imgs", "=", "imgs", "[", ":", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "results", "[", "'imgs'", "]", "=", "list", "(", "imgs", ")", "\n", "results", "[", "'original_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "results", "[", "'img_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.RawFrameDecode.__init__": [[1130, 1135], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "io_backend", "=", "'disk'", ",", "decoding_backend", "=", "'cv2'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "decoding_backend", "=", "decoding_backend", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.RawFrameDecode.__call__": [[1136, 1197], ["mmcv.use_backend", "list", "results.get", "mmcv.fileio.FileClient", "numpy.squeeze", "numpy.array", "os.join", "os.join", "loading.RawFrameDecode.file_client.get", "mmcv.imfrombytes", "list.append", "filename_tmpl.format", "os.join", "os.join", "os.join", "os.join", "loading.RawFrameDecode.file_client.get", "mmcv.imfrombytes", "loading.RawFrameDecode.file_client.get", "mmcv.imfrombytes", "list.extend", "filename_tmpl.format", "filename_tmpl.format"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the ``RawFrameDecode`` to pick frames given indices.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "mmcv", ".", "use_backend", "(", "self", ".", "decoding_backend", ")", "\n", "\n", "directory", "=", "results", "[", "'frame_dir'", "]", "\n", "filename_tmpl", "=", "results", "[", "'filename_tmpl'", "]", "\n", "modality", "=", "results", "[", "'modality'", "]", "\n", "\n", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "\n", "", "imgs", "=", "list", "(", ")", "\n", "\n", "if", "results", "[", "'frame_inds'", "]", ".", "ndim", "!=", "1", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "squeeze", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "\n", "", "offset", "=", "results", ".", "get", "(", "'offset'", ",", "0", ")", "\n", "\n", "for", "frame_idx", "in", "results", "[", "'frame_inds'", "]", ":", "\n", "            ", "frame_idx", "+=", "offset", "\n", "if", "modality", "==", "'RGB'", ":", "\n", "                ", "filepath", "=", "osp", ".", "join", "(", "directory", ",", "filename_tmpl", ".", "format", "(", "frame_idx", ")", ")", "\n", "img_bytes", "=", "self", ".", "file_client", ".", "get", "(", "filepath", ")", "\n", "# Get frame with channel order RGB directly.", "\n", "cur_frame", "=", "mmcv", ".", "imfrombytes", "(", "img_bytes", ",", "channel_order", "=", "'rgb'", ")", "\n", "imgs", ".", "append", "(", "cur_frame", ")", "\n", "", "elif", "modality", "==", "'Flow'", ":", "\n", "                ", "x_filepath", "=", "osp", ".", "join", "(", "directory", ",", "\n", "filename_tmpl", ".", "format", "(", "'x'", ",", "frame_idx", ")", ")", "\n", "y_filepath", "=", "osp", ".", "join", "(", "directory", ",", "\n", "filename_tmpl", ".", "format", "(", "'y'", ",", "frame_idx", ")", ")", "\n", "x_img_bytes", "=", "self", ".", "file_client", ".", "get", "(", "x_filepath", ")", "\n", "x_frame", "=", "mmcv", ".", "imfrombytes", "(", "x_img_bytes", ",", "flag", "=", "'grayscale'", ")", "\n", "y_img_bytes", "=", "self", ".", "file_client", ".", "get", "(", "y_filepath", ")", "\n", "y_frame", "=", "mmcv", ".", "imfrombytes", "(", "y_img_bytes", ",", "flag", "=", "'grayscale'", ")", "\n", "imgs", ".", "extend", "(", "[", "x_frame", ",", "y_frame", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "results", "[", "'original_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "results", "[", "'img_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# we resize the gt_bboxes and proposals to their real scale", "\n", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "h", ",", "w", "=", "results", "[", "'img_shape'", "]", "\n", "scale_factor", "=", "np", ".", "array", "(", "[", "w", ",", "h", ",", "w", ",", "h", "]", ")", "\n", "gt_bboxes", "=", "results", "[", "'gt_bboxes'", "]", "\n", "gt_bboxes", "=", "(", "gt_bboxes", "*", "scale_factor", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "gt_bboxes", "\n", "if", "'proposals'", "in", "results", "and", "results", "[", "'proposals'", "]", "is", "not", "None", ":", "\n", "                ", "proposals", "=", "results", "[", "'proposals'", "]", "\n", "proposals", "=", "(", "proposals", "*", "scale_factor", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "results", "[", "'proposals'", "]", "=", "proposals", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.RawFrameDecode.__repr__": [[1198, 1203], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'io_backend={self.io_backend}, '", "\n", "f'decoding_backend={self.decoding_backend})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.ImageDecode.__init__": [[1219, 1224], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "io_backend", "=", "'disk'", ",", "decoding_backend", "=", "'cv2'", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "decoding_backend", "=", "decoding_backend", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.ImageDecode.__call__": [[1225, 1249], ["mmcv.use_backend", "list", "loading.ImageDecode.file_client.get", "mmcv.imfrombytes", "list.append", "mmcv.fileio.FileClient"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the ``ImageDecode`` to load image given the file path.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "mmcv", ".", "use_backend", "(", "self", ".", "decoding_backend", ")", "\n", "\n", "filename", "=", "results", "[", "'filename'", "]", "\n", "\n", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "\n", "", "imgs", "=", "list", "(", ")", "\n", "img_bytes", "=", "self", ".", "file_client", ".", "get", "(", "filename", ")", "\n", "\n", "img", "=", "mmcv", ".", "imfrombytes", "(", "img_bytes", ",", "channel_order", "=", "'rgb'", ")", "\n", "imgs", ".", "append", "(", "img", ")", "\n", "\n", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "results", "[", "'original_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "results", "[", "'img_shape'", "]", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecodeInit.__init__": [[1264, 1277], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "io_backend", "=", "'disk'", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "pad_method", "=", "'zero'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "if", "pad_method", "in", "[", "'random'", ",", "'zero'", "]", ":", "\n", "            ", "self", ".", "pad_method", "=", "pad_method", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecodeInit._zero_pad": [[1278, 1281], ["numpy.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_pad", "(", "shape", ")", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecodeInit._random_pad": [[1282, 1286], ["numpy.random.rand().astype", "numpy.random.rand"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_random_pad", "(", "shape", ")", ":", "\n", "# librosa load raw audio file into a distribution of -1~+1", "\n", "        ", "return", "np", ".", "random", ".", "rand", "(", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecodeInit.__call__": [[1287, 1314], ["os.exists", "os.exists", "mmcv.fileio.FileClient", "io.BytesIO", "librosa.load", "getattr", "getattr.", "ImportError", "loading.AudioDecodeInit.file_client.get", "int", "round"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the librosa initialization.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "librosa", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'Please install librosa first.'", ")", "\n", "\n", "", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "", "if", "osp", ".", "exists", "(", "results", "[", "'audio_path'", "]", ")", ":", "\n", "            ", "file_obj", "=", "io", ".", "BytesIO", "(", "self", ".", "file_client", ".", "get", "(", "results", "[", "'audio_path'", "]", ")", ")", "\n", "y", ",", "sr", "=", "librosa", ".", "load", "(", "file_obj", ",", "sr", "=", "self", ".", "sample_rate", ")", "\n", "", "else", ":", "\n", "# Generate a random dummy 10s input", "\n", "            ", "pad_func", "=", "getattr", "(", "self", ",", "f'_{self.pad_method}_pad'", ")", "\n", "y", "=", "pad_func", "(", "int", "(", "round", "(", "10.0", "*", "self", ".", "sample_rate", ")", ")", ")", "\n", "sr", "=", "self", ".", "sample_rate", "\n", "\n", "", "results", "[", "'length'", "]", "=", "y", ".", "shape", "[", "0", "]", "\n", "results", "[", "'sample_rate'", "]", "=", "sr", "\n", "results", "[", "'audios'", "]", "=", "y", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecodeInit.__repr__": [[1315, 1321], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'io_backend={self.io_backend}, '", "\n", "f'sample_rate={self.sample_rate}, '", "\n", "f'pad_method={self.pad_method})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadAudioFeature.__init__": [[1331, 1335], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pad_method", "=", "'zero'", ")", ":", "\n", "        ", "if", "pad_method", "not", "in", "[", "'zero'", ",", "'random'", "]", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "pad_method", "=", "pad_method", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadAudioFeature._zero_pad": [[1336, 1339], ["numpy.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_pad", "(", "shape", ")", ":", "\n", "        ", "return", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadAudioFeature._random_pad": [[1340, 1344], ["numpy.random.rand().astype", "numpy.random.rand"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_random_pad", "(", "shape", ")", ":", "\n", "# spectrogram is normalized into a distribution of 0~1", "\n", "        ", "return", "np", ".", "random", ".", "rand", "(", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadAudioFeature.__call__": [[1345, 1363], ["os.exists", "os.exists", "numpy.load", "getattr", "getattr."], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the numpy loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "if", "osp", ".", "exists", "(", "results", "[", "'audio_path'", "]", ")", ":", "\n", "            ", "feature_map", "=", "np", ".", "load", "(", "results", "[", "'audio_path'", "]", ")", "\n", "", "else", ":", "\n", "# Generate a random dummy 10s input", "\n", "# Some videos do not have audio stream", "\n", "            ", "pad_func", "=", "getattr", "(", "self", ",", "f'_{self.pad_method}_pad'", ")", "\n", "feature_map", "=", "pad_func", "(", "(", "640", ",", "80", ")", ")", "\n", "\n", "", "results", "[", "'length'", "]", "=", "feature_map", ".", "shape", "[", "0", "]", "\n", "results", "[", "'audios'", "]", "=", "feature_map", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadAudioFeature.__repr__": [[1364, 1368], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'pad_method={self.pad_method})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecode.__init__": [[1383, 1385], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fixed_length", "=", "32000", ")", ":", "\n", "        ", "self", ".", "fixed_length", "=", "fixed_length", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioDecode.__call__": [[1386, 1419], ["list", "frame_inds.reshape.reshape.reshape", "range", "numpy.array", "max", "min", "list.append", "int", "int", "numpy.pad", "round", "round"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the ``AudioDecode`` to pick audio clips.\"\"\"", "\n", "audio", "=", "results", "[", "'audios'", "]", "\n", "frame_inds", "=", "results", "[", "'frame_inds'", "]", "\n", "num_clips", "=", "results", "[", "'num_clips'", "]", "\n", "resampled_clips", "=", "list", "(", ")", "\n", "frame_inds", "=", "frame_inds", ".", "reshape", "(", "num_clips", ",", "-", "1", ")", "\n", "for", "clip_idx", "in", "range", "(", "num_clips", ")", ":", "\n", "            ", "clip_frame_inds", "=", "frame_inds", "[", "clip_idx", "]", "\n", "start_idx", "=", "max", "(", "\n", "0", ",", "\n", "int", "(", "\n", "round", "(", "(", "clip_frame_inds", "[", "0", "]", "+", "1", ")", "/", "results", "[", "'total_frames'", "]", "*", "\n", "results", "[", "'length'", "]", ")", ")", ")", "\n", "end_idx", "=", "min", "(", "\n", "results", "[", "'length'", "]", ",", "\n", "int", "(", "\n", "round", "(", "(", "clip_frame_inds", "[", "-", "1", "]", "+", "1", ")", "/", "results", "[", "'total_frames'", "]", "*", "\n", "results", "[", "'length'", "]", ")", ")", ")", "\n", "cropped_audio", "=", "audio", "[", "start_idx", ":", "end_idx", "]", "\n", "if", "cropped_audio", ".", "shape", "[", "0", "]", ">=", "self", ".", "fixed_length", ":", "\n", "                ", "truncated_audio", "=", "cropped_audio", "[", ":", "self", ".", "fixed_length", "]", "\n", "", "else", ":", "\n", "                ", "truncated_audio", "=", "np", ".", "pad", "(", "\n", "cropped_audio", ",", "\n", "(", "(", "0", ",", "self", ".", "fixed_length", "-", "cropped_audio", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "mode", "=", "'constant'", ")", "\n", "\n", "", "resampled_clips", ".", "append", "(", "truncated_audio", ")", "\n", "\n", "", "results", "[", "'audios'", "]", "=", "np", ".", "array", "(", "resampled_clips", ")", "\n", "results", "[", "'audios_shape'", "]", "=", "results", "[", "'audios'", "]", ".", "shape", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.BuildPseudoClip.__init__": [[1432, 1434], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "clip_len", ")", ":", "\n", "        ", "self", ".", "clip_len", "=", "clip_len", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.BuildPseudoClip.__call__": [[1435, 1444], ["range", "len", "results[].append", "numpy.copy"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "# the input should be one single image", "\n", "        ", "assert", "len", "(", "results", "[", "'imgs'", "]", ")", "==", "1", "\n", "im", "=", "results", "[", "'imgs'", "]", "[", "0", "]", "\n", "for", "_", "in", "range", "(", "1", ",", "self", ".", "clip_len", ")", ":", "\n", "            ", "results", "[", "'imgs'", "]", ".", "append", "(", "np", ".", "copy", "(", "im", ")", ")", "\n", "", "results", "[", "'clip_len'", "]", "=", "self", ".", "clip_len", "\n", "results", "[", "'num_clips'", "]", "=", "1", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.BuildPseudoClip.__repr__": [[1445, 1449], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'fix_length={self.fixed_length})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.FrameSelector.__init__": [[1455, 1459], ["warnings.warn", "loading.RawFrameDecode.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "'\"FrameSelector\" is deprecated, please switch to'", "\n", "'\"RawFrameDecode\"'", ")", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioFeatureSelector.__init__": [[1474, 1476], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fixed_length", "=", "128", ")", ":", "\n", "        ", "self", ".", "fixed_length", "=", "fixed_length", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioFeatureSelector.__call__": [[1477, 1515], ["list", "frame_inds.reshape.reshape.reshape", "range", "numpy.array", "max", "min", "list.append", "int", "int", "numpy.pad", "round", "round"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the ``AudioFeatureSelector`` to pick audio feature clips.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "audio", "=", "results", "[", "'audios'", "]", "\n", "frame_inds", "=", "results", "[", "'frame_inds'", "]", "\n", "num_clips", "=", "results", "[", "'num_clips'", "]", "\n", "resampled_clips", "=", "list", "(", ")", "\n", "\n", "frame_inds", "=", "frame_inds", ".", "reshape", "(", "num_clips", ",", "-", "1", ")", "\n", "for", "clip_idx", "in", "range", "(", "num_clips", ")", ":", "\n", "            ", "clip_frame_inds", "=", "frame_inds", "[", "clip_idx", "]", "\n", "start_idx", "=", "max", "(", "\n", "0", ",", "\n", "int", "(", "\n", "round", "(", "(", "clip_frame_inds", "[", "0", "]", "+", "1", ")", "/", "results", "[", "'total_frames'", "]", "*", "\n", "results", "[", "'length'", "]", ")", ")", ")", "\n", "end_idx", "=", "min", "(", "\n", "results", "[", "'length'", "]", ",", "\n", "int", "(", "\n", "round", "(", "(", "clip_frame_inds", "[", "-", "1", "]", "+", "1", ")", "/", "results", "[", "'total_frames'", "]", "*", "\n", "results", "[", "'length'", "]", ")", ")", ")", "\n", "cropped_audio", "=", "audio", "[", "start_idx", ":", "end_idx", ",", ":", "]", "\n", "if", "cropped_audio", ".", "shape", "[", "0", "]", ">=", "self", ".", "fixed_length", ":", "\n", "                ", "truncated_audio", "=", "cropped_audio", "[", ":", "self", ".", "fixed_length", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "truncated_audio", "=", "np", ".", "pad", "(", "\n", "cropped_audio", ",", "\n", "(", "(", "0", ",", "self", ".", "fixed_length", "-", "cropped_audio", ".", "shape", "[", "0", "]", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\n", "mode", "=", "'constant'", ")", "\n", "\n", "", "resampled_clips", ".", "append", "(", "truncated_audio", ")", "\n", "", "results", "[", "'audios'", "]", "=", "np", ".", "array", "(", "resampled_clips", ")", "\n", "results", "[", "'audios_shape'", "]", "=", "results", "[", "'audios'", "]", ".", "shape", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.AudioFeatureSelector.__repr__": [[1516, 1520], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'fix_length={self.fixed_length})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadLocalizationFeature.__init__": [[1533, 1538], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "raw_feature_ext", "=", "'.csv'", ")", ":", "\n", "        ", "valid_raw_feature_ext", "=", "(", "'.csv'", ",", ")", "\n", "if", "raw_feature_ext", "not", "in", "valid_raw_feature_ext", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "raw_feature_ext", "=", "raw_feature_ext", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadLocalizationFeature.__call__": [[1539, 1556], ["os.join", "os.join", "numpy.loadtxt", "numpy.transpose"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the LoadLocalizationFeature loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "video_name", "=", "results", "[", "'video_name'", "]", "\n", "data_prefix", "=", "results", "[", "'data_prefix'", "]", "\n", "\n", "data_path", "=", "osp", ".", "join", "(", "data_prefix", ",", "video_name", "+", "self", ".", "raw_feature_ext", ")", "\n", "raw_feature", "=", "np", ".", "loadtxt", "(", "\n", "data_path", ",", "dtype", "=", "np", ".", "float32", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ")", "\n", "\n", "results", "[", "'raw_feature'", "]", "=", "np", ".", "transpose", "(", "raw_feature", ",", "(", "1", ",", "0", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadLocalizationFeature.__repr__": [[1557, 1561], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'raw_feature_ext={self.raw_feature_ext})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.GenerateLocalizationLabels.__call__": [[1571, 1596], ["numpy.array", "max", "max", "numpy.array.append", "float", "min", "min"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the GenerateLocalizationLabels loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "video_frame", "=", "results", "[", "'duration_frame'", "]", "\n", "video_second", "=", "results", "[", "'duration_second'", "]", "\n", "feature_frame", "=", "results", "[", "'feature_frame'", "]", "\n", "corrected_second", "=", "float", "(", "feature_frame", ")", "/", "video_frame", "*", "video_second", "\n", "annotations", "=", "results", "[", "'annotations'", "]", "\n", "\n", "gt_bbox", "=", "[", "]", "\n", "\n", "for", "annotation", "in", "annotations", ":", "\n", "            ", "current_start", "=", "max", "(", "\n", "min", "(", "1", ",", "annotation", "[", "'segment'", "]", "[", "0", "]", "/", "corrected_second", ")", ",", "0", ")", "\n", "current_end", "=", "max", "(", "\n", "min", "(", "1", ",", "annotation", "[", "'segment'", "]", "[", "1", "]", "/", "corrected_second", ")", ",", "0", ")", "\n", "gt_bbox", ".", "append", "(", "[", "current_start", ",", "current_end", "]", ")", "\n", "\n", "", "gt_bbox", "=", "np", ".", "array", "(", "gt_bbox", ")", "\n", "results", "[", "'gt_bbox'", "]", "=", "gt_bbox", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadProposals.__init__": [[1613, 1630], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "top_k", ",", "\n", "pgm_proposals_dir", ",", "\n", "pgm_features_dir", ",", "\n", "proposal_ext", "=", "'.csv'", ",", "\n", "feature_ext", "=", "'.npy'", ")", ":", "\n", "        ", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "pgm_proposals_dir", "=", "pgm_proposals_dir", "\n", "self", ".", "pgm_features_dir", "=", "pgm_features_dir", "\n", "valid_proposal_ext", "=", "(", "'.csv'", ",", ")", "\n", "if", "proposal_ext", "not", "in", "valid_proposal_ext", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "proposal_ext", "=", "proposal_ext", "\n", "valid_feature_ext", "=", "(", "'.npy'", ",", ")", "\n", "if", "feature_ext", "not", "in", "valid_feature_ext", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "feature_ext", "=", "feature_ext", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadProposals.__call__": [[1631, 1667], ["os.join", "os.join", "numpy.array", "os.join", "os.join", "numpy.loadtxt", "numpy.load().astype", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform the LoadProposals loading.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "video_name", "=", "results", "[", "'video_name'", "]", "\n", "proposal_path", "=", "osp", ".", "join", "(", "self", ".", "pgm_proposals_dir", ",", "\n", "video_name", "+", "self", ".", "proposal_ext", ")", "\n", "if", "self", ".", "proposal_ext", "==", "'.csv'", ":", "\n", "            ", "pgm_proposals", "=", "np", ".", "loadtxt", "(", "\n", "proposal_path", ",", "dtype", "=", "np", ".", "float32", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ")", "\n", "\n", "", "pgm_proposals", "=", "np", ".", "array", "(", "pgm_proposals", "[", ":", "self", ".", "top_k", "]", ")", "\n", "tmin", "=", "pgm_proposals", "[", ":", ",", "0", "]", "\n", "tmax", "=", "pgm_proposals", "[", ":", ",", "1", "]", "\n", "tmin_score", "=", "pgm_proposals", "[", ":", ",", "2", "]", "\n", "tmax_score", "=", "pgm_proposals", "[", ":", ",", "3", "]", "\n", "reference_temporal_iou", "=", "pgm_proposals", "[", ":", ",", "5", "]", "\n", "\n", "feature_path", "=", "osp", ".", "join", "(", "self", ".", "pgm_features_dir", ",", "\n", "video_name", "+", "self", ".", "feature_ext", ")", "\n", "if", "self", ".", "feature_ext", "==", "'.npy'", ":", "\n", "            ", "bsp_feature", "=", "np", ".", "load", "(", "feature_path", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "bsp_feature", "=", "bsp_feature", "[", ":", "self", ".", "top_k", ",", ":", "]", "\n", "\n", "results", "[", "'bsp_feature'", "]", "=", "bsp_feature", "\n", "results", "[", "'tmin'", "]", "=", "tmin", "\n", "results", "[", "'tmax'", "]", "=", "tmax", "\n", "results", "[", "'tmin_score'", "]", "=", "tmin_score", "\n", "results", "[", "'tmax_score'", "]", "=", "tmax_score", "\n", "results", "[", "'reference_temporal_iou'", "]", "=", "reference_temporal_iou", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.loading.LoadProposals.__repr__": [[1668, 1676], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'top_k={self.top_k}, '", "\n", "f'pgm_proposals_dir={self.pgm_proposals_dir}, '", "\n", "f'pgm_features_dir={self.pgm_features_dir}, '", "\n", "f'proposal_ext={self.proposal_ext}, '", "\n", "f'feature_ext={self.feature_ext})'", ")", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ToTensor.__init__": [[39, 41], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keys", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ToTensor.__call__": [[42, 52], ["formating.to_tensor"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.to_tensor"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the ToTensor formating.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "results", "[", "key", "]", "=", "to_tensor", "(", "results", "[", "key", "]", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ToTensor.__repr__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f'{self.__class__.__name__}(keys={self.keys})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Rename.__init__": [[68, 70], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mapping", ")", ":", "\n", "        ", "self", ".", "mapping", "=", "mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Rename.__call__": [[71, 80], ["formating.Rename.mapping.items", "results.pop", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "self", ".", "mapping", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "results", ":", "\n", "                ", "assert", "isinstance", "(", "key", ",", "str", ")", "and", "isinstance", "(", "value", ",", "str", ")", "\n", "assert", "value", "not", "in", "results", ",", "(", "'the new name already exists in '", "\n", "'results'", ")", "\n", "results", "[", "value", "]", "=", "results", "[", "key", "]", "\n", "results", ".", "pop", "(", "key", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ToDataContainer.__init__": [[94, 96], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fields", ")", ":", "\n", "        ", "self", ".", "fields", "=", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ToDataContainer.__call__": [[97, 113], ["field.copy", "field.copy.pop", "isinstance", "mmcv.parallel.DataContainer", "mmcv.parallel.DataContainer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the ToDataContainer formating.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "for", "field", "in", "self", ".", "fields", ":", "\n", "            ", "_field", "=", "field", ".", "copy", "(", ")", "\n", "key", "=", "_field", ".", "pop", "(", "'key'", ")", "\n", "if", "isinstance", "(", "key", ",", "list", ")", ":", "\n", "                ", "for", "item", "in", "key", ":", "\n", "                    ", "results", "[", "item", "]", "=", "DC", "(", "results", "[", "item", "]", ",", "**", "_field", ")", "\n", "", "", "else", ":", "\n", "                ", "results", "[", "key", "]", "=", "DC", "(", "results", "[", "key", "]", ",", "**", "_field", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ToDataContainer.__repr__": [[114, 116], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(fields={self.fields})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ImageToTensor.__init__": [[126, 128], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keys", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ImageToTensor.__call__": [[129, 139], ["formating.to_tensor", "results[].transpose"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.to_tensor"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the ImageToTensor formating.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "results", "[", "key", "]", "=", "to_tensor", "(", "results", "[", "key", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.ImageToTensor.__repr__": [[140, 142], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f'{self.__class__.__name__}(keys={self.keys})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Transpose.__init__": [[153, 156], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keys", ",", "order", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "order", "=", "order", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Transpose.__call__": [[157, 167], ["results[].transpose"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the Transpose formatting.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "transpose", "(", "self", ".", "order", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Transpose.__repr__": [[168, 170], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "f'{self.__class__.__name__}('", "\n", "f'keys={self.keys}, order={self.order})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Collect.__init__": [[212, 222], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "keys", ",", "\n", "meta_keys", "=", "(", "'filename'", ",", "'label'", ",", "'original_shape'", ",", "'img_shape'", ",", "\n", "'pad_shape'", ",", "'flip_direction'", ",", "'img_norm_cfg'", ")", ",", "\n", "meta_name", "=", "'img_metas'", ",", "\n", "nested", "=", "False", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "meta_keys", "=", "meta_keys", "\n", "self", ".", "meta_name", "=", "meta_name", "\n", "self", ".", "nested", "=", "nested", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Collect.__call__": [[223, 244], ["len", "mmcv.parallel.DataContainer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the Collect formating.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "data", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "data", "[", "key", "]", "=", "results", "[", "key", "]", "\n", "\n", "", "if", "len", "(", "self", ".", "meta_keys", ")", "!=", "0", ":", "\n", "            ", "meta", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "meta_keys", ":", "\n", "                ", "meta", "[", "key", "]", "=", "results", "[", "key", "]", "\n", "", "data", "[", "self", ".", "meta_name", "]", "=", "DC", "(", "meta", ",", "cpu_only", "=", "True", ")", "\n", "", "if", "self", ".", "nested", ":", "\n", "            ", "for", "k", "in", "data", ":", "\n", "                ", "data", "[", "k", "]", "=", "[", "data", "[", "k", "]", "]", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.Collect.__repr__": [[245, 247], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "f'{self.__class__.__name__}('", "\n", "f'keys={self.keys}, meta_keys={self.meta_keys}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.FormatShape.__init__": [[265, 271], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_format", ",", "collapse", "=", "False", ")", ":", "\n", "        ", "self", ".", "input_format", "=", "input_format", "\n", "self", ".", "collapse", "=", "collapse", "\n", "if", "self", ".", "input_format", "not", "in", "[", "'NCTHW'", ",", "'NCHW'", ",", "'NCHW_Flow'", ",", "'NPTCHW'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'The input format {self.input_format} is invalid.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.FormatShape.__call__": [[272, 330], ["isinstance", "numpy.array", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "numpy.transpose.squeeze", "numpy.transpose", "numpy.transpose.reshape", "numpy.transpose", "numpy.transpose.reshape", "numpy.transpose.reshape", "numpy.transpose"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the FormatShape formating.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "results", "[", "'imgs'", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "results", "[", "'imgs'", "]", "=", "np", ".", "array", "(", "results", "[", "'imgs'", "]", ")", "\n", "", "imgs", "=", "results", "[", "'imgs'", "]", "\n", "# [M x H x W x C]", "\n", "# M = 1 * N_crops * N_clips * L", "\n", "if", "self", ".", "collapse", ":", "\n", "            ", "assert", "results", "[", "'num_clips'", "]", "==", "1", "\n", "\n", "", "if", "self", ".", "input_format", "==", "'NCTHW'", ":", "\n", "            ", "num_clips", "=", "results", "[", "'num_clips'", "]", "\n", "clip_len", "=", "results", "[", "'clip_len'", "]", "\n", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", "num_clips", ",", "clip_len", ")", "+", "imgs", ".", "shape", "[", "1", ":", "]", ")", "\n", "# N_crops x N_clips x L x H x W x C", "\n", "imgs", "=", "np", ".", "transpose", "(", "imgs", ",", "(", "0", ",", "1", ",", "5", ",", "2", ",", "3", ",", "4", ")", ")", "\n", "# N_crops x N_clips x C x L x H x W", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "# M' x C x L x H x W", "\n", "# M' = N_crops x N_clips", "\n", "", "elif", "self", ".", "input_format", "==", "'NCHW'", ":", "\n", "            ", "imgs", "=", "np", ".", "transpose", "(", "imgs", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "# M x C x H x W", "\n", "", "elif", "self", ".", "input_format", "==", "'NCHW_Flow'", ":", "\n", "            ", "num_clips", "=", "results", "[", "'num_clips'", "]", "\n", "clip_len", "=", "results", "[", "'clip_len'", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", "num_clips", ",", "clip_len", ")", "+", "imgs", ".", "shape", "[", "1", ":", "]", ")", "\n", "# N_crops x N_clips x L x H x W x C", "\n", "imgs", "=", "np", ".", "transpose", "(", "imgs", ",", "(", "0", ",", "1", ",", "2", ",", "5", ",", "3", ",", "4", ")", ")", "\n", "# N_crops x N_clips x L x C x H x W", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", "imgs", ".", "shape", "[", "2", "]", "*", "imgs", ".", "shape", "[", "3", "]", ")", "+", "\n", "imgs", ".", "shape", "[", "4", ":", "]", ")", "\n", "# M' x C' x H x W", "\n", "# M' = N_crops x N_clips", "\n", "# C' = L x C", "\n", "", "elif", "self", ".", "input_format", "==", "'NPTCHW'", ":", "\n", "            ", "num_proposals", "=", "results", "[", "'num_proposals'", "]", "\n", "num_clips", "=", "results", "[", "'num_clips'", "]", "\n", "clip_len", "=", "results", "[", "'clip_len'", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "num_proposals", ",", "num_clips", "*", "clip_len", ")", "+", "\n", "imgs", ".", "shape", "[", "1", ":", "]", ")", "\n", "# P x M x H x W x C", "\n", "# M = N_clips x L", "\n", "imgs", "=", "np", ".", "transpose", "(", "imgs", ",", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", "\n", "# P x M x C x H x W", "\n", "", "if", "self", ".", "collapse", ":", "\n", "            ", "assert", "imgs", ".", "shape", "[", "0", "]", "==", "1", "\n", "imgs", "=", "imgs", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "results", "[", "'input_shape'", "]", "=", "imgs", ".", "shape", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.FormatShape.__repr__": [[331, 335], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f\"(input_format='{self.input_format}')\"", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.FormatAudioShape.__init__": [[348, 353], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_format", ")", ":", "\n", "        ", "self", ".", "input_format", "=", "input_format", "\n", "if", "self", ".", "input_format", "not", "in", "[", "'NCTF'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'The input format {self.input_format} is invalid.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.FormatAudioShape.__call__": [[354, 368], ["audios.reshape.reshape.reshape"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the FormatShape formatting.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "audios", "=", "results", "[", "'audios'", "]", "\n", "# clip x sample x freq -> clip x channel x sample x freq", "\n", "clip", ",", "sample", ",", "freq", "=", "audios", ".", "shape", "\n", "audios", "=", "audios", ".", "reshape", "(", "clip", ",", "1", ",", "sample", ",", "freq", ")", "\n", "results", "[", "'audios'", "]", "=", "audios", "\n", "results", "[", "'input_shape'", "]", "=", "audios", ".", "shape", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.FormatAudioShape.__repr__": [[369, 373], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f\"(input_format='{self.input_format}')\"", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.formating.to_tensor": [[11, 28], ["isinstance", "isinstance", "isinstance", "isinstance", "TypeError", "torch.from_numpy", "isinstance", "torch.tensor", "torch.LongTensor", "torch.FloatTensor", "mmcv.is_str", "type"], "function", ["None"], ["def", "to_tensor", "(", "data", ")", ":", "\n", "    ", "\"\"\"Convert objects of various python types to :obj:`torch.Tensor`.\n\n    Supported types are: :class:`numpy.ndarray`, :class:`torch.Tensor`,\n    :class:`Sequence`, :class:`int` and :class:`float`.\n    \"\"\"", "\n", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "data", "\n", "", "if", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "torch", ".", "from_numpy", "(", "data", ")", "\n", "", "if", "isinstance", "(", "data", ",", "Sequence", ")", "and", "not", "mmcv", ".", "is_str", "(", "data", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "data", ")", "\n", "", "if", "isinstance", "(", "data", ",", "int", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "[", "data", "]", ")", "\n", "", "if", "isinstance", "(", "data", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "FloatTensor", "(", "[", "data", "]", ")", "\n", "", "raise", "TypeError", "(", "f'type {type(data)} cannot be converted to tensor.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.PoseCompact.__init__": [[83, 98], ["torch.nn.modules.utils._pair"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "padding", "=", "0.25", ",", "\n", "threshold", "=", "10", ",", "\n", "hw_ratio", "=", "None", ",", "\n", "allow_imgpad", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "padding", "=", "padding", "\n", "self", ".", "threshold", "=", "threshold", "\n", "if", "hw_ratio", "is", "not", "None", ":", "\n", "            ", "hw_ratio", "=", "_pair", "(", "hw_ratio", ")", "\n", "\n", "", "self", ".", "hw_ratio", "=", "hw_ratio", "\n", "\n", "self", ".", "allow_imgpad", "=", "allow_imgpad", "\n", "assert", "self", ".", "padding", ">=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.PoseCompact.__call__": [[99, 150], ["numpy.min", "numpy.min", "numpy.max", "numpy.max", "results.get", "augmentations._combine_quadruple", "max", "max", "numpy.isnan", "int", "int", "int", "int", "int", "int", "int", "int", "max", "max", "min", "min"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._combine_quadruple"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "img_shape", "=", "results", "[", "'img_shape'", "]", "\n", "h", ",", "w", "=", "img_shape", "\n", "kp", "=", "results", "[", "'keypoint'", "]", "\n", "\n", "# Make NaN zero", "\n", "kp", "[", "np", ".", "isnan", "(", "kp", ")", "]", "=", "0.", "\n", "kp_x", "=", "kp", "[", "...", ",", "0", "]", "\n", "kp_y", "=", "kp", "[", "...", ",", "1", "]", "\n", "\n", "min_x", "=", "np", ".", "min", "(", "kp_x", "[", "kp_x", "!=", "0", "]", ",", "initial", "=", "np", ".", "Inf", ")", "\n", "min_y", "=", "np", ".", "min", "(", "kp_y", "[", "kp_y", "!=", "0", "]", ",", "initial", "=", "np", ".", "Inf", ")", "\n", "max_x", "=", "np", ".", "max", "(", "kp_x", "[", "kp_x", "!=", "0", "]", ",", "initial", "=", "-", "np", ".", "Inf", ")", "\n", "max_y", "=", "np", ".", "max", "(", "kp_y", "[", "kp_y", "!=", "0", "]", ",", "initial", "=", "-", "np", ".", "Inf", ")", "\n", "\n", "# The compact area is too small", "\n", "if", "max_x", "-", "min_x", "<", "self", ".", "threshold", "or", "max_y", "-", "min_y", "<", "self", ".", "threshold", ":", "\n", "            ", "return", "results", "\n", "\n", "", "center", "=", "(", "(", "max_x", "+", "min_x", ")", "/", "2", ",", "(", "max_y", "+", "min_y", ")", "/", "2", ")", "\n", "half_width", "=", "(", "max_x", "-", "min_x", ")", "/", "2", "*", "(", "1", "+", "self", ".", "padding", ")", "\n", "half_height", "=", "(", "max_y", "-", "min_y", ")", "/", "2", "*", "(", "1", "+", "self", ".", "padding", ")", "\n", "\n", "if", "self", ".", "hw_ratio", "is", "not", "None", ":", "\n", "            ", "half_height", "=", "max", "(", "self", ".", "hw_ratio", "[", "0", "]", "*", "half_width", ",", "half_height", ")", "\n", "half_width", "=", "max", "(", "1", "/", "self", ".", "hw_ratio", "[", "1", "]", "*", "half_height", ",", "half_width", ")", "\n", "\n", "", "min_x", ",", "max_x", "=", "center", "[", "0", "]", "-", "half_width", ",", "center", "[", "0", "]", "+", "half_width", "\n", "min_y", ",", "max_y", "=", "center", "[", "1", "]", "-", "half_height", ",", "center", "[", "1", "]", "+", "half_height", "\n", "\n", "# hot update", "\n", "if", "not", "self", ".", "allow_imgpad", ":", "\n", "            ", "min_x", ",", "min_y", "=", "int", "(", "max", "(", "0", ",", "min_x", ")", ")", ",", "int", "(", "max", "(", "0", ",", "min_y", ")", ")", "\n", "max_x", ",", "max_y", "=", "int", "(", "min", "(", "w", ",", "max_x", ")", ")", ",", "int", "(", "min", "(", "h", ",", "max_y", ")", ")", "\n", "", "else", ":", "\n", "            ", "min_x", ",", "min_y", "=", "int", "(", "min_x", ")", ",", "int", "(", "min_y", ")", "\n", "max_x", ",", "max_y", "=", "int", "(", "max_x", ")", ",", "int", "(", "max_y", ")", "\n", "\n", "", "kp_x", "[", "kp_x", "!=", "0", "]", "-=", "min_x", "\n", "kp_y", "[", "kp_y", "!=", "0", "]", "-=", "min_y", "\n", "\n", "new_shape", "=", "(", "max_y", "-", "min_y", ",", "max_x", "-", "min_x", ")", "\n", "results", "[", "'img_shape'", "]", "=", "new_shape", "\n", "\n", "# the order is x, y, w, h (in [0, 1]), a tuple", "\n", "crop_quadruple", "=", "results", ".", "get", "(", "'crop_quadruple'", ",", "(", "0.", ",", "0.", ",", "1.", ",", "1.", ")", ")", "\n", "new_crop_quadruple", "=", "(", "min_x", "/", "w", ",", "min_y", "/", "h", ",", "(", "max_x", "-", "min_x", ")", "/", "w", ",", "\n", "(", "max_y", "-", "min_y", ")", "/", "h", ")", "\n", "crop_quadruple", "=", "_combine_quadruple", "(", "crop_quadruple", ",", "new_crop_quadruple", ")", "\n", "results", "[", "'crop_quadruple'", "]", "=", "crop_quadruple", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.PoseCompact.__repr__": [[151, 157], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}(padding={self.padding}, '", "\n", "f'threshold={self.threshold}, '", "\n", "f'hw_ratio={self.hw_ratio}, '", "\n", "f'allow_imgpad={self.allow_imgpad})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.EntityBoxRescale.__init__": [[161, 164], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scale_factor", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "'This component should not be used in the '", "\n", "'data pipeline and is removed in PR #782. Details see '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.EntityBoxCrop.__init__": [[171, 174], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "crop_bbox", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "'This component should not be used in the '", "\n", "'data pipeline and is removed in PR #782. Details see '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.EntityBoxFlip.__init__": [[181, 184], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "img_shape", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "'This component should not be used in the '", "\n", "'data pipeline and is removed in PR #782. Details see '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.__init__": [[261, 278], ["augmentations.Imgaug.default_transforms", "isinstance", "isinstance", "iaa.Sequential", "all", "isinstance", "ValueError", "augmentations.Imgaug.imgaug_builder", "isinstance"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.default_transforms", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.imgaug_builder"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "import", "imgaug", ".", "augmenters", "as", "iaa", "\n", "\n", "if", "transforms", "==", "'default'", ":", "\n", "            ", "self", ".", "transforms", "=", "self", ".", "default_transforms", "(", ")", "\n", "", "elif", "isinstance", "(", "transforms", ",", "list", ")", ":", "\n", "            ", "assert", "all", "(", "isinstance", "(", "trans", ",", "dict", ")", "for", "trans", "in", "transforms", ")", "\n", "self", ".", "transforms", "=", "transforms", "\n", "", "elif", "isinstance", "(", "transforms", ",", "iaa", ".", "Augmenter", ")", ":", "\n", "            ", "self", ".", "aug", "=", "self", ".", "transforms", "=", "transforms", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'transforms must be `default` or a list of dicts'", "\n", "' or iaa.Augmenter object'", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "transforms", ",", "iaa", ".", "Augmenter", ")", ":", "\n", "            ", "self", ".", "aug", "=", "iaa", ".", "Sequential", "(", "\n", "[", "self", ".", "imgaug_builder", "(", "t", ")", "for", "t", "in", "self", ".", "transforms", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.default_transforms": [[279, 334], ["dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "max", "random.choice", "random.choice", "random.choice", "random.choice", "random.choice", "int"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "default_transforms", "(", ")", ":", "\n", "        ", "\"\"\"Default transforms for imgaug.\n\n        Implement RandAugment by imgaug.\n        Plase visit `https://arxiv.org/abs/1909.13719` for more information.\n\n        Augmenters and hyper parameters are borrowed from the following repo:\n        https://github.com/tensorflow/tpu/blob/master/models/official/efficientnet/autoaugment.py # noqa\n\n        Miss one augmenter ``SolarizeAdd`` since imgaug doesn't support this.\n\n        Returns:\n            dict: The constructed RandAugment transforms.\n        \"\"\"", "\n", "# RandAugment hyper params", "\n", "num_augmenters", "=", "2", "\n", "cur_magnitude", ",", "max_magnitude", "=", "9", ",", "10", "\n", "cur_level", "=", "1.0", "*", "cur_magnitude", "/", "max_magnitude", "\n", "\n", "return", "[", "\n", "dict", "(", "\n", "type", "=", "'SomeOf'", ",", "\n", "n", "=", "num_augmenters", ",", "\n", "children", "=", "[", "\n", "dict", "(", "\n", "type", "=", "'ShearX'", ",", "\n", "shear", "=", "17.19", "*", "cur_level", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'ShearY'", ",", "\n", "shear", "=", "17.19", "*", "cur_level", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'TranslateX'", ",", "\n", "percent", "=", ".2", "*", "cur_level", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'TranslateY'", ",", "\n", "percent", "=", ".2", "*", "cur_level", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'Rotate'", ",", "\n", "rotate", "=", "30", "*", "cur_level", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "dict", "(", "type", "=", "'Posterize'", ",", "nb_bits", "=", "max", "(", "1", ",", "int", "(", "4", "*", "cur_level", ")", ")", ")", ",", "\n", "dict", "(", "type", "=", "'Solarize'", ",", "threshold", "=", "256", "*", "cur_level", ")", ",", "\n", "dict", "(", "type", "=", "'EnhanceColor'", ",", "factor", "=", "1.8", "*", "cur_level", "+", ".1", ")", ",", "\n", "dict", "(", "type", "=", "'EnhanceContrast'", ",", "factor", "=", "1.8", "*", "cur_level", "+", ".1", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'EnhanceBrightness'", ",", "factor", "=", "1.8", "*", "cur_level", "+", ".1", ")", ",", "\n", "dict", "(", "type", "=", "'EnhanceSharpness'", ",", "factor", "=", "1.8", "*", "cur_level", "+", ".1", ")", ",", "\n", "dict", "(", "type", "=", "'Autocontrast'", ",", "cutoff", "=", "0", ")", ",", "\n", "dict", "(", "type", "=", "'Equalize'", ")", ",", "\n", "dict", "(", "type", "=", "'Invert'", ",", "p", "=", "1.", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'Cutout'", ",", "\n", "nb_iterations", "=", "1", ",", "\n", "size", "=", "0.2", "*", "cur_level", ",", "\n", "squared", "=", "True", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.imgaug_builder": [[337, 370], ["cfg.copy", "cfg.copy.pop", "mmcv.is_str", "obj_cls", "isinstance", "issubclass", "hasattr", "getattr", "getattr", "TypeError", "augmentations.Imgaug.imgaug_builder", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.imgaug_builder"], ["", "def", "imgaug_builder", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"Import a module from imgaug.\n\n        It follows the logic of :func:`build_from_cfg`. Use a dict object to\n        create an iaa.Augmenter object.\n\n        Args:\n            cfg (dict): Config dict. It should at least contain the key \"type\".\n\n        Returns:\n            obj:`iaa.Augmenter`: The constructed imgaug augmenter.\n        \"\"\"", "\n", "import", "imgaug", ".", "augmenters", "as", "iaa", "\n", "\n", "assert", "isinstance", "(", "cfg", ",", "dict", ")", "and", "'type'", "in", "cfg", "\n", "args", "=", "cfg", ".", "copy", "(", ")", "\n", "\n", "obj_type", "=", "args", ".", "pop", "(", "'type'", ")", "\n", "if", "mmcv", ".", "is_str", "(", "obj_type", ")", ":", "\n", "            ", "obj_cls", "=", "getattr", "(", "iaa", ",", "obj_type", ")", "if", "hasattr", "(", "iaa", ",", "obj_type", ")", "else", "getattr", "(", "iaa", ".", "pillike", ",", "obj_type", ")", "\n", "", "elif", "issubclass", "(", "obj_type", ",", "iaa", ".", "Augmenter", ")", ":", "\n", "            ", "obj_cls", "=", "obj_type", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f'type must be a str or valid type, but got {type(obj_type)}'", ")", "\n", "\n", "", "if", "'children'", "in", "args", ":", "\n", "            ", "args", "[", "'children'", "]", "=", "[", "\n", "self", ".", "imgaug_builder", "(", "child", ")", "for", "child", "in", "args", "[", "'children'", "]", "\n", "]", "\n", "\n", "", "return", "obj_cls", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.__repr__": [[371, 374], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "+", "f'(transforms={self.aug})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Imgaug.__call__": [[375, 426], ["augmentations.Imgaug.aug.to_deterministic", "augmentations.Imgaug.augment_image", "bbs.BoundingBoxesOnImage", "augmentations.Imgaug.augment_bounding_boxes", "bbs.BoundingBox", "bbs.BoundingBoxesOnImage", "augmentations.Imgaug.augment_bounding_boxes", "max", "max", "min", "min", "bbs.BoundingBox", "max", "max", "min", "min"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "assert", "results", "[", "'modality'", "]", "==", "'RGB'", ",", "'Imgaug only support RGB images.'", "\n", "in_type", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "dtype", ".", "type", "\n", "\n", "cur_aug", "=", "self", ".", "aug", ".", "to_deterministic", "(", ")", "\n", "\n", "results", "[", "'imgs'", "]", "=", "[", "\n", "cur_aug", ".", "augment_image", "(", "frame", ")", "for", "frame", "in", "results", "[", "'imgs'", "]", "\n", "]", "\n", "img_h", ",", "img_w", ",", "_", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "\n", "\n", "out_type", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "dtype", ".", "type", "\n", "assert", "in_type", "==", "out_type", ",", "(", "'Imgaug input dtype and output dtype are not the same. '", ",", "\n", "f'Convert from {in_type} to {out_type}'", ")", "\n", "\n", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "from", "imgaug", ".", "augmentables", "import", "bbs", "\n", "bbox_list", "=", "[", "\n", "bbs", ".", "BoundingBox", "(", "\n", "x1", "=", "bbox", "[", "0", "]", ",", "y1", "=", "bbox", "[", "1", "]", ",", "x2", "=", "bbox", "[", "2", "]", ",", "y2", "=", "bbox", "[", "3", "]", ")", "\n", "for", "bbox", "in", "results", "[", "'gt_bboxes'", "]", "\n", "]", "\n", "bboxes", "=", "bbs", ".", "BoundingBoxesOnImage", "(", "\n", "bbox_list", ",", "shape", "=", "results", "[", "'img_shape'", "]", ")", "\n", "bbox_aug", ",", "*", "_", "=", "cur_aug", ".", "augment_bounding_boxes", "(", "[", "bboxes", "]", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "[", "[", "\n", "max", "(", "bbox", ".", "x1", ",", "0", ")", ",", "\n", "max", "(", "bbox", ".", "y1", ",", "0", ")", ",", "\n", "min", "(", "bbox", ".", "x2", ",", "img_w", ")", ",", "\n", "min", "(", "bbox", ".", "y2", ",", "img_h", ")", "\n", "]", "for", "bbox", "in", "bbox_aug", ".", "items", "]", "\n", "if", "'proposals'", "in", "results", ":", "\n", "                ", "bbox_list", "=", "[", "\n", "bbs", ".", "BoundingBox", "(", "\n", "x1", "=", "bbox", "[", "0", "]", ",", "y1", "=", "bbox", "[", "1", "]", ",", "x2", "=", "bbox", "[", "2", "]", ",", "y2", "=", "bbox", "[", "3", "]", ")", "\n", "for", "bbox", "in", "results", "[", "'proposals'", "]", "\n", "]", "\n", "bboxes", "=", "bbs", ".", "BoundingBoxesOnImage", "(", "\n", "bbox_list", ",", "shape", "=", "results", "[", "'img_shape'", "]", ")", "\n", "bbox_aug", ",", "*", "_", "=", "cur_aug", ".", "augment_bounding_boxes", "(", "[", "bboxes", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "[", "[", "\n", "max", "(", "bbox", ".", "x1", ",", "0", ")", ",", "\n", "max", "(", "bbox", ".", "y1", ",", "0", ")", ",", "\n", "min", "(", "bbox", ".", "x2", ",", "img_w", ")", ",", "\n", "min", "(", "bbox", ".", "y2", ",", "img_h", ")", "\n", "]", "for", "bbox", "in", "bbox_aug", ".", "items", "]", "\n", "\n", "", "", "results", "[", "'img_shape'", "]", "=", "(", "img_h", ",", "img_w", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomErasing.__init__": [[429, 431], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "device", "=", "'cpu'", ",", "**", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "device", "=", "device", ",", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomErasing.__call__": [[432, 461], ["random.getstate", "torch.get_rng_state", "numpy.random.get_state", "random.setstate", "torch.set_rng_state", "numpy.random.set_state", "super().__call__().permute().numpy", "out_frame.append", "NotImplementedError", "super().__call__().permute", "super().__call__", "torch.from_numpy().permute", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.compose.Compose.__call__"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "in_type", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "dtype", ".", "type", "\n", "\n", "rand_state", "=", "random", ".", "getstate", "(", ")", "\n", "torchrand_state", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "numpyrand_state", "=", "np", ".", "random", ".", "get_state", "(", ")", "\n", "# not using cuda to preserve the determiness", "\n", "\n", "out_frame", "=", "[", "]", "\n", "for", "frame", "in", "results", "[", "'imgs'", "]", ":", "\n", "            ", "random", ".", "setstate", "(", "rand_state", ")", "\n", "torch", ".", "set_rng_state", "(", "torchrand_state", ")", "\n", "np", ".", "random", ".", "set_state", "(", "numpyrand_state", ")", "\n", "frame", "=", "super", "(", ")", ".", "__call__", "(", "torch", ".", "from_numpy", "(", "frame", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "numpy", "(", ")", "\n", "out_frame", ".", "append", "(", "frame", ")", "\n", "\n", "", "results", "[", "'imgs'", "]", "=", "out_frame", "\n", "img_h", ",", "img_w", ",", "_", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "\n", "\n", "out_type", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "dtype", ".", "type", "\n", "assert", "in_type", "==", "out_type", ",", "(", "'Timmaug input dtype and output dtype are not the same. '", ",", "\n", "f'Convert from {in_type} to {out_type}'", ")", "\n", "\n", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'only support recognition now'", ")", "\n", "", "assert", "results", "[", "'img_shape'", "]", "==", "(", "img_h", ",", "img_w", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Fuse.__call__": [[475, 505], ["lazyop[].round().astype", "ValueError", "mmcv.imresize", "lazyop[].round", "mmcv.imflip_"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "if", "'lazy'", "not", "in", "results", ":", "\n", "            ", "raise", "ValueError", "(", "'No lazy operation detected'", ")", "\n", "", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "imgs", "=", "results", "[", "'imgs'", "]", "\n", "\n", "# crop", "\n", "left", ",", "top", ",", "right", ",", "bottom", "=", "lazyop", "[", "'crop_bbox'", "]", ".", "round", "(", ")", ".", "astype", "(", "int", ")", "\n", "imgs", "=", "[", "img", "[", "top", ":", "bottom", ",", "left", ":", "right", "]", "for", "img", "in", "imgs", "]", "\n", "\n", "# resize", "\n", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "if", "lazyop", "[", "'interpolation'", "]", "is", "None", ":", "\n", "            ", "interpolation", "=", "'bilinear'", "\n", "", "else", ":", "\n", "            ", "interpolation", "=", "lazyop", "[", "'interpolation'", "]", "\n", "", "imgs", "=", "[", "\n", "mmcv", ".", "imresize", "(", "img", ",", "(", "img_w", ",", "img_h", ")", ",", "interpolation", "=", "interpolation", ")", "\n", "for", "img", "in", "imgs", "\n", "]", "\n", "\n", "# flip", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "            ", "for", "img", "in", "imgs", ":", "\n", "                ", "mmcv", ".", "imflip_", "(", "img", ",", "lazyop", "[", "'flip_direction'", "]", ")", "\n", "\n", "", "", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "del", "results", "[", "'lazy'", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomScale.__init__": [[526, 535], ["warnings.warn", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "scales", ",", "mode", "=", "'range'", ",", "**", "kwargs", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "'\"RandomScale\" is deprecated and will be removed in '", "\n", "'later versions. It is currently not used in MMAction2'", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "if", "self", ".", "mode", "not", "in", "[", "'range'", ",", "'value'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"mode should be 'range' or 'value', \"", "\n", "f'but got {self.mode}'", ")", "\n", "", "self", ".", "scales", "=", "scales", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomScale.select_scale": [[536, 561], ["len", "random.choice", "numpy.random.randint", "numpy.random.randint", "ValueError", "max", "min", "min", "min", "random.choice", "max", "max"], "methods", ["None"], ["", "def", "select_scale", "(", "self", ",", "scales", ")", ":", "\n", "        ", "num_scales", "=", "len", "(", "scales", ")", "\n", "if", "num_scales", "==", "1", ":", "\n", "# specify a fixed scale", "\n", "            ", "scale", "=", "scales", "[", "0", "]", "\n", "", "elif", "num_scales", "==", "2", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'range'", ":", "\n", "                ", "scale_long", "=", "[", "max", "(", "s", ")", "for", "s", "in", "scales", "]", "\n", "scale_short", "=", "[", "min", "(", "s", ")", "for", "s", "in", "scales", "]", "\n", "long_edge", "=", "np", ".", "random", ".", "randint", "(", "\n", "min", "(", "scale_long", ")", ",", "\n", "max", "(", "scale_long", ")", "+", "1", ")", "\n", "short_edge", "=", "np", ".", "random", ".", "randint", "(", "\n", "min", "(", "scale_short", ")", ",", "\n", "max", "(", "scale_short", ")", "+", "1", ")", "\n", "scale", "=", "(", "long_edge", ",", "short_edge", ")", "\n", "", "elif", "self", ".", "mode", "==", "'value'", ":", "\n", "                ", "scale", "=", "random", ".", "choice", "(", "scales", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "mode", "!=", "'value'", ":", "\n", "                ", "raise", "ValueError", "(", "\"Only 'value' mode supports more than \"", "\n", "'2 image scales'", ")", "\n", "", "scale", "=", "random", ".", "choice", "(", "scales", ")", "\n", "\n", "", "return", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomScale.__call__": [[562, 568], ["augmentations.RandomScale.select_scale", "augmentations.Resize", "Resize."], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomScale.select_scale"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "scale", "=", "self", ".", "select_scale", "(", "self", ".", "scales", ")", "\n", "results", "[", "'scale'", "]", "=", "scale", "\n", "resize", "=", "Resize", "(", "scale", ",", "**", "self", ".", "kwargs", ")", "\n", "results", "=", "resize", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomScale.__repr__": [[569, 573], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'scales={self.scales}, mode={self.mode})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop.__init__": [[589, 594], ["isinstance", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "lazy", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Size must be an int, but got {type(size)}'", ")", "\n", "", "self", ".", "size", "=", "size", "\n", "self", ".", "lazy", "=", "lazy", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_kps": [[595, 598], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_crop_kps", "(", "kps", ",", "crop_bbox", ")", ":", "\n", "        ", "return", "kps", "-", "crop_bbox", "[", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_imgs": [[599, 603], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_crop_imgs", "(", "imgs", ",", "crop_bbox", ")", ":", "\n", "        ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "crop_bbox", "\n", "return", "[", "img", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "for", "img", "in", "imgs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._box_crop": [[604, 620], ["box.copy", "numpy.clip", "numpy.clip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_box_crop", "(", "box", ",", "crop_bbox", ")", ":", "\n", "        ", "\"\"\"Crop the bounding boxes according to the crop_bbox.\n\n        Args:\n            box (np.ndarray): The bounding boxes.\n            crop_bbox(np.ndarray): The bbox used to crop the original image.\n        \"\"\"", "\n", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "crop_bbox", "\n", "img_w", ",", "img_h", "=", "x2", "-", "x1", ",", "y2", "-", "y1", "\n", "\n", "box_", "=", "box", ".", "copy", "(", ")", "\n", "box_", "[", "...", ",", "0", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "box", "[", "...", ",", "0", ":", ":", "2", "]", "-", "x1", ",", "0", ",", "img_w", "-", "1", ")", "\n", "box_", "[", "...", ",", "1", ":", ":", "2", "]", "=", "np", ".", "clip", "(", "box", "[", "...", ",", "1", ":", ":", "2", "]", "-", "y1", ",", "0", ",", "img_h", "-", "1", ")", "\n", "return", "box_", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._all_box_crop": [[621, 635], ["augmentations.RandomCrop._box_crop", "augmentations.RandomCrop._box_crop"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._box_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._box_crop"], ["", "def", "_all_box_crop", "(", "self", ",", "results", ",", "crop_bbox", ")", ":", "\n", "        ", "\"\"\"Crop the gt_bboxes and proposals in results according to crop_bbox.\n\n        Args:\n            results (dict): All information about the sample, which contain\n                'gt_bboxes' and 'proposals' (optional).\n            crop_bbox(np.ndarray): The bbox used to crop the original image.\n        \"\"\"", "\n", "results", "[", "'gt_bboxes'", "]", "=", "self", ".", "_box_crop", "(", "results", "[", "'gt_bboxes'", "]", ",", "crop_bbox", ")", "\n", "if", "'proposals'", "in", "results", "and", "results", "[", "'proposals'", "]", "is", "not", "None", ":", "\n", "            ", "assert", "results", "[", "'proposals'", "]", ".", "shape", "[", "1", "]", "==", "4", "\n", "results", "[", "'proposals'", "]", "=", "self", ".", "_box_crop", "(", "results", "[", "'proposals'", "]", ",", "\n", "crop_bbox", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop.__call__": [[636, 714], ["augmentations._init_lazy_if_proper", "numpy.array", "numpy.array", "int", "int", "numpy.array", "numpy.array", "augmentations.RandomCrop._all_box_crop", "numpy.random.randint", "numpy.random.randint", "augmentations.RandomCrop._crop_kps", "augmentations.RandomCrop._crop_imgs", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._all_box_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_kps", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_imgs"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the RandomCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "self", ".", "lazy", ")", "\n", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", ",", "(", "'Keypoint Augmentations are not compatible '", "\n", "'with lazy == True'", ")", "\n", "\n", "", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "assert", "self", ".", "size", "<=", "img_h", "and", "self", ".", "size", "<=", "img_w", "\n", "\n", "y_offset", "=", "0", "\n", "x_offset", "=", "0", "\n", "if", "img_h", ">", "self", ".", "size", ":", "\n", "            ", "y_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "img_h", "-", "self", ".", "size", ")", ")", "\n", "", "if", "img_w", ">", "self", ".", "size", ":", "\n", "            ", "x_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "img_w", "-", "self", ".", "size", ")", ")", "\n", "\n", "", "if", "'crop_quadruple'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "[", "0", ",", "0", ",", "1", ",", "1", "]", ",", "# x, y, w, h", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "x_ratio", ",", "y_ratio", "=", "x_offset", "/", "img_w", ",", "y_offset", "/", "img_h", "\n", "w_ratio", ",", "h_ratio", "=", "self", ".", "size", "/", "img_w", ",", "self", ".", "size", "/", "img_h", "\n", "\n", "old_crop_quadruple", "=", "results", "[", "'crop_quadruple'", "]", "\n", "old_x_ratio", ",", "old_y_ratio", "=", "old_crop_quadruple", "[", "0", "]", ",", "old_crop_quadruple", "[", "1", "]", "\n", "old_w_ratio", ",", "old_h_ratio", "=", "old_crop_quadruple", "[", "2", "]", ",", "old_crop_quadruple", "[", "3", "]", "\n", "new_crop_quadruple", "=", "[", "\n", "old_x_ratio", "+", "x_ratio", "*", "old_w_ratio", ",", "\n", "old_y_ratio", "+", "y_ratio", "*", "old_h_ratio", ",", "w_ratio", "*", "old_w_ratio", ",", "\n", "h_ratio", "*", "old_x_ratio", "\n", "]", "\n", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "new_crop_quadruple", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "new_h", ",", "new_w", "=", "self", ".", "size", ",", "self", ".", "size", "\n", "\n", "crop_bbox", "=", "np", ".", "array", "(", "\n", "[", "x_offset", ",", "y_offset", ",", "x_offset", "+", "new_w", ",", "y_offset", "+", "new_h", "]", ")", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bbox", "\n", "\n", "results", "[", "'img_shape'", "]", "=", "(", "new_h", ",", "new_w", ")", "\n", "\n", "if", "not", "self", ".", "lazy", ":", "\n", "            ", "if", "'keypoint'", "in", "results", ":", "\n", "                ", "results", "[", "'keypoint'", "]", "=", "self", ".", "_crop_kps", "(", "results", "[", "'keypoint'", "]", ",", "\n", "crop_bbox", ")", "\n", "", "if", "'imgs'", "in", "results", ":", "\n", "                ", "results", "[", "'imgs'", "]", "=", "self", ".", "_crop_imgs", "(", "results", "[", "'imgs'", "]", ",", "crop_bbox", ")", "\n", "", "", "else", ":", "\n", "            ", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Put Flip at last for now'", ")", "\n", "\n", "# record crop_bbox in lazyop dict to ensure only crop once in Fuse", "\n", "", "lazy_left", ",", "lazy_top", ",", "lazy_right", ",", "lazy_bottom", "=", "lazyop", "[", "'crop_bbox'", "]", "\n", "left", "=", "x_offset", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "right", "=", "(", "x_offset", "+", "new_w", ")", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "top", "=", "y_offset", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "bottom", "=", "(", "y_offset", "+", "new_h", ")", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "lazyop", "[", "'crop_bbox'", "]", "=", "np", ".", "array", "(", "[", "(", "lazy_left", "+", "left", ")", ",", "\n", "(", "lazy_top", "+", "top", ")", ",", "\n", "(", "lazy_left", "+", "right", ")", ",", "\n", "(", "lazy_top", "+", "bottom", ")", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# Process entity boxes", "\n", "", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", "\n", "results", "=", "self", ".", "_all_box_crop", "(", "results", ",", "results", "[", "'crop_bbox'", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop.__repr__": [[715, 719], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}(size={self.size}, '", "\n", "f'lazy={self.lazy})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomResizedCrop.__init__": [[738, 750], ["mmcv.is_tuple_of", "TypeError", "mmcv.is_tuple_of", "TypeError", "type", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "area_range", "=", "(", "0.08", ",", "1.0", ")", ",", "\n", "aspect_ratio_range", "=", "(", "3", "/", "4", ",", "4", "/", "3", ")", ",", "\n", "lazy", "=", "False", ")", ":", "\n", "        ", "self", ".", "area_range", "=", "area_range", "\n", "self", ".", "aspect_ratio_range", "=", "aspect_ratio_range", "\n", "self", ".", "lazy", "=", "lazy", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "area_range", ",", "float", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Area_range must be a tuple of float, '", "\n", "f'but got {type(area_range)}'", ")", "\n", "", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "aspect_ratio_range", ",", "float", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Aspect_ratio_range must be a tuple of float, '", "\n", "f'but got {type(aspect_ratio_range)}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomResizedCrop.get_crop_bbox": [[752, 802], ["numpy.exp", "numpy.round().astype", "numpy.round().astype", "range", "min", "numpy.random.uniform", "numpy.random.uniform", "numpy.log", "numpy.log", "numpy.round", "numpy.round", "random.randint", "random.randint", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "get_crop_bbox", "(", "img_shape", ",", "\n", "area_range", ",", "\n", "aspect_ratio_range", ",", "\n", "max_attempts", "=", "10", ")", ":", "\n", "        ", "\"\"\"Get a crop bbox given the area range and aspect ratio range.\n\n        Args:\n            img_shape (Tuple[int]): Image shape\n            area_range (Tuple[float]): The candidate area scales range of\n                output cropped images. Default: (0.08, 1.0).\n            aspect_ratio_range (Tuple[float]): The candidate aspect\n                ratio range of output cropped images. Default: (3 / 4, 4 / 3).\n                max_attempts (int): The maximum of attempts. Default: 10.\n            max_attempts (int): Max attempts times to generate random candidate\n                bounding box. If it doesn't qualified one, the center bounding\n                box will be used.\n        Returns:\n            (list[int]) A random crop bbox within the area range and aspect\n            ratio range.\n        \"\"\"", "\n", "assert", "0", "<", "area_range", "[", "0", "]", "<=", "area_range", "[", "1", "]", "<=", "1", "\n", "assert", "0", "<", "aspect_ratio_range", "[", "0", "]", "<=", "aspect_ratio_range", "[", "1", "]", "\n", "\n", "img_h", ",", "img_w", "=", "img_shape", "\n", "area", "=", "img_h", "*", "img_w", "\n", "\n", "min_ar", ",", "max_ar", "=", "aspect_ratio_range", "\n", "aspect_ratios", "=", "np", ".", "exp", "(", "\n", "np", ".", "random", ".", "uniform", "(", "\n", "np", ".", "log", "(", "min_ar", ")", ",", "np", ".", "log", "(", "max_ar", ")", ",", "size", "=", "max_attempts", ")", ")", "\n", "target_areas", "=", "np", ".", "random", ".", "uniform", "(", "*", "area_range", ",", "size", "=", "max_attempts", ")", "*", "area", "\n", "candidate_crop_w", "=", "np", ".", "round", "(", "np", ".", "sqrt", "(", "target_areas", "*", "\n", "aspect_ratios", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "candidate_crop_h", "=", "np", ".", "round", "(", "np", ".", "sqrt", "(", "target_areas", "/", "\n", "aspect_ratios", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_attempts", ")", ":", "\n", "            ", "crop_w", "=", "candidate_crop_w", "[", "i", "]", "\n", "crop_h", "=", "candidate_crop_h", "[", "i", "]", "\n", "if", "crop_h", "<=", "img_h", "and", "crop_w", "<=", "img_w", ":", "\n", "                ", "x_offset", "=", "random", ".", "randint", "(", "0", ",", "img_w", "-", "crop_w", ")", "\n", "y_offset", "=", "random", ".", "randint", "(", "0", ",", "img_h", "-", "crop_h", ")", "\n", "return", "x_offset", ",", "y_offset", ",", "x_offset", "+", "crop_w", ",", "y_offset", "+", "crop_h", "\n", "\n", "# Fallback", "\n", "", "", "crop_size", "=", "min", "(", "img_h", ",", "img_w", ")", "\n", "x_offset", "=", "(", "img_w", "-", "crop_size", ")", "//", "2", "\n", "y_offset", "=", "(", "img_h", "-", "crop_size", ")", "//", "2", "\n", "return", "x_offset", ",", "y_offset", ",", "x_offset", "+", "crop_size", ",", "y_offset", "+", "crop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomResizedCrop.__call__": [[803, 872], ["augmentations._init_lazy_if_proper", "augmentations.RandomResizedCrop.get_crop_bbox", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "augmentations.RandomResizedCrop._all_box_crop", "augmentations.RandomResizedCrop._crop_kps", "augmentations.RandomResizedCrop._crop_imgs", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomResizedCrop.get_crop_bbox", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._all_box_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_kps", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_imgs"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the RandomResizeCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "self", ".", "lazy", ")", "\n", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", ",", "(", "'Keypoint Augmentations are not compatible '", "\n", "'with lazy == True'", ")", "\n", "\n", "", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "\n", "left", ",", "top", ",", "right", ",", "bottom", "=", "self", ".", "get_crop_bbox", "(", "\n", "(", "img_h", ",", "img_w", ")", ",", "self", ".", "area_range", ",", "self", ".", "aspect_ratio_range", ")", "\n", "new_h", ",", "new_w", "=", "bottom", "-", "top", ",", "right", "-", "left", "\n", "\n", "if", "'crop_quadruple'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "[", "0", ",", "0", ",", "1", ",", "1", "]", ",", "# x, y, w, h", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "x_ratio", ",", "y_ratio", "=", "left", "/", "img_w", ",", "top", "/", "img_h", "\n", "w_ratio", ",", "h_ratio", "=", "new_w", "/", "img_w", ",", "new_h", "/", "img_h", "\n", "\n", "old_crop_quadruple", "=", "results", "[", "'crop_quadruple'", "]", "\n", "old_x_ratio", ",", "old_y_ratio", "=", "old_crop_quadruple", "[", "0", "]", ",", "old_crop_quadruple", "[", "1", "]", "\n", "old_w_ratio", ",", "old_h_ratio", "=", "old_crop_quadruple", "[", "2", "]", ",", "old_crop_quadruple", "[", "3", "]", "\n", "new_crop_quadruple", "=", "[", "\n", "old_x_ratio", "+", "x_ratio", "*", "old_w_ratio", ",", "\n", "old_y_ratio", "+", "y_ratio", "*", "old_h_ratio", ",", "w_ratio", "*", "old_w_ratio", ",", "\n", "h_ratio", "*", "old_x_ratio", "\n", "]", "\n", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "new_crop_quadruple", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "crop_bbox", "=", "np", ".", "array", "(", "[", "left", ",", "top", ",", "right", ",", "bottom", "]", ")", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bbox", "\n", "results", "[", "'img_shape'", "]", "=", "(", "new_h", ",", "new_w", ")", "\n", "\n", "if", "not", "self", ".", "lazy", ":", "\n", "            ", "if", "'keypoint'", "in", "results", ":", "\n", "                ", "results", "[", "'keypoint'", "]", "=", "self", ".", "_crop_kps", "(", "results", "[", "'keypoint'", "]", ",", "\n", "crop_bbox", ")", "\n", "", "if", "'imgs'", "in", "results", ":", "\n", "                ", "results", "[", "'imgs'", "]", "=", "self", ".", "_crop_imgs", "(", "results", "[", "'imgs'", "]", ",", "crop_bbox", ")", "\n", "", "", "else", ":", "\n", "            ", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Put Flip at last for now'", ")", "\n", "\n", "# record crop_bbox in lazyop dict to ensure only crop once in Fuse", "\n", "", "lazy_left", ",", "lazy_top", ",", "lazy_right", ",", "lazy_bottom", "=", "lazyop", "[", "'crop_bbox'", "]", "\n", "left", "=", "left", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "right", "=", "right", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "top", "=", "top", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "bottom", "=", "bottom", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "lazyop", "[", "'crop_bbox'", "]", "=", "np", ".", "array", "(", "[", "(", "lazy_left", "+", "left", ")", ",", "\n", "(", "lazy_top", "+", "top", ")", ",", "\n", "(", "lazy_left", "+", "right", ")", ",", "\n", "(", "lazy_top", "+", "bottom", ")", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", "\n", "results", "=", "self", ".", "_all_box_crop", "(", "results", ",", "results", "[", "'crop_bbox'", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomResizedCrop.__repr__": [[873, 879], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'area_range={self.area_range}, '", "\n", "f'aspect_ratio_range={self.aspect_ratio_range}, '", "\n", "f'lazy={self.lazy})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MultiScaleCrop.__init__": [[913, 937], ["torch.nn.modules.utils._pair", "mmcv.is_tuple_of", "TypeError", "isinstance", "TypeError", "ValueError", "type", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_size", ",", "\n", "scales", "=", "(", "1", ",", ")", ",", "\n", "max_wh_scale_gap", "=", "1", ",", "\n", "random_crop", "=", "False", ",", "\n", "num_fixed_crops", "=", "5", ",", "\n", "lazy", "=", "False", ")", ":", "\n", "        ", "self", ".", "input_size", "=", "_pair", "(", "input_size", ")", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "input_size", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Input_size must be int or tuple of int, '", "\n", "f'but got {type(input_size)}'", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "scales", ",", "tuple", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Scales must be tuple, but got {type(scales)}'", ")", "\n", "\n", "", "if", "num_fixed_crops", "not", "in", "[", "5", ",", "13", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Num_fix_crops must be in {[5, 13]}, '", "\n", "f'but got {num_fixed_crops}'", ")", "\n", "\n", "", "self", ".", "scales", "=", "scales", "\n", "self", ".", "max_wh_scale_gap", "=", "max_wh_scale_gap", "\n", "self", ".", "random_crop", "=", "random_crop", "\n", "self", ".", "num_fixed_crops", "=", "num_fixed_crops", "\n", "self", ".", "lazy", "=", "lazy", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MultiScaleCrop.__call__": [[938, 1049], ["augmentations._init_lazy_if_proper", "min", "enumerate", "random.choice", "range", "numpy.array", "numpy.array", "int", "enumerate", "random.randint", "random.randint", "random.choice", "numpy.array", "numpy.array", "augmentations.MultiScaleCrop._all_box_crop", "abs", "candidate_offsets.extend", "augmentations.MultiScaleCrop._crop_kps", "augmentations.MultiScaleCrop._crop_imgs", "NotImplementedError", "abs", "candidate_sizes.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._all_box_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_kps", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_imgs"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the MultiScaleCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "self", ".", "lazy", ")", "\n", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", ",", "(", "'Keypoint Augmentations are not compatible '", "\n", "'with lazy == True'", ")", "\n", "\n", "", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "base_size", "=", "min", "(", "img_h", ",", "img_w", ")", "\n", "crop_sizes", "=", "[", "int", "(", "base_size", "*", "s", ")", "for", "s", "in", "self", ".", "scales", "]", "\n", "\n", "candidate_sizes", "=", "[", "]", "\n", "for", "i", ",", "h", "in", "enumerate", "(", "crop_sizes", ")", ":", "\n", "            ", "for", "j", ",", "w", "in", "enumerate", "(", "crop_sizes", ")", ":", "\n", "                ", "if", "abs", "(", "i", "-", "j", ")", "<=", "self", ".", "max_wh_scale_gap", ":", "\n", "                    ", "candidate_sizes", ".", "append", "(", "[", "w", ",", "h", "]", ")", "\n", "\n", "", "", "", "crop_size", "=", "random", ".", "choice", "(", "candidate_sizes", ")", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "if", "abs", "(", "crop_size", "[", "i", "]", "-", "self", ".", "input_size", "[", "i", "]", ")", "<", "3", ":", "\n", "                ", "crop_size", "[", "i", "]", "=", "self", ".", "input_size", "[", "i", "]", "\n", "\n", "", "", "crop_w", ",", "crop_h", "=", "crop_size", "\n", "\n", "if", "self", ".", "random_crop", ":", "\n", "            ", "x_offset", "=", "random", ".", "randint", "(", "0", ",", "img_w", "-", "crop_w", ")", "\n", "y_offset", "=", "random", ".", "randint", "(", "0", ",", "img_h", "-", "crop_h", ")", "\n", "", "else", ":", "\n", "            ", "w_step", "=", "(", "img_w", "-", "crop_w", ")", "//", "4", "\n", "h_step", "=", "(", "img_h", "-", "crop_h", ")", "//", "4", "\n", "candidate_offsets", "=", "[", "\n", "(", "0", ",", "0", ")", ",", "# upper left", "\n", "(", "4", "*", "w_step", ",", "0", ")", ",", "# upper right", "\n", "(", "0", ",", "4", "*", "h_step", ")", ",", "# lower left", "\n", "(", "4", "*", "w_step", ",", "4", "*", "h_step", ")", ",", "# lower right", "\n", "(", "2", "*", "w_step", ",", "2", "*", "h_step", ")", ",", "# center", "\n", "]", "\n", "if", "self", ".", "num_fixed_crops", "==", "13", ":", "\n", "                ", "extra_candidate_offsets", "=", "[", "\n", "(", "0", ",", "2", "*", "h_step", ")", ",", "# center left", "\n", "(", "4", "*", "w_step", ",", "2", "*", "h_step", ")", ",", "# center right", "\n", "(", "2", "*", "w_step", ",", "4", "*", "h_step", ")", ",", "# lower center", "\n", "(", "2", "*", "w_step", ",", "0", "*", "h_step", ")", ",", "# upper center", "\n", "(", "1", "*", "w_step", ",", "1", "*", "h_step", ")", ",", "# upper left quarter", "\n", "(", "3", "*", "w_step", ",", "1", "*", "h_step", ")", ",", "# upper right quarter", "\n", "(", "1", "*", "w_step", ",", "3", "*", "h_step", ")", ",", "# lower left quarter", "\n", "(", "3", "*", "w_step", ",", "3", "*", "h_step", ")", "# lower right quarter", "\n", "]", "\n", "candidate_offsets", ".", "extend", "(", "extra_candidate_offsets", ")", "\n", "", "x_offset", ",", "y_offset", "=", "random", ".", "choice", "(", "candidate_offsets", ")", "\n", "\n", "", "new_h", ",", "new_w", "=", "crop_h", ",", "crop_w", "\n", "\n", "crop_bbox", "=", "np", ".", "array", "(", "\n", "[", "x_offset", ",", "y_offset", ",", "x_offset", "+", "new_w", ",", "y_offset", "+", "new_h", "]", ")", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bbox", "\n", "results", "[", "'img_shape'", "]", "=", "(", "new_h", ",", "new_w", ")", "\n", "results", "[", "'scales'", "]", "=", "self", ".", "scales", "\n", "\n", "if", "'crop_quadruple'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "[", "0", ",", "0", ",", "1", ",", "1", "]", ",", "# x, y, w, h", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "x_ratio", ",", "y_ratio", "=", "x_offset", "/", "img_w", ",", "y_offset", "/", "img_h", "\n", "w_ratio", ",", "h_ratio", "=", "new_w", "/", "img_w", ",", "new_h", "/", "img_h", "\n", "\n", "old_crop_quadruple", "=", "results", "[", "'crop_quadruple'", "]", "\n", "old_x_ratio", ",", "old_y_ratio", "=", "old_crop_quadruple", "[", "0", "]", ",", "old_crop_quadruple", "[", "1", "]", "\n", "old_w_ratio", ",", "old_h_ratio", "=", "old_crop_quadruple", "[", "2", "]", ",", "old_crop_quadruple", "[", "3", "]", "\n", "new_crop_quadruple", "=", "[", "\n", "old_x_ratio", "+", "x_ratio", "*", "old_w_ratio", ",", "\n", "old_y_ratio", "+", "y_ratio", "*", "old_h_ratio", ",", "w_ratio", "*", "old_w_ratio", ",", "\n", "h_ratio", "*", "old_x_ratio", "\n", "]", "\n", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "new_crop_quadruple", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "if", "not", "self", ".", "lazy", ":", "\n", "            ", "if", "'keypoint'", "in", "results", ":", "\n", "                ", "results", "[", "'keypoint'", "]", "=", "self", ".", "_crop_kps", "(", "results", "[", "'keypoint'", "]", ",", "\n", "crop_bbox", ")", "\n", "", "if", "'imgs'", "in", "results", ":", "\n", "                ", "results", "[", "'imgs'", "]", "=", "self", ".", "_crop_imgs", "(", "results", "[", "'imgs'", "]", ",", "crop_bbox", ")", "\n", "", "", "else", ":", "\n", "            ", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Put Flip at last for now'", ")", "\n", "\n", "# record crop_bbox in lazyop dict to ensure only crop once in Fuse", "\n", "", "lazy_left", ",", "lazy_top", ",", "lazy_right", ",", "lazy_bottom", "=", "lazyop", "[", "'crop_bbox'", "]", "\n", "left", "=", "x_offset", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "right", "=", "(", "x_offset", "+", "new_w", ")", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "top", "=", "y_offset", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "bottom", "=", "(", "y_offset", "+", "new_h", ")", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "lazyop", "[", "'crop_bbox'", "]", "=", "np", ".", "array", "(", "[", "(", "lazy_left", "+", "left", ")", ",", "\n", "(", "lazy_top", "+", "top", ")", ",", "\n", "(", "lazy_left", "+", "right", ")", ",", "\n", "(", "lazy_top", "+", "bottom", ")", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", "\n", "results", "=", "self", ".", "_all_box_crop", "(", "results", ",", "results", "[", "'crop_bbox'", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MultiScaleCrop.__repr__": [[1050, 1058], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'input_size={self.input_size}, scales={self.scales}, '", "\n", "f'max_wh_scale_gap={self.max_wh_scale_gap}, '", "\n", "f'random_crop={self.random_crop}, '", "\n", "f'num_fixed_crops={self.num_fixed_crops}, '", "\n", "f'lazy={self.lazy})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize.__init__": [[1084, 1105], ["isinstance", "isinstance", "ValueError", "max", "min", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "scale", ",", "\n", "keep_ratio", "=", "True", ",", "\n", "interpolation", "=", "'bilinear'", ",", "\n", "lazy", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "scale", ",", "float", ")", ":", "\n", "            ", "if", "scale", "<=", "0", ":", "\n", "                ", "raise", "ValueError", "(", "f'Invalid scale {scale}, must be positive.'", ")", "\n", "", "", "elif", "isinstance", "(", "scale", ",", "tuple", ")", ":", "\n", "            ", "max_long_edge", "=", "max", "(", "scale", ")", "\n", "max_short_edge", "=", "min", "(", "scale", ")", "\n", "if", "max_short_edge", "==", "-", "1", ":", "\n", "# assign np.inf to long edge for rescaling short edge later.", "\n", "                ", "scale", "=", "(", "np", ".", "inf", ",", "max_long_edge", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f'Scale must be float or tuple of int, but got {type(scale)}'", ")", "\n", "", "self", ".", "scale", "=", "scale", "\n", "self", ".", "keep_ratio", "=", "keep_ratio", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "self", ".", "lazy", "=", "lazy", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._resize_imgs": [[1106, 1111], ["mmcv.imresize"], "methods", ["None"], ["", "def", "_resize_imgs", "(", "self", ",", "imgs", ",", "new_w", ",", "new_h", ")", ":", "\n", "        ", "return", "[", "\n", "mmcv", ".", "imresize", "(", "\n", "img", ",", "(", "new_w", ",", "new_h", ")", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "for", "img", "in", "imgs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._resize_kps": [[1113, 1116], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_resize_kps", "(", "kps", ",", "scale_factor", ")", ":", "\n", "        ", "return", "kps", "*", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._box_resize": [[1117, 1128], ["numpy.concatenate", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_box_resize", "(", "box", ",", "scale_factor", ")", ":", "\n", "        ", "\"\"\"Rescale the bounding boxes according to the scale_factor.\n\n        Args:\n            box (np.ndarray): The bounding boxes.\n            scale_factor (np.ndarray): The scale factor used for rescaling.\n        \"\"\"", "\n", "assert", "len", "(", "scale_factor", ")", "==", "2", "\n", "scale_factor", "=", "np", ".", "concatenate", "(", "[", "scale_factor", ",", "scale_factor", "]", ")", "\n", "return", "box", "*", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize.__call__": [[1129, 1181], ["augmentations._init_lazy_if_proper", "numpy.array", "numpy.array", "mmcv.rescale_size", "augmentations.Resize._box_resize", "augmentations.Resize._resize_imgs", "augmentations.Resize._resize_kps", "NotImplementedError", "augmentations.Resize._box_resize"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._box_resize", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._resize_imgs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._resize_kps", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize._box_resize"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the Resize augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "\n", "_init_lazy_if_proper", "(", "results", ",", "self", ".", "lazy", ")", "\n", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", ",", "(", "'Keypoint Augmentations are not compatible '", "\n", "'with lazy == True'", ")", "\n", "\n", "", "if", "'scale_factor'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'scale_factor'", "]", "=", "np", ".", "array", "(", "[", "1", ",", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "\n", "if", "self", ".", "keep_ratio", ":", "\n", "            ", "new_w", ",", "new_h", "=", "mmcv", ".", "rescale_size", "(", "(", "img_w", ",", "img_h", ")", ",", "self", ".", "scale", ")", "\n", "", "else", ":", "\n", "            ", "new_w", ",", "new_h", "=", "self", ".", "scale", "\n", "\n", "", "self", ".", "scale_factor", "=", "np", ".", "array", "(", "[", "new_w", "/", "img_w", ",", "new_h", "/", "img_h", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "results", "[", "'img_shape'", "]", "=", "(", "new_h", ",", "new_w", ")", "\n", "results", "[", "'keep_ratio'", "]", "=", "self", ".", "keep_ratio", "\n", "results", "[", "'scale_factor'", "]", "=", "results", "[", "'scale_factor'", "]", "*", "self", ".", "scale_factor", "\n", "\n", "if", "not", "self", ".", "lazy", ":", "\n", "            ", "if", "'imgs'", "in", "results", ":", "\n", "                ", "results", "[", "'imgs'", "]", "=", "self", ".", "_resize_imgs", "(", "results", "[", "'imgs'", "]", ",", "new_w", ",", "\n", "new_h", ")", "\n", "", "if", "'keypoint'", "in", "results", ":", "\n", "                ", "results", "[", "'keypoint'", "]", "=", "self", ".", "_resize_kps", "(", "results", "[", "'keypoint'", "]", ",", "\n", "self", ".", "scale_factor", ")", "\n", "", "", "else", ":", "\n", "            ", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Put Flip at last for now'", ")", "\n", "", "lazyop", "[", "'interpolation'", "]", "=", "self", ".", "interpolation", "\n", "\n", "", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", "\n", "results", "[", "'gt_bboxes'", "]", "=", "self", ".", "_box_resize", "(", "results", "[", "'gt_bboxes'", "]", ",", "\n", "self", ".", "scale_factor", ")", "\n", "if", "'proposals'", "in", "results", "and", "results", "[", "'proposals'", "]", "is", "not", "None", ":", "\n", "                ", "assert", "results", "[", "'proposals'", "]", ".", "shape", "[", "1", "]", "==", "4", "\n", "results", "[", "'proposals'", "]", "=", "self", ".", "_box_resize", "(", "\n", "results", "[", "'proposals'", "]", ",", "self", ".", "scale_factor", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Resize.__repr__": [[1182, 1188], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'scale={self.scale}, keep_ratio={self.keep_ratio}, '", "\n", "f'interpolation={self.interpolation}, '", "\n", "f'lazy={self.lazy})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomRescale.__init__": [[1206, 1216], ["mmcv.is_tuple_of", "numpy.all", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "scale_range", ",", "interpolation", "=", "'bilinear'", ")", ":", "\n", "        ", "self", ".", "scale_range", "=", "scale_range", "\n", "# make sure scale_range is legal, first make sure the type is OK", "\n", "assert", "mmcv", ".", "is_tuple_of", "(", "scale_range", ",", "int", ")", "\n", "assert", "len", "(", "scale_range", ")", "==", "2", "\n", "assert", "scale_range", "[", "0", "]", "<", "scale_range", "[", "1", "]", "\n", "assert", "np", ".", "all", "(", "[", "x", ">", "0", "for", "x", "in", "scale_range", "]", ")", "\n", "\n", "self", ".", "keep_ratio", "=", "True", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomRescale.__call__": [[1217, 1234], ["numpy.random.randint", "augmentations.Resize", "Resize."], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the Resize augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "short_edge", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "scale_range", "[", "0", "]", ",", "\n", "self", ".", "scale_range", "[", "1", "]", "+", "1", ")", "\n", "resize", "=", "Resize", "(", "(", "-", "1", ",", "short_edge", ")", ",", "\n", "keep_ratio", "=", "True", ",", "\n", "interpolation", "=", "self", ".", "interpolation", ",", "\n", "lazy", "=", "False", ")", "\n", "results", "=", "resize", "(", "results", ")", "\n", "\n", "results", "[", "'short_edge'", "]", "=", "short_edge", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomRescale.__repr__": [[1235, 1241], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "scale_range", "=", "self", ".", "scale_range", "\n", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'scale_range=({scale_range[0]}, {scale_range[1]}), '", "\n", "f'interpolation={self.interpolation})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip.__init__": [[1271, 1287], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "flip_ratio", "=", "0.5", ",", "\n", "direction", "=", "'horizontal'", ",", "\n", "flip_label_map", "=", "None", ",", "\n", "left_kp", "=", "None", ",", "\n", "right_kp", "=", "None", ",", "\n", "lazy", "=", "False", ")", ":", "\n", "        ", "if", "direction", "not", "in", "self", ".", "_directions", ":", "\n", "            ", "raise", "ValueError", "(", "f'Direction {direction} is not supported. '", "\n", "f'Currently support ones are {self._directions}'", ")", "\n", "", "self", ".", "flip_ratio", "=", "flip_ratio", "\n", "self", ".", "direction", "=", "direction", "\n", "self", ".", "flip_label_map", "=", "flip_label_map", "\n", "self", ".", "left_kp", "=", "left_kp", "\n", "self", ".", "right_kp", "=", "right_kp", "\n", "self", ".", "lazy", "=", "lazy", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._flip_imgs": [[1288, 1296], ["len", "mmcv.imflip_", "range", "mmcv.iminvert"], "methods", ["None"], ["", "def", "_flip_imgs", "(", "self", ",", "imgs", ",", "modality", ")", ":", "\n", "        ", "_", "=", "[", "mmcv", ".", "imflip_", "(", "img", ",", "self", ".", "direction", ")", "for", "img", "in", "imgs", "]", "\n", "lt", "=", "len", "(", "imgs", ")", "\n", "if", "modality", "==", "'Flow'", ":", "\n", "# The 1st frame of each 2 frames is flow-x", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "lt", ",", "2", ")", ":", "\n", "                ", "imgs", "[", "i", "]", "=", "mmcv", ".", "iminvert", "(", "imgs", "[", "i", "]", ")", "\n", "", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._flip_kps": [[1297, 1309], ["list", "range", "zip"], "methods", ["None"], ["", "def", "_flip_kps", "(", "self", ",", "kps", ",", "kpscores", ",", "img_width", ")", ":", "\n", "        ", "kp_x", "=", "kps", "[", "...", ",", "0", "]", "\n", "kp_x", "[", "kp_x", "!=", "0", "]", "=", "img_width", "-", "kp_x", "[", "kp_x", "!=", "0", "]", "\n", "new_order", "=", "list", "(", "range", "(", "kps", ".", "shape", "[", "2", "]", ")", ")", "\n", "if", "self", ".", "left_kp", "is", "not", "None", "and", "self", ".", "right_kp", "is", "not", "None", ":", "\n", "            ", "for", "left", ",", "right", "in", "zip", "(", "self", ".", "left_kp", ",", "self", ".", "right_kp", ")", ":", "\n", "                ", "new_order", "[", "left", "]", "=", "right", "\n", "new_order", "[", "right", "]", "=", "left", "\n", "", "", "kps", "=", "kps", "[", ":", ",", ":", ",", "new_order", "]", "\n", "if", "kpscores", "is", "not", "None", ":", "\n", "            ", "kpscores", "=", "kpscores", "[", ":", ",", ":", ",", "new_order", "]", "\n", "", "return", "kps", ",", "kpscores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._box_flip": [[1310, 1322], ["box.copy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_box_flip", "(", "box", ",", "img_width", ")", ":", "\n", "        ", "\"\"\"Flip the bounding boxes given the width of the image.\n\n        Args:\n            box (np.ndarray): The bounding boxes.\n            img_width (int): The img width.\n        \"\"\"", "\n", "box_", "=", "box", ".", "copy", "(", ")", "\n", "box_", "[", "...", ",", "0", ":", ":", "4", "]", "=", "img_width", "-", "box", "[", "...", ",", "2", ":", ":", "4", "]", "\n", "box_", "[", "...", ",", "2", ":", ":", "4", "]", "=", "img_width", "-", "box", "[", "...", ",", "0", ":", ":", "4", "]", "\n", "return", "box_", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip.__call__": [[1323, 1381], ["augmentations._init_lazy_if_proper", "numpy.random.rand", "augmentations.Flip.flip_label_map.get", "augmentations.Flip._box_flip", "NotImplementedError", "augmentations.Flip._box_flip", "augmentations.Flip._flip_imgs", "results.get", "augmentations.Flip._flip_kps"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._box_flip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._box_flip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._flip_imgs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip._flip_kps"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the Flip augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "self", ".", "lazy", ")", "\n", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", ",", "(", "'Keypoint Augmentations are not compatible '", "\n", "'with lazy == True'", ")", "\n", "assert", "self", ".", "direction", "==", "'horizontal'", ",", "(", "\n", "'Only horizontal flips are'", "\n", "'supported for human keypoints'", ")", "\n", "\n", "", "modality", "=", "results", "[", "'modality'", "]", "\n", "if", "modality", "==", "'Flow'", ":", "\n", "            ", "assert", "self", ".", "direction", "==", "'horizontal'", "\n", "\n", "", "flip", "=", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "flip_ratio", "\n", "\n", "results", "[", "'flip'", "]", "=", "flip", "\n", "results", "[", "'flip_direction'", "]", "=", "self", ".", "direction", "\n", "img_width", "=", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "\n", "if", "self", ".", "flip_label_map", "is", "not", "None", "and", "flip", ":", "\n", "            ", "results", "[", "'label'", "]", "=", "self", ".", "flip_label_map", ".", "get", "(", "results", "[", "'label'", "]", ",", "\n", "results", "[", "'label'", "]", ")", "\n", "\n", "", "if", "not", "self", ".", "lazy", ":", "\n", "            ", "if", "flip", ":", "\n", "                ", "if", "'imgs'", "in", "results", ":", "\n", "                    ", "results", "[", "'imgs'", "]", "=", "self", ".", "_flip_imgs", "(", "results", "[", "'imgs'", "]", ",", "\n", "modality", ")", "\n", "", "if", "'keypoint'", "in", "results", ":", "\n", "                    ", "kp", "=", "results", "[", "'keypoint'", "]", "\n", "kpscore", "=", "results", ".", "get", "(", "'keypoint_score'", ",", "None", ")", "\n", "kp", ",", "kpscore", "=", "self", ".", "_flip_kps", "(", "kp", ",", "kpscore", ",", "img_width", ")", "\n", "results", "[", "'keypoint'", "]", "=", "kp", "\n", "if", "'keypoint_score'", "in", "results", ":", "\n", "                        ", "results", "[", "'keypoint_score'", "]", "=", "kpscore", "\n", "", "", "", "", "else", ":", "\n", "            ", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Use one Flip please'", ")", "\n", "", "lazyop", "[", "'flip'", "]", "=", "flip", "\n", "lazyop", "[", "'flip_direction'", "]", "=", "self", ".", "direction", "\n", "\n", "", "if", "'gt_bboxes'", "in", "results", "and", "flip", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", "and", "self", ".", "direction", "==", "'horizontal'", "\n", "width", "=", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "results", "[", "'gt_bboxes'", "]", "=", "self", ".", "_box_flip", "(", "results", "[", "'gt_bboxes'", "]", ",", "width", ")", "\n", "if", "'proposals'", "in", "results", "and", "results", "[", "'proposals'", "]", "is", "not", "None", ":", "\n", "                ", "assert", "results", "[", "'proposals'", "]", ".", "shape", "[", "1", "]", "==", "4", "\n", "results", "[", "'proposals'", "]", "=", "self", ".", "_box_flip", "(", "results", "[", "'proposals'", "]", ",", "\n", "width", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Flip.__repr__": [[1382, 1388], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "\n", "f'{self.__class__.__name__}('", "\n", "f'flip_ratio={self.flip_ratio}, direction={self.direction}, '", "\n", "f'flip_label_map={self.flip_label_map}, lazy={self.lazy})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Normalize.__init__": [[1407, 1421], ["numpy.array", "numpy.array", "isinstance", "TypeError", "isinstance", "TypeError", "type", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ",", "to_bgr", "=", "False", ",", "adjust_magnitude", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "mean", ",", "Sequence", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f'Mean must be list, tuple or np.ndarray, but got {type(mean)}'", "\n", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "std", ",", "Sequence", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f'Std must be list, tuple or np.ndarray, but got {type(std)}'", ")", "\n", "\n", "", "self", ".", "mean", "=", "np", ".", "array", "(", "mean", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "std", "=", "np", ".", "array", "(", "std", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "to_bgr", "=", "to_bgr", "\n", "self", ".", "adjust_magnitude", "=", "adjust_magnitude", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Normalize.__call__": [[1422, 1466], ["len", "numpy.empty", "enumerate", "dict", "len", "numpy.empty", "numpy.empty", "range", "numpy.stack", "dict", "mmcv.imnormalize_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "modality", "=", "results", "[", "'modality'", "]", "\n", "\n", "if", "modality", "==", "'RGB'", ":", "\n", "            ", "n", "=", "len", "(", "results", "[", "'imgs'", "]", ")", "\n", "h", ",", "w", ",", "c", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "\n", "imgs", "=", "np", ".", "empty", "(", "(", "n", ",", "h", ",", "w", ",", "c", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "results", "[", "'imgs'", "]", ")", ":", "\n", "                ", "imgs", "[", "i", "]", "=", "img", "\n", "\n", "", "for", "img", "in", "imgs", ":", "\n", "                ", "mmcv", ".", "imnormalize_", "(", "img", ",", "self", ".", "mean", ",", "self", ".", "std", ",", "self", ".", "to_bgr", ")", "\n", "\n", "", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "results", "[", "'img_norm_cfg'", "]", "=", "dict", "(", "\n", "mean", "=", "self", ".", "mean", ",", "std", "=", "self", ".", "std", ",", "to_bgr", "=", "self", ".", "to_bgr", ")", "\n", "return", "results", "\n", "", "if", "modality", "==", "'Flow'", ":", "\n", "            ", "num_imgs", "=", "len", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "num_imgs", "%", "2", "==", "0", "\n", "assert", "self", ".", "mean", ".", "shape", "[", "0", "]", "==", "2", "\n", "assert", "self", ".", "std", ".", "shape", "[", "0", "]", "==", "2", "\n", "n", "=", "num_imgs", "//", "2", "\n", "h", ",", "w", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "\n", "x_flow", "=", "np", ".", "empty", "(", "(", "n", ",", "h", ",", "w", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "y_flow", "=", "np", ".", "empty", "(", "(", "n", ",", "h", ",", "w", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "x_flow", "[", "i", "]", "=", "results", "[", "'imgs'", "]", "[", "2", "*", "i", "]", "\n", "y_flow", "[", "i", "]", "=", "results", "[", "'imgs'", "]", "[", "2", "*", "i", "+", "1", "]", "\n", "", "x_flow", "=", "(", "x_flow", "-", "self", ".", "mean", "[", "0", "]", ")", "/", "self", ".", "std", "[", "0", "]", "\n", "y_flow", "=", "(", "y_flow", "-", "self", ".", "mean", "[", "1", "]", ")", "/", "self", ".", "std", "[", "1", "]", "\n", "if", "self", ".", "adjust_magnitude", ":", "\n", "                ", "x_flow", "=", "x_flow", "*", "results", "[", "'scale_factor'", "]", "[", "0", "]", "\n", "y_flow", "=", "y_flow", "*", "results", "[", "'scale_factor'", "]", "[", "1", "]", "\n", "", "imgs", "=", "np", ".", "stack", "(", "[", "x_flow", ",", "y_flow", "]", ",", "axis", "=", "-", "1", ")", "\n", "results", "[", "'imgs'", "]", "=", "imgs", "\n", "args", "=", "dict", "(", "\n", "mean", "=", "self", ".", "mean", ",", "\n", "std", "=", "self", ".", "std", ",", "\n", "to_bgr", "=", "self", ".", "to_bgr", ",", "\n", "adjust_magnitude", "=", "self", ".", "adjust_magnitude", ")", "\n", "results", "[", "'img_norm_cfg'", "]", "=", "args", "\n", "return", "results", "\n", "", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.Normalize.__repr__": [[1467, 1474], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'mean={self.mean}, '", "\n", "f'std={self.std}, '", "\n", "f'to_bgr={self.to_bgr}, '", "\n", "f'adjust_magnitude={self.adjust_magnitude})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.__init__": [[1510, 1531], ["numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "color_space_aug", "=", "False", ",", "\n", "alpha_std", "=", "0.1", ",", "\n", "eig_val", "=", "None", ",", "\n", "eig_vec", "=", "None", ")", ":", "\n", "        ", "if", "eig_val", "is", "None", ":", "\n", "# note that the data range should be [0, 255]", "\n", "            ", "self", ".", "eig_val", "=", "np", ".", "array", "(", "[", "55.46", ",", "4.794", ",", "1.148", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eig_val", "=", "eig_val", "\n", "\n", "", "if", "eig_vec", "is", "None", ":", "\n", "            ", "self", ".", "eig_vec", "=", "np", ".", "array", "(", "[", "[", "-", "0.5675", ",", "0.7192", ",", "0.4009", "]", ",", "\n", "[", "-", "0.5808", ",", "-", "0.0045", ",", "-", "0.8140", "]", ",", "\n", "[", "-", "0.5836", ",", "-", "0.6948", ",", "0.4203", "]", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eig_vec", "=", "eig_vec", "\n", "\n", "", "self", ".", "alpha_std", "=", "alpha_std", "\n", "self", ".", "color_space_aug", "=", "color_space_aug", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.brightness": [[1532, 1547], ["numpy.random.rand", "numpy.float32"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "brightness", "(", "img", ",", "delta", ")", ":", "\n", "        ", "\"\"\"Brightness distortion.\n\n        Args:\n            img (np.ndarray): An input image.\n            delta (float): Delta value to distort brightness.\n                It ranges from [-32, 32).\n\n        Returns:\n            np.ndarray: A brightness distorted image.\n        \"\"\"", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", ":", "\n", "            ", "img", "=", "img", "+", "np", ".", "float32", "(", "delta", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.contrast": [[1548, 1563], ["numpy.random.rand", "numpy.float32"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "contrast", "(", "img", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Contrast distortion.\n\n        Args:\n            img (np.ndarray): An input image.\n            alpha (float): Alpha value to distort contrast.\n                It ranges from [0.6, 1.4).\n\n        Returns:\n            np.ndarray: A contrast distorted image.\n        \"\"\"", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", ":", "\n", "            ", "img", "=", "img", "*", "np", ".", "float32", "(", "alpha", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.saturation": [[1564, 1583], ["numpy.random.rand", "numpy.sum", "numpy.array"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "saturation", "(", "img", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Saturation distortion.\n\n        Args:\n            img (np.ndarray): An input image.\n            alpha (float): Alpha value to distort the saturation.\n                It ranges from [0.6, 1.4).\n\n        Returns:\n            np.ndarray: A saturation distorted image.\n        \"\"\"", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", ":", "\n", "            ", "gray", "=", "img", "*", "np", ".", "array", "(", "[", "0.299", ",", "0.587", ",", "0.114", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "gray", "=", "np", ".", "sum", "(", "gray", ",", "2", ",", "keepdims", "=", "True", ")", "\n", "gray", "*=", "(", "1.0", "-", "alpha", ")", "\n", "img", "=", "img", "*", "alpha", "\n", "img", "=", "img", "+", "gray", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.hue": [[1584, 1611], ["numpy.random.rand", "numpy.cos", "numpy.sin", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.dot", "numpy.dot", "numpy.dot"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "hue", "(", "img", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Hue distortion.\n\n        Args:\n            img (np.ndarray): An input image.\n            alpha (float): Alpha value to control the degree of rotation\n                for hue. It ranges from [-18, 18).\n\n        Returns:\n            np.ndarray: A hue distorted image.\n        \"\"\"", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", ":", "\n", "            ", "u", "=", "np", ".", "cos", "(", "alpha", "*", "np", ".", "pi", ")", "\n", "w", "=", "np", ".", "sin", "(", "alpha", "*", "np", ".", "pi", ")", "\n", "bt", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.0", ",", "0.0", "]", ",", "[", "0.0", ",", "u", ",", "-", "w", "]", ",", "[", "0.0", ",", "w", ",", "u", "]", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "tyiq", "=", "np", ".", "array", "(", "[", "[", "0.299", ",", "0.587", ",", "0.114", "]", ",", "[", "0.596", ",", "-", "0.274", ",", "-", "0.321", "]", ",", "\n", "[", "0.211", ",", "-", "0.523", ",", "0.311", "]", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "ityiq", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "0.956", ",", "0.621", "]", ",", "[", "1.0", ",", "-", "0.272", ",", "-", "0.647", "]", ",", "\n", "[", "1.0", ",", "-", "1.107", ",", "1.705", "]", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "t", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "ityiq", ",", "bt", ")", ",", "tyiq", ")", ".", "T", "\n", "t", "=", "np", ".", "array", "(", "t", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "img", "=", "np", ".", "dot", "(", "img", ",", "t", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.__call__": [[1612, 1648], ["numpy.random.normal", "numpy.array", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.rand", "numpy.dot", "augmentations.ColorJitter.brightness", "out.append", "augmentations.ColorJitter.contrast", "augmentations.ColorJitter.saturation", "augmentations.ColorJitter.hue", "augmentations.ColorJitter.saturation", "augmentations.ColorJitter.hue", "augmentations.ColorJitter.contrast"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.brightness", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.contrast", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.saturation", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.hue", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.saturation", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.hue", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.contrast"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "imgs", "=", "results", "[", "'imgs'", "]", "\n", "out", "=", "[", "]", "\n", "if", "self", ".", "color_space_aug", ":", "\n", "            ", "bright_delta", "=", "np", ".", "random", ".", "uniform", "(", "-", "32", ",", "32", ")", "\n", "contrast_alpha", "=", "np", ".", "random", ".", "uniform", "(", "0.6", ",", "1.4", ")", "\n", "saturation_alpha", "=", "np", ".", "random", ".", "uniform", "(", "0.6", ",", "1.4", ")", "\n", "hue_alpha", "=", "np", ".", "random", ".", "uniform", "(", "-", "18", ",", "18", ")", "\n", "jitter_coin", "=", "np", ".", "random", ".", "rand", "(", ")", "\n", "for", "img", "in", "imgs", ":", "\n", "                ", "img", "=", "self", ".", "brightness", "(", "img", ",", "delta", "=", "bright_delta", ")", "\n", "if", "jitter_coin", ">", "0.5", ":", "\n", "                    ", "img", "=", "self", ".", "contrast", "(", "img", ",", "alpha", "=", "contrast_alpha", ")", "\n", "img", "=", "self", ".", "saturation", "(", "img", ",", "alpha", "=", "saturation_alpha", ")", "\n", "img", "=", "self", ".", "hue", "(", "img", ",", "alpha", "=", "hue_alpha", ")", "\n", "", "else", ":", "\n", "                    ", "img", "=", "self", ".", "saturation", "(", "img", ",", "alpha", "=", "saturation_alpha", ")", "\n", "img", "=", "self", ".", "hue", "(", "img", ",", "alpha", "=", "hue_alpha", ")", "\n", "img", "=", "self", ".", "contrast", "(", "img", ",", "alpha", "=", "contrast_alpha", ")", "\n", "", "out", ".", "append", "(", "img", ")", "\n", "", "", "else", ":", "\n", "            ", "out", "=", "imgs", "\n", "\n", "# Add PCA based noise", "\n", "", "alpha", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "alpha_std", ",", "size", "=", "(", "3", ",", ")", ")", "\n", "rgb", "=", "np", ".", "array", "(", "\n", "np", ".", "dot", "(", "self", ".", "eig_vec", "*", "alpha", ",", "self", ".", "eig_val", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "rgb", "=", "rgb", "[", "None", ",", "None", ",", "...", "]", "\n", "\n", "results", "[", "'imgs'", "]", "=", "[", "img", "+", "rgb", "for", "img", "in", "out", "]", "\n", "results", "[", "'eig_val'", "]", "=", "self", ".", "eig_val", "\n", "results", "[", "'eig_vec'", "]", "=", "self", ".", "eig_vec", "\n", "results", "[", "'alpha_std'", "]", "=", "self", ".", "alpha_std", "\n", "results", "[", "'color_space_aug'", "]", "=", "self", ".", "color_space_aug", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ColorJitter.__repr__": [[1649, 1656], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'color_space_aug={self.color_space_aug}, '", "\n", "f'alpha_std={self.alpha_std}, '", "\n", "f'eig_val={self.eig_val}, '", "\n", "f'eig_vec={self.eig_vec})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.CenterCrop.__init__": [[1672, 1677], ["torch.nn.modules.utils._pair", "mmcv.is_tuple_of", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "crop_size", ",", "lazy", "=", "False", ")", ":", "\n", "        ", "self", ".", "crop_size", "=", "_pair", "(", "crop_size", ")", "\n", "self", ".", "lazy", "=", "lazy", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "crop_size", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Crop_size must be int or tuple of int, '", "\n", "f'but got {type(crop_size)}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.CenterCrop.__call__": [[1679, 1751], ["augmentations._init_lazy_if_proper", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "augmentations.CenterCrop._all_box_crop", "augmentations.CenterCrop._crop_kps", "augmentations.CenterCrop._crop_imgs", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._all_box_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_kps", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.RandomCrop._crop_imgs"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the CenterCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "self", ".", "lazy", ")", "\n", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", ",", "(", "'Keypoint Augmentations are not compatible '", "\n", "'with lazy == True'", ")", "\n", "\n", "", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "crop_w", ",", "crop_h", "=", "self", ".", "crop_size", "\n", "\n", "left", "=", "(", "img_w", "-", "crop_w", ")", "//", "2", "\n", "top", "=", "(", "img_h", "-", "crop_h", ")", "//", "2", "\n", "right", "=", "left", "+", "crop_w", "\n", "bottom", "=", "top", "+", "crop_h", "\n", "new_h", ",", "new_w", "=", "bottom", "-", "top", ",", "right", "-", "left", "\n", "\n", "crop_bbox", "=", "np", ".", "array", "(", "[", "left", ",", "top", ",", "right", ",", "bottom", "]", ")", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bbox", "\n", "results", "[", "'img_shape'", "]", "=", "(", "new_h", ",", "new_w", ")", "\n", "\n", "if", "'crop_quadruple'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "[", "0", ",", "0", ",", "1", ",", "1", "]", ",", "# x, y, w, h", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "x_ratio", ",", "y_ratio", "=", "left", "/", "img_w", ",", "top", "/", "img_h", "\n", "w_ratio", ",", "h_ratio", "=", "new_w", "/", "img_w", ",", "new_h", "/", "img_h", "\n", "\n", "old_crop_quadruple", "=", "results", "[", "'crop_quadruple'", "]", "\n", "old_x_ratio", ",", "old_y_ratio", "=", "old_crop_quadruple", "[", "0", "]", ",", "old_crop_quadruple", "[", "1", "]", "\n", "old_w_ratio", ",", "old_h_ratio", "=", "old_crop_quadruple", "[", "2", "]", ",", "old_crop_quadruple", "[", "3", "]", "\n", "new_crop_quadruple", "=", "[", "\n", "old_x_ratio", "+", "x_ratio", "*", "old_w_ratio", ",", "\n", "old_y_ratio", "+", "y_ratio", "*", "old_h_ratio", ",", "w_ratio", "*", "old_w_ratio", ",", "\n", "h_ratio", "*", "old_x_ratio", "\n", "]", "\n", "results", "[", "'crop_quadruple'", "]", "=", "np", ".", "array", "(", "\n", "new_crop_quadruple", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "if", "not", "self", ".", "lazy", ":", "\n", "            ", "if", "'keypoint'", "in", "results", ":", "\n", "                ", "results", "[", "'keypoint'", "]", "=", "self", ".", "_crop_kps", "(", "results", "[", "'keypoint'", "]", ",", "\n", "crop_bbox", ")", "\n", "", "if", "'imgs'", "in", "results", ":", "\n", "                ", "results", "[", "'imgs'", "]", "=", "self", ".", "_crop_imgs", "(", "results", "[", "'imgs'", "]", ",", "crop_bbox", ")", "\n", "", "", "else", ":", "\n", "            ", "lazyop", "=", "results", "[", "'lazy'", "]", "\n", "if", "lazyop", "[", "'flip'", "]", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Put Flip at last for now'", ")", "\n", "\n", "# record crop_bbox in lazyop dict to ensure only crop once in Fuse", "\n", "", "lazy_left", ",", "lazy_top", ",", "lazy_right", ",", "lazy_bottom", "=", "lazyop", "[", "'crop_bbox'", "]", "\n", "left", "=", "left", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "right", "=", "right", "*", "(", "lazy_right", "-", "lazy_left", ")", "/", "img_w", "\n", "top", "=", "top", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "bottom", "=", "bottom", "*", "(", "lazy_bottom", "-", "lazy_top", ")", "/", "img_h", "\n", "lazyop", "[", "'crop_bbox'", "]", "=", "np", ".", "array", "(", "[", "(", "lazy_left", "+", "left", ")", ",", "\n", "(", "lazy_top", "+", "top", ")", ",", "\n", "(", "lazy_left", "+", "right", ")", ",", "\n", "(", "lazy_top", "+", "bottom", ")", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "if", "'gt_bboxes'", "in", "results", ":", "\n", "            ", "assert", "not", "self", ".", "lazy", "\n", "results", "=", "self", ".", "_all_box_crop", "(", "results", ",", "results", "[", "'crop_bbox'", "]", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.CenterCrop.__repr__": [[1752, 1756], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}(crop_size={self.crop_size}, '", "\n", "f'lazy={self.lazy})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ThreeCrop.__init__": [[1771, 1775], ["torch.nn.modules.utils._pair", "mmcv.is_tuple_of", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "crop_size", ")", ":", "\n", "        ", "self", ".", "crop_size", "=", "_pair", "(", "crop_size", ")", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "crop_size", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Crop_size must be int or tuple of int, '", "\n", "f'but got {type(crop_size)}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ThreeCrop.__call__": [[1777, 1825], ["augmentations._init_lazy_if_proper", "numpy.array", "warnings.warn", "cropped.extend", "numpy.array.extend", "range", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the ThreeCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "False", ")", "\n", "if", "'gt_bboxes'", "in", "results", "or", "'proposals'", "in", "results", ":", "\n", "            ", "warnings", ".", "warn", "(", "'ThreeCrop cannot process bounding boxes'", ")", "\n", "\n", "", "imgs", "=", "results", "[", "'imgs'", "]", "\n", "img_h", ",", "img_w", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "crop_w", ",", "crop_h", "=", "self", ".", "crop_size", "\n", "assert", "crop_h", "==", "img_h", "or", "crop_w", "==", "img_w", "\n", "\n", "if", "crop_h", "==", "img_h", ":", "\n", "            ", "w_step", "=", "(", "img_w", "-", "crop_w", ")", "//", "2", "\n", "offsets", "=", "[", "\n", "(", "0", ",", "0", ")", ",", "# left", "\n", "(", "2", "*", "w_step", ",", "0", ")", ",", "# right", "\n", "(", "w_step", ",", "0", ")", ",", "# middle", "\n", "]", "\n", "", "elif", "crop_w", "==", "img_w", ":", "\n", "            ", "h_step", "=", "(", "img_h", "-", "crop_h", ")", "//", "2", "\n", "offsets", "=", "[", "\n", "(", "0", ",", "0", ")", ",", "# top", "\n", "(", "0", ",", "2", "*", "h_step", ")", ",", "# down", "\n", "(", "0", ",", "h_step", ")", ",", "# middle", "\n", "]", "\n", "\n", "", "cropped", "=", "[", "]", "\n", "crop_bboxes", "=", "[", "]", "\n", "for", "x_offset", ",", "y_offset", "in", "offsets", ":", "\n", "            ", "bbox", "=", "[", "x_offset", ",", "y_offset", ",", "x_offset", "+", "crop_w", ",", "y_offset", "+", "crop_h", "]", "\n", "crop", "=", "[", "\n", "img", "[", "y_offset", ":", "y_offset", "+", "crop_h", ",", "x_offset", ":", "x_offset", "+", "crop_w", "]", "\n", "for", "img", "in", "imgs", "\n", "]", "\n", "cropped", ".", "extend", "(", "crop", ")", "\n", "crop_bboxes", ".", "extend", "(", "[", "bbox", "for", "_", "in", "range", "(", "len", "(", "imgs", ")", ")", "]", ")", "\n", "\n", "", "crop_bboxes", "=", "np", ".", "array", "(", "crop_bboxes", ")", "\n", "results", "[", "'imgs'", "]", "=", "cropped", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bboxes", "\n", "results", "[", "'img_shape'", "]", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.ThreeCrop.__repr__": [[1826, 1829], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "f'{self.__class__.__name__}(crop_size={self.crop_size})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.TenCrop.__init__": [[1844, 1848], ["torch.nn.modules.utils._pair", "mmcv.is_tuple_of", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "crop_size", ")", ":", "\n", "        ", "self", ".", "crop_size", "=", "_pair", "(", "crop_size", ")", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "crop_size", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Crop_size must be int or tuple of int, '", "\n", "f'but got {type(crop_size)}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.TenCrop.__call__": [[1850, 1897], ["augmentations._init_lazy_if_proper", "list", "list", "numpy.array", "warnings.warn", "list.extend", "list.extend", "numpy.array.extend", "numpy.flip().copy", "numpy.flip", "range", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the TenCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "_init_lazy_if_proper", "(", "results", ",", "False", ")", "\n", "\n", "if", "'gt_bboxes'", "in", "results", "or", "'proposals'", "in", "results", ":", "\n", "            ", "warnings", ".", "warn", "(", "'TenCrop cannot process bounding boxes'", ")", "\n", "\n", "", "imgs", "=", "results", "[", "'imgs'", "]", "\n", "\n", "img_h", ",", "img_w", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "crop_w", ",", "crop_h", "=", "self", ".", "crop_size", "\n", "\n", "w_step", "=", "(", "img_w", "-", "crop_w", ")", "//", "4", "\n", "h_step", "=", "(", "img_h", "-", "crop_h", ")", "//", "4", "\n", "\n", "offsets", "=", "[", "\n", "(", "0", ",", "0", ")", ",", "# upper left", "\n", "(", "4", "*", "w_step", ",", "0", ")", ",", "# upper right", "\n", "(", "0", ",", "4", "*", "h_step", ")", ",", "# lower left", "\n", "(", "4", "*", "w_step", ",", "4", "*", "h_step", ")", ",", "# lower right", "\n", "(", "2", "*", "w_step", ",", "2", "*", "h_step", ")", ",", "# center", "\n", "]", "\n", "\n", "img_crops", "=", "list", "(", ")", "\n", "crop_bboxes", "=", "list", "(", ")", "\n", "for", "x_offset", ",", "y_offsets", "in", "offsets", ":", "\n", "            ", "crop", "=", "[", "\n", "img", "[", "y_offsets", ":", "y_offsets", "+", "crop_h", ",", "x_offset", ":", "x_offset", "+", "crop_w", "]", "\n", "for", "img", "in", "imgs", "\n", "]", "\n", "flip_crop", "=", "[", "np", ".", "flip", "(", "c", ",", "axis", "=", "1", ")", ".", "copy", "(", ")", "for", "c", "in", "crop", "]", "\n", "bbox", "=", "[", "x_offset", ",", "y_offsets", ",", "x_offset", "+", "crop_w", ",", "y_offsets", "+", "crop_h", "]", "\n", "img_crops", ".", "extend", "(", "crop", ")", "\n", "img_crops", ".", "extend", "(", "flip_crop", ")", "\n", "crop_bboxes", ".", "extend", "(", "[", "bbox", "for", "_", "in", "range", "(", "len", "(", "imgs", ")", "*", "2", ")", "]", ")", "\n", "\n", "", "crop_bboxes", "=", "np", ".", "array", "(", "crop_bboxes", ")", "\n", "results", "[", "'imgs'", "]", "=", "img_crops", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bboxes", "\n", "results", "[", "'img_shape'", "]", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.TenCrop.__repr__": [[1898, 1901], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "f'{self.__class__.__name__}(crop_size={self.crop_size})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MultiGroupCrop.__init__": [[1917, 1929], ["torch.nn.modules.utils._pair", "mmcv.is_tuple_of", "TypeError", "isinstance", "TypeError", "ValueError", "type", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "crop_size", ",", "groups", ")", ":", "\n", "        ", "self", ".", "crop_size", "=", "_pair", "(", "crop_size", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "if", "not", "mmcv", ".", "is_tuple_of", "(", "self", ".", "crop_size", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'Crop size must be int or tuple of int, '", "\n", "f'but got {type(crop_size)}'", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "groups", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'Groups must be int, but got {type(groups)}.'", ")", "\n", "\n", "", "if", "groups", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'Groups must be positive.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MultiGroupCrop.__call__": [[1930, 1964], ["range", "numpy.array", "warnings.warn", "random.randint", "random.randint", "img_crops.extend", "numpy.array.extend", "range", "len"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Performs the MultiGroupCrop augmentation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "if", "'gt_bboxes'", "in", "results", "or", "'proposals'", "in", "results", ":", "\n", "            ", "warnings", ".", "warn", "(", "'MultiGroupCrop cannot process bounding boxes'", ")", "\n", "\n", "", "imgs", "=", "results", "[", "'imgs'", "]", "\n", "img_h", ",", "img_w", "=", "imgs", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "crop_w", ",", "crop_h", "=", "self", ".", "crop_size", "\n", "\n", "img_crops", "=", "[", "]", "\n", "crop_bboxes", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "groups", ")", ":", "\n", "            ", "x_offset", "=", "random", ".", "randint", "(", "0", ",", "img_w", "-", "crop_w", ")", "\n", "y_offset", "=", "random", ".", "randint", "(", "0", ",", "img_h", "-", "crop_h", ")", "\n", "\n", "bbox", "=", "[", "x_offset", ",", "y_offset", ",", "x_offset", "+", "crop_w", ",", "y_offset", "+", "crop_h", "]", "\n", "crop", "=", "[", "\n", "img", "[", "y_offset", ":", "y_offset", "+", "crop_h", ",", "x_offset", ":", "x_offset", "+", "crop_w", "]", "\n", "for", "img", "in", "imgs", "\n", "]", "\n", "img_crops", ".", "extend", "(", "crop", ")", "\n", "crop_bboxes", ".", "extend", "(", "[", "bbox", "for", "_", "in", "range", "(", "len", "(", "imgs", ")", ")", "]", ")", "\n", "\n", "", "crop_bboxes", "=", "np", ".", "array", "(", "crop_bboxes", ")", "\n", "results", "[", "'imgs'", "]", "=", "img_crops", "\n", "results", "[", "'crop_bbox'", "]", "=", "crop_bboxes", "\n", "results", "[", "'img_shape'", "]", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MultiGroupCrop.__repr__": [[1965, 1970], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}'", "\n", "f'(crop_size={self.crop_size}, '", "\n", "f'groups={self.groups})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.AudioAmplify.__init__": [[1983, 1988], ["isinstance", "TypeError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ratio", ")", ":", "\n", "        ", "if", "isinstance", "(", "ratio", ",", "float", ")", ":", "\n", "            ", "self", ".", "ratio", "=", "ratio", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'Amplification ratio should be float.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.AudioAmplify.__call__": [[1989, 2002], ["None"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perfrom the audio amplification.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "\n", "assert", "'audios'", "in", "results", "\n", "results", "[", "'audios'", "]", "*=", "self", ".", "ratio", "\n", "results", "[", "'amplify_ratio'", "]", "=", "self", ".", "ratio", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.AudioAmplify.__repr__": [[2003, 2006], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "f'{self.__class__.__name__}(ratio={self.ratio})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MelSpectrogram.__init__": [[2024, 2038], ["all", "TypeError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "window_size", "=", "32", ",", "\n", "step_size", "=", "16", ",", "\n", "n_mels", "=", "80", ",", "\n", "fixed_length", "=", "128", ")", ":", "\n", "        ", "if", "all", "(", "\n", "isinstance", "(", "x", ",", "int", ")", "\n", "for", "x", "in", "[", "window_size", ",", "step_size", ",", "n_mels", ",", "fixed_length", "]", ")", ":", "\n", "            ", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "step_size", "=", "step_size", "\n", "self", ".", "n_mels", "=", "n_mels", "\n", "self", ".", "fixed_length", "=", "fixed_length", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'All arguments should be int.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MelSpectrogram.__call__": [[2039, 2073], ["int", "int", "list", "range", "numpy.array", "round", "round", "librosa.feature.melspectrogram", "list.append", "ImportError", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.data.build_audio_features.AudioTools.melspectrogram"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Perform MelSpectrogram transformation.\n\n        Args:\n            results (dict): The resulting dict to be modified and passed\n                to the next transform in pipeline.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "librosa", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'Install librosa first.'", ")", "\n", "", "signals", "=", "results", "[", "'audios'", "]", "\n", "sample_rate", "=", "results", "[", "'sample_rate'", "]", "\n", "n_fft", "=", "int", "(", "round", "(", "sample_rate", "*", "self", ".", "window_size", "/", "1000", ")", ")", "\n", "hop_length", "=", "int", "(", "round", "(", "sample_rate", "*", "self", ".", "step_size", "/", "1000", ")", ")", "\n", "melspectrograms", "=", "list", "(", ")", "\n", "for", "clip_idx", "in", "range", "(", "results", "[", "'num_clips'", "]", ")", ":", "\n", "            ", "clip_signal", "=", "signals", "[", "clip_idx", "]", "\n", "mel", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "y", "=", "clip_signal", ",", "\n", "sr", "=", "sample_rate", ",", "\n", "n_fft", "=", "n_fft", ",", "\n", "hop_length", "=", "hop_length", ",", "\n", "n_mels", "=", "self", ".", "n_mels", ")", "\n", "if", "mel", ".", "shape", "[", "0", "]", ">=", "self", ".", "fixed_length", ":", "\n", "                ", "mel", "=", "mel", "[", ":", "self", ".", "fixed_length", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "mel", "=", "np", ".", "pad", "(", "\n", "mel", ",", "(", "(", "0", ",", "mel", ".", "shape", "[", "-", "1", "]", "-", "self", ".", "fixed_length", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\n", "mode", "=", "'edge'", ")", "\n", "", "melspectrograms", ".", "append", "(", "mel", ")", "\n", "\n", "", "results", "[", "'audios'", "]", "=", "np", ".", "array", "(", "melspectrograms", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations.MelSpectrogram.__repr__": [[2074, 2081], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}'", "\n", "f'(window_size={self.window_size}), '", "\n", "f'step_size={self.step_size}, '", "\n", "f'n_mels={self.n_mels}, '", "\n", "f'fixed_length={self.fixed_length})'", ")", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._combine_quadruple": [[14, 16], ["None"], "function", ["None"], ["def", "_combine_quadruple", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "(", "a", "[", "0", "]", "+", "a", "[", "2", "]", "*", "b", "[", "0", "]", ",", "a", "[", "1", "]", "+", "a", "[", "3", "]", "*", "b", "[", "1", "]", ",", "a", "[", "2", "]", "*", "b", "[", "2", "]", ",", "a", "[", "3", "]", "*", "b", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._flip_quadruple": [[18, 20], ["None"], "function", ["None"], ["", "def", "_flip_quadruple", "(", "a", ")", ":", "\n", "    ", "return", "(", "1", "-", "a", "[", "0", "]", "-", "a", "[", "2", "]", ",", "a", "[", "1", "]", ",", "a", "[", "2", "]", ",", "a", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper": [[22, 54], ["dict", "numpy.array"], "function", ["None"], ["", "def", "_init_lazy_if_proper", "(", "results", ",", "lazy", ")", ":", "\n", "    ", "\"\"\"Initialize lazy operation properly.\n\n    Make sure that a lazy operation is properly initialized,\n    and avoid a non-lazy operation accidentally getting mixed in.\n\n    Required keys in results are \"imgs\" if \"img_shape\" not in results,\n    otherwise, Required keys in results are \"img_shape\", add or modified keys\n    are \"img_shape\", \"lazy\".\n    Add or modified keys in \"lazy\" are \"original_shape\", \"crop_bbox\", \"flip\",\n    \"flip_direction\", \"interpolation\".\n\n    Args:\n        results (dict): A dict stores data pipeline result.\n        lazy (bool): Determine whether to apply lazy operation. Default: False.\n    \"\"\"", "\n", "\n", "if", "'img_shape'", "not", "in", "results", ":", "\n", "        ", "results", "[", "'img_shape'", "]", "=", "results", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "", "if", "lazy", ":", "\n", "        ", "if", "'lazy'", "not", "in", "results", ":", "\n", "            ", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "lazyop", "=", "dict", "(", ")", "\n", "lazyop", "[", "'original_shape'", "]", "=", "results", "[", "'img_shape'", "]", "\n", "lazyop", "[", "'crop_bbox'", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "img_w", ",", "img_h", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "lazyop", "[", "'flip'", "]", "=", "False", "\n", "lazyop", "[", "'flip_direction'", "]", "=", "None", "\n", "lazyop", "[", "'interpolation'", "]", "=", "None", "\n", "results", "[", "'lazy'", "]", "=", "lazyop", "\n", "", "", "else", ":", "\n", "        ", "assert", "'lazy'", "not", "in", "results", ",", "'Use Fuse after lazy operations'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames.__init__": [[33, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "clip_len", ",", "num_clips", "=", "1", ",", "test_mode", "=", "False", ",", "seed", "=", "255", ")", ":", "\n", "\n", "        ", "self", ".", "clip_len", "=", "clip_len", "\n", "self", ".", "num_clips", "=", "num_clips", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "seed", "=", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_train_clips": [[40, 68], ["numpy.random.randint", "numpy.arange", "numpy.arange", "numpy.random.choice", "numpy.zeros", "numpy.cumsum", "numpy.array", "numpy.diff", "numpy.random.randint", "range"], "methods", ["None"], ["", "def", "_get_train_clips", "(", "self", ",", "num_frames", ",", "clip_len", ")", ":", "\n", "        ", "\"\"\"Uniformly sample indices for training clips.\n\n        Args:\n            num_frames (int): The number of frames.\n            clip_len (int): The length of the clip.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "num_clips", "==", "1", "\n", "if", "num_frames", "<", "clip_len", ":", "\n", "            ", "start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "num_frames", ")", "\n", "inds", "=", "np", ".", "arange", "(", "start", ",", "start", "+", "clip_len", ")", "\n", "", "elif", "clip_len", "<=", "num_frames", "<", "2", "*", "clip_len", ":", "\n", "            ", "basic", "=", "np", ".", "arange", "(", "clip_len", ")", "\n", "inds", "=", "np", ".", "random", ".", "choice", "(", "\n", "clip_len", "+", "1", ",", "num_frames", "-", "clip_len", ",", "replace", "=", "False", ")", "\n", "offset", "=", "np", ".", "zeros", "(", "clip_len", "+", "1", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "offset", "[", "inds", "]", "=", "1", "\n", "offset", "=", "np", ".", "cumsum", "(", "offset", ")", "\n", "inds", "=", "basic", "+", "offset", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "bids", "=", "np", ".", "array", "(", "\n", "[", "i", "*", "num_frames", "//", "clip_len", "for", "i", "in", "range", "(", "clip_len", "+", "1", ")", "]", ")", "\n", "bsize", "=", "np", ".", "diff", "(", "bids", ")", "\n", "bst", "=", "bids", "[", ":", "clip_len", "]", "\n", "offset", "=", "np", ".", "random", ".", "randint", "(", "bsize", ")", "\n", "inds", "=", "bst", "+", "offset", "\n", "", "return", "inds", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_test_clips": [[69, 112], ["numpy.random.seed", "numpy.concatenate", "list", "range", "numpy.concatenate", "numpy.array", "numpy.diff", "range", "numpy.concatenate", "range", "numpy.arange", "numpy.arange", "numpy.random.choice", "numpy.zeros", "numpy.cumsum", "all_inds.append", "numpy.random.randint", "all_inds.append", "range", "range"], "methods", ["None"], ["", "def", "_get_test_clips", "(", "self", ",", "num_frames", ",", "clip_len", ")", ":", "\n", "        ", "\"\"\"Uniformly sample indices for testing clips.\n\n        Args:\n            num_frames (int): The number of frames.\n            clip_len (int): The length of the clip.\n        \"\"\"", "\n", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "if", "num_frames", "<", "clip_len", ":", "\n", "# Then we use a simple strategy", "\n", "            ", "if", "num_frames", "<", "self", ".", "num_clips", ":", "\n", "                ", "start_inds", "=", "list", "(", "range", "(", "self", ".", "num_clips", ")", ")", "\n", "", "else", ":", "\n", "                ", "start_inds", "=", "[", "\n", "i", "*", "num_frames", "//", "self", ".", "num_clips", "\n", "for", "i", "in", "range", "(", "self", ".", "num_clips", ")", "\n", "]", "\n", "", "inds", "=", "np", ".", "concatenate", "(", "\n", "[", "np", ".", "arange", "(", "i", ",", "i", "+", "clip_len", ")", "for", "i", "in", "start_inds", "]", ")", "\n", "", "elif", "clip_len", "<=", "num_frames", "<", "clip_len", "*", "2", ":", "\n", "            ", "all_inds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_clips", ")", ":", "\n", "                ", "basic", "=", "np", ".", "arange", "(", "clip_len", ")", "\n", "inds", "=", "np", ".", "random", ".", "choice", "(", "\n", "clip_len", "+", "1", ",", "num_frames", "-", "clip_len", ",", "replace", "=", "False", ")", "\n", "offset", "=", "np", ".", "zeros", "(", "clip_len", "+", "1", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "offset", "[", "inds", "]", "=", "1", "\n", "offset", "=", "np", ".", "cumsum", "(", "offset", ")", "\n", "inds", "=", "basic", "+", "offset", "[", ":", "-", "1", "]", "\n", "all_inds", ".", "append", "(", "inds", ")", "\n", "", "inds", "=", "np", ".", "concatenate", "(", "all_inds", ")", "\n", "", "else", ":", "\n", "            ", "bids", "=", "np", ".", "array", "(", "\n", "[", "i", "*", "num_frames", "//", "clip_len", "for", "i", "in", "range", "(", "clip_len", "+", "1", ")", "]", ")", "\n", "bsize", "=", "np", ".", "diff", "(", "bids", ")", "\n", "bst", "=", "bids", "[", ":", "clip_len", "]", "\n", "all_inds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_clips", ")", ":", "\n", "                ", "offset", "=", "np", ".", "random", ".", "randint", "(", "bsize", ")", "\n", "all_inds", ".", "append", "(", "bst", "+", "offset", ")", "\n", "", "inds", "=", "np", ".", "concatenate", "(", "all_inds", ")", "\n", "", "return", "inds", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames.__call__": [[113, 130], ["numpy.mod", "pose_loading.UniformSampleFrames.astype", "pose_loading.UniformSampleFrames._get_test_clips", "pose_loading.UniformSampleFrames._get_train_clips"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_test_clips", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames._get_train_clips"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "num_frames", "=", "results", "[", "'total_frames'", "]", "\n", "\n", "if", "self", ".", "test_mode", ":", "\n", "            ", "inds", "=", "self", ".", "_get_test_clips", "(", "num_frames", ",", "self", ".", "clip_len", ")", "\n", "", "else", ":", "\n", "            ", "inds", "=", "self", ".", "_get_train_clips", "(", "num_frames", ",", "self", ".", "clip_len", ")", "\n", "\n", "", "inds", "=", "np", ".", "mod", "(", "inds", ",", "num_frames", ")", "\n", "start_index", "=", "results", "[", "'start_index'", "]", "\n", "inds", "=", "inds", "+", "start_index", "\n", "\n", "results", "[", "'frame_inds'", "]", "=", "inds", ".", "astype", "(", "np", ".", "int", ")", "\n", "results", "[", "'clip_len'", "]", "=", "self", ".", "clip_len", "\n", "results", "[", "'frame_interval'", "]", "=", "None", "\n", "results", "[", "'num_clips'", "]", "=", "self", ".", "num_clips", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.UniformSampleFrames.__repr__": [[131, 138], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'clip_len={self.clip_len}, '", "\n", "f'num_clips={self.num_clips}, '", "\n", "f'test_mode={self.test_mode}, '", "\n", "f'seed={self.seed})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.PoseDecode._load_kp": [[149, 159], ["x[].astype"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "_load_kp", "(", "kp", ",", "frame_inds", ")", ":", "\n", "        ", "\"\"\"Load keypoints given frame indices.\n\n        Args:\n            kp (np.ndarray): The keypoint coordinates.\n            frame_inds (np.ndarray): The frame indices.\n        \"\"\"", "\n", "\n", "return", "[", "x", "[", "frame_inds", "]", ".", "astype", "(", "np", ".", "float32", ")", "for", "x", "in", "kp", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.PoseDecode._load_kpscore": [[160, 170], ["x[].astype"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_load_kpscore", "(", "kpscore", ",", "frame_inds", ")", ":", "\n", "        ", "\"\"\"Load keypoint scores given frame indices.\n\n        Args:\n            kpscore (np.ndarray): The confidence scores of keypoints.\n            frame_inds (np.ndarray): The frame indices.\n        \"\"\"", "\n", "\n", "return", "[", "x", "[", "frame_inds", "]", ".", "astype", "(", "np", ".", "float32", ")", "for", "x", "in", "kpscore", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.PoseDecode.__call__": [[171, 192], ["results.get", "numpy.arange", "numpy.squeeze", "kpscore[].astype", "[].astype"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "\n", "        ", "if", "'frame_inds'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "results", "[", "'total_frames'", "]", ")", "\n", "\n", "", "if", "results", "[", "'frame_inds'", "]", ".", "ndim", "!=", "1", ":", "\n", "            ", "results", "[", "'frame_inds'", "]", "=", "np", ".", "squeeze", "(", "results", "[", "'frame_inds'", "]", ")", "\n", "\n", "", "offset", "=", "results", ".", "get", "(", "'offset'", ",", "0", ")", "\n", "frame_inds", "=", "results", "[", "'frame_inds'", "]", "+", "offset", "\n", "\n", "if", "'keypoint_score'", "in", "results", ":", "\n", "            ", "kpscore", "=", "results", "[", "'keypoint_score'", "]", "\n", "results", "[", "'keypoint_score'", "]", "=", "kpscore", "[", ":", ",", "\n", "frame_inds", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "'keypoint'", "in", "results", ":", "\n", "            ", "results", "[", "'keypoint'", "]", "=", "results", "[", "'keypoint'", "]", "[", ":", ",", "frame_inds", "]", ".", "astype", "(", "\n", "np", ".", "float32", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.PoseDecode.__repr__": [[193, 196], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "f'{self.__class__.__name__}()'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.LoadKineticsPose.__init__": [[220, 249], ["dict", "copy.deepcopy", "dict", "dict", "NotImplementedError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "io_backend", "=", "'disk'", ",", "\n", "squeeze", "=", "True", ",", "\n", "max_person", "=", "100", ",", "\n", "keypoint_weight", "=", "dict", "(", "face", "=", "1", ",", "torso", "=", "2", ",", "limb", "=", "3", ")", ",", "\n", "source", "=", "'mmpose'", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "io_backend", "=", "io_backend", "\n", "self", ".", "squeeze", "=", "squeeze", "\n", "self", ".", "max_person", "=", "max_person", "\n", "self", ".", "keypoint_weight", "=", "cp", ".", "deepcopy", "(", "keypoint_weight", ")", "\n", "self", ".", "source", "=", "source", "\n", "\n", "if", "source", "==", "'openpose'", ":", "\n", "            ", "self", ".", "kpsubset", "=", "dict", "(", "\n", "face", "=", "[", "0", ",", "14", ",", "15", ",", "16", ",", "17", "]", ",", "\n", "torso", "=", "[", "1", ",", "2", ",", "8", ",", "5", ",", "11", "]", ",", "\n", "limb", "=", "[", "3", ",", "4", ",", "6", ",", "7", ",", "9", ",", "10", ",", "12", ",", "13", "]", ")", "\n", "", "elif", "source", "==", "'mmpose'", ":", "\n", "            ", "self", ".", "kpsubset", "=", "dict", "(", "\n", "face", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ",", "\n", "torso", "=", "[", "5", ",", "6", ",", "11", ",", "12", "]", ",", "\n", "limb", "=", "[", "7", ",", "8", ",", "9", ",", "10", ",", "13", ",", "14", ",", "15", ",", "16", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Unknown source of Kinetics Pose'", ")", "\n", "\n", "", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "file_client", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.LoadKineticsPose.__call__": [[250, 335], ["results.pop", "results.pop", "pose_loading.LoadKineticsPose.file_client.get", "pickle.loads", "results.pop", "list", "numpy.zeros", "numpy.zeros", "numpy.zeros", "zip", "results.pop", "mmcv.fileio.FileClient", "numpy.unique", "numpy.array", "pose_loading.LoadKineticsPose.__call__.mapinds"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "\n", "        ", "assert", "'filename'", "in", "results", "\n", "filename", "=", "results", ".", "pop", "(", "'filename'", ")", "\n", "\n", "# only applicable to source == 'mmpose'", "\n", "anno_inds", "=", "None", "\n", "if", "'anno_inds'", "in", "results", ":", "\n", "            ", "assert", "self", ".", "source", "==", "'mmpose'", "\n", "anno_inds", "=", "results", ".", "pop", "(", "'anno_inds'", ")", "\n", "", "results", ".", "pop", "(", "'box_score'", ",", "None", ")", "\n", "\n", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "FileClient", "(", "self", ".", "io_backend", ",", "**", "self", ".", "kwargs", ")", "\n", "\n", "", "bytes", "=", "self", ".", "file_client", ".", "get", "(", "filename", ")", "\n", "\n", "# only the kp array is in the pickle file, each kp include x, y, score.", "\n", "kps", "=", "pickle", ".", "loads", "(", "bytes", ")", "\n", "\n", "total_frames", "=", "results", "[", "'total_frames'", "]", "\n", "\n", "frame_inds", "=", "results", ".", "pop", "(", "'frame_inds'", ")", "\n", "\n", "if", "anno_inds", "is", "not", "None", ":", "\n", "            ", "kps", "=", "kps", "[", "anno_inds", "]", "\n", "frame_inds", "=", "frame_inds", "[", "anno_inds", "]", "\n", "\n", "", "frame_inds", "=", "list", "(", "frame_inds", ")", "\n", "\n", "def", "mapinds", "(", "inds", ")", ":", "\n", "            ", "uni", "=", "np", ".", "unique", "(", "inds", ")", "\n", "mapp", "=", "{", "x", ":", "i", "for", "i", ",", "x", "in", "enumerate", "(", "uni", ")", "}", "\n", "inds", "=", "[", "mapp", "[", "x", "]", "for", "x", "in", "inds", "]", "\n", "return", "np", ".", "array", "(", "inds", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "\n", "", "if", "self", ".", "squeeze", ":", "\n", "            ", "frame_inds", "=", "mapinds", "(", "frame_inds", ")", "\n", "total_frames", "=", "np", ".", "max", "(", "frame_inds", ")", "+", "1", "\n", "\n", "# write it back", "\n", "", "results", "[", "'total_frames'", "]", "=", "total_frames", "\n", "\n", "h", ",", "w", "=", "results", "[", "'img_shape'", "]", "\n", "if", "self", ".", "source", "==", "'openpose'", ":", "\n", "            ", "kps", "[", ":", ",", ":", ",", "0", "]", "*=", "w", "\n", "kps", "[", ":", ",", ":", ",", "1", "]", "*=", "h", "\n", "\n", "", "num_kp", "=", "kps", ".", "shape", "[", "1", "]", "\n", "num_person", "=", "mode", "(", "frame_inds", ")", "[", "-", "1", "]", "[", "0", "]", "\n", "\n", "new_kp", "=", "np", ".", "zeros", "(", "[", "num_person", ",", "total_frames", ",", "num_kp", ",", "2", "]", ",", "\n", "dtype", "=", "np", ".", "float16", ")", "\n", "new_kpscore", "=", "np", ".", "zeros", "(", "[", "num_person", ",", "total_frames", ",", "num_kp", "]", ",", "\n", "dtype", "=", "np", ".", "float16", ")", "\n", "# 32768 is enough", "\n", "num_person_frame", "=", "np", ".", "zeros", "(", "[", "total_frames", "]", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "\n", "for", "frame_ind", ",", "kp", "in", "zip", "(", "frame_inds", ",", "kps", ")", ":", "\n", "            ", "person_ind", "=", "num_person_frame", "[", "frame_ind", "]", "\n", "new_kp", "[", "person_ind", ",", "frame_ind", "]", "=", "kp", "[", ":", ",", ":", "2", "]", "\n", "new_kpscore", "[", "person_ind", ",", "frame_ind", "]", "=", "kp", "[", ":", ",", "2", "]", "\n", "num_person_frame", "[", "frame_ind", "]", "+=", "1", "\n", "\n", "", "kpgrp", "=", "self", ".", "kpsubset", "\n", "weight", "=", "self", ".", "keypoint_weight", "\n", "results", "[", "'num_person'", "]", "=", "num_person", "\n", "\n", "if", "num_person", ">", "self", ".", "max_person", ":", "\n", "            ", "for", "i", "in", "range", "(", "total_frames", ")", ":", "\n", "                ", "np_frame", "=", "num_person_frame", "[", "i", "]", "\n", "val", "=", "new_kpscore", "[", ":", "np_frame", ",", "i", "]", "\n", "\n", "val", "=", "(", "\n", "np", ".", "sum", "(", "val", "[", ":", ",", "kpgrp", "[", "'face'", "]", "]", ",", "1", ")", "*", "weight", "[", "'face'", "]", "+", "\n", "np", ".", "sum", "(", "val", "[", ":", ",", "kpgrp", "[", "'torso'", "]", "]", ",", "1", ")", "*", "weight", "[", "'torso'", "]", "+", "\n", "np", ".", "sum", "(", "val", "[", ":", ",", "kpgrp", "[", "'limb'", "]", "]", ",", "1", ")", "*", "weight", "[", "'limb'", "]", ")", "\n", "inds", "=", "sorted", "(", "range", "(", "np_frame", ")", ",", "key", "=", "lambda", "x", ":", "-", "val", "[", "x", "]", ")", "\n", "new_kpscore", "[", ":", "np_frame", ",", "i", "]", "=", "new_kpscore", "[", "inds", ",", "i", "]", "\n", "new_kp", "[", ":", "np_frame", ",", "i", "]", "=", "new_kp", "[", "inds", ",", "i", "]", "\n", "", "results", "[", "'num_person'", "]", "=", "self", ".", "max_person", "\n", "\n", "", "results", "[", "'keypoint'", "]", "=", "new_kp", "[", ":", "self", ".", "max_person", "]", "\n", "results", "[", "'keypoint_score'", "]", "=", "new_kpscore", "[", ":", "self", ".", "max_person", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.LoadKineticsPose.__repr__": [[336, 345], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'io_backend={self.io_backend}, '", "\n", "f'squeeze={self.squeeze}, '", "\n", "f'max_person={self.max_person}, '", "\n", "f'keypoint_weight={self.keypoint_weight}, '", "\n", "f'source={self.source}, '", "\n", "f'kwargs={self.kwargs})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.__init__": [[376, 403], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "sigma", "=", "0.6", ",", "\n", "use_score", "=", "True", ",", "\n", "with_kp", "=", "True", ",", "\n", "with_limb", "=", "False", ",", "\n", "skeletons", "=", "(", "(", "0", ",", "1", ")", ",", "(", "0", ",", "2", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "4", ")", ",", "(", "0", ",", "5", ")", ",", "(", "5", ",", "7", ")", ",", "\n", "(", "7", ",", "9", ")", ",", "(", "0", ",", "6", ")", ",", "(", "6", ",", "8", ")", ",", "(", "8", ",", "10", ")", ",", "(", "5", ",", "11", ")", ",", "(", "11", ",", "13", ")", ",", "\n", "(", "13", ",", "15", ")", ",", "(", "6", ",", "12", ")", ",", "(", "12", ",", "14", ")", ",", "(", "14", ",", "16", ")", ",", "(", "11", ",", "12", ")", ")", ",", "\n", "double", "=", "False", ",", "\n", "left_kp", "=", "(", "1", ",", "3", ",", "5", ",", "7", ",", "9", ",", "11", ",", "13", ",", "15", ")", ",", "\n", "right_kp", "=", "(", "2", ",", "4", ",", "6", ",", "8", ",", "10", ",", "12", ",", "14", ",", "16", ")", ")", ":", "\n", "\n", "        ", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "use_score", "=", "use_score", "\n", "self", ".", "with_kp", "=", "with_kp", "\n", "self", ".", "with_limb", "=", "with_limb", "\n", "self", ".", "double", "=", "double", "\n", "\n", "# an auxiliary const", "\n", "self", ".", "eps", "=", "1e-4", "\n", "\n", "assert", "self", ".", "with_kp", "or", "self", ".", "with_limb", ",", "(", "\n", "'At least one of \"with_limb\" '", "\n", "'and \"with_kp\" should be set as True.'", ")", "\n", "self", ".", "left_kp", "=", "left_kp", "\n", "self", ".", "right_kp", "=", "right_kp", "\n", "self", ".", "skeletons", "=", "skeletons", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_a_heatmap": [[404, 445], ["numpy.zeros", "zip", "max", "min", "max", "min", "numpy.arange", "numpy.arange", "numpy.exp", "numpy.maximum", "int", "int", "int", "int", "len", "len"], "methods", ["None"], ["", "def", "generate_a_heatmap", "(", "self", ",", "img_h", ",", "img_w", ",", "centers", ",", "sigma", ",", "max_values", ")", ":", "\n", "        ", "\"\"\"Generate pseudo heatmap for one keypoint in one frame.\n\n        Args:\n            img_h (int): The height of the heatmap.\n            img_w (int): The width of the heatmap.\n            centers (np.ndarray): The coordinates of corresponding keypoints\n                (of multiple persons).\n            sigma (float): The sigma of generated gaussian.\n            max_values (np.ndarray): The max values of each keypoint.\n\n        Returns:\n            np.ndarray: The generated pseudo heatmap.\n        \"\"\"", "\n", "\n", "heatmap", "=", "np", ".", "zeros", "(", "[", "img_h", ",", "img_w", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "center", ",", "max_value", "in", "zip", "(", "centers", ",", "max_values", ")", ":", "\n", "            ", "mu_x", ",", "mu_y", "=", "center", "[", "0", "]", ",", "center", "[", "1", "]", "\n", "if", "max_value", "<", "self", ".", "eps", ":", "\n", "                ", "continue", "\n", "\n", "", "st_x", "=", "max", "(", "int", "(", "mu_x", "-", "3", "*", "sigma", ")", ",", "0", ")", "\n", "ed_x", "=", "min", "(", "int", "(", "mu_x", "+", "3", "*", "sigma", ")", "+", "1", ",", "img_w", ")", "\n", "st_y", "=", "max", "(", "int", "(", "mu_y", "-", "3", "*", "sigma", ")", ",", "0", ")", "\n", "ed_y", "=", "min", "(", "int", "(", "mu_y", "+", "3", "*", "sigma", ")", "+", "1", ",", "img_h", ")", "\n", "x", "=", "np", ".", "arange", "(", "st_x", ",", "ed_x", ",", "1", ",", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "arange", "(", "st_y", ",", "ed_y", ",", "1", ",", "np", ".", "float32", ")", "\n", "\n", "# if the keypoint not in the heatmap coordinate system", "\n", "if", "not", "(", "len", "(", "x", ")", "and", "len", "(", "y", ")", ")", ":", "\n", "                ", "continue", "\n", "", "y", "=", "y", "[", ":", ",", "None", "]", "\n", "\n", "patch", "=", "np", ".", "exp", "(", "-", "(", "(", "x", "-", "mu_x", ")", "**", "2", "+", "(", "y", "-", "mu_y", ")", "**", "2", ")", "/", "2", "/", "sigma", "**", "2", ")", "\n", "patch", "=", "patch", "*", "max_value", "\n", "heatmap", "[", "st_y", ":", "ed_y", ",", "\n", "st_x", ":", "ed_x", "]", "=", "np", ".", "maximum", "(", "heatmap", "[", "st_y", ":", "ed_y", ",", "st_x", ":", "ed_x", "]", ",", "\n", "patch", ")", "\n", "\n", "", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_a_limb_heatmap": [[446, 531], ["numpy.zeros", "zip", "min", "max", "min", "max", "min", "numpy.arange", "numpy.arange", "numpy.zeros_like", "numpy.zeros_like", "numpy.stack", "numpy.exp", "numpy.maximum", "min", "max", "min", "max", "int", "int", "pose_loading.GeneratePoseTarget.generate_a_heatmap", "numpy.maximum", "int", "int", "len", "len", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_a_heatmap"], ["", "def", "generate_a_limb_heatmap", "(", "self", ",", "img_h", ",", "img_w", ",", "starts", ",", "ends", ",", "sigma", ",", "\n", "start_values", ",", "end_values", ")", ":", "\n", "        ", "\"\"\"Generate pseudo heatmap for one limb in one frame.\n\n        Args:\n            img_h (int): The height of the heatmap.\n            img_w (int): The width of the heatmap.\n            starts (np.ndarray): The coordinates of one keypoint in the\n                corresponding limbs (of multiple persons).\n            ends (np.ndarray): The coordinates of the other keypoint in the\n                corresponding limbs (of multiple persons).\n            sigma (float): The sigma of generated gaussian.\n            start_values (np.ndarray): The max values of one keypoint in the\n                corresponding limbs.\n            end_values (np.ndarray): The max values of the other keypoint in\n                the corresponding limbs.\n\n        Returns:\n            np.ndarray: The generated pseudo heatmap.\n        \"\"\"", "\n", "\n", "heatmap", "=", "np", ".", "zeros", "(", "[", "img_h", ",", "img_w", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "start", ",", "end", ",", "start_value", ",", "end_value", "in", "zip", "(", "starts", ",", "ends", ",", "\n", "start_values", ",", "\n", "end_values", ")", ":", "\n", "            ", "value_coeff", "=", "min", "(", "start_value", ",", "end_value", ")", "\n", "if", "value_coeff", "<", "self", ".", "eps", ":", "\n", "                ", "continue", "\n", "\n", "", "min_x", ",", "max_x", "=", "min", "(", "start", "[", "0", "]", ",", "end", "[", "0", "]", ")", ",", "max", "(", "start", "[", "0", "]", ",", "end", "[", "0", "]", ")", "\n", "min_y", ",", "max_y", "=", "min", "(", "start", "[", "1", "]", ",", "end", "[", "1", "]", ")", ",", "max", "(", "start", "[", "1", "]", ",", "end", "[", "1", "]", ")", "\n", "\n", "min_x", "=", "max", "(", "int", "(", "min_x", "-", "3", "*", "sigma", ")", ",", "0", ")", "\n", "max_x", "=", "min", "(", "int", "(", "max_x", "+", "3", "*", "sigma", ")", "+", "1", ",", "img_w", ")", "\n", "min_y", "=", "max", "(", "int", "(", "min_y", "-", "3", "*", "sigma", ")", ",", "0", ")", "\n", "max_y", "=", "min", "(", "int", "(", "max_y", "+", "3", "*", "sigma", ")", "+", "1", ",", "img_h", ")", "\n", "\n", "x", "=", "np", ".", "arange", "(", "min_x", ",", "max_x", ",", "1", ",", "np", ".", "float32", ")", "\n", "y", "=", "np", ".", "arange", "(", "min_y", ",", "max_y", ",", "1", ",", "np", ".", "float32", ")", "\n", "\n", "if", "not", "(", "len", "(", "x", ")", "and", "len", "(", "y", ")", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "y", "=", "y", "[", ":", ",", "None", "]", "\n", "x_0", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "y_0", "=", "np", ".", "zeros_like", "(", "y", ")", "\n", "\n", "# distance to start keypoints", "\n", "d2_start", "=", "(", "(", "x", "-", "start", "[", "0", "]", ")", "**", "2", "+", "(", "y", "-", "start", "[", "1", "]", ")", "**", "2", ")", "\n", "\n", "# distance to end keypoints", "\n", "d2_end", "=", "(", "(", "x", "-", "end", "[", "0", "]", ")", "**", "2", "+", "(", "y", "-", "end", "[", "1", "]", ")", "**", "2", ")", "\n", "\n", "# the distance between start and end keypoints.", "\n", "d2_ab", "=", "(", "(", "start", "[", "0", "]", "-", "end", "[", "0", "]", ")", "**", "2", "+", "(", "start", "[", "1", "]", "-", "end", "[", "1", "]", ")", "**", "2", ")", "\n", "\n", "if", "d2_ab", "<", "1", ":", "\n", "                ", "full_map", "=", "self", ".", "generate_a_heatmap", "(", "img_h", ",", "img_w", ",", "[", "start", "]", ",", "\n", "sigma", ",", "[", "start_value", "]", ")", "\n", "heatmap", "=", "np", ".", "maximum", "(", "heatmap", ",", "full_map", ")", "\n", "continue", "\n", "\n", "", "coeff", "=", "(", "d2_start", "-", "d2_end", "+", "d2_ab", ")", "/", "2.", "/", "d2_ab", "\n", "\n", "a_dominate", "=", "coeff", "<=", "0", "\n", "b_dominate", "=", "coeff", ">=", "1", "\n", "seg_dominate", "=", "1", "-", "a_dominate", "-", "b_dominate", "\n", "\n", "position", "=", "np", ".", "stack", "(", "[", "x", "+", "y_0", ",", "y", "+", "x_0", "]", ",", "axis", "=", "-", "1", ")", "\n", "projection", "=", "start", "+", "np", ".", "stack", "(", "[", "coeff", ",", "coeff", "]", ",", "axis", "=", "-", "1", ")", "*", "(", "\n", "end", "-", "start", ")", "\n", "d2_line", "=", "position", "-", "projection", "\n", "d2_line", "=", "d2_line", "[", ":", ",", ":", ",", "0", "]", "**", "2", "+", "d2_line", "[", ":", ",", ":", ",", "1", "]", "**", "2", "\n", "d2_seg", "=", "(", "\n", "a_dominate", "*", "d2_start", "+", "b_dominate", "*", "d2_end", "+", "\n", "seg_dominate", "*", "d2_line", ")", "\n", "\n", "patch", "=", "np", ".", "exp", "(", "-", "d2_seg", "/", "2.", "/", "sigma", "**", "2", ")", "\n", "patch", "=", "patch", "*", "value_coeff", "\n", "\n", "heatmap", "[", "min_y", ":", "max_y", ",", "min_x", ":", "max_x", "]", "=", "np", ".", "maximum", "(", "\n", "heatmap", "[", "min_y", ":", "max_y", ",", "min_x", ":", "max_x", "]", ",", "patch", ")", "\n", "\n", "", "return", "heatmap", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_heatmap": [[532, 570], ["numpy.stack", "range", "pose_loading.GeneratePoseTarget.generate_a_heatmap", "heatmaps.append", "pose_loading.GeneratePoseTarget.generate_a_limb_heatmap", "heatmaps.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_a_heatmap", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_a_limb_heatmap"], ["", "def", "generate_heatmap", "(", "self", ",", "img_h", ",", "img_w", ",", "kps", ",", "sigma", ",", "max_values", ")", ":", "\n", "        ", "\"\"\"Generate pseudo heatmap for all keypoints and limbs in one frame (if\n        needed).\n\n        Args:\n            img_h (int): The height of the heatmap.\n            img_w (int): The width of the heatmap.\n            kps (np.ndarray): The coordinates of keypoints in this frame.\n            sigma (float): The sigma of generated gaussian.\n            max_values (np.ndarray): The confidence score of each keypoint.\n\n        Returns:\n            np.ndarray: The generated pseudo heatmap.\n        \"\"\"", "\n", "\n", "heatmaps", "=", "[", "]", "\n", "if", "self", ".", "with_kp", ":", "\n", "            ", "num_kp", "=", "kps", ".", "shape", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "num_kp", ")", ":", "\n", "                ", "heatmap", "=", "self", ".", "generate_a_heatmap", "(", "img_h", ",", "img_w", ",", "kps", "[", ":", ",", "i", "]", ",", "\n", "sigma", ",", "max_values", "[", ":", ",", "i", "]", ")", "\n", "heatmaps", ".", "append", "(", "heatmap", ")", "\n", "\n", "", "", "if", "self", ".", "with_limb", ":", "\n", "            ", "for", "limb", "in", "self", ".", "skeletons", ":", "\n", "                ", "start_idx", ",", "end_idx", "=", "limb", "\n", "starts", "=", "kps", "[", ":", ",", "start_idx", "]", "\n", "ends", "=", "kps", "[", ":", ",", "end_idx", "]", "\n", "\n", "start_values", "=", "max_values", "[", ":", ",", "start_idx", "]", "\n", "end_values", "=", "max_values", "[", ":", ",", "end_idx", "]", "\n", "heatmap", "=", "self", ".", "generate_a_limb_heatmap", "(", "img_h", ",", "img_w", ",", "starts", ",", "\n", "ends", ",", "sigma", ",", "\n", "start_values", ",", "\n", "end_values", ")", "\n", "heatmaps", ".", "append", "(", "heatmap", ")", "\n", "\n", "", "", "return", "np", ".", "stack", "(", "heatmaps", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.gen_an_aug": [[571, 606], ["range", "numpy.ones", "numpy.ones", "pose_loading.GeneratePoseTarget.generate_heatmap", "imgs.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.generate_heatmap"], ["", "def", "gen_an_aug", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Generate pseudo heatmaps for all frames.\n\n        Args:\n            results (dict): The dictionary that contains all info of a sample.\n\n        Returns:\n            list[np.ndarray]: The generated pseudo heatmaps.\n        \"\"\"", "\n", "\n", "all_kps", "=", "results", "[", "'keypoint'", "]", "\n", "kp_shape", "=", "all_kps", ".", "shape", "\n", "\n", "if", "'keypoint_score'", "in", "results", ":", "\n", "            ", "all_kpscores", "=", "results", "[", "'keypoint_score'", "]", "\n", "", "else", ":", "\n", "            ", "all_kpscores", "=", "np", ".", "ones", "(", "kp_shape", "[", ":", "-", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "img_h", ",", "img_w", "=", "results", "[", "'img_shape'", "]", "\n", "num_frame", "=", "kp_shape", "[", "1", "]", "\n", "\n", "imgs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_frame", ")", ":", "\n", "            ", "sigma", "=", "self", ".", "sigma", "\n", "kps", "=", "all_kps", "[", ":", ",", "i", "]", "\n", "kpscores", "=", "all_kpscores", "[", ":", ",", "i", "]", "\n", "\n", "max_values", "=", "np", ".", "ones", "(", "kpscores", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "self", ".", "use_score", ":", "\n", "                ", "max_values", "=", "kpscores", "\n", "\n", "", "hmap", "=", "self", ".", "generate_heatmap", "(", "img_h", ",", "img_w", ",", "kps", ",", "sigma", ",", "max_values", ")", "\n", "imgs", ".", "append", "(", "hmap", ")", "\n", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.__call__": [[607, 619], ["numpy.stack", "copy.deepcopy", "augmentations.Flip", "augmentations.Flip.", "numpy.concatenate", "pose_loading.GeneratePoseTarget.gen_an_aug", "pose_loading.GeneratePoseTarget.gen_an_aug", "pose_loading.GeneratePoseTarget.gen_an_aug"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.gen_an_aug", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.gen_an_aug", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.gen_an_aug"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "if", "not", "self", ".", "double", ":", "\n", "            ", "results", "[", "'imgs'", "]", "=", "np", ".", "stack", "(", "self", ".", "gen_an_aug", "(", "results", ")", ")", "\n", "", "else", ":", "\n", "            ", "results_", "=", "cp", ".", "deepcopy", "(", "results", ")", "\n", "flip", "=", "Flip", "(", "\n", "flip_ratio", "=", "1", ",", "left_kp", "=", "self", ".", "left_kp", ",", "right_kp", "=", "self", ".", "right_kp", ")", "\n", "results_", "=", "flip", "(", "results_", ")", "\n", "results", "[", "'imgs'", "]", "=", "np", ".", "concatenate", "(", "\n", "[", "self", ".", "gen_an_aug", "(", "results", ")", ",", "\n", "self", ".", "gen_an_aug", "(", "results_", ")", "]", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.pose_loading.GeneratePoseTarget.__repr__": [[620, 631], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "(", "f'{self.__class__.__name__}('", "\n", "f'sigma={self.sigma}, '", "\n", "f'use_score={self.use_score}, '", "\n", "f'with_kp={self.with_kp}, '", "\n", "f'with_limb={self.with_limb}, '", "\n", "f'skeletons={self.skeletons}, '", "\n", "f'double={self.double}, '", "\n", "f'left_kp={self.left_kp}, '", "\n", "f'right_kp={self.right_kp})'", ")", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.compose.Compose.__init__": [[17, 28], ["isinstance", "isinstance", "mmcv.utils.build_from_cfg", "compose.Compose.transforms.append", "callable", "compose.Compose.transforms.append", "TypeError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "assert", "isinstance", "(", "transforms", ",", "Sequence", ")", "\n", "self", ".", "transforms", "=", "[", "]", "\n", "for", "transform", "in", "transforms", ":", "\n", "            ", "if", "isinstance", "(", "transform", ",", "dict", ")", ":", "\n", "                ", "transform", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "self", ".", "transforms", ".", "append", "(", "transform", ")", "\n", "", "elif", "callable", "(", "transform", ")", ":", "\n", "                ", "self", ".", "transforms", ".", "append", "(", "transform", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "f'transform must be callable or a dict, '", "\n", "f'but got {type(transform)}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.compose.Compose.__call__": [[30, 45], ["t"], "methods", ["None"], ["", "", "", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"Call function to apply transforms sequentially.\n\n        Args:\n            data (dict): A result dict contains the data to transform.\n\n        Returns:\n            dict: Transformed data.\n        \"\"\"", "\n", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "data", "=", "t", "(", "data", ")", "\n", "if", "data", "is", "None", ":", "\n", "                ", "return", "None", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.compose.Compose.__repr__": [[46, 53], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer": [[16, 57], ["isinstance", "mmaction.models.build_recognizer", "mmaction.models.build_recognizer.to", "mmaction.models.build_recognizer.eval", "mmcv.Config.fromfile", "RuntimeError", "mmcv.runner.load_checkpoint", "isinstance", "TypeError", "mmcv.Config.fromfile.get", "type"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["def", "init_recognizer", "(", "config", ",", "\n", "checkpoint", "=", "None", ",", "\n", "device", "=", "'cuda:0'", ",", "\n", "use_frames", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initialize a recognizer from config file.\n\n    Args:\n        config (str | :obj:`mmcv.Config`): Config file path or the config\n            object.\n        checkpoint (str | None, optional): Checkpoint path/url. If set to None,\n            the model will not load any weights. Default: None.\n        device (str | :obj:`torch.device`): The desired device of returned\n            tensor. Default: 'cuda:0'.\n        use_frames (bool): Whether to use rawframes as input. Default:False.\n\n    Returns:\n        nn.Module: The constructed recognizer.\n    \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "str", ")", ":", "\n", "        ", "config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "config", ")", "\n", "", "elif", "not", "isinstance", "(", "config", ",", "mmcv", ".", "Config", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'config must be a filename or Config object, '", "\n", "f'but got {type(config)}'", ")", "\n", "", "if", "(", "(", "use_frames", "and", "config", ".", "dataset_type", "!=", "'RawframeDataset'", ")", "\n", "or", "(", "not", "use_frames", "and", "config", ".", "dataset_type", "!=", "'VideoDataset'", ")", ")", ":", "\n", "        ", "input_type", "=", "'rawframes'", "if", "use_frames", "else", "'video'", "\n", "raise", "RuntimeError", "(", "'input data type should be consist with the '", "\n", "f'dataset type in config, but got input type '", "\n", "f\"'{input_type}' and dataset type \"", "\n", "f\"'{config.dataset_type}'\"", ")", "\n", "\n", "# pretrained model is unnecessary since we directly load checkpoint later", "\n", "", "config", ".", "model", ".", "backbone", ".", "pretrained", "=", "None", "\n", "model", "=", "build_recognizer", "(", "config", ".", "model", ",", "test_cfg", "=", "config", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "load_checkpoint", "(", "model", ",", "checkpoint", ",", "map_location", "=", "device", ")", "\n", "", "model", ".", "cfg", "=", "config", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer": [[59, 157], ["isinstance", "mmaction.datasets.pipelines.Compose", "mmaction.datasets.pipelines.Compose.", "mmcv.parallel.collate", "tuple", "sorted", "RuntimeError", "os.isfile", "RuntimeError", "os.isdir", "RuntimeError", "isinstance", "next", "open", "cfg.data.test.get", "cfg.data.test.get", "cfg.data.test.get", "pattern.replace.replace", "len", "dict", "cfg.data.test.get", "dict", "next", "mmaction.core.OutputHook", "zip", "os.exists", "video_path.startswith", "model.parameters", "line.strip", "pattern.replace.replace", "list", "model.parameters", "mmcv.parallel.scatter", "torch.no_grad", "operator.itemgetter", "filter", "model", "pattern.replace.find", "os.listdir", "os.listdir", "pattern.replace.find", "re.match"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "inference_recognizer", "(", "model", ",", "\n", "video_path", ",", "\n", "label_path", ",", "\n", "use_frames", "=", "False", ",", "\n", "outputs", "=", "None", ",", "\n", "as_tensor", "=", "True", ")", ":", "\n", "    ", "\"\"\"Inference a video with the detector.\n\n    Args:\n        model (nn.Module): The loaded recognizer.\n        video_path (str): The video file path/url or the rawframes directory\n            path. If ``use_frames`` is set to True, it should be rawframes\n            directory path. Otherwise, it should be video file path.\n        label_path (str): The label file path.\n        use_frames (bool): Whether to use rawframes as input. Default:False.\n        outputs (list(str) | tuple(str) | str | None) : Names of layers whose\n            outputs need to be returned, default: None.\n        as_tensor (bool): Same as that in ``OutputHook``. Default: True.\n\n    Returns:\n        dict[tuple(str, float)]: Top-5 recognition result dict.\n        dict[torch.tensor | np.ndarray]:\n            Output feature maps from layers specified in `outputs`.\n    \"\"\"", "\n", "if", "not", "(", "osp", ".", "exists", "(", "video_path", ")", "or", "video_path", ".", "startswith", "(", "'http'", ")", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"'{video_path}' is missing\"", ")", "\n", "\n", "", "if", "osp", ".", "isfile", "(", "video_path", ")", "and", "use_frames", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"'{video_path}' is a video file, not a rawframe directory\"", ")", "\n", "", "if", "osp", ".", "isdir", "(", "video_path", ")", "and", "not", "use_frames", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"'{video_path}' is a rawframe directory, not a video file\"", ")", "\n", "\n", "", "if", "isinstance", "(", "outputs", ",", "str", ")", ":", "\n", "        ", "outputs", "=", "(", "outputs", ",", ")", "\n", "", "assert", "outputs", "is", "None", "or", "isinstance", "(", "outputs", ",", "(", "tuple", ",", "list", ")", ")", "\n", "\n", "cfg", "=", "model", ".", "cfg", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# model device", "\n", "# construct label map", "\n", "with", "open", "(", "label_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "# build the data pipeline", "\n", "", "test_pipeline", "=", "cfg", ".", "data", ".", "test", ".", "pipeline", "\n", "test_pipeline", "=", "Compose", "(", "test_pipeline", ")", "\n", "# prepare data", "\n", "if", "use_frames", ":", "\n", "        ", "filename_tmpl", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'filename_tmpl'", ",", "'img_{:05}.jpg'", ")", "\n", "modality", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'modality'", ",", "'RGB'", ")", "\n", "start_index", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'start_index'", ",", "1", ")", "\n", "\n", "# count the number of frames that match the format of `filename_tmpl`", "\n", "# RGB pattern example: img_{:05}.jpg -> ^img_\\d+.jpg$", "\n", "# Flow patteren example: {}_{:05d}.jpg -> ^x_\\d+.jpg$", "\n", "pattern", "=", "f'^{filename_tmpl}$'", "\n", "if", "modality", "==", "'Flow'", ":", "\n", "            ", "pattern", "=", "pattern", ".", "replace", "(", "'{}'", ",", "'x'", ")", "\n", "", "pattern", "=", "pattern", ".", "replace", "(", "\n", "pattern", "[", "pattern", ".", "find", "(", "'{'", ")", ":", "pattern", ".", "find", "(", "'}'", ")", "+", "1", "]", ",", "'\\\\d+'", ")", "\n", "total_frames", "=", "len", "(", "\n", "list", "(", "\n", "filter", "(", "lambda", "x", ":", "re", ".", "match", "(", "pattern", ",", "x", ")", "is", "not", "None", ",", "\n", "os", ".", "listdir", "(", "video_path", ")", ")", ")", ")", "\n", "\n", "data", "=", "dict", "(", "\n", "frame_dir", "=", "video_path", ",", "\n", "total_frames", "=", "total_frames", ",", "\n", "label", "=", "-", "1", ",", "\n", "start_index", "=", "start_index", ",", "\n", "filename_tmpl", "=", "filename_tmpl", ",", "\n", "modality", "=", "modality", ")", "\n", "", "else", ":", "\n", "        ", "start_index", "=", "cfg", ".", "data", ".", "test", ".", "get", "(", "'start_index'", ",", "0", ")", "\n", "data", "=", "dict", "(", "\n", "filename", "=", "video_path", ",", "\n", "label", "=", "-", "1", ",", "\n", "start_index", "=", "start_index", ",", "\n", "modality", "=", "'RGB'", ")", "\n", "", "data", "=", "test_pipeline", "(", "data", ")", "\n", "data", "=", "collate", "(", "[", "data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "# scatter to specified GPU", "\n", "        ", "data", "=", "scatter", "(", "data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "\n", "# forward the model", "\n", "", "with", "OutputHook", "(", "model", ",", "outputs", "=", "outputs", ",", "as_tensor", "=", "as_tensor", ")", "as", "h", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "model", "(", "return_loss", "=", "False", ",", "**", "data", ")", "[", "0", "]", "\n", "", "returned_features", "=", "h", ".", "layer_outputs", "if", "outputs", "else", "None", "\n", "\n", "", "score_tuples", "=", "tuple", "(", "zip", "(", "label", ",", "scores", ")", ")", "\n", "score_sorted", "=", "sorted", "(", "score_tuples", ",", "key", "=", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "top5_label", "=", "score_sorted", "[", ":", "5", "]", "\n", "if", "outputs", ":", "\n", "        ", "return", "top5_label", ",", "returned_features", "\n", "", "return", "top5_label", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model": [[20, 262], ["dict", "utils.get_root_logger", "dict", "dict", "mmcv.runner.build_optimizer", "cfg.get", "Runner.register_training_hooks", "cfg.get", "dict", "Runner.run", "isinstance", "cfg.data.get", "cfg.data.get", "cfg.optimizer_config.get", "cfg.optimizer_config.get", "cfg.get", "mmcv.parallel.MMDistributedDataParallel", "mmcv.parallel.MMDataParallel", "Runner", "Runner", "mmcv.runner.hooks.Fp16OptimizerHook", "cfg.get", "datasets.build_dataset", "dict", "datasets.build_dataloader", "utils.PreciseBNHook", "Runner.register_hook", "cfg.get", "datasets.build_dataset", "dict", "dict", "datasets.build_dataloader", "Runner.register_hook", "Runner.resume", "dict", "datasets.build_dataset", "cfg.get().get", "cfg.get().get", "dict", "dict", "datasets.build_dataloader", "zip", "cfg.data.get", "len", "cfg.data.get", "datasets.build_dataloader", "datasets.build_dataloader", "apex.amp.initialize", "mmcv.parallel.MMDataParallel.modules", "mmcv.parallel.MMDataParallel.cuda", "mmcv.parallel.MMDataParallel.cuda", "mmcv.runner.OptimizerHook", "Runner.register_hook", "Runner.register_hook", "dict", "eval_hook", "cfg.get", "os.exists", "Runner.auto_resume", "hasattr", "dict", "os.join", "names.append", "ckpts.append", "names.append", "ckpts.append", "test.multi_gpu_test", "mmcv.runner.get_dist_info", "cfg.data.get", "cfg.optimizer_config.get", "len", "len", "copy.deepcopy", "dataloader_settings.append", "zip", "mmcv.parallel.MMDataParallel.cuda", "hasattr", "core.OmniSourceDistSamplerSeedHook", "mmcv.runner.DistSamplerSeedHook", "cfg.data.get", "len", "cfg.get", "cfg.data.get", "cfg.data.get", "len", "cfg.data.get", "os.join", "Runner.load_checkpoint", "cfg.get", "cfg.get", "cfg.data.get", "cfg.data.get", "len", "cfg.data.get", "Runner.load_checkpoint", "os.join", "datasets.build_dataset.dump_results", "cfg.get", "datasets.build_dataset.evaluate", "Runner.logger.info", "test_dataset.evaluate.items", "torch.cuda.current_device", "os.exists", "Runner.logger.info", "Runner.logger.info", "cfg.get.pop", "Runner.logger.info"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.resume", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.auto_resume", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.dump_results", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["\n", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a recognizer'", ")", "\n", "parser", ".", "add_argument", "(", "'config'", ",", "help", "=", "'train config file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--work-dir'", ",", "help", "=", "'the dir to save logs and models'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume-from'", ",", "help", "=", "'the checkpoint file to resume from'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--validate'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to evaluate the checkpoint during training'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test-last'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to test the checkpoint after training'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test-best'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "(", "'whether to test the best checkpoint (if applicable) after '", "\n", "'training'", ")", ")", "\n", "group_gpus", "=", "parser", ".", "add_mutually_exclusive_group", "(", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpus'", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'number of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "group_gpus", ".", "add_argument", "(", "\n", "'--gpu-ids'", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "'+'", ",", "\n", "help", "=", "'ids of gpus to use '", "\n", "'(only applicable to non-distributed training)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--deterministic'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'whether to set deterministic options for CUDNN backend.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg-options'", ",", "\n", "nargs", "=", "'+'", ",", "\n", "action", "=", "DictAction", ",", "\n", "default", "=", "{", "}", ",", "\n", "help", "=", "'override some settings in the used config, the key-value pair '", "\n", "'in xxx=yyy format will be merged into config file. For example, '", "\n", "\"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--launcher'", ",", "\n", "choices", "=", "[", "'none'", ",", "'pytorch'", ",", "'slurm'", ",", "'mpi'", "]", ",", "\n", "default", "=", "'none'", ",", "\n", "help", "=", "'job launcher'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "'LOCAL_RANK'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "\n", "", "return", "args", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "cfg", "=", "Config", ".", "fromfile", "(", "args", ".", "config", ")", "\n", "\n", "cfg", ".", "merge_from_dict", "(", "args", ".", "cfg_options", ")", "\n", "\n", "# set cudnn_benchmark", "\n", "if", "cfg", ".", "get", "(", "'cudnn_benchmark'", ",", "False", ")", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# work_dir is determined in this priority:", "\n", "# CLI > config file > default (base filename)", "\n", "", "if", "args", ".", "work_dir", "is", "not", "None", ":", "\n", "# update configs according to CLI args if args.work_dir is not None", "\n", "        ", "cfg", ".", "work_dir", "=", "args", ".", "work_dir", "\n", "", "elif", "cfg", ".", "get", "(", "'work_dir'", ",", "None", ")", "is", "None", ":", "\n", "# use config filename as default work_dir if cfg.work_dir is None", "\n", "        ", "cfg", ".", "work_dir", "=", "osp", ".", "join", "(", "'./work_dirs'", ",", "\n", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", "[", "0", "]", ")", "\n", "", "if", "args", ".", "resume_from", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "resume_from", "=", "args", ".", "resume_from", "\n", "", "if", "args", ".", "gpu_ids", "is", "not", "None", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "args", ".", "gpu_ids", "\n", "", "else", ":", "\n", "        ", "cfg", ".", "gpu_ids", "=", "range", "(", "1", ")", "if", "args", ".", "gpus", "is", "None", "else", "range", "(", "args", ".", "gpus", ")", "\n", "\n", "# init distributed env first, since logger depends on the dist info.", "\n", "", "if", "args", ".", "launcher", "==", "'none'", ":", "\n", "        ", "distributed", "=", "False", "\n", "", "else", ":", "\n", "        ", "distributed", "=", "True", "\n", "init_dist", "(", "args", ".", "launcher", ",", "**", "cfg", ".", "dist_params", ")", "\n", "_", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "cfg", ".", "gpu_ids", "=", "range", "(", "world_size", ")", "\n", "\n", "# The flag is used to determine whether it is omnisource training", "\n", "", "cfg", ".", "setdefault", "(", "'omnisource'", ",", "False", ")", "\n", "\n", "# The flag is used to register module's hooks", "\n", "cfg", ".", "setdefault", "(", "'module_hooks'", ",", "[", "]", ")", "\n", "\n", "# create work_dir", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "abspath", "(", "cfg", ".", "work_dir", ")", ")", "\n", "# dump config", "\n", "cfg", ".", "dump", "(", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "osp", ".", "basename", "(", "args", ".", "config", ")", ")", ")", "\n", "# init logger before other steps", "\n", "timestamp", "=", "time", ".", "strftime", "(", "'%Y%m%d_%H%M%S'", ",", "time", ".", "localtime", "(", ")", ")", "\n", "log_file", "=", "osp", ".", "join", "(", "cfg", ".", "work_dir", ",", "f'{timestamp}.log'", ")", "\n", "logger", "=", "get_root_logger", "(", "log_file", "=", "log_file", ",", "log_level", "=", "cfg", ".", "log_level", ")", "\n", "\n", "# init the meta dict to record some important information such as", "\n", "# environment info and seed, which will be logged", "\n", "meta", "=", "dict", "(", ")", "\n", "# log env info", "\n", "env_info_dict", "=", "collect_env", "(", ")", "\n", "env_info", "=", "'\\n'", ".", "join", "(", "[", "f'{k}: {v}'", "for", "k", ",", "v", "in", "env_info_dict", ".", "items", "(", ")", "]", ")", "\n", "dash_line", "=", "'-'", "*", "60", "+", "'\\n'", "\n", "logger", ".", "info", "(", "'Environment info:\\n'", "+", "dash_line", "+", "env_info", "+", "'\\n'", "+", "\n", "dash_line", ")", "\n", "meta", "[", "'env_info'", "]", "=", "env_info", "\n", "\n", "# log some basic info", "\n", "logger", ".", "info", "(", "f'Distributed training: {distributed}'", ")", "\n", "logger", ".", "info", "(", "f'Config: {cfg.pretty_text}'", ")", "\n", "\n", "# set random seeds", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "f'Set random seed to {args.seed}, '", "\n", "f'deterministic: {args.deterministic}'", ")", "\n", "set_random_seed", "(", "args", ".", "seed", ",", "deterministic", "=", "args", ".", "deterministic", ")", "\n", "", "cfg", ".", "seed", "=", "args", ".", "seed", "\n", "meta", "[", "'seed'", "]", "=", "args", ".", "seed", "\n", "meta", "[", "'config_name'", "]", "=", "osp", ".", "basename", "(", "args", ".", "config", ")", "\n", "meta", "[", "'work_dir'", "]", "=", "osp", ".", "basename", "(", "cfg", ".", "work_dir", ".", "rstrip", "(", "'/\\\\'", ")", ")", "\n", "\n", "model", "=", "build_model", "(", "\n", "cfg", ".", "model", ",", "\n", "train_cfg", "=", "cfg", ".", "get", "(", "'train_cfg'", ")", ",", "\n", "test_cfg", "=", "cfg", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "\n", "if", "len", "(", "cfg", ".", "module_hooks", ")", ">", "0", ":", "\n", "        ", "register_module_hooks", "(", "model", ",", "cfg", ".", "module_hooks", ")", "\n", "\n", "", "if", "cfg", ".", "omnisource", ":", "\n", "# If omnisource flag is set, cfg.data.train should be a list", "\n", "        ", "assert", "isinstance", "(", "cfg", ".", "data", ".", "train", ",", "list", ")", "\n", "datasets", "=", "[", "build_dataset", "(", "dataset", ")", "for", "dataset", "in", "cfg", ".", "data", ".", "train", "]", "\n", "", "else", ":", "\n", "        ", "datasets", "=", "[", "build_dataset", "(", "cfg", ".", "data", ".", "train", ")", "]", "\n", "\n", "", "if", "len", "(", "cfg", ".", "workflow", ")", "==", "2", ":", "\n", "# For simplicity, omnisource is not compatiable with val workflow,", "\n", "# we recommend you to use `--validate`", "\n", "        ", "assert", "not", "cfg", ".", "omnisource", "\n", "if", "args", ".", "validate", ":", "\n", "            ", "warnings", ".", "warn", "(", "'val workflow is duplicated with `--validate`, '", "\n", "'it is recommended to use `--validate`. see '", "\n", "'https://github.com/open-mmlab/mmaction2/pull/123'", ")", "\n", "", "val_dataset", "=", "copy", ".", "deepcopy", "(", "cfg", ".", "data", ".", "val", ")", "\n", "datasets", ".", "append", "(", "build_dataset", "(", "val_dataset", ")", ")", "\n", "", "if", "cfg", ".", "checkpoint_config", "is", "not", "None", ":", "\n", "# save mmaction version, config file content and class names in", "\n", "# checkpoints as meta data", "\n", "        ", "cfg", ".", "checkpoint_config", ".", "meta", "=", "dict", "(", "\n", "mmaction_version", "=", "__version__", "+", "get_git_hash", "(", "digits", "=", "7", ")", ",", "\n", "config", "=", "cfg", ".", "pretty_text", ")", "\n", "\n", "", "test_option", "=", "dict", "(", "test_last", "=", "args", ".", "test_last", ",", "test_best", "=", "args", ".", "test_best", ")", "\n", "train_model", "(", "\n", "model", ",", "\n", "datasets", ",", "\n", "cfg", ",", "\n", "distributed", "=", "distributed", ",", "\n", "validate", "=", "args", ".", "validate", ",", "\n", "test", "=", "test_option", ",", "\n", "timestamp", "=", "timestamp", ",", "\n", "meta", "=", "meta", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou": [[4, 23], ["numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.divide"], "function", ["None"], ["def", "temporal_iou", "(", "proposal_min", ",", "proposal_max", ",", "gt_min", ",", "gt_max", ")", ":", "\n", "    ", "\"\"\"Compute IoU score between a groundtruth bbox and the proposals.\n\n    Args:\n        proposal_min (list[float]): List of temporal anchor min.\n        proposal_max (list[float]): List of temporal anchor max.\n        gt_min (float): Groundtruth temporal box min.\n        gt_max (float): Groundtruth temporal box max.\n\n    Returns:\n        list[float]: List of iou scores.\n    \"\"\"", "\n", "len_anchors", "=", "proposal_max", "-", "proposal_min", "\n", "int_tmin", "=", "np", ".", "maximum", "(", "proposal_min", ",", "gt_min", ")", "\n", "int_tmax", "=", "np", ".", "minimum", "(", "proposal_max", ",", "gt_max", ")", "\n", "inter_len", "=", "np", ".", "maximum", "(", "int_tmax", "-", "int_tmin", ",", "0.", ")", "\n", "union_len", "=", "len_anchors", "-", "inter_len", "+", "gt_max", "-", "gt_min", "\n", "jaccard", "=", "np", ".", "divide", "(", "inter_len", ",", "union_len", ")", "\n", "return", "jaccard", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop": [[25, 46], ["numpy.array", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.divide"], "function", ["None"], ["", "def", "temporal_iop", "(", "proposal_min", ",", "proposal_max", ",", "gt_min", ",", "gt_max", ")", ":", "\n", "    ", "\"\"\"Compute IoP score between a groundtruth bbox and the proposals.\n\n    Compute the IoP which is defined as the overlap ratio with\n    groundtruth proportional to the duration of this proposal.\n\n    Args:\n        proposal_min (list[float]): List of temporal anchor min.\n        proposal_max (list[float]): List of temporal anchor max.\n        gt_min (float): Groundtruth temporal box min.\n        gt_max (float): Groundtruth temporal box max.\n\n    Returns:\n        list[float]: List of intersection over anchor scores.\n    \"\"\"", "\n", "len_anchors", "=", "np", ".", "array", "(", "proposal_max", "-", "proposal_min", ")", "\n", "int_tmin", "=", "np", ".", "maximum", "(", "proposal_min", ",", "gt_min", ")", "\n", "int_tmax", "=", "np", ".", "minimum", "(", "proposal_max", ",", "gt_max", ")", "\n", "inter_len", "=", "np", ".", "maximum", "(", "int_tmax", "-", "int_tmin", ",", "0.", ")", "\n", "scores", "=", "np", ".", "divide", "(", "inter_len", ",", "len_anchors", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.soft_nms": [[48, 95], ["list", "list", "list", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "numpy.concatenate", "numpy.argmax", "proposal_utils.temporal_iou", "numpy.exp", "enumerate", "np.array().reshape.append", "np.array().reshape.append", "np.array().reshape.append", "list.pop", "list.pop", "list.pop", "len", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "proposals[].argsort", "numpy.square"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou"], ["", "def", "soft_nms", "(", "proposals", ",", "alpha", ",", "low_threshold", ",", "high_threshold", ",", "top_k", ")", ":", "\n", "    ", "\"\"\"Soft NMS for temporal proposals.\n\n    Args:\n        proposals (np.ndarray): Proposals generated by network.\n        alpha (float): Alpha value of Gaussian decaying function.\n        low_threshold (float): Low threshold for soft nms.\n        high_threshold (float): High threshold for soft nms.\n        top_k (int): Top k values to be considered.\n\n    Returns:\n        np.ndarray: The updated proposals.\n    \"\"\"", "\n", "proposals", "=", "proposals", "[", "proposals", "[", ":", ",", "-", "1", "]", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "tstart", "=", "list", "(", "proposals", "[", ":", ",", "0", "]", ")", "\n", "tend", "=", "list", "(", "proposals", "[", ":", ",", "1", "]", ")", "\n", "tscore", "=", "list", "(", "proposals", "[", ":", ",", "-", "1", "]", ")", "\n", "rstart", "=", "[", "]", "\n", "rend", "=", "[", "]", "\n", "rscore", "=", "[", "]", "\n", "\n", "while", "len", "(", "tscore", ")", ">", "0", "and", "len", "(", "rscore", ")", "<=", "top_k", ":", "\n", "        ", "max_index", "=", "np", ".", "argmax", "(", "tscore", ")", "\n", "max_width", "=", "tend", "[", "max_index", "]", "-", "tstart", "[", "max_index", "]", "\n", "iou_list", "=", "temporal_iou", "(", "tstart", "[", "max_index", "]", ",", "tend", "[", "max_index", "]", ",", "\n", "np", ".", "array", "(", "tstart", ")", ",", "np", ".", "array", "(", "tend", ")", ")", "\n", "iou_exp_list", "=", "np", ".", "exp", "(", "-", "np", ".", "square", "(", "iou_list", ")", "/", "alpha", ")", "\n", "\n", "for", "idx", ",", "_", "in", "enumerate", "(", "tscore", ")", ":", "\n", "            ", "if", "idx", "!=", "max_index", ":", "\n", "                ", "current_iou", "=", "iou_list", "[", "idx", "]", "\n", "if", "current_iou", ">", "low_threshold", "+", "(", "high_threshold", "-", "\n", "low_threshold", ")", "*", "max_width", ":", "\n", "                    ", "tscore", "[", "idx", "]", "=", "tscore", "[", "idx", "]", "*", "iou_exp_list", "[", "idx", "]", "\n", "\n", "", "", "", "rstart", ".", "append", "(", "tstart", "[", "max_index", "]", ")", "\n", "rend", ".", "append", "(", "tend", "[", "max_index", "]", ")", "\n", "rscore", ".", "append", "(", "tscore", "[", "max_index", "]", ")", "\n", "tstart", ".", "pop", "(", "max_index", ")", "\n", "tend", ".", "pop", "(", "max_index", ")", "\n", "tscore", ".", "pop", "(", "max_index", ")", "\n", "\n", "", "rstart", "=", "np", ".", "array", "(", "rstart", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "rend", "=", "np", ".", "array", "(", "rend", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "rscore", "=", "np", ".", "array", "(", "rscore", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "new_proposals", "=", "np", ".", "concatenate", "(", "(", "rstart", ",", "rend", ",", "rscore", ")", ",", "axis", "=", "1", ")", "\n", "return", "new_proposals", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.load_localize_proposal_file": [[9, 93], ["list", "itertools.groupby", "open", "int", "int", "int", "ssn_utils.load_localize_proposal_file.parse_group"], "function", ["None"], ["def", "load_localize_proposal_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Load the proposal file and split it into many parts which contain one\n    video's information separately.\n\n    Args:\n        filename(str): Path to the proposal file.\n\n    Returns:\n        list: List of all videos' information.\n    \"\"\"", "\n", "lines", "=", "list", "(", "open", "(", "filename", ")", ")", "\n", "\n", "# Split the proposal file into many parts which contain one video's", "\n", "# information separately.", "\n", "groups", "=", "groupby", "(", "lines", ",", "lambda", "x", ":", "x", ".", "startswith", "(", "'#'", ")", ")", "\n", "\n", "video_infos", "=", "[", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "list", "(", "g", ")", "]", "for", "k", ",", "g", "in", "groups", "if", "not", "k", "]", "\n", "\n", "def", "parse_group", "(", "video_info", ")", ":", "\n", "        ", "\"\"\"Parse the video's information.\n\n        Template information of a video in a standard file:\n            # index\n            video_id\n            num_frames\n            fps\n            num_gts\n            label, start_frame, end_frame\n            label, start_frame, end_frame\n            ...\n            num_proposals\n            label, best_iou, overlap_self, start_frame, end_frame\n            label, best_iou, overlap_self, start_frame, end_frame\n            ...\n\n        Example of a standard annotation file:\n\n        .. code-block:: txt\n\n            # 0\n            video_validation_0000202\n            5666\n            1\n            3\n            8 130 185\n            8 832 1136\n            8 1303 1381\n            5\n            8 0.0620 0.0620 790 5671\n            8 0.1656 0.1656 790 2619\n            8 0.0833 0.0833 3945 5671\n            8 0.0960 0.0960 4173 5671\n            8 0.0614 0.0614 3327 5671\n\n        Args:\n            video_info (list): Information of the video.\n\n        Returns:\n            tuple[str, int, list, list]:\n                video_id (str): Name of the video.\n                num_frames (int): Number of frames in the video.\n                gt_boxes (list): List of the information of gt boxes.\n                proposal_boxes (list): List of the information of\n                    proposal boxes.\n        \"\"\"", "\n", "offset", "=", "0", "\n", "video_id", "=", "video_info", "[", "offset", "]", "\n", "offset", "+=", "1", "\n", "\n", "num_frames", "=", "int", "(", "float", "(", "video_info", "[", "1", "]", ")", "*", "float", "(", "video_info", "[", "2", "]", ")", ")", "\n", "num_gts", "=", "int", "(", "video_info", "[", "3", "]", ")", "\n", "offset", "=", "4", "\n", "\n", "gt_boxes", "=", "[", "x", ".", "split", "(", ")", "for", "x", "in", "video_info", "[", "offset", ":", "offset", "+", "num_gts", "]", "]", "\n", "offset", "+=", "num_gts", "\n", "num_proposals", "=", "int", "(", "video_info", "[", "offset", "]", ")", "\n", "offset", "+=", "1", "\n", "proposal_boxes", "=", "[", "\n", "x", ".", "split", "(", ")", "for", "x", "in", "video_info", "[", "offset", ":", "offset", "+", "num_proposals", "]", "\n", "]", "\n", "\n", "return", "video_id", ",", "num_frames", ",", "gt_boxes", ",", "proposal_boxes", "\n", "\n", "", "return", "[", "parse_group", "(", "video_info", ")", "for", "video_info", "in", "video_infos", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.perform_regression": [[95, 118], ["numpy.concatenate", "numpy.exp", "numpy.clip", "numpy.clip"], "function", ["None"], ["", "def", "perform_regression", "(", "detections", ")", ":", "\n", "    ", "\"\"\"Perform regression on detection results.\n\n    Args:\n        detections (list): Detection results before regression.\n\n    Returns:\n        list: Detection results after regression.\n    \"\"\"", "\n", "starts", "=", "detections", "[", ":", ",", "0", "]", "\n", "ends", "=", "detections", "[", ":", ",", "1", "]", "\n", "centers", "=", "(", "starts", "+", "ends", ")", "/", "2", "\n", "durations", "=", "ends", "-", "starts", "\n", "\n", "new_centers", "=", "centers", "+", "durations", "*", "detections", "[", ":", ",", "3", "]", "\n", "new_durations", "=", "durations", "*", "np", ".", "exp", "(", "detections", "[", ":", ",", "4", "]", ")", "\n", "\n", "new_detections", "=", "np", ".", "concatenate", "(", "\n", "(", "np", ".", "clip", "(", "new_centers", "-", "new_durations", "/", "2", ",", "0", ",", "\n", "1", ")", "[", ":", ",", "None", "]", ",", "np", ".", "clip", "(", "new_centers", "+", "new_durations", "/", "2", ",", "0", ",", "\n", "1", ")", "[", ":", ",", "None", "]", ",", "detections", "[", ":", ",", "2", ":", "]", ")", ",", "\n", "axis", "=", "1", ")", "\n", "return", "new_detections", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.temporal_nms": [[120, 146], ["scores.argsort", "keep.append", "temporal_iou", "numpy.where"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou"], ["", "def", "temporal_nms", "(", "detections", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Parse the video's information.\n\n    Args:\n        detections (list): Detection results before NMS.\n        threshold (float): Threshold of NMS.\n\n    Returns:\n        list: Detection results after NMS.\n    \"\"\"", "\n", "starts", "=", "detections", "[", ":", ",", "0", "]", "\n", "ends", "=", "detections", "[", ":", ",", "1", "]", "\n", "scores", "=", "detections", "[", ":", ",", "2", "]", "\n", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "i", ")", "\n", "ious", "=", "temporal_iou", "(", "starts", "[", "order", "[", "1", ":", "]", "]", ",", "ends", "[", "order", "[", "1", ":", "]", "]", ",", "starts", "[", "i", "]", ",", "\n", "ends", "[", "i", "]", ")", "\n", "idxs", "=", "np", ".", "where", "(", "ious", "<=", "threshold", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "idxs", "+", "1", "]", "\n", "\n", "", "return", "detections", "[", "keep", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.ssn_utils.eval_ap": [[148, 169], ["numpy.zeros", "enumerate", "enumerate", "len", "len", "core.average_precision_at_temporal_iou"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_precision_at_temporal_iou"], ["", "def", "eval_ap", "(", "detections", ",", "gt_by_cls", ",", "iou_range", ")", ":", "\n", "    ", "\"\"\"Evaluate average precisions.\n\n    Args:\n        detections (dict): Results of detections.\n        gt_by_cls (dict): Information of groudtruth.\n        iou_range (list): Ranges of iou.\n\n    Returns:\n        list: Average precision values of classes at ious.\n    \"\"\"", "\n", "ap_values", "=", "np", ".", "zeros", "(", "(", "len", "(", "detections", ")", ",", "len", "(", "iou_range", ")", ")", ")", "\n", "\n", "for", "iou_idx", ",", "min_overlap", "in", "enumerate", "(", "iou_range", ")", ":", "\n", "        ", "for", "class_idx", ",", "_", "in", "enumerate", "(", "detections", ")", ":", "\n", "            ", "ap", "=", "average_precision_at_temporal_iou", "(", "gt_by_cls", "[", "class_idx", "]", ",", "\n", "detections", "[", "class_idx", "]", ",", "\n", "[", "min_overlap", "]", ")", "\n", "ap_values", "[", "class_idx", ",", "iou_idx", "]", "=", "ap", "\n", "\n", "", "", "return", "ap_values", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_candidate_proposals": [[8, 124], ["NotImplementedError", "os.join", "numpy.loadtxt", "max", "max", "numpy.zeros", "numpy.zeros", "range", "range", "zip", "numpy.stack", "numpy.concatenate", "numpy.array().reshape", "numpy.array().reshape", "numpy.concatenate", "numpy.concatenate", "len", "len", "zip", "gt_tmins.append", "gt_tmaxs.append", "max", "max", "np.array().reshape.append", "np.array().reshape.append", "tmin_list.append", "tmin_score_list.append", "tmax_list.append", "tmax_score_list.append", "np.concatenate.append", "float", "proposal_utils.temporal_iou", "proposal_utils.temporal_iop", "numpy.array", "numpy.array", "new_props[].argsort"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop"], ["def", "generate_candidate_proposals", "(", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "temporal_scale", ",", "\n", "peak_threshold", ",", "\n", "tem_results_ext", "=", "'.csv'", ",", "\n", "result_dict", "=", "None", ")", ":", "\n", "    ", "\"\"\"Generate Candidate Proposals with given temporal evalutation results.\n    Each proposal file will contain:\n    'tmin,tmax,tmin_score,tmax_score,score,match_iou,match_ioa'.\n\n    Args:\n        video_list (list[int]): List of video indexs to generate proposals.\n        video_infos (list[dict]): List of video_info dict that contains\n            'video_name', 'duration_frame', 'duration_second',\n            'feature_frame', and 'annotations'.\n        tem_results_dir (str): Directory to load temporal evaluation\n            results.\n        temporal_scale (int): The number (scale) on temporal axis.\n        peak_threshold (float): The threshold for proposal generation.\n        tem_results_ext (str): File extension for temporal evaluation\n            model output. Default: '.csv'.\n        result_dict (dict | None): The dict to save the results. Default: None.\n\n    Returns:\n        dict: A dict contains video_name as keys and proposal list as value.\n            If result_dict is not None, save the results to it.\n    \"\"\"", "\n", "if", "tem_results_ext", "!=", "'.csv'", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Only support csv format now.'", ")", "\n", "\n", "", "tscale", "=", "temporal_scale", "\n", "tgap", "=", "1.", "/", "tscale", "\n", "proposal_dict", "=", "{", "}", "\n", "for", "video_index", "in", "video_list", ":", "\n", "        ", "video_name", "=", "video_infos", "[", "video_index", "]", "[", "'video_name'", "]", "\n", "tem_path", "=", "osp", ".", "join", "(", "tem_results_dir", ",", "video_name", "+", "tem_results_ext", ")", "\n", "tem_results", "=", "np", ".", "loadtxt", "(", "\n", "tem_path", ",", "dtype", "=", "np", ".", "float32", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ")", "\n", "start_scores", "=", "tem_results", "[", ":", ",", "1", "]", "\n", "end_scores", "=", "tem_results", "[", ":", ",", "2", "]", "\n", "\n", "max_start", "=", "max", "(", "start_scores", ")", "\n", "max_end", "=", "max", "(", "end_scores", ")", "\n", "\n", "start_bins", "=", "np", ".", "zeros", "(", "len", "(", "start_scores", ")", ")", "\n", "start_bins", "[", "[", "0", ",", "-", "1", "]", "]", "=", "1", "\n", "end_bins", "=", "np", ".", "zeros", "(", "len", "(", "end_scores", ")", ")", "\n", "end_bins", "[", "[", "0", ",", "-", "1", "]", "]", "=", "1", "\n", "for", "idx", "in", "range", "(", "1", ",", "tscale", "-", "1", ")", ":", "\n", "            ", "if", "start_scores", "[", "idx", "]", ">", "start_scores", "[", "\n", "idx", "+", "1", "]", "and", "start_scores", "[", "idx", "]", ">", "start_scores", "[", "idx", "-", "1", "]", ":", "\n", "                ", "start_bins", "[", "idx", "]", "=", "1", "\n", "", "elif", "start_scores", "[", "idx", "]", ">", "(", "peak_threshold", "*", "max_start", ")", ":", "\n", "                ", "start_bins", "[", "idx", "]", "=", "1", "\n", "", "if", "end_scores", "[", "idx", "]", ">", "end_scores", "[", "\n", "idx", "+", "1", "]", "and", "end_scores", "[", "idx", "]", ">", "end_scores", "[", "idx", "-", "1", "]", ":", "\n", "                ", "end_bins", "[", "idx", "]", "=", "1", "\n", "", "elif", "end_scores", "[", "idx", "]", ">", "(", "peak_threshold", "*", "max_end", ")", ":", "\n", "                ", "end_bins", "[", "idx", "]", "=", "1", "\n", "\n", "", "", "tmin_list", "=", "[", "]", "\n", "tmin_score_list", "=", "[", "]", "\n", "tmax_list", "=", "[", "]", "\n", "tmax_score_list", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "tscale", ")", ":", "\n", "            ", "if", "start_bins", "[", "idx", "]", "==", "1", ":", "\n", "                ", "tmin_list", ".", "append", "(", "tgap", "/", "2", "+", "tgap", "*", "idx", ")", "\n", "tmin_score_list", ".", "append", "(", "start_scores", "[", "idx", "]", ")", "\n", "", "if", "end_bins", "[", "idx", "]", "==", "1", ":", "\n", "                ", "tmax_list", ".", "append", "(", "tgap", "/", "2", "+", "tgap", "*", "idx", ")", "\n", "tmax_score_list", ".", "append", "(", "end_scores", "[", "idx", "]", ")", "\n", "\n", "", "", "new_props", "=", "[", "]", "\n", "for", "tmax", ",", "tmax_score", "in", "zip", "(", "tmax_list", ",", "tmax_score_list", ")", ":", "\n", "            ", "for", "tmin", ",", "tmin_score", "in", "zip", "(", "tmin_list", ",", "tmin_score_list", ")", ":", "\n", "                ", "if", "tmin", ">=", "tmax", ":", "\n", "                    ", "break", "\n", "", "new_props", ".", "append", "(", "[", "tmin", ",", "tmax", ",", "tmin_score", ",", "tmax_score", "]", ")", "\n", "\n", "", "", "new_props", "=", "np", ".", "stack", "(", "new_props", ")", "\n", "\n", "score", "=", "(", "new_props", "[", ":", ",", "2", "]", "*", "new_props", "[", ":", ",", "3", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "new_props", "=", "np", ".", "concatenate", "(", "(", "new_props", ",", "score", ")", ",", "axis", "=", "1", ")", "\n", "\n", "new_props", "=", "new_props", "[", "new_props", "[", ":", ",", "-", "1", "]", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "video_info", "=", "video_infos", "[", "video_index", "]", "\n", "video_frame", "=", "video_info", "[", "'duration_frame'", "]", "\n", "video_second", "=", "video_info", "[", "'duration_second'", "]", "\n", "feature_frame", "=", "video_info", "[", "'feature_frame'", "]", "\n", "corrected_second", "=", "float", "(", "feature_frame", ")", "/", "video_frame", "*", "video_second", "\n", "\n", "gt_tmins", "=", "[", "]", "\n", "gt_tmaxs", "=", "[", "]", "\n", "for", "annotations", "in", "video_info", "[", "'annotations'", "]", ":", "\n", "            ", "gt_tmins", ".", "append", "(", "annotations", "[", "'segment'", "]", "[", "0", "]", "/", "corrected_second", ")", "\n", "gt_tmaxs", ".", "append", "(", "annotations", "[", "'segment'", "]", "[", "1", "]", "/", "corrected_second", ")", "\n", "\n", "", "new_iou_list", "=", "[", "]", "\n", "new_ioa_list", "=", "[", "]", "\n", "for", "new_prop", "in", "new_props", ":", "\n", "            ", "new_iou", "=", "max", "(", "\n", "temporal_iou", "(", "new_prop", "[", "0", "]", ",", "new_prop", "[", "1", "]", ",", "gt_tmins", ",", "gt_tmaxs", ")", ")", "\n", "new_ioa", "=", "max", "(", "\n", "temporal_iop", "(", "new_prop", "[", "0", "]", ",", "new_prop", "[", "1", "]", ",", "gt_tmins", ",", "gt_tmaxs", ")", ")", "\n", "new_iou_list", ".", "append", "(", "new_iou", ")", "\n", "new_ioa_list", ".", "append", "(", "new_ioa", ")", "\n", "\n", "", "new_iou_list", "=", "np", ".", "array", "(", "new_iou_list", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "new_ioa_list", "=", "np", ".", "array", "(", "new_ioa_list", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "new_props", "=", "np", ".", "concatenate", "(", "(", "new_props", ",", "new_iou_list", ")", ",", "axis", "=", "1", ")", "\n", "new_props", "=", "np", ".", "concatenate", "(", "(", "new_props", ",", "new_ioa_list", ")", ",", "axis", "=", "1", ")", "\n", "proposal_dict", "[", "video_name", "]", "=", "new_props", "\n", "if", "result_dict", "is", "not", "None", ":", "\n", "            ", "result_dict", "[", "video_name", "]", "=", "new_props", "\n", "", "", "return", "proposal_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_bsp_feature": [[126, 268], ["NotImplementedError", "os.join", "numpy.loadtxt", "len", "int", "os.join", "numpy.loadtxt", "numpy.zeros", "numpy.concatenate", "range", "range", "numpy.array", "begin_tp.append", "end_tp.append", "middle_tp.append", "numpy.interp", "numpy.interp", "numpy.interp", "numpy.concatenate", "np.array.append", "numpy.mean", "numpy.mean", "numpy.mean", "range", "range", "range", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "generate_bsp_feature", "(", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "\n", "top_k", "=", "1000", ",", "\n", "bsp_boundary_ratio", "=", "0.2", ",", "\n", "num_sample_start", "=", "8", ",", "\n", "num_sample_end", "=", "8", ",", "\n", "num_sample_action", "=", "16", ",", "\n", "num_sample_interp", "=", "3", ",", "\n", "tem_results_ext", "=", "'.csv'", ",", "\n", "pgm_proposal_ext", "=", "'.csv'", ",", "\n", "result_dict", "=", "None", ")", ":", "\n", "    ", "\"\"\"Generate Boundary-Sensitive Proposal Feature with given proposals.\n\n    Args:\n        video_list (list[int]): List of video indexs to generate bsp_feature.\n        video_infos (list[dict]): List of video_info dict that contains\n            'video_name'.\n        tem_results_dir (str): Directory to load temporal evaluation\n            results.\n        pgm_proposals_dir (str): Directory to load proposals.\n        top_k (int): Number of proposals to be considered. Default: 1000\n        bsp_boundary_ratio (float): Ratio for proposal boundary\n            (start/end). Default: 0.2.\n        num_sample_start (int): Num of samples for actionness in\n            start region. Default: 8.\n        num_sample_end (int): Num of samples for actionness in end region.\n            Default: 8.\n        num_sample_action (int): Num of samples for actionness in center\n            region. Default: 16.\n        num_sample_interp (int): Num of samples for interpolation for\n            each sample point. Default: 3.\n        tem_results_ext (str): File extension for temporal evaluation\n            model output. Default: '.csv'.\n        pgm_proposal_ext (str): File extension for proposals. Default: '.csv'.\n        result_dict (dict | None): The dict to save the results. Default: None.\n\n    Returns:\n        bsp_feature_dict (dict): A dict contains video_name as keys and\n            bsp_feature as value. If result_dict is not None, save the\n            results to it.\n    \"\"\"", "\n", "if", "tem_results_ext", "!=", "'.csv'", "or", "pgm_proposal_ext", "!=", "'.csv'", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Only support csv format now.'", ")", "\n", "\n", "", "bsp_feature_dict", "=", "{", "}", "\n", "for", "video_index", "in", "video_list", ":", "\n", "        ", "video_name", "=", "video_infos", "[", "video_index", "]", "[", "'video_name'", "]", "\n", "\n", "# Load temporal evaluation results", "\n", "tem_path", "=", "osp", ".", "join", "(", "tem_results_dir", ",", "video_name", "+", "tem_results_ext", ")", "\n", "tem_results", "=", "np", ".", "loadtxt", "(", "\n", "tem_path", ",", "dtype", "=", "np", ".", "float32", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ")", "\n", "score_action", "=", "tem_results", "[", ":", ",", "0", "]", "\n", "seg_tmins", "=", "tem_results", "[", ":", ",", "3", "]", "\n", "seg_tmaxs", "=", "tem_results", "[", ":", ",", "4", "]", "\n", "video_scale", "=", "len", "(", "tem_results", ")", "\n", "video_gap", "=", "seg_tmaxs", "[", "0", "]", "-", "seg_tmins", "[", "0", "]", "\n", "video_extend", "=", "int", "(", "video_scale", "/", "4", "+", "10", ")", "\n", "\n", "# Load proposals results", "\n", "proposal_path", "=", "osp", ".", "join", "(", "pgm_proposals_dir", ",", "\n", "video_name", "+", "pgm_proposal_ext", ")", "\n", "pgm_proposals", "=", "np", ".", "loadtxt", "(", "\n", "proposal_path", ",", "dtype", "=", "np", ".", "float32", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ")", "\n", "pgm_proposals", "=", "pgm_proposals", "[", ":", "top_k", "]", "\n", "\n", "# Generate temporal sample points", "\n", "boundary_zeros", "=", "np", ".", "zeros", "(", "[", "video_extend", "]", ")", "\n", "score_action", "=", "np", ".", "concatenate", "(", "\n", "(", "boundary_zeros", ",", "score_action", ",", "boundary_zeros", ")", ")", "\n", "begin_tp", "=", "[", "]", "\n", "middle_tp", "=", "[", "]", "\n", "end_tp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "video_extend", ")", ":", "\n", "            ", "begin_tp", ".", "append", "(", "-", "video_gap", "/", "2", "-", "\n", "(", "video_extend", "-", "1", "-", "i", ")", "*", "video_gap", ")", "\n", "end_tp", ".", "append", "(", "video_gap", "/", "2", "+", "seg_tmaxs", "[", "-", "1", "]", "+", "i", "*", "video_gap", ")", "\n", "", "for", "i", "in", "range", "(", "video_scale", ")", ":", "\n", "            ", "middle_tp", ".", "append", "(", "video_gap", "/", "2", "+", "i", "*", "video_gap", ")", "\n", "", "t_points", "=", "begin_tp", "+", "middle_tp", "+", "end_tp", "\n", "\n", "bsp_feature", "=", "[", "]", "\n", "for", "pgm_proposal", "in", "pgm_proposals", ":", "\n", "            ", "tmin", "=", "pgm_proposal", "[", "0", "]", "\n", "tmax", "=", "pgm_proposal", "[", "1", "]", "\n", "\n", "tlen", "=", "tmax", "-", "tmin", "\n", "# Temporal range for start", "\n", "tmin_0", "=", "tmin", "-", "tlen", "*", "bsp_boundary_ratio", "\n", "tmin_1", "=", "tmin", "+", "tlen", "*", "bsp_boundary_ratio", "\n", "# Temporal range for end", "\n", "tmax_0", "=", "tmax", "-", "tlen", "*", "bsp_boundary_ratio", "\n", "tmax_1", "=", "tmax", "+", "tlen", "*", "bsp_boundary_ratio", "\n", "\n", "# Generate features at start boundary", "\n", "tlen_start", "=", "(", "tmin_1", "-", "tmin_0", ")", "/", "(", "num_sample_start", "-", "1", ")", "\n", "tlen_start_sample", "=", "tlen_start", "/", "num_sample_interp", "\n", "t_new", "=", "[", "\n", "tmin_0", "-", "tlen_start", "/", "2", "+", "tlen_start_sample", "*", "i", "\n", "for", "i", "in", "range", "(", "num_sample_start", "*", "num_sample_interp", "+", "1", ")", "\n", "]", "\n", "y_new_start_action", "=", "np", ".", "interp", "(", "t_new", ",", "t_points", ",", "score_action", ")", "\n", "y_new_start", "=", "[", "\n", "np", ".", "mean", "(", "y_new_start_action", "[", "i", "*", "num_sample_interp", ":", "(", "i", "+", "1", ")", "*", "\n", "num_sample_interp", "+", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "num_sample_start", ")", "\n", "]", "\n", "# Generate features at end boundary", "\n", "tlen_end", "=", "(", "tmax_1", "-", "tmax_0", ")", "/", "(", "num_sample_end", "-", "1", ")", "\n", "tlen_end_sample", "=", "tlen_end", "/", "num_sample_interp", "\n", "t_new", "=", "[", "\n", "tmax_0", "-", "tlen_end", "/", "2", "+", "tlen_end_sample", "*", "i", "\n", "for", "i", "in", "range", "(", "num_sample_end", "*", "num_sample_interp", "+", "1", ")", "\n", "]", "\n", "y_new_end_action", "=", "np", ".", "interp", "(", "t_new", ",", "t_points", ",", "score_action", ")", "\n", "y_new_end", "=", "[", "\n", "np", ".", "mean", "(", "y_new_end_action", "[", "i", "*", "num_sample_interp", ":", "(", "i", "+", "1", ")", "*", "\n", "num_sample_interp", "+", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "num_sample_end", ")", "\n", "]", "\n", "# Generate features for action", "\n", "tlen_action", "=", "(", "tmax", "-", "tmin", ")", "/", "(", "num_sample_action", "-", "1", ")", "\n", "tlen_action_sample", "=", "tlen_action", "/", "num_sample_interp", "\n", "t_new", "=", "[", "\n", "tmin", "-", "tlen_action", "/", "2", "+", "tlen_action_sample", "*", "i", "\n", "for", "i", "in", "range", "(", "num_sample_action", "*", "num_sample_interp", "+", "1", ")", "\n", "]", "\n", "y_new_action", "=", "np", ".", "interp", "(", "t_new", ",", "t_points", ",", "score_action", ")", "\n", "y_new_action", "=", "[", "\n", "np", ".", "mean", "(", "y_new_action", "[", "i", "*", "num_sample_interp", ":", "(", "i", "+", "1", ")", "*", "\n", "num_sample_interp", "+", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "num_sample_action", ")", "\n", "]", "\n", "feature", "=", "np", ".", "concatenate", "(", "[", "y_new_action", ",", "y_new_start", ",", "y_new_end", "]", ")", "\n", "bsp_feature", ".", "append", "(", "feature", ")", "\n", "", "bsp_feature", "=", "np", ".", "array", "(", "bsp_feature", ")", "\n", "bsp_feature_dict", "[", "video_name", "]", "=", "bsp_feature", "\n", "if", "result_dict", "is", "not", "None", ":", "\n", "            ", "result_dict", "[", "video_name", "]", "=", "bsp_feature", "\n", "", "", "return", "bsp_feature_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_backbone": [[27, 30], ["BACKBONES.build"], "function", ["None"], ["    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_head": [[32, 35], ["HEADS.build"], "function", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer": [[37, 53], ["RECOGNIZERS.build", "warnings.warn", "cfg.get", "cfg.get", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["if", "cfg", "[", "'type'", "]", "==", "'RepeatDataset'", ":", "\n", "        ", "from", ".", "dataset_wrappers", "import", "RepeatDataset", "\n", "dataset", "=", "RepeatDataset", "(", "\n", "build_dataset", "(", "cfg", "[", "'dataset'", "]", ",", "default_args", ")", ",", "cfg", "[", "'times'", "]", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "build_from_cfg", "(", "cfg", ",", "DATASETS", ",", "default_args", ")", "\n", "", "return", "dataset", "\n", "\n", "\n", "", "def", "build_dataloader", "(", "dataset", ",", "\n", "videos_per_gpu", ",", "\n", "workers_per_gpu", ",", "\n", "num_gpus", "=", "1", ",", "\n", "dist", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "drop_last", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_loss": [[55, 58], ["LOSSES.build"], "function", ["None"], ["**", "kwargs", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer": [[60, 63], ["LOCALIZERS.build"], "function", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_model": [[65, 86], ["cfg.copy", "cfg.copy.pop", "ValueError", "builder.build_localizer", "builder.build_recognizer", "build_detector", "ImportError", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "sample_by_class", "=", "getattr", "(", "dataset", ",", "'sample_by_class'", ",", "False", ")", "\n", "\n", "if", "dist", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_neck": [[89, 92], ["NECKS.build"], "function", ["None"], ["sampler", "=", "ClassSpecificDistributedSampler", "(", "\n", "dataset", ",", "\n", "world_size", ",", "\n", "rank", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.Identity.forward": [[12, 14], ["None"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.DownSample.__init__": [[44, 73], ["dict", "torch.Module.__init__", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "torch.MaxPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "(", "3", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "1", ",", "0", ",", "0", ")", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "downsample_position", "=", "'after'", ",", "\n", "downsample_scale", "=", "(", "1", ",", "2", ",", "2", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "groups", "=", "groups", ",", "\n", "bias", "=", "bias", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "assert", "downsample_position", "in", "[", "'before'", ",", "'after'", "]", "\n", "self", ".", "downsample_position", "=", "downsample_position", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool3d", "(", "\n", "downsample_scale", ",", "downsample_scale", ",", "(", "0", ",", "0", ",", "0", ")", ",", "ceil_mode", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.DownSample.forward": [[74, 82], ["tpn.DownSample.pool", "tpn.DownSample.conv", "tpn.DownSample.conv", "tpn.DownSample.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "downsample_position", "==", "'before'", ":", "\n", "            ", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.LevelFusion.__init__": [[102, 136], ["torch.Module.__init__", "len", "torch.ModuleList", "torch.ModuleList", "range", "mmcv.cnn.ConvModule", "tpn.DownSample", "tpn.LevelFusion.downsamples.append", "sum", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "mid_channels", ",", "\n", "out_channels", ",", "\n", "downsample_scales", "=", "(", "(", "1", ",", "1", ",", "1", ")", ",", "(", "1", ",", "1", ",", "1", ")", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "num_stages", "=", "len", "(", "in_channels", ")", "\n", "\n", "self", ".", "downsamples", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_stages", ")", ":", "\n", "            ", "downsample", "=", "DownSample", "(", "\n", "in_channels", "[", "i", "]", ",", "\n", "mid_channels", "[", "i", "]", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "bias", "=", "False", ",", "\n", "padding", "=", "(", "0", ",", "0", ",", "0", ")", ",", "\n", "groups", "=", "32", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ",", "\n", "downsample_position", "=", "'before'", ",", "\n", "downsample_scale", "=", "downsample_scales", "[", "i", "]", ")", "\n", "self", ".", "downsamples", ".", "append", "(", "downsample", ")", "\n", "\n", "", "self", ".", "fusion_conv", "=", "ConvModule", "(", "\n", "sum", "(", "mid_channels", ")", ",", "\n", "out_channels", ",", "\n", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.LevelFusion.forward": [[137, 143], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "tpn.LevelFusion.fusion_conv", "enumerate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "[", "self", ".", "downsamples", "[", "i", "]", "(", "feature", ")", "for", "i", ",", "feature", "in", "enumerate", "(", "x", ")", "]", "\n", "out", "=", "torch", ".", "cat", "(", "out", ",", "1", ")", "\n", "out", "=", "self", ".", "fusion_conv", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.SpatialModulation.__init__": [[158, 183], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "int", "torch.ModuleList", "torch.ModuleList", "tpn.SpatialModulation.spatial_modulation.append", "numpy.log2", "tpn.Identity", "range", "Identity.append", "mmcv.cnn.ConvModule", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "spatial_modulation", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "channel", "in", "in_channels", ":", "\n", "            ", "downsample_scale", "=", "out_channels", "//", "channel", "\n", "downsample_factor", "=", "int", "(", "np", ".", "log2", "(", "downsample_scale", ")", ")", "\n", "op", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "downsample_factor", "<", "1", ":", "\n", "                ", "op", "=", "Identity", "(", ")", "\n", "", "else", ":", "\n", "                ", "for", "factor", "in", "range", "(", "downsample_factor", ")", ":", "\n", "                    ", "in_factor", "=", "2", "**", "factor", "\n", "out_factor", "=", "2", "**", "(", "factor", "+", "1", ")", "\n", "op", ".", "append", "(", "\n", "ConvModule", "(", "\n", "channel", "*", "in_factor", ",", "\n", "channel", "*", "out_factor", ",", "(", "1", ",", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ")", ")", "\n", "", "", "self", ".", "spatial_modulation", ".", "append", "(", "op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.SpatialModulation.forward": [[184, 195], ["enumerate", "isinstance", "out.append", "out.append", "op"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "[", "]", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "x", ")", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "spatial_modulation", "[", "i", "]", ",", "nn", ".", "ModuleList", ")", ":", "\n", "                ", "out_", "=", "x", "[", "i", "]", "\n", "for", "op", "in", "self", ".", "spatial_modulation", "[", "i", "]", ":", "\n", "                    ", "out_", "=", "op", "(", "out_", ")", "\n", "", "out", ".", "append", "(", "out_", ")", "\n", "", "else", ":", "\n", "                ", "out", ".", "append", "(", "self", ".", "spatial_modulation", "[", "i", "]", "(", "x", "[", "i", "]", ")", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.AuxHead.__init__": [[212, 232], ["dict", "torch.Module.__init__", "mmcv.cnn.ConvModule", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "builder.build_loss", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_loss"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "loss_weight", "=", "0.5", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "in_channels", "*", "2", ",", "(", "1", ",", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "in_channels", "*", "2", ",", "out_channels", ")", "\n", "self", ".", "loss_cls", "=", "build_loss", "(", "loss_cls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.AuxHead.init_weights": [[233, 241], ["tpn.AuxHead.modules", "isinstance", "isinstance", "isinstance", "mmcv.cnn.normal_init", "mmcv.cnn.xavier_init", "mmcv.cnn.constant_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "normal_init", "(", "m", ",", "std", "=", "0.01", ")", "\n", "", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "xavier_init", "(", "m", ",", "distribution", "=", "'uniform'", ")", "\n", "", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.AuxHead.forward": [[242, 256], ["dict", "tpn.AuxHead.conv", "tpn.AuxHead.avg_pool().squeeze().squeeze().squeeze", "tpn.AuxHead.dropout", "tpn.AuxHead.fc", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "target.unsqueeze.unsqueeze.unsqueeze", "tpn.AuxHead.loss_cls", "tpn.AuxHead.avg_pool().squeeze().squeeze", "tpn.AuxHead.avg_pool().squeeze", "tpn.AuxHead.avg_pool"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ",", "target", "=", "None", ")", ":", "\n", "        ", "losses", "=", "dict", "(", ")", "\n", "if", "target", "is", "None", ":", "\n", "            ", "return", "losses", "\n", "", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "avg_pool", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "if", "target", ".", "shape", "==", "torch", ".", "Size", "(", "[", "]", ")", ":", "\n", "            ", "target", "=", "target", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "losses", "[", "'loss_aux'", "]", "=", "self", ".", "loss_weight", "*", "self", ".", "loss_cls", "(", "x", ",", "target", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.TemporalModulation.__init__": [[270, 285], ["torch.Module.__init__", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "torch.MaxPool3d", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "downsample_scale", "=", "8", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "(", "3", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "1", ",", "0", ",", "0", ")", ",", "\n", "bias", "=", "False", ",", "\n", "groups", "=", "32", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "act_cfg", "=", "None", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool3d", "(", "(", "downsample_scale", ",", "1", ",", "1", ")", ",", "\n", "(", "downsample_scale", ",", "1", ",", "1", ")", ",", "(", "0", ",", "0", ",", "0", ")", ",", "\n", "ceil_mode", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.TemporalModulation.forward": [[286, 290], ["tpn.TemporalModulation.conv", "tpn.TemporalModulation.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.TPN.__init__": [[320, 398], ["torch.Module.__init__", "isinstance", "isinstance", "len", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "tpn.LevelFusion", "tpn.SpatialModulation", "range", "tpn.LevelFusion", "mmcv.cnn.ConvModule", "tpn.TPN.init_weights", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "ValueError", "tpn.AuxHead", "tpn.TemporalModulation", "tpn.TPN.temporal_modulation_ops.append", "dict", "dict", "torch.Upsample", "torch.Upsample", "tpn.TPN.upsample_ops.append", "tpn.DownSample", "tpn.TPN.downsample_ops.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "spatial_modulation_cfg", "=", "None", ",", "\n", "temporal_modulation_cfg", "=", "None", ",", "\n", "upsample_cfg", "=", "None", ",", "\n", "downsample_cfg", "=", "None", ",", "\n", "level_fusion_cfg", "=", "None", ",", "\n", "aux_head_cfg", "=", "None", ",", "\n", "flow_type", "=", "'cascade'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "in_channels", ",", "tuple", ")", "\n", "assert", "isinstance", "(", "out_channels", ",", "int", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_tpn_stages", "=", "len", "(", "in_channels", ")", "\n", "\n", "assert", "spatial_modulation_cfg", "is", "None", "or", "isinstance", "(", "\n", "spatial_modulation_cfg", ",", "dict", ")", "\n", "assert", "temporal_modulation_cfg", "is", "None", "or", "isinstance", "(", "\n", "temporal_modulation_cfg", ",", "dict", ")", "\n", "assert", "upsample_cfg", "is", "None", "or", "isinstance", "(", "upsample_cfg", ",", "dict", ")", "\n", "assert", "downsample_cfg", "is", "None", "or", "isinstance", "(", "downsample_cfg", ",", "dict", ")", "\n", "assert", "aux_head_cfg", "is", "None", "or", "isinstance", "(", "aux_head_cfg", ",", "dict", ")", "\n", "assert", "level_fusion_cfg", "is", "None", "or", "isinstance", "(", "level_fusion_cfg", ",", "dict", ")", "\n", "\n", "if", "flow_type", "not", "in", "[", "'cascade'", ",", "'parallel'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"flow type in TPN should be 'cascade' or 'parallel', \"", "\n", "f'but got {flow_type} instead.'", ")", "\n", "", "self", ".", "flow_type", "=", "flow_type", "\n", "\n", "self", ".", "temporal_modulation_ops", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "upsample_ops", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "downsample_ops", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "level_fusion_1", "=", "LevelFusion", "(", "**", "level_fusion_cfg", ")", "\n", "self", ".", "spatial_modulation", "=", "SpatialModulation", "(", "**", "spatial_modulation_cfg", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_tpn_stages", ")", ":", "\n", "\n", "            ", "if", "temporal_modulation_cfg", "is", "not", "None", ":", "\n", "                ", "downsample_scale", "=", "temporal_modulation_cfg", "[", "\n", "'downsample_scales'", "]", "[", "i", "]", "\n", "temporal_modulation", "=", "TemporalModulation", "(", "\n", "in_channels", "[", "-", "1", "]", ",", "out_channels", ",", "downsample_scale", ")", "\n", "self", ".", "temporal_modulation_ops", ".", "append", "(", "temporal_modulation", ")", "\n", "\n", "", "if", "i", "<", "self", ".", "num_tpn_stages", "-", "1", ":", "\n", "                ", "if", "upsample_cfg", "is", "not", "None", ":", "\n", "                    ", "upsample", "=", "nn", ".", "Upsample", "(", "**", "upsample_cfg", ")", "\n", "self", ".", "upsample_ops", ".", "append", "(", "upsample", ")", "\n", "\n", "", "if", "downsample_cfg", "is", "not", "None", ":", "\n", "                    ", "downsample", "=", "DownSample", "(", "out_channels", ",", "out_channels", ",", "\n", "**", "downsample_cfg", ")", "\n", "self", ".", "downsample_ops", ".", "append", "(", "downsample", ")", "\n", "\n", "", "", "", "out_dims", "=", "level_fusion_cfg", "[", "'out_channels'", "]", "\n", "\n", "# two pyramids", "\n", "self", ".", "level_fusion_2", "=", "LevelFusion", "(", "**", "level_fusion_cfg", ")", "\n", "\n", "self", ".", "pyramid_fusion", "=", "ConvModule", "(", "\n", "out_dims", "*", "2", ",", "\n", "2048", ",", "\n", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "if", "aux_head_cfg", "is", "not", "None", ":", "\n", "            ", "self", ".", "aux_head", "=", "AuxHead", "(", "self", ".", "in_channels", "[", "-", "2", "]", ",", "**", "aux_head_cfg", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "aux_head", "=", "None", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.TPN.init_weights": [[400, 409], ["tpn.TPN.modules", "isinstance", "isinstance", "tpn.TPN.aux_head.init_weights", "mmcv.cnn.xavier_init", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "xavier_init", "(", "m", ",", "distribution", "=", "'uniform'", ")", "\n", "", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n", "", "", "if", "self", ".", "aux_head", "is", "not", "None", ":", "\n", "            ", "self", ".", "aux_head", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.necks.tpn.TPN.forward": [[410, 449], ["dict", "tpn.TPN.spatial_modulation", "enumerate", "tpn.TPN.level_fusion_1", "tpn.TPN.level_fusion_2", "tpn.TPN.pyramid_fusion", "tpn.TPN.aux_head", "temporal_modulation_outs.append", "out.clone", "len", "range", "len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "temporal_modulation", "out.clone"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "target", "=", "None", ")", ":", "\n", "        ", "loss_aux", "=", "dict", "(", ")", "\n", "\n", "# Auxiliary loss", "\n", "if", "self", ".", "aux_head", "is", "not", "None", ":", "\n", "            ", "loss_aux", "=", "self", ".", "aux_head", "(", "x", "[", "-", "2", "]", ",", "target", ")", "\n", "\n", "# Spatial Modulation", "\n", "", "spatial_modulation_outs", "=", "self", ".", "spatial_modulation", "(", "x", ")", "\n", "\n", "# Temporal Modulation", "\n", "temporal_modulation_outs", "=", "[", "]", "\n", "for", "i", ",", "temporal_modulation", "in", "enumerate", "(", "self", ".", "temporal_modulation_ops", ")", ":", "\n", "            ", "temporal_modulation_outs", ".", "append", "(", "\n", "temporal_modulation", "(", "spatial_modulation_outs", "[", "i", "]", ")", ")", "\n", "\n", "", "outs", "=", "[", "out", ".", "clone", "(", ")", "for", "out", "in", "temporal_modulation_outs", "]", "\n", "if", "len", "(", "self", ".", "upsample_ops", ")", "!=", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "num_tpn_stages", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "outs", "[", "i", "-", "1", "]", "=", "outs", "[", "i", "-", "1", "]", "+", "self", ".", "upsample_ops", "[", "i", "-", "1", "]", "(", "outs", "[", "i", "]", ")", "\n", "\n", "# Get top-down outs", "\n", "", "", "top_down_outs", "=", "self", ".", "level_fusion_1", "(", "outs", ")", "\n", "\n", "# Build bottom-up flow using downsample operation", "\n", "if", "self", ".", "flow_type", "==", "'parallel'", ":", "\n", "            ", "outs", "=", "[", "out", ".", "clone", "(", ")", "for", "out", "in", "temporal_modulation_outs", "]", "\n", "", "if", "len", "(", "self", ".", "downsample_ops", ")", "!=", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "num_tpn_stages", "-", "1", ")", ":", "\n", "                ", "outs", "[", "i", "+", "1", "]", "=", "outs", "[", "i", "+", "1", "]", "+", "self", ".", "downsample_ops", "[", "i", "]", "(", "outs", "[", "i", "]", ")", "\n", "\n", "# Get bottom-up outs", "\n", "", "", "botton_up_outs", "=", "self", ".", "level_fusion_2", "(", "outs", ")", "\n", "\n", "# fuse two pyramid outs", "\n", "outs", "=", "self", ".", "pyramid_fusion", "(", "\n", "torch", ".", "cat", "(", "[", "top_down_outs", ",", "botton_up_outs", "]", ",", "1", ")", ")", "\n", "\n", "return", "outs", ",", "loss_aux", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D.forward_train": [[12, 48], ["imgs.reshape.reshape.reshape", "dict", "recognizer2d.Recognizer2D.extract_feat", "recognizer2d.Recognizer2D.cls_head", "labels.squeeze", "recognizer2d.Recognizer2D.cls_head.loss", "dict.update", "x.squeeze.squeeze.reshape", "x.squeeze.squeeze.reshape", "recognizer2d.Recognizer2D.neck", "x.squeeze.squeeze.squeeze", "dict.update", "each.reshape().transpose().contiguous", "labels.squeeze", "len", "torch.nn.AdaptiveAvgPool2d", "each.reshape().transpose", "each.reshape"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss"], ["def", "forward_train", "(", "self", ",", "imgs", ",", "labels", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when training.\"\"\"", "\n", "\n", "assert", "self", ".", "with_cls_head", "\n", "batches", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "num_segs", "=", "imgs", ".", "shape", "[", "0", "]", "//", "batches", "\n", "\n", "losses", "=", "dict", "(", ")", "\n", "\n", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "\n", "if", "self", ".", "backbone_from", "in", "[", "'torchvision'", ",", "'timm'", "]", ":", "\n", "            ", "if", "len", "(", "x", ".", "shape", ")", "==", "4", "and", "(", "x", ".", "shape", "[", "2", "]", ">", "1", "or", "x", ".", "shape", "[", "3", "]", ">", "1", ")", ":", "\n", "# apply adaptive avg pooling", "\n", "                ", "x", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "(", "x", ")", "\n", "", "x", "=", "x", ".", "reshape", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "+", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "[", "\n", "each", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "\n", "each", ".", "shape", "[", "1", ":", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "for", "each", "in", "x", "\n", "]", "\n", "x", ",", "loss_aux", "=", "self", ".", "neck", "(", "x", ",", "labels", ".", "squeeze", "(", ")", ")", "\n", "x", "=", "x", ".", "squeeze", "(", "2", ")", "\n", "num_segs", "=", "1", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "\n", "", "cls_score", "=", "self", ".", "cls_head", "(", "x", ",", "num_segs", ")", "\n", "gt_labels", "=", "labels", ".", "squeeze", "(", ")", "\n", "loss_cls", "=", "self", ".", "cls_head", ".", "loss", "(", "cls_score", ",", "gt_labels", ",", "**", "kwargs", ")", "\n", "losses", ".", "update", "(", "loss_cls", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D._do_test": [[49, 101], ["imgs.reshape.reshape.reshape", "recognizer2d.Recognizer2D.extract_feat", "recognizer2d.Recognizer2D.cls_head", "recognizer2d.Recognizer2D.average_clip", "x.mean.mean.reshape", "x.mean.mean.reshape", "recognizer2d.Recognizer2D.neck", "x.mean.mean.squeeze", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d.", "x.mean.mean.reshape", "x.mean.mean.mean", "each.reshape().transpose().contiguous", "len", "torch.nn.AdaptiveAvgPool2d", "recognizer2d.Recognizer2D.size", "recognizer2d.Recognizer2D.size", "each.reshape().transpose", "each.reshape"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip"], ["", "def", "_do_test", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when evaluation,\n        testing and gradcam.\"\"\"", "\n", "batches", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "num_segs", "=", "imgs", ".", "shape", "[", "0", "]", "//", "batches", "\n", "\n", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "\n", "if", "self", ".", "backbone_from", "in", "[", "'torchvision'", ",", "'timm'", "]", ":", "\n", "            ", "if", "len", "(", "x", ".", "shape", ")", "==", "4", "and", "(", "x", ".", "shape", "[", "2", "]", ">", "1", "or", "x", ".", "shape", "[", "3", "]", ">", "1", ")", ":", "\n", "# apply adaptive avg pooling", "\n", "                ", "x", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "(", "x", ")", "\n", "", "x", "=", "x", ".", "reshape", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "+", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "[", "\n", "each", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "\n", "each", ".", "shape", "[", "1", ":", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "for", "each", "in", "x", "\n", "]", "\n", "x", ",", "_", "=", "self", ".", "neck", "(", "x", ")", "\n", "x", "=", "x", ".", "squeeze", "(", "2", ")", "\n", "num_segs", "=", "1", "\n", "\n", "", "if", "self", ".", "feature_extraction", ":", "\n", "# perform spatial pooling", "\n", "            ", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "x", "=", "avg_pool", "(", "x", ")", "\n", "# squeeze dimensions", "\n", "x", "=", "x", ".", "reshape", "(", "(", "batches", ",", "num_segs", ",", "-", "1", ")", ")", "\n", "# temporal average pooling", "\n", "x", "=", "x", ".", "mean", "(", "axis", "=", "1", ")", "\n", "return", "x", "\n", "\n", "# When using `TSNHead` or `TPNHead`, shape is [batch_size, num_classes]", "\n", "# When using `TSMHead`, shape is [batch_size * num_crops, num_classes]", "\n", "# `num_crops` is calculated by:", "\n", "#   1) `twice_sample` in `SampleFrames`", "\n", "#   2) `num_sample_positions` in `DenseSampleFrames`", "\n", "#   3) `ThreeCrop/TenCrop/MultiGroupCrop` in `test_pipeline`", "\n", "#   4) `num_clips` in `SampleFrames` or its subclass if `clip_len != 1`", "\n", "\n", "# should have cls_head if not extracting features", "\n", "", "cls_score", "=", "self", ".", "cls_head", "(", "x", ",", "num_segs", ")", "\n", "\n", "assert", "cls_score", ".", "size", "(", ")", "[", "0", "]", "%", "batches", "==", "0", "\n", "# calculate num_crops automatically", "\n", "cls_score", "=", "self", ".", "average_clip", "(", "cls_score", ",", "\n", "cls_score", ".", "size", "(", ")", "[", "0", "]", "//", "batches", ")", "\n", "return", "cls_score", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D._do_fcn_test": [[102, 138], ["torch.flip.reshape", "recognizer2d.Recognizer2D.test_cfg.get", "recognizer2d.Recognizer2D.test_cfg.get", "recognizer2d.Recognizer2D.extract_feat", "recognizer2d.Recognizer2D.cls_head", "recognizer2d.Recognizer2D.average_clip", "torch.flip", "recognizer2d.Recognizer2D.neck", "x.reshape().transpose().contiguous.reshape().transpose().contiguous.reshape().transpose().contiguous", "each.reshape().transpose().contiguous", "x.reshape().transpose().contiguous.reshape().transpose().contiguous.reshape().transpose", "recognizer2d.Recognizer2D.size", "recognizer2d.Recognizer2D.size", "each.reshape().transpose", "x.reshape().transpose().contiguous.reshape().transpose().contiguous.reshape", "each.reshape"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip"], ["", "def", "_do_fcn_test", "(", "self", ",", "imgs", ")", ":", "\n", "# [N, num_crops * num_segs, C, H, W] ->", "\n", "# [N * num_crops * num_segs, C, H, W]", "\n", "        ", "batches", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "num_segs", "=", "self", ".", "test_cfg", ".", "get", "(", "'num_segs'", ",", "self", ".", "backbone", ".", "num_segments", ")", "\n", "\n", "if", "self", ".", "test_cfg", ".", "get", "(", "'flip'", ",", "False", ")", ":", "\n", "            ", "imgs", "=", "torch", ".", "flip", "(", "imgs", ",", "[", "-", "1", "]", ")", "\n", "", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "[", "\n", "each", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "\n", "each", ".", "shape", "[", "1", ":", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "for", "each", "in", "x", "\n", "]", "\n", "x", ",", "_", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "\n", "x", ".", "shape", "[", "1", ":", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# When using `TSNHead` or `TPNHead`, shape is [batch_size, num_classes]", "\n", "# When using `TSMHead`, shape is [batch_size * num_crops, num_classes]", "\n", "# `num_crops` is calculated by:", "\n", "#   1) `twice_sample` in `SampleFrames`", "\n", "#   2) `num_sample_positions` in `DenseSampleFrames`", "\n", "#   3) `ThreeCrop/TenCrop/MultiGroupCrop` in `test_pipeline`", "\n", "#   4) `num_clips` in `SampleFrames` or its subclass if `clip_len != 1`", "\n", "", "cls_score", "=", "self", ".", "cls_head", "(", "x", ",", "fcn_test", "=", "True", ")", "\n", "\n", "assert", "cls_score", ".", "size", "(", ")", "[", "0", "]", "%", "batches", "==", "0", "\n", "# calculate num_crops automatically", "\n", "cls_score", "=", "self", ".", "average_clip", "(", "cls_score", ",", "\n", "cls_score", ".", "size", "(", ")", "[", "0", "]", "//", "batches", ")", "\n", "return", "cls_score", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D.forward_test": [[139, 148], ["recognizer2d.Recognizer2D.test_cfg.get", "recognizer2d.Recognizer2D._do_test().cpu().numpy", "recognizer2d.Recognizer2D._do_fcn_test().cpu().numpy", "recognizer2d.Recognizer2D._do_test().cpu", "recognizer2d.Recognizer2D._do_fcn_test().cpu", "recognizer2d.Recognizer2D._do_test", "recognizer2d.Recognizer2D._do_fcn_test"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D._do_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D._do_fcn_test"], ["", "def", "forward_test", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when evaluation and\n        testing.\"\"\"", "\n", "if", "self", ".", "test_cfg", ".", "get", "(", "'fcn_test'", ",", "False", ")", ":", "\n", "# If specified, spatially fully-convolutional testing is performed", "\n", "            ", "assert", "not", "self", ".", "feature_extraction", "\n", "assert", "self", ".", "with_cls_head", "\n", "return", "self", ".", "_do_fcn_test", "(", "imgs", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "self", ".", "_do_test", "(", "imgs", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D.forward_dummy": [[149, 180], ["imgs.reshape.reshape.reshape", "recognizer2d.Recognizer2D.extract_feat", "recognizer2d.Recognizer2D.cls_head", "recognizer2d.Recognizer2D.neck", "x.squeeze.squeeze.squeeze", "torch.nn.functional.softmax", "each.reshape().transpose().contiguous", "each.reshape().transpose", "each.reshape"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["", "def", "forward_dummy", "(", "self", ",", "imgs", ",", "softmax", "=", "False", ")", ":", "\n", "        ", "\"\"\"Used for computing network FLOPs.\n\n        See ``tools/analysis/get_flops.py``.\n\n        Args:\n            imgs (torch.Tensor): Input images.\n\n        Returns:\n            Tensor: Class score.\n        \"\"\"", "\n", "assert", "self", ".", "with_cls_head", "\n", "batches", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "num_segs", "=", "imgs", ".", "shape", "[", "0", "]", "//", "batches", "\n", "\n", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "[", "\n", "each", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "\n", "each", ".", "shape", "[", "1", ":", "]", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "for", "each", "in", "x", "\n", "]", "\n", "x", ",", "_", "=", "self", ".", "neck", "(", "x", ")", "\n", "x", "=", "x", ".", "squeeze", "(", "2", ")", "\n", "num_segs", "=", "1", "\n", "\n", "", "outs", "=", "self", ".", "cls_head", "(", "x", ",", "num_segs", ")", "\n", "if", "softmax", ":", "\n", "            ", "outs", "=", "nn", ".", "functional", ".", "softmax", "(", "outs", ")", "\n", "", "return", "(", "outs", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer2d.Recognizer2D.forward_gradcam": [[181, 186], ["recognizer2d.Recognizer2D._do_test"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D._do_test"], ["", "def", "forward_gradcam", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when using gradcam\n        utils.\"\"\"", "\n", "assert", "self", ".", "with_cls_head", "\n", "return", "self", ".", "_do_test", "(", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.__init__": [[32, 112], ["torch.Module.__init__", "backbone[].startswith", "base.BaseRecognizer.init_weights", "mmcls_builder.build_backbone", "backbone[].startswith", "builder.build_neck", "builder.build_head", "isinstance", "build_from_cfg", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "backbone[].startswith", "ImportError", "backbone.pop", "timm.create_model", "builder.build_backbone", "ImportError", "backbone.pop", "ImportError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_backbone", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_neck", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_head", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_backbone"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n", "                ", "class_prob", ".", "append", "(", "len", "(", "samples", ")", "/", "len", "(", "self", ".", "video_infos", ")", ")", "\n", "", "class_prob", "=", "[", "x", "**", "self", ".", "power", "for", "x", "in", "class_prob", "]", "\n", "\n", "summ", "=", "sum", "(", "class_prob", ")", "\n", "class_prob", "=", "[", "x", "/", "summ", "for", "x", "in", "class_prob", "]", "\n", "\n", "self", ".", "class_prob", "=", "dict", "(", "zip", "(", "self", ".", "video_infos_by_class", ",", "class_prob", ")", ")", "\n", "\n", "", "", "@", "abstractmethod", "\n", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "\n", "# json annotations already looks like video_infos, so for each dataset,", "\n", "# this func should be the same", "\n", "", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "path_key", "=", "'frame_dir'", "if", "'frame_dir'", "in", "video_infos", "[", "0", "]", "else", "'filename'", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.with_neck": [[113, 117], ["hasattr"], "methods", ["None"], ["for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.with_cls_head": [[118, 122], ["hasattr"], "methods", ["None"], ["if", "self", ".", "multi_class", ":", "\n", "                ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "video_infos", "[", "i", "]", "[", "'label'", "]", ")", "==", "1", "\n", "video_infos", "[", "i", "]", "[", "'label'", "]", "=", "video_infos", "[", "i", "]", "[", "'label'", "]", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.init_weights": [[123, 140], ["base.BaseRecognizer.backbone.init_weights", "base.BaseRecognizer.cls_head.init_weights", "base.BaseRecognizer.neck.init_weights", "warnings.warn", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "return", "video_infos", "\n", "\n", "", "def", "parse_by_class", "(", "self", ")", ":", "\n", "        ", "video_infos_by_class", "=", "defaultdict", "(", "list", ")", "\n", "for", "item", "in", "self", ".", "video_infos", ":", "\n", "            ", "label", "=", "item", "[", "'label'", "]", "\n", "video_infos_by_class", "[", "label", "]", ".", "append", "(", "item", ")", "\n", "", "return", "video_infos_by_class", "\n", "\n", "", "@", "staticmethod", "\n", "def", "label2array", "(", "num", ",", "label", ")", ":", "\n", "        ", "arr", "=", "np", ".", "zeros", "(", "num", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr", "[", "label", "]", "=", "1.", "\n", "return", "arr", "\n", "\n", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'top_k_accuracy'", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.extract_feat": [[141, 159], ["mmcv.runner.auto_fp16", "hasattr", "base.BaseRecognizer.backbone.features", "base.BaseRecognizer.backbone.forward_features", "base.BaseRecognizer.backbone"], "methods", ["None"], ["metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "(", "1", ",", "5", ")", ")", ")", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip": [[160, 195], ["cls_score.mean.mean.view", "base.BaseRecognizer.test_cfg.keys", "KeyError", "ValueError", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "torch.softmax().mean", "cls_score.mean.mean.mean", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["\n", "# Protect ``metric_options`` since it uses mutable value as default", "\n", "metric_options", "=", "copy", ".", "deepcopy", "(", "metric_options", ")", "\n", "\n", "if", "deprecated_kwargs", "!=", "{", "}", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'Option arguments for metrics has been changed to '", "\n", "\"`metric_options`, See 'https://github.com/open-mmlab/mmaction2/pull/286' \"", "# noqa: E501", "\n", "'for more details'", ")", "\n", "metric_options", "[", "'top_k_accuracy'", "]", "=", "dict", "(", "\n", "metric_options", "[", "'top_k_accuracy'", "]", ",", "**", "deprecated_kwargs", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "results", ",", "list", ")", ":", "\n", "            ", "raise", "TypeError", "(", "f'results must be a list, but got {type(results)}'", ")", "\n", "", "assert", "len", "(", "results", ")", "==", "len", "(", "self", ")", ",", "(", "\n", "f'The length of results is not equal to the dataset len: '", "\n", "f'{len(results)} != {len(self)}'", ")", "\n", "\n", "metrics", "=", "metrics", "if", "isinstance", "(", "metrics", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "metrics", "]", "\n", "allowed_metrics", "=", "[", "\n", "'top_k_accuracy'", ",", "'mean_class_accuracy'", ",", "'mean_average_precision'", ",", "\n", "'mmit_mean_average_precision'", "\n", "]", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "if", "metric", "not", "in", "allowed_metrics", ":", "\n", "                ", "raise", "KeyError", "(", "f'metric {metric} is not supported'", ")", "\n", "\n", "", "", "eval_results", "=", "OrderedDict", "(", ")", "\n", "gt_labels", "=", "[", "ann", "[", "'label'", "]", "for", "ann", "in", "self", ".", "video_infos", "]", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "msg", "=", "f'Evaluating {metric} ...'", "\n", "if", "logger", "is", "None", ":", "\n", "                ", "msg", "=", "'\\n'", "+", "msg", "\n", "", "print_log", "(", "msg", ",", "logger", "=", "logger", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.forward_train": [[196, 199], ["None"], "methods", ["None"], ["\n", "if", "metric", "==", "'top_k_accuracy'", ":", "\n", "                ", "topk", "=", "metric_options", ".", "setdefault", "(", "'top_k_accuracy'", ",", "\n", "{", "}", ")", ".", "setdefault", "(", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.forward_test": [[200, 204], ["None"], "methods", ["None"], ["'topk'", ",", "(", "1", ",", "5", ")", ")", "\n", "if", "not", "isinstance", "(", "topk", ",", "(", "int", ",", "tuple", ")", ")", ":", "\n", "                    ", "raise", "TypeError", "(", "'topk must be int or tuple of int, '", "\n", "f'but got {type(topk)}'", ")", "\n", "", "if", "isinstance", "(", "topk", ",", "int", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.forward_gradcam": [[205, 209], ["None"], "methods", ["None"], ["                    ", "topk", "=", "(", "topk", ",", ")", "\n", "\n", "", "top_k_acc", "=", "top_k_accuracy", "(", "results", ",", "gt_labels", ",", "topk", ")", "\n", "log_msg", "=", "[", "]", "\n", "for", "k", ",", "acc", "in", "zip", "(", "topk", ",", "top_k_acc", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer._parse_losses": [[210, 245], ["collections.OrderedDict", "losses.items", "sum", "collections.OrderedDict.items", "isinstance", "loss_value.data.clone.data.clone.item", "loss_value.data.clone.data.clone.mean", "isinstance", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "loss_value.data.clone.data.clone.data.clone", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "sum", "TypeError", "collections.OrderedDict.items", "loss_value.data.clone.data.clone.div_", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "_loss.mean"], "methods", ["None"], ["                    ", "eval_results", "[", "f'top{k}_acc'", "]", "=", "acc", "\n", "log_msg", ".", "append", "(", "f'\\ntop{k}_acc\\t{acc:.4f}'", ")", "\n", "", "log_msg", "=", "''", ".", "join", "(", "log_msg", ")", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "continue", "\n", "\n", "", "if", "metric", "==", "'mean_class_accuracy'", ":", "\n", "                ", "mean_acc", "=", "mean_class_accuracy", "(", "results", ",", "gt_labels", ")", "\n", "eval_results", "[", "'mean_class_accuracy'", "]", "=", "mean_acc", "\n", "log_msg", "=", "f'\\nmean_acc\\t{mean_acc:.4f}'", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "continue", "\n", "\n", "", "if", "metric", "in", "[", "\n", "'mean_average_precision'", ",", "'mmit_mean_average_precision'", "\n", "]", ":", "\n", "                ", "gt_labels", "=", "[", "\n", "self", ".", "label2array", "(", "self", ".", "num_classes", ",", "label", ")", "\n", "for", "label", "in", "gt_labels", "\n", "]", "\n", "if", "metric", "==", "'mean_average_precision'", ":", "\n", "                    ", "mAP", "=", "mean_average_precision", "(", "results", ",", "gt_labels", ")", "\n", "eval_results", "[", "'mean_average_precision'", "]", "=", "mAP", "\n", "log_msg", "=", "f'\\nmean_average_precision\\t{mAP:.4f}'", "\n", "", "elif", "metric", "==", "'mmit_mean_average_precision'", ":", "\n", "                    ", "mAP", "=", "mmit_mean_average_precision", "(", "results", ",", "gt_labels", ")", "\n", "eval_results", "[", "'mmit_mean_average_precision'", "]", "=", "mAP", "\n", "log_msg", "=", "f'\\nmmit_mean_average_precision\\t{mAP:.4f}'", "\n", "", "print_log", "(", "log_msg", ",", "logger", "=", "logger", ")", "\n", "continue", "\n", "\n", "", "", "return", "eval_results", "\n", "\n", "", "@", "staticmethod", "\n", "def", "dump_results", "(", "results", ",", "out", ")", ":", "\n", "        ", "\"\"\"Dump data to json/yaml/pickle strings or files.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.forward": [[246, 259], ["kwargs.get", "base.BaseRecognizer.forward_test", "base.BaseRecognizer.forward_gradcam", "base.BaseRecognizer.forward_train", "ValueError", "base.BaseRecognizer.blending"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_gradcam", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train"], ["return", "mmcv", ".", "dump", "(", "results", ",", "out", ")", "\n", "\n", "", "def", "prepare_train_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for training given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "# prepare tensor in getitem", "\n", "# If HVU, type(results['label']) is dict", "\n", "if", "self", ".", "multi_class", "and", "isinstance", "(", "results", "[", "'label'", "]", ",", "list", ")", ":", "\n", "            ", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "results", "[", "'label'", "]", "]", "=", "1.", "\n", "results", "[", "'label'", "]", "=", "onehot", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.train_step": [[260, 304], ["base.BaseRecognizer.", "base.BaseRecognizer._parse_losses", "dict", "len", "next", "iter", "data_batch.values"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer._parse_losses"], ["\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n", "", "def", "prepare_test_frames", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Prepare the frames for testing given the index.\"\"\"", "\n", "results", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_infos", "[", "idx", "]", ")", "\n", "results", "[", "'modality'", "]", "=", "self", ".", "modality", "\n", "results", "[", "'start_index'", "]", "=", "self", ".", "start_index", "\n", "\n", "# prepare tensor in getitem", "\n", "# If HVU, type(results['label']) is dict", "\n", "if", "self", ".", "multi_class", "and", "isinstance", "(", "results", "[", "'label'", "]", ",", "list", ")", ":", "\n", "            ", "onehot", "=", "torch", ".", "zeros", "(", "self", ".", "num_classes", ")", "\n", "onehot", "[", "results", "[", "'label'", "]", "]", "=", "1.", "\n", "results", "[", "'label'", "]", "=", "onehot", "\n", "\n", "", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the size of the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "video_infos", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get the sample for either training or testing given index.\"\"\"", "\n", "if", "self", ".", "test_mode", ":", "\n", "            ", "return", "self", ".", "prepare_test_frames", "(", "idx", ")", "\n", "\n", "", "return", "self", ".", "prepare_train_frames", "(", "idx", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.val_step": [[305, 329], ["base.BaseRecognizer.", "base.BaseRecognizer._parse_losses", "dict", "len", "next", "iter", "data_batch.values"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer._parse_losses"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D.forward_train": [[12, 30], ["imgs.reshape.reshape.reshape", "dict", "recognizer3d.Recognizer3D.extract_feat", "recognizer3d.Recognizer3D.cls_head", "labels.squeeze", "recognizer3d.Recognizer3D.cls_head.loss", "dict.update", "recognizer3d.Recognizer3D.neck", "dict.update", "labels.squeeze"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss"], ["def", "forward_train", "(", "self", ",", "imgs", ",", "labels", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when training.\"\"\"", "\n", "\n", "assert", "self", ".", "with_cls_head", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "\n", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", ",", "loss_aux", "=", "self", ".", "neck", "(", "x", ",", "labels", ".", "squeeze", "(", ")", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "\n", "", "cls_score", "=", "self", ".", "cls_head", "(", "x", ")", "\n", "gt_labels", "=", "labels", ".", "squeeze", "(", ")", "\n", "loss_cls", "=", "self", ".", "cls_head", ".", "loss", "(", "cls_score", ",", "gt_labels", ",", "**", "kwargs", ")", "\n", "losses", ".", "update", "(", "loss_cls", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D._do_test": [[31, 86], ["imgs.reshape.reshape.reshape", "recognizer3d.Recognizer3D.cls_head", "recognizer3d.Recognizer3D.average_clip", "isinstance", "recognizer3d.Recognizer3D.extract_feat", "torch.nn.AdaptiveAvgPool3d", "isinstance", "nn.AdaptiveAvgPool3d.reshape", "nn.AdaptiveAvgPool3d.mean", "recognizer3d.Recognizer3D.extract_feat", "feats.append", "len", "tuple", "torch.cat", "recognizer3d.Recognizer3D.neck", "torch.cat", "torch.nn.AdaptiveAvgPool3d.", "recognizer3d.Recognizer3D.neck", "torch.cat", "torch.nn.AdaptiveAvgPool3d.", "range"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat"], ["", "def", "_do_test", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when evaluation,\n        testing and gradcam.\"\"\"", "\n", "batches", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "num_segs", "=", "imgs", ".", "shape", "[", "1", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n", "if", "self", ".", "max_testing_views", "is", "not", "None", ":", "\n", "            ", "total_views", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "assert", "num_segs", "==", "total_views", ",", "(", "\n", "'max_testing_views is only compatible '", "\n", "'with batch_size == 1'", ")", "\n", "view_ptr", "=", "0", "\n", "feats", "=", "[", "]", "\n", "while", "view_ptr", "<", "total_views", ":", "\n", "                ", "batch_imgs", "=", "imgs", "[", "view_ptr", ":", "view_ptr", "+", "self", ".", "max_testing_views", "]", "\n", "x", "=", "self", ".", "extract_feat", "(", "batch_imgs", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "                    ", "x", ",", "_", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "feats", ".", "append", "(", "x", ")", "\n", "view_ptr", "+=", "self", ".", "max_testing_views", "\n", "# should consider the case that feat is a tuple", "\n", "", "if", "isinstance", "(", "feats", "[", "0", "]", ",", "tuple", ")", ":", "\n", "                ", "len_tuple", "=", "len", "(", "feats", "[", "0", "]", ")", "\n", "feat", "=", "[", "\n", "torch", ".", "cat", "(", "[", "x", "[", "i", "]", "for", "x", "in", "feats", "]", ")", "for", "i", "in", "range", "(", "len_tuple", ")", "\n", "]", "\n", "feat", "=", "tuple", "(", "feat", ")", "\n", "", "else", ":", "\n", "                ", "feat", "=", "torch", ".", "cat", "(", "feats", ")", "\n", "", "", "else", ":", "\n", "            ", "feat", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "                ", "feat", ",", "_", "=", "self", ".", "neck", "(", "feat", ")", "\n", "\n", "", "", "if", "self", ".", "feature_extraction", ":", "\n", "# perform spatio-temporal pooling", "\n", "            ", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "1", ")", "\n", "if", "isinstance", "(", "feat", ",", "tuple", ")", ":", "\n", "                ", "feat", "=", "[", "avg_pool", "(", "x", ")", "for", "x", "in", "feat", "]", "\n", "# concat them", "\n", "feat", "=", "torch", ".", "cat", "(", "feat", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "feat", "=", "avg_pool", "(", "feat", ")", "\n", "# squeeze dimensions", "\n", "", "feat", "=", "feat", ".", "reshape", "(", "(", "batches", ",", "num_segs", ",", "-", "1", ")", ")", "\n", "# temporal average pooling", "\n", "feat", "=", "feat", ".", "mean", "(", "axis", "=", "1", ")", "\n", "return", "feat", "\n", "\n", "# should have cls_head if not extracting features", "\n", "", "assert", "self", ".", "with_cls_head", "\n", "cls_score", "=", "self", ".", "cls_head", "(", "feat", ")", "\n", "cls_score", "=", "self", ".", "average_clip", "(", "cls_score", ",", "num_segs", ")", "\n", "return", "cls_score", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D.forward_test": [[87, 91], ["recognizer3d.Recognizer3D._do_test().cpu().numpy", "recognizer3d.Recognizer3D._do_test().cpu", "recognizer3d.Recognizer3D._do_test"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D._do_test"], ["", "def", "forward_test", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when evaluation and\n        testing.\"\"\"", "\n", "return", "self", ".", "_do_test", "(", "imgs", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D.forward_dummy": [[92, 114], ["imgs.reshape.reshape.reshape", "recognizer3d.Recognizer3D.extract_feat", "recognizer3d.Recognizer3D.cls_head", "recognizer3d.Recognizer3D.neck", "torch.nn.functional.softmax"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["", "def", "forward_dummy", "(", "self", ",", "imgs", ",", "softmax", "=", "False", ")", ":", "\n", "        ", "\"\"\"Used for computing network FLOPs.\n\n        See ``tools/analysis/get_flops.py``.\n\n        Args:\n            imgs (torch.Tensor): Input images.\n\n        Returns:\n            Tensor: Class score.\n        \"\"\"", "\n", "assert", "self", ".", "with_cls_head", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", ",", "_", "=", "self", ".", "neck", "(", "x", ")", "\n", "\n", "", "outs", "=", "self", ".", "cls_head", "(", "x", ")", "\n", "if", "softmax", ":", "\n", "            ", "outs", "=", "nn", ".", "functional", ".", "softmax", "(", "outs", ")", "\n", "", "return", "(", "outs", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D.forward_gradcam": [[115, 120], ["recognizer3d.Recognizer3D._do_test"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.recognizer3d.Recognizer3D._do_test"], ["", "def", "forward_gradcam", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when using gradcam\n        utils.\"\"\"", "\n", "assert", "self", ".", "with_cls_head", "\n", "return", "self", ".", "_do_test", "(", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.audio_recognizer.AudioRecognizer.forward": [[9, 17], ["audio_recognizer.AudioRecognizer.forward_test", "audio_recognizer.AudioRecognizer.forward_train", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train"], ["def", "forward", "(", "self", ",", "audios", ",", "label", "=", "None", ",", "return_loss", "=", "True", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "if", "label", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Label should not be None.'", ")", "\n", "", "return", "self", ".", "forward_train", "(", "audios", ",", "label", ")", "\n", "\n", "", "return", "self", ".", "forward_test", "(", "audios", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.audio_recognizer.AudioRecognizer.forward_train": [[18, 27], ["audios.reshape.reshape.reshape", "audio_recognizer.AudioRecognizer.extract_feat", "audio_recognizer.AudioRecognizer.cls_head", "labels.squeeze", "audio_recognizer.AudioRecognizer.cls_head.loss"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss"], ["", "def", "forward_train", "(", "self", ",", "audios", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when training.\"\"\"", "\n", "audios", "=", "audios", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "audios", ".", "shape", "[", "2", ":", "]", ")", "\n", "x", "=", "self", ".", "extract_feat", "(", "audios", ")", "\n", "cls_score", "=", "self", ".", "cls_head", "(", "x", ")", "\n", "gt_labels", "=", "labels", ".", "squeeze", "(", ")", "\n", "loss", "=", "self", ".", "cls_head", ".", "loss", "(", "cls_score", ",", "gt_labels", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.audio_recognizer.AudioRecognizer.forward_test": [[28, 38], ["audios.reshape.reshape.reshape", "audio_recognizer.AudioRecognizer.extract_feat", "audio_recognizer.AudioRecognizer.cls_head", "audio_recognizer.AudioRecognizer.average_clip", "audio_recognizer.AudioRecognizer.cpu().numpy", "audio_recognizer.AudioRecognizer.cpu"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip"], ["", "def", "forward_test", "(", "self", ",", "audios", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call when evaluation and\n        testing.\"\"\"", "\n", "num_segs", "=", "audios", ".", "shape", "[", "1", "]", "\n", "audios", "=", "audios", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "audios", ".", "shape", "[", "2", ":", "]", ")", "\n", "x", "=", "self", ".", "extract_feat", "(", "audios", ")", "\n", "cls_score", "=", "self", ".", "cls_head", "(", "x", ")", "\n", "cls_score", "=", "self", ".", "average_clip", "(", "cls_score", ",", "num_segs", ")", "\n", "\n", "return", "cls_score", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.audio_recognizer.AudioRecognizer.forward_gradcam": [[39, 41], ["None"], "methods", ["None"], ["", "def", "forward_gradcam", "(", "self", ",", "audios", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.audio_recognizer.AudioRecognizer.train_step": [[42, 81], ["audio_recognizer.AudioRecognizer.", "audio_recognizer.AudioRecognizer._parse_losses", "dict", "len", "next", "iter", "data_batch.values"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer._parse_losses"], ["", "def", "train_step", "(", "self", ",", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"The iteration step during training.\n\n        This method defines an iteration step during training, except for the\n        back propagation and optimizer updating, which are done in an optimizer\n        hook. Note that in some complicated cases or models, the whole process\n        including back propagation and optimizer updating is also defined in\n        this method, such as GAN.\n\n        Args:\n            data_batch (dict): The output of dataloader.\n            optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\n                runner is passed to ``train_step()``. This argument is unused\n                and reserved.\n\n        Returns:\n            dict: It should contain at least 3 keys: ``loss``, ``log_vars``,\n                ``num_samples``.\n                ``loss`` is a tensor for back propagation, which can be a\n                weighted sum of multiple losses.\n                ``log_vars`` contains all the variables to be sent to the\n                logger.\n                ``num_samples`` indicates the batch size (when the model is\n                DDP, it means the batch size on each GPU), which is used for\n                averaging the logs.\n        \"\"\"", "\n", "audios", "=", "data_batch", "[", "'audios'", "]", "\n", "label", "=", "data_batch", "[", "'label'", "]", "\n", "\n", "losses", "=", "self", "(", "audios", ",", "label", ")", "\n", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "\n", "log_vars", "=", "log_vars", ",", "\n", "num_samples", "=", "len", "(", "next", "(", "iter", "(", "data_batch", ".", "values", "(", ")", ")", ")", ")", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.audio_recognizer.AudioRecognizer.val_step": [[82, 102], ["audio_recognizer.AudioRecognizer.", "audio_recognizer.AudioRecognizer._parse_losses", "dict", "len", "next", "iter", "data_batch.values"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer._parse_losses"], ["", "def", "val_step", "(", "self", ",", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"The iteration step during validation.\n\n        This method shares the same signature as :func:`train_step`, but used\n        during val epochs. Note that the evaluation after training epochs is\n        not implemented with this method, but an evaluation hook.\n        \"\"\"", "\n", "audios", "=", "data_batch", "[", "'audios'", "]", "\n", "label", "=", "data_batch", "[", "'label'", "]", "\n", "\n", "losses", "=", "self", "(", "audios", ",", "label", ")", "\n", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "\n", "log_vars", "=", "log_vars", ",", "\n", "num_samples", "=", "len", "(", "next", "(", "iter", "(", "data_batch", ".", "values", "(", ")", ")", ")", ")", ")", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.__init__": [[19, 27], ["torch.Module.__init__", "builder.build_backbone", "builder.build_head", "base.BaseLocalizer.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_backbone", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_head", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.init_weights": [[28, 32], ["base.BaseLocalizer.backbone.init_weights", "base.BaseLocalizer.cls_head.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat": [[33, 43], ["base.BaseLocalizer.backbone"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.forward_train": [[44, 47], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.forward_test": [[48, 51], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.forward": [[52, 58], ["base.BaseLocalizer.forward_test", "base.BaseLocalizer.forward_train"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer._parse_losses": [[59, 94], ["collections.OrderedDict", "losses.items", "sum", "collections.OrderedDict.items", "isinstance", "loss_value.data.clone.data.clone.item", "loss_value.data.clone.data.clone.mean", "isinstance", "torch.is_available", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "torch.is_initialized", "loss_value.data.clone.data.clone.data.clone", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "sum", "TypeError", "collections.OrderedDict.items", "loss_value.data.clone.data.clone.div_", "torch.get_world_size", "torch.get_world_size", "torch.get_world_size", "_loss.mean"], "methods", ["None"], ["ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n", "                ", "class_prob", ".", "append", "(", "len", "(", "samples", ")", "/", "len", "(", "self", ".", "video_infos", ")", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.train_step": [[95, 131], ["base.BaseLocalizer.forward", "base.BaseLocalizer._parse_losses", "dict", "len", "next", "iter", "data_batch.values"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.forward", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer._parse_losses"], ["", "class_prob", "=", "[", "x", "**", "self", ".", "power", "for", "x", "in", "class_prob", "]", "\n", "\n", "summ", "=", "sum", "(", "class_prob", ")", "\n", "class_prob", "=", "[", "x", "/", "summ", "for", "x", "in", "class_prob", "]", "\n", "\n", "self", ".", "class_prob", "=", "dict", "(", "zip", "(", "self", ".", "video_infos_by_class", ",", "class_prob", ")", ")", "\n", "\n", "", "", "@", "abstractmethod", "\n", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "\n", "# json annotations already looks like video_infos, so for each dataset,", "\n", "# this func should be the same", "\n", "", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "path_key", "=", "'frame_dir'", "if", "'frame_dir'", "in", "video_infos", "[", "0", "]", "else", "'filename'", "\n", "for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n", "if", "self", ".", "multi_class", ":", "\n", "                ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "video_infos", "[", "i", "]", "[", "'label'", "]", ")", "==", "1", "\n", "video_infos", "[", "i", "]", "[", "'label'", "]", "=", "video_infos", "[", "i", "]", "[", "'label'", "]", "[", "0", "]", "\n", "", "", "return", "video_infos", "\n", "\n", "", "def", "parse_by_class", "(", "self", ")", ":", "\n", "        ", "video_infos_by_class", "=", "defaultdict", "(", "list", ")", "\n", "for", "item", "in", "self", ".", "video_infos", ":", "\n", "            ", "label", "=", "item", "[", "'label'", "]", "\n", "video_infos_by_class", "[", "label", "]", ".", "append", "(", "item", ")", "\n", "", "return", "video_infos_by_class", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.val_step": [[132, 144], ["base.BaseLocalizer.forward", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.forward"], ["", "@", "staticmethod", "\n", "def", "label2array", "(", "num", ",", "label", ")", ":", "\n", "        ", "arr", "=", "np", ".", "zeros", "(", "num", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr", "[", "label", "]", "=", "1.", "\n", "return", "arr", "\n", "\n", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'top_k_accuracy'", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "(", "1", ",", "5", ")", ")", ")", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.ssn.SSN.__init__": [[28, 57], ["dict", "base.BaseLocalizer.__init__", "builder.build_loss", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Dropout", "torch.Dropout", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_loss"], ["def", "__init__", "(", "self", ",", "\n", "backbone", ",", "\n", "cls_head", ",", "\n", "in_channels", "=", "3", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.5", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'SSNLoss'", ")", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "backbone", ",", "cls_head", ",", "train_cfg", ",", "test_cfg", ")", "\n", "\n", "self", ".", "is_test_prepared", "=", "False", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "(", "7", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "", "elif", "self", ".", "spatial_type", "==", "'max'", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "(", "7", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pool", "=", "None", "\n", "\n", "", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "loss_cls", "=", "builder", ".", "build_loss", "(", "loss_cls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.ssn.SSN.forward_train": [[58, 79], ["imgs.reshape.reshape.reshape", "ssn.SSN.extract_feat", "ssn.SSN.cls_head", "ssn.SSN.loss_cls", "dict", "ssn.SSN.pool", "ssn.SSN.dropout"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat"], ["", "def", "forward_train", "(", "self", ",", "imgs", ",", "proposal_scale_factor", ",", "proposal_type", ",", "\n", "proposal_labels", ",", "reg_targets", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when training.\"\"\"", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "in_channels", ")", "+", "imgs", ".", "shape", "[", "4", ":", "]", ")", "\n", "\n", "x", "=", "self", ".", "extract_feat", "(", "imgs", ")", "\n", "\n", "if", "self", ".", "pool", ":", "\n", "            ", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "activity_scores", ",", "completeness_scores", ",", "bbox_preds", "=", "self", ".", "cls_head", "(", "\n", "(", "x", ",", "proposal_scale_factor", ")", ")", "\n", "\n", "loss", "=", "self", ".", "loss_cls", "(", "activity_scores", ",", "completeness_scores", ",", "bbox_preds", ",", "\n", "proposal_type", ",", "proposal_labels", ",", "reg_targets", ",", "\n", "self", ".", "train_cfg", ")", "\n", "loss_dict", "=", "dict", "(", "**", "loss", ")", "\n", "\n", "return", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.ssn.SSN.forward_test": [[80, 135], ["imgs.reshape.reshape.reshape", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "relative_proposal_list.cpu().numpy.cpu().numpy.squeeze", "proposal_tick_list.squeeze.squeeze.squeeze", "scale_factor_list.squeeze.squeeze.squeeze", "reg_norm_consts.squeeze.squeeze.squeeze", "ssn.SSN.cls_head", "relative_proposal_list.cpu().numpy.cpu().numpy.cpu().numpy", "activity_scores.cpu().numpy.cpu().numpy.cpu().numpy", "completeness_scores.cpu().numpy.cpu().numpy.cpu().numpy", "imgs[].view", "ssn.SSN.extract_feat", "ssn.SSN.reshape().mean", "torch.cat.append", "torch.cat.append", "ssn.SSN.cls_head.prepare_test_fc", "bbox_preds.cpu().numpy.cpu().numpy.view", "bbox_preds.cpu().numpy.cpu().numpy.cpu().numpy", "dict", "ssn.SSN.pool", "relative_proposal_list.cpu().numpy.cpu().numpy.cpu", "activity_scores.cpu().numpy.cpu().numpy.cpu", "completeness_scores.cpu().numpy.cpu().numpy.cpu", "ssn.SSN.reshape", "bbox_preds.cpu().numpy.cpu().numpy.cpu", "ssn.SSN.size"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.base.BaseLocalizer.extract_feat", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.SSNHead.prepare_test_fc"], ["", "def", "forward_test", "(", "self", ",", "imgs", ",", "relative_proposal_list", ",", "scale_factor_list", ",", "\n", "proposal_tick_list", ",", "reg_norm_consts", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when testing.\"\"\"", "\n", "num_crops", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "imgs", "=", "imgs", ".", "reshape", "(", "(", "num_crops", ",", "-", "1", ",", "self", ".", "in_channels", ")", "+", "imgs", ".", "shape", "[", "3", ":", "]", ")", "\n", "num_ticks", "=", "imgs", ".", "shape", "[", "1", "]", "\n", "\n", "output", "=", "[", "]", "\n", "minibatch_size", "=", "self", ".", "test_cfg", ".", "ssn", ".", "sampler", ".", "batch_size", "\n", "for", "idx", "in", "range", "(", "0", ",", "num_ticks", ",", "minibatch_size", ")", ":", "\n", "            ", "chunk", "=", "imgs", "[", ":", ",", "idx", ":", "idx", "+", "\n", "minibatch_size", ",", ":", ",", ":", ",", ":", "]", ".", "view", "(", "(", "-", "1", ",", ")", "+", "imgs", ".", "shape", "[", "2", ":", "]", ")", "\n", "x", "=", "self", ".", "extract_feat", "(", "chunk", ")", "\n", "if", "self", ".", "pool", ":", "\n", "                ", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "# Merge crop to save memory.", "\n", "", "x", "=", "x", ".", "reshape", "(", "(", "num_crops", ",", "x", ".", "size", "(", "0", ")", "//", "num_crops", ",", "-", "1", ")", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "output", ".", "append", "(", "x", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "output", ",", "dim", "=", "0", ")", "\n", "\n", "relative_proposal_list", "=", "relative_proposal_list", ".", "squeeze", "(", "0", ")", "\n", "proposal_tick_list", "=", "proposal_tick_list", ".", "squeeze", "(", "0", ")", "\n", "scale_factor_list", "=", "scale_factor_list", ".", "squeeze", "(", "0", ")", "\n", "reg_norm_consts", "=", "reg_norm_consts", ".", "squeeze", "(", "0", ")", "\n", "\n", "if", "not", "self", ".", "is_test_prepared", ":", "\n", "            ", "self", ".", "is_test_prepared", "=", "self", ".", "cls_head", ".", "prepare_test_fc", "(", "\n", "self", ".", "cls_head", ".", "consensus", ".", "num_multipliers", ")", "\n", "\n", "", "(", "output", ",", "activity_scores", ",", "completeness_scores", ",", "\n", "bbox_preds", ")", "=", "self", ".", "cls_head", "(", "\n", "(", "output", ",", "proposal_tick_list", ",", "scale_factor_list", ")", ",", "test_mode", "=", "True", ")", "\n", "\n", "relative_proposal_list", "=", "relative_proposal_list", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "activity_scores", "=", "activity_scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "completeness_scores", "=", "completeness_scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "bbox_preds", "is", "not", "None", ":", "\n", "            ", "bbox_preds", "=", "bbox_preds", ".", "view", "(", "-", "1", ",", "self", ".", "cls_head", ".", "num_classes", ",", "2", ")", "\n", "bbox_preds", "[", ":", ",", ":", ",", "0", "]", "=", "(", "\n", "bbox_preds", "[", ":", ",", ":", ",", "0", "]", "*", "reg_norm_consts", "[", "1", ",", "0", "]", "+", "\n", "reg_norm_consts", "[", "0", ",", "0", "]", ")", "\n", "bbox_preds", "[", ":", ",", ":", ",", "1", "]", "=", "(", "\n", "bbox_preds", "[", ":", ",", ":", ",", "1", "]", "*", "reg_norm_consts", "[", "1", ",", "1", "]", "+", "\n", "reg_norm_consts", "[", "0", ",", "1", "]", ")", "\n", "bbox_preds", "=", "bbox_preds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "result", "=", "[", "\n", "dict", "(", "\n", "relative_proposal_list", "=", "relative_proposal_list", ",", "\n", "activity_scores", "=", "activity_scores", ",", "\n", "completeness_scores", "=", "completeness_scores", ",", "\n", "bbox_preds", "=", "bbox_preds", ")", "\n", "]", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN.__init__": [[40, 137], ["dict", "base.BaseLocalizer.__init__", "builder.build_loss", "bmn.BMN._get_interp1d_mask", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "bmn.BMN._temporal_anchors", "bmn.BMN._match_map", "bmn.BMN._get_bm_mask", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Sigmoid", "torch.Sigmoid", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Sigmoid", "torch.Sigmoid", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.Conv3d", "torch.Conv3d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._get_interp1d_mask", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM._temporal_anchors", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._match_map", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._get_bm_mask"], ["def", "__init__", "(", "self", ",", "\n", "temporal_dim", ",", "\n", "boundary_ratio", ",", "\n", "num_samples", ",", "\n", "num_samples_per_bin", ",", "\n", "feat_dim", ",", "\n", "soft_nms_alpha", ",", "\n", "soft_nms_low_threshold", ",", "\n", "soft_nms_high_threshold", ",", "\n", "post_process_top_k", ",", "\n", "feature_extraction_interval", "=", "16", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'BMNLoss'", ")", ",", "\n", "hidden_dim_1d", "=", "256", ",", "\n", "hidden_dim_2d", "=", "128", ",", "\n", "hidden_dim_3d", "=", "512", ")", ":", "\n", "        ", "super", "(", "BaseLocalizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "tscale", "=", "temporal_dim", "\n", "self", ".", "boundary_ratio", "=", "boundary_ratio", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "num_samples_per_bin", "=", "num_samples_per_bin", "\n", "self", ".", "feat_dim", "=", "feat_dim", "\n", "self", ".", "soft_nms_alpha", "=", "soft_nms_alpha", "\n", "self", ".", "soft_nms_low_threshold", "=", "soft_nms_low_threshold", "\n", "self", ".", "soft_nms_high_threshold", "=", "soft_nms_high_threshold", "\n", "self", ".", "post_process_top_k", "=", "post_process_top_k", "\n", "self", ".", "feature_extraction_interval", "=", "feature_extraction_interval", "\n", "self", ".", "loss_cls", "=", "build_loss", "(", "loss_cls", ")", "\n", "self", ".", "hidden_dim_1d", "=", "hidden_dim_1d", "\n", "self", ".", "hidden_dim_2d", "=", "hidden_dim_2d", "\n", "self", ".", "hidden_dim_3d", "=", "hidden_dim_3d", "\n", "\n", "self", ".", "_get_interp1d_mask", "(", ")", "\n", "\n", "# Base Module", "\n", "self", ".", "x_1d_b", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "self", ".", "feat_dim", ",", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "4", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv1d", "(", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "4", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "# Temporal Evaluation Module", "\n", "self", ".", "x_1d_s", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "4", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv1d", "(", "self", ".", "hidden_dim_1d", ",", "1", ",", "kernel_size", "=", "1", ")", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "self", ".", "x_1d_e", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "4", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv1d", "(", "self", ".", "hidden_dim_1d", ",", "1", ",", "kernel_size", "=", "1", ")", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n", "# Proposal Evaluation Module", "\n", "self", ".", "x_1d_p", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "x_3d_p", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "\n", "self", ".", "hidden_dim_1d", ",", "\n", "self", ".", "hidden_dim_3d", ",", "\n", "kernel_size", "=", "(", "self", ".", "num_samples", ",", "1", ",", "1", ")", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "x_2d_p", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "hidden_dim_3d", ",", "self", ".", "hidden_dim_2d", ",", "kernel_size", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "\n", "self", ".", "hidden_dim_2d", ",", "\n", "self", ".", "hidden_dim_2d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "\n", "self", ".", "hidden_dim_2d", ",", "\n", "self", ".", "hidden_dim_2d", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "self", ".", "hidden_dim_2d", ",", "2", ",", "kernel_size", "=", "1", ")", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "self", ".", "anchors_tmins", ",", "self", ".", "anchors_tmaxs", "=", "self", ".", "_temporal_anchors", "(", "\n", "-", "0.5", ",", "1.5", ")", "\n", "self", ".", "match_map", "=", "self", ".", "_match_map", "(", ")", "\n", "self", ".", "bm_mask", "=", "self", ".", "_get_bm_mask", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._match_map": [[138, 153], ["range", "numpy.array", "numpy.transpose", "numpy.reshape", "range", "numpy.reshape.append", "match_window.append"], "methods", ["None"], ["", "def", "_match_map", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generate match map.\"\"\"", "\n", "temporal_gap", "=", "1.", "/", "self", ".", "tscale", "\n", "match_map", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "            ", "match_window", "=", "[", "]", "\n", "tmin", "=", "temporal_gap", "*", "idx", "\n", "for", "jdx", "in", "range", "(", "1", ",", "self", ".", "tscale", "+", "1", ")", ":", "\n", "                ", "tmax", "=", "tmin", "+", "temporal_gap", "*", "jdx", "\n", "match_window", ".", "append", "(", "[", "tmin", ",", "tmax", "]", ")", "\n", "", "match_map", ".", "append", "(", "match_window", ")", "\n", "", "match_map", "=", "np", ".", "array", "(", "match_map", ")", "\n", "match_map", "=", "np", ".", "transpose", "(", "match_map", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "match_map", "=", "np", ".", "reshape", "(", "match_map", ",", "[", "-", "1", ",", "2", "]", ")", "\n", "return", "match_map", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._temporal_anchors": [[154, 175], ["range", "anchors_tmins.append", "anchors_tmaxs.append"], "methods", ["None"], ["", "def", "_temporal_anchors", "(", "self", ",", "tmin_offset", "=", "0.", ",", "tmax_offset", "=", "1.", ")", ":", "\n", "        ", "\"\"\"Generate temporal anchors.\n\n        Args:\n            tmin_offset (int): Offset for the minimum value of temporal anchor.\n                Default: 0.\n            tmax_offset (int): Offset for the maximun value of temporal anchor.\n                Default: 1.\n\n        Returns:\n            tuple[Sequence[float]]: The minimum and maximum values of temporal\n                anchors.\n        \"\"\"", "\n", "temporal_gap", "=", "1.", "/", "self", ".", "tscale", "\n", "anchors_tmins", "=", "[", "]", "\n", "anchors_tmaxs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "            ", "anchors_tmins", ".", "append", "(", "temporal_gap", "*", "(", "i", "+", "tmin_offset", ")", ")", "\n", "anchors_tmaxs", ".", "append", "(", "temporal_gap", "*", "(", "i", "+", "tmax_offset", ")", ")", "\n", "\n", "", "return", "anchors_tmins", ",", "anchors_tmaxs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._forward": [[176, 202], ["bmn.BMN.x_1d_b", "bmn.BMN.x_1d_s().squeeze", "bmn.BMN.x_1d_e().squeeze", "bmn.BMN.x_1d_p", "bmn.BMN._boundary_matching_layer", "bmn.BMN.x_3d_p().squeeze", "bmn.BMN.x_2d_p", "bmn.BMN.x_1d_s", "bmn.BMN.x_1d_e", "bmn.BMN.x_3d_p"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._boundary_matching_layer"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "# x.shape [batch_size, self.feat_dim, self.tscale]", "\n", "base_feature", "=", "self", ".", "x_1d_b", "(", "x", ")", "\n", "# base_feature.shape [batch_size, self.hidden_dim_1d, self.tscale]", "\n", "start", "=", "self", ".", "x_1d_s", "(", "base_feature", ")", ".", "squeeze", "(", "1", ")", "\n", "# start.shape [batch_size, self.tscale]", "\n", "end", "=", "self", ".", "x_1d_e", "(", "base_feature", ")", ".", "squeeze", "(", "1", ")", "\n", "# end.shape [batch_size, self.tscale]", "\n", "confidence_map", "=", "self", ".", "x_1d_p", "(", "base_feature", ")", "\n", "# [batch_size, self.hidden_dim_1d, self.tscale]", "\n", "confidence_map", "=", "self", ".", "_boundary_matching_layer", "(", "confidence_map", ")", "\n", "# [batch_size, self.hidden_dim_1d,, self.num_sampls, self.tscale, self.tscale] # noqa", "\n", "confidence_map", "=", "self", ".", "x_3d_p", "(", "confidence_map", ")", ".", "squeeze", "(", "2", ")", "\n", "# [batch_size, self.hidden_dim_3d, self.tscale, self.tscale]", "\n", "confidence_map", "=", "self", ".", "x_2d_p", "(", "confidence_map", ")", "\n", "# [batch_size, 2, self.tscale, self.tscale]", "\n", "\n", "return", "confidence_map", ",", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._boundary_matching_layer": [[203, 212], ["x.size", "torch.matmul().reshape", "torch.matmul().reshape", "torch.matmul().reshape", "torch.matmul().reshape", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "_boundary_matching_layer", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Generate matching layer.\"\"\"", "\n", "input_size", "=", "x", ".", "size", "(", ")", "\n", "out", "=", "torch", ".", "matmul", "(", "x", ",", "\n", "self", ".", "sample_mask", ")", ".", "reshape", "(", "input_size", "[", "0", "]", ",", "\n", "input_size", "[", "1", "]", ",", "\n", "self", ".", "num_samples", ",", "\n", "self", ".", "tscale", ",", "self", ".", "tscale", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN.forward_test": [[213, 274], ["bmn.BMN._forward", "start[].cpu().numpy", "end[].cpu().numpy", "[].cpu().numpy", "[].cpu().numpy", "max", "max", "numpy.zeros", "numpy.zeros", "range", "range", "numpy.stack", "dict", "utils.post_processing", "len", "len", "range", "dict", "start[].cpu", "end[].cpu", "[].cpu", "[].cpu", "numpy.stack.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.post_processing.post_processing"], ["", "def", "forward_test", "(", "self", ",", "raw_feature", ",", "video_meta", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when testing.\"\"\"", "\n", "confidence_map", ",", "start", ",", "end", "=", "self", ".", "_forward", "(", "raw_feature", ")", "\n", "start_scores", "=", "start", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "end_scores", "=", "end", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cls_confidence", "=", "(", "confidence_map", "[", "0", "]", "[", "1", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "reg_confidence", "=", "(", "confidence_map", "[", "0", "]", "[", "0", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "max_start", "=", "max", "(", "start_scores", ")", "\n", "max_end", "=", "max", "(", "end_scores", ")", "\n", "\n", "# generate the set of start points and end points", "\n", "start_bins", "=", "np", ".", "zeros", "(", "len", "(", "start_scores", ")", ")", "\n", "start_bins", "[", "0", "]", "=", "1", "# [1,0,0...,0,0]", "\n", "end_bins", "=", "np", ".", "zeros", "(", "len", "(", "end_scores", ")", ")", "\n", "end_bins", "[", "-", "1", "]", "=", "1", "# [0,0,0...,0,1]", "\n", "for", "idx", "in", "range", "(", "1", ",", "self", ".", "tscale", "-", "1", ")", ":", "\n", "            ", "if", "start_scores", "[", "idx", "]", ">", "start_scores", "[", "\n", "idx", "+", "1", "]", "and", "start_scores", "[", "idx", "]", ">", "start_scores", "[", "idx", "-", "1", "]", ":", "\n", "                ", "start_bins", "[", "idx", "]", "=", "1", "\n", "", "elif", "start_scores", "[", "idx", "]", ">", "(", "0.5", "*", "max_start", ")", ":", "\n", "                ", "start_bins", "[", "idx", "]", "=", "1", "\n", "", "if", "end_scores", "[", "idx", "]", ">", "end_scores", "[", "\n", "idx", "+", "1", "]", "and", "end_scores", "[", "idx", "]", ">", "end_scores", "[", "idx", "-", "1", "]", ":", "\n", "                ", "end_bins", "[", "idx", "]", "=", "1", "\n", "", "elif", "end_scores", "[", "idx", "]", ">", "(", "0.5", "*", "max_end", ")", ":", "\n", "                ", "end_bins", "[", "idx", "]", "=", "1", "\n", "\n", "# iterate through all combinations of start_index and end_index", "\n", "", "", "new_proposals", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "            ", "for", "jdx", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "                ", "start_index", "=", "jdx", "\n", "end_index", "=", "start_index", "+", "idx", "+", "1", "\n", "if", "end_index", "<", "self", ".", "tscale", "and", "start_bins", "[", "\n", "start_index", "]", "==", "1", "and", "end_bins", "[", "end_index", "]", "==", "1", ":", "\n", "                    ", "tmin", "=", "start_index", "/", "self", ".", "tscale", "\n", "tmax", "=", "end_index", "/", "self", ".", "tscale", "\n", "tmin_score", "=", "start_scores", "[", "start_index", "]", "\n", "tmax_score", "=", "end_scores", "[", "end_index", "]", "\n", "cls_score", "=", "cls_confidence", "[", "idx", ",", "jdx", "]", "\n", "reg_score", "=", "reg_confidence", "[", "idx", ",", "jdx", "]", "\n", "score", "=", "tmin_score", "*", "tmax_score", "*", "cls_score", "*", "reg_score", "\n", "new_proposals", ".", "append", "(", "[", "\n", "tmin", ",", "tmax", ",", "tmin_score", ",", "tmax_score", ",", "cls_score", ",", "\n", "reg_score", ",", "score", "\n", "]", ")", "\n", "", "", "", "new_proposals", "=", "np", ".", "stack", "(", "new_proposals", ")", "\n", "video_info", "=", "dict", "(", "video_meta", "[", "0", "]", ")", "\n", "proposal_list", "=", "post_processing", "(", "new_proposals", ",", "video_info", ",", "\n", "self", ".", "soft_nms_alpha", ",", "\n", "self", ".", "soft_nms_low_threshold", ",", "\n", "self", ".", "soft_nms_high_threshold", ",", "\n", "self", ".", "post_process_top_k", ",", "\n", "self", ".", "feature_extraction_interval", ")", "\n", "output", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "video_info", "[", "'video_name'", "]", ",", "\n", "proposal_list", "=", "proposal_list", ")", "\n", "]", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN.forward_train": [[275, 284], ["bmn.BMN._forward", "bmn.BMN.loss_cls", "dict", "bmn.BMN.bm_mask.to"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward"], ["", "def", "forward_train", "(", "self", ",", "raw_feature", ",", "label_confidence", ",", "label_start", ",", "\n", "label_end", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when training.\"\"\"", "\n", "confidence_map", ",", "start", ",", "end", "=", "self", ".", "_forward", "(", "raw_feature", ")", "\n", "loss", "=", "self", ".", "loss_cls", "(", "confidence_map", ",", "start", ",", "end", ",", "label_confidence", ",", "\n", "label_start", ",", "label_end", ",", "\n", "self", ".", "bm_mask", ".", "to", "(", "raw_feature", ".", "device", ")", ")", "\n", "loss_dict", "=", "dict", "(", "loss", "=", "loss", "[", "0", "]", ")", "\n", "return", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN.generate_labels": [[285, 338], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.array().astype", "numpy.max", "numpy.stack", "numpy.stack", "zip", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "isinstance", "isinstance", "localization.temporal_iou", "numpy.reshape", "numpy.max.append", "match_score_start.append", "match_score_end.append", "start.numpy.numpy.numpy", "end.numpy.numpy.numpy", "numpy.array", "numpy.max", "numpy.max", "localization.temporal_iop", "localization.temporal_iop"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop"], ["", "def", "generate_labels", "(", "self", ",", "gt_bbox", ")", ":", "\n", "        ", "\"\"\"Generate training labels.\"\"\"", "\n", "match_score_confidence_list", "=", "[", "]", "\n", "match_score_start_list", "=", "[", "]", "\n", "match_score_end_list", "=", "[", "]", "\n", "for", "every_gt_bbox", "in", "gt_bbox", ":", "\n", "            ", "gt_iou_map", "=", "[", "]", "\n", "for", "start", ",", "end", "in", "every_gt_bbox", ":", "\n", "                ", "if", "isinstance", "(", "start", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "start", "=", "start", ".", "numpy", "(", ")", "\n", "", "if", "isinstance", "(", "end", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "end", "=", "end", ".", "numpy", "(", ")", "\n", "", "current_gt_iou_map", "=", "temporal_iou", "(", "self", ".", "match_map", "[", ":", ",", "0", "]", ",", "\n", "self", ".", "match_map", "[", ":", ",", "1", "]", ",", "start", ",", "\n", "end", ")", "\n", "current_gt_iou_map", "=", "np", ".", "reshape", "(", "current_gt_iou_map", ",", "\n", "[", "self", ".", "tscale", ",", "self", ".", "tscale", "]", ")", "\n", "gt_iou_map", ".", "append", "(", "current_gt_iou_map", ")", "\n", "", "gt_iou_map", "=", "np", ".", "array", "(", "gt_iou_map", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "gt_iou_map", "=", "np", ".", "max", "(", "gt_iou_map", ",", "axis", "=", "0", ")", "\n", "\n", "gt_tmins", "=", "every_gt_bbox", "[", ":", ",", "0", "]", "\n", "gt_tmaxs", "=", "every_gt_bbox", "[", ":", ",", "1", "]", "\n", "\n", "gt_len_pad", "=", "3", "*", "(", "1.", "/", "self", ".", "tscale", ")", "\n", "\n", "gt_start_bboxs", "=", "np", ".", "stack", "(", "\n", "(", "gt_tmins", "-", "gt_len_pad", "/", "2", ",", "gt_tmins", "+", "gt_len_pad", "/", "2", ")", ",", "axis", "=", "1", ")", "\n", "gt_end_bboxs", "=", "np", ".", "stack", "(", "\n", "(", "gt_tmaxs", "-", "gt_len_pad", "/", "2", ",", "gt_tmaxs", "+", "gt_len_pad", "/", "2", ")", ",", "axis", "=", "1", ")", "\n", "\n", "match_score_start", "=", "[", "]", "\n", "match_score_end", "=", "[", "]", "\n", "\n", "for", "anchor_tmin", ",", "anchor_tmax", "in", "zip", "(", "self", ".", "anchors_tmins", ",", "\n", "self", ".", "anchors_tmaxs", ")", ":", "\n", "                ", "match_score_start", ".", "append", "(", "\n", "np", ".", "max", "(", "\n", "temporal_iop", "(", "anchor_tmin", ",", "anchor_tmax", ",", "\n", "gt_start_bboxs", "[", ":", ",", "0", "]", ",", "gt_start_bboxs", "[", ":", ",", "\n", "1", "]", ")", ")", ")", "\n", "match_score_end", ".", "append", "(", "\n", "np", ".", "max", "(", "\n", "temporal_iop", "(", "anchor_tmin", ",", "anchor_tmax", ",", "\n", "gt_end_bboxs", "[", ":", ",", "0", "]", ",", "gt_end_bboxs", "[", ":", ",", "1", "]", ")", ")", ")", "\n", "", "match_score_confidence_list", ".", "append", "(", "gt_iou_map", ")", "\n", "match_score_start_list", ".", "append", "(", "match_score_start", ")", "\n", "match_score_end_list", ".", "append", "(", "match_score_end", ")", "\n", "", "match_score_confidence_list", "=", "torch", ".", "Tensor", "(", "match_score_confidence_list", ")", "\n", "match_score_start_list", "=", "torch", ".", "Tensor", "(", "match_score_start_list", ")", "\n", "match_score_end_list", "=", "torch", ".", "Tensor", "(", "match_score_end_list", ")", "\n", "return", "(", "match_score_confidence_list", ",", "match_score_start_list", ",", "\n", "match_score_end_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN.forward": [[339, 356], ["bmn.BMN.forward_test", "bmn.BMN.generate_labels", "label_confidence.to.to.to", "label_start.to.to.to", "label_end.to.to.to", "bmn.BMN.forward_train"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.generate_labels", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train"], ["", "def", "forward", "(", "self", ",", "\n", "raw_feature", ",", "\n", "gt_bbox", "=", "None", ",", "\n", "video_meta", "=", "None", ",", "\n", "return_loss", "=", "True", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "label_confidence", ",", "label_start", ",", "label_end", "=", "(", "\n", "self", ".", "generate_labels", "(", "gt_bbox", ")", ")", "\n", "device", "=", "raw_feature", ".", "device", "\n", "label_confidence", "=", "label_confidence", ".", "to", "(", "device", ")", "\n", "label_start", "=", "label_start", ".", "to", "(", "device", ")", "\n", "label_end", "=", "label_end", ".", "to", "(", "device", ")", "\n", "return", "self", ".", "forward_train", "(", "raw_feature", ",", "label_confidence", ",", "\n", "label_start", ",", "label_end", ")", "\n", "\n", "", "return", "self", ".", "forward_test", "(", "raw_feature", ",", "video_meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._get_interp1d_bin_mask": [[357, 383], ["float", "range", "numpy.stack", "numpy.zeros", "numpy.stack.append", "range", "math.ceil", "math.modf", "int", "int", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_interp1d_bin_mask", "(", "seg_tmin", ",", "seg_tmax", ",", "tscale", ",", "num_samples", ",", "\n", "num_samples_per_bin", ")", ":", "\n", "        ", "\"\"\"Generate sample mask for a boundary-matching pair.\"\"\"", "\n", "plen", "=", "float", "(", "seg_tmax", "-", "seg_tmin", ")", "\n", "plen_sample", "=", "plen", "/", "(", "num_samples", "*", "num_samples_per_bin", "-", "1.0", ")", "\n", "total_samples", "=", "[", "\n", "seg_tmin", "+", "plen_sample", "*", "i", "\n", "for", "i", "in", "range", "(", "num_samples", "*", "num_samples_per_bin", ")", "\n", "]", "\n", "p_mask", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "bin_samples", "=", "total_samples", "[", "idx", "*", "num_samples_per_bin", ":", "(", "idx", "+", "1", ")", "*", "\n", "num_samples_per_bin", "]", "\n", "bin_vector", "=", "np", ".", "zeros", "(", "tscale", ")", "\n", "for", "sample", "in", "bin_samples", ":", "\n", "                ", "sample_upper", "=", "math", ".", "ceil", "(", "sample", ")", "\n", "sample_decimal", ",", "sample_down", "=", "math", ".", "modf", "(", "sample", ")", "\n", "if", "0", "<=", "int", "(", "sample_down", ")", "<=", "(", "tscale", "-", "1", ")", ":", "\n", "                    ", "bin_vector", "[", "int", "(", "sample_down", ")", "]", "+=", "1", "-", "sample_decimal", "\n", "", "if", "0", "<=", "int", "(", "sample_upper", ")", "<=", "(", "tscale", "-", "1", ")", ":", "\n", "                    ", "bin_vector", "[", "int", "(", "sample_upper", ")", "]", "+=", "sample_decimal", "\n", "", "", "bin_vector", "=", "1.0", "/", "num_samples_per_bin", "*", "bin_vector", "\n", "p_mask", ".", "append", "(", "bin_vector", ")", "\n", "", "p_mask", "=", "np", ".", "stack", "(", "p_mask", ",", "axis", "=", "1", ")", "\n", "return", "p_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._get_interp1d_mask": [[384, 408], ["range", "numpy.stack", "mask_mat.astype.astype.astype", "torch.Parameter", "torch.Parameter", "range", "numpy.stack", "mask_mat.astype.astype.append", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "numpy.stack.append", "bmn.BMN._get_interp1d_bin_mask", "numpy.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "float"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._get_interp1d_bin_mask"], ["", "def", "_get_interp1d_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generate sample mask for each point in Boundary-Matching Map.\"\"\"", "\n", "mask_mat", "=", "[", "]", "\n", "for", "start_index", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "            ", "mask_mat_vector", "=", "[", "]", "\n", "for", "duration_index", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "                ", "if", "start_index", "+", "duration_index", "<", "self", ".", "tscale", ":", "\n", "                    ", "p_tmin", "=", "start_index", "\n", "p_tmax", "=", "start_index", "+", "duration_index", "\n", "center_len", "=", "float", "(", "p_tmax", "-", "p_tmin", ")", "+", "1", "\n", "sample_tmin", "=", "p_tmin", "-", "(", "center_len", "*", "self", ".", "boundary_ratio", ")", "\n", "sample_tmax", "=", "p_tmax", "+", "(", "center_len", "*", "self", ".", "boundary_ratio", ")", "\n", "p_mask", "=", "self", ".", "_get_interp1d_bin_mask", "(", "\n", "sample_tmin", ",", "sample_tmax", ",", "self", ".", "tscale", ",", "\n", "self", ".", "num_samples", ",", "self", ".", "num_samples_per_bin", ")", "\n", "", "else", ":", "\n", "                    ", "p_mask", "=", "np", ".", "zeros", "(", "[", "self", ".", "tscale", ",", "self", ".", "num_samples", "]", ")", "\n", "", "mask_mat_vector", ".", "append", "(", "p_mask", ")", "\n", "", "mask_mat_vector", "=", "np", ".", "stack", "(", "mask_mat_vector", ",", "axis", "=", "2", ")", "\n", "mask_mat", ".", "append", "(", "mask_mat_vector", ")", "\n", "", "mask_mat", "=", "np", ".", "stack", "(", "mask_mat", ",", "axis", "=", "3", ")", "\n", "mask_mat", "=", "mask_mat", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "sample_mask", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "tensor", "(", "mask_mat", ")", ".", "view", "(", "self", ".", "tscale", ",", "-", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bmn.BMN._get_bm_mask": [[409, 417], ["range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.append", "torch.tensor.append"], "methods", ["None"], ["", "def", "_get_bm_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generate Boundary-Matching Mask.\"\"\"", "\n", "bm_mask", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "self", ".", "tscale", ")", ":", "\n", "            ", "mask_vector", "=", "[", "1", "]", "*", "(", "self", ".", "tscale", "-", "idx", ")", "+", "[", "0", "]", "*", "idx", "\n", "bm_mask", ".", "append", "(", "mask_vector", ")", "\n", "", "bm_mask", "=", "torch", ".", "tensor", "(", "bm_mask", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "return", "bm_mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.__init__": [[35, 82], ["dict", "base.BaseLocalizer.__init__", "builder.build_loss", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "bsn.TEM._temporal_anchors"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM._temporal_anchors"], ["def", "__init__", "(", "self", ",", "\n", "temporal_dim", ",", "\n", "boundary_ratio", ",", "\n", "tem_feat_dim", ",", "\n", "tem_hidden_dim", ",", "\n", "tem_match_threshold", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'BinaryLogisticRegressionLoss'", ")", ",", "\n", "loss_weight", "=", "2", ",", "\n", "output_dim", "=", "3", ",", "\n", "conv1_ratio", "=", "1", ",", "\n", "conv2_ratio", "=", "1", ",", "\n", "conv3_ratio", "=", "0.01", ")", ":", "\n", "        ", "super", "(", "BaseLocalizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "temporal_dim", "=", "temporal_dim", "\n", "self", ".", "boundary_ratio", "=", "boundary_ratio", "\n", "self", ".", "feat_dim", "=", "tem_feat_dim", "\n", "self", ".", "c_hidden", "=", "tem_hidden_dim", "\n", "self", ".", "match_threshold", "=", "tem_match_threshold", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "loss_cls", "=", "build_loss", "(", "loss_cls", ")", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "self", ".", "conv1_ratio", "=", "conv1_ratio", "\n", "self", ".", "conv2_ratio", "=", "conv2_ratio", "\n", "self", ".", "conv3_ratio", "=", "conv3_ratio", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "\n", "in_channels", "=", "self", ".", "feat_dim", ",", "\n", "out_channels", "=", "self", ".", "c_hidden", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "\n", "in_channels", "=", "self", ".", "c_hidden", ",", "\n", "out_channels", "=", "self", ".", "c_hidden", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "1", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv1d", "(", "\n", "in_channels", "=", "self", ".", "c_hidden", ",", "\n", "out_channels", "=", "self", ".", "output_dim", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ")", "\n", "self", ".", "anchors_tmins", ",", "self", ".", "anchors_tmaxs", "=", "self", ".", "_temporal_anchors", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM._temporal_anchors": [[83, 104], ["range", "anchors_tmins.append", "anchors_tmaxs.append"], "methods", ["None"], ["", "def", "_temporal_anchors", "(", "self", ",", "tmin_offset", "=", "0.", ",", "tmax_offset", "=", "1.", ")", ":", "\n", "        ", "\"\"\"Generate temporal anchors.\n\n        Args:\n            tmin_offset (int): Offset for the minimum value of temporal anchor.\n                Default: 0.\n            tmax_offset (int): Offset for the maximun value of temporal anchor.\n                Default: 1.\n\n        Returns:\n            tuple[Sequence[float]]: The minimum and maximum values of temporal\n                anchors.\n        \"\"\"", "\n", "temporal_gap", "=", "1.", "/", "self", ".", "temporal_dim", "\n", "anchors_tmins", "=", "[", "]", "\n", "anchors_tmaxs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "temporal_dim", ")", ":", "\n", "            ", "anchors_tmins", ".", "append", "(", "temporal_gap", "*", "(", "i", "+", "tmin_offset", ")", ")", "\n", "anchors_tmaxs", ".", "append", "(", "temporal_gap", "*", "(", "i", "+", "tmax_offset", ")", ")", "\n", "\n", "", "return", "anchors_tmins", ",", "anchors_tmaxs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM._forward": [[105, 118], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "bsn.TEM.conv1", "bsn.TEM.conv2", "bsn.TEM.conv3"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1_ratio", "*", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2_ratio", "*", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "torch", ".", "sigmoid", "(", "self", ".", "conv3_ratio", "*", "self", ".", "conv3", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.forward_train": [[119, 139], ["bsn.TEM._forward", "bsn.TEM.loss_cls", "bsn.TEM.loss_cls", "bsn.TEM.loss_cls"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward"], ["", "def", "forward_train", "(", "self", ",", "raw_feature", ",", "label_action", ",", "label_start", ",", "label_end", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when training.\"\"\"", "\n", "tem_output", "=", "self", ".", "_forward", "(", "raw_feature", ")", "\n", "score_action", "=", "tem_output", "[", ":", ",", "0", ",", ":", "]", "\n", "score_start", "=", "tem_output", "[", ":", ",", "1", ",", ":", "]", "\n", "score_end", "=", "tem_output", "[", ":", ",", "2", ",", ":", "]", "\n", "\n", "loss_action", "=", "self", ".", "loss_cls", "(", "score_action", ",", "label_action", ",", "\n", "self", ".", "match_threshold", ")", "\n", "loss_start_small", "=", "self", ".", "loss_cls", "(", "score_start", ",", "label_start", ",", "\n", "self", ".", "match_threshold", ")", "\n", "loss_end_small", "=", "self", ".", "loss_cls", "(", "score_end", ",", "label_end", ",", "\n", "self", ".", "match_threshold", ")", "\n", "loss_dict", "=", "{", "\n", "'loss_action'", ":", "loss_action", "*", "self", ".", "loss_weight", ",", "\n", "'loss_start'", ":", "loss_start_small", ",", "\n", "'loss_end'", ":", "loss_end_small", "\n", "}", "\n", "\n", "return", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.forward_test": [[140, 161], ["bsn.TEM._forward().cpu().numpy", "enumerate", "dict", "numpy.stack", "video_results.append", "bsn.TEM._forward().cpu", "bsn.TEM._forward"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward"], ["", "def", "forward_test", "(", "self", ",", "raw_feature", ",", "video_meta", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when testing.\"\"\"", "\n", "tem_output", "=", "self", ".", "_forward", "(", "raw_feature", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "batch_action", "=", "tem_output", "[", ":", ",", "0", ",", ":", "]", "\n", "batch_start", "=", "tem_output", "[", ":", ",", "1", ",", ":", "]", "\n", "batch_end", "=", "tem_output", "[", ":", ",", "2", ",", ":", "]", "\n", "\n", "video_meta_list", "=", "[", "dict", "(", "x", ")", "for", "x", "in", "video_meta", "]", "\n", "\n", "video_results", "=", "[", "]", "\n", "\n", "for", "batch_idx", ",", "_", "in", "enumerate", "(", "batch_action", ")", ":", "\n", "            ", "video_name", "=", "video_meta_list", "[", "batch_idx", "]", "[", "'video_name'", "]", "\n", "video_action", "=", "batch_action", "[", "batch_idx", "]", "\n", "video_start", "=", "batch_start", "[", "batch_idx", "]", "\n", "video_end", "=", "batch_end", "[", "batch_idx", "]", "\n", "video_result", "=", "np", ".", "stack", "(", "(", "video_action", ",", "video_start", ",", "video_end", ",", "\n", "self", ".", "anchors_tmins", ",", "self", ".", "anchors_tmaxs", ")", ",", "\n", "axis", "=", "1", ")", "\n", "video_results", ".", "append", "(", "(", "video_name", ",", "video_result", ")", ")", "\n", "", "return", "video_results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.generate_labels": [[162, 207], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "every_gt_bbox[].cpu().numpy", "every_gt_bbox[].cpu().numpy", "numpy.maximum", "numpy.stack", "numpy.stack", "zip", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "torch.Tensor.append", "match_score_action.append", "match_score_start.append", "match_score_end.append", "every_gt_bbox[].cpu", "every_gt_bbox[].cpu", "numpy.max", "numpy.max", "numpy.max", "localization.temporal_iop", "localization.temporal_iop", "localization.temporal_iop"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop"], ["", "def", "generate_labels", "(", "self", ",", "gt_bbox", ")", ":", "\n", "        ", "\"\"\"Generate training labels.\"\"\"", "\n", "match_score_action_list", "=", "[", "]", "\n", "match_score_start_list", "=", "[", "]", "\n", "match_score_end_list", "=", "[", "]", "\n", "for", "every_gt_bbox", "in", "gt_bbox", ":", "\n", "            ", "gt_tmins", "=", "every_gt_bbox", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "gt_tmaxs", "=", "every_gt_bbox", "[", ":", ",", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "gt_lens", "=", "gt_tmaxs", "-", "gt_tmins", "\n", "gt_len_pad", "=", "np", ".", "maximum", "(", "1.", "/", "self", ".", "temporal_dim", ",", "\n", "self", ".", "boundary_ratio", "*", "gt_lens", ")", "\n", "\n", "gt_start_bboxs", "=", "np", ".", "stack", "(", "\n", "(", "gt_tmins", "-", "gt_len_pad", "/", "2", ",", "gt_tmins", "+", "gt_len_pad", "/", "2", ")", ",", "axis", "=", "1", ")", "\n", "gt_end_bboxs", "=", "np", ".", "stack", "(", "\n", "(", "gt_tmaxs", "-", "gt_len_pad", "/", "2", ",", "gt_tmaxs", "+", "gt_len_pad", "/", "2", ")", ",", "axis", "=", "1", ")", "\n", "\n", "match_score_action", "=", "[", "]", "\n", "match_score_start", "=", "[", "]", "\n", "match_score_end", "=", "[", "]", "\n", "\n", "for", "anchor_tmin", ",", "anchor_tmax", "in", "zip", "(", "self", ".", "anchors_tmins", ",", "\n", "self", ".", "anchors_tmaxs", ")", ":", "\n", "                ", "match_score_action", ".", "append", "(", "\n", "np", ".", "max", "(", "\n", "temporal_iop", "(", "anchor_tmin", ",", "anchor_tmax", ",", "gt_tmins", ",", "\n", "gt_tmaxs", ")", ")", ")", "\n", "match_score_start", ".", "append", "(", "\n", "np", ".", "max", "(", "\n", "temporal_iop", "(", "anchor_tmin", ",", "anchor_tmax", ",", "\n", "gt_start_bboxs", "[", ":", ",", "0", "]", ",", "gt_start_bboxs", "[", ":", ",", "\n", "1", "]", ")", ")", ")", "\n", "match_score_end", ".", "append", "(", "\n", "np", ".", "max", "(", "\n", "temporal_iop", "(", "anchor_tmin", ",", "anchor_tmax", ",", "\n", "gt_end_bboxs", "[", ":", ",", "0", "]", ",", "gt_end_bboxs", "[", ":", ",", "1", "]", ")", ")", ")", "\n", "", "match_score_action_list", ".", "append", "(", "match_score_action", ")", "\n", "match_score_start_list", ".", "append", "(", "match_score_start", ")", "\n", "match_score_end_list", ".", "append", "(", "match_score_end", ")", "\n", "", "match_score_action_list", "=", "torch", ".", "Tensor", "(", "match_score_action_list", ")", "\n", "match_score_start_list", "=", "torch", ".", "Tensor", "(", "match_score_start_list", ")", "\n", "match_score_end_list", "=", "torch", ".", "Tensor", "(", "match_score_end_list", ")", "\n", "return", "(", "match_score_action_list", ",", "match_score_start_list", ",", "\n", "match_score_end_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.forward": [[208, 225], ["bsn.TEM.forward_test", "bsn.TEM.generate_labels", "label_action.to.to.to", "label_start.to.to.to", "label_end.to.to.to", "bsn.TEM.forward_train"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.TEM.generate_labels", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train"], ["", "def", "forward", "(", "self", ",", "\n", "raw_feature", ",", "\n", "gt_bbox", "=", "None", ",", "\n", "video_meta", "=", "None", ",", "\n", "return_loss", "=", "True", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "label_action", ",", "label_start", ",", "label_end", "=", "(", "\n", "self", ".", "generate_labels", "(", "gt_bbox", ")", ")", "\n", "device", "=", "raw_feature", ".", "device", "\n", "label_action", "=", "label_action", ".", "to", "(", "device", ")", "\n", "label_start", "=", "label_start", ".", "to", "(", "device", ")", "\n", "label_end", "=", "label_end", ".", "to", "(", "device", ")", "\n", "return", "self", ".", "forward_train", "(", "raw_feature", ",", "label_action", ",", "label_start", ",", "\n", "label_end", ")", "\n", "\n", "", "return", "self", ".", "forward_test", "(", "raw_feature", ",", "video_meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.PEM.__init__": [[256, 294], ["base.BaseLocalizer.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "pem_feat_dim", ",", "\n", "pem_hidden_dim", ",", "\n", "pem_u_ratio_m", ",", "\n", "pem_u_ratio_l", ",", "\n", "pem_high_temporal_iou_threshold", ",", "\n", "pem_low_temporal_iou_threshold", ",", "\n", "soft_nms_alpha", ",", "\n", "soft_nms_low_threshold", ",", "\n", "soft_nms_high_threshold", ",", "\n", "post_process_top_k", ",", "\n", "feature_extraction_interval", "=", "16", ",", "\n", "fc1_ratio", "=", "0.1", ",", "\n", "fc2_ratio", "=", "0.1", ",", "\n", "output_dim", "=", "1", ")", ":", "\n", "        ", "super", "(", "BaseLocalizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feat_dim", "=", "pem_feat_dim", "\n", "self", ".", "hidden_dim", "=", "pem_hidden_dim", "\n", "self", ".", "u_ratio_m", "=", "pem_u_ratio_m", "\n", "self", ".", "u_ratio_l", "=", "pem_u_ratio_l", "\n", "self", ".", "pem_high_temporal_iou_threshold", "=", "pem_high_temporal_iou_threshold", "\n", "self", ".", "pem_low_temporal_iou_threshold", "=", "pem_low_temporal_iou_threshold", "\n", "self", ".", "soft_nms_alpha", "=", "soft_nms_alpha", "\n", "self", ".", "soft_nms_low_threshold", "=", "soft_nms_low_threshold", "\n", "self", ".", "soft_nms_high_threshold", "=", "soft_nms_high_threshold", "\n", "self", ".", "post_process_top_k", "=", "post_process_top_k", "\n", "self", ".", "feature_extraction_interval", "=", "feature_extraction_interval", "\n", "self", ".", "fc1_ratio", "=", "fc1_ratio", "\n", "self", ".", "fc2_ratio", "=", "fc2_ratio", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "\n", "in_features", "=", "self", ".", "feat_dim", ",", "out_features", "=", "self", ".", "hidden_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "\n", "in_features", "=", "self", ".", "hidden_dim", ",", "\n", "out_features", "=", "self", ".", "output_dim", ",", "\n", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.PEM._forward": [[295, 308], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "list", "bsn.PEM.fc1", "bsn.PEM.fc2"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "x", "=", "torch", ".", "cat", "(", "list", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1_ratio", "*", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "torch", ".", "sigmoid", "(", "self", ".", "fc2_ratio", "*", "self", ".", "fc2", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.PEM.forward_train": [[309, 351], ["bsn.PEM._forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "reference_temporal_iou.to.to.to", "bsn.PEM.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.smooth_l1_loss", "torch.smooth_l1_loss", "torch.smooth_l1_loss", "dict", "list", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "u_hmask.size", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "u_hmask.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward"], ["", "def", "forward_train", "(", "self", ",", "bsp_feature", ",", "reference_temporal_iou", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when training.\"\"\"", "\n", "pem_output", "=", "self", ".", "_forward", "(", "bsp_feature", ")", "\n", "reference_temporal_iou", "=", "torch", ".", "cat", "(", "list", "(", "reference_temporal_iou", ")", ")", "\n", "device", "=", "pem_output", ".", "device", "\n", "reference_temporal_iou", "=", "reference_temporal_iou", ".", "to", "(", "device", ")", "\n", "\n", "anchors_temporal_iou", "=", "pem_output", ".", "view", "(", "-", "1", ")", "\n", "u_hmask", "=", "(", "reference_temporal_iou", ">", "\n", "self", ".", "pem_high_temporal_iou_threshold", ")", ".", "float", "(", ")", "\n", "u_mmask", "=", "(", "\n", "(", "reference_temporal_iou", "<=", "self", ".", "pem_high_temporal_iou_threshold", ")", "\n", "&", "(", "reference_temporal_iou", ">", "self", ".", "pem_low_temporal_iou_threshold", ")", "\n", ")", ".", "float", "(", ")", "\n", "u_lmask", "=", "(", "reference_temporal_iou", "<=", "\n", "self", ".", "pem_low_temporal_iou_threshold", ")", ".", "float", "(", ")", "\n", "\n", "num_h", "=", "torch", ".", "sum", "(", "u_hmask", ")", "\n", "num_m", "=", "torch", ".", "sum", "(", "u_mmask", ")", "\n", "num_l", "=", "torch", ".", "sum", "(", "u_lmask", ")", "\n", "\n", "r_m", "=", "self", ".", "u_ratio_m", "*", "num_h", "/", "(", "num_m", ")", "\n", "r_m", "=", "torch", ".", "min", "(", "r_m", ",", "torch", ".", "Tensor", "(", "[", "1.0", "]", ")", ".", "to", "(", "device", ")", ")", "[", "0", "]", "\n", "u_smmask", "=", "torch", ".", "rand", "(", "u_hmask", ".", "size", "(", ")", "[", "0", "]", ",", "device", "=", "device", ")", "\n", "u_smmask", "=", "u_smmask", "*", "u_mmask", "\n", "u_smmask", "=", "(", "u_smmask", ">", "(", "1.", "-", "r_m", ")", ")", ".", "float", "(", ")", "\n", "\n", "r_l", "=", "self", ".", "u_ratio_l", "*", "num_h", "/", "(", "num_l", ")", "\n", "r_l", "=", "torch", ".", "min", "(", "r_l", ",", "torch", ".", "Tensor", "(", "[", "1.0", "]", ")", ".", "to", "(", "device", ")", ")", "[", "0", "]", "\n", "u_slmask", "=", "torch", ".", "rand", "(", "u_hmask", ".", "size", "(", ")", "[", "0", "]", ",", "device", "=", "device", ")", "\n", "u_slmask", "=", "u_slmask", "*", "u_lmask", "\n", "u_slmask", "=", "(", "u_slmask", ">", "(", "1.", "-", "r_l", ")", ")", ".", "float", "(", ")", "\n", "\n", "temporal_iou_weights", "=", "u_hmask", "+", "u_smmask", "+", "u_slmask", "\n", "temporal_iou_loss", "=", "F", ".", "smooth_l1_loss", "(", "anchors_temporal_iou", ",", "\n", "reference_temporal_iou", ")", "\n", "temporal_iou_loss", "=", "torch", ".", "sum", "(", "\n", "temporal_iou_loss", "*", "\n", "temporal_iou_weights", ")", "/", "torch", ".", "sum", "(", "temporal_iou_weights", ")", "\n", "loss_dict", "=", "dict", "(", "temporal_iou_loss", "=", "temporal_iou_loss", ")", "\n", "\n", "return", "loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.PEM.forward_test": [[352, 379], ["bsn.PEM._forward().view().cpu().numpy().reshape", "tmin.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy().reshape", "tmax.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy().reshape", "tmin_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy().reshape", "tmax_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy().reshape", "numpy.array().reshape", "numpy.concatenate", "result.reshape.reshape.reshape", "dict", "utils.post_processing", "dict", "bsn.PEM._forward().view().cpu().numpy", "tmin.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy", "tmax.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy", "tmin_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy", "tmax_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu().numpy", "numpy.array", "bsn.PEM._forward().view().cpu", "tmin.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu", "tmax.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu", "tmin_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu", "tmax_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view().cpu", "bsn.PEM._forward().view", "tmin.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view", "tmax.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view", "tmin_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view", "tmax_score.view().cpu().numpy().reshape.view().cpu().numpy().reshape.view", "bsn.PEM._forward"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.post_processing.post_processing", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward"], ["", "def", "forward_test", "(", "self", ",", "bsp_feature", ",", "tmin", ",", "tmax", ",", "tmin_score", ",", "tmax_score", ",", "\n", "video_meta", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call when testing.\"\"\"", "\n", "pem_output", "=", "self", ".", "_forward", "(", "bsp_feature", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "\n", "-", "1", ",", "1", ")", "\n", "\n", "tmin", "=", "tmin", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "tmax", "=", "tmax", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "tmin_score", "=", "tmin_score", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "tmax_score", "=", "tmax_score", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "score", "=", "np", ".", "array", "(", "pem_output", "*", "tmin_score", "*", "tmax_score", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "result", "=", "np", ".", "concatenate", "(", "\n", "(", "tmin", ",", "tmax", ",", "tmin_score", ",", "tmax_score", ",", "pem_output", ",", "score", ")", ",", "axis", "=", "1", ")", "\n", "result", "=", "result", ".", "reshape", "(", "-", "1", ",", "6", ")", "\n", "video_info", "=", "dict", "(", "video_meta", "[", "0", "]", ")", "\n", "proposal_list", "=", "post_processing", "(", "result", ",", "video_info", ",", "\n", "self", ".", "soft_nms_alpha", ",", "\n", "self", ".", "soft_nms_low_threshold", ",", "\n", "self", ".", "soft_nms_high_threshold", ",", "\n", "self", ".", "post_process_top_k", ",", "\n", "self", ".", "feature_extraction_interval", ")", "\n", "output", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "video_info", "[", "'video_name'", "]", ",", "\n", "proposal_list", "=", "proposal_list", ")", "\n", "]", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localizers.bsn.PEM.forward": [[380, 395], ["bsn.PEM.forward_test", "bsn.PEM.forward_train"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train"], ["", "def", "forward", "(", "self", ",", "\n", "bsp_feature", ",", "\n", "reference_temporal_iou", "=", "None", ",", "\n", "tmin", "=", "None", ",", "\n", "tmax", "=", "None", ",", "\n", "tmin_score", "=", "None", ",", "\n", "tmax_score", "=", "None", ",", "\n", "video_meta", "=", "None", ",", "\n", "return_loss", "=", "True", ")", ":", "\n", "        ", "\"\"\"Define the computation performed at every call.\"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "return", "self", ".", "forward_train", "(", "bsp_feature", ",", "reference_temporal_iou", ")", "\n", "\n", "", "return", "self", ".", "forward_test", "(", "bsp_feature", ",", "tmin", ",", "tmax", ",", "tmin_score", ",", "\n", "tmax_score", ",", "video_meta", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tsn_head.TSNHead.__init__": [[25, 59], ["dict", "dict", "base.BaseHead.__init__", "consensus.copy", "consensus.copy.pop", "torch.Linear", "base.AvgConsensus", "torch.AdaptiveAvgPool2d", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "consensus", "=", "dict", "(", "type", "=", "'AvgConsensus'", ",", "dim", "=", "1", ")", ",", "\n", "dropout_ratio", "=", "0.4", ",", "\n", "init_std", "=", "0.01", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", "=", "loss_cls", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "consensus_", "=", "consensus", ".", "copy", "(", ")", "\n", "\n", "consensus_type", "=", "consensus_", ".", "pop", "(", "'type'", ")", "\n", "if", "consensus_type", "==", "'AvgConsensus'", ":", "\n", "            ", "self", ".", "consensus", "=", "AvgConsensus", "(", "**", "consensus_", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "consensus", "=", "None", "\n", "\n", "", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "# use `nn.AdaptiveAvgPool2d` to adaptively match the in_channels.", "\n", "            ", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool", "=", "None", "\n", "\n", "", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tsn_head.TSNHead.init_weights": [[60, 63], ["mmcv.cnn.normal_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_cls", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tsn_head.TSNHead.forward": [[64, 92], ["tsn_head.TSNHead.reshape", "tsn_head.TSNHead.consensus", "tsn_head.TSNHead.squeeze", "tsn_head.TSNHead.view", "tsn_head.TSNHead.fc_cls", "tsn_head.TSNHead.avg_pool", "tsn_head.TSNHead.dropout", "tsn_head.TSNHead.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_segs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n            num_segs (int): Number of segments into which a video\n                is divided.\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# [N * num_segs, in_channels, 7, 7]", "\n", "if", "self", ".", "avg_pool", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "# [N * num_segs, in_channels, 1, 1]", "\n", "", "x", "=", "x", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", "\n", "# [N, num_segs, in_channels, 1, 1]", "\n", "x", "=", "self", ".", "consensus", "(", "x", ")", "\n", "# [N, 1, in_channels, 1, 1]", "\n", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "# [N, in_channels, 1, 1]", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "# [N, in_channels, 1, 1]", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "# [N, in_channels]", "\n", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "# [N, num_classes]", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.audio_tsn_head.AudioTSNHead.__init__": [[24, 49], ["dict", "base.BaseHead.__init__", "torch.Linear", "torch.AdaptiveAvgPool2d", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.4", ",", "\n", "init_std", "=", "0.01", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", "=", "loss_cls", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "# use `nn.AdaptiveAvgPool2d` to adaptively match the in_channels.", "\n", "            ", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool", "=", "None", "\n", "\n", "", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.audio_tsn_head.AudioTSNHead.init_weights": [[50, 53], ["mmcv.cnn.normal_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_cls", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.audio_tsn_head.AudioTSNHead.forward": [[54, 74], ["audio_tsn_head.AudioTSNHead.avg_pool", "audio_tsn_head.AudioTSNHead.view", "audio_tsn_head.AudioTSNHead.fc_cls", "audio_tsn_head.AudioTSNHead.size", "audio_tsn_head.AudioTSNHead.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# [N * num_segs, in_channels, h, w]", "\n", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "# [N, in_channels, 1, 1]", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "# [N, in_channels]", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "# [N, in_channels]", "\n", "", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "# [N, num_classes]", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tpn_head.TPNHead.__init__": [[26, 37], ["tsn_head.TSNHead.__init__", "torch.AdaptiveAvgPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "# use `nn.AdaptiveAvgPool3d` to adaptively match the in_channels.", "\n", "            ", "self", ".", "avg_pool3d", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool3d", "=", "None", "\n", "\n", "", "self", ".", "avg_pool2d", "=", "None", "\n", "self", ".", "new_cls", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tpn_head.TPNHead._init_new_cls": [[38, 44], ["torch.Conv3d", "tpn_head.TPNHead.new_cls.weight.copy_", "tpn_head.TPNHead.new_cls.bias.copy_", "next", "tpn_head.TPNHead.new_cls.cuda", "tpn_head.TPNHead.fc_cls.parameters"], "methods", ["None"], ["", "def", "_init_new_cls", "(", "self", ")", ":", "\n", "        ", "self", ".", "new_cls", "=", "nn", ".", "Conv3d", "(", "self", ".", "in_channels", ",", "self", ".", "num_classes", ",", "1", ",", "1", ",", "0", ")", "\n", "if", "next", "(", "self", ".", "fc_cls", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "            ", "self", ".", "new_cls", "=", "self", ".", "new_cls", ".", "cuda", "(", ")", "\n", "", "self", ".", "new_cls", ".", "weight", ".", "copy_", "(", "self", ".", "fc_cls", ".", "weight", "[", "...", ",", "None", ",", "None", ",", "None", "]", ")", "\n", "self", ".", "new_cls", ".", "bias", ".", "copy_", "(", "self", ".", "fc_cls", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tpn_head.TPNHead.forward": [[45, 91], ["tpn_head.TPNHead.view", "tpn_head.TPNHead.fc_cls", "tpn_head.TPNHead.new_cls", "torch.AvgPool3d", "tpn_head.TPNHead.avg_pool3d", "tpn_head.TPNHead.avg_pool2d", "tpn_head.TPNHead.reshape", "tpn_head.TPNHead.consensus", "tpn_head.TPNHead.squeeze", "tpn_head.TPNHead.dropout", "tpn_head.TPNHead.size", "tpn_head.TPNHead.avg_pool3d", "tpn_head.TPNHead._init_new_cls"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tpn_head.TPNHead._init_new_cls"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_segs", "=", "None", ",", "fcn_test", "=", "False", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n            num_segs (int | None): Number of segments into which a video\n                is divided. Default: None.\n            fcn_test (bool): Whether to apply full convolution (fcn) testing.\n                Default: False.\n\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "if", "fcn_test", ":", "\n", "            ", "if", "self", ".", "avg_pool3d", ":", "\n", "                ", "x", "=", "self", ".", "avg_pool3d", "(", "x", ")", "\n", "", "if", "self", ".", "new_cls", "is", "None", ":", "\n", "                ", "self", ".", "_init_new_cls", "(", ")", "\n", "", "cls_score_feat_map", "=", "self", ".", "new_cls", "(", "x", ")", "\n", "return", "cls_score_feat_map", "\n", "\n", "", "if", "self", ".", "avg_pool2d", "is", "None", ":", "\n", "            ", "kernel_size", "=", "(", "1", ",", "x", ".", "shape", "[", "-", "2", "]", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "self", ".", "avg_pool2d", "=", "nn", ".", "AvgPool3d", "(", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "", "if", "num_segs", "is", "None", ":", "\n", "# [N, in_channels, 3, 7, 7]", "\n", "            ", "x", "=", "self", ".", "avg_pool3d", "(", "x", ")", "\n", "", "else", ":", "\n", "# [N * num_segs, in_channels, 7, 7]", "\n", "            ", "x", "=", "self", ".", "avg_pool2d", "(", "x", ")", "\n", "# [N * num_segs, in_channels, 1, 1]", "\n", "x", "=", "x", ".", "reshape", "(", "(", "-", "1", ",", "num_segs", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", "\n", "# [N, num_segs, in_channels, 1, 1]", "\n", "x", "=", "self", ".", "consensus", "(", "x", ")", "\n", "# [N, 1, in_channels, 1, 1]", "\n", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "# [N, in_channels, 1, 1]", "\n", "", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "# [N, in_channels, 1, 1]", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "# [N, in_channels]", "\n", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "# [N, num_classes]", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.base.AvgConsensus.__init__": [[18, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["class", "BaseDataset", "(", "Dataset", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.base.AvgConsensus.forward": [[22, 25], ["x.mean"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.base.BaseHead.__init__": [[46, 58], ["dict", "torch.Module.__init__", "builder.build_loss"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_loss"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.base.BaseHead.init_weights": [[59, 63], ["None"], "methods", ["None"], ["ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.base.BaseHead.forward": [[64, 67], ["None"], "methods", ["None"], ["num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.base.BaseHead.loss": [[68, 109], ["dict", "base.BaseHead.loss_cls", "isinstance", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "labels.unsqueeze.unsqueeze.unsqueeze", "core.top_k_accuracy", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "dict.update", "labels.unsqueeze.unsqueeze.unsqueeze", "cls_score.size", "labels.unsqueeze.unsqueeze.size", "cls_score.detach().cpu().numpy", "labels.unsqueeze.unsqueeze.detach().cpu().numpy", "labels.unsqueeze.unsqueeze.dim", "labels.unsqueeze.unsqueeze.size", "cls_score.size", "cls_score.detach().cpu", "labels.unsqueeze.unsqueeze.detach().cpu", "cls_score.detach", "labels.unsqueeze.unsqueeze.detach"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy"], ["power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n", "                ", "class_prob", ".", "append", "(", "len", "(", "samples", ")", "/", "len", "(", "self", ".", "video_infos", ")", ")", "\n", "", "class_prob", "=", "[", "x", "**", "self", ".", "power", "for", "x", "in", "class_prob", "]", "\n", "\n", "summ", "=", "sum", "(", "class_prob", ")", "\n", "class_prob", "=", "[", "x", "/", "summ", "for", "x", "in", "class_prob", "]", "\n", "\n", "self", ".", "class_prob", "=", "dict", "(", "zip", "(", "self", ".", "video_infos_by_class", ",", "class_prob", ")", ")", "\n", "\n", "", "", "@", "abstractmethod", "\n", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "\n", "# json annotations already looks like video_infos, so for each dataset,", "\n", "# this func should be the same", "\n", "", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.slowfast_head.SlowFastHead.__init__": [[25, 49], ["dict", "base.BaseHead.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.8", ",", "\n", "init_std", "=", "0.01", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", ",", "**", "kwargs", ")", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "in_channels", ",", "num_classes", ")", "\n", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.slowfast_head.SlowFastHead.init_weights": [[50, 53], ["mmcv.cnn.normal_init"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_cls", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.slowfast_head.SlowFastHead.forward": [[54, 80], ["slowfast_head.SlowFastHead.avg_pool", "slowfast_head.SlowFastHead.avg_pool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "slowfast_head.SlowFastHead.view", "slowfast_head.SlowFastHead.fc_cls", "slowfast_head.SlowFastHead.dropout", "slowfast_head.SlowFastHead.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# ([N, channel_fast, T, H, W], [(N, channel_slow, T, H, W)])", "\n", "x_fast", ",", "x_slow", "=", "x", "\n", "# ([N, channel_fast, 1, 1, 1], [N, channel_slow, 1, 1, 1])", "\n", "x_fast", "=", "self", ".", "avg_pool", "(", "x_fast", ")", "\n", "x_slow", "=", "self", ".", "avg_pool", "(", "x_slow", ")", "\n", "# [N, channel_fast + channel_slow, 1, 1, 1]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x_slow", ",", "x_fast", ")", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "# [N x C]", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "# [N x num_classes]", "\n", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tsm_head.TSMHead.__init__": [[31, 71], ["dict", "dict", "base.BaseHead.__init__", "consensus.copy", "consensus.copy.pop", "torch.Linear", "torch.Linear", "base.AvgConsensus", "torch.Dropout", "torch.Dropout", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "num_segments", "=", "8", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "consensus", "=", "dict", "(", "type", "=", "'AvgConsensus'", ",", "dim", "=", "1", ")", ",", "\n", "dropout_ratio", "=", "0.8", ",", "\n", "init_std", "=", "0.001", ",", "\n", "is_shift", "=", "True", ",", "\n", "temporal_pool", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "init_std", "=", "init_std", "\n", "self", ".", "is_shift", "=", "is_shift", "\n", "self", ".", "temporal_pool", "=", "temporal_pool", "\n", "\n", "consensus_", "=", "consensus", ".", "copy", "(", ")", "\n", "\n", "consensus_type", "=", "consensus_", ".", "pop", "(", "'type'", ")", "\n", "if", "consensus_type", "==", "'AvgConsensus'", ":", "\n", "            ", "self", ".", "consensus", "=", "AvgConsensus", "(", "**", "consensus_", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "consensus", "=", "None", "\n", "\n", "", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels", ",", "self", ".", "num_classes", ")", "\n", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "# use `nn.AdaptiveAvgPool2d` to adaptively match the in_channels.", "\n", "            ", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tsm_head.TSMHead.init_weights": [[72, 75], ["mmcv.cnn.normal_init"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_cls", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.tsm_head.TSMHead.forward": [[76, 112], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "tsm_head.TSMHead.fc_cls", "tsm_head.TSMHead.consensus", "cls_score.view.view.squeeze", "tsm_head.TSMHead.avg_pool", "tsm_head.TSMHead.dropout", "cls_score.view.view.view", "cls_score.view.view.view", "cls_score.view.view.size", "cls_score.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_segs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n            num_segs (int): Useless in TSMHead. By default, `num_segs`\n                is equal to `clip_len * num_clips * num_crops`, which is\n                automatically generated in Recognizer forward phase and\n                useless in TSM models. The `self.num_segments` we need is a\n                hyper parameter to build TSM models.\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# [N * num_segs, in_channels, 7, 7]", "\n", "if", "self", ".", "avg_pool", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "# [N * num_segs, in_channels, 1, 1]", "\n", "", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "# [N * num_segs, in_channels]", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "# [N * num_segs, num_classes]", "\n", "", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "\n", "if", "self", ".", "is_shift", "and", "self", ".", "temporal_pool", ":", "\n", "# [2 * N, num_segs // 2, num_classes]", "\n", "            ", "cls_score", "=", "cls_score", ".", "view", "(", "(", "-", "1", ",", "self", ".", "num_segments", "//", "2", ")", "+", "\n", "cls_score", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "# [N, num_segs, num_classes]", "\n", "            ", "cls_score", "=", "cls_score", ".", "view", "(", "(", "-", "1", ",", "self", ".", "num_segments", ")", "+", "\n", "cls_score", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "# [N, 1, num_classes]", "\n", "", "cls_score", "=", "self", ".", "consensus", "(", "cls_score", ")", "\n", "# [N, num_classes]", "\n", "return", "cls_score", ".", "squeeze", "(", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.lfb_infer_head.LFBInferHead.__init__": [[33, 66], ["torch.Module.__init__", "mmcv.runner.get_dist_info", "print", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "os.exists", "print", "mmcv.mkdir_or_exist"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "lfb_prefix_path", ",", "\n", "dataset_mode", "=", "'train'", ",", "\n", "use_half_precision", "=", "True", ",", "\n", "temporal_pool_type", "=", "'avg'", ",", "\n", "spatial_pool_type", "=", "'max'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "rank", ",", "_", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "            ", "if", "not", "osp", ".", "exists", "(", "lfb_prefix_path", ")", ":", "\n", "                ", "print", "(", "f'lfb prefix path {lfb_prefix_path} does not exist. '", "\n", "f'Creating the folder...'", ")", "\n", "mmcv", ".", "mkdir_or_exist", "(", "lfb_prefix_path", ")", "\n", "", "print", "(", "'\\nInferring LFB...'", ")", "\n", "\n", "", "assert", "temporal_pool_type", "in", "[", "'max'", ",", "'avg'", "]", "\n", "assert", "spatial_pool_type", "in", "[", "'max'", ",", "'avg'", "]", "\n", "self", ".", "lfb_prefix_path", "=", "lfb_prefix_path", "\n", "self", ".", "dataset_mode", "=", "dataset_mode", "\n", "self", ".", "use_half_precision", "=", "use_half_precision", "\n", "\n", "# Pool by default", "\n", "if", "temporal_pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "temporal_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "temporal_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "", "if", "spatial_pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "spatial_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "None", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "spatial_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "None", ",", "1", ",", "1", ")", ")", "\n", "\n", "", "self", ".", "all_features", "=", "[", "]", "\n", "self", ".", "all_metadata", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.lfb_infer_head.LFBInferHead.init_weights": [[67, 70], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "# LFBInferHead has no parameters to be initialized.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.lfb_infer_head.LFBInferHead.forward": [[71, 85], ["lfb_infer_head.LFBInferHead.temporal_pool", "lfb_infer_head.LFBInferHead.spatial_pool", "rois[].type", "list", "features.half.half.half", "lfb_infer_head.LFBInferHead.all_metadata.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "rois", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "# [N, C, 1, 1, 1]", "\n", "        ", "features", "=", "self", ".", "temporal_pool", "(", "x", ")", "\n", "features", "=", "self", ".", "spatial_pool", "(", "features", ")", "\n", "if", "self", ".", "use_half_precision", ":", "\n", "            ", "features", "=", "features", ".", "half", "(", ")", "\n", "\n", "", "inds", "=", "rois", "[", ":", ",", "0", "]", ".", "type", "(", "torch", ".", "int64", ")", "\n", "for", "ind", "in", "inds", ":", "\n", "            ", "self", ".", "all_metadata", ".", "append", "(", "img_metas", "[", "ind", "]", "[", "'img_key'", "]", ")", "\n", "", "self", ".", "all_features", "+=", "list", "(", "features", ")", "\n", "\n", "# Return the input directly and doesn't affect the input.", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.lfb_infer_head.LFBInferHead.__del__": [[86, 142], ["mmcv.runner.get_dist_info", "zip", "os.normpath", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "print", "range", "os.normpath", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "len", "len", "torch.barrier", "torch.barrier", "torch.barrier", "metadata.split", "int", "[].append", "os.join", "torch.barrier", "torch.barrier", "torch.barrier", "os.normpath", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.join", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "os.join", "len", "len", "lfb[].update"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "all_features", ")", "==", "len", "(", "self", ".", "all_metadata", ")", ",", "(", "\n", "'features and metadata are not equal in length!'", ")", "\n", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "if", "world_size", ">", "1", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "_lfb", "=", "{", "}", "\n", "for", "feature", ",", "metadata", "in", "zip", "(", "self", ".", "all_features", ",", "self", ".", "all_metadata", ")", ":", "\n", "            ", "video_id", ",", "timestamp", "=", "metadata", ".", "split", "(", "','", ")", "\n", "timestamp", "=", "int", "(", "timestamp", ")", "\n", "\n", "if", "video_id", "not", "in", "_lfb", ":", "\n", "                ", "_lfb", "[", "video_id", "]", "=", "{", "}", "\n", "", "if", "timestamp", "not", "in", "_lfb", "[", "video_id", "]", ":", "\n", "                ", "_lfb", "[", "video_id", "]", "[", "timestamp", "]", "=", "[", "]", "\n", "\n", "", "_lfb", "[", "video_id", "]", "[", "timestamp", "]", ".", "append", "(", "torch", ".", "squeeze", "(", "feature", ")", ")", "\n", "\n", "", "_lfb_file_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "self", ".", "lfb_prefix_path", ",", "\n", "f'_lfb_{self.dataset_mode}_{rank}.pkl'", ")", ")", "\n", "torch", ".", "save", "(", "_lfb", ",", "_lfb_file_path", ")", "\n", "print", "(", "f'{len(self.all_features)} features from {len(_lfb)} videos '", "\n", "f'on GPU {rank} have been stored in {_lfb_file_path}.'", ")", "\n", "\n", "# Synchronizes all processes to make sure all gpus have stored their", "\n", "# roi features", "\n", "if", "world_size", ">", "1", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "", "if", "rank", ">", "0", ":", "\n", "            ", "return", "\n", "\n", "", "print", "(", "'Gathering all the roi features...'", ")", "\n", "\n", "lfb", "=", "{", "}", "\n", "for", "rank_id", "in", "range", "(", "world_size", ")", ":", "\n", "            ", "_lfb_file_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "self", ".", "lfb_prefix_path", ",", "\n", "f'_lfb_{self.dataset_mode}_{rank_id}.pkl'", ")", ")", "\n", "\n", "# Since each frame will only be distributed to one GPU,", "\n", "# the roi features on the same timestamp of the same video are all", "\n", "# on the same GPU", "\n", "_lfb", "=", "torch", ".", "load", "(", "_lfb_file_path", ")", "\n", "for", "video_id", "in", "_lfb", ":", "\n", "                ", "if", "video_id", "not", "in", "lfb", ":", "\n", "                    ", "lfb", "[", "video_id", "]", "=", "_lfb", "[", "video_id", "]", "\n", "", "else", ":", "\n", "                    ", "lfb", "[", "video_id", "]", ".", "update", "(", "_lfb", "[", "video_id", "]", ")", "\n", "\n", "", "", "", "lfb_file_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "self", ".", "lfb_prefix_path", ",", "f'lfb_{self.dataset_mode}.pkl'", ")", ")", "\n", "torch", ".", "save", "(", "lfb", ",", "lfb_file_path", ")", "\n", "print", "(", "f'LFB has been constructed in {lfb_file_path}!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.__init__": [[41, 105], ["torch.Module.__init__", "all", "torch.Linear", "torch.Linear", "torch.Linear", "isinstance", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "isinstance", "all", "TypeError", "isinstance", "type"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "temporal_pool_type", "=", "'avg'", ",", "\n", "spatial_pool_type", "=", "'max'", ",", "\n", "in_channels", "=", "2048", ",", "\n", "# The first class is reserved, to classify bbox as pos / neg", "\n", "focal_gamma", "=", "0.", ",", "\n", "focal_alpha", "=", "1.", ",", "\n", "num_classes", "=", "81", ",", "\n", "dropout_ratio", "=", "0", ",", "\n", "dropout_before_pool", "=", "True", ",", "\n", "topk", "=", "(", "3", ",", "5", ")", ",", "\n", "multilabel", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", "BBoxHeadAVA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "temporal_pool_type", "in", "[", "'max'", ",", "'avg'", "]", "\n", "assert", "spatial_pool_type", "in", "[", "'max'", ",", "'avg'", "]", "\n", "self", ".", "temporal_pool_type", "=", "temporal_pool_type", "\n", "self", ".", "spatial_pool_type", "=", "spatial_pool_type", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "dropout_before_pool", "=", "dropout_before_pool", "\n", "\n", "self", ".", "multilabel", "=", "multilabel", "\n", "\n", "self", ".", "focal_gamma", "=", "focal_gamma", "\n", "self", ".", "focal_alpha", "=", "focal_alpha", "\n", "\n", "if", "topk", "is", "None", ":", "\n", "            ", "self", ".", "topk", "=", "(", ")", "\n", "", "elif", "isinstance", "(", "topk", ",", "int", ")", ":", "\n", "            ", "self", ".", "topk", "=", "(", "topk", ",", ")", "\n", "", "elif", "isinstance", "(", "topk", ",", "tuple", ")", ":", "\n", "            ", "assert", "all", "(", "[", "isinstance", "(", "k", ",", "int", ")", "for", "k", "in", "topk", "]", ")", "\n", "self", ".", "topk", "=", "topk", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'topk should be int or tuple[int], '", "\n", "f'but get {type(topk)}'", ")", "\n", "# Class 0 is ignored when calculaing multilabel accuracy,", "\n", "# so topk cannot be equal to num_classes", "\n", "", "assert", "all", "(", "[", "k", "<", "num_classes", "for", "k", "in", "self", ".", "topk", "]", ")", "\n", "\n", "# Handle AVA first", "\n", "assert", "self", ".", "multilabel", "\n", "\n", "in_channels", "=", "self", ".", "in_channels", "\n", "# Pool by default", "\n", "if", "self", ".", "temporal_pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "temporal_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "temporal_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "", "if", "self", ".", "spatial_pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "spatial_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "None", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "spatial_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "None", ",", "1", ",", "1", ")", ")", "\n", "\n", "", "if", "dropout_ratio", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_ratio", ")", "\n", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "in_channels", ",", "num_classes", ")", "\n", "self", ".", "debug_imgs", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.init_weights": [[106, 109], ["torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc_cls", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc_cls", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.forward": [[110, 124], ["bbox_head.BBoxHeadAVA.temporal_pool", "bbox_head.BBoxHeadAVA.spatial_pool", "bbox_head.BBoxHeadAVA.view", "bbox_head.BBoxHeadAVA.fc_cls", "bbox_head.BBoxHeadAVA.dropout", "bbox_head.BBoxHeadAVA.dropout", "bbox_head.BBoxHeadAVA.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "dropout_before_pool", "and", "self", ".", "dropout_ratio", ">", "0", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "temporal_pool", "(", "x", ")", "\n", "x", "=", "self", ".", "spatial_pool", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "dropout_before_pool", "and", "self", ".", "dropout_ratio", ">", "0", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "# We do not predict bbox, so return None", "\n", "return", "cls_score", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.get_targets": [[125, 133], ["mmaction.core.bbox.bbox_target"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.bbox.bbox_target.bbox_target"], ["", "@", "staticmethod", "\n", "def", "get_targets", "(", "sampling_results", ",", "gt_bboxes", ",", "gt_labels", ",", "rcnn_train_cfg", ")", ":", "\n", "        ", "pos_proposals", "=", "[", "res", ".", "pos_bboxes", "for", "res", "in", "sampling_results", "]", "\n", "neg_proposals", "=", "[", "res", ".", "neg_bboxes", "for", "res", "in", "sampling_results", "]", "\n", "pos_gt_labels", "=", "[", "res", ".", "pos_gt_labels", "for", "res", "in", "sampling_results", "]", "\n", "cls_reg_targets", "=", "bbox_target", "(", "pos_proposals", ",", "neg_proposals", ",", "\n", "pos_gt_labels", ",", "rcnn_train_cfg", ")", "\n", "return", "cls_reg_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.recall_prec": [[134, 147], ["correct.sum", "target_vec.sum().float", "correct.sum", "recall.mean", "prec.mean", "pred_vec.sum", "target_vec.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "recall_prec", "(", "pred_vec", ",", "target_vec", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pred_vec (tensor[N x C]): each element is either 0 or 1\n            target_vec (tensor[N x C]): each element is either 0 or 1\n\n        \"\"\"", "\n", "correct", "=", "pred_vec", "&", "target_vec", "\n", "# Seems torch 1.5 has no auto type conversion", "\n", "recall", "=", "correct", ".", "sum", "(", "1", ")", "/", "target_vec", ".", "sum", "(", "1", ")", ".", "float", "(", ")", "\n", "prec", "=", "correct", ".", "sum", "(", "1", ")", "/", "(", "pred_vec", ".", "sum", "(", "1", ")", "+", "1e-6", ")", "\n", "return", "recall", ".", "mean", "(", ")", ",", "prec", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.multi_label_accuracy": [[148, 167], ["pred.sigmoid.sigmoid.sigmoid", "bbox_head.BBoxHeadAVA.recall_prec", "pred.sigmoid.sigmoid.topk", "pred.sigmoid.sigmoid.new_full", "range", "bbox_head.BBoxHeadAVA.recall_prec", "recalls.append", "precs.append", "pred.sigmoid.sigmoid.size"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.recall_prec", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.recall_prec"], ["", "def", "multi_label_accuracy", "(", "self", ",", "pred", ",", "target", ",", "thr", "=", "0.5", ")", ":", "\n", "        ", "pred", "=", "pred", ".", "sigmoid", "(", ")", "\n", "pred_vec", "=", "pred", ">", "thr", "\n", "# Target is 0 or 1, so using 0.5 as the borderline is OK", "\n", "target_vec", "=", "target", ">", "0.5", "\n", "recall_thr", ",", "prec_thr", "=", "self", ".", "recall_prec", "(", "pred_vec", ",", "target_vec", ")", "\n", "\n", "recalls", ",", "precs", "=", "[", "]", ",", "[", "]", "\n", "for", "k", "in", "self", ".", "topk", ":", "\n", "            ", "_", ",", "pred_label", "=", "pred", ".", "topk", "(", "k", ",", "1", ",", "True", ",", "True", ")", "\n", "pred_vec", "=", "pred", ".", "new_full", "(", "pred", ".", "size", "(", ")", ",", "0", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "\n", "num_sample", "=", "pred", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "                ", "pred_vec", "[", "i", ",", "pred_label", "[", "i", "]", "]", "=", "1", "\n", "", "recall_k", ",", "prec_k", "=", "self", ".", "recall_prec", "(", "pred_vec", ",", "target_vec", ")", "\n", "recalls", ".", "append", "(", "recall_k", ")", "\n", "precs", ".", "append", "(", "prec_k", ")", "\n", "", "return", "recall_thr", ",", "prec_thr", ",", "recalls", ",", "precs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss": [[168, 201], ["dict", "bce_loss", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "bbox_head.BBoxHeadAVA.multi_label_accuracy", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.multi_label_accuracy"], ["", "def", "loss", "(", "self", ",", "\n", "cls_score", ",", "\n", "bbox_pred", ",", "\n", "rois", ",", "\n", "labels", ",", "\n", "label_weights", ",", "\n", "bbox_targets", "=", "None", ",", "\n", "bbox_weights", "=", "None", ",", "\n", "reduce", "=", "True", ")", ":", "\n", "\n", "        ", "losses", "=", "dict", "(", ")", "\n", "if", "cls_score", "is", "not", "None", ":", "\n", "# Only use the cls_score", "\n", "            ", "labels", "=", "labels", "[", ":", ",", "1", ":", "]", "\n", "pos_inds", "=", "torch", ".", "sum", "(", "labels", ",", "dim", "=", "-", "1", ")", ">", "0", "\n", "cls_score", "=", "cls_score", "[", "pos_inds", ",", "1", ":", "]", "\n", "labels", "=", "labels", "[", "pos_inds", "]", "\n", "\n", "bce_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "\n", "\n", "loss", "=", "bce_loss", "(", "cls_score", ",", "labels", ",", "reduction", "=", "'none'", ")", "\n", "pt", "=", "torch", ".", "exp", "(", "-", "loss", ")", "\n", "F_loss", "=", "self", ".", "focal_alpha", "*", "(", "1", "-", "pt", ")", "**", "self", ".", "focal_gamma", "*", "loss", "\n", "losses", "[", "'loss_action_cls'", "]", "=", "torch", ".", "mean", "(", "F_loss", ")", "\n", "\n", "recall_thr", ",", "prec_thr", ",", "recall_k", ",", "prec_k", "=", "self", ".", "multi_label_accuracy", "(", "\n", "cls_score", ",", "labels", ",", "thr", "=", "0.5", ")", "\n", "losses", "[", "'recall@thr=0.5'", "]", "=", "recall_thr", "\n", "losses", "[", "'prec@thr=0.5'", "]", "=", "prec_thr", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "self", ".", "topk", ")", ":", "\n", "                ", "losses", "[", "f'recall@top{k}'", "]", "=", "recall_k", "[", "i", "]", "\n", "losses", "[", "f'prec@top{k}'", "]", "=", "prec_k", "[", "i", "]", "\n", "", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.get_det_bboxes": [[202, 244], ["isinstance", "bbox_head.BBoxHeadAVA.get_det_bboxes._bbox_crop_undo"], "methods", ["None"], ["", "def", "get_det_bboxes", "(", "self", ",", "\n", "rois", ",", "\n", "cls_score", ",", "\n", "img_shape", ",", "\n", "flip", "=", "False", ",", "\n", "crop_quadruple", "=", "None", ",", "\n", "cfg", "=", "None", ")", ":", "\n", "\n", "# might be used by testing w. augmentation", "\n", "        ", "if", "isinstance", "(", "cls_score", ",", "list", ")", ":", "\n", "            ", "cls_score", "=", "sum", "(", "cls_score", ")", "/", "float", "(", "len", "(", "cls_score", ")", ")", "\n", "\n", "", "assert", "self", ".", "multilabel", "\n", "\n", "scores", "=", "cls_score", ".", "sigmoid", "(", ")", "if", "cls_score", "is", "not", "None", "else", "None", "\n", "bboxes", "=", "rois", "[", ":", ",", "1", ":", "]", "\n", "assert", "bboxes", ".", "shape", "[", "-", "1", "]", "==", "4", "\n", "\n", "# First reverse the flip", "\n", "img_h", ",", "img_w", "=", "img_shape", "\n", "if", "flip", ":", "\n", "            ", "bboxes_", "=", "bboxes", ".", "clone", "(", ")", "\n", "bboxes_", "[", ":", ",", "0", "]", "=", "img_w", "-", "1", "-", "bboxes", "[", ":", ",", "2", "]", "\n", "bboxes_", "[", ":", ",", "2", "]", "=", "img_w", "-", "1", "-", "bboxes", "[", ":", ",", "0", "]", "\n", "bboxes", "=", "bboxes_", "\n", "\n", "# Then normalize the bbox to [0, 1]", "\n", "", "bboxes", "[", ":", ",", "0", ":", ":", "2", "]", "/=", "img_w", "\n", "bboxes", "[", ":", ",", "1", ":", ":", "2", "]", "/=", "img_h", "\n", "\n", "def", "_bbox_crop_undo", "(", "bboxes", ",", "crop_quadruple", ")", ":", "\n", "            ", "decropped", "=", "bboxes", ".", "clone", "(", ")", "\n", "\n", "if", "crop_quadruple", "is", "not", "None", ":", "\n", "                ", "x1", ",", "y1", ",", "tw", ",", "th", "=", "crop_quadruple", "\n", "decropped", "[", ":", ",", "0", ":", ":", "2", "]", "=", "bboxes", "[", "...", ",", "0", ":", ":", "2", "]", "*", "tw", "+", "x1", "\n", "decropped", "[", ":", ",", "1", ":", ":", "2", "]", "=", "bboxes", "[", "...", ",", "1", ":", ":", "2", "]", "*", "th", "+", "y1", "\n", "\n", "", "return", "decropped", "\n", "\n", "", "bboxes", "=", "_bbox_crop_undo", "(", "bboxes", ",", "crop_quadruple", ")", "\n", "return", "bboxes", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.misc_head.ACRNHead.__init__": [[35, 90], ["dict", "dict", "dict", "torch.Module.__init__", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "range", "torch.ModuleList", "torch.ModuleList", "mmcv.cnn.ConvModule", "convs.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "stride", "=", "1", ",", "\n", "num_convs", "=", "1", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "num_convs", "=", "num_convs", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "max_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "1", ")", "\n", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "\n", "assert", "num_convs", ">=", "1", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "stride", ",", "stride", ")", ",", "\n", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "\n", "convs", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_convs", "-", "1", ")", ":", "\n", "            ", "conv", "=", "ConvModule", "(", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "convs", ".", "append", "(", "conv", ")", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "convs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.misc_head.ACRNHead.init_weights": [[91, 98], ["misc_head.ACRNHead.modules", "isinstance", "mmcv.cnn.kaiming_init", "isinstance", "mmcv.cnn.constant_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Weight Initialization for ACRNHead.\"\"\"", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.misc_head.ACRNHead.forward": [[99, 128], ["misc_head.ACRNHead.max_pool", "misc_head.ACRNHead.repeat", "rois[].type", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "misc_head.ACRNHead.conv1", "misc_head.ACRNHead.conv2", "conv"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ",", "feat", ",", "rois", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The extracted RoI feature.\n            feat (torch.Tensor): The context feature.\n            rois (torch.Tensor): The regions of interest.\n\n        Returns:\n            torch.Tensor: The RoI features that have interacted with context\n                feature.\n        \"\"\"", "\n", "# We use max pooling by default", "\n", "x", "=", "self", ".", "max_pool", "(", "x", ")", "\n", "\n", "h", ",", "w", "=", "feat", ".", "shape", "[", "-", "2", ":", "]", "\n", "x_tile", "=", "x", ".", "repeat", "(", "1", ",", "1", ",", "1", ",", "h", ",", "w", ")", "\n", "\n", "roi_inds", "=", "rois", "[", ":", ",", "0", "]", ".", "type", "(", "torch", ".", "long", ")", "\n", "roi_gfeat", "=", "feat", "[", "roi_inds", "]", "\n", "\n", "new_feat", "=", "torch", ".", "cat", "(", "[", "x_tile", ",", "roi_gfeat", "]", ",", "dim", "=", "1", ")", "\n", "new_feat", "=", "self", ".", "conv1", "(", "new_feat", ")", "\n", "new_feat", "=", "self", ".", "conv2", "(", "new_feat", ")", "\n", "\n", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "new_feat", "=", "conv", "(", "new_feat", ")", "\n", "\n", "", "return", "new_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.NonLocalLayer.__init__": [[42, 110], ["torch.Module.__init__", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.ReLU", "torch.ReLU", "mmcv.cnn.ConvModule", "dict", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "st_feat_channels", ",", "\n", "lt_feat_channels", ",", "\n", "latent_channels", ",", "\n", "num_st_feat", ",", "\n", "num_lt_feat", ",", "\n", "use_scale", "=", "True", ",", "\n", "pre_activate", "=", "True", ",", "\n", "pre_activate_with_ln", "=", "True", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "dropout_ratio", "=", "0.2", ",", "\n", "zero_init_out_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "conv_cfg", "is", "None", ":", "\n", "            ", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", "\n", "", "self", ".", "st_feat_channels", "=", "st_feat_channels", "\n", "self", ".", "lt_feat_channels", "=", "lt_feat_channels", "\n", "self", ".", "latent_channels", "=", "latent_channels", "\n", "self", ".", "num_st_feat", "=", "num_st_feat", "\n", "self", ".", "num_lt_feat", "=", "num_lt_feat", "\n", "self", ".", "use_scale", "=", "use_scale", "\n", "self", ".", "pre_activate", "=", "pre_activate", "\n", "self", ".", "pre_activate_with_ln", "=", "pre_activate_with_ln", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "zero_init_out_conv", "=", "zero_init_out_conv", "\n", "\n", "self", ".", "st_feat_conv", "=", "ConvModule", "(", "\n", "self", ".", "st_feat_channels", ",", "\n", "self", ".", "latent_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "self", ".", "lt_feat_conv", "=", "ConvModule", "(", "\n", "self", ".", "lt_feat_channels", ",", "\n", "self", ".", "latent_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "self", ".", "global_conv", "=", "ConvModule", "(", "\n", "self", ".", "lt_feat_channels", ",", "\n", "self", ".", "latent_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "if", "pre_activate", ":", "\n", "            ", "self", ".", "ln", "=", "nn", ".", "LayerNorm", "(", "[", "latent_channels", ",", "num_st_feat", ",", "1", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ln", "=", "nn", ".", "LayerNorm", "(", "[", "st_feat_channels", ",", "num_st_feat", ",", "1", ",", "1", "]", ")", "\n", "\n", "", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "out_conv", "=", "ConvModule", "(", "\n", "self", ".", "latent_channels", ",", "\n", "self", ".", "st_feat_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "if", "self", ".", "dropout_ratio", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.NonLocalLayer.init_weights": [[111, 128], ["isinstance", "mmaction.utils.get_root_logger", "mmaction.utils.get_root_logger.info", "mmcv.runner.load_checkpoint", "fbo_head.NonLocalLayer.modules", "TypeError", "isinstance", "mmcv.cnn.constant_init", "mmcv.cnn.kaiming_init", "isinstance", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], ["", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "if", "isinstance", "(", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'load model from: {pretrained}'", ")", "\n", "load_checkpoint", "(", "self", ",", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "", "elif", "pretrained", "is", "None", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "constant_init", "(", "m", ",", "1", ")", "\n", "", "", "if", "self", ".", "zero_init_out_conv", ":", "\n", "                ", "constant_init", "(", "self", ".", "out_conv", ",", "0", ",", "bias", "=", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.NonLocalLayer.forward": [[129, 169], ["fbo_head.NonLocalLayer.st_feat_conv", "theta.view.view.view", "fbo_head.NonLocalLayer.lt_feat_conv", "phi.view.view.view", "fbo_head.NonLocalLayer.global_conv", "g.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.softmax", "torch.matmul.softmax", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "fbo_head.NonLocalLayer.out_conv", "st_feat.size", "theta.view.view.permute", "fbo_head.NonLocalLayer.relu", "fbo_head.NonLocalLayer.ln", "fbo_head.NonLocalLayer.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "fbo_head.NonLocalLayer.ln", "torch.matmul.softmax.permute"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["", "", "def", "forward", "(", "self", ",", "st_feat", ",", "lt_feat", ")", ":", "\n", "        ", "n", ",", "c", "=", "st_feat", ".", "size", "(", "0", ")", ",", "self", ".", "latent_channels", "\n", "num_st_feat", ",", "num_lt_feat", "=", "self", ".", "num_st_feat", ",", "self", ".", "num_lt_feat", "\n", "\n", "theta", "=", "self", ".", "st_feat_conv", "(", "st_feat", ")", "\n", "theta", "=", "theta", ".", "view", "(", "n", ",", "c", ",", "num_st_feat", ")", "\n", "\n", "phi", "=", "self", ".", "lt_feat_conv", "(", "lt_feat", ")", "\n", "phi", "=", "phi", ".", "view", "(", "n", ",", "c", ",", "num_lt_feat", ")", "\n", "\n", "g", "=", "self", ".", "global_conv", "(", "lt_feat", ")", "\n", "g", "=", "g", ".", "view", "(", "n", ",", "c", ",", "num_lt_feat", ")", "\n", "\n", "# (n, num_st_feat, c), (n, c, num_lt_feat)", "\n", "# -> (n, num_st_feat, num_lt_feat)", "\n", "theta_phi", "=", "torch", ".", "matmul", "(", "theta", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ",", "phi", ")", "\n", "if", "self", ".", "use_scale", ":", "\n", "            ", "theta_phi", "/=", "c", "**", "0.5", "\n", "\n", "", "p", "=", "theta_phi", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "# (n, c, num_lt_feat), (n, num_lt_feat, num_st_feat)", "\n", "# -> (n, c, num_st_feat, 1, 1)", "\n", "out", "=", "torch", ".", "matmul", "(", "g", ",", "p", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "view", "(", "n", ",", "c", ",", "num_st_feat", ",", "1", ",", "1", ")", "\n", "\n", "# If need to activate it before out_conv, use relu here, otherwise", "\n", "# use relu outside the non local layer.", "\n", "if", "self", ".", "pre_activate", ":", "\n", "            ", "if", "self", ".", "pre_activate_with_ln", ":", "\n", "                ", "out", "=", "self", ".", "ln", "(", "out", ")", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "out_conv", "(", "out", ")", "\n", "\n", "if", "not", "self", ".", "pre_activate", ":", "\n", "            ", "out", "=", "self", ".", "ln", "(", "out", ")", "\n", "", "if", "self", ".", "dropout_ratio", ">", "0", ":", "\n", "            ", "out", "=", "self", ".", "dropout", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBONonLocal.__init__": [[192, 245], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "range", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReLU", "torch.ReLU", "fbo_head.FBONonLocal.add_module", "fbo_head.FBONonLocal.non_local_layers.append", "fbo_head.NonLocalLayer"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "st_feat_channels", ",", "\n", "lt_feat_channels", ",", "\n", "latent_channels", ",", "\n", "num_st_feat", ",", "\n", "num_lt_feat", ",", "\n", "num_non_local_layers", "=", "2", ",", "\n", "st_feat_dropout_ratio", "=", "0.2", ",", "\n", "lt_feat_dropout_ratio", "=", "0.2", ",", "\n", "pre_activate", "=", "True", ",", "\n", "zero_init_out_conv", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "num_non_local_layers", ">=", "1", ",", "(", "\n", "'At least one non_local_layer is needed.'", ")", "\n", "self", ".", "st_feat_channels", "=", "st_feat_channels", "\n", "self", ".", "lt_feat_channels", "=", "lt_feat_channels", "\n", "self", ".", "latent_channels", "=", "latent_channels", "\n", "self", ".", "num_st_feat", "=", "num_st_feat", "\n", "self", ".", "num_lt_feat", "=", "num_lt_feat", "\n", "self", ".", "num_non_local_layers", "=", "num_non_local_layers", "\n", "self", ".", "st_feat_dropout_ratio", "=", "st_feat_dropout_ratio", "\n", "self", ".", "lt_feat_dropout_ratio", "=", "lt_feat_dropout_ratio", "\n", "self", ".", "pre_activate", "=", "pre_activate", "\n", "self", ".", "zero_init_out_conv", "=", "zero_init_out_conv", "\n", "\n", "self", ".", "st_feat_conv", "=", "nn", ".", "Conv3d", "(", "\n", "st_feat_channels", ",", "latent_channels", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "lt_feat_conv", "=", "nn", ".", "Conv3d", "(", "\n", "lt_feat_channels", ",", "latent_channels", ",", "kernel_size", "=", "1", ")", "\n", "\n", "if", "self", ".", "st_feat_dropout_ratio", ">", "0", ":", "\n", "            ", "self", ".", "st_feat_dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "st_feat_dropout_ratio", ")", "\n", "\n", "", "if", "self", ".", "lt_feat_dropout_ratio", ">", "0", ":", "\n", "            ", "self", ".", "lt_feat_dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "lt_feat_dropout_ratio", ")", "\n", "\n", "", "if", "not", "self", ".", "pre_activate", ":", "\n", "            ", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "non_local_layers", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_non_local_layers", ")", ":", "\n", "            ", "layer_name", "=", "f'non_local_layer_{idx + 1}'", "\n", "self", ".", "add_module", "(", "\n", "layer_name", ",", "\n", "NonLocalLayer", "(", "\n", "latent_channels", ",", "\n", "latent_channels", ",", "\n", "latent_channels", ",", "\n", "num_st_feat", ",", "\n", "num_lt_feat", ",", "\n", "pre_activate", "=", "self", ".", "pre_activate", ",", "\n", "zero_init_out_conv", "=", "self", ".", "zero_init_out_conv", ")", ")", "\n", "self", ".", "non_local_layers", ".", "append", "(", "layer_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBONonLocal.init_weights": [[246, 258], ["isinstance", "mmaction.utils.get_root_logger", "mmcv.runner.load_checkpoint", "mmcv.cnn.kaiming_init", "mmcv.cnn.kaiming_init", "TypeError", "getattr", "getattr.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "load_checkpoint", "(", "self", ",", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "", "elif", "pretrained", "is", "None", ":", "\n", "            ", "kaiming_init", "(", "self", ".", "st_feat_conv", ")", "\n", "kaiming_init", "(", "self", ".", "lt_feat_conv", ")", "\n", "for", "layer_name", "in", "self", ".", "non_local_layers", ":", "\n", "                ", "non_local_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "non_local_layer", ".", "init_weights", "(", "pretrained", "=", "pretrained", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBONonLocal.forward": [[259, 281], ["fbo_head.FBONonLocal.st_feat_conv", "fbo_head.FBONonLocal.lt_feat_conv", "fbo_head.FBONonLocal.st_feat_dropout", "fbo_head.FBONonLocal.lt_feat_dropout", "getattr", "getattr.", "fbo_head.FBONonLocal.relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "st_feat", ",", "lt_feat", ")", ":", "\n", "# prepare st_feat", "\n", "        ", "st_feat", "=", "self", ".", "st_feat_conv", "(", "st_feat", ")", "\n", "if", "self", ".", "st_feat_dropout_ratio", ">", "0", ":", "\n", "            ", "st_feat", "=", "self", ".", "st_feat_dropout", "(", "st_feat", ")", "\n", "\n", "# prepare lt_feat", "\n", "", "lt_feat", "=", "self", ".", "lt_feat_conv", "(", "lt_feat", ")", "\n", "if", "self", ".", "lt_feat_dropout_ratio", ">", "0", ":", "\n", "            ", "lt_feat", "=", "self", ".", "lt_feat_dropout", "(", "lt_feat", ")", "\n", "\n", "# fuse short-term and long-term features in NonLocal Layer", "\n", "", "for", "layer_name", "in", "self", ".", "non_local_layers", ":", "\n", "            ", "identity", "=", "st_feat", "\n", "non_local_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "nl_out", "=", "non_local_layer", "(", "st_feat", ",", "lt_feat", ")", "\n", "nl_out", "=", "identity", "+", "nl_out", "\n", "if", "not", "self", ".", "pre_activate", ":", "\n", "                ", "nl_out", "=", "self", ".", "relu", "(", "nl_out", ")", "\n", "", "st_feat", "=", "nl_out", "\n", "\n", "", "return", "nl_out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOAvg.__init__": [[286, 289], ["torch.Module.__init__", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOAvg.init_weights": [[290, 293], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "# FBOAvg has no parameters to be initalized.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOAvg.forward": [[294, 297], ["fbo_head.FBOAvg.avg_pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "st_feat", ",", "lt_feat", ")", ":", "\n", "        ", "out", "=", "self", ".", "avg_pool", "(", "lt_feat", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOMax.__init__": [[302, 305], ["torch.Module.__init__", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOMax.init_weights": [[306, 309], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "# FBOMax has no parameters to be initialized.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOMax.forward": [[310, 313], ["fbo_head.FBOMax.max_pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "st_feat", ",", "lt_feat", ")", ":", "\n", "        ", "out", "=", "self", ".", "max_pool", "(", "lt_feat", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOHead.__init__": [[335, 361], ["torch.Module.__init__", "fbo_cfg.pop", "copy.deepcopy", "copy.deepcopy", "mmaction.models.common.LFB", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d", "torch.AdaptiveMaxPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "lfb_cfg", ",", "\n", "fbo_cfg", ",", "\n", "temporal_pool_type", "=", "'avg'", ",", "\n", "spatial_pool_type", "=", "'max'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "fbo_type", "=", "fbo_cfg", ".", "pop", "(", "'type'", ",", "'non_local'", ")", "\n", "assert", "fbo_type", "in", "FBOHead", ".", "fbo_dict", "\n", "assert", "temporal_pool_type", "in", "[", "'max'", ",", "'avg'", "]", "\n", "assert", "spatial_pool_type", "in", "[", "'max'", ",", "'avg'", "]", "\n", "\n", "self", ".", "lfb_cfg", "=", "copy", ".", "deepcopy", "(", "lfb_cfg", ")", "\n", "self", ".", "fbo_cfg", "=", "copy", ".", "deepcopy", "(", "fbo_cfg", ")", "\n", "\n", "self", ".", "lfb", "=", "LFB", "(", "**", "self", ".", "lfb_cfg", ")", "\n", "self", ".", "fbo", "=", "self", ".", "fbo_dict", "[", "fbo_type", "]", "(", "**", "self", ".", "fbo_cfg", ")", "\n", "\n", "# Pool by default", "\n", "if", "temporal_pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "temporal_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "temporal_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "1", ",", "None", ",", "None", ")", ")", "\n", "", "if", "spatial_pool_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "spatial_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "None", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "spatial_pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "None", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOHead.init_weights": [[362, 370], ["fbo_head.FBOHead.fbo.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialize the weights in the module.\n\n        Args:\n            pretrained (str, optional): Path to pre-trained weights.\n                Default: None.\n        \"\"\"", "\n", "self", ".", "fbo", ".", "init_weights", "(", "pretrained", "=", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOHead.sample_lfb": [[371, 381], ["rois[].type", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lt_feat.permute().contiguous.permute().contiguous.permute().contiguous", "lt_feat.permute().contiguous.permute().contiguous.unsqueeze().unsqueeze", "lt_feat_list.append", "fbo_head.FBOHead.lfb[].to", "lt_feat.permute().contiguous.permute().contiguous.permute", "lt_feat.permute().contiguous.permute().contiguous.unsqueeze"], "methods", ["None"], ["", "def", "sample_lfb", "(", "self", ",", "rois", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Sample long-term features for each ROI feature.\"\"\"", "\n", "inds", "=", "rois", "[", ":", ",", "0", "]", ".", "type", "(", "torch", ".", "int64", ")", "\n", "lt_feat_list", "=", "[", "]", "\n", "for", "ind", "in", "inds", ":", "\n", "            ", "lt_feat_list", ".", "append", "(", "self", ".", "lfb", "[", "img_metas", "[", "ind", "]", "[", "'img_key'", "]", "]", ".", "to", "(", ")", ")", "\n", "", "lt_feat", "=", "torch", ".", "stack", "(", "lt_feat_list", ",", "dim", "=", "0", ")", "\n", "# [N, lfb_channels, window_size * max_num_feat_per_step]", "\n", "lt_feat", "=", "lt_feat", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "lt_feat", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOHead.forward": [[382, 395], ["fbo_head.FBOHead.temporal_pool", "fbo_head.FBOHead.spatial_pool", "fbo_head.FBOHead.sample_lfb().to", "fbo_head.FBOHead.fbo", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fbo_head.FBOHead.sample_lfb"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.fbo_head.FBOHead.sample_lfb"], ["", "def", "forward", "(", "self", ",", "x", ",", "rois", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "# [N, C, 1, 1, 1]", "\n", "        ", "st_feat", "=", "self", ".", "temporal_pool", "(", "x", ")", "\n", "st_feat", "=", "self", ".", "spatial_pool", "(", "st_feat", ")", "\n", "identity", "=", "st_feat", "\n", "\n", "# [N, C, window_size * num_feat_per_step, 1, 1]", "\n", "lt_feat", "=", "self", ".", "sample_lfb", "(", "rois", ",", "img_metas", ")", ".", "to", "(", "st_feat", ".", "device", ")", "\n", "\n", "fbo_feat", "=", "self", ".", "fbo", "(", "st_feat", ",", "lt_feat", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "[", "identity", ",", "fbo_feat", "]", ",", "dim", "=", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTrain.__init__": [[37, 51], ["torch.Module.__init__", "ssn_head.parse_stage_config", "ssn_head.parse_stage_config", "ssn_head.parse_stage_config"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config"], ["def", "__init__", "(", "self", ",", "stpp_stage", "=", "(", "1", ",", "(", "1", ",", "2", ")", ",", "1", ")", ",", "num_segments_list", "=", "(", "2", ",", "5", ",", "2", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "starting_part", ",", "starting_multiplier", "=", "parse_stage_config", "(", "stpp_stage", "[", "0", "]", ")", "\n", "course_part", ",", "course_multiplier", "=", "parse_stage_config", "(", "stpp_stage", "[", "1", "]", ")", "\n", "ending_part", ",", "ending_multiplier", "=", "parse_stage_config", "(", "stpp_stage", "[", "2", "]", ")", "\n", "\n", "self", ".", "num_multipliers", "=", "(", "\n", "starting_multiplier", "+", "course_multiplier", "+", "ending_multiplier", ")", "\n", "self", ".", "stpp_stages", "=", "(", "starting_part", ",", "course_part", ",", "ending_part", ")", "\n", "self", ".", "multiplier_list", "=", "(", "starting_multiplier", ",", "course_multiplier", ",", "\n", "ending_multiplier", ")", "\n", "\n", "self", ".", "num_segments_list", "=", "num_segments_list", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTrain._extract_stage_feature": [[52, 81], ["stage_feat.size", "torch.arange().int", "torch.arange().int", "torch.arange().int", "torch.arange().int", "range", "stage_stpp_feat.append", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "stage_feat[].mean", "scale_factors.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_extract_stage_feature", "(", "stage_feat", ",", "stage_parts", ",", "num_multipliers", ",", "\n", "scale_factors", ",", "num_samples", ")", ":", "\n", "        ", "\"\"\"Extract stage feature based on structured temporal pyramid pooling.\n\n        Args:\n            stage_feat (torch.Tensor): Stage features to be STPP.\n            stage_parts (tuple): Config of STPP.\n            num_multipliers (int): Total number of parts in the stage.\n            scale_factors (list): Ratios of the effective sampling lengths\n                to augmented lengths.\n            num_samples (int): Number of samples.\n\n        Returns:\n            torch.Tensor: Features of the stage.\n        \"\"\"", "\n", "stage_stpp_feat", "=", "[", "]", "\n", "stage_len", "=", "stage_feat", ".", "size", "(", "1", ")", "\n", "for", "stage_part", "in", "stage_parts", ":", "\n", "            ", "ticks", "=", "torch", ".", "arange", "(", "0", ",", "stage_len", "+", "1e-5", ",", "\n", "stage_len", "/", "stage_part", ")", ".", "int", "(", ")", "\n", "for", "i", "in", "range", "(", "stage_part", ")", ":", "\n", "                ", "part_feat", "=", "stage_feat", "[", ":", ",", "ticks", "[", "i", "]", ":", "ticks", "[", "i", "+", "1", "]", ",", ":", "]", ".", "mean", "(", "\n", "dim", "=", "1", ")", "/", "num_multipliers", "\n", "if", "scale_factors", "is", "not", "None", ":", "\n", "                    ", "part_feat", "=", "(", "\n", "part_feat", "*", "scale_factors", ".", "view", "(", "num_samples", ",", "1", ")", ")", "\n", "", "stage_stpp_feat", ".", "append", "(", "part_feat", ")", "\n", "", "", "return", "stage_stpp_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTrain.forward": [[82, 122], ["x.view.view.size", "x.view.view.view", "x.view.view.size", "scale_factors.view.view.view", "stage_stpp_feats.extend", "stage_stpp_feats.extend", "stage_stpp_feats.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x[].mean", "ssn_head.STPPTrain._extract_stage_feature", "ssn_head.STPPTrain._extract_stage_feature", "ssn_head.STPPTrain._extract_stage_feature"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTrain._extract_stage_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTrain._extract_stage_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTrain._extract_stage_feature"], ["", "def", "forward", "(", "self", ",", "x", ",", "scale_factors", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n            scale_factors (list): Ratios of the effective sampling lengths\n                to augmented lengths.\n\n        Returns:\n            tuple[torch.Tensor, torch.Tensor]:\n                Features for predicting activity scores and\n                completeness scores.\n        \"\"\"", "\n", "x0", "=", "self", ".", "num_segments_list", "[", "0", "]", "\n", "x1", "=", "x0", "+", "self", ".", "num_segments_list", "[", "1", "]", "\n", "num_segments", "=", "x1", "+", "self", ".", "num_segments_list", "[", "2", "]", "\n", "\n", "feat_dim", "=", "x", ".", "size", "(", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "num_segments", ",", "feat_dim", ")", "\n", "num_samples", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "scale_factors", "=", "scale_factors", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "\n", "stage_stpp_feats", "=", "[", "]", "\n", "stage_stpp_feats", ".", "extend", "(", "\n", "self", ".", "_extract_stage_feature", "(", "x", "[", ":", ",", ":", "x0", ",", ":", "]", ",", "self", ".", "stpp_stages", "[", "0", "]", ",", "\n", "self", ".", "multiplier_list", "[", "0", "]", ",", "\n", "scale_factors", "[", ":", ",", "0", "]", ",", "num_samples", ")", ")", "\n", "stage_stpp_feats", ".", "extend", "(", "\n", "self", ".", "_extract_stage_feature", "(", "x", "[", ":", ",", "x0", ":", "x1", ",", ":", "]", ",", "self", ".", "stpp_stages", "[", "1", "]", ",", "\n", "self", ".", "multiplier_list", "[", "1", "]", ",", "None", ",", "\n", "num_samples", ")", ")", "\n", "stage_stpp_feats", ".", "extend", "(", "\n", "self", ".", "_extract_stage_feature", "(", "x", "[", ":", ",", "x1", ":", ",", ":", "]", ",", "self", ".", "stpp_stages", "[", "2", "]", ",", "\n", "self", ".", "multiplier_list", "[", "2", "]", ",", "\n", "scale_factors", "[", ":", ",", "1", "]", ",", "num_samples", ")", ")", "\n", "stpp_feat", "=", "torch", ".", "cat", "(", "stage_stpp_feats", ",", "dim", "=", "1", ")", "\n", "\n", "course_feat", "=", "x", "[", ":", ",", "x0", ":", "x1", ",", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "\n", "return", "course_feat", ",", "stpp_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTest.__init__": [[135, 169], ["torch.Module.__init__", "ssn_head.parse_stage_config", "ssn_head.parse_stage_config", "ssn_head.parse_stage_config", "slice", "slice", "slice"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "use_regression", "=", "True", ",", "\n", "stpp_stage", "=", "(", "1", ",", "(", "1", ",", "2", ")", ",", "1", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "activity_score_len", "=", "num_classes", "+", "1", "\n", "self", ".", "complete_score_len", "=", "num_classes", "\n", "self", ".", "reg_score_len", "=", "num_classes", "*", "2", "\n", "self", ".", "use_regression", "=", "use_regression", "\n", "\n", "starting_parts", ",", "starting_multiplier", "=", "parse_stage_config", "(", "stpp_stage", "[", "0", "]", ")", "\n", "course_parts", ",", "course_multiplier", "=", "parse_stage_config", "(", "stpp_stage", "[", "1", "]", ")", "\n", "ending_parts", ",", "ending_multiplier", "=", "parse_stage_config", "(", "stpp_stage", "[", "2", "]", ")", "\n", "\n", "self", ".", "num_multipliers", "=", "(", "\n", "starting_multiplier", "+", "course_multiplier", "+", "ending_multiplier", ")", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "self", ".", "feat_dim", "=", "(", "\n", "self", ".", "activity_score_len", "+", "self", ".", "num_multipliers", "*", "\n", "(", "self", ".", "complete_score_len", "+", "self", ".", "reg_score_len", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "feat_dim", "=", "(", "\n", "self", ".", "activity_score_len", "+", "\n", "self", ".", "num_multipliers", "*", "self", ".", "complete_score_len", ")", "\n", "", "self", ".", "stpp_stage", "=", "(", "starting_parts", ",", "course_parts", ",", "ending_parts", ")", "\n", "\n", "self", ".", "activity_slice", "=", "slice", "(", "0", ",", "self", ".", "activity_score_len", ")", "\n", "self", ".", "complete_slice", "=", "slice", "(", "\n", "self", ".", "activity_slice", ".", "stop", ",", "self", ".", "activity_slice", ".", "stop", "+", "\n", "self", ".", "complete_score_len", "*", "self", ".", "num_multipliers", ")", "\n", "self", ".", "reg_slice", "=", "slice", "(", "\n", "self", ".", "complete_slice", ".", "stop", ",", "self", ".", "complete_slice", ".", "stop", "+", "\n", "self", ".", "reg_score_len", "*", "self", ".", "num_multipliers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTest._pyramids_pooling": [[170, 219], ["enumerate", "sum", "float", "max", "torch.arange().int", "torch.arange().int", "torch.arange().int", "torch.arange().int", "range", "raw_scores.size", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "raw_scale_score.detach().cpu", "raw_score.mean", "raw_scale_score.detach"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_pyramids_pooling", "(", "out_scores", ",", "index", ",", "raw_scores", ",", "ticks", ",", "scale_factors", ",", "\n", "score_len", ",", "stpp_stage", ")", ":", "\n", "        ", "\"\"\"Perform pyramids pooling.\n\n        Args:\n            out_scores (torch.Tensor): Scores to be returned.\n            index (int): Index of output scores.\n            raw_scores (torch.Tensor): Raw scores before STPP.\n            ticks (list): Ticks of raw scores.\n            scale_factors (list): Ratios of the effective sampling lengths\n                to augmented lengths.\n            score_len (int): Length of the score.\n            stpp_stage (tuple): Config of STPP.\n        \"\"\"", "\n", "offset", "=", "0", "\n", "for", "stage_idx", ",", "stage_cfg", "in", "enumerate", "(", "stpp_stage", ")", ":", "\n", "            ", "if", "stage_idx", "==", "0", ":", "\n", "                ", "scale_factor", "=", "scale_factors", "[", "0", "]", "\n", "", "elif", "stage_idx", "==", "len", "(", "stpp_stage", ")", "-", "1", ":", "\n", "                ", "scale_factor", "=", "scale_factors", "[", "1", "]", "\n", "", "else", ":", "\n", "                ", "scale_factor", "=", "1.0", "\n", "\n", "", "sum_parts", "=", "sum", "(", "stage_cfg", ")", "\n", "tick_left", "=", "ticks", "[", "stage_idx", "]", "\n", "tick_right", "=", "float", "(", "max", "(", "ticks", "[", "stage_idx", "]", "+", "1", ",", "ticks", "[", "stage_idx", "+", "1", "]", ")", ")", "\n", "\n", "if", "tick_right", "<=", "0", "or", "tick_left", ">=", "raw_scores", ".", "size", "(", "0", ")", ":", "\n", "                ", "offset", "+=", "sum_parts", "\n", "continue", "\n", "", "for", "num_parts", "in", "stage_cfg", ":", "\n", "                ", "part_ticks", "=", "torch", ".", "arange", "(", "tick_left", ",", "tick_right", "+", "1e-5", ",", "\n", "(", "tick_right", "-", "tick_left", ")", "/", "\n", "num_parts", ")", ".", "int", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_parts", ")", ":", "\n", "                    ", "part_tick_left", "=", "part_ticks", "[", "i", "]", "\n", "part_tick_right", "=", "part_ticks", "[", "i", "+", "1", "]", "\n", "if", "part_tick_right", "-", "part_tick_left", ">=", "1", ":", "\n", "                        ", "raw_score", "=", "raw_scores", "[", "part_tick_left", ":", "part_tick_right", ",", "\n", "offset", "*", "\n", "score_len", ":", "(", "offset", "+", "1", ")", "*", "\n", "score_len", "]", "\n", "raw_scale_score", "=", "raw_score", ".", "mean", "(", "dim", "=", "0", ")", "*", "scale_factor", "\n", "out_scores", "[", "index", ",", ":", "]", "+=", "raw_scale_score", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "offset", "+=", "1", "\n", "\n", "", "", "", "return", "out_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTest.forward": [[220, 270], ["proposal_ticks.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "x.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "raw_activity_scores[].mean", "ssn_head.STPPTest._pyramids_pooling", "ssn_head.STPPTest._pyramids_pooling", "max"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTest._pyramids_pooling", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.STPPTest._pyramids_pooling"], ["", "def", "forward", "(", "self", ",", "x", ",", "proposal_ticks", ",", "scale_factors", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n            proposal_ticks (list): Ticks of proposals to be STPP.\n            scale_factors (list): Ratios of the effective sampling lengths\n                to augmented lengths.\n\n        Returns:\n            tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n                out_activity_scores (torch.Tensor): Activity scores\n                out_complete_scores (torch.Tensor): Completeness scores.\n                out_reg_scores (torch.Tensor): Regression scores.\n        \"\"\"", "\n", "assert", "x", ".", "size", "(", "1", ")", "==", "self", ".", "feat_dim", "\n", "num_ticks", "=", "proposal_ticks", ".", "size", "(", "0", ")", "\n", "\n", "out_activity_scores", "=", "torch", ".", "zeros", "(", "(", "num_ticks", ",", "self", ".", "activity_score_len", ")", ",", "\n", "dtype", "=", "x", ".", "dtype", ")", "\n", "raw_activity_scores", "=", "x", "[", ":", ",", "self", ".", "activity_slice", "]", "\n", "\n", "out_complete_scores", "=", "torch", ".", "zeros", "(", "(", "num_ticks", ",", "self", ".", "complete_score_len", ")", ",", "\n", "dtype", "=", "x", ".", "dtype", ")", "\n", "raw_complete_scores", "=", "x", "[", ":", ",", "self", ".", "complete_slice", "]", "\n", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "out_reg_scores", "=", "torch", ".", "zeros", "(", "(", "num_ticks", ",", "self", ".", "reg_score_len", ")", ",", "\n", "dtype", "=", "x", ".", "dtype", ")", "\n", "raw_reg_scores", "=", "x", "[", ":", ",", "self", ".", "reg_slice", "]", "\n", "", "else", ":", "\n", "            ", "out_reg_scores", "=", "None", "\n", "raw_reg_scores", "=", "None", "\n", "\n", "", "for", "i", "in", "range", "(", "num_ticks", ")", ":", "\n", "            ", "ticks", "=", "proposal_ticks", "[", "i", "]", "\n", "\n", "out_activity_scores", "[", "i", ",", ":", "]", "=", "raw_activity_scores", "[", "\n", "ticks", "[", "1", "]", ":", "max", "(", "ticks", "[", "1", "]", "+", "1", ",", "ticks", "[", "2", "]", ")", ",", ":", "]", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "out_complete_scores", "=", "self", ".", "_pyramids_pooling", "(", "\n", "out_complete_scores", ",", "i", ",", "raw_complete_scores", ",", "ticks", ",", "\n", "scale_factors", "[", "i", "]", ",", "self", ".", "complete_score_len", ",", "self", ".", "stpp_stage", ")", "\n", "\n", "if", "self", ".", "use_regression", ":", "\n", "                ", "out_reg_scores", "=", "self", ".", "_pyramids_pooling", "(", "\n", "out_reg_scores", ",", "i", ",", "raw_reg_scores", ",", "ticks", ",", "scale_factors", "[", "i", "]", ",", "\n", "self", ".", "reg_score_len", ",", "self", ".", "stpp_stage", ")", "\n", "\n", "", "", "return", "out_activity_scores", ",", "out_complete_scores", ",", "out_reg_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.SSNHead.__init__": [[286, 330], ["dict", "torch.Module.__init__", "consensus.copy", "consensus.copy.pop", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "ssn_head.STPPTrain", "torch.Linear", "torch.Linear", "ssn_head.STPPTest"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dropout_ratio", "=", "0.8", ",", "\n", "in_channels", "=", "1024", ",", "\n", "num_classes", "=", "20", ",", "\n", "consensus", "=", "dict", "(", "\n", "type", "=", "'STPPTrain'", ",", "\n", "standalong_classifier", "=", "True", ",", "\n", "stpp_cfg", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "num_seg", "=", "(", "2", ",", "5", ",", "2", ")", ")", ",", "\n", "use_regression", "=", "True", ",", "\n", "init_std", "=", "0.001", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "use_regression", "=", "use_regression", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "\n", "# Based on this copy, the model will utilize different", "\n", "# structured temporal pyramid pooling at training and testing.", "\n", "# Warning: this copy cannot be removed.", "\n", "", "consensus_", "=", "consensus", ".", "copy", "(", ")", "\n", "consensus_type", "=", "consensus_", ".", "pop", "(", "'type'", ")", "\n", "if", "consensus_type", "==", "'STPPTrain'", ":", "\n", "            ", "self", ".", "consensus", "=", "STPPTrain", "(", "**", "consensus_", ")", "\n", "", "elif", "consensus_type", "==", "'STPPTest'", ":", "\n", "            ", "consensus_", "[", "'num_classes'", "]", "=", "self", ".", "num_classes", "\n", "self", ".", "consensus", "=", "STPPTest", "(", "**", "consensus_", ")", "\n", "\n", "", "self", ".", "in_channels_activity", "=", "in_channels", "\n", "self", ".", "in_channels_complete", "=", "(", "\n", "self", ".", "consensus", ".", "num_multipliers", "*", "in_channels", ")", "\n", "self", ".", "activity_fc", "=", "nn", ".", "Linear", "(", "in_channels", ",", "num_classes", "+", "1", ")", "\n", "self", ".", "completeness_fc", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels_complete", ",", "\n", "num_classes", ")", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "self", ".", "regressor_fc", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels_complete", ",", "\n", "num_classes", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.SSNHead.init_weights": [[331, 337], ["mmcv.cnn.normal_init", "mmcv.cnn.normal_init", "mmcv.cnn.normal_init"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "activity_fc", ",", "std", "=", "self", ".", "init_std", ")", "\n", "normal_init", "(", "self", ".", "completeness_fc", ",", "std", "=", "self", ".", "init_std", ")", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "normal_init", "(", "self", ".", "regressor_fc", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.SSNHead.prepare_test_fc": [[338, 383], ["torch.Linear", "torch.Linear", "ssn_head.SSNHead.completeness_fc.weight.data.view().transpose().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ssn_head.SSNHead.completeness_fc.bias.data.view().expand().contiguous().view", "ssn_head.SSNHead.regressor_fc.weight.data.view().transpose().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ssn_head.SSNHead.completeness_fc.weight.data.view().transpose().contiguous", "ssn_head.SSNHead.regressor_fc.bias.data.view().expand().contiguous().view", "ssn_head.SSNHead.completeness_fc.bias.data.view().expand().contiguous", "ssn_head.SSNHead.regressor_fc.weight.data.view().transpose().contiguous", "ssn_head.SSNHead.completeness_fc.weight.data.view().transpose", "ssn_head.SSNHead.regressor_fc.bias.data.view().expand().contiguous", "ssn_head.SSNHead.completeness_fc.bias.data.view().expand", "ssn_head.SSNHead.regressor_fc.weight.data.view().transpose", "ssn_head.SSNHead.completeness_fc.weight.data.view", "ssn_head.SSNHead.regressor_fc.bias.data.view().expand", "ssn_head.SSNHead.completeness_fc.bias.data.view", "ssn_head.SSNHead.regressor_fc.weight.data.view", "ssn_head.SSNHead.regressor_fc.bias.data.view"], "methods", ["None"], ["", "", "def", "prepare_test_fc", "(", "self", ",", "stpp_feat_multiplier", ")", ":", "\n", "        ", "\"\"\"Reorganize the shape of fully connected layer at testing, in order\n        to improve testing efficiency.\n\n        Args:\n            stpp_feat_multiplier (int): Total number of parts.\n\n        Returns:\n            bool: Whether the shape transformation is ready for testing.\n        \"\"\"", "\n", "\n", "in_features", "=", "self", ".", "activity_fc", ".", "in_features", "\n", "out_features", "=", "(", "\n", "self", ".", "activity_fc", ".", "out_features", "+", "\n", "self", ".", "completeness_fc", ".", "out_features", "*", "stpp_feat_multiplier", ")", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "out_features", "+=", "(", "\n", "self", ".", "regressor_fc", ".", "out_features", "*", "stpp_feat_multiplier", ")", "\n", "", "self", ".", "test_fc", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "\n", "# Fetch weight and bias of the reorganized fc.", "\n", "complete_weight", "=", "self", ".", "completeness_fc", ".", "weight", ".", "data", ".", "view", "(", "\n", "self", ".", "completeness_fc", ".", "out_features", ",", "stpp_feat_multiplier", ",", "\n", "in_features", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "in_features", ")", "\n", "complete_bias", "=", "self", ".", "completeness_fc", ".", "bias", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "\n", "stpp_feat_multiplier", ",", "self", ".", "completeness_fc", ".", "out_features", "\n", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "/", "stpp_feat_multiplier", "\n", "\n", "weight", "=", "torch", ".", "cat", "(", "(", "self", ".", "activity_fc", ".", "weight", ".", "data", ",", "complete_weight", ")", ")", "\n", "bias", "=", "torch", ".", "cat", "(", "(", "self", ".", "activity_fc", ".", "bias", ".", "data", ",", "complete_bias", ")", ")", "\n", "\n", "if", "self", ".", "use_regression", ":", "\n", "            ", "reg_weight", "=", "self", ".", "regressor_fc", ".", "weight", ".", "data", ".", "view", "(", "\n", "self", ".", "regressor_fc", ".", "out_features", ",", "stpp_feat_multiplier", ",", "\n", "in_features", ")", ".", "transpose", "(", "0", ",", "\n", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "in_features", ")", "\n", "reg_bias", "=", "self", ".", "regressor_fc", ".", "bias", ".", "data", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "\n", "stpp_feat_multiplier", ",", "self", ".", "regressor_fc", ".", "out_features", "\n", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "/", "stpp_feat_multiplier", "\n", "weight", "=", "torch", ".", "cat", "(", "(", "weight", ",", "reg_weight", ")", ")", "\n", "bias", "=", "torch", ".", "cat", "(", "(", "bias", ",", "reg_bias", ")", ")", "\n", "\n", "", "self", ".", "test_fc", ".", "weight", ".", "data", "=", "weight", "\n", "self", ".", "test_fc", ".", "bias", ".", "data", "=", "bias", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.SSNHead.forward": [[384, 413], ["ssn_head.SSNHead.test_fc", "ssn_head.SSNHead.consensus", "ssn_head.SSNHead.consensus", "ssn_head.SSNHead.activity_fc", "ssn_head.SSNHead.completeness_fc", "ssn_head.SSNHead.dropout", "ssn_head.SSNHead.dropout", "ssn_head.SSNHead.regressor_fc", "bbox_preds.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\"\"\"", "\n", "if", "not", "test_mode", ":", "\n", "            ", "x", ",", "proposal_scale_factor", "=", "x", "\n", "activity_feat", ",", "completeness_feat", "=", "self", ".", "consensus", "(", "\n", "x", ",", "proposal_scale_factor", ")", "\n", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "                ", "activity_feat", "=", "self", ".", "dropout", "(", "activity_feat", ")", "\n", "completeness_feat", "=", "self", ".", "dropout", "(", "completeness_feat", ")", "\n", "\n", "", "activity_scores", "=", "self", ".", "activity_fc", "(", "activity_feat", ")", "\n", "complete_scores", "=", "self", ".", "completeness_fc", "(", "completeness_feat", ")", "\n", "if", "self", ".", "use_regression", ":", "\n", "                ", "bbox_preds", "=", "self", ".", "regressor_fc", "(", "completeness_feat", ")", "\n", "bbox_preds", "=", "bbox_preds", ".", "view", "(", "-", "1", ",", "\n", "self", ".", "completeness_fc", ".", "out_features", ",", "\n", "2", ")", "\n", "", "else", ":", "\n", "                ", "bbox_preds", "=", "None", "\n", "", "return", "activity_scores", ",", "complete_scores", ",", "bbox_preds", "\n", "\n", "", "x", ",", "proposal_tick_list", ",", "scale_factor_list", "=", "x", "\n", "test_scores", "=", "self", ".", "test_fc", "(", "x", ")", "\n", "(", "activity_scores", ",", "completeness_scores", ",", "\n", "bbox_preds", ")", "=", "self", ".", "consensus", "(", "test_scores", ",", "proposal_tick_list", ",", "\n", "scale_factor_list", ")", "\n", "\n", "return", "(", "test_scores", ",", "activity_scores", ",", "completeness_scores", ",", "bbox_preds", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.ssn_head.parse_stage_config": [[8, 25], ["isinstance", "isinstance", "ValueError", "sum"], "function", ["None"], ["def", "parse_stage_config", "(", "stage_cfg", ")", ":", "\n", "    ", "\"\"\"Parse config of STPP for three stages.\n\n    Args:\n        stage_cfg (int | tuple[int]):\n            Config of structured temporal pyramid pooling.\n\n    Returns:\n        tuple[tuple[int], int]:\n            Config of structured temporal pyramid pooling and\n            total number of parts(number of multipliers).\n    \"\"\"", "\n", "if", "isinstance", "(", "stage_cfg", ",", "int", ")", ":", "\n", "        ", "return", "(", "stage_cfg", ",", ")", ",", "stage_cfg", "\n", "", "if", "isinstance", "(", "stage_cfg", ",", "tuple", ")", ":", "\n", "        ", "return", "stage_cfg", ",", "sum", "(", "stage_cfg", ")", "\n", "", "raise", "ValueError", "(", "f'Incorrect STPP config {stage_cfg}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.i3d_head.I3DHead.__init__": [[24, 48], ["dict", "base.BaseHead.__init__", "torch.Linear", "torch.Dropout", "torch.AdaptiveAvgPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.5", ",", "\n", "init_std", "=", "0.01", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels", ",", "self", ".", "num_classes", ")", "\n", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "# use `nn.AdaptiveAvgPool3d` to adaptively match the in_channels.", "\n", "            ", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.i3d_head.I3DHead.init_weights": [[49, 52], ["mmcv.cnn.normal_init"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_cls", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.i3d_head.I3DHead.forward": [[53, 74], ["i3d_head.I3DHead.view", "i3d_head.I3DHead.fc_cls", "i3d_head.I3DHead.avg_pool", "i3d_head.I3DHead.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# [N, in_channels, 4, 7, 7]", "\n", "if", "self", ".", "avg_pool", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "# [N, in_channels, 1, 1, 1]", "\n", "", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "# [N, in_channels, 1, 1, 1]", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "# [N, in_channels]", "\n", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "# [N, num_classes]", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.x3d_head.X3DHead.__init__": [[23, 58], ["dict", "base.BaseHead.__init__", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.Dropout", "torch.AdaptiveAvgPool3d", "torch.AdaptiveMaxPool3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.5", ",", "\n", "init_std", "=", "0.01", ",", "\n", "fc1_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", ")", "\n", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "mid_channels", "=", "2048", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "fc1_bias", "=", "fc1_bias", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "mid_channels", ",", "bias", "=", "self", ".", "fc1_bias", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "mid_channels", ",", "self", ".", "num_classes", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "pool", "=", "None", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "elif", "self", ".", "spatial_type", "==", "'max'", ":", "\n", "            ", "self", ".", "pool", "=", "nn", ".", "AdaptiveMaxPool3d", "(", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.x3d_head.X3DHead.init_weights": [[59, 63], ["mmcv.cnn.normal_init", "mmcv.cnn.normal_init"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc1", ",", "std", "=", "self", ".", "init_std", ")", "\n", "normal_init", "(", "self", ".", "fc2", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.x3d_head.X3DHead.forward": [[64, 90], ["x3d_head.X3DHead.pool", "x3d_head.X3DHead.view", "x3d_head.X3DHead.fc1", "x3d_head.X3DHead.relu", "x3d_head.X3DHead.fc2", "x3d_head.X3DHead.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# [N, in_channels, T, H, W]", "\n", "assert", "self", ".", "pool", "is", "not", "None", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "# [N, in_channels, 1, 1, 1]", "\n", "# [N, in_channels, 1, 1, 1]", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "# [N, in_channels]", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "# [N, 2048]", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "", "cls_score", "=", "self", ".", "fc2", "(", "x", ")", "\n", "# [N, num_classes]", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.RelationModule.__init__": [[22, 32], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "hidden_dim", ",", "num_segments", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "bottleneck_dim", "=", "512", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "num_segments", "*", "self", ".", "hidden_dim", ",", "bottleneck_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "bottleneck_dim", ",", "self", ".", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.RelationModule.init_weights": [[33, 36], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "# Use the default kaiming_uniform for all nn.linear layers.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.RelationModule.forward": [[37, 42], ["trn_head.RelationModule.view", "trn_head.RelationModule.classifier", "trn_head.RelationModule.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# [N, num_segs * hidden_dim]", "\n", "        ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.RelationModuleMultiScale.__init__": [[54, 83], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "list", "trn_head.RelationModuleMultiScale.relations_scales.append", "trn_head.RelationModuleMultiScale.subsample_scales.append", "len", "torch.Sequential", "torch.Sequential", "trn_head.RelationModuleMultiScale.fc_fusion_scales.append", "itertools.combinations", "min", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "range", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "hidden_dim", ",", "num_segments", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n", "# generate the multiple frame relations", "\n", "self", ".", "scales", "=", "range", "(", "num_segments", ",", "1", ",", "-", "1", ")", "\n", "\n", "self", ".", "relations_scales", "=", "[", "]", "\n", "self", ".", "subsample_scales", "=", "[", "]", "\n", "max_subsample", "=", "3", "\n", "for", "scale", "in", "self", ".", "scales", ":", "\n", "# select the different frame features for different scales", "\n", "            ", "relations_scale", "=", "list", "(", "\n", "itertools", ".", "combinations", "(", "range", "(", "self", ".", "num_segments", ")", ",", "scale", ")", ")", "\n", "self", ".", "relations_scales", ".", "append", "(", "relations_scale", ")", "\n", "# sample `max_subsample` relation_scale at most", "\n", "self", ".", "subsample_scales", ".", "append", "(", "\n", "min", "(", "max_subsample", ",", "len", "(", "relations_scale", ")", ")", ")", "\n", "", "assert", "len", "(", "self", ".", "relations_scales", "[", "0", "]", ")", "==", "1", "\n", "\n", "bottleneck_dim", "=", "256", "\n", "self", ".", "fc_fusion_scales", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "scale", "in", "self", ".", "scales", ":", "\n", "            ", "fc_fusion", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "scale", "*", "self", ".", "hidden_dim", ",", "bottleneck_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "bottleneck_dim", ",", "self", ".", "num_classes", ")", ")", "\n", "self", ".", "fc_fusion_scales", ".", "append", "(", "fc_fusion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.RelationModuleMultiScale.init_weights": [[84, 87], ["None"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "# Use the default kaiming_uniform for all nn.linear layers.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.RelationModuleMultiScale.forward": [[88, 109], ["act_all.view.view.view", "range", "act_all.view.view.size", "len", "numpy.random.choice", "len", "act_relation.view.view.view", "act_relation.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# the first one is the largest scale", "\n", "        ", "act_all", "=", "x", "[", ":", ",", "self", ".", "relations_scales", "[", "0", "]", "[", "0", "]", ",", ":", "]", "\n", "act_all", "=", "act_all", ".", "view", "(", "\n", "act_all", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "0", "]", "*", "self", ".", "hidden_dim", ")", "\n", "act_all", "=", "self", ".", "fc_fusion_scales", "[", "0", "]", "(", "act_all", ")", "\n", "\n", "for", "scaleID", "in", "range", "(", "1", ",", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "# iterate over the scales", "\n", "            ", "idx_relations_randomsample", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "relations_scales", "[", "scaleID", "]", ")", ",", "\n", "self", ".", "subsample_scales", "[", "scaleID", "]", ",", "\n", "replace", "=", "False", ")", "\n", "for", "idx", "in", "idx_relations_randomsample", ":", "\n", "                ", "act_relation", "=", "x", "[", ":", ",", "self", ".", "relations_scales", "[", "scaleID", "]", "[", "idx", "]", ",", ":", "]", "\n", "act_relation", "=", "act_relation", ".", "view", "(", "\n", "act_relation", ".", "size", "(", "0", ")", ",", "\n", "self", ".", "scales", "[", "scaleID", "]", "*", "self", ".", "hidden_dim", ")", "\n", "act_relation", "=", "self", ".", "fc_fusion_scales", "[", "scaleID", "]", "(", "act_relation", ")", "\n", "act_all", "+=", "act_relation", "\n", "", "", "return", "act_all", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.TRNHead.__init__": [[132, 175], ["dict", "base.BaseHead.__init__", "torch.Linear", "torch.Linear", "trn_head.RelationModule", "torch.Dropout", "torch.Dropout", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "trn_head.RelationModuleMultiScale", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", ",", "\n", "in_channels", ",", "\n", "num_segments", "=", "8", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "relation_type", "=", "'TRNMultiScale'", ",", "\n", "hidden_dim", "=", "256", ",", "\n", "dropout_ratio", "=", "0.8", ",", "\n", "init_std", "=", "0.001", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "num_classes", ",", "in_channels", ",", "loss_cls", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "spatial_type", "=", "spatial_type", "\n", "self", ".", "relation_type", "=", "relation_type", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "if", "self", ".", "relation_type", "==", "'TRN'", ":", "\n", "            ", "self", ".", "consensus", "=", "RelationModule", "(", "self", ".", "hidden_dim", ",", "self", ".", "num_segments", ",", "\n", "self", ".", "num_classes", ")", "\n", "", "elif", "self", ".", "relation_type", "==", "'TRNMultiScale'", ":", "\n", "            ", "self", ".", "consensus", "=", "RelationModuleMultiScale", "(", "self", ".", "hidden_dim", ",", "\n", "self", ".", "num_segments", ",", "\n", "self", ".", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown Relation Type {self.relation_type}!'", ")", "\n", "\n", "", "if", "self", ".", "dropout_ratio", "!=", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fc_cls", "=", "nn", ".", "Linear", "(", "self", ".", "in_channels", ",", "self", ".", "hidden_dim", ")", "\n", "\n", "if", "self", ".", "spatial_type", "==", "'avg'", ":", "\n", "# use `nn.AdaptiveAvgPool2d` to adaptively match the in_channels.", "\n", "            ", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "avg_pool", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.TRNHead.init_weights": [[176, 180], ["mmcv.cnn.normal_init", "trn_head.TRNHead.consensus.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "normal_init", "(", "self", ".", "fc_cls", ",", "std", "=", "self", ".", "init_std", ")", "\n", "self", ".", "consensus", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.trn_head.TRNHead.forward": [[181, 211], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "trn_head.TRNHead.fc_cls", "trn_head.TRNHead.view", "trn_head.TRNHead.consensus", "trn_head.TRNHead.avg_pool", "trn_head.TRNHead.dropout", "trn_head.TRNHead.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_segs", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n            num_segs (int): Useless in TRNHead. By default, `num_segs`\n                is equal to `clip_len * num_clips * num_crops`, which is\n                automatically generated in Recognizer forward phase and\n                useless in TRN models. The `self.num_segments` we need is a\n                hyper parameter to build TRN models.\n        Returns:\n            torch.Tensor: The classification scores for input samples.\n        \"\"\"", "\n", "# [N * num_segs, in_channels, 7, 7]", "\n", "if", "self", ".", "avg_pool", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "# [N * num_segs, in_channels, 1, 1]", "\n", "", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "# [N * num_segs, in_channels]", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "# [N, num_segs, hidden_dim]", "\n", "", "cls_score", "=", "self", ".", "fc_cls", "(", "x", ")", "\n", "cls_score", "=", "cls_score", ".", "view", "(", "(", "-", "1", ",", "self", ".", "num_segments", ")", "+", "\n", "cls_score", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "\n", "# [N, num_classes]", "\n", "cls_score", "=", "self", ".", "consensus", "(", "cls_score", ")", "\n", "return", "cls_score", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.tanet.TABlock.__init__": [[28, 40], ["dict", "torch.Module.__init__", "copy.deepcopy", "common.TAM", "isinstance", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "block", ",", "num_segments", ",", "tam_cfg", "=", "dict", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tam_cfg", "=", "deepcopy", "(", "tam_cfg", ")", "\n", "self", ".", "block", "=", "block", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "tam", "=", "TAM", "(", "\n", "in_channels", "=", "block", ".", "conv1", ".", "out_channels", ",", "\n", "num_segments", "=", "num_segments", ",", "\n", "**", "self", ".", "tam_cfg", ")", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "block", ",", "Bottleneck", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'TA-Blocks have not been fully '", "\n", "'implemented except the pattern based '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.tanet.TABlock.forward": [[43, 70], ["isinstance", "tanet.TABlock.block.relu", "tanet.TABlock.block.conv1", "tanet.TABlock.tam", "tanet.TABlock.block.conv2", "tanet.TABlock.block.conv3", "torch.utils.checkpoint.checkpoint", "tanet.TABlock.forward._inner_forward"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "isinstance", "(", "self", ".", "block", ",", "Bottleneck", ")", "\n", "\n", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "\"\"\"Forward wrapper for utilizing checkpoint.\"\"\"", "\n", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "block", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "tam", "(", "out", ")", "\n", "out", "=", "self", ".", "block", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "block", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "block", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "block", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "out", "+", "identity", "\n", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "block", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "block", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.tanet.TANet.__init__": [[91, 96], ["dict", "resnet.ResNet.__init__", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "depth", ",", "num_segments", ",", "tam_cfg", "=", "dict", "(", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "depth", ",", "**", "kwargs", ")", "\n", "assert", "num_segments", ">=", "3", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "tam_cfg", "=", "deepcopy", "(", "tam_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.tanet.TANet.init_weights": [[97, 100], ["super().init_weights", "tanet.TANet.make_tam_modeling"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.tanet.TANet.make_tam_modeling"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "init_weights", "(", ")", "\n", "self", ".", "make_tam_modeling", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.tanet.TANet.make_tam_modeling": [[101, 115], ["range", "dict", "list", "enumerate", "torch.Sequential", "getattr", "setattr", "stage.children", "tanet.TABlock", "tanet.TANet.make_tam_modeling.make_tam_block"], "methods", ["None"], ["", "def", "make_tam_modeling", "(", "self", ")", ":", "\n", "        ", "\"\"\"Replace ResNet-Block with TA-Block.\"\"\"", "\n", "\n", "def", "make_tam_block", "(", "stage", ",", "num_segments", ",", "tam_cfg", "=", "dict", "(", ")", ")", ":", "\n", "            ", "blocks", "=", "list", "(", "stage", ".", "children", "(", ")", ")", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "blocks", ")", ":", "\n", "                ", "blocks", "[", "i", "]", "=", "TABlock", "(", "block", ",", "num_segments", ",", "deepcopy", "(", "tam_cfg", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "layer_name", "=", "f'layer{i + 1}'", "\n", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "setattr", "(", "self", ",", "layer_name", ",", "\n", "make_tam_block", "(", "res_layer", ",", "self", ".", "num_segments", ",", "self", ".", "tam_cfg", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.c3d.C3D.__init__": [[31, 83], ["torch.Module.__init__", "dict", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.MaxPool3d", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.Dropout", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "pretrained", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "dropout_ratio", "=", "0.5", ",", "\n", "init_std", "=", "0.005", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "conv_cfg", "is", "None", ":", "\n", "            ", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", "\n", "", "if", "act_cfg", "is", "None", ":", "\n", "            ", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", "\n", "", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "c3d_conv_param", "=", "dict", "(", "\n", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n", "self", ".", "conv1a", "=", "ConvModule", "(", "3", ",", "64", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "1", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv2a", "=", "ConvModule", "(", "64", ",", "128", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv3a", "=", "ConvModule", "(", "128", ",", "256", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "conv3b", "=", "ConvModule", "(", "256", ",", "256", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "pool3", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv4a", "=", "ConvModule", "(", "256", ",", "512", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "conv4b", "=", "ConvModule", "(", "512", ",", "512", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "pool4", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "conv5a", "=", "ConvModule", "(", "512", ",", "512", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "conv5b", "=", "ConvModule", "(", "512", ",", "512", ",", "**", "c3d_conv_param", ")", "\n", "self", ".", "pool5", "=", "nn", ".", "MaxPool3d", "(", "\n", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "fc6", "=", "nn", ".", "Linear", "(", "8192", ",", "4096", ")", "\n", "self", ".", "fc7", "=", "nn", ".", "Linear", "(", "4096", ",", "4096", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.c3d.C3D.init_weights": [[84, 104], ["isinstance", "utils.get_root_logger", "utils.get_root_logger.info", "mmcv.runner.load_checkpoint", "c3d.C3D.modules", "TypeError", "isinstance", "mmcv.cnn.kaiming_init", "isinstance", "mmcv.cnn.normal_init", "isinstance", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'load model from: {self.pretrained}'", ")", "\n", "\n", "load_checkpoint", "(", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "\n", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                    ", "normal_init", "(", "m", ",", "std", "=", "self", ".", "init_std", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.c3d.C3D.forward": [[105, 140], ["c3d.C3D.conv1a", "c3d.C3D.pool1", "c3d.C3D.conv2a", "c3d.C3D.pool2", "c3d.C3D.conv3a", "c3d.C3D.conv3b", "c3d.C3D.pool3", "c3d.C3D.conv4a", "c3d.C3D.conv4b", "c3d.C3D.pool4", "c3d.C3D.conv5a", "c3d.C3D.conv5b", "c3d.C3D.pool5", "c3d.C3D.flatten", "c3d.C3D.relu", "c3d.C3D.dropout", "c3d.C3D.relu", "c3d.C3D.fc6", "c3d.C3D.fc7"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n                the size of x is (num_batches, 3, 16, 112, 112).\n\n        Returns:\n            torch.Tensor: The feature of the input\n            samples extracted by the backbone.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1a", "(", "x", ")", "\n", "x", "=", "self", ".", "pool1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv2a", "(", "x", ")", "\n", "x", "=", "self", ".", "pool2", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv3a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3b", "(", "x", ")", "\n", "x", "=", "self", ".", "pool3", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv4a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4b", "(", "x", ")", "\n", "x", "=", "self", ".", "pool4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv5a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv5b", "(", "x", ")", "\n", "x", "=", "self", ".", "pool5", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "x", "=", "self", ".", "relu", "(", "self", ".", "fc6", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "self", ".", "fc7", "(", "x", ")", ")", "\n", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet2plus1d.ResNet2Plus1d.__init__": [[13, 17], ["resnet3d.ResNet3d.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "assert", "self", ".", "pretrained2d", "is", "False", "\n", "assert", "self", ".", "conv_cfg", "[", "'type'", "]", "==", "'Conv2plus1d'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet2plus1d.ResNet2Plus1d._freeze_stages": [[18, 31], ["range", "resnet2plus1d.ResNet2Plus1d.conv1.eval", "resnet2plus1d.ResNet2Plus1d.conv1.parameters", "getattr", "getattr.eval", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prevent all the parameters from being optimized before\n        ``self.frozen_stages``.\"\"\"", "\n", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "conv1", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet2plus1d.ResNet2Plus1d.forward": [[32, 50], ["resnet2plus1d.ResNet2Plus1d.conv1", "resnet2plus1d.ResNet2Plus1d.maxpool", "getattr", "getattr."], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The feature of the input\n            samples extracted by the backbone.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "for", "layer_name", "in", "self", ".", "res_layers", ":", "\n", "            ", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "# no pool2 in R(2+1)d", "\n", "x", "=", "res_layer", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.SEModule.__init__": [[16, 26], ["torch.Module.__init__", "torch.AdaptiveAvgPool3d", "torch.AdaptiveAvgPool3d", "x3d.SEModule._round_width", "torch.Conv3d", "torch.Conv3d", "torch.ReLU", "torch.ReLU", "torch.Conv3d", "torch.Conv3d", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._round_width"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "reduction", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool3d", "(", "1", ")", "\n", "self", ".", "bottleneck", "=", "self", ".", "_round_width", "(", "channels", ",", "reduction", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Conv3d", "(", "\n", "channels", ",", "self", ".", "bottleneck", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Conv3d", "(", "\n", "self", ".", "bottleneck", ",", "channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.SEModule._round_width": [[27, 36], ["max", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_round_width", "(", "width", ",", "multiplier", ",", "min_width", "=", "8", ",", "divisor", "=", "8", ")", ":", "\n", "        ", "width", "*=", "multiplier", "\n", "min_width", "=", "min_width", "or", "divisor", "\n", "width_out", "=", "max", "(", "min_width", ",", "\n", "int", "(", "width", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "if", "width_out", "<", "0.9", "*", "width", ":", "\n", "            ", "width_out", "+=", "divisor", "\n", "", "return", "int", "(", "width_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.SEModule.forward": [[37, 45], ["x3d.SEModule.avg_pool", "x3d.SEModule.fc1", "x3d.SEModule.relu", "x3d.SEModule.fc2", "x3d.SEModule.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "module_input", "=", "x", "\n", "x", "=", "self", ".", "avg_pool", "(", "x", ")", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "sigmoid", "(", "x", ")", "\n", "return", "module_input", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.BlockX3D.__init__": [[70, 137], ["dict", "dict", "dict", "torch.Module.__init__", "dict", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.Swish", "mmcv.cnn.ConvModule", "mmcv.cnn.build_activation_layer", "x3d.SEModule"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "outplanes", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "se_ratio", "=", "None", ",", "\n", "use_swish", "=", "True", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "planes", "=", "planes", "\n", "self", ".", "outplanes", "=", "outplanes", "\n", "self", ".", "spatial_stride", "=", "spatial_stride", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "se_ratio", "=", "se_ratio", "\n", "self", ".", "use_swish", "=", "use_swish", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "act_cfg_swish", "=", "dict", "(", "type", "=", "'Swish'", ")", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "in_channels", "=", "inplanes", ",", "\n", "out_channels", "=", "planes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "# Here we use the channel-wise conv", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "in_channels", "=", "planes", ",", "\n", "out_channels", "=", "planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "(", "1", ",", "self", ".", "spatial_stride", ",", "self", ".", "spatial_stride", ")", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "planes", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "self", ".", "swish", "=", "Swish", "(", ")", "\n", "\n", "self", ".", "conv3", "=", "ConvModule", "(", "\n", "in_channels", "=", "planes", ",", "\n", "out_channels", "=", "outplanes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "if", "self", ".", "se_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "se_module", "=", "SEModule", "(", "planes", ",", "self", ".", "se_ratio", ")", "\n", "\n", "", "self", ".", "relu", "=", "build_activation_layer", "(", "self", ".", "act_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.BlockX3D.forward": [[138, 166], ["x3d.BlockX3D.relu", "x3d.BlockX3D.conv1", "x3d.BlockX3D.conv2", "x3d.BlockX3D.swish", "x3d.BlockX3D.conv3", "torch.checkpoint", "torch.checkpoint", "x3d.BlockX3D.forward._inner_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\"\"\"", "\n", "\n", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "\"\"\"Forward wrapper for utilizing checkpoint.\"\"\"", "\n", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "if", "self", ".", "se_ratio", "is", "not", "None", ":", "\n", "                ", "out", "=", "self", ".", "se_module", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "swish", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "out", "+", "identity", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D.__init__": [[209, 309], ["dict", "dict", "dict", "torch.Module.__init__", "x3d.X3D._round_width", "x3d.X3D._make_stem_layer", "enumerate", "mmcv.cnn.ConvModule", "int", "x3d.X3D._round_repeats", "len", "int", "x3d.X3D.make_res_layer", "x3d.X3D.add_module", "x3d.X3D.res_layers.append", "int", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._round_width", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._make_stem_layer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._round_repeats", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.make_res_layer"], ["def", "__init__", "(", "self", ",", "\n", "gamma_w", "=", "1.0", ",", "\n", "gamma_b", "=", "1.0", ",", "\n", "gamma_d", "=", "1.0", ",", "\n", "pretrained", "=", "None", ",", "\n", "in_channels", "=", "3", ",", "\n", "num_stages", "=", "4", ",", "\n", "spatial_strides", "=", "(", "2", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "se_style", "=", "'half'", ",", "\n", "se_ratio", "=", "1", "/", "16", ",", "\n", "use_swish", "=", "True", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ",", "\n", "norm_eval", "=", "False", ",", "\n", "with_cp", "=", "False", ",", "\n", "zero_init_residual", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma_w", "=", "gamma_w", "\n", "self", ".", "gamma_b", "=", "gamma_b", "\n", "self", ".", "gamma_d", "=", "gamma_d", "\n", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "# Hard coded, can be changed by gamma_w", "\n", "self", ".", "base_channels", "=", "24", "\n", "self", ".", "stage_blocks", "=", "[", "1", ",", "2", ",", "5", ",", "3", "]", "\n", "\n", "# apply parameters gamma_w and gamma_d", "\n", "self", ".", "base_channels", "=", "self", ".", "_round_width", "(", "self", ".", "base_channels", ",", "\n", "self", ".", "gamma_w", ")", "\n", "\n", "self", ".", "stage_blocks", "=", "[", "\n", "self", ".", "_round_repeats", "(", "x", ",", "self", ".", "gamma_d", ")", "for", "x", "in", "self", ".", "stage_blocks", "\n", "]", "\n", "\n", "self", ".", "num_stages", "=", "num_stages", "\n", "assert", "1", "<=", "num_stages", "<=", "4", "\n", "self", ".", "spatial_strides", "=", "spatial_strides", "\n", "assert", "len", "(", "spatial_strides", ")", "==", "num_stages", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "\n", "self", ".", "se_style", "=", "se_style", "\n", "assert", "self", ".", "se_style", "in", "[", "'all'", ",", "'half'", "]", "\n", "self", ".", "se_ratio", "=", "se_ratio", "\n", "assert", "(", "self", ".", "se_ratio", "is", "None", ")", "or", "(", "self", ".", "se_ratio", ">", "0", ")", "\n", "self", ".", "use_swish", "=", "use_swish", "\n", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "norm_eval", "=", "norm_eval", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "zero_init_residual", "=", "zero_init_residual", "\n", "\n", "self", ".", "block", "=", "BlockX3D", "\n", "self", ".", "stage_blocks", "=", "self", ".", "stage_blocks", "[", ":", "num_stages", "]", "\n", "self", ".", "layer_inplanes", "=", "self", ".", "base_channels", "\n", "self", ".", "_make_stem_layer", "(", ")", "\n", "\n", "self", ".", "res_layers", "=", "[", "]", "\n", "for", "i", ",", "num_blocks", "in", "enumerate", "(", "self", ".", "stage_blocks", ")", ":", "\n", "            ", "spatial_stride", "=", "spatial_strides", "[", "i", "]", "\n", "inplanes", "=", "self", ".", "base_channels", "*", "2", "**", "i", "\n", "planes", "=", "int", "(", "inplanes", "*", "self", ".", "gamma_b", ")", "\n", "\n", "res_layer", "=", "self", ".", "make_res_layer", "(", "\n", "self", ".", "block", ",", "\n", "self", ".", "layer_inplanes", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "num_blocks", ",", "\n", "spatial_stride", "=", "spatial_stride", ",", "\n", "se_style", "=", "self", ".", "se_style", ",", "\n", "se_ratio", "=", "self", ".", "se_ratio", ",", "\n", "use_swish", "=", "self", ".", "use_swish", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "layer_inplanes", "=", "inplanes", "\n", "layer_name", "=", "f'layer{i + 1}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "res_layer", ")", "\n", "self", ".", "res_layers", ".", "append", "(", "layer_name", ")", "\n", "\n", "", "self", ".", "feat_dim", "=", "self", ".", "base_channels", "*", "2", "**", "(", "len", "(", "self", ".", "stage_blocks", ")", "-", "1", ")", "\n", "self", ".", "conv5", "=", "ConvModule", "(", "\n", "self", ".", "feat_dim", ",", "\n", "int", "(", "self", ".", "feat_dim", "*", "self", ".", "gamma_b", ")", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "self", ".", "feat_dim", "=", "int", "(", "self", ".", "feat_dim", "*", "self", ".", "gamma_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._round_width": [[310, 323], ["max", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_round_width", "(", "width", ",", "multiplier", ",", "min_depth", "=", "8", ",", "divisor", "=", "8", ")", ":", "\n", "        ", "\"\"\"Round width of filters based on width multiplier.\"\"\"", "\n", "if", "not", "multiplier", ":", "\n", "            ", "return", "width", "\n", "\n", "", "width", "*=", "multiplier", "\n", "min_depth", "=", "min_depth", "or", "divisor", "\n", "new_filters", "=", "max", "(", "min_depth", ",", "\n", "int", "(", "width", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "if", "new_filters", "<", "0.9", "*", "width", ":", "\n", "            ", "new_filters", "+=", "divisor", "\n", "", "return", "int", "(", "new_filters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._round_repeats": [[324, 330], ["int", "math.ceil"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_round_repeats", "(", "repeats", ",", "multiplier", ")", ":", "\n", "        ", "\"\"\"Round number of layers based on depth multiplier.\"\"\"", "\n", "if", "not", "multiplier", ":", "\n", "            ", "return", "repeats", "\n", "", "return", "int", "(", "math", ".", "ceil", "(", "multiplier", "*", "repeats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D.make_res_layer": [[333, 432], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "mmcv.cnn.ConvModule", "block", "layers.append", "block", "range"], "methods", ["None"], ["", "def", "make_res_layer", "(", "self", ",", "\n", "block", ",", "\n", "layer_inplanes", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "blocks", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "se_style", "=", "'half'", ",", "\n", "se_ratio", "=", "None", ",", "\n", "use_swish", "=", "True", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "with_cp", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Build residual layer for ResNet3D.\n\n        Args:\n            block (nn.Module): Residual module to be built.\n            layer_inplanes (int): Number of channels for the input feature\n                of the res layer.\n            inplanes (int): Number of channels for the input feature in each\n                block, which equals to base_channels * gamma_w.\n            planes (int): Number of channels for the output feature in each\n                block, which equals to base_channel * gamma_w * gamma_b.\n            blocks (int): Number of residual blocks.\n            spatial_stride (int): Spatial strides in residual and conv layers.\n                Default: 1.\n            se_style (str): The style of inserting SE modules into BlockX3D,\n                'half' denotes insert into half of the blocks, while 'all'\n                denotes insert into all blocks. Default: 'half'.\n            se_ratio (float | None): The reduction ratio of squeeze and\n                excitation unit. If set as None, it means not using SE unit.\n                Default: None.\n            use_swish (bool): Whether to use swish as the activation function\n                before and after the 3x3x3 conv. Default: True.\n            conv_cfg (dict | None): Config for norm layers. Default: None.\n            norm_cfg (dict | None): Config for norm layers. Default: None.\n            act_cfg (dict | None): Config for activate layers. Default: None.\n            with_cp (bool | None): Use checkpoint or not. Using checkpoint\n                will save some memory while slowing down the training speed.\n                Default: False.\n\n        Returns:\n            nn.Module: A residual layer for the given config.\n        \"\"\"", "\n", "downsample", "=", "None", "\n", "if", "spatial_stride", "!=", "1", "or", "layer_inplanes", "!=", "inplanes", ":", "\n", "            ", "downsample", "=", "ConvModule", "(", "\n", "layer_inplanes", ",", "\n", "inplanes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "(", "1", ",", "spatial_stride", ",", "spatial_stride", ")", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "", "use_se", "=", "[", "False", "]", "*", "blocks", "\n", "if", "self", ".", "se_style", "==", "'all'", ":", "\n", "            ", "use_se", "=", "[", "True", "]", "*", "blocks", "\n", "", "elif", "self", ".", "se_style", "==", "'half'", ":", "\n", "            ", "use_se", "=", "[", "i", "%", "2", "==", "0", "for", "i", "in", "range", "(", "blocks", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "\n", "block", "(", "\n", "layer_inplanes", ",", "\n", "planes", ",", "\n", "inplanes", ",", "\n", "spatial_stride", "=", "spatial_stride", ",", "\n", "downsample", "=", "downsample", ",", "\n", "se_ratio", "=", "se_ratio", "if", "use_se", "[", "0", "]", "else", "None", ",", "\n", "use_swish", "=", "use_swish", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "inplanes", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "se_ratio", "=", "se_ratio", "if", "use_se", "[", "i", "]", "else", "None", ",", "\n", "use_swish", "=", "use_swish", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._make_stem_layer": [[433, 457], ["mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule"], "methods", ["None"], ["", "def", "_make_stem_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct the stem layers consists of a conv+norm+act module and a\n        pooling layer.\"\"\"", "\n", "self", ".", "conv1_s", "=", "ConvModule", "(", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "base_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ")", "\n", "self", ".", "conv1_t", "=", "ConvModule", "(", "\n", "self", ".", "base_channels", ",", "\n", "self", ".", "base_channels", ",", "\n", "kernel_size", "=", "(", "5", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "2", ",", "0", ",", "0", ")", ",", "\n", "groups", "=", "self", ".", "base_channels", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D._freeze_stages": [[458, 474], ["range", "x3d.X3D.conv1_s.eval", "x3d.X3D.conv1_t.eval", "x3d.X3D.conv1_s.parameters", "x3d.X3D.conv1_t.parameters", "getattr", "getattr.eval", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prevent all the parameters from being optimized before\n        ``self.frozen_stages``.\"\"\"", "\n", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "conv1_s", ".", "eval", "(", ")", "\n", "self", ".", "conv1_t", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "conv1_s", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "conv1_t", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D.init_weights": [[475, 497], ["isinstance", "utils.get_root_logger", "utils.get_root_logger.info", "mmcv.runner.load_checkpoint", "x3d.X3D.modules", "TypeError", "isinstance", "x3d.X3D.modules", "mmcv.cnn.kaiming_init", "isinstance", "isinstance", "mmcv.cnn.constant_init", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], ["", "", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'load model from: {self.pretrained}'", ")", "\n", "\n", "load_checkpoint", "(", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "\n", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n", "", "", "if", "self", ".", "zero_init_residual", ":", "\n", "                ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "BlockX3D", ")", ":", "\n", "                        ", "constant_init", "(", "m", ".", "conv3", ".", "bn", ",", "0", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D.forward": [[498, 515], ["x3d.X3D.conv1_s", "x3d.X3D.conv1_t", "x3d.X3D.conv5", "getattr", "getattr."], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The feature of the input\n            samples extracted by the backbone.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1_s", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1_t", "(", "x", ")", "\n", "for", "layer_name", "in", "self", ".", "res_layers", ":", "\n", "            ", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "x", "=", "res_layer", "(", "x", ")", "\n", "", "x", "=", "self", ".", "conv5", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.x3d.X3D.train": [[516, 524], ["super().train", "x3d.X3D._freeze_stages", "x3d.X3D.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Set the optimization status when training.\"\"\"", "\n", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.InvertedResidual.__init__": [[57, 104], ["dict", "dict", "torch.Module.__init__", "int", "layers.extend", "torch.Sequential", "torch.Sequential", "round", "layers.append", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "stride", ",", "\n", "expand_ratio", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU6'", ")", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "super", "(", "InvertedResidual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", ",", "f'stride must in [1, 2]. '", "f'But received {stride}.'", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "use_res_connect", "=", "self", ".", "stride", "==", "1", "and", "in_channels", "==", "out_channels", "\n", "hidden_dim", "=", "int", "(", "round", "(", "in_channels", "*", "expand_ratio", ")", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "if", "expand_ratio", "!=", "1", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", ")", "\n", "", "layers", ".", "extend", "(", "[", "\n", "ConvModule", "(", "\n", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "hidden_dim", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", ",", "\n", "ConvModule", "(", "\n", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "]", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.InvertedResidual.forward": [[105, 119], ["mobilenet_v2.InvertedResidual.conv", "torch.checkpoint", "torch.checkpoint", "mobilenet_v2.InvertedResidual.forward._inner_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "if", "self", ".", "use_res_connect", ":", "\n", "                ", "return", "x", "+", "self", ".", "conv", "(", "x", ")", "\n", "\n", "", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2.__init__": [[152, 224], ["dict", "dict", "dict", "torch.Module.__init__", "mobilenet_v2.make_divisible", "mmcv.cnn.ConvModule", "enumerate", "mmcv.cnn.ConvModule", "mobilenet_v2.MobileNetV2.add_module", "mobilenet_v2.MobileNetV2.layers.append", "range", "ValueError", "mobilenet_v2.make_divisible", "mobilenet_v2.MobileNetV2.make_layer", "mobilenet_v2.MobileNetV2.add_module", "mobilenet_v2.MobileNetV2.layers.append", "int", "range", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.make_divisible", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.make_divisible", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2.make_layer"], ["def", "__init__", "(", "self", ",", "\n", "pretrained", "=", "None", ",", "\n", "widen_factor", "=", "1.", ",", "\n", "out_indices", "=", "(", "7", ",", ")", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN2d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU6'", ",", "inplace", "=", "True", ")", ",", "\n", "norm_eval", "=", "False", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "widen_factor", "=", "widen_factor", "\n", "self", ".", "out_indices", "=", "out_indices", "\n", "for", "index", "in", "out_indices", ":", "\n", "            ", "if", "index", "not", "in", "range", "(", "0", ",", "8", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'the item in out_indices must in '", "\n", "f'range(0, 8). But received {index}'", ")", "\n", "\n", "", "", "if", "frozen_stages", "not", "in", "range", "(", "-", "1", ",", "8", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'frozen_stages must be in range(-1, 8). '", "\n", "f'But received {frozen_stages}'", ")", "\n", "", "self", ".", "out_indices", "=", "out_indices", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "norm_eval", "=", "norm_eval", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "\n", "self", ".", "in_channels", "=", "make_divisible", "(", "32", "*", "widen_factor", ",", "8", ")", "\n", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "in_channels", "=", "3", ",", "\n", "out_channels", "=", "self", ".", "in_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n", "self", ".", "layers", "=", "[", "]", "\n", "\n", "for", "i", ",", "layer_cfg", "in", "enumerate", "(", "self", ".", "arch_settings", ")", ":", "\n", "            ", "expand_ratio", ",", "channel", ",", "num_blocks", ",", "stride", "=", "layer_cfg", "\n", "out_channels", "=", "make_divisible", "(", "channel", "*", "widen_factor", ",", "8", ")", "\n", "inverted_res_layer", "=", "self", ".", "make_layer", "(", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "stride", "=", "stride", ",", "\n", "expand_ratio", "=", "expand_ratio", ")", "\n", "layer_name", "=", "f'layer{i + 1}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "inverted_res_layer", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer_name", ")", "\n", "\n", "", "if", "widen_factor", ">", "1.0", ":", "\n", "            ", "self", ".", "out_channel", "=", "int", "(", "1280", "*", "widen_factor", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_channel", "=", "1280", "\n", "\n", "", "layer", "=", "ConvModule", "(", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "out_channels", "=", "self", ".", "out_channel", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "self", ".", "add_module", "(", "'conv2'", ",", "layer", ")", "\n", "self", ".", "layers", ".", "append", "(", "'conv2'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2.make_layer": [[225, 252], ["range", "torch.Sequential", "torch.Sequential", "layers.append", "mobilenet_v2.InvertedResidual"], "methods", ["None"], ["", "def", "make_layer", "(", "self", ",", "out_channels", ",", "num_blocks", ",", "stride", ",", "expand_ratio", ")", ":", "\n", "        ", "\"\"\"Stack InvertedResidual blocks to build a layer for MobileNetV2.\n\n        Args:\n            out_channels (int): out_channels of block.\n            num_blocks (int): number of blocks.\n            stride (int): stride of the first block. Default: 1\n            expand_ratio (int): Expand the number of channels of the\n                hidden layer in InvertedResidual by this ratio. Default: 6.\n        \"\"\"", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "if", "i", ">=", "1", ":", "\n", "                ", "stride", "=", "1", "\n", "", "layers", ".", "append", "(", "\n", "InvertedResidual", "(", "\n", "self", ".", "in_channels", ",", "\n", "out_channels", ",", "\n", "stride", ",", "\n", "expand_ratio", "=", "expand_ratio", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ",", "\n", "with_cp", "=", "self", ".", "with_cp", ")", ")", "\n", "self", ".", "in_channels", "=", "out_channels", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2.init_weights": [[253, 265], ["isinstance", "utils.get_root_logger", "mmcv.runner.load_checkpoint", "mobilenet_v2.MobileNetV2.modules", "TypeError", "isinstance", "mmcv.cnn.kaiming_init", "isinstance", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "load_checkpoint", "(", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "_BatchNorm", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                    ", "constant_init", "(", "m", ",", "1", ")", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2.forward": [[266, 280], ["mobilenet_v2.MobileNetV2.conv1", "enumerate", "tuple", "getattr", "getattr.", "len", "outs.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "layer_name", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "x", "=", "layer", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "out_indices", ":", "\n", "                ", "outs", ".", "append", "(", "x", ")", "\n", "\n", "", "", "if", "len", "(", "outs", ")", "==", "1", ":", "\n", "            ", "return", "outs", "[", "0", "]", "\n", "\n", "", "return", "tuple", "(", "outs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2._freeze_stages": [[281, 290], ["range", "mobilenet_v2.MobileNetV2.conv1.parameters", "getattr", "getattr.eval", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "for", "param", "in", "self", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "layer", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "layer", ".", "eval", "(", ")", "\n", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.MobileNetV2.train": [[291, 298], ["super().train", "mobilenet_v2.MobileNetV2._freeze_stages", "mobilenet_v2.MobileNetV2.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "MobileNetV2", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2.make_divisible": [[11, 34], ["max", "int"], "function", ["None"], ["def", "make_divisible", "(", "value", ",", "divisor", ",", "min_value", "=", "None", ",", "min_ratio", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"Make divisible function.\n\n    This function rounds the channel number down to the nearest value that can\n    be divisible by the divisor.\n    Args:\n        value (int): The original channel number.\n        divisor (int): The divisor to fully divide the channel number.\n        min_value (int, optional): The minimum value of the output channel.\n            Default: None, means that the minimum value equal to the divisor.\n        min_ratio (float, optional): The minimum ratio of the rounded channel\n            number to the original channel number. Default: 0.9.\n    Returns:\n        int: The modified output channel number\n    \"\"\"", "\n", "\n", "if", "min_value", "is", "None", ":", "\n", "        ", "min_value", "=", "divisor", "\n", "", "new_value", "=", "max", "(", "min_value", ",", "int", "(", "value", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than (1-min_ratio).", "\n", "if", "new_value", "<", "min_ratio", "*", "value", ":", "\n", "        ", "new_value", "+=", "divisor", "\n", "", "return", "new_value", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.CombineNet.__init__": [[76, 80], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "net1", ",", "net2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net1", "=", "net1", "\n", "self", ".", "net2", "=", "net2", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.CombineNet.forward": [[81, 96], ["resnet_tin.CombineNet.net1", "resnet_tin.CombineNet.net2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "# input shape: [num_batches * num_segments, C, H, W]", "\n", "# output x shape: [num_batches * num_segments, C, H, W]", "\n", "x", "=", "self", ".", "net1", "(", "x", ")", "\n", "# [num_batches * num_segments, C, H, W]", "\n", "x", "=", "self", ".", "net2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.WeightNet.__init__": [[112, 120], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Conv1d", "torch.Conv1d", "resnet_tin.WeightNet.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "groups", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "in_channels", ",", "groups", ",", "3", ",", "padding", "=", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.WeightNet.init_weights": [[121, 127], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "# we set the initial bias of the convolution", "\n", "# layer to 0, and the final initial output will be 1.0", "\n", "self", ".", "conv", ".", "bias", ".", "data", "[", "...", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.WeightNet.forward": [[128, 150], ["resnet_tin.WeightNet.conv", "x.permute.permute.view", "x.permute.permute.permute", "resnet_tin.WeightNet.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "# calculate weight", "\n", "# [N, C, T]", "\n", "n", ",", "_", ",", "t", "=", "x", ".", "shape", "\n", "# [N, groups, T]", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "n", ",", "self", ".", "groups", ",", "t", ")", "\n", "# [N, T, groups]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# scale the output to range (0, 2)", "\n", "x", "=", "2", "*", "self", ".", "sigmoid", "(", "x", ")", "\n", "# [N, T, groups]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.OffsetNet.__init__": [[167, 180], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "resnet_tin.OffsetNet.init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "groups", ",", "num_segments", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "# hard code ``kernel_size`` and ``padding`` according to original repo.", "\n", "kernel_size", "=", "3", "\n", "padding", "=", "1", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "in_channels", ",", "1", ",", "kernel_size", ",", "padding", "=", "padding", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "num_segments", ",", "num_segments", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "num_segments", ",", "groups", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.OffsetNet.init_weights": [[181, 187], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "# The bias of the last fc layer is initialized to", "\n", "# make the post-sigmoid output start from 1", "\n", "self", ".", "fc2", ".", "bias", ".", "data", "[", "...", "]", "=", "0.5108", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.OffsetNet.forward": [[188, 216], ["resnet_tin.OffsetNet.conv", "x.view.view.view", "resnet_tin.OffsetNet.relu", "resnet_tin.OffsetNet.fc2", "x.view.view.view", "resnet_tin.OffsetNet.fc1", "resnet_tin.OffsetNet.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "# calculate offset", "\n", "# [N, C, T]", "\n", "n", ",", "_", ",", "t", "=", "x", ".", "shape", "\n", "# [N, 1, T]", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "# [N, T]", "\n", "x", "=", "x", ".", "view", "(", "n", ",", "t", ")", "\n", "# [N, T]", "\n", "x", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "# [N, groups]", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "# [N, 1, groups]", "\n", "x", "=", "x", ".", "view", "(", "n", ",", "1", ",", "-", "1", ")", "\n", "\n", "# to make sure the output is in (-t/2, t/2)", "\n", "# where t = num_segments = 8", "\n", "x", "=", "4", "*", "(", "self", ".", "sigmoid", "(", "x", ")", "-", "0.5", ")", "\n", "# [N, 1, groups]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.TemporalInterlace.__init__": [[230, 242], ["torch.Module.__init__", "resnet_tin.OffsetNet", "resnet_tin.WeightNet"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "num_segments", "=", "3", ",", "shift_div", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "shift_div", "=", "shift_div", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "# hard code ``deform_groups`` according to original repo.", "\n", "self", ".", "deform_groups", "=", "2", "\n", "\n", "self", ".", "offset_net", "=", "OffsetNet", "(", "in_channels", "//", "shift_div", ",", "\n", "self", ".", "deform_groups", ",", "num_segments", ")", "\n", "self", ".", "weight_net", "=", "WeightNet", "(", "in_channels", "//", "shift_div", ",", "\n", "self", ".", "deform_groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.TemporalInterlace.forward": [[243, 305], ["x.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "x[].view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "x_pooled.permute().contiguous.permute().contiguous.permute().contiguous", "resnet_tin.TemporalInterlace.offset_net().view", "resnet_tin.TemporalInterlace.weight_net", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "resnet_tin.linear_sampler", "x_weight.view.view.repeat", "x_weight.view.view.view", "x_shift.contiguous().view.contiguous().view.contiguous().view", "x_weight.view.view.size", "x_weight.view.view.size", "x_pooled.permute().contiguous.permute().contiguous.permute", "resnet_tin.TemporalInterlace.offset_net", "x_shift.contiguous().view.contiguous().view.contiguous"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.linear_sampler"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "# x: [N, C, H, W],", "\n", "# where N = num_batches x num_segments, C = shift_div * num_folds", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "num_batches", "=", "n", "//", "self", ".", "num_segments", "\n", "num_folds", "=", "c", "//", "self", ".", "shift_div", "\n", "\n", "# x_out: [num_batches x num_segments, C, H, W]", "\n", "x_out", "=", "torch", ".", "zeros", "(", "(", "n", ",", "c", ",", "h", ",", "w", ")", ",", "device", "=", "x", ".", "device", ")", "\n", "# x_descriptor: [num_batches, num_segments, num_folds, H, W]", "\n", "x_descriptor", "=", "x", "[", ":", ",", ":", "num_folds", ",", ":", ",", ":", "]", ".", "view", "(", "num_batches", ",", "\n", "self", ".", "num_segments", ",", "\n", "num_folds", ",", "h", ",", "w", ")", "\n", "\n", "# x should only obtain information on temporal and channel dimensions", "\n", "# x_pooled: [num_batches, num_segments, num_folds, W]", "\n", "x_pooled", "=", "torch", ".", "mean", "(", "x_descriptor", ",", "3", ")", "\n", "# x_pooled: [num_batches, num_segments, num_folds]", "\n", "x_pooled", "=", "torch", ".", "mean", "(", "x_pooled", ",", "3", ")", "\n", "# x_pooled: [num_batches, num_folds, num_segments]", "\n", "x_pooled", "=", "x_pooled", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Calculate weight and bias, here groups = 2", "\n", "# x_offset: [num_batches, groups]", "\n", "x_offset", "=", "self", ".", "offset_net", "(", "x_pooled", ")", ".", "view", "(", "num_batches", ",", "-", "1", ")", "\n", "# x_weight: [num_batches, num_segments, groups]", "\n", "x_weight", "=", "self", ".", "weight_net", "(", "x_pooled", ")", "\n", "\n", "# x_offset: [num_batches, 2 * groups]", "\n", "x_offset", "=", "torch", ".", "cat", "(", "[", "x_offset", ",", "-", "x_offset", "]", ",", "1", ")", "\n", "# x_shift: [num_batches, num_segments, num_folds, H, W]", "\n", "x_shift", "=", "linear_sampler", "(", "x_descriptor", ",", "x_offset", ")", "\n", "\n", "# x_weight: [num_batches, num_segments, groups, 1]", "\n", "x_weight", "=", "x_weight", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "# x_weight:", "\n", "# [num_batches, num_segments, groups * 2, c // self.shift_div // 4]", "\n", "x_weight", "=", "x_weight", ".", "repeat", "(", "1", ",", "1", ",", "2", ",", "num_folds", "//", "2", "//", "2", ")", "\n", "# x_weight:", "\n", "# [num_batches, num_segments, c // self.shift_div = num_folds]", "\n", "x_weight", "=", "x_weight", ".", "view", "(", "x_weight", ".", "size", "(", "0", ")", ",", "x_weight", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "# x_weight: [num_batches, num_segments, num_folds, 1, 1]", "\n", "x_weight", "=", "x_weight", "[", ":", ",", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "# x_shift: [num_batches, num_segments, num_folds, H, W]", "\n", "x_shift", "=", "x_shift", "*", "x_weight", "\n", "# x_shift: [num_batches, num_segments, num_folds, H, W]", "\n", "x_shift", "=", "x_shift", ".", "contiguous", "(", ")", ".", "view", "(", "n", ",", "num_folds", ",", "h", ",", "w", ")", "\n", "\n", "# x_out: [num_batches x num_segments, C, H, W]", "\n", "x_out", "[", ":", ",", ":", "num_folds", ",", ":", "]", "=", "x_shift", "\n", "x_out", "[", ":", ",", "num_folds", ":", ",", ":", "]", "=", "x", "[", ":", ",", "num_folds", ":", ",", ":", "]", "\n", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.ResNetTIN.__init__": [[319, 329], ["resnet_tsm.ResNetTSM.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "num_segments", "=", "8", ",", "\n", "is_tin", "=", "True", ",", "\n", "shift_div", "=", "4", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "depth", ",", "**", "kwargs", ")", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "is_tin", "=", "is_tin", "\n", "self", ".", "shift_div", "=", "shift_div", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.ResNetTIN.make_temporal_interlace": [[330, 370], ["resnet_tin.ResNetTIN.make_temporal_interlace.make_block_interlace"], "methods", ["None"], ["", "def", "make_temporal_interlace", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make temporal interlace for some layers.\"\"\"", "\n", "num_segment_list", "=", "[", "self", ".", "num_segments", "]", "*", "4", "\n", "assert", "num_segment_list", "[", "-", "1", "]", ">", "0", "\n", "\n", "n_round", "=", "1", "\n", "if", "len", "(", "list", "(", "self", ".", "layer3", ".", "children", "(", ")", ")", ")", ">=", "23", ":", "\n", "            ", "print", "(", "f'=> Using n_round {n_round} to insert temporal shift.'", ")", "\n", "\n", "", "def", "make_block_interlace", "(", "stage", ",", "num_segments", ",", "shift_div", ")", ":", "\n", "            ", "\"\"\"Apply Deformable shift for a ResNet layer module.\n\n            Args:\n                stage (nn.module): A ResNet layer to be deformed.\n                num_segments (int): Number of frame segments.\n                shift_div (int): Number of division parts for shift.\n\n            Returns:\n                nn.Sequential: A Sequential container consisted of\n                    deformed Interlace blocks.\n            \"\"\"", "\n", "blocks", "=", "list", "(", "stage", ".", "children", "(", ")", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "blocks", ")", ":", "\n", "                ", "if", "i", "%", "n_round", "==", "0", ":", "\n", "                    ", "tds", "=", "TemporalInterlace", "(", "\n", "b", ".", "conv1", ".", "in_channels", ",", "\n", "num_segments", "=", "num_segments", ",", "\n", "shift_div", "=", "shift_div", ")", "\n", "blocks", "[", "i", "]", ".", "conv1", ".", "conv", "=", "CombineNet", "(", "tds", ",", "\n", "blocks", "[", "i", "]", ".", "conv1", ".", "conv", ")", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "", "self", ".", "layer1", "=", "make_block_interlace", "(", "self", ".", "layer1", ",", "num_segment_list", "[", "0", "]", ",", "\n", "self", ".", "shift_div", ")", "\n", "self", ".", "layer2", "=", "make_block_interlace", "(", "self", ".", "layer2", ",", "num_segment_list", "[", "1", "]", ",", "\n", "self", ".", "shift_div", ")", "\n", "self", ".", "layer3", "=", "make_block_interlace", "(", "self", ".", "layer3", ",", "num_segment_list", "[", "2", "]", ",", "\n", "self", ".", "shift_div", ")", "\n", "self", ".", "layer4", "=", "make_block_interlace", "(", "self", ".", "layer4", ",", "num_segment_list", "[", "3", "]", ",", "\n", "self", ".", "shift_div", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.ResNetTIN.init_weights": [[371, 379], ["super().init_weights", "resnet_tin.ResNetTIN.make_temporal_interlace", "len", "resnet_tin.ResNetTIN.make_non_local"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.ResNetTIN.make_temporal_interlace", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.make_non_local"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "super", "(", "ResNetTSM", ",", "self", ")", ".", "init_weights", "(", ")", "\n", "if", "self", ".", "is_tin", ":", "\n", "            ", "self", ".", "make_temporal_interlace", "(", ")", "\n", "", "if", "len", "(", "self", ".", "non_local_cfg", ")", "!=", "0", ":", "\n", "            ", "self", ".", "make_non_local", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tin.linear_sampler": [[17, 64], ["torch.floor().int", "torch.floor().int", "data.view().contiguous.view().contiguous", "tin_shift", "tin_shift", "weight0[].repeat", "weight0.view.view", "weight1[].repeat", "weight1.view.view", "output.view.view", "weight0.view.size", "weight1.view.size", "torch.floor", "torch.floor", "data.view().contiguous.view", "torch.floor().int.float"], "function", ["None"], ["", "", "def", "linear_sampler", "(", "data", ",", "offset", ")", ":", "\n", "    ", "\"\"\"Differentiable Temporal-wise Frame Sampling, which is essentially a\n    linear interpolation process.\n\n    It gets the feature map which has been split into several groups\n    and shift them by different offsets according to their groups.\n    Then compute the weighted sum along with the temporal dimension.\n\n    Args:\n        data (torch.Tensor): Split data for certain group in shape\n            [N, num_segments, C, H, W].\n        offset (torch.Tensor): Data offsets for this group data in shape\n            [N, num_segments].\n    \"\"\"", "\n", "# [N, num_segments, C, H, W]", "\n", "n", ",", "t", ",", "c", ",", "h", ",", "w", "=", "data", ".", "shape", "\n", "\n", "# offset0, offset1: [N, num_segments]", "\n", "offset0", "=", "torch", ".", "floor", "(", "offset", ")", ".", "int", "(", ")", "\n", "offset1", "=", "offset0", "+", "1", "\n", "\n", "# data, data0, data1: [N, num_segments, C, H * W]", "\n", "data", "=", "data", ".", "view", "(", "n", ",", "t", ",", "c", ",", "h", "*", "w", ")", ".", "contiguous", "(", ")", "\n", "data0", "=", "tin_shift", "(", "data", ",", "offset0", ")", "\n", "data1", "=", "tin_shift", "(", "data", ",", "offset1", ")", "\n", "\n", "# weight0, weight1: [N, num_segments]", "\n", "weight0", "=", "1", "-", "(", "offset", "-", "offset0", ".", "float", "(", ")", ")", "\n", "weight1", "=", "1", "-", "weight0", "\n", "\n", "# weight0, weight1:", "\n", "# [N, num_segments] -> [N, num_segments, C // num_segments] -> [N, C]", "\n", "group_size", "=", "offset", ".", "shape", "[", "1", "]", "\n", "weight0", "=", "weight0", "[", ":", ",", ":", ",", "None", "]", ".", "repeat", "(", "1", ",", "1", ",", "c", "//", "group_size", ")", "\n", "weight0", "=", "weight0", ".", "view", "(", "weight0", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "weight1", "=", "weight1", "[", ":", ",", ":", ",", "None", "]", ".", "repeat", "(", "1", ",", "1", ",", "c", "//", "group_size", ")", "\n", "weight1", "=", "weight1", ".", "view", "(", "weight1", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "# weight0, weight1: [N, C] -> [N, 1, C, 1]", "\n", "weight0", "=", "weight0", "[", ":", ",", "None", ",", ":", ",", "None", "]", "\n", "weight1", "=", "weight1", "[", ":", ",", "None", ",", ":", ",", "None", "]", "\n", "\n", "# output: [N, num_segments, C, H * W] -> [N, num_segments, C, H, W]", "\n", "output", "=", "weight0", "*", "data0", "+", "weight1", "*", "data1", "\n", "output", "=", "output", ".", "view", "(", "n", ",", "t", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.NL3DWrapper.__init__": [[21, 28], ["dict", "torch.Module.__init__", "mmcv.cnn.NonLocal3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "block", ",", "num_segments", ",", "non_local_cfg", "=", "dict", "(", ")", ")", ":", "\n", "        ", "super", "(", "NL3DWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "block", "=", "block", "\n", "self", ".", "non_local_cfg", "=", "non_local_cfg", "\n", "self", ".", "non_local_block", "=", "NonLocal3d", "(", "self", ".", "block", ".", "conv3", ".", "norm", ".", "num_features", ",", "\n", "**", "self", ".", "non_local_cfg", ")", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.NL3DWrapper.forward": [[29, 38], ["resnet_tsm.NL3DWrapper.block", "x.transpose().contiguous().view.transpose().contiguous().view.size", "x.transpose().contiguous().view.transpose().contiguous().view.view().transpose().contiguous", "resnet_tsm.NL3DWrapper.non_local_block", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "x.transpose().contiguous().view.transpose().contiguous().view.view().transpose", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "x.transpose().contiguous().view.transpose().contiguous().view.view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "block", "(", "x", ")", "\n", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "n", "//", "self", ".", "num_segments", ",", "self", ".", "num_segments", ",", "c", ",", "h", ",", "\n", "w", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "non_local_block", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "n", ",", "c", ",", "h", ",", "w", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.TemporalShift.__init__": [[53, 58], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "num_segments", "=", "3", ",", "shift_div", "=", "8", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "shift_div", "=", "shift_div", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.TemporalShift.forward": [[59, 70], ["resnet_tsm.TemporalShift.shift", "resnet_tsm.TemporalShift.net"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.TemporalShift.shift"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "x", "=", "self", ".", "shift", "(", "x", ",", "self", ".", "num_segments", ",", "shift_div", "=", "self", ".", "shift_div", ")", "\n", "return", "self", ".", "net", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.TemporalShift.shift": [[71, 122], ["x.view.view.size", "x.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.view", "torch.cat.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "shift", "(", "x", ",", "num_segments", ",", "shift_div", "=", "3", ")", ":", "\n", "        ", "\"\"\"Perform temporal shift operation on the feature.\n\n        Args:\n            x (torch.Tensor): The input feature to be shifted.\n            num_segments (int): Number of frame segments.\n            shift_div (int): Number of divisions for shift. Default: 3.\n\n        Returns:\n            torch.Tensor: The shifted feature.\n        \"\"\"", "\n", "# [N, C, H, W]", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "\n", "# [N // num_segments, num_segments, C, H*W]", "\n", "# can't use 5 dimensional array on PPL2D backend for caffe", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "num_segments", ",", "c", ",", "h", "*", "w", ")", "\n", "\n", "# get shift fold", "\n", "fold", "=", "c", "//", "shift_div", "\n", "\n", "# split c channel into three parts:", "\n", "# left_split, mid_split, right_split", "\n", "left_split", "=", "x", "[", ":", ",", ":", ",", ":", "fold", ",", ":", "]", "\n", "mid_split", "=", "x", "[", ":", ",", ":", ",", "fold", ":", "2", "*", "fold", ",", ":", "]", "\n", "right_split", "=", "x", "[", ":", ",", ":", ",", "2", "*", "fold", ":", ",", ":", "]", "\n", "\n", "# can't use torch.zeros(*A.shape) or torch.zeros_like(A)", "\n", "# because array on caffe inference must be got by computing", "\n", "\n", "# shift left on num_segments channel in `left_split`", "\n", "zeros", "=", "left_split", "-", "left_split", "\n", "blank", "=", "zeros", "[", ":", ",", ":", "1", ",", ":", ",", ":", "]", "\n", "left_split", "=", "left_split", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "left_split", "=", "torch", ".", "cat", "(", "(", "left_split", ",", "blank", ")", ",", "1", ")", "\n", "\n", "# shift right on num_segments channel in `mid_split`", "\n", "zeros", "=", "mid_split", "-", "mid_split", "\n", "blank", "=", "zeros", "[", ":", ",", ":", "1", ",", ":", ",", ":", "]", "\n", "mid_split", "=", "mid_split", "[", ":", ",", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "mid_split", "=", "torch", ".", "cat", "(", "(", "blank", ",", "mid_split", ")", ",", "1", ")", "\n", "\n", "# right_split: no shift", "\n", "\n", "# concatenate", "\n", "out", "=", "torch", ".", "cat", "(", "(", "left_split", ",", "mid_split", ",", "right_split", ")", ",", "2", ")", "\n", "\n", "# [N, C, H, W]", "\n", "# restore the original dimension", "\n", "return", "out", ".", "view", "(", "n", ",", "c", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.__init__": [[147, 166], ["dict", "resnet.ResNet.__init__", "torch.nn.modules.utils._ntuple", "torch.nn.modules.utils._ntuple"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "num_segments", "=", "8", ",", "\n", "is_shift", "=", "True", ",", "\n", "non_local", "=", "(", "0", ",", "0", ",", "0", ",", "0", ")", ",", "\n", "non_local_cfg", "=", "dict", "(", ")", ",", "\n", "shift_div", "=", "8", ",", "\n", "shift_place", "=", "'blockres'", ",", "\n", "temporal_pool", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "depth", ",", "**", "kwargs", ")", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "is_shift", "=", "is_shift", "\n", "self", ".", "shift_div", "=", "shift_div", "\n", "self", ".", "shift_place", "=", "shift_place", "\n", "self", ".", "temporal_pool", "=", "temporal_pool", "\n", "self", ".", "non_local", "=", "non_local", "\n", "self", ".", "non_local_stages", "=", "_ntuple", "(", "self", ".", "num_stages", ")", "(", "non_local", ")", "\n", "self", ".", "non_local_cfg", "=", "non_local_cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.make_temporal_shift": [[167, 233], ["ValueError", "resnet_tsm.ResNetTSM.make_temporal_shift.make_block_temporal"], "methods", ["None"], ["", "def", "make_temporal_shift", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make temporal shift for some layers.\"\"\"", "\n", "if", "self", ".", "temporal_pool", ":", "\n", "            ", "num_segment_list", "=", "[", "\n", "self", ".", "num_segments", ",", "self", ".", "num_segments", "//", "2", ",", "\n", "self", ".", "num_segments", "//", "2", ",", "self", ".", "num_segments", "//", "2", "\n", "]", "\n", "", "else", ":", "\n", "            ", "num_segment_list", "=", "[", "self", ".", "num_segments", "]", "*", "4", "\n", "", "if", "num_segment_list", "[", "-", "1", "]", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'num_segment_list[-1] must be positive'", ")", "\n", "\n", "", "if", "self", ".", "shift_place", "==", "'block'", ":", "\n", "\n", "            ", "def", "make_block_temporal", "(", "stage", ",", "num_segments", ")", ":", "\n", "                ", "\"\"\"Make temporal shift on some blocks.\n\n                Args:\n                    stage (nn.Module): Model layers to be shifted.\n                    num_segments (int): Number of frame segments.\n\n                Returns:\n                    nn.Module: The shifted blocks.\n                \"\"\"", "\n", "blocks", "=", "list", "(", "stage", ".", "children", "(", ")", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "blocks", ")", ":", "\n", "                    ", "blocks", "[", "i", "]", "=", "TemporalShift", "(", "\n", "b", ",", "num_segments", "=", "num_segments", ",", "shift_div", "=", "self", ".", "shift_div", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "", "self", ".", "layer1", "=", "make_block_temporal", "(", "self", ".", "layer1", ",", "num_segment_list", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "make_block_temporal", "(", "self", ".", "layer2", ",", "num_segment_list", "[", "1", "]", ")", "\n", "self", ".", "layer3", "=", "make_block_temporal", "(", "self", ".", "layer3", ",", "num_segment_list", "[", "2", "]", ")", "\n", "self", ".", "layer4", "=", "make_block_temporal", "(", "self", ".", "layer4", ",", "num_segment_list", "[", "3", "]", ")", "\n", "\n", "", "elif", "'blockres'", "in", "self", ".", "shift_place", ":", "\n", "            ", "n_round", "=", "1", "\n", "if", "len", "(", "list", "(", "self", ".", "layer3", ".", "children", "(", ")", ")", ")", ">=", "23", ":", "\n", "                ", "n_round", "=", "2", "\n", "\n", "", "def", "make_block_temporal", "(", "stage", ",", "num_segments", ")", ":", "\n", "                ", "\"\"\"Make temporal shift on some blocks.\n\n                Args:\n                    stage (nn.Module): Model layers to be shifted.\n                    num_segments (int): Number of frame segments.\n\n                Returns:\n                    nn.Module: The shifted blocks.\n                \"\"\"", "\n", "blocks", "=", "list", "(", "stage", ".", "children", "(", ")", ")", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "blocks", ")", ":", "\n", "                    ", "if", "i", "%", "n_round", "==", "0", ":", "\n", "                        ", "blocks", "[", "i", "]", ".", "conv1", ".", "conv", "=", "TemporalShift", "(", "\n", "b", ".", "conv1", ".", "conv", ",", "\n", "num_segments", "=", "num_segments", ",", "\n", "shift_div", "=", "self", ".", "shift_div", ")", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "blocks", ")", "\n", "\n", "", "self", ".", "layer1", "=", "make_block_temporal", "(", "self", ".", "layer1", ",", "num_segment_list", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "make_block_temporal", "(", "self", ".", "layer2", ",", "num_segment_list", "[", "1", "]", ")", "\n", "self", ".", "layer3", "=", "make_block_temporal", "(", "self", ".", "layer3", ",", "num_segment_list", "[", "2", "]", ")", "\n", "self", ".", "layer4", "=", "make_block_temporal", "(", "self", ".", "layer4", ",", "num_segment_list", "[", "3", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.make_temporal_pool": [[234, 268], ["TemporalPool", "resnet.ResNet.__init__", "torch.MaxPool3d", "torch.MaxPool3d", "x.transpose().contiguous().view.transpose().contiguous().view.size", "x.transpose().contiguous().view.transpose().contiguous().view.view().transpose", "resnet_tsm.ResNetTSM.max_pool3d", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "resnet_tsm.ResNetTSM.net", "x.transpose().contiguous().view.transpose().contiguous().view.view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "x.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["", "", "def", "make_temporal_pool", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make temporal pooling between layer1 and layer2, using a 3D max\n        pooling layer.\"\"\"", "\n", "\n", "class", "TemporalPool", "(", "nn", ".", "Module", ")", ":", "\n", "            ", "\"\"\"Temporal pool module.\n\n            Wrap layer2 in ResNet50 with a 3D max pooling layer.\n\n            Args:\n                net (nn.Module): Module to make temporal pool.\n                num_segments (int): Number of frame segments.\n            \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "net", ",", "num_segments", ")", ":", "\n", "                ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "max_pool3d", "=", "nn", ".", "MaxPool3d", "(", "\n", "kernel_size", "=", "(", "3", ",", "1", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# [N, C, H, W]", "\n", "                ", "n", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "# [N // num_segments, C, num_segments, H, W]", "\n", "x", "=", "x", ".", "view", "(", "n", "//", "self", ".", "num_segments", ",", "self", ".", "num_segments", ",", "c", ",", "h", ",", "\n", "w", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# [N // num_segmnets, C, num_segments // 2, H, W]", "\n", "x", "=", "self", ".", "max_pool3d", "(", "x", ")", "\n", "# [N // 2, C, H, W]", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "n", "//", "2", ",", "c", ",", "h", ",", "w", ")", "\n", "return", "self", ".", "net", "(", "x", ")", "\n", "\n", "", "", "self", ".", "layer2", "=", "TemporalPool", "(", "self", ".", "layer2", ",", "self", ".", "num_segments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.make_non_local": [[269, 284], ["range", "getattr", "enumerate", "sum", "resnet_tsm.NL3DWrapper"], "methods", ["None"], ["", "def", "make_non_local", "(", "self", ")", ":", "\n", "# This part is for ResNet50", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "non_local_stage", "=", "self", ".", "non_local_stages", "[", "i", "]", "\n", "if", "sum", "(", "non_local_stage", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "layer_name", "=", "f'layer{i + 1}'", "\n", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "\n", "for", "idx", ",", "non_local", "in", "enumerate", "(", "non_local_stage", ")", ":", "\n", "                ", "if", "non_local", ":", "\n", "                    ", "res_layer", "[", "idx", "]", "=", "NL3DWrapper", "(", "res_layer", "[", "idx", "]", ",", "\n", "self", ".", "num_segments", ",", "\n", "self", ".", "non_local_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.init_weights": [[285, 295], ["super().init_weights", "resnet_tsm.ResNetTSM.make_temporal_shift", "len", "resnet_tsm.ResNetTSM.make_non_local", "resnet_tsm.ResNetTSM.make_temporal_pool"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2_tsm.MobileNetV2TSM.make_temporal_shift", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.make_non_local", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_tsm.ResNetTSM.make_temporal_pool"], ["", "", "", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "super", "(", ")", ".", "init_weights", "(", ")", "\n", "if", "self", ".", "is_shift", ":", "\n", "            ", "self", ".", "make_temporal_shift", "(", ")", "\n", "", "if", "len", "(", "self", ".", "non_local_cfg", ")", "!=", "0", ":", "\n", "            ", "self", ".", "make_non_local", "(", ")", "\n", "", "if", "self", ".", "temporal_pool", ":", "\n", "            ", "self", ".", "make_temporal_pool", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.BasicBlock3d.__init__": [[48, 130], ["dict", "dict", "dict", "dict", "torch.Module.__init__", "set().issubset", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.build_activation_layer", "mmcv.cnn.NonLocal3d", "set"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "temporal_stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "inflate", "=", "True", ",", "\n", "non_local", "=", "False", ",", "\n", "non_local_cfg", "=", "dict", "(", ")", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "with_cp", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "style", "in", "[", "'pytorch'", ",", "'caffe'", "]", "\n", "# make sure that only ``inflate_style`` is passed into kwargs", "\n", "assert", "set", "(", "kwargs", ")", ".", "issubset", "(", "[", "'inflate_style'", "]", ")", "\n", "\n", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "planes", "=", "planes", "\n", "self", ".", "spatial_stride", "=", "spatial_stride", "\n", "self", ".", "temporal_stride", "=", "temporal_stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "inflate", "=", "inflate", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "non_local", "=", "non_local", "\n", "self", ".", "non_local_cfg", "=", "non_local_cfg", "\n", "\n", "self", ".", "conv1_stride_s", "=", "spatial_stride", "\n", "self", ".", "conv2_stride_s", "=", "1", "\n", "self", ".", "conv1_stride_t", "=", "temporal_stride", "\n", "self", ".", "conv2_stride_t", "=", "1", "\n", "\n", "if", "self", ".", "inflate", ":", "\n", "            ", "conv1_kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", "\n", "conv1_padding", "=", "(", "1", ",", "dilation", ",", "dilation", ")", "\n", "conv2_kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", "\n", "conv2_padding", "=", "(", "1", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "conv1_kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", "\n", "conv1_padding", "=", "(", "0", ",", "dilation", ",", "dilation", ")", "\n", "conv2_kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", "\n", "conv2_padding", "=", "(", "0", ",", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "conv1_kernel_size", ",", "\n", "stride", "=", "(", "self", ".", "conv1_stride_t", ",", "self", ".", "conv1_stride_s", ",", "\n", "self", ".", "conv1_stride_s", ")", ",", "\n", "padding", "=", "conv1_padding", ",", "\n", "dilation", "=", "(", "1", ",", "dilation", ",", "dilation", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "planes", ",", "\n", "planes", "*", "self", ".", "expansion", ",", "\n", "conv2_kernel_size", ",", "\n", "stride", "=", "(", "self", ".", "conv2_stride_t", ",", "self", ".", "conv2_stride_s", ",", "\n", "self", ".", "conv2_stride_s", ")", ",", "\n", "padding", "=", "conv2_padding", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "relu", "=", "build_activation_layer", "(", "self", ".", "act_cfg", ")", "\n", "\n", "if", "self", ".", "non_local", ":", "\n", "            ", "self", ".", "non_local_block", "=", "NonLocal3d", "(", "self", ".", "conv2", ".", "norm", ".", "num_features", ",", "\n", "**", "self", ".", "non_local_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.BasicBlock3d.forward": [[131, 157], ["resnet3d.BasicBlock3d.relu", "resnet3d.BasicBlock3d.conv1", "resnet3d.BasicBlock3d.conv2", "torch.checkpoint", "torch.checkpoint", "resnet3d.BasicBlock3d.forward._inner_forward"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\"\"\"", "\n", "\n", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "\"\"\"Forward wrapper for utilizing checkpoint.\"\"\"", "\n", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "out", "+", "identity", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "if", "self", ".", "non_local", ":", "\n", "            ", "out", "=", "self", ".", "non_local_block", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.Bottleneck3d.__init__": [[190, 294], ["dict", "dict", "dict", "dict", "torch.Module.__init__", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.build_activation_layer", "mmcv.cnn.NonLocal3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "temporal_stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "inflate", "=", "True", ",", "\n", "inflate_style", "=", "'3x1x1'", ",", "\n", "non_local", "=", "False", ",", "\n", "non_local_cfg", "=", "dict", "(", ")", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "style", "in", "[", "'pytorch'", ",", "'caffe'", "]", "\n", "assert", "inflate_style", "in", "[", "'3x1x1'", ",", "'3x3x3'", "]", "\n", "\n", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "planes", "=", "planes", "\n", "self", ".", "spatial_stride", "=", "spatial_stride", "\n", "self", ".", "temporal_stride", "=", "temporal_stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "inflate", "=", "inflate", "\n", "self", ".", "inflate_style", "=", "inflate_style", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "non_local", "=", "non_local", "\n", "self", ".", "non_local_cfg", "=", "non_local_cfg", "\n", "\n", "if", "self", ".", "style", "==", "'pytorch'", ":", "\n", "            ", "self", ".", "conv1_stride_s", "=", "1", "\n", "self", ".", "conv2_stride_s", "=", "spatial_stride", "\n", "self", ".", "conv1_stride_t", "=", "1", "\n", "self", ".", "conv2_stride_t", "=", "temporal_stride", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1_stride_s", "=", "spatial_stride", "\n", "self", ".", "conv2_stride_s", "=", "1", "\n", "self", ".", "conv1_stride_t", "=", "temporal_stride", "\n", "self", ".", "conv2_stride_t", "=", "1", "\n", "\n", "", "if", "self", ".", "inflate", ":", "\n", "            ", "if", "inflate_style", "==", "'3x1x1'", ":", "\n", "                ", "conv1_kernel_size", "=", "(", "3", ",", "1", ",", "1", ")", "\n", "conv1_padding", "=", "(", "1", ",", "0", ",", "0", ")", "\n", "conv2_kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", "\n", "conv2_padding", "=", "(", "0", ",", "dilation", ",", "dilation", ")", "\n", "", "else", ":", "\n", "                ", "conv1_kernel_size", "=", "(", "1", ",", "1", ",", "1", ")", "\n", "conv1_padding", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "conv2_kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", "\n", "conv2_padding", "=", "(", "1", ",", "dilation", ",", "dilation", ")", "\n", "", "", "else", ":", "\n", "            ", "conv1_kernel_size", "=", "(", "1", ",", "1", ",", "1", ")", "\n", "conv1_padding", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "conv2_kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", "\n", "conv2_padding", "=", "(", "0", ",", "dilation", ",", "dilation", ")", "\n", "\n", "", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "conv1_kernel_size", ",", "\n", "stride", "=", "(", "self", ".", "conv1_stride_t", ",", "self", ".", "conv1_stride_s", ",", "\n", "self", ".", "conv1_stride_s", ")", ",", "\n", "padding", "=", "conv1_padding", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "planes", ",", "\n", "planes", ",", "\n", "conv2_kernel_size", ",", "\n", "stride", "=", "(", "self", ".", "conv2_stride_t", ",", "self", ".", "conv2_stride_s", ",", "\n", "self", ".", "conv2_stride_s", ")", ",", "\n", "padding", "=", "conv2_padding", ",", "\n", "dilation", "=", "(", "1", ",", "dilation", ",", "dilation", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n", "self", ".", "conv3", "=", "ConvModule", "(", "\n", "planes", ",", "\n", "planes", "*", "self", ".", "expansion", ",", "\n", "1", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "# No activation in the third ConvModule for bottleneck", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "relu", "=", "build_activation_layer", "(", "self", ".", "act_cfg", ")", "\n", "\n", "if", "self", ".", "non_local", ":", "\n", "            ", "self", ".", "non_local_block", "=", "NonLocal3d", "(", "self", ".", "conv3", ".", "norm", ".", "num_features", ",", "\n", "**", "self", ".", "non_local_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.Bottleneck3d.forward": [[295, 322], ["resnet3d.Bottleneck3d.relu", "resnet3d.Bottleneck3d.conv1", "resnet3d.Bottleneck3d.conv2", "resnet3d.Bottleneck3d.conv3", "torch.checkpoint", "torch.checkpoint", "resnet3d.Bottleneck3d.forward._inner_forward"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\"\"\"", "\n", "\n", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "\"\"\"Forward wrapper for utilizing checkpoint.\"\"\"", "\n", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "=", "out", "+", "identity", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "if", "self", ".", "non_local", ":", "\n", "            ", "out", "=", "self", ".", "non_local_block", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d.__init__": [[396, 508], ["dict", "dict", "dict", "dict", "torch.Module.__init__", "resnet3d.ResNet3d._make_stem_layer", "enumerate", "KeyError", "max", "len", "len", "len", "torch.nn.modules.utils._ntuple", "torch.nn.modules.utils._ntuple", "torch.nn.modules.utils._ntuple", "torch.nn.modules.utils._ntuple", "resnet3d.ResNet3d.make_res_layer", "resnet3d.ResNet3d.add_module", "resnet3d.ResNet3d.res_layers.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._make_stem_layer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.make_res_layer"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "pretrained", ",", "\n", "stage_blocks", "=", "None", ",", "\n", "pretrained2d", "=", "True", ",", "\n", "in_channels", "=", "3", ",", "\n", "num_stages", "=", "4", ",", "\n", "base_channels", "=", "64", ",", "\n", "out_indices", "=", "(", "3", ",", ")", ",", "\n", "spatial_strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "temporal_strides", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "conv1_kernel", "=", "(", "3", ",", "7", ",", "7", ")", ",", "\n", "conv1_stride_s", "=", "2", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_s", "=", "2", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "with_pool2", "=", "True", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "inflate", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "inflate_style", "=", "'3x1x1'", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ",", "\n", "norm_eval", "=", "False", ",", "\n", "with_cp", "=", "False", ",", "\n", "non_local", "=", "(", "0", ",", "0", ",", "0", ",", "0", ")", ",", "\n", "non_local_cfg", "=", "dict", "(", ")", ",", "\n", "zero_init_residual", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "depth", "not", "in", "self", ".", "arch_settings", ":", "\n", "            ", "raise", "KeyError", "(", "f'invalid depth {depth} for resnet'", ")", "\n", "", "self", ".", "depth", "=", "depth", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "pretrained2d", "=", "pretrained2d", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "base_channels", "=", "base_channels", "\n", "self", ".", "num_stages", "=", "num_stages", "\n", "assert", "1", "<=", "num_stages", "<=", "4", "\n", "self", ".", "stage_blocks", "=", "stage_blocks", "\n", "self", ".", "out_indices", "=", "out_indices", "\n", "assert", "max", "(", "out_indices", ")", "<", "num_stages", "\n", "self", ".", "spatial_strides", "=", "spatial_strides", "\n", "self", ".", "temporal_strides", "=", "temporal_strides", "\n", "self", ".", "dilations", "=", "dilations", "\n", "assert", "len", "(", "spatial_strides", ")", "==", "len", "(", "temporal_strides", ")", "==", "len", "(", "\n", "dilations", ")", "==", "num_stages", "\n", "if", "self", ".", "stage_blocks", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "self", ".", "stage_blocks", ")", "==", "num_stages", "\n", "\n", "", "self", ".", "conv1_kernel", "=", "conv1_kernel", "\n", "self", ".", "conv1_stride_s", "=", "conv1_stride_s", "\n", "self", ".", "conv1_stride_t", "=", "conv1_stride_t", "\n", "self", ".", "pool1_stride_s", "=", "pool1_stride_s", "\n", "self", ".", "pool1_stride_t", "=", "pool1_stride_t", "\n", "self", ".", "with_pool2", "=", "with_pool2", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "self", ".", "stage_inflations", "=", "_ntuple", "(", "num_stages", ")", "(", "inflate", ")", "\n", "self", ".", "non_local_stages", "=", "_ntuple", "(", "num_stages", ")", "(", "non_local", ")", "\n", "self", ".", "inflate_style", "=", "inflate_style", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "norm_eval", "=", "norm_eval", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "zero_init_residual", "=", "zero_init_residual", "\n", "\n", "self", ".", "block", ",", "stage_blocks", "=", "self", ".", "arch_settings", "[", "depth", "]", "\n", "\n", "if", "self", ".", "stage_blocks", "is", "None", ":", "\n", "            ", "self", ".", "stage_blocks", "=", "stage_blocks", "[", ":", "num_stages", "]", "\n", "\n", "", "self", ".", "inplanes", "=", "self", ".", "base_channels", "\n", "\n", "self", ".", "non_local_cfg", "=", "non_local_cfg", "\n", "\n", "self", ".", "_make_stem_layer", "(", ")", "\n", "\n", "self", ".", "res_layers", "=", "[", "]", "\n", "for", "i", ",", "num_blocks", "in", "enumerate", "(", "self", ".", "stage_blocks", ")", ":", "\n", "            ", "spatial_stride", "=", "spatial_strides", "[", "i", "]", "\n", "temporal_stride", "=", "temporal_strides", "[", "i", "]", "\n", "dilation", "=", "dilations", "[", "i", "]", "\n", "planes", "=", "self", ".", "base_channels", "*", "2", "**", "i", "\n", "res_layer", "=", "self", ".", "make_res_layer", "(", "\n", "self", ".", "block", ",", "\n", "self", ".", "inplanes", ",", "\n", "planes", ",", "\n", "num_blocks", ",", "\n", "spatial_stride", "=", "spatial_stride", ",", "\n", "temporal_stride", "=", "temporal_stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "style", "=", "self", ".", "style", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ",", "\n", "non_local", "=", "self", ".", "non_local_stages", "[", "i", "]", ",", "\n", "non_local_cfg", "=", "self", ".", "non_local_cfg", ",", "\n", "inflate", "=", "self", ".", "stage_inflations", "[", "i", "]", ",", "\n", "inflate_style", "=", "self", ".", "inflate_style", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "self", ".", "block", ".", "expansion", "\n", "layer_name", "=", "f'layer{i + 1}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "res_layer", ")", "\n", "self", ".", "res_layers", ".", "append", "(", "layer_name", ")", "\n", "\n", "", "self", ".", "feat_dim", "=", "self", ".", "block", ".", "expansion", "*", "self", ".", "base_channels", "*", "2", "**", "(", "\n", "len", "(", "self", ".", "stage_blocks", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d.make_res_layer": [[509, 622], ["dict", "layers.append", "range", "torch.Sequential", "torch.Sequential", "mmcv.cnn.ConvModule", "block", "layers.append", "isinstance", "isinstance", "len", "len", "block"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_res_layer", "(", "block", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "blocks", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "temporal_stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "inflate", "=", "1", ",", "\n", "inflate_style", "=", "'3x1x1'", ",", "\n", "non_local", "=", "0", ",", "\n", "non_local_cfg", "=", "dict", "(", ")", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "with_cp", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Build residual layer for ResNet3D.\n\n        Args:\n            block (nn.Module): Residual module to be built.\n            inplanes (int): Number of channels for the input feature\n                in each block.\n            planes (int): Number of channels for the output feature\n                in each block.\n            blocks (int): Number of residual blocks.\n            spatial_stride (int | Sequence[int]): Spatial strides in\n                residual and conv layers. Default: 1.\n            temporal_stride (int | Sequence[int]): Temporal strides in\n                residual and conv layers. Default: 1.\n            dilation (int): Spacing between kernel elements. Default: 1.\n            style (str): ``pytorch`` or ``caffe``. If set to ``pytorch``,\n                the stride-two layer is the 3x3 conv layer, otherwise\n                the stride-two layer is the first 1x1 conv layer.\n                Default: ``pytorch``.\n            inflate (int | Sequence[int]): Determine whether to inflate\n                for each block. Default: 1.\n            inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines\n                the kernel sizes and padding strides for conv1 and conv2\n                in each block. Default: '3x1x1'.\n            non_local (int | Sequence[int]): Determine whether to apply\n                non-local module in the corresponding block of each stages.\n                Default: 0.\n            non_local_cfg (dict): Config for non-local module.\n                Default: ``dict()``.\n            conv_cfg (dict | None): Config for norm layers. Default: None.\n            norm_cfg (dict | None): Config for norm layers. Default: None.\n            act_cfg (dict | None): Config for activate layers. Default: None.\n            with_cp (bool | None): Use checkpoint or not. Using checkpoint\n                will save some memory while slowing down the training speed.\n                Default: False.\n\n        Returns:\n            nn.Module: A residual layer for the given config.\n        \"\"\"", "\n", "inflate", "=", "inflate", "if", "not", "isinstance", "(", "inflate", ",", "\n", "int", ")", "else", "(", "inflate", ",", ")", "*", "blocks", "\n", "non_local", "=", "non_local", "if", "not", "isinstance", "(", "\n", "non_local", ",", "int", ")", "else", "(", "non_local", ",", ")", "*", "blocks", "\n", "assert", "len", "(", "inflate", ")", "==", "blocks", "and", "len", "(", "non_local", ")", "==", "blocks", "\n", "downsample", "=", "None", "\n", "if", "spatial_stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "ConvModule", "(", "\n", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "(", "temporal_stride", ",", "spatial_stride", ",", "spatial_stride", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "spatial_stride", "=", "spatial_stride", ",", "\n", "temporal_stride", "=", "temporal_stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "downsample", "=", "downsample", ",", "\n", "style", "=", "style", ",", "\n", "inflate", "=", "(", "inflate", "[", "0", "]", "==", "1", ")", ",", "\n", "inflate_style", "=", "inflate_style", ",", "\n", "non_local", "=", "(", "non_local", "[", "0", "]", "==", "1", ")", ",", "\n", "non_local_cfg", "=", "non_local_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", ")", "\n", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "temporal_stride", "=", "1", ",", "\n", "dilation", "=", "dilation", ",", "\n", "style", "=", "style", ",", "\n", "inflate", "=", "(", "inflate", "[", "i", "]", "==", "1", ")", ",", "\n", "inflate_style", "=", "inflate_style", ",", "\n", "non_local", "=", "(", "non_local", "[", "i", "]", "==", "1", ")", ",", "\n", "non_local_cfg", "=", "non_local_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_conv_params": [[623, 650], ["conv3d.weight.data.copy_", "inflated_param_names.append", "conv2d_weight.data.unsqueeze().expand_as", "getattr", "conv3d.bias.data.copy_", "inflated_param_names.append", "conv2d_weight.data.unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_inflate_conv_params", "(", "conv3d", ",", "state_dict_2d", ",", "module_name_2d", ",", "\n", "inflated_param_names", ")", ":", "\n", "        ", "\"\"\"Inflate a conv module from 2d to 3d.\n\n        Args:\n            conv3d (nn.Module): The destination conv3d module.\n            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n            module_name_2d (str): The name of corresponding conv module in the\n                2d model.\n            inflated_param_names (list[str]): List of parameters that have been\n                inflated.\n        \"\"\"", "\n", "weight_2d_name", "=", "module_name_2d", "+", "'.weight'", "\n", "\n", "conv2d_weight", "=", "state_dict_2d", "[", "weight_2d_name", "]", "\n", "kernel_t", "=", "conv3d", ".", "weight", ".", "data", ".", "shape", "[", "2", "]", "\n", "\n", "new_weight", "=", "conv2d_weight", ".", "data", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "conv3d", ".", "weight", ")", "/", "kernel_t", "\n", "conv3d", ".", "weight", ".", "data", ".", "copy_", "(", "new_weight", ")", "\n", "inflated_param_names", ".", "append", "(", "weight_2d_name", ")", "\n", "\n", "if", "getattr", "(", "conv3d", ",", "'bias'", ")", "is", "not", "None", ":", "\n", "            ", "bias_2d_name", "=", "module_name_2d", "+", "'.bias'", "\n", "conv3d", ".", "bias", ".", "data", ".", "copy_", "(", "state_dict_2d", "[", "bias_2d_name", "]", ")", "\n", "inflated_param_names", ".", "append", "(", "bias_2d_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_bn_params": [[651, 678], ["bn3d.named_parameters", "bn3d.named_buffers", "param.data.copy_", "inflated_param_names.append", "param.data.copy_", "inflated_param_names.append"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_inflate_bn_params", "(", "bn3d", ",", "state_dict_2d", ",", "module_name_2d", ",", "\n", "inflated_param_names", ")", ":", "\n", "        ", "\"\"\"Inflate a norm module from 2d to 3d.\n\n        Args:\n            bn3d (nn.Module): The destination bn3d module.\n            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n            module_name_2d (str): The name of corresponding bn module in the\n                2d model.\n            inflated_param_names (list[str]): List of parameters that have been\n                inflated.\n        \"\"\"", "\n", "for", "param_name", ",", "param", "in", "bn3d", ".", "named_parameters", "(", ")", ":", "\n", "            ", "param_2d_name", "=", "f'{module_name_2d}.{param_name}'", "\n", "param_2d", "=", "state_dict_2d", "[", "param_2d_name", "]", "\n", "param", ".", "data", ".", "copy_", "(", "param_2d", ")", "\n", "inflated_param_names", ".", "append", "(", "param_2d_name", ")", "\n", "\n", "", "for", "param_name", ",", "param", "in", "bn3d", ".", "named_buffers", "(", ")", ":", "\n", "            ", "param_2d_name", "=", "f'{module_name_2d}.{param_name}'", "\n", "# some buffers like num_batches_tracked may not exist in old", "\n", "# checkpoints", "\n", "if", "param_2d_name", "in", "state_dict_2d", ":", "\n", "                ", "param_2d", "=", "state_dict_2d", "[", "param_2d_name", "]", "\n", "param", ".", "data", ".", "copy_", "(", "param_2d", ")", "\n", "inflated_param_names", ".", "append", "(", "param_2d_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_weights": [[679, 742], ["mmcv.runner._load_checkpoint", "resnet3d.ResNet3d.named_modules", "isinstance", "set", "set", "logger.info", "mmcv.runner._load_checkpoint.keys", "name.replace", "logger.warning", "logger.warning", "resnet3d.ResNet3d._inflate_bn_params", "logger.warning", "resnet3d.ResNet3d._inflate_conv_params"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_bn_params", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway._inflate_conv_params"], ["", "", "", "@", "staticmethod", "\n", "def", "_inflate_weights", "(", "self", ",", "logger", ")", ":", "\n", "        ", "\"\"\"Inflate the resnet2d parameters to resnet3d.\n\n        The differences between resnet3d and resnet2d mainly lie in an extra\n        axis of conv kernel. To utilize the pretrained parameters in 2d model,\n        the weight of conv2d models should be inflated to fit in the shapes of\n        the 3d counterpart.\n\n        Args:\n            logger (logging.Logger): The logger used to print\n                debugging infomation.\n        \"\"\"", "\n", "\n", "state_dict_r2d", "=", "_load_checkpoint", "(", "self", ".", "pretrained", ")", "\n", "if", "'state_dict'", "in", "state_dict_r2d", ":", "\n", "            ", "state_dict_r2d", "=", "state_dict_r2d", "[", "'state_dict'", "]", "\n", "\n", "", "inflated_param_names", "=", "[", "]", "\n", "for", "name", ",", "module", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "ConvModule", ")", ":", "\n", "# we use a ConvModule to wrap conv+bn+relu layers, thus the", "\n", "# name mapping is needed", "\n", "                ", "if", "'downsample'", "in", "name", ":", "\n", "# layer{X}.{Y}.downsample.conv->layer{X}.{Y}.downsample.0", "\n", "                    ", "original_conv_name", "=", "name", "+", "'.0'", "\n", "# layer{X}.{Y}.downsample.bn->layer{X}.{Y}.downsample.1", "\n", "original_bn_name", "=", "name", "+", "'.1'", "\n", "", "else", ":", "\n", "# layer{X}.{Y}.conv{n}.conv->layer{X}.{Y}.conv{n}", "\n", "                    ", "original_conv_name", "=", "name", "\n", "# layer{X}.{Y}.conv{n}.bn->layer{X}.{Y}.bn{n}", "\n", "original_bn_name", "=", "name", ".", "replace", "(", "'conv'", ",", "'bn'", ")", "\n", "", "if", "original_conv_name", "+", "'.weight'", "not", "in", "state_dict_r2d", ":", "\n", "                    ", "logger", ".", "warning", "(", "f'Module not exist in the state_dict_r2d'", "\n", "f': {original_conv_name}'", ")", "\n", "", "else", ":", "\n", "                    ", "shape_2d", "=", "state_dict_r2d", "[", "original_conv_name", "+", "\n", "'.weight'", "]", ".", "shape", "\n", "shape_3d", "=", "module", ".", "conv", ".", "weight", ".", "data", ".", "shape", "\n", "if", "shape_2d", "!=", "shape_3d", "[", ":", "2", "]", "+", "shape_3d", "[", "3", ":", "]", ":", "\n", "                        ", "logger", ".", "warning", "(", "f'Weight shape mismatch for '", "\n", "f': {original_conv_name} : '", "\n", "f'3d weight shape: {shape_3d}; '", "\n", "f'2d weight shape: {shape_2d}. '", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "_inflate_conv_params", "(", "module", ".", "conv", ",", "state_dict_r2d", ",", "\n", "original_conv_name", ",", "\n", "inflated_param_names", ")", "\n", "\n", "", "", "if", "original_bn_name", "+", "'.weight'", "not", "in", "state_dict_r2d", ":", "\n", "                    ", "logger", ".", "warning", "(", "f'Module not exist in the state_dict_r2d'", "\n", "f': {original_bn_name}'", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_inflate_bn_params", "(", "module", ".", "bn", ",", "state_dict_r2d", ",", "\n", "original_bn_name", ",", "\n", "inflated_param_names", ")", "\n", "\n", "# check if any parameters in the 2d checkpoint are not loaded", "\n", "", "", "", "remaining_names", "=", "set", "(", "\n", "state_dict_r2d", ".", "keys", "(", ")", ")", "-", "set", "(", "inflated_param_names", ")", "\n", "if", "remaining_names", ":", "\n", "            ", "logger", ".", "info", "(", "f'These parameters in the 2d checkpoint are not loaded'", "\n", "f': {remaining_names}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d.inflate_weights": [[744, 746], ["resnet3d.ResNet3d._inflate_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_weights"], ["", "", "def", "inflate_weights", "(", "self", ",", "logger", ")", ":", "\n", "        ", "self", ".", "_inflate_weights", "(", "self", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._make_stem_layer": [[747, 769], ["mmcv.cnn.ConvModule", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "tuple", "torch.nn.modules.utils._triple", "torch.nn.modules.utils._triple"], "methods", ["None"], ["", "def", "_make_stem_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct the stem layers consists of a conv+norm+act module and a\n        pooling layer.\"\"\"", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "base_channels", ",", "\n", "kernel_size", "=", "self", ".", "conv1_kernel", ",", "\n", "stride", "=", "(", "self", ".", "conv1_stride_t", ",", "self", ".", "conv1_stride_s", ",", "\n", "self", ".", "conv1_stride_s", ")", ",", "\n", "padding", "=", "tuple", "(", "[", "(", "k", "-", "1", ")", "//", "2", "for", "k", "in", "_triple", "(", "self", ".", "conv1_kernel", ")", "]", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "\n", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "\n", "stride", "=", "(", "self", ".", "pool1_stride_t", ",", "self", ".", "pool1_stride_s", ",", "\n", "self", ".", "pool1_stride_s", ")", ",", "\n", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "2", ",", "1", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._freeze_stages": [[770, 783], ["range", "resnet3d.ResNet3d.conv1.eval", "resnet3d.ResNet3d.conv1.parameters", "getattr", "getattr.eval", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prevent all the parameters from being optimized before\n        ``self.frozen_stages``.\"\"\"", "\n", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "conv1", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._init_weights": [[784, 824], ["isinstance", "utils.get_root_logger", "utils.get_root_logger.info", "resnet3d.ResNet3d.inflate_weights", "mmcv.runner.load_checkpoint", "resnet3d.ResNet3d.modules", "TypeError", "isinstance", "resnet3d.ResNet3d.modules", "mmcv.cnn.kaiming_init", "isinstance", "isinstance", "mmcv.cnn.constant_init", "mmcv.cnn.constant_init", "isinstance", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway.inflate_weights"], ["", "", "", "@", "staticmethod", "\n", "def", "_init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\n\n        Args:\n            pretrained (str | None): The path of the pretrained weight. Will\n                override the original `pretrained` if set. The arg is added to\n                be compatible with mmdet. Default: None.\n        \"\"\"", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "pretrained", "=", "pretrained", "\n", "", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'load model from: {self.pretrained}'", ")", "\n", "\n", "if", "self", ".", "pretrained2d", ":", "\n", "# Inflate 2D model into 3D model.", "\n", "                ", "self", ".", "inflate_weights", "(", "logger", ")", "\n", "\n", "", "else", ":", "\n", "# Directly load 3D model.", "\n", "                ", "load_checkpoint", "(", "\n", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "\n", "", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n", "", "", "if", "self", ".", "zero_init_residual", ":", "\n", "                ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "Bottleneck3d", ")", ":", "\n", "                        ", "constant_init", "(", "m", ".", "conv3", ".", "bn", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock3d", ")", ":", "\n", "                        ", "constant_init", "(", "m", ".", "conv2", ".", "bn", ",", "0", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d.init_weights": [[825, 827], ["resnet3d.ResNet3d._init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._init_weights"], ["", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "self", ".", "_init_weights", "(", "self", ",", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d.forward": [[828, 852], ["resnet3d.ResNet3d.conv1", "resnet3d.ResNet3d.maxpool", "enumerate", "tuple", "getattr", "getattr.", "len", "resnet3d.ResNet3d.pool2", "outs.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The feature of the input\n            samples extracted by the backbone.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "layer_name", "in", "enumerate", "(", "self", ".", "res_layers", ")", ":", "\n", "            ", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "x", "=", "res_layer", "(", "x", ")", "\n", "if", "i", "==", "0", "and", "self", ".", "with_pool2", ":", "\n", "                ", "x", "=", "self", ".", "pool2", "(", "x", ")", "\n", "", "if", "i", "in", "self", ".", "out_indices", ":", "\n", "                ", "outs", ".", "append", "(", "x", ")", "\n", "", "", "if", "len", "(", "outs", ")", "==", "1", ":", "\n", "            ", "return", "outs", "[", "0", "]", "\n", "\n", "", "return", "tuple", "(", "outs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d.train": [[853, 861], ["super().train", "resnet3d.ResNet3d._freeze_stages", "resnet3d.ResNet3d.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Set the optimization status when training.\"\"\"", "\n", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3dLayer.__init__": [[902, 981], ["dict", "dict", "dict", "torch.Module.__init__", "resnet3d.ResNet3dLayer.make_res_layer", "resnet3d.ResNet3dLayer.add_module"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.make_res_layer"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "pretrained", ",", "\n", "pretrained2d", "=", "True", ",", "\n", "stage", "=", "3", ",", "\n", "base_channels", "=", "64", ",", "\n", "spatial_stride", "=", "2", ",", "\n", "temporal_stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "all_frozen", "=", "False", ",", "\n", "inflate", "=", "1", ",", "\n", "inflate_style", "=", "'3x1x1'", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ",", "\n", "norm_eval", "=", "False", ",", "\n", "with_cp", "=", "False", ",", "\n", "zero_init_residual", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "arch_settings", "=", "ResNet3d", ".", "arch_settings", "\n", "assert", "depth", "in", "self", ".", "arch_settings", "\n", "\n", "self", ".", "make_res_layer", "=", "ResNet3d", ".", "make_res_layer", "\n", "self", ".", "_inflate_conv_params", "=", "ResNet3d", ".", "_inflate_conv_params", "\n", "self", ".", "_inflate_bn_params", "=", "ResNet3d", ".", "_inflate_bn_params", "\n", "self", ".", "_inflate_weights", "=", "ResNet3d", ".", "_inflate_weights", "\n", "self", ".", "_init_weights", "=", "ResNet3d", ".", "_init_weights", "\n", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "pretrained2d", "=", "pretrained2d", "\n", "self", ".", "stage", "=", "stage", "\n", "# stage index is 0 based", "\n", "assert", "0", "<=", "stage", "<=", "3", "\n", "self", ".", "base_channels", "=", "base_channels", "\n", "\n", "self", ".", "spatial_stride", "=", "spatial_stride", "\n", "self", ".", "temporal_stride", "=", "temporal_stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "all_frozen", "=", "all_frozen", "\n", "\n", "self", ".", "stage_inflation", "=", "inflate", "\n", "self", ".", "inflate_style", "=", "inflate_style", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "norm_eval", "=", "norm_eval", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "zero_init_residual", "=", "zero_init_residual", "\n", "\n", "block", ",", "stage_blocks", "=", "self", ".", "arch_settings", "[", "depth", "]", "\n", "stage_block", "=", "stage_blocks", "[", "stage", "]", "\n", "planes", "=", "64", "*", "2", "**", "stage", "\n", "inplanes", "=", "64", "*", "2", "**", "(", "stage", "-", "1", ")", "*", "block", ".", "expansion", "\n", "\n", "res_layer", "=", "self", ".", "make_res_layer", "(", "\n", "block", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "stage_block", ",", "\n", "spatial_stride", "=", "spatial_stride", ",", "\n", "temporal_stride", "=", "temporal_stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "style", "=", "self", ".", "style", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ",", "\n", "inflate", "=", "self", ".", "stage_inflation", ",", "\n", "inflate_style", "=", "self", ".", "inflate_style", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "**", "kwargs", ")", "\n", "\n", "self", ".", "layer_name", "=", "f'layer{stage + 1}'", "\n", "self", ".", "add_module", "(", "self", ".", "layer_name", ",", "res_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3dLayer.inflate_weights": [[982, 984], ["resnet3d.ResNet3dLayer._inflate_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_weights"], ["", "def", "inflate_weights", "(", "self", ",", "logger", ")", ":", "\n", "        ", "self", ".", "_inflate_weights", "(", "self", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3dLayer._freeze_stages": [[985, 993], ["getattr", "getattr.eval", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prevent all the parameters from being optimized before\n        ``self.frozen_stages``.\"\"\"", "\n", "if", "self", ".", "all_frozen", ":", "\n", "            ", "layer", "=", "getattr", "(", "self", ",", "self", ".", "layer_name", ")", "\n", "layer", ".", "eval", "(", ")", "\n", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3dLayer.init_weights": [[994, 996], ["resnet3d.ResNet3dLayer._init_weights"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._init_weights"], ["", "", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "self", ".", "_init_weights", "(", "self", ",", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3dLayer.forward": [[997, 1010], ["getattr", "getattr."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The feature of the input\n            samples extracted by the backbone.\n        \"\"\"", "\n", "res_layer", "=", "getattr", "(", "self", ",", "self", ".", "layer_name", ")", "\n", "out", "=", "res_layer", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3dLayer.train": [[1011, 1019], ["super().train", "resnet3d.ResNet3dLayer._freeze_stages", "resnet3d.ResNet3dLayer.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Set the optimization status when training.\"\"\"", "\n", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.Mlp.__init__": [[20, 28], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "act_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "hidden_features", "=", "None", ",", "out_features", "=", "None", ",", "act_layer", "=", "nn", ".", "GELU", ",", "drop", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "out_features", "=", "out_features", "or", "in_features", "\n", "hidden_features", "=", "hidden_features", "or", "in_features", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_features", ",", "hidden_features", ")", "\n", "self", ".", "act", "=", "act_layer", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_features", ",", "out_features", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.Mlp.forward": [[29, 36], ["swin_transformer.Mlp.fc1", "swin_transformer.Mlp.act", "swin_transformer.Mlp.drop", "swin_transformer.Mlp.fc2", "swin_transformer.Mlp.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.WindowAttention3D.__init__": [[100, 137], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "relative_coords.permute().contiguous.permute().contiguous.permute().contiguous", "relative_coords.permute().contiguous.permute().contiguous.sum", "swin_transformer.WindowAttention3D.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "timm.models.layers.trunc_normal_", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "relative_coords.permute().contiguous.permute().contiguous.permute"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "window_size", ",", "num_heads", ",", "qkv_bias", "=", "False", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.", ",", "proj_drop", "=", "0.", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "window_size", "=", "window_size", "# Wd, Wh, Ww", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "# define a parameter table of relative position bias", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "2", "]", "-", "1", ")", ",", "num_heads", ")", ")", "# 2*Wd-1 * 2*Wh-1 * 2*Ww-1, nH", "\n", "\n", "# get pair-wise relative position index for each token inside the window", "\n", "coords_d", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "0", "]", ")", "\n", "coords_h", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "1", "]", ")", "\n", "coords_w", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "2", "]", ")", "\n", "coords", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "coords_d", ",", "coords_h", ",", "coords_w", ")", ")", "# 3, Wd, Wh, Ww", "\n", "coords_flatten", "=", "torch", ".", "flatten", "(", "coords", ",", "1", ")", "# 3, Wd*Wh*Ww", "\n", "relative_coords", "=", "coords_flatten", "[", ":", ",", ":", ",", "None", "]", "-", "coords_flatten", "[", ":", ",", "None", ",", ":", "]", "# 3, Wd*Wh*Ww, Wd*Wh*Ww", "\n", "relative_coords", "=", "relative_coords", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "# Wd*Wh*Ww, Wd*Wh*Ww, 3", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "+=", "self", ".", "window_size", "[", "0", "]", "-", "1", "# shift to start from 0", "\n", "relative_coords", "[", ":", ",", ":", ",", "1", "]", "+=", "self", ".", "window_size", "[", "1", "]", "-", "1", "\n", "relative_coords", "[", ":", ",", ":", ",", "2", "]", "+=", "self", ".", "window_size", "[", "2", "]", "-", "1", "\n", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "*=", "(", "2", "*", "self", ".", "window_size", "[", "1", "]", "-", "1", ")", "*", "(", "2", "*", "self", ".", "window_size", "[", "2", "]", "-", "1", ")", "\n", "relative_coords", "[", ":", ",", ":", ",", "1", "]", "*=", "(", "2", "*", "self", ".", "window_size", "[", "2", "]", "-", "1", ")", "\n", "relative_position_index", "=", "relative_coords", ".", "sum", "(", "-", "1", ")", "# Wd*Wh*Ww, Wd*Wh*Ww", "\n", "self", ".", "register_buffer", "(", "\"relative_position_index\"", ",", "relative_position_index", ")", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "relative_position_bias_table", ",", "std", "=", ".02", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.WindowAttention3D.forward": [[138, 170], ["swin_transformer.WindowAttention3D.qkv().reshape().permute", "swin_transformer.WindowAttention3D.relative_position_bias_table[].reshape", "relative_position_bias.permute().contiguous.permute().contiguous.permute().contiguous", "swin_transformer.WindowAttention3D.attn_drop", "swin_transformer.WindowAttention3D.proj", "swin_transformer.WindowAttention3D.proj_drop", "k.transpose", "relative_position_bias.permute().contiguous.permute().contiguous.unsqueeze", "swin_transformer.WindowAttention3D.view", "swin_transformer.WindowAttention3D.softmax", "swin_transformer.WindowAttention3D.softmax", "swin_transformer.WindowAttention3D.qkv().reshape", "relative_position_bias.permute().contiguous.permute().contiguous.permute", "swin_transformer.WindowAttention3D.view", "mask.unsqueeze().unsqueeze", "swin_transformer.WindowAttention3D.qkv", "swin_transformer.WindowAttention3D.relative_position_index[].reshape", "mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Forward function.\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, N, N) or None\n        \"\"\"", "\n", "B_", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B_", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "# B_, nH, N, C", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", "\n", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "self", ".", "relative_position_index", "[", ":", "N", ",", ":", "N", "]", ".", "reshape", "(", "-", "1", ")", "]", ".", "reshape", "(", "\n", "N", ",", "N", ",", "-", "1", ")", "# Wd*Wh*Ww,Wd*Wh*Ww,nH", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# nH, Wd*Wh*Ww, Wd*Wh*Ww", "\n", "attn", "=", "attn", "+", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "# B_, nH, N, N", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "nW", "=", "mask", ".", "shape", "[", "0", "]", "\n", "attn", "=", "attn", ".", "view", "(", "B_", "//", "nW", ",", "nW", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "+", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "attn", "=", "attn", ".", "view", "(", "-", "1", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "\n", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "\n", "", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B_", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformerBlock3D.__init__": [[190, 214], ["torch.Module.__init__", "norm_layer", "swin_transformer.WindowAttention3D", "norm_layer", "int", "swin_transformer.Mlp", "timm.models.layers.DropPath", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_heads", ",", "window_size", "=", "(", "2", ",", "7", ",", "7", ")", ",", "shift_size", "=", "(", "0", ",", "0", ",", "0", ")", ",", "\n", "mlp_ratio", "=", "4.", ",", "qkv_bias", "=", "True", ",", "qk_scale", "=", "None", ",", "drop", "=", "0.", ",", "attn_drop", "=", "0.", ",", "drop_path", "=", "0.", ",", "\n", "act_layer", "=", "nn", ".", "GELU", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "use_checkpoint", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "shift_size", "=", "shift_size", "\n", "self", ".", "mlp_ratio", "=", "mlp_ratio", "\n", "self", ".", "use_checkpoint", "=", "use_checkpoint", "\n", "\n", "assert", "0", "<=", "self", ".", "shift_size", "[", "0", "]", "<", "self", ".", "window_size", "[", "0", "]", ",", "\"shift_size must in 0-window_size\"", "\n", "assert", "0", "<=", "self", ".", "shift_size", "[", "1", "]", "<", "self", ".", "window_size", "[", "1", "]", ",", "\"shift_size must in 0-window_size\"", "\n", "assert", "0", "<=", "self", ".", "shift_size", "[", "2", "]", "<", "self", ".", "window_size", "[", "2", "]", ",", "\"shift_size must in 0-window_size\"", "\n", "\n", "self", ".", "norm1", "=", "norm_layer", "(", "dim", ")", "\n", "self", ".", "attn", "=", "WindowAttention3D", "(", "\n", "dim", ",", "window_size", "=", "self", ".", "window_size", ",", "num_heads", "=", "num_heads", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "qk_scale", "=", "qk_scale", ",", "attn_drop", "=", "attn_drop", ",", "proj_drop", "=", "drop", ")", "\n", "\n", "self", ".", "drop_path", "=", "DropPath", "(", "drop_path", ")", "if", "drop_path", ">", "0.", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "norm2", "=", "norm_layer", "(", "dim", ")", "\n", "mlp_hidden_dim", "=", "int", "(", "dim", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "Mlp", "(", "in_features", "=", "dim", ",", "hidden_features", "=", "mlp_hidden_dim", ",", "act_layer", "=", "act_layer", ",", "drop", "=", "drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformerBlock3D.forward_part1": [[215, 250], ["swin_transformer.get_window_size", "swin_transformer.SwinTransformerBlock3D.norm1", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "any", "swin_transformer.window_partition", "swin_transformer.SwinTransformerBlock3D.attn", "attn_windows.view.view.view", "swin_transformer.window_reverse", "any", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "x[].contiguous"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.get_window_size", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.window_partition", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.window_reverse"], ["", "def", "forward_part1", "(", "self", ",", "x", ",", "mask_matrix", ")", ":", "\n", "        ", "B", ",", "D", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "window_size", ",", "shift_size", "=", "get_window_size", "(", "(", "D", ",", "H", ",", "W", ")", ",", "self", ".", "window_size", ",", "self", ".", "shift_size", ")", "\n", "\n", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "# pad feature maps to multiples of window size", "\n", "pad_l", "=", "pad_t", "=", "pad_d0", "=", "0", "\n", "pad_d1", "=", "(", "window_size", "[", "0", "]", "-", "D", "%", "window_size", "[", "0", "]", ")", "%", "window_size", "[", "0", "]", "\n", "pad_b", "=", "(", "window_size", "[", "1", "]", "-", "H", "%", "window_size", "[", "1", "]", ")", "%", "window_size", "[", "1", "]", "\n", "pad_r", "=", "(", "window_size", "[", "2", "]", "-", "W", "%", "window_size", "[", "2", "]", ")", "%", "window_size", "[", "2", "]", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "pad_l", ",", "pad_r", ",", "pad_t", ",", "pad_b", ",", "pad_d0", ",", "pad_d1", ")", ")", "\n", "_", ",", "Dp", ",", "Hp", ",", "Wp", ",", "_", "=", "x", ".", "shape", "\n", "# cyclic shift", "\n", "if", "any", "(", "i", ">", "0", "for", "i", "in", "shift_size", ")", ":", "\n", "            ", "shifted_x", "=", "torch", ".", "roll", "(", "x", ",", "shifts", "=", "(", "-", "shift_size", "[", "0", "]", ",", "-", "shift_size", "[", "1", "]", ",", "-", "shift_size", "[", "2", "]", ")", ",", "dims", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "attn_mask", "=", "mask_matrix", "\n", "", "else", ":", "\n", "            ", "shifted_x", "=", "x", "\n", "attn_mask", "=", "None", "\n", "# partition windows", "\n", "", "x_windows", "=", "window_partition", "(", "shifted_x", ",", "window_size", ")", "# B*nW, Wd*Wh*Ww, C", "\n", "# W-MSA/SW-MSA", "\n", "attn_windows", "=", "self", ".", "attn", "(", "x_windows", ",", "mask", "=", "attn_mask", ")", "# B*nW, Wd*Wh*Ww, C", "\n", "# merge windows", "\n", "attn_windows", "=", "attn_windows", ".", "view", "(", "-", "1", ",", "*", "(", "window_size", "+", "(", "C", ",", ")", ")", ")", "\n", "shifted_x", "=", "window_reverse", "(", "attn_windows", ",", "window_size", ",", "B", ",", "Dp", ",", "Hp", ",", "Wp", ")", "# B D' H' W' C", "\n", "# reverse cyclic shift", "\n", "if", "any", "(", "i", ">", "0", "for", "i", "in", "shift_size", ")", ":", "\n", "            ", "x", "=", "torch", ".", "roll", "(", "shifted_x", ",", "shifts", "=", "(", "shift_size", "[", "0", "]", ",", "shift_size", "[", "1", "]", ",", "shift_size", "[", "2", "]", ")", ",", "dims", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "shifted_x", "\n", "\n", "", "if", "pad_d1", ">", "0", "or", "pad_r", ">", "0", "or", "pad_b", ">", "0", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", "D", ",", ":", "H", ",", ":", "W", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformerBlock3D.forward_part2": [[251, 253], ["swin_transformer.SwinTransformerBlock3D.drop_path", "swin_transformer.SwinTransformerBlock3D.mlp", "swin_transformer.SwinTransformerBlock3D.norm2"], "methods", ["None"], ["", "def", "forward_part2", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "drop_path", "(", "self", ".", "mlp", "(", "self", ".", "norm2", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformerBlock3D.forward": [[254, 275], ["torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "swin_transformer.SwinTransformerBlock3D.forward_part1", "swin_transformer.SwinTransformerBlock3D.drop_path", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "swin_transformer.SwinTransformerBlock3D.forward_part2"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformerBlock3D.forward_part1", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformerBlock3D.forward_part2"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask_matrix", ")", ":", "\n", "        ", "\"\"\" Forward function.\n\n        Args:\n            x: Input feature, tensor size (B, D, H, W, C).\n            mask_matrix: Attention mask for cyclic shift.\n        \"\"\"", "\n", "\n", "shortcut", "=", "x", "\n", "if", "self", ".", "use_checkpoint", ":", "\n", "            ", "x", "=", "checkpoint", ".", "checkpoint", "(", "self", ".", "forward_part1", ",", "x", ",", "mask_matrix", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "forward_part1", "(", "x", ",", "mask_matrix", ")", "\n", "", "x", "=", "shortcut", "+", "self", ".", "drop_path", "(", "x", ")", "\n", "\n", "if", "self", ".", "use_checkpoint", ":", "\n", "            ", "x", "=", "x", "+", "checkpoint", ".", "checkpoint", "(", "self", ".", "forward_part2", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "forward_part2", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.PatchMerging.__init__": [[284, 289], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "reduction", "=", "nn", ".", "Linear", "(", "4", "*", "dim", ",", "2", "*", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "4", "*", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.PatchMerging.forward": [[290, 313], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "swin_transformer.PatchMerging.norm", "swin_transformer.PatchMerging.reduction", "torch.pad", "torch.pad", "torch.pad", "torch.pad"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Forward function.\n\n        Args:\n            x: Input feature, tensor size (B, D, H, W, C).\n        \"\"\"", "\n", "B", ",", "D", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "\n", "# padding", "\n", "pad_input", "=", "(", "H", "%", "2", "==", "1", ")", "or", "(", "W", "%", "2", "==", "1", ")", "\n", "if", "pad_input", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "W", "%", "2", ",", "0", ",", "H", "%", "2", ")", ")", "\n", "\n", "", "x0", "=", "x", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", ":", "]", "# B D H/2 W/2 C", "\n", "x1", "=", "x", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", ":", "]", "# B D H/2 W/2 C", "\n", "x2", "=", "x", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", ":", "]", "# B D H/2 W/2 C", "\n", "x3", "=", "x", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", ":", "]", "# B D H/2 W/2 C", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x0", ",", "x1", ",", "x2", ",", "x3", "]", ",", "-", "1", ")", "# B D H/2 W/2 4*C", "\n", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "self", ".", "reduction", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.BasicLayer.__init__": [[350, 391], ["torch.Module.__init__", "tuple", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "downsample", "swin_transformer.SwinTransformerBlock3D", "range", "isinstance"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dim", ",", "\n", "depth", ",", "\n", "num_heads", ",", "\n", "window_size", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "False", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop", "=", "0.", ",", "\n", "attn_drop", "=", "0.", ",", "\n", "drop_path", "=", "0.", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "downsample", "=", "None", ",", "\n", "use_checkpoint", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "shift_size", "=", "tuple", "(", "i", "//", "2", "for", "i", "in", "window_size", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "use_checkpoint", "=", "use_checkpoint", "\n", "\n", "# build blocks", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "SwinTransformerBlock3D", "(", "\n", "dim", "=", "dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "window_size", "=", "window_size", ",", "\n", "shift_size", "=", "(", "0", ",", "0", ",", "0", ")", "if", "(", "i", "%", "2", "==", "0", ")", "else", "self", ".", "shift_size", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop", ",", "\n", "attn_drop", "=", "attn_drop", ",", "\n", "drop_path", "=", "drop_path", "[", "i", "]", "if", "isinstance", "(", "drop_path", ",", "list", ")", "else", "drop_path", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "use_checkpoint", "=", "use_checkpoint", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", "]", ")", "\n", "\n", "self", ".", "downsample", "=", "downsample", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", "=", "downsample", "(", "dim", "=", "dim", ",", "norm_layer", "=", "norm_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.BasicLayer.forward": [[392, 414], ["swin_transformer.get_window_size", "einops.rearrange", "swin_transformer.compute_mask", "swin_transformer.BasicLayer.view", "einops.rearrange", "int", "int", "int", "blk", "swin_transformer.BasicLayer.downsample", "numpy.ceil", "numpy.ceil", "numpy.ceil"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.get_window_size", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.compute_mask"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Forward function.\n\n        Args:\n            x: Input feature, tensor size (B, C, D, H, W).\n        \"\"\"", "\n", "# calculate attention mask for SW-MSA", "\n", "B", ",", "C", ",", "D", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "window_size", ",", "shift_size", "=", "get_window_size", "(", "(", "D", ",", "H", ",", "W", ")", ",", "self", ".", "window_size", ",", "self", ".", "shift_size", ")", "\n", "x", "=", "rearrange", "(", "x", ",", "'b c d h w -> b d h w c'", ")", "\n", "Dp", "=", "int", "(", "np", ".", "ceil", "(", "D", "/", "window_size", "[", "0", "]", ")", ")", "*", "window_size", "[", "0", "]", "\n", "Hp", "=", "int", "(", "np", ".", "ceil", "(", "H", "/", "window_size", "[", "1", "]", ")", ")", "*", "window_size", "[", "1", "]", "\n", "Wp", "=", "int", "(", "np", ".", "ceil", "(", "W", "/", "window_size", "[", "2", "]", ")", ")", "*", "window_size", "[", "2", "]", "\n", "attn_mask", "=", "compute_mask", "(", "Dp", ",", "Hp", ",", "Wp", ",", "window_size", ",", "shift_size", ",", "x", ".", "device", ")", "\n", "for", "blk", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "blk", "(", "x", ",", "attn_mask", ")", "\n", "", "x", "=", "x", ".", "view", "(", "B", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "x", "=", "rearrange", "(", "x", ",", "'b d h w c -> b c d h w'", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.PatchEmbed3D.__init__": [[425, 437], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "patch_size", "=", "(", "2", ",", "4", ",", "4", ")", ",", "in_chans", "=", "3", ",", "embed_dim", "=", "96", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "self", ".", "in_chans", "=", "in_chans", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Conv3d", "(", "in_chans", ",", "embed_dim", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ")", "\n", "if", "norm_layer", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "norm_layer", "(", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.PatchEmbed3D.forward": [[438, 457], ["x.transpose().view.transpose().view.size", "swin_transformer.PatchEmbed3D.proj", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "x.transpose().view.transpose().view.flatten().transpose", "swin_transformer.PatchEmbed3D.norm", "x.transpose().view.transpose().view.transpose().view", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.size", "x.transpose().view.transpose().view.flatten", "x.transpose().view.transpose().view.transpose"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "# padding", "\n", "_", ",", "_", ",", "D", ",", "H", ",", "W", "=", "x", ".", "size", "(", ")", "\n", "if", "W", "%", "self", ".", "patch_size", "[", "2", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "self", ".", "patch_size", "[", "2", "]", "-", "W", "%", "self", ".", "patch_size", "[", "2", "]", ")", ")", "\n", "", "if", "H", "%", "self", ".", "patch_size", "[", "1", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "self", ".", "patch_size", "[", "1", "]", "-", "H", "%", "self", ".", "patch_size", "[", "1", "]", ")", ")", "\n", "", "if", "D", "%", "self", ".", "patch_size", "[", "0", "]", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "self", ".", "patch_size", "[", "0", "]", "-", "D", "%", "self", ".", "patch_size", "[", "0", "]", ")", ")", "\n", "\n", "", "x", "=", "self", ".", "proj", "(", "x", ")", "# B C D Wh Ww", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "D", ",", "Wh", ",", "Ww", "=", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ",", "x", ".", "size", "(", "4", ")", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "view", "(", "-", "1", ",", "self", ".", "embed_dim", ",", "D", ",", "Wh", ",", "Ww", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformer3D.__init__": [[483, 548], ["torch.Module.__init__", "len", "swin_transformer.PatchEmbed3D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "int", "norm_layer", "swin_transformer.SwinTransformer3D._freeze_stages", "x.item", "swin_transformer.BasicLayer", "swin_transformer.SwinTransformer3D.layers.append", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "sum", "int", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["def", "__init__", "(", "self", ",", "\n", "pretrained", "=", "None", ",", "\n", "pretrained2d", "=", "True", ",", "\n", "patch_size", "=", "(", "4", ",", "4", ",", "4", ")", ",", "\n", "in_chans", "=", "3", ",", "\n", "embed_dim", "=", "96", ",", "\n", "depths", "=", "[", "2", ",", "2", ",", "6", ",", "2", "]", ",", "\n", "num_heads", "=", "[", "3", ",", "6", ",", "12", ",", "24", "]", ",", "\n", "window_size", "=", "(", "2", ",", "7", ",", "7", ")", ",", "\n", "mlp_ratio", "=", "4.", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.2", ",", "\n", "norm_layer", "=", "nn", ".", "LayerNorm", ",", "\n", "patch_norm", "=", "False", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "use_checkpoint", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "pretrained2d", "=", "pretrained2d", "\n", "self", ".", "num_layers", "=", "len", "(", "depths", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "patch_norm", "=", "patch_norm", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "# split image into non-overlapping patches", "\n", "self", ".", "patch_embed", "=", "PatchEmbed3D", "(", "\n", "patch_size", "=", "patch_size", ",", "in_chans", "=", "in_chans", ",", "embed_dim", "=", "embed_dim", ",", "\n", "norm_layer", "=", "norm_layer", "if", "self", ".", "patch_norm", "else", "None", ")", "\n", "\n", "self", ".", "pos_drop", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "# stochastic depth", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", "]", "# stochastic depth decay rule", "\n", "\n", "# build layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i_layer", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "layer", "=", "BasicLayer", "(", "\n", "dim", "=", "int", "(", "embed_dim", "*", "2", "**", "i_layer", ")", ",", "\n", "depth", "=", "depths", "[", "i_layer", "]", ",", "\n", "num_heads", "=", "num_heads", "[", "i_layer", "]", ",", "\n", "window_size", "=", "window_size", ",", "\n", "mlp_ratio", "=", "mlp_ratio", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop", "=", "drop_rate", ",", "\n", "attn_drop", "=", "attn_drop_rate", ",", "\n", "drop_path", "=", "dpr", "[", "sum", "(", "depths", "[", ":", "i_layer", "]", ")", ":", "sum", "(", "depths", "[", ":", "i_layer", "+", "1", "]", ")", "]", ",", "\n", "norm_layer", "=", "norm_layer", ",", "\n", "downsample", "=", "PatchMerging", "if", "i_layer", "<", "self", ".", "num_layers", "-", "1", "else", "None", ",", "\n", "use_checkpoint", "=", "use_checkpoint", ")", "\n", "self", ".", "layers", ".", "append", "(", "layer", ")", "\n", "\n", "", "self", ".", "num_features", "=", "int", "(", "embed_dim", "*", "2", "**", "(", "self", ".", "num_layers", "-", "1", ")", ")", "\n", "\n", "# add a norm layer for each output", "\n", "self", ".", "norm", "=", "norm_layer", "(", "self", ".", "num_features", ")", "\n", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformer3D._freeze_stages": [[549, 562], ["swin_transformer.SwinTransformer3D.patch_embed.eval", "swin_transformer.SwinTransformer3D.patch_embed.parameters", "swin_transformer.SwinTransformer3D.pos_drop.eval", "range", "m.eval", "m.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "patch_embed", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "patch_embed", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "self", ".", "frozen_stages", ">=", "1", ":", "\n", "            ", "self", ".", "pos_drop", ".", "eval", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "frozen_stages", ")", ":", "\n", "                ", "m", "=", "self", ".", "layers", "[", "i", "]", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformer3D.inflate_weights": [[563, 615], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "swin_transformer.SwinTransformer3D.load_state_dict", "logger.info", "logger.info", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "state_dict[].unsqueeze().repeat", "torch.nn.functional.interpolate.view().permute.size", "relative_position_bias_table_current.size", "torch.nn.functional.interpolate.view().permute.repeat", "state_dict.keys", "state_dict.keys", "state_dict.keys", "swin_transformer.SwinTransformer3D.state_dict", "logger.warning", "state_dict[].unsqueeze", "int", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate.view().permute", "torch.nn.functional.interpolate.view().permute", "torch.nn.functional.interpolate.view().permute", "torch.nn.functional.interpolate.view().permute", "torch.nn.functional.interpolate.view().permute.permute().view", "torch.nn.functional.interpolate.view", "torch.nn.functional.interpolate.view", "torch.nn.functional.interpolate.view", "torch.nn.functional.interpolate.view", "torch.nn.functional.interpolate.view().permute.permute"], "methods", ["None"], ["", "", "", "", "def", "inflate_weights", "(", "self", ",", "logger", ")", ":", "\n", "        ", "\"\"\"Inflate the swin2d parameters to swin3d.\n\n        The differences between swin3d and swin2d mainly lie in an extra\n        axis. To utilize the pretrained parameters in 2d model,\n        the weight of swin2d models should be inflated to fit in the shapes of\n        the 3d counterpart.\n\n        Args:\n            logger (logging.Logger): The logger used to print\n                debugging infomation.\n        \"\"\"", "\n", "checkpoint", "=", "torch", ".", "load", "(", "self", ".", "pretrained", ",", "map_location", "=", "'cpu'", ")", "\n", "state_dict", "=", "checkpoint", "[", "'model'", "]", "\n", "\n", "# delete relative_position_index since we always re-init it", "\n", "relative_position_index_keys", "=", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "if", "\"relative_position_index\"", "in", "k", "]", "\n", "for", "k", "in", "relative_position_index_keys", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "# delete attn_mask since we always re-init it", "\n", "", "attn_mask_keys", "=", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "if", "\"attn_mask\"", "in", "k", "]", "\n", "for", "k", "in", "attn_mask_keys", ":", "\n", "            ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "state_dict", "[", "'patch_embed.proj.weight'", "]", "=", "state_dict", "[", "'patch_embed.proj.weight'", "]", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "patch_size", "[", "0", "]", ",", "1", ",", "1", ")", "/", "self", ".", "patch_size", "[", "0", "]", "\n", "\n", "# bicubic interpolate relative_position_bias_table if not match", "\n", "relative_position_bias_table_keys", "=", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "if", "\"relative_position_bias_table\"", "in", "k", "]", "\n", "for", "k", "in", "relative_position_bias_table_keys", ":", "\n", "            ", "relative_position_bias_table_pretrained", "=", "state_dict", "[", "k", "]", "\n", "relative_position_bias_table_current", "=", "self", ".", "state_dict", "(", ")", "[", "k", "]", "\n", "L1", ",", "nH1", "=", "relative_position_bias_table_pretrained", ".", "size", "(", ")", "\n", "L2", ",", "nH2", "=", "relative_position_bias_table_current", ".", "size", "(", ")", "\n", "L2", "=", "(", "2", "*", "self", ".", "window_size", "[", "1", "]", "-", "1", ")", "*", "(", "2", "*", "self", ".", "window_size", "[", "2", "]", "-", "1", ")", "\n", "wd", "=", "self", ".", "window_size", "[", "0", "]", "\n", "if", "nH1", "!=", "nH2", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Error in loading {k}, passing\"", ")", "\n", "", "else", ":", "\n", "                ", "if", "L1", "!=", "L2", ":", "\n", "                    ", "S1", "=", "int", "(", "L1", "**", "0.5", ")", "\n", "relative_position_bias_table_pretrained_resized", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "relative_position_bias_table_pretrained", ".", "permute", "(", "1", ",", "0", ")", ".", "view", "(", "1", ",", "nH1", ",", "S1", ",", "S1", ")", ",", "size", "=", "(", "2", "*", "self", ".", "window_size", "[", "1", "]", "-", "1", ",", "2", "*", "self", ".", "window_size", "[", "2", "]", "-", "1", ")", ",", "\n", "mode", "=", "'bicubic'", ")", "\n", "relative_position_bias_table_pretrained", "=", "relative_position_bias_table_pretrained_resized", ".", "view", "(", "nH2", ",", "L2", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "", "", "state_dict", "[", "k", "]", "=", "relative_position_bias_table_pretrained", ".", "repeat", "(", "2", "*", "wd", "-", "1", ",", "1", ")", "\n", "\n", "", "msg", "=", "self", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "logger", ".", "info", "(", "msg", ")", "\n", "logger", ".", "info", "(", "f\"=> loaded successfully '{self.pretrained}'\"", ")", "\n", "del", "checkpoint", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformer3D.init_weights": [[616, 649], ["isinstance", "isinstance", "swin_transformer.SwinTransformer3D.apply", "mmaction.utils.get_root_logger", "mmaction.utils.get_root_logger.info", "timm.models.layers.trunc_normal_", "isinstance", "swin_transformer.SwinTransformer3D.inflate_weights", "mmcv.runner.load_checkpoint", "swin_transformer.SwinTransformer3D.apply", "TypeError", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway.inflate_weights"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initialize the weights in backbone.\n\n        Args:\n            pretrained (str, optional): Path to pre-trained weights.\n                Defaults to None.\n        \"\"\"", "\n", "def", "_init_weights", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n", "", "", "if", "pretrained", ":", "\n", "            ", "self", ".", "pretrained", "=", "pretrained", "\n", "", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "self", ".", "apply", "(", "_init_weights", ")", "\n", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'load model from: {self.pretrained}'", ")", "\n", "\n", "if", "self", ".", "pretrained2d", ":", "\n", "# Inflate 2D model into 3D model.", "\n", "                ", "self", ".", "inflate_weights", "(", "logger", ")", "\n", "", "else", ":", "\n", "# Directly load 3D model.", "\n", "                ", "load_checkpoint", "(", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "self", ".", "apply", "(", "_init_weights", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformer3D.forward": [[650, 664], ["swin_transformer.SwinTransformer3D.patch_embed", "swin_transformer.SwinTransformer3D.pos_drop", "einops.rearrange", "swin_transformer.SwinTransformer3D.norm", "einops.rearrange", "layer", "layer.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "pos_drop", "(", "x", ")", "\n", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ".", "contiguous", "(", ")", ")", "\n", "\n", "", "x", "=", "rearrange", "(", "x", ",", "'n c d h w -> n d h w c'", ")", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "x", "=", "rearrange", "(", "x", ",", "'n d h w c -> n c d h w'", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.SwinTransformer3D.train": [[665, 669], ["super().train", "swin_transformer.SwinTransformer3D._freeze_stages"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Convert the model into training mode while keep layers freezed.\"\"\"", "\n", "super", "(", "SwinTransformer3D", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.window_partition": [[38, 51], ["x.view.view", "x.view.permute().contiguous().view", "functools.reduce", "x.view.permute().contiguous", "x.view.permute"], "function", ["None"], ["", "", "def", "window_partition", "(", "x", ",", "window_size", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        x: (B, D, H, W, C)\n        window_size (tuple[int]): window size\n\n    Returns:\n        windows: (B*num_windows, window_size*window_size, C)\n    \"\"\"", "\n", "B", ",", "D", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "D", "//", "window_size", "[", "0", "]", ",", "window_size", "[", "0", "]", ",", "H", "//", "window_size", "[", "1", "]", ",", "window_size", "[", "1", "]", ",", "W", "//", "window_size", "[", "2", "]", ",", "window_size", "[", "2", "]", ",", "C", ")", "\n", "windows", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "5", ",", "2", ",", "4", ",", "6", ",", "7", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "reduce", "(", "mul", ",", "window_size", ")", ",", "C", ")", "\n", "return", "windows", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.window_reverse": [[53, 67], ["windows.view", "x.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous().view.permute().contiguous", "x.permute().contiguous().view.permute"], "function", ["None"], ["", "def", "window_reverse", "(", "windows", ",", "window_size", ",", "B", ",", "D", ",", "H", ",", "W", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        windows: (B*num_windows, window_size, window_size, C)\n        window_size (tuple[int]): Window size\n        H (int): Height of image\n        W (int): Width of image\n\n    Returns:\n        x: (B, D, H, W, C)\n    \"\"\"", "\n", "x", "=", "windows", ".", "view", "(", "B", ",", "D", "//", "window_size", "[", "0", "]", ",", "H", "//", "window_size", "[", "1", "]", ",", "W", "//", "window_size", "[", "2", "]", ",", "window_size", "[", "0", "]", ",", "window_size", "[", "1", "]", ",", "window_size", "[", "2", "]", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "5", ",", "3", ",", "6", ",", "7", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.get_window_size": [[71, 85], ["list", "range", "list", "len", "tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "get_window_size", "(", "x_size", ",", "window_size", ",", "shift_size", "=", "None", ")", ":", "\n", "    ", "use_window_size", "=", "list", "(", "window_size", ")", "\n", "if", "shift_size", "is", "not", "None", ":", "\n", "        ", "use_shift_size", "=", "list", "(", "shift_size", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "x_size", ")", ")", ":", "\n", "        ", "if", "x_size", "[", "i", "]", "<=", "window_size", "[", "i", "]", ":", "\n", "            ", "use_window_size", "[", "i", "]", "=", "x_size", "[", "i", "]", "\n", "if", "shift_size", "is", "not", "None", ":", "\n", "                ", "use_shift_size", "[", "i", "]", "=", "0", "\n", "\n", "", "", "", "if", "shift_size", "is", "None", ":", "\n", "        ", "return", "tuple", "(", "use_window_size", ")", "\n", "", "else", ":", "\n", "        ", "return", "tuple", "(", "use_window_size", ")", ",", "tuple", "(", "use_shift_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.compute_mask": [[316, 330], ["functools.lru_cache", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "swin_transformer.window_partition", "mask_windows.squeeze.squeeze", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill", "slice", "slice", "slice", "mask_windows.squeeze.unsqueeze", "mask_windows.squeeze.unsqueeze", "float", "slice", "slice", "slice", "attn_mask.masked_fill().masked_fill.masked_fill", "slice", "slice", "slice", "float"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.swin_transformer.window_partition"], ["", "", "@", "lru_cache", "(", ")", "\n", "def", "compute_mask", "(", "D", ",", "H", ",", "W", ",", "window_size", ",", "shift_size", ",", "device", ")", ":", "\n", "    ", "img_mask", "=", "torch", ".", "zeros", "(", "(", "1", ",", "D", ",", "H", ",", "W", ",", "1", ")", ",", "device", "=", "device", ")", "# 1 Dp Hp Wp 1", "\n", "cnt", "=", "0", "\n", "for", "d", "in", "slice", "(", "-", "window_size", "[", "0", "]", ")", ",", "slice", "(", "-", "window_size", "[", "0", "]", ",", "-", "shift_size", "[", "0", "]", ")", ",", "slice", "(", "-", "shift_size", "[", "0", "]", ",", "None", ")", ":", "\n", "        ", "for", "h", "in", "slice", "(", "-", "window_size", "[", "1", "]", ")", ",", "slice", "(", "-", "window_size", "[", "1", "]", ",", "-", "shift_size", "[", "1", "]", ")", ",", "slice", "(", "-", "shift_size", "[", "1", "]", ",", "None", ")", ":", "\n", "            ", "for", "w", "in", "slice", "(", "-", "window_size", "[", "2", "]", ")", ",", "slice", "(", "-", "window_size", "[", "2", "]", ",", "-", "shift_size", "[", "2", "]", ")", ",", "slice", "(", "-", "shift_size", "[", "2", "]", ",", "None", ")", ":", "\n", "                ", "img_mask", "[", ":", ",", "d", ",", "h", ",", "w", ",", ":", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "", "", "", "mask_windows", "=", "window_partition", "(", "img_mask", ",", "window_size", ")", "# nW, ws[0]*ws[1]*ws[2], 1", "\n", "mask_windows", "=", "mask_windows", ".", "squeeze", "(", "-", "1", ")", "# nW, ws[0]*ws[1]*ws[2]", "\n", "attn_mask", "=", "mask_windows", ".", "unsqueeze", "(", "1", ")", "-", "mask_windows", ".", "unsqueeze", "(", "2", ")", "\n", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", "!=", "0", ",", "float", "(", "-", "100.0", ")", ")", ".", "masked_fill", "(", "attn_mask", "==", "0", ",", "float", "(", "0.0", ")", ")", "\n", "return", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway.__init__": [[36, 85], ["resnet3d.ResNet3d.__init__", "range", "mmcv.cnn.ConvModule", "len", "setattr", "resnet3d_slowfast.ResNet3dPathway.lateral_connections.append", "mmcv.cnn.ConvModule"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "*", "args", ",", "\n", "lateral", "=", "False", ",", "\n", "speed_ratio", "=", "8", ",", "\n", "channel_ratio", "=", "8", ",", "\n", "fusion_kernel", "=", "5", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "lateral", "=", "lateral", "\n", "self", ".", "speed_ratio", "=", "speed_ratio", "\n", "self", ".", "channel_ratio", "=", "channel_ratio", "\n", "self", ".", "fusion_kernel", "=", "fusion_kernel", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "inplanes", "=", "self", ".", "base_channels", "\n", "if", "self", ".", "lateral", ":", "\n", "            ", "self", ".", "conv1_lateral", "=", "ConvModule", "(", "\n", "self", ".", "inplanes", "//", "self", ".", "channel_ratio", ",", "\n", "# https://arxiv.org/abs/1812.03982, the", "\n", "# third type of lateral connection has out_channel:", "\n", "# 2 * \\beta * C", "\n", "self", ".", "inplanes", "*", "2", "//", "self", ".", "channel_ratio", ",", "\n", "kernel_size", "=", "(", "fusion_kernel", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "self", ".", "speed_ratio", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "(", "fusion_kernel", "-", "1", ")", "//", "2", ",", "0", ",", "0", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "", "self", ".", "lateral_connections", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "stage_blocks", ")", ")", ":", "\n", "            ", "planes", "=", "self", ".", "base_channels", "*", "2", "**", "i", "\n", "self", ".", "inplanes", "=", "planes", "*", "self", ".", "block", ".", "expansion", "\n", "\n", "if", "lateral", "and", "i", "!=", "self", ".", "num_stages", "-", "1", ":", "\n", "# no lateral connection needed in final stage", "\n", "                ", "lateral_name", "=", "f'layer{(i + 1)}_lateral'", "\n", "setattr", "(", "\n", "self", ",", "lateral_name", ",", "\n", "ConvModule", "(", "\n", "self", ".", "inplanes", "//", "self", ".", "channel_ratio", ",", "\n", "self", ".", "inplanes", "*", "2", "//", "self", ".", "channel_ratio", ",", "\n", "kernel_size", "=", "(", "fusion_kernel", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "self", ".", "speed_ratio", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "(", "fusion_kernel", "-", "1", ")", "//", "2", ",", "0", ",", "0", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ")", ")", "\n", "self", ".", "lateral_connections", ".", "append", "(", "lateral_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway.make_res_layer": [[86, 203], ["dict", "layers.append", "range", "torch.Sequential", "torch.Sequential", "mmcv.cnn.ConvModule", "block", "layers.append", "isinstance", "isinstance", "len", "len", "block"], "methods", ["None"], ["", "", "", "def", "make_res_layer", "(", "self", ",", "\n", "block", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "blocks", ",", "\n", "spatial_stride", "=", "1", ",", "\n", "temporal_stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "inflate", "=", "1", ",", "\n", "inflate_style", "=", "'3x1x1'", ",", "\n", "non_local", "=", "0", ",", "\n", "non_local_cfg", "=", "dict", "(", ")", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "\"\"\"Build residual layer for Slowfast.\n\n        Args:\n            block (nn.Module): Residual module to be built.\n            inplanes (int): Number of channels for the input\n                feature in each block.\n            planes (int): Number of channels for the output\n                feature in each block.\n            blocks (int): Number of residual blocks.\n            spatial_stride (int | Sequence[int]): Spatial strides\n                in residual and conv layers. Default: 1.\n            temporal_stride (int | Sequence[int]): Temporal strides in\n                residual and conv layers. Default: 1.\n            dilation (int): Spacing between kernel elements. Default: 1.\n            style (str): ``pytorch`` or ``caffe``. If set to ``pytorch``,\n                the stride-two layer is the 3x3 conv layer,\n                otherwise the stride-two layer is the first 1x1 conv layer.\n                Default: ``pytorch``.\n            inflate (int | Sequence[int]): Determine whether to inflate\n                for each block. Default: 1.\n            inflate_style (str): ``3x1x1`` or ``3x3x3``. which determines\n                the kernel sizes and padding strides for conv1 and\n                conv2 in each block. Default: ``3x1x1``.\n            non_local (int | Sequence[int]): Determine whether to apply\n                non-local module in the corresponding block of each stages.\n                Default: 0.\n            non_local_cfg (dict): Config for non-local module.\n                Default: ``dict()``.\n            conv_cfg (dict | None): Config for conv layers. Default: None.\n            norm_cfg (dict | None): Config for norm layers. Default: None.\n            act_cfg (dict | None): Config for activate layers. Default: None.\n            with_cp (bool): Use checkpoint or not. Using checkpoint will save\n                some memory while slowing down the training speed.\n                Default: False.\n\n        Returns:\n            nn.Module: A residual layer for the given config.\n        \"\"\"", "\n", "inflate", "=", "inflate", "if", "not", "isinstance", "(", "inflate", ",", "\n", "int", ")", "else", "(", "inflate", ",", ")", "*", "blocks", "\n", "non_local", "=", "non_local", "if", "not", "isinstance", "(", "\n", "non_local", ",", "int", ")", "else", "(", "non_local", ",", ")", "*", "blocks", "\n", "assert", "len", "(", "inflate", ")", "==", "blocks", "and", "len", "(", "non_local", ")", "==", "blocks", "\n", "if", "self", ".", "lateral", ":", "\n", "            ", "lateral_inplanes", "=", "inplanes", "*", "2", "//", "self", ".", "channel_ratio", "\n", "", "else", ":", "\n", "            ", "lateral_inplanes", "=", "0", "\n", "", "if", "(", "spatial_stride", "!=", "1", "\n", "or", "(", "inplanes", "+", "lateral_inplanes", ")", "!=", "planes", "*", "block", ".", "expansion", ")", ":", "\n", "            ", "downsample", "=", "ConvModule", "(", "\n", "inplanes", "+", "lateral_inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "(", "temporal_stride", ",", "spatial_stride", ",", "spatial_stride", ")", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "", "else", ":", "\n", "            ", "downsample", "=", "None", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "+", "lateral_inplanes", ",", "\n", "planes", ",", "\n", "spatial_stride", ",", "\n", "temporal_stride", ",", "\n", "dilation", ",", "\n", "downsample", ",", "\n", "style", "=", "style", ",", "\n", "inflate", "=", "(", "inflate", "[", "0", "]", "==", "1", ")", ",", "\n", "inflate_style", "=", "inflate_style", ",", "\n", "non_local", "=", "(", "non_local", "[", "0", "]", "==", "1", ")", ",", "\n", "non_local_cfg", "=", "non_local_cfg", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ")", ")", "\n", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "1", ",", "\n", "1", ",", "\n", "dilation", ",", "\n", "style", "=", "style", ",", "\n", "inflate", "=", "(", "inflate", "[", "i", "]", "==", "1", ")", ",", "\n", "inflate_style", "=", "inflate_style", ",", "\n", "non_local", "=", "(", "non_local", "[", "i", "]", "==", "1", ")", ",", "\n", "non_local_cfg", "=", "non_local_cfg", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "with_cp", "=", "with_cp", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway.inflate_weights": [[204, 259], ["mmcv.runner._load_checkpoint", "resnet3d_slowfast.ResNet3dPathway.named_modules", "isinstance", "set", "set", "logger.info", "mmcv.runner._load_checkpoint.keys", "name.replace", "logger.warning", "resnet3d_slowfast.ResNet3dPathway._inflate_conv_params", "logger.warning", "resnet3d_slowfast.ResNet3dPathway._inflate_bn_params"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway._inflate_conv_params", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d.ResNet3d._inflate_bn_params"], ["", "def", "inflate_weights", "(", "self", ",", "logger", ")", ":", "\n", "        ", "\"\"\"Inflate the resnet2d parameters to resnet3d pathway.\n\n        The differences between resnet3d and resnet2d mainly lie in an extra\n        axis of conv kernel. To utilize the pretrained parameters in 2d model,\n        the weight of conv2d models should be inflated to fit in the shapes of\n        the 3d counterpart. For pathway the ``lateral_connection`` part should\n        not be inflated from 2d weights.\n\n        Args:\n            logger (logging.Logger): The logger used to print\n                debugging infomation.\n        \"\"\"", "\n", "\n", "state_dict_r2d", "=", "_load_checkpoint", "(", "self", ".", "pretrained", ")", "\n", "if", "'state_dict'", "in", "state_dict_r2d", ":", "\n", "            ", "state_dict_r2d", "=", "state_dict_r2d", "[", "'state_dict'", "]", "\n", "\n", "", "inflated_param_names", "=", "[", "]", "\n", "for", "name", ",", "module", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "'lateral'", "in", "name", ":", "\n", "                ", "continue", "\n", "", "if", "isinstance", "(", "module", ",", "ConvModule", ")", ":", "\n", "# we use a ConvModule to wrap conv+bn+relu layers, thus the", "\n", "# name mapping is needed", "\n", "                ", "if", "'downsample'", "in", "name", ":", "\n", "# layer{X}.{Y}.downsample.conv->layer{X}.{Y}.downsample.0", "\n", "                    ", "original_conv_name", "=", "name", "+", "'.0'", "\n", "# layer{X}.{Y}.downsample.bn->layer{X}.{Y}.downsample.1", "\n", "original_bn_name", "=", "name", "+", "'.1'", "\n", "", "else", ":", "\n", "# layer{X}.{Y}.conv{n}.conv->layer{X}.{Y}.conv{n}", "\n", "                    ", "original_conv_name", "=", "name", "\n", "# layer{X}.{Y}.conv{n}.bn->layer{X}.{Y}.bn{n}", "\n", "original_bn_name", "=", "name", ".", "replace", "(", "'conv'", ",", "'bn'", ")", "\n", "", "if", "original_conv_name", "+", "'.weight'", "not", "in", "state_dict_r2d", ":", "\n", "                    ", "logger", ".", "warning", "(", "f'Module not exist in the state_dict_r2d'", "\n", "f': {original_conv_name}'", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_inflate_conv_params", "(", "module", ".", "conv", ",", "state_dict_r2d", ",", "\n", "original_conv_name", ",", "\n", "inflated_param_names", ")", "\n", "", "if", "original_bn_name", "+", "'.weight'", "not", "in", "state_dict_r2d", ":", "\n", "                    ", "logger", ".", "warning", "(", "f'Module not exist in the state_dict_r2d'", "\n", "f': {original_bn_name}'", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_inflate_bn_params", "(", "module", ".", "bn", ",", "state_dict_r2d", ",", "\n", "original_bn_name", ",", "\n", "inflated_param_names", ")", "\n", "\n", "# check if any parameters in the 2d checkpoint are not loaded", "\n", "", "", "", "remaining_names", "=", "set", "(", "\n", "state_dict_r2d", ".", "keys", "(", ")", ")", "-", "set", "(", "inflated_param_names", ")", "\n", "if", "remaining_names", ":", "\n", "            ", "logger", ".", "info", "(", "f'These parameters in the 2d checkpoint are not loaded'", "\n", "f': {remaining_names}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway._inflate_conv_params": [[261, 303], ["conv3d.weight.data.copy_", "inflated_param_names.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.data.unsqueeze().expand_as", "torch.cat.data.unsqueeze().expand_as", "getattr", "conv3d.bias.data.copy_", "inflated_param_names.append", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.cat.data.unsqueeze", "torch.cat.data.unsqueeze", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "", "def", "_inflate_conv_params", "(", "self", ",", "conv3d", ",", "state_dict_2d", ",", "module_name_2d", ",", "\n", "inflated_param_names", ")", ":", "\n", "        ", "\"\"\"Inflate a conv module from 2d to 3d.\n\n        The differences of conv modules betweene 2d and 3d in Pathway\n        mainly lie in the inplanes due to lateral connections. To fit the\n        shapes of the lateral connection counterpart, it will expand\n        parameters by concatting conv2d parameters and extra zero paddings.\n\n        Args:\n            conv3d (nn.Module): The destination conv3d module.\n            state_dict_2d (OrderedDict): The state dict of pretrained 2d model.\n            module_name_2d (str): The name of corresponding conv module in the\n                2d model.\n            inflated_param_names (list[str]): List of parameters that have been\n                inflated.\n        \"\"\"", "\n", "weight_2d_name", "=", "module_name_2d", "+", "'.weight'", "\n", "conv2d_weight", "=", "state_dict_2d", "[", "weight_2d_name", "]", "\n", "old_shape", "=", "conv2d_weight", ".", "shape", "\n", "new_shape", "=", "conv3d", ".", "weight", ".", "data", ".", "shape", "\n", "kernel_t", "=", "new_shape", "[", "2", "]", "\n", "if", "new_shape", "[", "1", "]", "!=", "old_shape", "[", "1", "]", ":", "\n", "# Inplanes may be different due to lateral connections", "\n", "            ", "new_channels", "=", "new_shape", "[", "1", "]", "-", "old_shape", "[", "1", "]", "\n", "pad_shape", "=", "old_shape", "\n", "pad_shape", "=", "pad_shape", "[", ":", "1", "]", "+", "(", "new_channels", ",", ")", "+", "pad_shape", "[", "2", ":", "]", "\n", "# Expand parameters by concat extra channels", "\n", "conv2d_weight", "=", "torch", ".", "cat", "(", "\n", "(", "conv2d_weight", ",", "\n", "torch", ".", "zeros", "(", "pad_shape", ")", ".", "type_as", "(", "conv2d_weight", ")", ".", "to", "(", "\n", "conv2d_weight", ".", "device", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "", "new_weight", "=", "conv2d_weight", ".", "data", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "conv3d", ".", "weight", ")", "/", "kernel_t", "\n", "conv3d", ".", "weight", ".", "data", ".", "copy_", "(", "new_weight", ")", "\n", "inflated_param_names", ".", "append", "(", "weight_2d_name", ")", "\n", "\n", "if", "getattr", "(", "conv3d", ",", "'bias'", ")", "is", "not", "None", ":", "\n", "            ", "bias_2d_name", "=", "module_name_2d", "+", "'.bias'", "\n", "conv3d", ".", "bias", ".", "data", ".", "copy_", "(", "state_dict_2d", "[", "bias_2d_name", "]", ")", "\n", "inflated_param_names", ".", "append", "(", "bias_2d_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway._freeze_stages": [[304, 325], ["range", "resnet3d_slowfast.ResNet3dPathway.conv1.eval", "resnet3d_slowfast.ResNet3dPathway.conv1.parameters", "getattr", "getattr.eval", "getattr.parameters", "getattr", "getattr.eval", "getattr.parameters", "len"], "methods", ["None"], ["", "", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prevent all the parameters from being optimized before\n        `self.frozen_stages`.\"\"\"", "\n", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "conv1", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "i", "!=", "len", "(", "self", ".", "res_layers", ")", "and", "self", ".", "lateral", ":", "\n", "# No fusion needed in the final stage", "\n", "                ", "lateral_name", "=", "self", ".", "lateral_connections", "[", "i", "-", "1", "]", "\n", "conv_lateral", "=", "getattr", "(", "self", ",", "lateral_name", ")", "\n", "conv_lateral", ".", "eval", "(", ")", "\n", "for", "param", "in", "conv_lateral", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dPathway.init_weights": [[326, 339], ["super().init_weights", "getattr", "getattr.modules", "isinstance", "mmcv.cnn.kaiming_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "", "", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "pretrained", "=", "pretrained", "\n", "\n", "# Override the init_weights of i3d", "\n", "", "super", "(", ")", ".", "init_weights", "(", ")", "\n", "for", "module_name", "in", "self", ".", "lateral_connections", ":", "\n", "            ", "layer", "=", "getattr", "(", "self", ",", "module_name", ")", "\n", "for", "m", "in", "layer", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "(", "nn", ".", "Conv3d", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dSlowFast.__init__": [[416, 452], ["dict", "dict", "torch.Module.__init__", "resnet3d_slowfast.build_pathway", "resnet3d_slowfast.build_pathway"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.build_pathway", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.build_pathway"], ["def", "__init__", "(", "self", ",", "\n", "pretrained", ",", "\n", "resample_rate", "=", "8", ",", "\n", "speed_ratio", "=", "8", ",", "\n", "channel_ratio", "=", "8", ",", "\n", "slow_pathway", "=", "dict", "(", "\n", "type", "=", "'resnet3d'", ",", "\n", "depth", "=", "50", ",", "\n", "pretrained", "=", "None", ",", "\n", "lateral", "=", "True", ",", "\n", "conv1_kernel", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "0", ",", "0", ",", "1", ",", "1", ")", ")", ",", "\n", "fast_pathway", "=", "dict", "(", "\n", "type", "=", "'resnet3d'", ",", "\n", "depth", "=", "50", ",", "\n", "pretrained", "=", "None", ",", "\n", "lateral", "=", "False", ",", "\n", "base_channels", "=", "8", ",", "\n", "conv1_kernel", "=", "(", "5", ",", "7", ",", "7", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "resample_rate", "=", "resample_rate", "\n", "self", ".", "speed_ratio", "=", "speed_ratio", "\n", "self", ".", "channel_ratio", "=", "channel_ratio", "\n", "\n", "if", "slow_pathway", "[", "'lateral'", "]", ":", "\n", "            ", "slow_pathway", "[", "'speed_ratio'", "]", "=", "speed_ratio", "\n", "slow_pathway", "[", "'channel_ratio'", "]", "=", "channel_ratio", "\n", "\n", "", "self", ".", "slow_path", "=", "build_pathway", "(", "slow_pathway", ")", "\n", "self", ".", "fast_path", "=", "build_pathway", "(", "fast_pathway", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dSlowFast.init_weights": [[453, 471], ["isinstance", "utils.get_root_logger", "mmcv.utils.print_log", "mmcv.runner.load_checkpoint", "resnet3d_slowfast.ResNet3dSlowFast.fast_path.init_weights", "resnet3d_slowfast.ResNet3dSlowFast.slow_path.init_weights", "TypeError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "init_weights", "(", "self", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "if", "pretrained", ":", "\n", "            ", "self", ".", "pretrained", "=", "pretrained", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "msg", "=", "f'load model from: {self.pretrained}'", "\n", "print_log", "(", "msg", ",", "logger", "=", "logger", ")", "\n", "# Directly load 3D model.", "\n", "load_checkpoint", "(", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "True", ",", "logger", "=", "logger", ")", "\n", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "# Init two branch seperately.", "\n", "            ", "self", ".", "fast_path", ".", "init_weights", "(", ")", "\n", "self", ".", "slow_path", ".", "init_weights", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.ResNet3dSlowFast.forward": [[472, 517], ["torch.functional.interpolate", "torch.functional.interpolate", "resnet3d_slowfast.ResNet3dSlowFast.slow_path.conv1", "resnet3d_slowfast.ResNet3dSlowFast.slow_path.maxpool", "torch.functional.interpolate", "torch.functional.interpolate", "resnet3d_slowfast.ResNet3dSlowFast.fast_path.conv1", "resnet3d_slowfast.ResNet3dSlowFast.fast_path.maxpool", "enumerate", "resnet3d_slowfast.ResNet3dSlowFast.slow_path.conv1_lateral", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "getattr", "getattr.", "getattr", "getattr.", "getattr", "getattr.", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            tuple[torch.Tensor]: The feature of the input samples extracted\n                by the backbone.\n        \"\"\"", "\n", "x_slow", "=", "nn", ".", "functional", ".", "interpolate", "(", "\n", "x", ",", "\n", "mode", "=", "'nearest'", ",", "\n", "scale_factor", "=", "(", "1.0", "/", "self", ".", "resample_rate", ",", "1.0", ",", "1.0", ")", ")", "\n", "x_slow", "=", "self", ".", "slow_path", ".", "conv1", "(", "x_slow", ")", "\n", "x_slow", "=", "self", ".", "slow_path", ".", "maxpool", "(", "x_slow", ")", "\n", "\n", "x_fast", "=", "nn", ".", "functional", ".", "interpolate", "(", "\n", "x", ",", "\n", "mode", "=", "'nearest'", ",", "\n", "scale_factor", "=", "(", "1.0", "/", "(", "self", ".", "resample_rate", "//", "self", ".", "speed_ratio", ")", ",", "1.0", ",", "\n", "1.0", ")", ")", "\n", "x_fast", "=", "self", ".", "fast_path", ".", "conv1", "(", "x_fast", ")", "\n", "x_fast", "=", "self", ".", "fast_path", ".", "maxpool", "(", "x_fast", ")", "\n", "\n", "if", "self", ".", "slow_path", ".", "lateral", ":", "\n", "            ", "x_fast_lateral", "=", "self", ".", "slow_path", ".", "conv1_lateral", "(", "x_fast", ")", "\n", "x_slow", "=", "torch", ".", "cat", "(", "(", "x_slow", ",", "x_fast_lateral", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "for", "i", ",", "layer_name", "in", "enumerate", "(", "self", ".", "slow_path", ".", "res_layers", ")", ":", "\n", "            ", "res_layer", "=", "getattr", "(", "self", ".", "slow_path", ",", "layer_name", ")", "\n", "x_slow", "=", "res_layer", "(", "x_slow", ")", "\n", "res_layer_fast", "=", "getattr", "(", "self", ".", "fast_path", ",", "layer_name", ")", "\n", "x_fast", "=", "res_layer_fast", "(", "x_fast", ")", "\n", "if", "(", "i", "!=", "len", "(", "self", ".", "slow_path", ".", "res_layers", ")", "-", "1", "\n", "and", "self", ".", "slow_path", ".", "lateral", ")", ":", "\n", "# No fusion needed in the final stage", "\n", "                ", "lateral_name", "=", "self", ".", "slow_path", ".", "lateral_connections", "[", "i", "]", "\n", "conv_lateral", "=", "getattr", "(", "self", ".", "slow_path", ",", "lateral_name", ")", "\n", "x_fast_lateral", "=", "conv_lateral", "(", "x_fast", ")", "\n", "x_slow", "=", "torch", ".", "cat", "(", "(", "x_slow", ",", "x_fast_lateral", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "out", "=", "(", "x_slow", ",", "x_fast", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowfast.build_pathway": [[347, 369], ["cfg.copy", "cfg.copy.pop", "pathway_cls", "TypeError", "KeyError", "isinstance"], "function", ["None"], ["def", "build_pathway", "(", "cfg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Build pathway.\n\n    Args:\n        cfg (None or dict): cfg should contain:\n            - type (str): identify conv layer type.\n\n    Returns:\n        nn.Module: Created pathway.\n    \"\"\"", "\n", "if", "not", "(", "isinstance", "(", "cfg", ",", "dict", ")", "and", "'type'", "in", "cfg", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'cfg must be a dict containing the key \"type\"'", ")", "\n", "", "cfg_", "=", "cfg", ".", "copy", "(", ")", "\n", "\n", "pathway_type", "=", "cfg_", ".", "pop", "(", "'type'", ")", "\n", "if", "pathway_type", "not", "in", "pathway_cfg", ":", "\n", "        ", "raise", "KeyError", "(", "f'Unrecognized pathway type {pathway_type}'", ")", "\n", "\n", "", "pathway_cls", "=", "pathway_cfg", "[", "pathway_type", "]", "\n", "pathway", "=", "pathway_cls", "(", "*", "args", ",", "**", "kwargs", ",", "**", "cfg_", ")", "\n", "\n", "return", "pathway", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_csn.CSNBottleneck3d.__init__": [[34, 66], ["resnet3d.Bottleneck3d.__init__", "bool", "mmcv.cnn.ConvModule", "conv2.append", "torch.Sequential", "conv2.append", "torch.Conv3d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "*", "args", ",", "\n", "bottleneck_mode", "=", "'ir'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CSNBottleneck3d", ",", "self", ")", ".", "__init__", "(", "inplanes", ",", "planes", ",", "*", "args", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "bottleneck_mode", "=", "bottleneck_mode", "\n", "conv2", "=", "[", "]", "\n", "if", "self", ".", "bottleneck_mode", "==", "'ip'", ":", "\n", "            ", "conv2", ".", "append", "(", "\n", "nn", ".", "Conv3d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "", "conv2_kernel_size", "=", "self", ".", "conv2", ".", "conv", ".", "kernel_size", "\n", "conv2_stride", "=", "self", ".", "conv2", ".", "conv", ".", "stride", "\n", "conv2_padding", "=", "self", ".", "conv2", ".", "conv", ".", "padding", "\n", "conv2_dilation", "=", "self", ".", "conv2", ".", "conv", ".", "dilation", "\n", "conv2_bias", "=", "bool", "(", "self", ".", "conv2", ".", "conv", ".", "bias", ")", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "planes", ",", "\n", "planes", ",", "\n", "conv2_kernel_size", ",", "\n", "stride", "=", "conv2_stride", ",", "\n", "padding", "=", "conv2_padding", ",", "\n", "dilation", "=", "conv2_dilation", ",", "\n", "bias", "=", "conv2_bias", ",", "\n", "conv_cfg", "=", "self", ".", "conv_cfg", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ",", "\n", "groups", "=", "planes", ")", "\n", "conv2", ".", "append", "(", "self", ".", "conv2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "*", "conv2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_csn.ResNet3dCSN.__init__": [[104, 138], ["dict", "resnet3d.ResNet3d.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "pretrained", ",", "\n", "temporal_strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "conv1_kernel", "=", "(", "3", ",", "7", ",", "7", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ",", "eps", "=", "1e-3", ")", ",", "\n", "inflate_style", "=", "'3x3x3'", ",", "\n", "bottleneck_mode", "=", "'ir'", ",", "\n", "bn_frozen", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "arch_settings", "=", "{", "\n", "# 18: (BasicBlock3d, (2, 2, 2, 2)),", "\n", "# 34: (BasicBlock3d, (3, 4, 6, 3)),", "\n", "50", ":", "(", "CSNBottleneck3d", ",", "(", "3", ",", "4", ",", "6", ",", "3", ")", ")", ",", "\n", "101", ":", "(", "CSNBottleneck3d", ",", "(", "3", ",", "4", ",", "23", ",", "3", ")", ")", ",", "\n", "152", ":", "(", "CSNBottleneck3d", ",", "(", "3", ",", "8", ",", "36", ",", "3", ")", ")", "\n", "}", "\n", "self", ".", "bn_frozen", "=", "bn_frozen", "\n", "if", "bottleneck_mode", "not", "in", "[", "'ip'", ",", "'ir'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Bottleneck mode must be \"ip\" or \"ir\",'", "\n", "f'but got {bottleneck_mode}.'", ")", "\n", "", "super", "(", "ResNet3dCSN", ",", "self", ")", ".", "__init__", "(", "\n", "depth", ",", "\n", "pretrained", ",", "\n", "temporal_strides", "=", "temporal_strides", ",", "\n", "conv1_kernel", "=", "conv1_kernel", ",", "\n", "conv1_stride_t", "=", "conv1_stride_t", ",", "\n", "pool1_stride_t", "=", "pool1_stride_t", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "inflate_style", "=", "inflate_style", ",", "\n", "bottleneck_mode", "=", "bottleneck_mode", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_csn.ResNet3dCSN.train": [[139, 149], ["super().train", "resnet3d_csn.ResNet3dCSN._freeze_stages", "resnet3d_csn.ResNet3dCSN.modules", "isinstance", "m.eval", "m.parameters"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "ResNet3d", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "if", "self", ".", "bn_frozen", ":", "\n", "                        ", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                            ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.BasicBlock.__init__": [[34, 78], ["dict", "dict", "dict", "torch.Module.__init__", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["self", ".", "comp_idx", "=", "0", "\n", "self", ".", "prev_blob", "=", "prev_blob", "\n", "self", ".", "is_test", "=", "is_test", "\n", "self", ".", "bn_epsilon", "=", "bn_epsilon", "\n", "self", ".", "bn_momentum", "=", "bn_momentum", "\n", "self", ".", "no_bias", "=", "1", "if", "no_bias", "else", "0", "\n", "\n", "", "def", "add_conv", "(", "\n", "self", ",", "\n", "in_filters", ",", "\n", "out_filters", ",", "\n", "kernel", ",", "\n", "stride", "=", "1", ",", "\n", "group", "=", "1", ",", "\n", "pad", "=", "0", ",", "\n", ")", ":", "\n", "        ", "self", ".", "comp_idx", "+=", "1", "\n", "self", ".", "prev_blob", "=", "brew", ".", "conv", "(", "\n", "self", ".", "model", ",", "\n", "self", ".", "prev_blob", ",", "\n", "'comp_%d_conv_%d'", "%", "(", "self", ".", "comp_count", ",", "self", ".", "comp_idx", ")", ",", "\n", "in_filters", ",", "\n", "out_filters", ",", "\n", "weight_init", "=", "(", "\"MSRAFill\"", ",", "{", "}", ")", ",", "\n", "kernel", "=", "kernel", ",", "\n", "stride", "=", "stride", ",", "\n", "group", "=", "group", ",", "\n", "pad", "=", "pad", ",", "\n", "no_bias", "=", "self", ".", "no_bias", ",", "\n", ")", "\n", "return", "self", ".", "prev_blob", "\n", "\n", "", "def", "add_relu", "(", "self", ")", ":", "\n", "        ", "self", ".", "prev_blob", "=", "brew", ".", "relu", "(", "\n", "self", ".", "model", ",", "\n", "self", ".", "prev_blob", ",", "\n", "self", ".", "prev_blob", ",", "# in-place", "\n", ")", "\n", "return", "self", ".", "prev_blob", "\n", "\n", "", "def", "add_spatial_bn", "(", "self", ",", "num_filters", ")", ":", "\n", "        ", "self", ".", "prev_blob", "=", "brew", ".", "spatial_bn", "(", "\n", "self", ".", "model", ",", "\n", "self", ".", "prev_blob", ",", "\n", "'comp_%d_spatbn_%d'", "%", "(", "self", ".", "comp_count", ",", "self", ".", "comp_idx", ")", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.BasicBlock.forward": [[79, 100], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.conv2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["num_filters", ",", "\n", "epsilon", "=", "self", ".", "bn_epsilon", ",", "\n", "momentum", "=", "self", ".", "bn_momentum", ",", "\n", "is_test", "=", "self", ".", "is_test", ",", "\n", ")", "\n", "return", "self", ".", "prev_blob", "\n", "\n", "", "'''\n    Add a \"bottleneck\" component as described in He et. al. Figure 3 (right)\n    '''", "\n", "\n", "def", "add_bottleneck", "(", "\n", "self", ",", "\n", "input_filters", ",", "# num of feature maps from preceding layer", "\n", "base_filters", ",", "# num of filters internally in the component", "\n", "output_filters", ",", "# num of feature maps to output", "\n", "stride", "=", "1", ",", "\n", "group", "=", "1", ",", "\n", "spatial_batch_norm", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "comp_idx", "=", "0", "\n", "shortcut_blob", "=", "self", ".", "prev_blob", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.Bottleneck.__init__": [[128, 185], ["dict", "dict", "dict", "torch.Module.__init__", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["\n", "# 1x1", "\n", "last_conv", "=", "self", ".", "add_conv", "(", "base_filters", ",", "output_filters", ",", "kernel", "=", "1", ")", "\n", "if", "spatial_batch_norm", ":", "\n", "            ", "last_conv", "=", "self", ".", "add_spatial_bn", "(", "output_filters", ")", "\n", "\n", "# Summation with input signal (shortcut)", "\n", "# When the number of feature maps mismatch between the input", "\n", "# and output (this usually happens when the residual stage", "\n", "# changes), we need to do a projection for the short cut", "\n", "", "if", "output_filters", "!=", "input_filters", ":", "\n", "            ", "shortcut_blob", "=", "brew", ".", "conv", "(", "\n", "self", ".", "model", ",", "\n", "shortcut_blob", ",", "\n", "'shortcut_projection_%d'", "%", "self", ".", "comp_count", ",", "\n", "input_filters", ",", "\n", "output_filters", ",", "\n", "weight_init", "=", "(", "\"MSRAFill\"", ",", "{", "}", ")", ",", "\n", "kernel", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "no_bias", "=", "self", ".", "no_bias", ",", "\n", ")", "\n", "if", "spatial_batch_norm", ":", "\n", "                ", "shortcut_blob", "=", "brew", ".", "spatial_bn", "(", "\n", "self", ".", "model", ",", "\n", "shortcut_blob", ",", "\n", "'shortcut_projection_%d_spatbn'", "%", "self", ".", "comp_count", ",", "\n", "output_filters", ",", "\n", "epsilon", "=", "self", ".", "bn_epsilon", ",", "\n", "momentum", "=", "self", ".", "bn_momentum", ",", "\n", "is_test", "=", "self", ".", "is_test", ",", "\n", ")", "\n", "\n", "", "", "self", ".", "prev_blob", "=", "brew", ".", "sum", "(", "\n", "self", ".", "model", ",", "[", "shortcut_blob", ",", "last_conv", "]", ",", "\n", "'comp_%d_sum_%d'", "%", "(", "self", ".", "comp_count", ",", "self", ".", "comp_idx", ")", "\n", ")", "\n", "self", ".", "comp_idx", "+=", "1", "\n", "self", ".", "add_relu", "(", ")", "\n", "\n", "# Keep track of number of high level components if this ResNetBuilder", "\n", "self", ".", "comp_count", "+=", "1", "\n", "\n", "return", "output_filters", "\n", "\n", "", "def", "add_simple_block", "(", "\n", "self", ",", "\n", "input_filters", ",", "\n", "num_filters", ",", "\n", "down_sampling", "=", "False", ",", "\n", "spatial_batch_norm", "=", "True", "\n", ")", ":", "\n", "        ", "self", ".", "comp_idx", "=", "0", "\n", "shortcut_blob", "=", "self", ".", "prev_blob", "\n", "\n", "# 3x3", "\n", "self", ".", "add_conv", "(", "\n", "input_filters", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.Bottleneck.forward": [[186, 219], ["resnet.Bottleneck.relu", "resnet.Bottleneck.conv1", "resnet.Bottleneck.conv2", "resnet.Bottleneck.conv3", "torch.utils.checkpoint.checkpoint", "resnet.Bottleneck.forward._inner_forward"], "methods", ["None"], ["num_filters", ",", "\n", "kernel", "=", "3", ",", "\n", "stride", "=", "(", "1", "if", "down_sampling", "is", "False", "else", "2", ")", ",", "\n", "pad", "=", "1", "\n", ")", "\n", "\n", "if", "spatial_batch_norm", ":", "\n", "            ", "self", ".", "add_spatial_bn", "(", "num_filters", ")", "\n", "", "self", ".", "add_relu", "(", ")", "\n", "\n", "last_conv", "=", "self", ".", "add_conv", "(", "num_filters", ",", "num_filters", ",", "kernel", "=", "3", ",", "pad", "=", "1", ")", "\n", "if", "spatial_batch_norm", ":", "\n", "            ", "last_conv", "=", "self", ".", "add_spatial_bn", "(", "num_filters", ")", "\n", "\n", "# Increase of dimensions, need a projection for the shortcut", "\n", "", "if", "(", "num_filters", "!=", "input_filters", ")", ":", "\n", "            ", "shortcut_blob", "=", "brew", ".", "conv", "(", "\n", "self", ".", "model", ",", "\n", "shortcut_blob", ",", "\n", "'shortcut_projection_%d'", "%", "self", ".", "comp_count", ",", "\n", "input_filters", ",", "\n", "num_filters", ",", "\n", "weight_init", "=", "(", "\"MSRAFill\"", ",", "{", "}", ")", ",", "\n", "kernel", "=", "1", ",", "\n", "stride", "=", "(", "1", "if", "down_sampling", "is", "False", "else", "2", ")", ",", "\n", "no_bias", "=", "self", ".", "no_bias", ",", "\n", ")", "\n", "if", "spatial_batch_norm", ":", "\n", "                ", "shortcut_blob", "=", "brew", ".", "spatial_bn", "(", "\n", "self", ".", "model", ",", "\n", "shortcut_blob", ",", "\n", "'shortcut_projection_%d_spatbn'", "%", "self", ".", "comp_count", ",", "\n", "num_filters", ",", "\n", "epsilon", "=", "1e-3", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet.__init__": [[333, 403], ["dict", "dict", "dict", "torch.Module.__init__", "resnet.ResNet._make_stem_layer", "enumerate", "KeyError", "max", "len", "len", "resnet.make_res_layer", "resnet.ResNet.add_module", "resnet.ResNet.res_layers.append", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._make_stem_layer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.make_res_layer"], ["pad", "=", "3", ",", "\n", "no_bias", "=", "no_bias", "\n", ")", "\n", "\n", "bn_blob", "=", "brew", ".", "spatial_bn", "(", "\n", "model", ",", "\n", "conv_blob", ",", "\n", "'conv1_spatbn_relu'", ",", "\n", "num_filters", "[", "0", "]", ",", "\n", "epsilon", "=", "bn_epsilon", ",", "\n", "momentum", "=", "bn_momentum", ",", "\n", "is_test", "=", "is_test", "\n", ")", "\n", "relu_blob", "=", "brew", ".", "relu", "(", "model", ",", "bn_blob", ",", "bn_blob", ")", "\n", "max_pool", "=", "brew", ".", "max_pool", "(", "model", ",", "relu_blob", ",", "'pool1'", ",", "kernel", "=", "3", ",", "stride", "=", "2", ",", "pad", "=", "1", ")", "\n", "\n", "# Residual blocks...", "\n", "builder", "=", "ResNetBuilder", "(", "model", ",", "max_pool", ",", "no_bias", "=", "no_bias", ",", "\n", "is_test", "=", "is_test", ",", "bn_epsilon", "=", "1e-5", ",", "bn_momentum", "=", "0.9", ")", "\n", "\n", "inner_dim", "=", "num_groups", "*", "num_width_per_group", "\n", "\n", "# 4 different kinds of residual blocks", "\n", "for", "residual_idx", "in", "range", "(", "4", ")", ":", "\n", "        ", "residual_num", "=", "num_blocks", "[", "residual_idx", "]", "\n", "residual_stride", "=", "strides", "[", "residual_idx", "]", "\n", "dim_in", "=", "num_filters", "[", "residual_idx", "]", "\n", "\n", "for", "blk_idx", "in", "range", "(", "residual_num", ")", ":", "\n", "            ", "dim_in", "=", "builder", ".", "add_bottleneck", "(", "\n", "dim_in", ",", "\n", "inner_dim", ",", "\n", "num_filters", "[", "residual_idx", "+", "1", "]", ",", "# dim out", "\n", "stride", "=", "residual_stride", "if", "blk_idx", "==", "0", "else", "1", ",", "\n", "group", "=", "num_groups", ",", "\n", ")", "\n", "\n", "", "inner_dim", "*=", "2", "\n", "\n", "# Final layers", "\n", "", "final_avg", "=", "brew", ".", "average_pool", "(", "\n", "model", ",", "\n", "builder", ".", "prev_blob", ",", "\n", "'final_avg'", ",", "\n", "kernel", "=", "final_avg_kernel", ",", "\n", "stride", "=", "1", ",", "\n", "global_pooling", "=", "True", ",", "\n", ")", "\n", "\n", "# Final dimension of the \"image\" is reduced to 7x7", "\n", "last_out", "=", "brew", ".", "fc", "(", "\n", "model", ",", "final_avg", ",", "'last_out_L{}'", ".", "format", "(", "num_labels", ")", ",", "num_features", ",", "num_labels", "\n", ")", "\n", "\n", "if", "no_loss", ":", "\n", "        ", "return", "last_out", "\n", "\n", "# If we create model for training, use softmax-with-loss", "\n", "", "if", "(", "label", "is", "not", "None", ")", ":", "\n", "        ", "(", "softmax", ",", "loss", ")", "=", "model", ".", "SoftmaxWithLoss", "(", "\n", "[", "last_out", ",", "label", "]", ",", "\n", "[", "\"softmax\"", ",", "\"loss\"", "]", ",", "\n", ")", "\n", "\n", "return", "(", "softmax", ",", "loss", ")", "\n", "", "else", ":", "\n", "# For inference, we just return softmax", "\n", "        ", "return", "brew", ".", "softmax", "(", "model", ",", "last_out", ",", "\"softmax\"", ")", "\n", "\n", "\n", "# The conv1 and final_avg kernel/stride args provide a basic mechanism for", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._make_stem_layer": [[404, 418], ["mmcv.cnn.ConvModule", "torch.MaxPool2d"], "methods", ["None"], ["# adapting resnet50 for different sizes of input images.", "\n", "", "", "def", "create_resnet50", "(", "\n", "model", ",", "\n", "data", ",", "\n", "num_input_channels", ",", "\n", "num_labels", ",", "\n", "label", "=", "None", ",", "\n", "is_test", "=", "False", ",", "\n", "no_loss", "=", "False", ",", "\n", "no_bias", "=", "0", ",", "\n", "conv1_kernel", "=", "7", ",", "\n", "conv1_stride", "=", "2", ",", "\n", "final_avg_kernel", "=", "7", ",", "\n", ")", ":", "\n", "# resnet50 is a special case for ResNeXt50-1x64d", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._load_conv_params": [[419, 444], ["conv.weight.data.copy_", "loaded_param_names.append", "getattr", "conv.bias.data.copy_", "loaded_param_names.append"], "methods", ["None"], ["    ", "return", "create_resnext", "(", "\n", "model", ",", "\n", "data", ",", "\n", "num_input_channels", ",", "\n", "num_labels", ",", "\n", "num_layers", "=", "50", ",", "\n", "num_groups", "=", "1", ",", "\n", "num_width_per_group", "=", "64", ",", "\n", "label", "=", "label", ",", "\n", "is_test", "=", "is_test", ",", "\n", "no_loss", "=", "no_loss", ",", "\n", "no_bias", "=", "no_bias", ",", "\n", "conv1_kernel", "=", "conv1_kernel", ",", "\n", "conv1_stride", "=", "conv1_stride", ",", "\n", "final_avg_kernel", "=", "final_avg_kernel", ",", "\n", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._load_bn_params": [[445, 474], ["bn.named_parameters", "bn.named_buffers", "param.data.copy_", "loaded_param_names.append", "param.data.copy_", "loaded_param_names.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._load_torchvision_checkpoint": [[475, 507], ["mmcv.runner._load_checkpoint", "resnet.ResNet.named_modules", "isinstance", "set", "set", "logger.info", "resnet.ResNet._load_conv_params", "resnet.ResNet._load_bn_params", "mmcv.runner._load_checkpoint.keys", "name.replace"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._load_conv_params", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._load_bn_params"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet.init_weights": [[509, 529], ["isinstance", "utils.get_root_logger", "resnet.ResNet._load_torchvision_checkpoint", "mmcv.runner.load_checkpoint", "resnet.ResNet.modules", "TypeError", "isinstance", "mmcv.cnn.kaiming_init", "isinstance", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._load_torchvision_checkpoint"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet.forward": [[530, 552], ["resnet.ResNet.conv1", "resnet.ResNet.maxpool", "enumerate", "tuple", "getattr", "getattr.", "len", "outs.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._freeze_stages": [[553, 567], ["range", "resnet.ResNet.conv1.bn.eval", "resnet.ResNet.conv1.modules", "getattr", "getattr.eval", "getattr.parameters", "getattr.parameters"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._partial_bn": [[568, 580], ["utils.get_root_logger", "utils.get_root_logger.info", "resnet.ResNet.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet.train": [[581, 591], ["super().train", "resnet.ResNet._freeze_stages", "resnet.ResNet.modules", "resnet.ResNet._partial_bn", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.ResNet._partial_bn"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet.make_res_layer": [[221, 293], ["layers.append", "range", "torch.Sequential", "mmcv.cnn.ConvModule", "block", "layers.append", "block"], "function", ["None"], [")", "\n", "\n", "", "", "self", ".", "prev_blob", "=", "brew", ".", "sum", "(", "\n", "self", ".", "model", ",", "[", "shortcut_blob", ",", "last_conv", "]", ",", "\n", "'comp_%d_sum_%d'", "%", "(", "self", ".", "comp_count", ",", "self", ".", "comp_idx", ")", "\n", ")", "\n", "self", ".", "comp_idx", "+=", "1", "\n", "self", ".", "add_relu", "(", ")", "\n", "\n", "# Keep track of number of high level components if this ResNetBuilder", "\n", "self", ".", "comp_count", "+=", "1", "\n", "\n", "\n", "", "", "def", "create_resnet_32x32", "(", "\n", "model", ",", "data", ",", "num_input_channels", ",", "num_groups", ",", "num_labels", ",", "is_test", "=", "False", "\n", ")", ":", "\n", "    ", "'''\n    Create residual net for smaller images (sec 4.2 of He et. al (2015))\n    num_groups = 'n' in the paper\n    '''", "\n", "# conv1 + maxpool", "\n", "brew", ".", "conv", "(", "\n", "model", ",", "data", ",", "'conv1'", ",", "num_input_channels", ",", "16", ",", "kernel", "=", "3", ",", "stride", "=", "1", "\n", ")", "\n", "brew", ".", "spatial_bn", "(", "\n", "model", ",", "'conv1'", ",", "'conv1_spatbn'", ",", "16", ",", "epsilon", "=", "1e-3", ",", "is_test", "=", "is_test", "\n", ")", "\n", "brew", ".", "relu", "(", "model", ",", "'conv1_spatbn'", ",", "'relu1'", ")", "\n", "\n", "# Number of blocks as described in sec 4.2", "\n", "filters", "=", "[", "16", ",", "32", ",", "64", "]", "\n", "\n", "builder", "=", "ResNetBuilder", "(", "model", ",", "'relu1'", ",", "no_bias", "=", "0", ",", "is_test", "=", "is_test", ")", "\n", "prev_filters", "=", "16", "\n", "for", "groupidx", "in", "range", "(", "0", ",", "3", ")", ":", "\n", "        ", "for", "blockidx", "in", "range", "(", "0", ",", "2", "*", "num_groups", ")", ":", "\n", "            ", "builder", ".", "add_simple_block", "(", "\n", "prev_filters", "if", "blockidx", "==", "0", "else", "filters", "[", "groupidx", "]", ",", "\n", "filters", "[", "groupidx", "]", ",", "\n", "down_sampling", "=", "(", "True", "if", "blockidx", "==", "0", "and", "\n", "groupidx", ">", "0", "else", "False", ")", ")", "\n", "", "prev_filters", "=", "filters", "[", "groupidx", "]", "\n", "\n", "# Final layers", "\n", "", "brew", ".", "average_pool", "(", "\n", "model", ",", "builder", ".", "prev_blob", ",", "'final_avg'", ",", "kernel", "=", "8", ",", "stride", "=", "1", "\n", ")", "\n", "brew", ".", "fc", "(", "model", ",", "'final_avg'", ",", "'last_out'", ",", "64", ",", "num_labels", ")", "\n", "softmax", "=", "brew", ".", "softmax", "(", "model", ",", "'last_out'", ",", "'softmax'", ")", "\n", "return", "softmax", "\n", "\n", "\n", "", "RESNEXT_BLOCK_CONFIG", "=", "{", "\n", "18", ":", "(", "2", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "34", ":", "(", "3", ",", "4", ",", "6", ",", "3", ")", ",", "\n", "50", ":", "(", "3", ",", "4", ",", "6", ",", "3", ")", ",", "\n", "101", ":", "(", "3", ",", "4", ",", "23", ",", "3", ")", ",", "\n", "152", ":", "(", "3", ",", "8", ",", "36", ",", "3", ")", ",", "\n", "200", ":", "(", "3", ",", "24", ",", "36", ",", "3", ")", ",", "\n", "}", "\n", "\n", "RESNEXT_STRIDES", "=", "[", "1", ",", "2", ",", "2", ",", "2", "]", "\n", "\n", "logging", ".", "basicConfig", "(", ")", "\n", "log", "=", "logging", ".", "getLogger", "(", "\"resnext_builder\"", ")", "\n", "log", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "\n", "# The conv1 and final_avg kernel/stride args provide a basic mechanism for", "\n", "# adapting resnet50 for different sizes of input images.", "\n", "def", "create_resnext", "(", "\n", "model", ",", "\n", "data", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.Bottleneck2dAudio.__init__": [[30, 86], ["torch.Module.__init__", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "torch.ReLU", "torch.ReLU", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "stride", "=", "2", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "factorize", "=", "True", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "planes", "=", "planes", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "factorize", "=", "factorize", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "\n", "self", ".", "conv1_stride", "=", "1", "\n", "self", ".", "conv2_stride", "=", "stride", "\n", "\n", "conv1_kernel_size", "=", "(", "1", ",", "1", ")", "\n", "conv1_padding", "=", "0", "\n", "conv2_kernel_size", "=", "(", "3", ",", "3", ")", "\n", "conv2_padding", "=", "(", "dilation", ",", "dilation", ")", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "conv1_kernel_size", ",", "\n", "padding", "=", "conv1_padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "planes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "conv2_kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "conv2_padding", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'ConvAudio'", ")", "if", "factorize", "else", "dict", "(", "\n", "type", "=", "'Conv'", ")", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ")", "\n", "self", ".", "conv3", "=", "ConvModule", "(", "\n", "2", "*", "planes", "if", "factorize", "else", "planes", ",", "\n", "planes", "*", "self", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.Bottleneck2dAudio.forward": [[87, 109], ["resnet_audio.Bottleneck2dAudio.relu", "resnet_audio.Bottleneck2dAudio.conv1", "resnet_audio.Bottleneck2dAudio.conv2", "resnet_audio.Bottleneck2dAudio.conv3", "torch.checkpoint", "torch.checkpoint", "resnet_audio.Bottleneck2dAudio.forward._inner_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "identity", "=", "x", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "out", "+=", "identity", "\n", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.__init__": [[157, 224], ["dict", "dict", "dict", "torch.Module.__init__", "resnet_audio.ResNetAudio._make_stem_layer", "enumerate", "KeyError", "torch.nn.modules.utils._ntuple", "torch.nn.modules.utils._ntuple", "resnet_audio.ResNetAudio.make_res_layer", "resnet_audio.ResNetAudio.add_module", "resnet_audio.ResNetAudio.res_layers.append", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._make_stem_layer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.make_res_layer"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "pretrained", ",", "\n", "in_channels", "=", "1", ",", "\n", "num_stages", "=", "4", ",", "\n", "base_channels", "=", "32", ",", "\n", "strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "conv1_kernel", "=", "9", ",", "\n", "conv1_stride", "=", "1", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "factorize", "=", "(", "1", ",", "1", ",", "0", ",", "0", ")", ",", "\n", "norm_eval", "=", "False", ",", "\n", "with_cp", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN2d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ",", "inplace", "=", "True", ")", ",", "\n", "zero_init_residual", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "depth", "not", "in", "self", ".", "arch_settings", ":", "\n", "            ", "raise", "KeyError", "(", "f'invalid depth {depth} for resnet'", ")", "\n", "", "self", ".", "depth", "=", "depth", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "base_channels", "=", "base_channels", "\n", "self", ".", "num_stages", "=", "num_stages", "\n", "assert", "1", "<=", "num_stages", "<=", "4", "\n", "self", ".", "dilations", "=", "dilations", "\n", "self", ".", "conv1_kernel", "=", "conv1_kernel", "\n", "self", ".", "conv1_stride", "=", "conv1_stride", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "self", ".", "stage_factorization", "=", "_ntuple", "(", "num_stages", ")", "(", "factorize", ")", "\n", "self", ".", "norm_eval", "=", "norm_eval", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "zero_init_residual", "=", "zero_init_residual", "\n", "\n", "self", ".", "block", ",", "stage_blocks", "=", "self", ".", "arch_settings", "[", "depth", "]", "\n", "self", ".", "stage_blocks", "=", "stage_blocks", "[", ":", "num_stages", "]", "\n", "self", ".", "inplanes", "=", "self", ".", "base_channels", "\n", "\n", "self", ".", "_make_stem_layer", "(", ")", "\n", "\n", "self", ".", "res_layers", "=", "[", "]", "\n", "for", "i", ",", "num_blocks", "in", "enumerate", "(", "self", ".", "stage_blocks", ")", ":", "\n", "            ", "stride", "=", "strides", "[", "i", "]", "\n", "dilation", "=", "dilations", "[", "i", "]", "\n", "planes", "=", "self", ".", "base_channels", "*", "2", "**", "i", "\n", "res_layer", "=", "self", ".", "make_res_layer", "(", "\n", "self", ".", "block", ",", "\n", "self", ".", "inplanes", ",", "\n", "planes", ",", "\n", "num_blocks", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "factorize", "=", "self", ".", "stage_factorization", "[", "i", "]", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "with_cp", "=", "with_cp", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "self", ".", "block", ".", "expansion", "\n", "layer_name", "=", "f'layer{i + 1}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "res_layer", ")", "\n", "self", ".", "res_layers", ".", "append", "(", "layer_name", ")", "\n", "\n", "", "self", ".", "feat_dim", "=", "self", ".", "block", ".", "expansion", "*", "self", ".", "base_channels", "*", "2", "**", "(", "\n", "len", "(", "self", ".", "stage_blocks", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.make_res_layer": [[225, 297], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "len", "mmcv.cnn.ConvModule", "block", "layers.append", "isinstance", "block"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_res_layer", "(", "block", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "blocks", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "factorize", "=", "1", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "\"\"\"Build residual layer for ResNetAudio.\n\n        Args:\n            block (nn.Module): Residual module to be built.\n            inplanes (int): Number of channels for the input feature\n                in each block.\n            planes (int): Number of channels for the output feature\n                in each block.\n            blocks (int): Number of residual blocks.\n            stride (Sequence[int]): Strides of residual blocks of each stage.\n                Default: (1, 2, 2, 2).\n            dilation (int): Spacing between kernel elements. Default: 1.\n            factorize (int | Sequence[int]): Determine whether to factorize\n                for each block. Default: 1.\n            norm_cfg (dict):\n                Config for norm layers. required keys are `type` and\n                `requires_grad`. Default: None.\n            with_cp (bool): Use checkpoint or not. Using checkpoint will save\n                some memory while slowing down the training speed.\n                Default: False.\n\n        Returns:\n            A residual layer for the given config.\n        \"\"\"", "\n", "factorize", "=", "factorize", "if", "not", "isinstance", "(", "\n", "factorize", ",", "int", ")", "else", "(", "factorize", ",", ")", "*", "blocks", "\n", "assert", "len", "(", "factorize", ")", "==", "blocks", "\n", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "ConvModule", "(", "\n", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "stride", ",", "\n", "dilation", ",", "\n", "downsample", ",", "\n", "factorize", "=", "(", "factorize", "[", "0", "]", "==", "1", ")", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "with_cp", "=", "with_cp", ")", ")", "\n", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "1", ",", "\n", "dilation", ",", "\n", "factorize", "=", "(", "factorize", "[", "i", "]", "==", "1", ")", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "with_cp", "=", "with_cp", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._make_stem_layer": [[298, 310], ["mmcv.cnn.ConvModule", "dict"], "methods", ["None"], ["", "def", "_make_stem_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct the stem layers consists of a conv+norm+act module and a\n        pooling layer.\"\"\"", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "base_channels", ",", "\n", "kernel_size", "=", "self", ".", "conv1_kernel", ",", "\n", "stride", "=", "self", ".", "conv1_stride", ",", "\n", "bias", "=", "False", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'ConvAudio'", ",", "op", "=", "'sum'", ")", ",", "\n", "norm_cfg", "=", "self", ".", "norm_cfg", ",", "\n", "act_cfg", "=", "self", ".", "act_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages": [[311, 325], ["range", "resnet_audio.ResNetAudio.conv1.bn.eval", "getattr", "getattr.eval", "getattr.parameters", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prevent all the parameters from being optimized before\n        ``self.frozen_stages``.\"\"\"", "\n", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "self", ".", "conv1", ".", "bn", ".", "eval", "(", ")", "\n", "for", "m", "in", "[", "self", ".", "conv1", ".", "conv", ",", "self", ".", "conv1", ".", "bn", "]", ":", "\n", "                ", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.init_weights": [[326, 349], ["isinstance", "utils.get_root_logger", "utils.get_root_logger.info", "mmcv.runner.load_checkpoint", "resnet_audio.ResNetAudio.modules", "TypeError", "isinstance", "resnet_audio.ResNetAudio.modules", "mmcv.cnn.kaiming_init", "isinstance", "isinstance", "mmcv.cnn.constant_init", "mmcv.cnn.constant_init"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger"], ["", "", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "logger", ".", "info", "(", "f'load model from: {self.pretrained}'", ")", "\n", "\n", "load_checkpoint", "(", "self", ",", "self", ".", "pretrained", ",", "strict", "=", "False", ",", "logger", "=", "logger", ")", "\n", "\n", "", "elif", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "constant_init", "(", "m", ",", "1", ")", "\n", "\n", "", "", "if", "self", ".", "zero_init_residual", ":", "\n", "                ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "m", ",", "Bottleneck2dAudio", ")", ":", "\n", "                        ", "constant_init", "(", "m", ".", "conv3", ".", "bn", ",", "0", ")", "\n", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.forward": [[350, 365], ["resnet_audio.ResNetAudio.conv1", "getattr", "getattr."], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The feature of the input samples extracted\n            by the backbone.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "for", "layer_name", "in", "self", ".", "res_layers", ":", "\n", "            ", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "x", "=", "res_layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train": [[366, 374], ["super().train", "resnet_audio.ResNetAudio._freeze_stages", "resnet_audio.ResNetAudio.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Set the optimization status when training.\"\"\"", "\n", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet3d_slowonly.ResNet3dSlowOnly.__init__": [[29, 49], ["resnet3d_slowfast.ResNet3dPathway.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "*", "args", ",", "\n", "lateral", "=", "False", ",", "\n", "conv1_kernel", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "0", ",", "0", ",", "1", ",", "1", ")", ",", "\n", "with_pool2", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "lateral", "=", "lateral", ",", "\n", "conv1_kernel", "=", "conv1_kernel", ",", "\n", "conv1_stride_t", "=", "conv1_stride_t", ",", "\n", "pool1_stride_t", "=", "pool1_stride_t", ",", "\n", "inflate", "=", "inflate", ",", "\n", "with_pool2", "=", "with_pool2", ",", "\n", "**", "kwargs", ")", "\n", "\n", "assert", "not", "self", ".", "lateral", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2_tsm.MobileNetV2TSM.__init__": [[18, 23], ["mobilenet_v2.MobileNetV2.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "num_segments", "=", "8", ",", "is_shift", "=", "True", ",", "shift_div", "=", "8", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "is_shift", "=", "is_shift", "\n", "self", ".", "shift_div", "=", "shift_div", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2_tsm.MobileNetV2TSM.make_temporal_shift": [[24, 33], ["mobilenet_v2_tsm.MobileNetV2TSM.modules", "isinstance", "resnet_tsm.TemporalShift", "len"], "methods", ["None"], ["", "def", "make_temporal_shift", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make temporal shift for some layers.\"\"\"", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "InvertedResidual", ")", "and", "len", "(", "m", ".", "conv", ")", "==", "3", "and", "m", ".", "use_res_connect", ":", "\n", "                ", "m", ".", "conv", "[", "0", "]", "=", "TemporalShift", "(", "\n", "m", ".", "conv", "[", "0", "]", ",", "\n", "num_segments", "=", "self", ".", "num_segments", ",", "\n", "shift_div", "=", "self", ".", "shift_div", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2_tsm.MobileNetV2TSM.init_weights": [[35, 41], ["super().init_weights", "mobilenet_v2_tsm.MobileNetV2TSM.make_temporal_shift"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.mobilenet_v2_tsm.MobileNetV2TSM.make_temporal_shift"], ["", "", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters either from existing checkpoint or from\n        scratch.\"\"\"", "\n", "super", "(", ")", ".", "init_weights", "(", ")", "\n", "if", "self", ".", "is_shift", ":", "\n", "            ", "self", ".", "make_temporal_shift", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.roi_extractors.single_straight3d.SingleRoIExtractor3D.__init__": [[51, 87], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "RoIPool", "RoIAlign"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "roi_layer_type", "=", "'RoIAlign'", ",", "\n", "featmap_stride", "=", "16", ",", "\n", "output_size", "=", "16", ",", "\n", "sampling_ratio", "=", "0", ",", "\n", "pool_mode", "=", "'avg'", ",", "\n", "aligned", "=", "True", ",", "\n", "with_temporal_pool", "=", "True", ",", "\n", "temporal_pool_mode", "=", "'avg'", ",", "\n", "with_global", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "roi_layer_type", "=", "roi_layer_type", "\n", "assert", "self", ".", "roi_layer_type", "in", "[", "'RoIPool'", ",", "'RoIAlign'", "]", "\n", "self", ".", "featmap_stride", "=", "featmap_stride", "\n", "self", ".", "spatial_scale", "=", "1.", "/", "self", ".", "featmap_stride", "\n", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "sampling_ratio", "=", "sampling_ratio", "\n", "self", ".", "pool_mode", "=", "pool_mode", "\n", "self", ".", "aligned", "=", "aligned", "\n", "\n", "self", ".", "with_temporal_pool", "=", "with_temporal_pool", "\n", "self", ".", "temporal_pool_mode", "=", "temporal_pool_mode", "\n", "\n", "self", ".", "with_global", "=", "with_global", "\n", "\n", "if", "self", ".", "roi_layer_type", "==", "'RoIPool'", ":", "\n", "            ", "self", ".", "roi_layer", "=", "RoIPool", "(", "self", ".", "output_size", ",", "self", ".", "spatial_scale", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "roi_layer", "=", "RoIAlign", "(", "\n", "self", ".", "output_size", ",", "\n", "self", ".", "spatial_scale", ",", "\n", "sampling_ratio", "=", "self", ".", "sampling_ratio", ",", "\n", "pool_mode", "=", "self", ".", "pool_mode", ",", "\n", "aligned", "=", "self", ".", "aligned", ")", "\n", "", "self", ".", "global_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "self", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.roi_extractors.single_straight3d.SingleRoIExtractor3D.init_weights": [[88, 90], ["None"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.roi_extractors.single_straight3d.SingleRoIExtractor3D.forward": [[92, 125], ["torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "range", "isinstance", "len", "max", "torch.cat().contiguous.size", "torch.cat().contiguous.size", "torch.cat().contiguous.size", "feat[].contiguous", "single_straight3d.SingleRoIExtractor3D.roi_layer", "roi_feats.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.interpolate().contiguous", "torch.interpolate().contiguous", "torch.interpolate().contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "single_straight3d.SingleRoIExtractor3D.global_pool", "rois[].type", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "roi_feat.contiguous.contiguous.contiguous", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "feat[].contiguous.contiguous", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "feat", ",", "rois", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "feat", ",", "tuple", ")", ":", "\n", "            ", "feat", "=", "(", "feat", ",", ")", "\n", "\n", "", "if", "len", "(", "feat", ")", ">=", "2", ":", "\n", "            ", "maxT", "=", "max", "(", "[", "x", ".", "shape", "[", "2", "]", "for", "x", "in", "feat", "]", ")", "\n", "max_shape", "=", "(", "maxT", ",", ")", "+", "feat", "[", "0", "]", ".", "shape", "[", "3", ":", "]", "\n", "# resize each feat to the largest shape (w. nearest)", "\n", "feat", "=", "[", "F", ".", "interpolate", "(", "x", ",", "max_shape", ")", ".", "contiguous", "(", ")", "for", "x", "in", "feat", "]", "\n", "\n", "", "if", "self", ".", "with_temporal_pool", ":", "\n", "            ", "if", "self", ".", "temporal_pool_mode", "==", "'avg'", ":", "\n", "                ", "feat", "=", "[", "torch", ".", "mean", "(", "x", ",", "2", ",", "keepdim", "=", "True", ")", "for", "x", "in", "feat", "]", "\n", "", "elif", "self", ".", "temporal_pool_mode", "==", "'max'", ":", "\n", "                ", "feat", "=", "[", "torch", ".", "max", "(", "x", ",", "2", ",", "keepdim", "=", "True", ")", "[", "0", "]", "for", "x", "in", "feat", "]", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "feat", "=", "torch", ".", "cat", "(", "feat", ",", "axis", "=", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "roi_feats", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "feat", ".", "size", "(", "2", ")", ")", ":", "\n", "            ", "frame_feat", "=", "feat", "[", ":", ",", ":", ",", "t", "]", ".", "contiguous", "(", ")", "\n", "roi_feat", "=", "self", ".", "roi_layer", "(", "frame_feat", ",", "rois", ")", "\n", "if", "self", ".", "with_global", ":", "\n", "                ", "global_feat", "=", "self", ".", "global_pool", "(", "frame_feat", ".", "contiguous", "(", ")", ")", "\n", "inds", "=", "rois", "[", ":", ",", "0", "]", ".", "type", "(", "torch", ".", "int64", ")", "\n", "global_feat", "=", "global_feat", "[", "inds", "]", "\n", "roi_feat", "=", "torch", ".", "cat", "(", "[", "roi_feat", ",", "global_feat", "]", ",", "dim", "=", "1", ")", "\n", "roi_feat", "=", "roi_feat", ".", "contiguous", "(", ")", "\n", "", "roi_feats", ".", "append", "(", "roi_feat", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "roi_feats", ",", "dim", "=", "2", ")", ",", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.base.BaseWeightedLoss.__init__": [[17, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["\n", "class", "BaseDataset", "(", "Dataset", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.base.BaseWeightedLoss._forward": [[21, 24], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.base.BaseWeightedLoss.forward": [[25, 45], ["base.BaseWeightedLoss._forward", "isinstance"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.forward": [[12, 52], ["pred.size", "torch.zeros", "torch.zeros", "range", "losses.view().contiguous.view().contiguous.view().contiguous", "torch.sort", "int", "torch.zeros", "range", "pred.size", "losses.view().contiguous.view().contiguous.size", "len", "ValueError", "max", "losses.view().contiguous.view().contiguous.size", "sorted_losses[].sum", "losses.view().contiguous.view().contiguous.view", "len"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "pred", ",", "labels", ",", "is_positive", ",", "ohem_ratio", ",", "group_size", ")", ":", "\n", "        ", "\"\"\"Calculate OHEM hinge loss.\n\n        Args:\n            pred (torch.Tensor): Predicted completeness score.\n            labels (torch.Tensor): Groundtruth class label.\n            is_positive (int): Set to 1 when proposals are positive and\n                set to -1 when proposals are incomplete.\n            ohem_ratio (float): Ratio of hard examples.\n            group_size (int): Number of proposals sampled per video.\n\n        Returns:\n            torch.Tensor: Returned class-wise hinge loss.\n        \"\"\"", "\n", "num_samples", "=", "pred", ".", "size", "(", "0", ")", "\n", "if", "num_samples", "!=", "len", "(", "labels", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'Number of samples should be equal to that '", "\n", "f'of labels, but got {num_samples} samples and '", "\n", "f'{len(labels)} labels.'", ")", "\n", "\n", "", "losses", "=", "torch", ".", "zeros", "(", "num_samples", ",", "device", "=", "pred", ".", "device", ")", "\n", "slopes", "=", "torch", ".", "zeros", "(", "num_samples", ",", "device", "=", "pred", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "losses", "[", "i", "]", "=", "max", "(", "0", ",", "1", "-", "is_positive", "*", "pred", "[", "i", ",", "labels", "[", "i", "]", "-", "1", "]", ")", "\n", "slopes", "[", "i", "]", "=", "-", "is_positive", "if", "losses", "[", "i", "]", "!=", "0", "else", "0", "\n", "\n", "", "losses", "=", "losses", ".", "view", "(", "-", "1", ",", "group_size", ")", ".", "contiguous", "(", ")", "\n", "sorted_losses", ",", "indices", "=", "torch", ".", "sort", "(", "losses", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "keep_length", "=", "int", "(", "group_size", "*", "ohem_ratio", ")", "\n", "loss", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "pred", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "losses", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "loss", "+=", "sorted_losses", "[", "i", ",", ":", "keep_length", "]", ".", "sum", "(", ")", "\n", "", "ctx", ".", "loss_index", "=", "indices", "[", ":", ",", ":", "keep_length", "]", "\n", "ctx", ".", "labels", "=", "labels", "\n", "ctx", ".", "slopes", "=", "slopes", "\n", "ctx", ".", "shape", "=", "pred", ".", "size", "(", ")", "\n", "ctx", ".", "group_size", "=", "group_size", "\n", "ctx", ".", "num_groups", "=", "losses", ".", "size", "(", "0", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.backward": [[53, 65], ["torch.zeros", "range", "torch.autograd.Variable"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "labels", "=", "ctx", ".", "labels", "\n", "slopes", "=", "ctx", ".", "slopes", "\n", "\n", "grad_in", "=", "torch", ".", "zeros", "(", "ctx", ".", "shape", ",", "device", "=", "ctx", ".", "slopes", ".", "device", ")", "\n", "for", "group", "in", "range", "(", "ctx", ".", "num_groups", ")", ":", "\n", "            ", "for", "idx", "in", "ctx", ".", "loss_index", "[", "group", "]", ":", "\n", "                ", "loc", "=", "idx", "+", "group", "*", "ctx", ".", "group_size", "\n", "grad_in", "[", "loc", ",", "labels", "[", "loc", "]", "-", "1", "]", "=", "(", "\n", "slopes", "[", "loc", "]", "*", "grad_output", ".", "data", "[", "0", "]", ")", "\n", "", "", "return", "torch", ".", "autograd", ".", "Variable", "(", "grad_in", ")", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.activity_loss": [[12, 29], ["torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "activity_loss", "(", "activity_score", ",", "labels", ",", "activity_indexer", ")", ":", "\n", "        ", "\"\"\"Activity Loss.\n\n        It will calculate activity loss given activity_score and label.\n\n        Args\uff1a\n            activity_score (torch.Tensor): Predicted activity score.\n            labels (torch.Tensor): Groundtruth class label.\n            activity_indexer (torch.Tensor): Index slices of proposals.\n\n        Returns:\n            torch.Tensor: Returned cross entropy loss.\n        \"\"\"", "\n", "pred", "=", "activity_score", "[", "activity_indexer", ",", ":", "]", "\n", "gt", "=", "labels", "[", "activity_indexer", "]", "\n", "return", "F", ".", "cross_entropy", "(", "pred", ",", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.completeness_loss": [[30, 80], ["pred.view.view.size", "pred.view.view.view", "gt.view.view.view", "pred[].contiguous().view", "pred[].contiguous().view", "ohem_hinge_loss.OHEMHingeLoss.apply", "ohem_hinge_loss.OHEMHingeLoss.apply", "pred[].contiguous().view.size", "int", "gt[].contiguous().view", "gt[].contiguous().view", "float", "pred[].contiguous", "pred[].contiguous", "pred[].contiguous().view.size", "gt[].contiguous", "gt[].contiguous"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "completeness_loss", "(", "completeness_score", ",", "\n", "labels", ",", "\n", "completeness_indexer", ",", "\n", "positive_per_video", ",", "\n", "incomplete_per_video", ",", "\n", "ohem_ratio", "=", "0.17", ")", ":", "\n", "        ", "\"\"\"Completeness Loss.\n\n        It will calculate completeness loss given completeness_score and label.\n\n        Args\uff1a\n            completeness_score (torch.Tensor): Predicted completeness score.\n            labels (torch.Tensor): Groundtruth class label.\n            completeness_indexer (torch.Tensor): Index slices of positive and\n                incomplete proposals.\n            positive_per_video (int): Number of positive proposals sampled\n                per video.\n            incomplete_per_video (int): Number of incomplete proposals sampled\n                pre video.\n            ohem_ratio (float): Ratio of online hard example mining.\n                Default: 0.17.\n\n        Returns:\n            torch.Tensor: Returned class-wise completeness loss.\n        \"\"\"", "\n", "pred", "=", "completeness_score", "[", "completeness_indexer", ",", ":", "]", "\n", "gt", "=", "labels", "[", "completeness_indexer", "]", "\n", "\n", "pred_dim", "=", "pred", ".", "size", "(", "1", ")", "\n", "pred", "=", "pred", ".", "view", "(", "-", "1", ",", "positive_per_video", "+", "incomplete_per_video", ",", "\n", "pred_dim", ")", "\n", "gt", "=", "gt", ".", "view", "(", "-", "1", ",", "positive_per_video", "+", "incomplete_per_video", ")", "\n", "\n", "# yapf:disable", "\n", "positive_pred", "=", "pred", "[", ":", ",", ":", "positive_per_video", ",", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "pred_dim", ")", "# noqa:E501", "\n", "incomplete_pred", "=", "pred", "[", ":", ",", "positive_per_video", ":", ",", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "pred_dim", ")", "# noqa:E501", "\n", "# yapf:enable", "\n", "\n", "positive_loss", "=", "OHEMHingeLoss", ".", "apply", "(", "\n", "positive_pred", ",", "gt", "[", ":", ",", ":", "positive_per_video", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "1", ",", "\n", "1.0", ",", "positive_per_video", ")", "\n", "incomplete_loss", "=", "OHEMHingeLoss", ".", "apply", "(", "\n", "incomplete_pred", ",", "gt", "[", ":", ",", "positive_per_video", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "\n", "-", "1", ",", "ohem_ratio", ",", "incomplete_per_video", ")", "\n", "num_positives", "=", "positive_pred", ".", "size", "(", "0", ")", "\n", "num_incompletes", "=", "int", "(", "incomplete_pred", ".", "size", "(", "0", ")", "*", "ohem_ratio", ")", "\n", "\n", "return", "(", "(", "positive_loss", "+", "incomplete_loss", ")", "/", "\n", "float", "(", "num_positives", "+", "num_incompletes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.classwise_regression_loss": [[81, 114], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.smooth_l1_loss", "torch.smooth_l1_loss", "torch.smooth_l1_loss", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "reg_target.view", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "classwise_regression_loss", "(", "bbox_pred", ",", "labels", ",", "bbox_targets", ",", "\n", "regression_indexer", ")", ":", "\n", "        ", "\"\"\"Classwise Regression Loss.\n\n        It will calculate classwise_regression loss given\n        class_reg_pred and targets.\n\n        Args\uff1a\n            bbox_pred (torch.Tensor): Predicted interval center and span\n                of positive proposals.\n            labels (torch.Tensor): Groundtruth class label.\n            bbox_targets (torch.Tensor): Groundtruth center and span\n                of positive proposals.\n            regression_indexer (torch.Tensor): Index slices of\n                positive proposals.\n\n        Returns:\n            torch.Tensor: Returned class-wise regression loss.\n        \"\"\"", "\n", "pred", "=", "bbox_pred", "[", "regression_indexer", ",", ":", ",", ":", "]", "\n", "gt", "=", "labels", "[", "regression_indexer", "]", "\n", "reg_target", "=", "bbox_targets", "[", "regression_indexer", ",", ":", "]", "\n", "\n", "class_idx", "=", "gt", ".", "data", "-", "1", "\n", "classwise_pred", "=", "pred", "[", ":", ",", "class_idx", ",", ":", "]", "\n", "classwise_reg_pred", "=", "torch", ".", "cat", "(", "\n", "(", "torch", ".", "diag", "(", "classwise_pred", "[", ":", ",", ":", ",", "0", "]", ")", ".", "view", "(", "\n", "-", "1", ",", "1", ")", ",", "torch", ".", "diag", "(", "classwise_pred", "[", ":", ",", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "loss", "=", "F", ".", "smooth_l1_loss", "(", "\n", "classwise_reg_pred", ".", "view", "(", "-", "1", ")", ",", "reg_target", ".", "view", "(", "-", "1", ")", ")", "*", "2", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.forward": [[115, 180], ["dict", "proposal_type.view.view.view", "labels.view.view.view", "int", "int", "ssn_loss.SSNLoss.activity_loss", "ssn_loss.SSNLoss.completeness_loss", "bbox_targets.view.view.view", "ssn_loss.SSNLoss.classwise_regression_loss"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.activity_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.completeness_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.classwise_regression_loss"], ["", "def", "forward", "(", "self", ",", "activity_score", ",", "completeness_score", ",", "bbox_pred", ",", "\n", "proposal_type", ",", "labels", ",", "bbox_targets", ",", "train_cfg", ")", ":", "\n", "        ", "\"\"\"Calculate Boundary Matching Network Loss.\n\n        Args:\n            activity_score (torch.Tensor): Predicted activity score.\n            completeness_score (torch.Tensor): Predicted completeness score.\n            bbox_pred (torch.Tensor): Predicted interval center and span\n                of positive proposals.\n            proposal_type (torch.Tensor): Type index slices of proposals.\n            labels (torch.Tensor): Groundtruth class label.\n            bbox_targets (torch.Tensor): Groundtruth center and span\n                of positive proposals.\n            train_cfg (dict): Config for training.\n\n        Returns:\n            dict([torch.Tensor, torch.Tensor, torch.Tensor]):\n                (loss_activity, loss_completeness, loss_reg).\n                Loss_activity is the activity loss, loss_completeness is\n                the class-wise completeness loss,\n                loss_reg is the class-wise regression loss.\n        \"\"\"", "\n", "self", ".", "sampler", "=", "train_cfg", ".", "ssn", ".", "sampler", "\n", "self", ".", "loss_weight", "=", "train_cfg", ".", "ssn", ".", "loss_weight", "\n", "losses", "=", "dict", "(", ")", "\n", "\n", "proposal_type", "=", "proposal_type", ".", "view", "(", "-", "1", ")", "\n", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "activity_indexer", "=", "(", "(", "proposal_type", "==", "0", ")", "+", "\n", "(", "proposal_type", "==", "2", ")", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "completeness_indexer", "=", "(", "(", "proposal_type", "==", "0", ")", "+", "\n", "(", "proposal_type", "==", "1", ")", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "total_ratio", "=", "(", "\n", "self", ".", "sampler", ".", "positive_ratio", "+", "self", ".", "sampler", ".", "background_ratio", "+", "\n", "self", ".", "sampler", ".", "incomplete_ratio", ")", "\n", "positive_per_video", "=", "int", "(", "self", ".", "sampler", ".", "num_per_video", "*", "\n", "(", "self", ".", "sampler", ".", "positive_ratio", "/", "total_ratio", ")", ")", "\n", "background_per_video", "=", "int", "(", "\n", "self", ".", "sampler", ".", "num_per_video", "*", "\n", "(", "self", ".", "sampler", ".", "background_ratio", "/", "total_ratio", ")", ")", "\n", "incomplete_per_video", "=", "(", "\n", "self", ".", "sampler", ".", "num_per_video", "-", "positive_per_video", "-", "\n", "background_per_video", ")", "\n", "\n", "losses", "[", "'loss_activity'", "]", "=", "self", ".", "activity_loss", "(", "activity_score", ",", "labels", ",", "\n", "activity_indexer", ")", "\n", "\n", "losses", "[", "'loss_completeness'", "]", "=", "self", ".", "completeness_loss", "(", "\n", "completeness_score", ",", "\n", "labels", ",", "\n", "completeness_indexer", ",", "\n", "positive_per_video", ",", "\n", "incomplete_per_video", ",", "\n", "ohem_ratio", "=", "positive_per_video", "/", "incomplete_per_video", ")", "\n", "losses", "[", "'loss_completeness'", "]", "*=", "self", ".", "loss_weight", ".", "comp_loss_weight", "\n", "\n", "if", "bbox_pred", "is", "not", "None", ":", "\n", "            ", "regression_indexer", "=", "(", "proposal_type", "==", "0", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "\n", "bbox_targets", "=", "bbox_targets", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "losses", "[", "'loss_reg'", "]", "=", "self", ".", "classwise_regression_loss", "(", "\n", "bbox_pred", ",", "labels", ",", "bbox_targets", ",", "regression_indexer", ")", "\n", "losses", "[", "'loss_reg'", "]", "*=", "self", ".", "loss_weight", ".", "reg_loss_weight", "\n", "\n", "", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.binary_logistic_regression_loss.BinaryLogisticRegressionLoss.forward": [[39, 62], ["binary_logistic_regression_loss.binary_logistic_regression_loss"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.binary_logistic_regression_loss.binary_logistic_regression_loss"], ["def", "forward", "(", "self", ",", "\n", "reg_score", ",", "\n", "label", ",", "\n", "threshold", "=", "0.5", ",", "\n", "ratio_range", "=", "(", "1.05", ",", "21", ")", ",", "\n", "eps", "=", "1e-5", ")", ":", "\n", "        ", "\"\"\"Calculate Binary Logistic Regression Loss.\n\n        Args:\n                reg_score (torch.Tensor): Predicted score by model.\n                label (torch.Tensor): Groundtruth labels.\n                threshold (float): Threshold for positive instances.\n                    Default: 0.5.\n                ratio_range (tuple): Lower bound and upper bound for ratio.\n                    Default: (1.05, 21)\n                eps (float): Epsilon for small value. Default: 1e-5.\n\n        Returns:\n                torch.Tensor: Returned binary logistic loss.\n        \"\"\"", "\n", "\n", "return", "binary_logistic_regression_loss", "(", "reg_score", ",", "label", ",", "threshold", ",", "\n", "ratio_range", ",", "eps", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.binary_logistic_regression_loss.binary_logistic_regression_loss": [[7, 29], ["label.view().to.view().to", "reg_score.contiguous().view.contiguous().view", "max", "len", "min", "torch.sum", "torch.sum", "max", "torch.mean", "torch.mean", "label.view().to.view", "reg_score.contiguous().view.contiguous", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["def", "binary_logistic_regression_loss", "(", "reg_score", ",", "\n", "label", ",", "\n", "threshold", "=", "0.5", ",", "\n", "ratio_range", "=", "(", "1.05", ",", "21", ")", ",", "\n", "eps", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"Binary Logistic Regression Loss.\"\"\"", "\n", "label", "=", "label", ".", "view", "(", "-", "1", ")", ".", "to", "(", "reg_score", ".", "device", ")", "\n", "reg_score", "=", "reg_score", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "pmask", "=", "(", "label", ">", "threshold", ")", ".", "float", "(", ")", ".", "to", "(", "reg_score", ".", "device", ")", "\n", "num_positive", "=", "max", "(", "torch", ".", "sum", "(", "pmask", ")", ",", "1", ")", "\n", "num_entries", "=", "len", "(", "label", ")", "\n", "ratio", "=", "num_entries", "/", "num_positive", "\n", "# clip ratio value between ratio_range", "\n", "ratio", "=", "min", "(", "max", "(", "ratio", ",", "ratio_range", "[", "0", "]", ")", ",", "ratio_range", "[", "1", "]", ")", "\n", "\n", "coef_0", "=", "0.5", "*", "ratio", "/", "(", "ratio", "-", "1", ")", "\n", "coef_1", "=", "0.5", "*", "ratio", "\n", "loss", "=", "coef_1", "*", "pmask", "*", "torch", ".", "log", "(", "reg_score", "+", "eps", ")", "+", "coef_0", "*", "(", "\n", "1.0", "-", "pmask", ")", "*", "torch", ".", "log", "(", "1.0", "-", "reg_score", "+", "eps", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "loss", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.hvu_loss.HVULoss.__init__": [[34, 60], ["base.BaseWeightedLoss.__init__", "range", "len", "len", "hvu_loss.HVULoss.category_startidx.append", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "categories", "=", "(", "'action'", ",", "'attribute'", ",", "'concept'", ",", "'event'", ",", "\n", "'object'", ",", "'scene'", ")", ",", "\n", "category_nums", "=", "(", "739", ",", "117", ",", "291", ",", "69", ",", "1678", ",", "248", ")", ",", "\n", "category_loss_weights", "=", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "loss_type", "=", "'all'", ",", "\n", "with_mask", "=", "False", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "loss_weight", "=", "1.0", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "loss_weight", ")", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "category_nums", "=", "category_nums", "\n", "self", ".", "category_loss_weights", "=", "category_loss_weights", "\n", "assert", "len", "(", "self", ".", "category_nums", ")", "==", "len", "(", "self", ".", "category_loss_weights", ")", "\n", "for", "category_loss_weight", "in", "self", ".", "category_loss_weights", ":", "\n", "            ", "assert", "category_loss_weight", ">=", "0", "\n", "", "self", ".", "loss_type", "=", "loss_type", "\n", "self", ".", "with_mask", "=", "with_mask", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "category_startidx", "=", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "category_nums", ")", "-", "1", ")", ":", "\n", "            ", "self", ".", "category_startidx", ".", "append", "(", "self", ".", "category_startidx", "[", "-", "1", "]", "+", "\n", "self", ".", "category_nums", "[", "i", "]", ")", "\n", "", "assert", "self", ".", "loss_type", "in", "[", "'individual'", ",", "'all'", "]", "\n", "assert", "self", ".", "reduction", "in", "[", "'mean'", ",", "'sum'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.hvu_loss.HVULoss._forward": [[61, 141], ["torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "dict", "zip", "sum", "sum", "losses.update", "ValueError", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "dict", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "hvu_loss.HVULoss.categories.index", "loss_weights.values", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "category_mask[].reshape", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "loss_weights.items", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss_weights.items", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "cls_score", ",", "label", ",", "mask", ",", "category_mask", ")", ":", "\n", "        ", "\"\"\"Forward function.\n\n        Args:\n            cls_score (torch.Tensor): The class score.\n            label (torch.Tensor): The ground truth label.\n            mask (torch.Tensor): The mask of tags. 0 indicates that the\n                category of this tag is missing in the label of the video.\n            category_mask (torch.Tensor): The category mask. For each sample,\n                it's a tensor with length `len(self.categories)`, denotes that\n                if the category is labeled for this video.\n\n        Returns:\n            torch.Tensor: The returned CrossEntropy loss.\n        \"\"\"", "\n", "\n", "if", "self", ".", "loss_type", "==", "'all'", ":", "\n", "            ", "loss_cls", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "cls_score", ",", "label", ",", "reduction", "=", "'none'", ")", "\n", "if", "self", ".", "with_mask", ":", "\n", "                ", "w_loss_cls", "=", "mask", "*", "loss_cls", "\n", "w_loss_cls", "=", "torch", ".", "sum", "(", "w_loss_cls", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "                    ", "w_loss_cls", "=", "w_loss_cls", "/", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", "\n", "", "w_loss_cls", "=", "torch", ".", "mean", "(", "w_loss_cls", ")", "\n", "return", "dict", "(", "loss_cls", "=", "w_loss_cls", ")", "\n", "\n", "", "if", "self", ".", "reduction", "==", "'sum'", ":", "\n", "                ", "loss_cls", "=", "torch", ".", "sum", "(", "loss_cls", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "dict", "(", "loss_cls", "=", "torch", ".", "mean", "(", "loss_cls", ")", ")", "\n", "\n", "", "if", "self", ".", "loss_type", "==", "'individual'", ":", "\n", "            ", "losses", "=", "{", "}", "\n", "loss_weights", "=", "{", "}", "\n", "for", "name", ",", "num", ",", "start_idx", "in", "zip", "(", "self", ".", "categories", ",", "\n", "self", ".", "category_nums", ",", "\n", "self", ".", "category_startidx", ")", ":", "\n", "                ", "category_score", "=", "cls_score", "[", ":", ",", "start_idx", ":", "start_idx", "+", "num", "]", "\n", "category_label", "=", "label", "[", ":", ",", "start_idx", ":", "start_idx", "+", "num", "]", "\n", "category_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "category_score", ",", "category_label", ",", "reduction", "=", "'none'", ")", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "                    ", "category_loss", "=", "torch", ".", "mean", "(", "category_loss", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "reduction", "==", "'sum'", ":", "\n", "                    ", "category_loss", "=", "torch", ".", "sum", "(", "category_loss", ",", "dim", "=", "1", ")", "\n", "\n", "", "idx", "=", "self", ".", "categories", ".", "index", "(", "name", ")", "\n", "if", "self", ".", "with_mask", ":", "\n", "                    ", "category_mask_i", "=", "category_mask", "[", ":", ",", "idx", "]", ".", "reshape", "(", "-", "1", ")", "\n", "# there should be at least one sample which contains tags", "\n", "# in thie category", "\n", "if", "torch", ".", "sum", "(", "category_mask_i", ")", "<", "0.5", ":", "\n", "                        ", "losses", "[", "f'{name}_LOSS'", "]", "=", "torch", ".", "tensor", "(", ".0", ")", ".", "cuda", "(", ")", "\n", "loss_weights", "[", "f'{name}_LOSS'", "]", "=", ".0", "\n", "continue", "\n", "", "category_loss", "=", "torch", ".", "sum", "(", "category_loss", "*", "category_mask_i", ")", "\n", "category_loss", "=", "category_loss", "/", "torch", ".", "sum", "(", "category_mask_i", ")", "\n", "", "else", ":", "\n", "                    ", "category_loss", "=", "torch", ".", "mean", "(", "category_loss", ")", "\n", "# We name the loss of each category as 'LOSS', since we only", "\n", "# want to monitor them, not backward them. We will also provide", "\n", "# the loss used for backward in the losses dictionary", "\n", "", "losses", "[", "f'{name}_LOSS'", "]", "=", "category_loss", "\n", "loss_weights", "[", "f'{name}_LOSS'", "]", "=", "self", ".", "category_loss_weights", "[", "idx", "]", "\n", "", "loss_weight_sum", "=", "sum", "(", "loss_weights", ".", "values", "(", ")", ")", "\n", "loss_weights", "=", "{", "\n", "k", ":", "v", "/", "loss_weight_sum", "\n", "for", "k", ",", "v", "in", "loss_weights", ".", "items", "(", ")", "\n", "}", "\n", "loss_cls", "=", "sum", "(", "[", "losses", "[", "k", "]", "*", "loss_weights", "[", "k", "]", "for", "k", "in", "losses", "]", ")", "\n", "losses", "[", "'loss_cls'", "]", "=", "loss_cls", "\n", "# We also trace the loss weights", "\n", "losses", ".", "update", "(", "{", "\n", "k", "+", "'_weight'", ":", "torch", ".", "tensor", "(", "v", ")", ".", "to", "(", "losses", "[", "k", "]", ".", "device", ")", "\n", "for", "k", ",", "v", "in", "loss_weights", ".", "items", "(", ")", "\n", "}", ")", "\n", "# Note that the loss weights are just for reference.", "\n", "return", "losses", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"loss_type should be 'all' or 'individual', \"", "\n", "f'but got {self.loss_type}'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.nll_loss.NLLLoss._forward": [[14, 27], ["torch.nll_loss"], "methods", ["None"], ["def", "_forward", "(", "self", ",", "cls_score", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward function.\n\n        Args:\n            cls_score (torch.Tensor): The class score.\n            label (torch.Tensor): The ground truth label.\n            kwargs: Any keyword argument to be used to calculate nll loss.\n\n        Returns:\n            torch.Tensor: The returned nll loss.\n        \"\"\"", "\n", "loss_cls", "=", "F", ".", "nll_loss", "(", "cls_score", ",", "label", ",", "**", "kwargs", ")", "\n", "return", "loss_cls", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.tem_loss": [[25, 45], ["binary_logistic_regression_loss.binary_logistic_regression_loss.binary_logistic_regression_loss", "binary_logistic_regression_loss.binary_logistic_regression_loss.binary_logistic_regression_loss"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.binary_logistic_regression_loss.binary_logistic_regression_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.binary_logistic_regression_loss.binary_logistic_regression_loss"], ["@", "staticmethod", "\n", "def", "tem_loss", "(", "pred_start", ",", "pred_end", ",", "gt_start", ",", "gt_end", ")", ":", "\n", "        ", "\"\"\"Calculate Temporal Evaluation Module Loss.\n\n        This function calculate the binary_logistic_regression_loss for start\n        and end respectively and returns the sum of their losses.\n\n        Args:\n            pred_start (torch.Tensor): Predicted start score by BMN model.\n            pred_end (torch.Tensor): Predicted end score by BMN model.\n            gt_start (torch.Tensor): Groundtruth confidence score for start.\n            gt_end (torch.Tensor): Groundtruth confidence score for end.\n\n        Returns:\n            torch.Tensor: Returned binary logistic loss.\n        \"\"\"", "\n", "loss_start", "=", "binary_logistic_regression_loss", "(", "pred_start", ",", "gt_start", ")", "\n", "loss_end", "=", "binary_logistic_regression_loss", "(", "pred_end", ",", "gt_end", ")", "\n", "loss", "=", "loss_start", "+", "loss_end", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.pem_reg_loss": [[46, 94], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.rand_like", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pem_reg_loss", "(", "pred_score", ",", "\n", "gt_iou_map", ",", "\n", "mask", ",", "\n", "high_temporal_iou_threshold", "=", "0.7", ",", "\n", "low_temporal_iou_threshold", "=", "0.3", ")", ":", "\n", "        ", "\"\"\"Calculate Proposal Evaluation Module Regression Loss.\n\n        Args:\n            pred_score (torch.Tensor): Predicted temporal_iou score by BMN.\n            gt_iou_map (torch.Tensor): Groundtruth temporal_iou score.\n            mask (torch.Tensor): Boundary-Matching mask.\n            high_temporal_iou_threshold (float): Higher threshold of\n                temporal_iou. Default: 0.7.\n            low_temporal_iou_threshold (float): Higher threshold of\n                temporal_iou. Default: 0.3.\n\n        Returns:\n            torch.Tensor: Proposal evalutaion regression loss.\n        \"\"\"", "\n", "u_hmask", "=", "(", "gt_iou_map", ">", "high_temporal_iou_threshold", ")", ".", "float", "(", ")", "\n", "u_mmask", "=", "(", "(", "gt_iou_map", "<=", "high_temporal_iou_threshold", ")", "&", "\n", "(", "gt_iou_map", ">", "low_temporal_iou_threshold", ")", ")", ".", "float", "(", ")", "\n", "u_lmask", "=", "(", "(", "gt_iou_map", "<=", "low_temporal_iou_threshold", ")", "&", "\n", "(", "gt_iou_map", ">", "0.", ")", ")", ".", "float", "(", ")", "\n", "u_lmask", "=", "u_lmask", "*", "mask", "\n", "\n", "num_h", "=", "torch", ".", "sum", "(", "u_hmask", ")", "\n", "num_m", "=", "torch", ".", "sum", "(", "u_mmask", ")", "\n", "num_l", "=", "torch", ".", "sum", "(", "u_lmask", ")", "\n", "\n", "r_m", "=", "num_h", "/", "num_m", "\n", "u_smmask", "=", "torch", ".", "rand_like", "(", "gt_iou_map", ")", "\n", "u_smmask", "=", "u_mmask", "*", "u_smmask", "\n", "u_smmask", "=", "(", "u_smmask", ">", "(", "1.", "-", "r_m", ")", ")", ".", "float", "(", ")", "\n", "\n", "r_l", "=", "num_h", "/", "num_l", "\n", "u_slmask", "=", "torch", ".", "rand_like", "(", "gt_iou_map", ")", "\n", "u_slmask", "=", "u_lmask", "*", "u_slmask", "\n", "u_slmask", "=", "(", "u_slmask", ">", "(", "1.", "-", "r_l", ")", ")", ".", "float", "(", ")", "\n", "\n", "weights", "=", "u_hmask", "+", "u_smmask", "+", "u_slmask", "\n", "\n", "loss", "=", "F", ".", "mse_loss", "(", "pred_score", "*", "weights", ",", "gt_iou_map", "*", "weights", ")", "\n", "loss", "=", "0.5", "*", "torch", ".", "sum", "(", "\n", "loss", "*", "torch", ".", "ones_like", "(", "weights", ")", ")", "/", "torch", ".", "sum", "(", "weights", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.pem_cls_loss": [[95, 133], ["max", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "pem_cls_loss", "(", "pred_score", ",", "\n", "gt_iou_map", ",", "\n", "mask", ",", "\n", "threshold", "=", "0.9", ",", "\n", "ratio_range", "=", "(", "1.05", ",", "21", ")", ",", "\n", "eps", "=", "1e-5", ")", ":", "\n", "        ", "\"\"\"Calculate Proposal Evaluation Module Classification Loss.\n\n        Args:\n            pred_score (torch.Tensor): Predicted temporal_iou score by BMN.\n            gt_iou_map (torch.Tensor): Groundtruth temporal_iou score.\n            mask (torch.Tensor): Boundary-Matching mask.\n            threshold (float): Threshold of temporal_iou for positive\n                instances. Default: 0.9.\n            ratio_range (tuple): Lower bound and upper bound for ratio.\n                Default: (1.05, 21)\n            eps (float): Epsilon for small value. Default: 1e-5\n\n        Returns:\n            torch.Tensor: Proposal evalutaion classification loss.\n        \"\"\"", "\n", "pmask", "=", "(", "gt_iou_map", ">", "threshold", ")", ".", "float", "(", ")", "\n", "nmask", "=", "(", "gt_iou_map", "<=", "threshold", ")", ".", "float", "(", ")", "\n", "nmask", "=", "nmask", "*", "mask", "\n", "\n", "num_positive", "=", "max", "(", "torch", ".", "sum", "(", "pmask", ")", ",", "1", ")", "\n", "num_entries", "=", "num_positive", "+", "torch", ".", "sum", "(", "nmask", ")", "\n", "ratio", "=", "num_entries", "/", "num_positive", "\n", "ratio", "=", "torch", ".", "clamp", "(", "ratio", ",", "ratio_range", "[", "0", "]", ",", "ratio_range", "[", "1", "]", ")", "\n", "\n", "coef_0", "=", "0.5", "*", "ratio", "/", "(", "ratio", "-", "1", ")", "\n", "coef_1", "=", "0.5", "*", "ratio", "\n", "\n", "loss_pos", "=", "coef_1", "*", "torch", ".", "log", "(", "pred_score", "+", "eps", ")", "*", "pmask", "\n", "loss_neg", "=", "coef_0", "*", "torch", ".", "log", "(", "1.0", "-", "pred_score", "+", "eps", ")", "*", "nmask", "\n", "loss", "=", "-", "1", "*", "torch", ".", "sum", "(", "loss_pos", "+", "loss_neg", ")", "/", "num_entries", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.forward": [[134, 181], ["pred_bm[].contiguous", "pred_bm[].contiguous", "bmn_loss.BMNLoss.pem_reg_loss", "bmn_loss.BMNLoss.pem_cls_loss", "bmn_loss.BMNLoss.tem_loss"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.pem_reg_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.pem_cls_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.tem_loss"], ["", "def", "forward", "(", "self", ",", "\n", "pred_bm", ",", "\n", "pred_start", ",", "\n", "pred_end", ",", "\n", "gt_iou_map", ",", "\n", "gt_start", ",", "\n", "gt_end", ",", "\n", "bm_mask", ",", "\n", "weight_tem", "=", "1.0", ",", "\n", "weight_pem_reg", "=", "10.0", ",", "\n", "weight_pem_cls", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Calculate Boundary Matching Network Loss.\n\n        Args:\n            pred_bm (torch.Tensor): Predicted confidence score for boundary\n                matching map.\n            pred_start (torch.Tensor): Predicted confidence score for start.\n            pred_end (torch.Tensor): Predicted confidence score for end.\n            gt_iou_map (torch.Tensor): Groundtruth score for boundary matching\n                map.\n            gt_start (torch.Tensor): Groundtruth temporal_iou score for start.\n            gt_end (torch.Tensor): Groundtruth temporal_iou score for end.\n            bm_mask (torch.Tensor): Boundary-Matching mask.\n            weight_tem (float): Weight for tem loss. Default: 1.0.\n            weight_pem_reg (float): Weight for pem regression loss.\n                Default: 10.0.\n            weight_pem_cls (float): Weight for pem classification loss.\n                Default: 1.0.\n\n        Returns:\n            tuple([torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]):\n                (loss, tem_loss, pem_reg_loss, pem_cls_loss). Loss is the bmn\n                loss, tem_loss is the temporal evaluation loss, pem_reg_loss is\n                the proposal evaluation regression loss, pem_cls_loss is the\n                proposal evaluation classification loss.\n        \"\"\"", "\n", "pred_bm_reg", "=", "pred_bm", "[", ":", ",", "0", "]", ".", "contiguous", "(", ")", "\n", "pred_bm_cls", "=", "pred_bm", "[", ":", ",", "1", "]", ".", "contiguous", "(", ")", "\n", "gt_iou_map", "=", "gt_iou_map", "*", "bm_mask", "\n", "\n", "pem_reg_loss", "=", "self", ".", "pem_reg_loss", "(", "pred_bm_reg", ",", "gt_iou_map", ",", "bm_mask", ")", "\n", "pem_cls_loss", "=", "self", ".", "pem_cls_loss", "(", "pred_bm_cls", ",", "gt_iou_map", ",", "bm_mask", ")", "\n", "tem_loss", "=", "self", ".", "tem_loss", "(", "pred_start", ",", "pred_end", ",", "gt_start", ",", "gt_end", ")", "\n", "loss", "=", "(", "\n", "weight_tem", "*", "tem_loss", "+", "weight_pem_reg", "*", "pem_reg_loss", "+", "\n", "weight_pem_cls", "*", "pem_cls_loss", ")", "\n", "return", "loss", ",", "tem_loss", ",", "pem_reg_loss", ",", "pem_cls_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.CrossEntropyLoss.__init__": [[32, 37], ["base.BaseWeightedLoss.__init__", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "loss_weight", "=", "1.0", ",", "class_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "loss_weight", "=", "loss_weight", ")", "\n", "self", ".", "class_weight", "=", "None", "\n", "if", "class_weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "class_weight", "=", "torch", ".", "Tensor", "(", "class_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.CrossEntropyLoss._forward": [[38, 81], ["cls_score.size", "label.size", "torch.log_softmax", "torch.log_softmax", "torch.cross_entropy", "torch.cross_entropy", "cls_score.dim", "len", "loss_cls.mean.mean.mean", "cross_entropy_loss.CrossEntropyLoss.class_weight.to", "cross_entropy_loss.CrossEntropyLoss.class_weight.unsqueeze", "loss_cls.mean.mean.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "cross_entropy_loss.CrossEntropyLoss.class_weight.unsqueeze"], "methods", ["None"], ["", "", "def", "_forward", "(", "self", ",", "cls_score", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward function.\n\n        Args:\n            cls_score (torch.Tensor): The class score.\n            label (torch.Tensor): The ground truth label.\n            kwargs: Any keyword argument to be used to calculate\n                CrossEntropy loss.\n\n        Returns:\n            torch.Tensor: The returned CrossEntropy loss.\n        \"\"\"", "\n", "if", "cls_score", ".", "size", "(", ")", "==", "label", ".", "size", "(", ")", ":", "\n", "# calculate loss for soft label", "\n", "\n", "            ", "assert", "cls_score", ".", "dim", "(", ")", "==", "2", ",", "'Only support 2-dim soft label'", "\n", "assert", "len", "(", "kwargs", ")", "==", "0", ",", "(", "'For now, no extra args are supported for soft label, '", "\n", "f'but get {kwargs}'", ")", "\n", "\n", "lsm", "=", "F", ".", "log_softmax", "(", "cls_score", ",", "1", ")", "\n", "if", "self", ".", "class_weight", "is", "not", "None", ":", "\n", "                ", "lsm", "=", "lsm", "*", "self", ".", "class_weight", ".", "unsqueeze", "(", "0", ")", "\n", "", "loss_cls", "=", "-", "(", "label", "*", "lsm", ")", ".", "sum", "(", "1", ")", "\n", "\n", "# default reduction 'mean'", "\n", "if", "self", ".", "class_weight", "is", "not", "None", ":", "\n", "# Use weighted average as pytorch CrossEntropyLoss does.", "\n", "# For more information, please visit https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html # noqa", "\n", "                ", "loss_cls", "=", "loss_cls", ".", "sum", "(", ")", "/", "torch", ".", "sum", "(", "\n", "self", ".", "class_weight", ".", "unsqueeze", "(", "0", ")", "*", "label", ")", "\n", "", "else", ":", "\n", "                ", "loss_cls", "=", "loss_cls", ".", "mean", "(", ")", "\n", "", "", "else", ":", "\n", "# calculate loss for hard label", "\n", "\n", "            ", "if", "self", ".", "class_weight", "is", "not", "None", ":", "\n", "                ", "assert", "'weight'", "not", "in", "kwargs", ",", "\"The key 'weight' already exists.\"", "\n", "kwargs", "[", "'weight'", "]", "=", "self", ".", "class_weight", ".", "to", "(", "cls_score", ".", "device", ")", "\n", "", "loss_cls", "=", "F", ".", "cross_entropy", "(", "cls_score", ",", "label", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "loss_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits.__init__": [[96, 101], ["base.BaseWeightedLoss.__init__", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "loss_weight", "=", "1.0", ",", "class_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "loss_weight", "=", "loss_weight", ")", "\n", "self", ".", "class_weight", "=", "None", "\n", "if", "class_weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "class_weight", "=", "torch", ".", "Tensor", "(", "class_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.cross_entropy_loss.BCELossWithLogits._forward": [[102, 120], ["torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "cross_entropy_loss.BCELossWithLogits.class_weight.to"], "methods", ["None"], ["", "", "def", "_forward", "(", "self", ",", "cls_score", ",", "label", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward function.\n\n        Args:\n            cls_score (torch.Tensor): The class score.\n            label (torch.Tensor): The ground truth label.\n            kwargs: Any keyword argument to be used to calculate\n                bce loss with logits.\n\n        Returns:\n            torch.Tensor: The returned bce loss with logits.\n        \"\"\"", "\n", "if", "self", ".", "class_weight", "is", "not", "None", ":", "\n", "            ", "assert", "'weight'", "not", "in", "kwargs", ",", "\"The key 'weight' already exists.\"", "\n", "kwargs", "[", "'weight'", "]", "=", "self", ".", "class_weight", ".", "to", "(", "cls_score", ".", "device", ")", "\n", "", "loss_cls", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "cls_score", ",", "label", ",", "\n", "**", "kwargs", ")", "\n", "return", "loss_cls", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.__init__": [[70, 123], ["mmcv.runner.get_dist_info", "os.exists", "ValueError", "isinstance", "isinstance", "lfb.LFB.load_lfb", "lfb.LFB.load_lfb", "warnings.warn", "os.normpath", "lmdb.open", "ValueError", "os.join", "print", "lfb.LFB.load_lfb_on_lmdb", "torch.barrier", "torch.barrier"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.load_lfb", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.load_lfb", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.load_lfb_on_lmdb"], ["def", "__init__", "(", "self", ",", "\n", "lfb_prefix_path", ",", "\n", "max_num_sampled_feat", "=", "5", ",", "\n", "window_size", "=", "60", ",", "\n", "lfb_channels", "=", "2048", ",", "\n", "dataset_modes", "=", "(", "'train'", ",", "'val'", ")", ",", "\n", "device", "=", "'gpu'", ",", "\n", "lmdb_map_size", "=", "4e9", ",", "\n", "construct_lmdb", "=", "True", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "lfb_prefix_path", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'lfb prefix path {lfb_prefix_path} does not exist!'", ")", "\n", "", "self", ".", "lfb_prefix_path", "=", "lfb_prefix_path", "\n", "self", ".", "max_num_sampled_feat", "=", "max_num_sampled_feat", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "lfb_channels", "=", "lfb_channels", "\n", "if", "not", "isinstance", "(", "dataset_modes", ",", "tuple", ")", ":", "\n", "            ", "assert", "isinstance", "(", "dataset_modes", ",", "str", ")", "\n", "dataset_modes", "=", "(", "dataset_modes", ",", ")", "\n", "", "self", ".", "dataset_modes", "=", "dataset_modes", "\n", "self", ".", "device", "=", "device", "\n", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "\n", "# Loading LFB", "\n", "if", "self", ".", "device", "==", "'gpu'", ":", "\n", "            ", "self", ".", "load_lfb", "(", "f'cuda:{rank}'", ")", "\n", "", "elif", "self", ".", "device", "==", "'cpu'", ":", "\n", "            ", "if", "world_size", ">", "1", ":", "\n", "                ", "warnings", ".", "warn", "(", "\n", "'If distributed training is used with multi-GPUs, lfb '", "\n", "'will be loaded multiple times on RAM. In this case, '", "\n", "\"'lmdb' is recomended.\"", ",", "UserWarning", ")", "\n", "", "self", ".", "load_lfb", "(", "'cpu'", ")", "\n", "", "elif", "self", ".", "device", "==", "'lmdb'", ":", "\n", "            ", "assert", "lmdb_imported", ",", "(", "\n", "'Please install `lmdb` to load lfb on lmdb!'", ")", "\n", "self", ".", "lmdb_map_size", "=", "lmdb_map_size", "\n", "self", ".", "construct_lmdb", "=", "construct_lmdb", "\n", "self", ".", "lfb_lmdb_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "self", ".", "lfb_prefix_path", ",", "'lmdb'", ")", ")", "\n", "\n", "if", "rank", "==", "0", "and", "self", ".", "construct_lmdb", ":", "\n", "                ", "print", "(", "'Constructing LFB lmdb...'", ")", "\n", "self", ".", "load_lfb_on_lmdb", "(", ")", "\n", "\n", "# Synchronizes all processes to make sure lfb lmdb exist.", "\n", "", "if", "world_size", ">", "1", ":", "\n", "                ", "dist", ".", "barrier", "(", ")", "\n", "", "self", ".", "lmdb_env", "=", "lmdb", ".", "open", "(", "self", ".", "lfb_lmdb_path", ",", "readonly", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Device must be 'gpu', 'cpu' or 'lmdb', \"", ",", "\n", "f'but get {self.device}.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.load_lfb": [[124, 132], ["print", "os.normpath", "print", "lfb.LFB.lfb.update", "os.join", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "load_lfb", "(", "self", ",", "map_location", ")", ":", "\n", "        ", "self", ".", "lfb", "=", "{", "}", "\n", "for", "dataset_mode", "in", "self", ".", "dataset_modes", ":", "\n", "            ", "lfb_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "self", ".", "lfb_prefix_path", ",", "f'lfb_{dataset_mode}.pkl'", ")", ")", "\n", "print", "(", "f'Loading LFB from {lfb_path}...'", ")", "\n", "self", ".", "lfb", ".", "update", "(", "torch", ".", "load", "(", "lfb_path", ",", "map_location", "=", "map_location", ")", ")", "\n", "", "print", "(", "f'LFB has been loaded on {map_location}.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.load_lfb_on_lmdb": [[133, 151], ["lmdb.open", "lfb.items", "print", "os.normpath", "lfb.update", "lmdb.open.begin", "io.BytesIO", "torch.save", "torch.save", "torch.save", "torch.save", "io.BytesIO.seek", "lmdb.open.begin.put", "lmdb.open.begin.commit", "io.BytesIO.close", "os.join", "torch.load", "torch.load", "torch.load", "torch.load", "key.encode", "io.BytesIO.read"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "load_lfb_on_lmdb", "(", "self", ")", ":", "\n", "        ", "lfb", "=", "{", "}", "\n", "for", "dataset_mode", "in", "self", ".", "dataset_modes", ":", "\n", "            ", "lfb_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "self", ".", "lfb_prefix_path", ",", "f'lfb_{dataset_mode}.pkl'", ")", ")", "\n", "lfb", ".", "update", "(", "torch", ".", "load", "(", "lfb_path", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "\n", "", "lmdb_env", "=", "lmdb", ".", "open", "(", "self", ".", "lfb_lmdb_path", ",", "map_size", "=", "self", ".", "lmdb_map_size", ")", "\n", "for", "key", ",", "value", "in", "lfb", ".", "items", "(", ")", ":", "\n", "            ", "txn", "=", "lmdb_env", ".", "begin", "(", "write", "=", "True", ")", "\n", "buff", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "save", "(", "value", ",", "buff", ")", "\n", "buff", ".", "seek", "(", "0", ")", "\n", "txn", ".", "put", "(", "key", ".", "encode", "(", ")", ",", "buff", ".", "read", "(", ")", ")", "\n", "txn", ".", "commit", "(", ")", "\n", "buff", ".", "close", "(", ")", "\n", "\n", "", "print", "(", "f'LFB lmdb has been constructed on {self.lfb_lmdb_path}!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.sample_long_term_features": [[152, 179], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "range", "lfb.LFB.lmdb_env.begin", "txn.get", "torch.load", "torch.load", "torch.load", "torch.load", "len", "min", "numpy.random.choice", "enumerate", "video_id.encode", "io.BytesIO", "range"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "sample_long_term_features", "(", "self", ",", "video_id", ",", "timestamp", ")", ":", "\n", "        ", "if", "self", ".", "device", "==", "'lmdb'", ":", "\n", "            ", "with", "self", ".", "lmdb_env", ".", "begin", "(", "write", "=", "False", ")", "as", "txn", ":", "\n", "                ", "buf", "=", "txn", ".", "get", "(", "video_id", ".", "encode", "(", ")", ")", "\n", "video_features", "=", "torch", ".", "load", "(", "io", ".", "BytesIO", "(", "buf", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "video_features", "=", "self", ".", "lfb", "[", "video_id", "]", "\n", "\n", "# Sample long term features.", "\n", "", "window_size", ",", "K", "=", "self", ".", "window_size", ",", "self", ".", "max_num_sampled_feat", "\n", "start", "=", "timestamp", "-", "(", "window_size", "//", "2", ")", "\n", "lt_feats", "=", "torch", ".", "zeros", "(", "window_size", "*", "K", ",", "self", ".", "lfb_channels", ")", "\n", "\n", "for", "idx", ",", "sec", "in", "enumerate", "(", "range", "(", "start", ",", "start", "+", "window_size", ")", ")", ":", "\n", "            ", "if", "sec", "in", "video_features", ":", "\n", "# `num_feat` is the number of roi features in this second.", "\n", "                ", "num_feat", "=", "len", "(", "video_features", "[", "sec", "]", ")", "\n", "num_feat_sampled", "=", "min", "(", "num_feat", ",", "K", ")", "\n", "# Sample some roi features randomly.", "\n", "random_lfb_indices", "=", "np", ".", "random", ".", "choice", "(", "\n", "range", "(", "num_feat", ")", ",", "num_feat_sampled", ",", "replace", "=", "False", ")", "\n", "\n", "for", "k", ",", "rand_idx", "in", "enumerate", "(", "random_lfb_indices", ")", ":", "\n", "                    ", "lt_feats", "[", "idx", "*", "K", "+", "k", "]", "=", "video_features", "[", "sec", "]", "[", "rand_idx", "]", "\n", "\n", "# [window_size * max_num_sampled_feat, lfb_channels]", "\n", "", "", "", "return", "lt_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.__getitem__": [[180, 185], ["img_key.split", "lfb.LFB.sample_long_term_features", "int"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.sample_long_term_features"], ["", "def", "__getitem__", "(", "self", ",", "img_key", ")", ":", "\n", "        ", "\"\"\"Sample long term features like `lfb['0f39OWEqJ24,0902']` where `lfb`\n        is a instance of class LFB.\"\"\"", "\n", "video_id", ",", "timestamp", "=", "img_key", ".", "split", "(", "','", ")", "\n", "return", "self", ".", "sample_long_term_features", "(", "video_id", ",", "int", "(", "timestamp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.lfb.LFB.__len__": [[186, 189], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"The number of videos whose ROI features are stored in LFB.\"\"\"", "\n", "return", "len", "(", "self", ".", "lfb", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.conv_audio.ConvAudio.__init__": [[29, 81], ["torch.Module.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "conv_audio.ConvAudio.init_weights", "dict", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "op", "=", "'concat'", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "assert", "op", "in", "[", "'concat'", ",", "'sum'", "]", "\n", "self", ".", "op", "=", "op", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "output_padding", "=", "(", "0", ",", "0", ")", "\n", "self", ".", "transposed", "=", "False", "\n", "\n", "self", ".", "conv_1", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "(", "kernel_size", "[", "0", "]", ",", "1", ")", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "(", "kernel_size", "[", "0", "]", "//", "2", ",", "0", ")", ",", "\n", "bias", "=", "bias", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ")", "\n", "\n", "self", ".", "conv_2", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "kernel_size", "[", "1", "]", ")", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "(", "0", ",", "kernel_size", "[", "1", "]", "//", "2", ")", ",", "\n", "bias", "=", "bias", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.conv_audio.ConvAudio.forward": [[82, 98], ["conv_audio.ConvAudio.conv_1", "conv_audio.ConvAudio.conv_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "x_1", "=", "self", ".", "conv_1", "(", "x", ")", "\n", "x_2", "=", "self", ".", "conv_2", "(", "x", ")", "\n", "if", "self", ".", "op", "==", "'concat'", ":", "\n", "            ", "out", "=", "torch", ".", "cat", "(", "[", "x_1", ",", "x_2", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "x_1", "+", "x_2", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.conv_audio.ConvAudio.init_weights": [[99, 105], ["mmcv.cnn.kaiming_init", "mmcv.cnn.kaiming_init", "mmcv.cnn.constant_init", "mmcv.cnn.constant_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "kaiming_init", "(", "self", ".", "conv_1", ".", "conv", ")", "\n", "kaiming_init", "(", "self", ".", "conv_2", ".", "conv", ")", "\n", "constant_init", "(", "self", ".", "conv_1", ".", "bn", ",", "1", ",", "bias", "=", "0", ")", "\n", "constant_init", "(", "self", ".", "conv_2", ".", "bn", ",", "1", ",", "bias", "=", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.conv2plus1d.Conv2plus1d.__init__": [[25, 84], ["dict", "torch.Module.__init__", "torch.nn.modules.utils._triple", "torch.nn.modules.utils._triple", "torch.nn.modules.utils._triple", "int", "torch.Conv3d", "mmcv.cnn.build_norm_layer", "torch.ReLU", "torch.Conv3d", "conv2plus1d.Conv2plus1d.init_weights", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "groups", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "kernel_size", "=", "_triple", "(", "kernel_size", ")", "\n", "stride", "=", "_triple", "(", "stride", ")", "\n", "padding", "=", "_triple", "(", "padding", ")", "\n", "assert", "len", "(", "kernel_size", ")", "==", "len", "(", "stride", ")", "==", "len", "(", "padding", ")", "==", "3", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "output_padding", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "self", ".", "transposed", "=", "False", "\n", "\n", "# The middle-plane is calculated according to:", "\n", "# M_i = \\floor{\\frac{t * d^2 N_i-1 * N_i}", "\n", "#   {d^2 * N_i-1 + t * N_i}}", "\n", "# where d, t are spatial and temporal kernel, and", "\n", "# N_i, N_i-1 are planes", "\n", "# and inplanes. https://arxiv.org/pdf/1711.11248.pdf", "\n", "mid_channels", "=", "3", "*", "(", "\n", "in_channels", "*", "out_channels", "*", "kernel_size", "[", "1", "]", "*", "kernel_size", "[", "2", "]", ")", "\n", "mid_channels", "/=", "(", "\n", "in_channels", "*", "kernel_size", "[", "1", "]", "*", "kernel_size", "[", "2", "]", "+", "3", "*", "out_channels", ")", "\n", "mid_channels", "=", "int", "(", "mid_channels", ")", "\n", "\n", "self", ".", "conv_s", "=", "nn", ".", "Conv3d", "(", "\n", "in_channels", ",", "\n", "mid_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "kernel_size", "[", "1", "]", ",", "kernel_size", "[", "2", "]", ")", ",", "\n", "stride", "=", "(", "1", ",", "stride", "[", "1", "]", ",", "stride", "[", "2", "]", ")", ",", "\n", "padding", "=", "(", "0", ",", "padding", "[", "1", "]", ",", "padding", "[", "2", "]", ")", ",", "\n", "bias", "=", "bias", ")", "\n", "_", ",", "self", ".", "bn_s", "=", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "mid_channels", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv_t", "=", "nn", ".", "Conv3d", "(", "\n", "mid_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "(", "kernel_size", "[", "0", "]", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "stride", "[", "0", "]", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "padding", "[", "0", "]", ",", "0", ",", "0", ")", ",", "\n", "bias", "=", "bias", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.conv2plus1d.Conv2plus1d.forward": [[85, 99], ["conv2plus1d.Conv2plus1d.conv_s", "conv2plus1d.Conv2plus1d.bn_s", "conv2plus1d.Conv2plus1d.relu", "conv2plus1d.Conv2plus1d.conv_t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv_s", "(", "x", ")", "\n", "x", "=", "self", ".", "bn_s", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv_t", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.conv2plus1d.Conv2plus1d.init_weights": [[100, 105], ["mmcv.cnn.kaiming_init", "mmcv.cnn.kaiming_init", "mmcv.cnn.constant_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "kaiming_init", "(", "self", ".", "conv_s", ")", "\n", "kaiming_init", "(", "self", ".", "conv_t", ")", "\n", "constant_init", "(", "self", ".", "bn_s", ",", "1", ",", "bias", "=", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.tam.TAM.__init__": [[34, 76], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "tam.TAM.init_weights", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "num_segments", ",", "\n", "alpha", "=", "2", ",", "\n", "adaptive_kernel_size", "=", "3", ",", "\n", "beta", "=", "4", ",", "\n", "conv1d_kernel_size", "=", "3", ",", "\n", "adaptive_convolution_stride", "=", "1", ",", "\n", "adaptive_convolution_padding", "=", "1", ",", "\n", "init_std", "=", "0.001", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "beta", ">", "0", "and", "alpha", ">", "0", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "adaptive_kernel_size", "=", "adaptive_kernel_size", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "conv1d_kernel_size", "=", "conv1d_kernel_size", "\n", "self", ".", "adaptive_convolution_stride", "=", "adaptive_convolution_stride", "\n", "self", ".", "adaptive_convolution_padding", "=", "adaptive_convolution_padding", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "self", ".", "G", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "num_segments", ",", "num_segments", "*", "alpha", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "num_segments", "*", "alpha", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "num_segments", "*", "alpha", ",", "adaptive_kernel_size", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Softmax", "(", "-", "1", ")", ")", "\n", "\n", "self", ".", "L", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "\n", "in_channels", ",", "\n", "in_channels", "//", "beta", ",", "\n", "conv1d_kernel_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "conv1d_kernel_size", "//", "2", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "BatchNorm1d", "(", "in_channels", "//", "beta", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv1d", "(", "in_channels", "//", "beta", ",", "in_channels", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.tam.TAM.init_weights": [[77, 86], ["tam.TAM.modules", "isinstance", "mmcv.cnn.kaiming_init", "isinstance", "mmcv.cnn.constant_init", "isinstance", "mmcv.cnn.normal_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initiate the parameters from scratch.\"\"\"", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv1d", ")", ":", "\n", "                ", "kaiming_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm1d", ")", ":", "\n", "                ", "constant_init", "(", "m", ",", "1", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "normal_init", "(", "m", ",", "std", "=", "self", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.common.tam.TAM.forward": [[87, 135], ["x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute().contiguous", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "tam.TAM.G().view", "tam.TAM.L().view", "torch.conv2d", "torch.conv2d", "y.permute().contiguous().view.permute().contiguous().view.view", "y.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous.permute().contiguous.view", "new_x.view", "x.permute().contiguous.permute().contiguous.permute", "tam.TAM.G", "tam.TAM.L", "y.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "torch.adaptive_avg_pool2d.view", "torch.adaptive_avg_pool2d.view", "y.permute().contiguous().view.permute().contiguous().view.permute"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Defines the computation performed at every call.\n\n        Args:\n            x (torch.Tensor): The input data.\n\n        Returns:\n            torch.Tensor: The output of the module.\n        \"\"\"", "\n", "# [n, c, h, w]", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "num_segments", "=", "self", ".", "num_segments", "\n", "num_batches", "=", "n", "//", "num_segments", "\n", "assert", "c", "==", "self", ".", "in_channels", "\n", "\n", "# [num_batches, c, num_segments, h, w]", "\n", "x", "=", "x", ".", "view", "(", "num_batches", ",", "num_segments", ",", "c", ",", "h", ",", "w", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", ".", "contiguous", "(", ")", "\n", "\n", "# [num_batches * c, num_segments, 1, 1]", "\n", "theta_out", "=", "F", ".", "adaptive_avg_pool2d", "(", "\n", "x", ".", "view", "(", "-", "1", ",", "num_segments", ",", "h", ",", "w", ")", ",", "(", "1", ",", "1", ")", ")", "\n", "\n", "# [num_batches * c, 1, adaptive_kernel_size, 1]", "\n", "conv_kernel", "=", "self", ".", "G", "(", "theta_out", ".", "view", "(", "-", "1", ",", "num_segments", ")", ")", ".", "view", "(", "\n", "num_batches", "*", "c", ",", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "# [num_batches, c, num_segments, 1, 1]", "\n", "local_activation", "=", "self", ".", "L", "(", "theta_out", ".", "view", "(", "-", "1", ",", "c", ",", "num_segments", ")", ")", ".", "view", "(", "\n", "num_batches", ",", "c", ",", "num_segments", ",", "1", ",", "1", ")", "\n", "\n", "# [num_batches, c, num_segments, h, w]", "\n", "new_x", "=", "x", "*", "local_activation", "\n", "\n", "# [1, num_batches * c, num_segments, h * w]", "\n", "y", "=", "F", ".", "conv2d", "(", "\n", "new_x", ".", "view", "(", "1", ",", "num_batches", "*", "c", ",", "num_segments", ",", "h", "*", "w", ")", ",", "\n", "conv_kernel", ",", "\n", "bias", "=", "None", ",", "\n", "stride", "=", "(", "self", ".", "adaptive_convolution_stride", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "adaptive_convolution_padding", ",", "0", ")", ",", "\n", "groups", "=", "num_batches", "*", "c", ")", "\n", "\n", "# [n, c, h, w]", "\n", "y", "=", "y", ".", "view", "(", "num_batches", ",", "c", ",", "num_segments", ",", "h", ",", "w", ")", "\n", "y", "=", "y", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", ".", "contiguous", "(", ")", ".", "view", "(", "n", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "return", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.scheduler.lr_updater.TINLrUpdaterHook.__init__": [[8, 11], ["mmcv.runner.LrUpdaterHook.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "min_lr", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "min_lr", "=", "min_lr", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.scheduler.lr_updater.TINLrUpdaterHook.get_warmup_lr": [[12, 25], ["None"], "methods", ["None"], ["", "def", "get_warmup_lr", "(", "self", ",", "cur_iters", ")", ":", "\n", "        ", "if", "self", ".", "warmup", "==", "'linear'", ":", "\n", "# 'linear' warmup is rewritten according to TIN repo:", "\n", "# https://github.com/deepcs233/TIN/blob/master/main.py#L409-L412", "\n", "            ", "k", "=", "(", "cur_iters", "/", "self", ".", "warmup_iters", ")", "*", "(", "\n", "1", "-", "self", ".", "warmup_ratio", ")", "+", "self", ".", "warmup_ratio", "\n", "warmup_lr", "=", "[", "_lr", "*", "k", "for", "_lr", "in", "self", ".", "regular_lr", "]", "\n", "", "elif", "self", ".", "warmup", "==", "'constant'", ":", "\n", "            ", "warmup_lr", "=", "[", "_lr", "*", "self", ".", "warmup_ratio", "for", "_lr", "in", "self", ".", "regular_lr", "]", "\n", "", "elif", "self", ".", "warmup", "==", "'exp'", ":", "\n", "            ", "k", "=", "self", ".", "warmup_ratio", "**", "(", "1", "-", "cur_iters", "/", "self", ".", "warmup_iters", ")", "\n", "warmup_lr", "=", "[", "_lr", "*", "k", "for", "_lr", "in", "self", ".", "regular_lr", "]", "\n", "", "return", "warmup_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.scheduler.lr_updater.TINLrUpdaterHook.get_lr": [[26, 40], ["mmcv.runner.hooks.lr_updater.annealing_cos"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ",", "runner", ",", "base_lr", ")", ":", "\n", "        ", "if", "self", ".", "by_epoch", ":", "\n", "            ", "progress", "=", "runner", ".", "epoch", "\n", "max_progress", "=", "runner", ".", "max_epochs", "\n", "", "else", ":", "\n", "            ", "progress", "=", "runner", ".", "iter", "\n", "max_progress", "=", "runner", ".", "max_iters", "\n", "\n", "", "target_lr", "=", "self", ".", "min_lr", "\n", "if", "self", ".", "warmup", "is", "not", "None", ":", "\n", "            ", "progress", "=", "progress", "-", "self", ".", "warmup_iters", "\n", "max_progress", "=", "max_progress", "-", "self", ".", "warmup_iters", "\n", "", "factor", "=", "progress", "/", "max_progress", "\n", "return", "annealing_cos", "(", "base_lr", ",", "target_lr", ",", "factor", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization.__init__": [[23, 52], ["numpy.linspace", "utils.get_root_logger", "eval_detection.ActivityNetLocalization._import_ground_truth", "eval_detection.ActivityNetLocalization._import_prediction", "IOError", "IOError", "mmcv.utils.print_log", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization._import_ground_truth", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization._import_prediction"], ["def", "__init__", "(", "self", ",", "\n", "ground_truth_filename", "=", "None", ",", "\n", "prediction_filename", "=", "None", ",", "\n", "tiou_thresholds", "=", "np", ".", "linspace", "(", "0.5", ",", "0.95", ",", "10", ")", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "not", "ground_truth_filename", ":", "\n", "            ", "raise", "IOError", "(", "'Please input a valid ground truth file.'", ")", "\n", "", "if", "not", "prediction_filename", ":", "\n", "            ", "raise", "IOError", "(", "'Please input a valid prediction file.'", ")", "\n", "", "self", ".", "ground_truth_filename", "=", "ground_truth_filename", "\n", "self", ".", "prediction_filename", "=", "prediction_filename", "\n", "self", ".", "tiou_thresholds", "=", "tiou_thresholds", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "ap", "=", "None", "\n", "self", ".", "logger", "=", "get_root_logger", "(", ")", "\n", "# Import ground truth and predictions.", "\n", "self", ".", "ground_truth", ",", "self", ".", "activity_index", "=", "self", ".", "_import_ground_truth", "(", "\n", "ground_truth_filename", ")", "\n", "self", ".", "prediction", "=", "self", ".", "_import_prediction", "(", "prediction_filename", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "log_msg", "=", "(", "\n", "'[INIT] Loaded ground_truth from '", "\n", "f'{self.ground_truth_filename}, prediction from '", "\n", "f'{self.prediction_filename}.\\n'", "\n", "f'Number of ground truth instances: {len(self.ground_truth)}\\n'", "\n", "f'Number of predictions: {len(self.prediction)}\\n'", "\n", "f'Fixed threshold for tiou score: {self.tiou_thresholds}'", ")", "\n", "print_log", "(", "log_msg", ",", "logger", "=", "self", ".", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization._import_ground_truth": [[53, 87], ["json.load.items", "open", "json.load", "float", "float", "ground_truth.append"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_import_ground_truth", "(", "ground_truth_filename", ")", ":", "\n", "        ", "\"\"\"Read ground truth file and return the ground truth instances and the\n        activity classes.\n\n        Args:\n            ground_truth_filename (str): Full path to the ground truth json\n                file.\n\n        Returns:\n            tuple[list, dict]: (ground_truth, activity_index).\n                ground_truth contains the ground truth instances, which is in a\n                    dict format.\n                activity_index contains classes index.\n        \"\"\"", "\n", "with", "open", "(", "ground_truth_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "# Checking format", "\n", "", "activity_index", ",", "class_idx", "=", "{", "}", ",", "0", "\n", "ground_truth", "=", "[", "]", "\n", "for", "video_id", ",", "video_info", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "for", "anno", "in", "video_info", "[", "'annotations'", "]", ":", "\n", "                ", "if", "anno", "[", "'label'", "]", "not", "in", "activity_index", ":", "\n", "                    ", "activity_index", "[", "anno", "[", "'label'", "]", "]", "=", "class_idx", "\n", "class_idx", "+=", "1", "\n", "# old video_anno", "\n", "", "ground_truth_item", "=", "{", "}", "\n", "ground_truth_item", "[", "'video-id'", "]", "=", "video_id", "[", "2", ":", "]", "\n", "ground_truth_item", "[", "'t-start'", "]", "=", "float", "(", "anno", "[", "'segment'", "]", "[", "0", "]", ")", "\n", "ground_truth_item", "[", "'t-end'", "]", "=", "float", "(", "anno", "[", "'segment'", "]", "[", "1", "]", ")", "\n", "ground_truth_item", "[", "'label'", "]", "=", "activity_index", "[", "anno", "[", "'label'", "]", "]", "\n", "ground_truth", ".", "append", "(", "ground_truth_item", ")", "\n", "\n", "", "", "return", "ground_truth", ",", "activity_index", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization._import_prediction": [[88, 112], ["data[].items", "open", "json.load", "dict", "float", "float", "prediction.append"], "methods", ["None"], ["", "def", "_import_prediction", "(", "self", ",", "prediction_filename", ")", ":", "\n", "        ", "\"\"\"Read prediction file and return the prediction instances.\n\n        Args:\n            prediction_filename (str): Full path to the prediction json file.\n\n        Returns:\n            List: List containing the prediction instances (dictionaries).\n        \"\"\"", "\n", "with", "open", "(", "prediction_filename", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "# Read predictions.", "\n", "", "prediction", "=", "[", "]", "\n", "for", "video_id", ",", "video_info", "in", "data", "[", "'results'", "]", ".", "items", "(", ")", ":", "\n", "            ", "for", "result", "in", "video_info", ":", "\n", "                ", "prediction_item", "=", "dict", "(", ")", "\n", "prediction_item", "[", "'video-id'", "]", "=", "video_id", "\n", "prediction_item", "[", "'label'", "]", "=", "self", ".", "activity_index", "[", "result", "[", "'label'", "]", "]", "\n", "prediction_item", "[", "'t-start'", "]", "=", "float", "(", "result", "[", "'segment'", "]", "[", "0", "]", ")", "\n", "prediction_item", "[", "'t-end'", "]", "=", "float", "(", "result", "[", "'segment'", "]", "[", "1", "]", ")", "\n", "prediction_item", "[", "'score'", "]", "=", "result", "[", "'score'", "]", "\n", "prediction", ".", "append", "(", "prediction_item", ")", "\n", "\n", "", "", "return", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization.wrapper_compute_average_precision": [[113, 135], ["numpy.zeros", "range", "range", "len", "ground_truth_by_label.append", "prediction_by_label.append", "ground_truth_by_label[].append", "prediction_by_label[].append", "len", "eval_detection.compute_average_precision_detection", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.compute_average_precision_detection"], ["", "def", "wrapper_compute_average_precision", "(", "self", ")", ":", "\n", "        ", "\"\"\"Computes average precision for each class.\"\"\"", "\n", "ap", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "tiou_thresholds", ")", ",", "len", "(", "self", ".", "activity_index", ")", ")", ")", "\n", "\n", "# Adaptation to query faster", "\n", "ground_truth_by_label", "=", "[", "]", "\n", "prediction_by_label", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "activity_index", ")", ")", ":", "\n", "            ", "ground_truth_by_label", ".", "append", "(", "[", "]", ")", "\n", "prediction_by_label", ".", "append", "(", "[", "]", ")", "\n", "", "for", "gt", "in", "self", ".", "ground_truth", ":", "\n", "            ", "ground_truth_by_label", "[", "gt", "[", "'label'", "]", "]", ".", "append", "(", "gt", ")", "\n", "", "for", "pred", "in", "self", ".", "prediction", ":", "\n", "            ", "prediction_by_label", "[", "pred", "[", "'label'", "]", "]", ".", "append", "(", "pred", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "activity_index", ")", ")", ":", "\n", "            ", "ap_result", "=", "compute_average_precision_detection", "(", "\n", "ground_truth_by_label", "[", "i", "]", ",", "prediction_by_label", "[", "i", "]", ",", "\n", "self", ".", "tiou_thresholds", ")", "\n", "ap", "[", ":", ",", "i", "]", "=", "ap_result", "\n", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization.evaluate": [[136, 148], ["eval_detection.ActivityNetLocalization.wrapper_compute_average_precision", "eval_detection.ActivityNetLocalization.ap.mean", "eval_detection.ActivityNetLocalization.mAP.mean"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.ActivityNetLocalization.wrapper_compute_average_precision"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Evaluates a prediction file.\n\n        For the detection task we measure the interpolated mean average\n        precision to measure the performance of a method.\n        \"\"\"", "\n", "self", ".", "ap", "=", "self", ".", "wrapper_compute_average_precision", "(", ")", "\n", "\n", "self", ".", "mAP", "=", "self", ".", "ap", ".", "mean", "(", "axis", "=", "1", ")", "\n", "self", ".", "average_mAP", "=", "self", ".", "mAP", ".", "mean", "(", ")", "\n", "\n", "return", "self", ".", "mAP", ",", "self", ".", "average_mAP", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.eval_detection.compute_average_precision_detection": [[150, 234], ["numpy.linspace", "len", "len", "len", "numpy.zeros", "float", "prediction.sort", "numpy.zeros", "numpy.zeros", "enumerate", "enumerate", "numpy.cumsum().astype", "numpy.cumsum().astype", "range", "len", "numpy.ones", "ground_truth_by_videoid.setdefault().append", "accuracy.pairwise_temporal_iou", "tiou_arr.reshape.reshape", "enumerate", "len", "accuracy.interpolated_precision_recall", "numpy.array", "numpy.array", "tiou_arr.reshape.argsort", "numpy.cumsum", "numpy.cumsum", "ground_truth_by_videoid.setdefault", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.interpolated_precision_recall"], ["", "", "def", "compute_average_precision_detection", "(", "ground_truth", ",", "\n", "prediction", ",", "\n", "tiou_thresholds", "=", "np", ".", "linspace", "(", "\n", "0.5", ",", "0.95", ",", "10", ")", ")", ":", "\n", "    ", "\"\"\"Compute average precision (detection task) between ground truth and\n    predictions data frames. If multiple predictions occurs for the same\n    predicted segment, only the one with highest score is matches as true\n    positive. This code is greatly inspired by Pascal VOC devkit.\n\n    Args:\n        ground_truth (list[dict]): List containing the ground truth instances\n            (dictionaries). Required keys are 'video-id', 't-start' and\n            't-end'.\n        prediction (list[dict]): List containing the prediction instances\n            (dictionaries). Required keys are: 'video-id', 't-start', 't-end'\n            and 'score'.\n        tiou_thresholds (np.ndarray): A 1darray indicates the temporal\n            intersection over union threshold, which is optional.\n            Default: ``np.linspace(0.5, 0.95, 10)``.\n\n    Returns:\n        Float: ap, Average precision score.\n    \"\"\"", "\n", "num_thresholds", "=", "len", "(", "tiou_thresholds", ")", "\n", "num_gts", "=", "len", "(", "ground_truth", ")", "\n", "num_preds", "=", "len", "(", "prediction", ")", "\n", "ap", "=", "np", ".", "zeros", "(", "num_thresholds", ")", "\n", "if", "len", "(", "prediction", ")", "==", "0", ":", "\n", "        ", "return", "ap", "\n", "\n", "", "num_positive", "=", "float", "(", "num_gts", ")", "\n", "lock_gt", "=", "np", ".", "ones", "(", "(", "num_thresholds", ",", "num_gts", ")", ")", "*", "-", "1", "\n", "# Sort predictions by decreasing score order.", "\n", "prediction", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "x", "[", "'score'", "]", ")", "\n", "# Initialize true positive and false positive vectors.", "\n", "tp", "=", "np", ".", "zeros", "(", "(", "num_thresholds", ",", "num_preds", ")", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "(", "num_thresholds", ",", "num_preds", ")", ")", "\n", "\n", "# Adaptation to query faster", "\n", "ground_truth_by_videoid", "=", "{", "}", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "ground_truth", ")", ":", "\n", "        ", "item", "[", "'index'", "]", "=", "i", "\n", "ground_truth_by_videoid", ".", "setdefault", "(", "item", "[", "'video-id'", "]", ",", "[", "]", ")", ".", "append", "(", "item", ")", "\n", "\n", "# Assigning true positive to truly grount truth instances.", "\n", "", "for", "idx", ",", "pred", "in", "enumerate", "(", "prediction", ")", ":", "\n", "        ", "if", "pred", "[", "'video-id'", "]", "in", "ground_truth_by_videoid", ":", "\n", "            ", "gts", "=", "ground_truth_by_videoid", "[", "pred", "[", "'video-id'", "]", "]", "\n", "", "else", ":", "\n", "            ", "fp", "[", ":", ",", "idx", "]", "=", "1", "\n", "continue", "\n", "\n", "", "tiou_arr", "=", "pairwise_temporal_iou", "(", "\n", "np", ".", "array", "(", "[", "pred", "[", "'t-start'", "]", ",", "pred", "[", "'t-end'", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "np", ".", "array", "(", "[", "gt", "[", "'t-start'", "]", ",", "gt", "[", "'t-end'", "]", "]", ")", "for", "gt", "in", "gts", "]", ")", ")", "\n", "tiou_arr", "=", "tiou_arr", ".", "reshape", "(", "-", "1", ")", "\n", "# We would like to retrieve the predictions with highest tiou score.", "\n", "tiou_sorted_idx", "=", "tiou_arr", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "for", "t_idx", ",", "tiou_threshold", "in", "enumerate", "(", "tiou_thresholds", ")", ":", "\n", "            ", "for", "j_idx", "in", "tiou_sorted_idx", ":", "\n", "                ", "if", "tiou_arr", "[", "j_idx", "]", "<", "tiou_threshold", ":", "\n", "                    ", "fp", "[", "t_idx", ",", "idx", "]", "=", "1", "\n", "break", "\n", "", "if", "lock_gt", "[", "t_idx", ",", "gts", "[", "j_idx", "]", "[", "'index'", "]", "]", ">=", "0", ":", "\n", "                    ", "continue", "\n", "# Assign as true positive after the filters above.", "\n", "", "tp", "[", "t_idx", ",", "idx", "]", "=", "1", "\n", "lock_gt", "[", "t_idx", ",", "gts", "[", "j_idx", "]", "[", "'index'", "]", "]", "=", "idx", "\n", "break", "\n", "\n", "", "if", "fp", "[", "t_idx", ",", "idx", "]", "==", "0", "and", "tp", "[", "t_idx", ",", "idx", "]", "==", "0", ":", "\n", "                ", "fp", "[", "t_idx", ",", "idx", "]", "=", "1", "\n", "\n", "", "", "", "tp_cumsum", "=", "np", ".", "cumsum", "(", "tp", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "fp_cumsum", "=", "np", ".", "cumsum", "(", "fp", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "recall_cumsum", "=", "tp_cumsum", "/", "num_positive", "\n", "\n", "precision_cumsum", "=", "tp_cumsum", "/", "(", "tp_cumsum", "+", "fp_cumsum", ")", "\n", "\n", "for", "t_idx", "in", "range", "(", "len", "(", "tiou_thresholds", ")", ")", ":", "\n", "        ", "ap", "[", "t_idx", "]", "=", "interpolated_precision_recall", "(", "precision_cumsum", "[", "t_idx", ",", ":", "]", ",", "\n", "recall_cumsum", "[", "t_idx", ",", ":", "]", ")", "\n", "\n", "", "return", "ap", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix": [[4, 66], ["isinstance", "isinstance", "numpy.unique", "len", "numpy.zeros", "enumerate", "numpy.bincount().reshape", "ValueError", "numpy.array", "isinstance", "TypeError", "TypeError", "numpy.array", "isinstance", "TypeError", "TypeError", "numpy.concatenate", "numpy.errstate", "numpy.nan_to_num", "numpy.bincount", "np.nan_to_num.sum", "type", "type", "np.nan_to_num.sum", "np.nan_to_num.sum"], "function", ["None"], ["def", "confusion_matrix", "(", "y_pred", ",", "y_real", ",", "normalize", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute confusion matrix.\n\n    Args:\n        y_pred (list[int] | np.ndarray[int]): Prediction labels.\n        y_real (list[int] | np.ndarray[int]): Ground truth labels.\n        normalize (str | None): Normalizes confusion matrix over the true\n            (rows), predicted (columns) conditions or all the population.\n            If None, confusion matrix will not be normalized. Options are\n            \"true\", \"pred\", \"all\", None. Default: None.\n\n    Returns:\n        np.ndarray: Confusion matrix.\n    \"\"\"", "\n", "if", "normalize", "not", "in", "[", "'true'", ",", "'pred'", ",", "'all'", ",", "None", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"normalize must be one of {'true', 'pred', \"", "\n", "\"'all', None}\"", ")", "\n", "\n", "", "if", "isinstance", "(", "y_pred", ",", "list", ")", ":", "\n", "        ", "y_pred", "=", "np", ".", "array", "(", "y_pred", ")", "\n", "", "if", "not", "isinstance", "(", "y_pred", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f'y_pred must be list or np.ndarray, but got {type(y_pred)}'", ")", "\n", "", "if", "not", "y_pred", ".", "dtype", "==", "np", ".", "int64", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f'y_pred dtype must be np.int64, but got {y_pred.dtype}'", ")", "\n", "\n", "", "if", "isinstance", "(", "y_real", ",", "list", ")", ":", "\n", "        ", "y_real", "=", "np", ".", "array", "(", "y_real", ")", "\n", "", "if", "not", "isinstance", "(", "y_real", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f'y_real must be list or np.ndarray, but got {type(y_real)}'", ")", "\n", "", "if", "not", "y_real", ".", "dtype", "==", "np", ".", "int64", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f'y_real dtype must be np.int64, but got {y_real.dtype}'", ")", "\n", "\n", "", "label_set", "=", "np", ".", "unique", "(", "np", ".", "concatenate", "(", "(", "y_pred", ",", "y_real", ")", ")", ")", "\n", "num_labels", "=", "len", "(", "label_set", ")", "\n", "max_label", "=", "label_set", "[", "-", "1", "]", "\n", "label_map", "=", "np", ".", "zeros", "(", "max_label", "+", "1", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "label_set", ")", ":", "\n", "        ", "label_map", "[", "label", "]", "=", "i", "\n", "\n", "", "y_pred_mapped", "=", "label_map", "[", "y_pred", "]", "\n", "y_real_mapped", "=", "label_map", "[", "y_real", "]", "\n", "\n", "confusion_mat", "=", "np", ".", "bincount", "(", "\n", "num_labels", "*", "y_real_mapped", "+", "y_pred_mapped", ",", "\n", "minlength", "=", "num_labels", "**", "2", ")", ".", "reshape", "(", "num_labels", ",", "num_labels", ")", "\n", "\n", "with", "np", ".", "errstate", "(", "all", "=", "'ignore'", ")", ":", "\n", "        ", "if", "normalize", "==", "'true'", ":", "\n", "            ", "confusion_mat", "=", "(", "\n", "confusion_mat", "/", "confusion_mat", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "", "elif", "normalize", "==", "'pred'", ":", "\n", "            ", "confusion_mat", "=", "(", "\n", "confusion_mat", "/", "confusion_mat", ".", "sum", "(", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "\n", "", "elif", "normalize", "==", "'all'", ":", "\n", "            ", "confusion_mat", "=", "(", "confusion_mat", "/", "confusion_mat", ".", "sum", "(", ")", ")", "\n", "", "confusion_mat", "=", "np", ".", "nan_to_num", "(", "confusion_mat", ")", "\n", "\n", "", "return", "confusion_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy": [[68, 88], ["numpy.argmax", "confusion_matrix().astype", "confusion_matrix().astype.sum", "numpy.diag", "numpy.mean", "accuracy.confusion_matrix", "zip"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix"], ["", "def", "mean_class_accuracy", "(", "scores", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Calculate mean class accuracy.\n\n    Args:\n        scores (list[np.ndarray]): Prediction scores for each class.\n        labels (list[int]): Ground truth labels.\n\n    Returns:\n        np.ndarray: Mean class accuracy.\n    \"\"\"", "\n", "pred", "=", "np", ".", "argmax", "(", "scores", ",", "axis", "=", "1", ")", "\n", "cf_mat", "=", "confusion_matrix", "(", "pred", ",", "labels", ")", ".", "astype", "(", "float", ")", "\n", "\n", "cls_cnt", "=", "cf_mat", ".", "sum", "(", "axis", "=", "1", ")", "\n", "cls_hit", "=", "np", ".", "diag", "(", "cf_mat", ")", "\n", "\n", "mean_class_acc", "=", "np", ".", "mean", "(", "\n", "[", "hit", "/", "cnt", "if", "cnt", "else", "0.0", "for", "cnt", ",", "hit", "in", "zip", "(", "cls_cnt", ",", "cls_hit", ")", "]", ")", "\n", "\n", "return", "mean_class_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy": [[90, 110], ["numpy.array", "numpy.logical_or.reduce", "res.append", "np.logical_or.reduce.sum", "numpy.argsort"], "function", ["None"], ["", "def", "top_k_accuracy", "(", "scores", ",", "labels", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Calculate top k accuracy score.\n\n    Args:\n        scores (list[np.ndarray]): Prediction scores for each class.\n        labels (list[int]): Ground truth labels.\n        topk (tuple[int]): K value for top_k_accuracy. Default: (1, ).\n\n    Returns:\n        list[float]: Top k accuracy score for each k.\n    \"\"\"", "\n", "res", "=", "[", "]", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "max_k_preds", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "1", ")", "[", ":", ",", "-", "k", ":", "]", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "match_array", "=", "np", ".", "logical_or", ".", "reduce", "(", "max_k_preds", "==", "labels", ",", "axis", "=", "1", ")", "\n", "topk_acc_score", "=", "match_array", ".", "sum", "(", ")", "/", "match_array", ".", "shape", "[", "0", "]", "\n", "res", ".", "append", "(", "topk_acc_score", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mmit_mean_average_precision": [[112, 133], ["zip", "numpy.mean", "accuracy.binary_precision_recall_curve", "results.append", "numpy.sum", "numpy.diff", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.binary_precision_recall_curve"], ["", "def", "mmit_mean_average_precision", "(", "scores", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Mean average precision for multi-label recognition. Used for reporting\n    MMIT style mAP on Multi-Moments in Times. The difference is that this\n    method calculates average-precision for each sample and averages them among\n    samples.\n\n    Args:\n        scores (list[np.ndarray]): Prediction scores of different classes for\n            each sample.\n        labels (list[np.ndarray]): Ground truth many-hot vector for each\n            sample.\n\n    Returns:\n        np.float: The MMIT style mean average precision.\n    \"\"\"", "\n", "results", "=", "[", "]", "\n", "for", "score", ",", "label", "in", "zip", "(", "scores", ",", "labels", ")", ":", "\n", "        ", "precision", ",", "recall", ",", "_", "=", "binary_precision_recall_curve", "(", "score", ",", "label", ")", "\n", "ap", "=", "-", "np", ".", "sum", "(", "np", ".", "diff", "(", "recall", ")", "*", "np", ".", "array", "(", "precision", ")", "[", ":", "-", "1", "]", ")", "\n", "results", ".", "append", "(", "ap", ")", "\n", "", "return", "np", ".", "mean", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_average_precision": [[135, 159], ["zip", "numpy.mean", "numpy.stack", "numpy.stack", "accuracy.binary_precision_recall_curve", "results.append", "numpy.sum", "numpy.isnan", "numpy.diff", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.binary_precision_recall_curve"], ["", "def", "mean_average_precision", "(", "scores", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Mean average precision for multi-label recognition.\n\n    Args:\n        scores (list[np.ndarray]): Prediction scores of different classes for\n            each sample.\n        labels (list[np.ndarray]): Ground truth many-hot vector for each\n            sample.\n\n    Returns:\n        np.float: The mean average precision.\n    \"\"\"", "\n", "results", "=", "[", "]", "\n", "scores", "=", "np", ".", "stack", "(", "scores", ")", ".", "T", "\n", "labels", "=", "np", ".", "stack", "(", "labels", ")", ".", "T", "\n", "\n", "for", "score", ",", "label", "in", "zip", "(", "scores", ",", "labels", ")", ":", "\n", "        ", "precision", ",", "recall", ",", "_", "=", "binary_precision_recall_curve", "(", "score", ",", "label", ")", "\n", "ap", "=", "-", "np", ".", "sum", "(", "np", ".", "diff", "(", "recall", ")", "*", "np", ".", "array", "(", "precision", ")", "[", ":", "-", "1", "]", ")", "\n", "results", ".", "append", "(", "ap", ")", "\n", "", "results", "=", "[", "x", "for", "x", "in", "results", "if", "not", "np", ".", "isnan", "(", "x", ")", "]", "\n", "if", "results", "==", "[", "]", ":", "\n", "        ", "return", "np", ".", "nan", "\n", "", "return", "np", ".", "mean", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.binary_precision_recall_curve": [[161, 203], ["isinstance", "isinstance", "tps.searchsorted", "slice", "numpy.argsort", "numpy.where", "numpy.cumsum", "numpy.diff", "numpy.isnan"], "function", ["None"], ["", "def", "binary_precision_recall_curve", "(", "y_score", ",", "y_true", ")", ":", "\n", "    ", "\"\"\"Calculate the binary precision recall curve at step thresholds.\n\n    Args:\n        y_score (np.ndarray): Prediction scores for each class.\n            Shape should be (num_classes, ).\n        y_true (np.ndarray): Ground truth many-hot vector.\n            Shape should be (num_classes, ).\n\n    Returns:\n        precision (np.ndarray): The precision of different thresholds.\n        recall (np.ndarray): The recall of different thresholds.\n        thresholds (np.ndarray): Different thresholds at which precison and\n            recall are tested.\n    \"\"\"", "\n", "assert", "isinstance", "(", "y_score", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "y_true", ",", "np", ".", "ndarray", ")", "\n", "assert", "y_score", ".", "shape", "==", "y_true", ".", "shape", "\n", "\n", "# make y_true a boolean vector", "\n", "y_true", "=", "(", "y_true", "==", "1", ")", "\n", "# sort scores and corresponding truth values", "\n", "desc_score_indices", "=", "np", ".", "argsort", "(", "y_score", ",", "kind", "=", "'mergesort'", ")", "[", ":", ":", "-", "1", "]", "\n", "y_score", "=", "y_score", "[", "desc_score_indices", "]", "\n", "y_true", "=", "y_true", "[", "desc_score_indices", "]", "\n", "# There may be ties in values, therefore find the `distinct_value_inds`", "\n", "distinct_value_inds", "=", "np", ".", "where", "(", "np", ".", "diff", "(", "y_score", ")", ")", "[", "0", "]", "\n", "threshold_inds", "=", "np", ".", "r_", "[", "distinct_value_inds", ",", "y_true", ".", "size", "-", "1", "]", "\n", "# accumulate the true positives with decreasing threshold", "\n", "tps", "=", "np", ".", "cumsum", "(", "y_true", ")", "[", "threshold_inds", "]", "\n", "fps", "=", "1", "+", "threshold_inds", "-", "tps", "\n", "thresholds", "=", "y_score", "[", "threshold_inds", "]", "\n", "\n", "precision", "=", "tps", "/", "(", "tps", "+", "fps", ")", "\n", "precision", "[", "np", ".", "isnan", "(", "precision", ")", "]", "=", "0", "\n", "recall", "=", "tps", "/", "tps", "[", "-", "1", "]", "\n", "# stop when full recall attained", "\n", "# and reverse the outputs so recall is decreasing", "\n", "last_ind", "=", "tps", ".", "searchsorted", "(", "tps", "[", "-", "1", "]", ")", "\n", "sl", "=", "slice", "(", "last_ind", ",", "None", ",", "-", "1", ")", "\n", "\n", "return", "np", ".", "r_", "[", "precision", "[", "sl", "]", ",", "1", "]", ",", "np", ".", "r_", "[", "recall", "[", "sl", "]", ",", "0", "]", ",", "thresholds", "[", "sl", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou": [[205, 263], ["numpy.empty", "range", "ValueError", "numpy.empty", "numpy.maximum", "numpy.minimum", "numpy.squeeze", "segments_intersection.astype", "numpy.squeeze", "segments_intersection.astype"], "function", ["None"], ["", "def", "pairwise_temporal_iou", "(", "candidate_segments", ",", "\n", "target_segments", ",", "\n", "calculate_overlap_self", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute intersection over union between segments.\n\n    Args:\n        candidate_segments (np.ndarray): 1-dim/2-dim array in format\n            ``[init, end]/[m x 2:=[init, end]]``.\n        target_segments (np.ndarray): 2-dim array in format\n            ``[n x 2:=[init, end]]``.\n        calculate_overlap_self (bool): Whether to calculate overlap_self\n            (union / candidate_length) or not. Default: False.\n\n    Returns:\n        t_iou (np.ndarray): 1-dim array [n] /\n            2-dim array [n x m] with IoU ratio.\n        t_overlap_self (np.ndarray, optional): 1-dim array [n] /\n            2-dim array [n x m] with overlap_self, returns when\n            calculate_overlap_self is True.\n    \"\"\"", "\n", "candidate_segments_ndim", "=", "candidate_segments", ".", "ndim", "\n", "if", "target_segments", ".", "ndim", "!=", "2", "or", "candidate_segments_ndim", "not", "in", "[", "1", ",", "2", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Dimension of arguments is incorrect'", ")", "\n", "\n", "", "if", "candidate_segments_ndim", "==", "1", ":", "\n", "        ", "candidate_segments", "=", "candidate_segments", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "n", ",", "m", "=", "target_segments", ".", "shape", "[", "0", "]", ",", "candidate_segments", ".", "shape", "[", "0", "]", "\n", "t_iou", "=", "np", ".", "empty", "(", "(", "n", ",", "m", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "calculate_overlap_self", ":", "\n", "        ", "t_overlap_self", "=", "np", ".", "empty", "(", "(", "n", ",", "m", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "        ", "candidate_segment", "=", "candidate_segments", "[", "i", ",", ":", "]", "\n", "tt1", "=", "np", ".", "maximum", "(", "candidate_segment", "[", "0", "]", ",", "target_segments", "[", ":", ",", "0", "]", ")", "\n", "tt2", "=", "np", ".", "minimum", "(", "candidate_segment", "[", "1", "]", ",", "target_segments", "[", ":", ",", "1", "]", ")", "\n", "# Intersection including Non-negative overlap score.", "\n", "segments_intersection", "=", "(", "tt2", "-", "tt1", ")", ".", "clip", "(", "0", ")", "\n", "# Segment union.", "\n", "segments_union", "=", "(", "(", "target_segments", "[", ":", ",", "1", "]", "-", "target_segments", "[", ":", ",", "0", "]", ")", "+", "\n", "(", "candidate_segment", "[", "1", "]", "-", "candidate_segment", "[", "0", "]", ")", "-", "\n", "segments_intersection", ")", "\n", "# Compute overlap as the ratio of the intersection", "\n", "# over union of two segments.", "\n", "t_iou", "[", ":", ",", "i", "]", "=", "(", "segments_intersection", ".", "astype", "(", "float", ")", "/", "segments_union", ")", "\n", "if", "calculate_overlap_self", ":", "\n", "            ", "candidate_length", "=", "candidate_segment", "[", "1", "]", "-", "candidate_segment", "[", "0", "]", "\n", "t_overlap_self", "[", ":", ",", "i", "]", "=", "(", "\n", "segments_intersection", ".", "astype", "(", "float", ")", "/", "candidate_length", ")", "\n", "\n", "", "", "if", "candidate_segments_ndim", "==", "1", ":", "\n", "        ", "t_iou", "=", "np", ".", "squeeze", "(", "t_iou", ",", "axis", "=", "1", ")", "\n", "", "if", "calculate_overlap_self", ":", "\n", "        ", "if", "candidate_segments_ndim", "==", "1", ":", "\n", "            ", "t_overlap_self", "=", "np", ".", "squeeze", "(", "t_overlap_self", ",", "axis", "=", "1", ")", "\n", "", "return", "t_iou", ",", "t_overlap_self", "\n", "\n", "", "return", "t_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_recall_at_avg_proposals": [[265, 387], ["numpy.linspace", "len", "numpy.empty", "numpy.empty", "numpy.empty", "enumerate", "np.empty.mean", "numpy.trapz", "this_video_proposals[].astype", "ground_truth_video_id[].astype", "numpy.minimum", "accuracy.pairwise_temporal_iou", "score_list.append", "enumerate", "float", "float", "proposals_video_id[].argsort", "score_list.append", "numpy.expand_dims", "numpy.expand_dims", "int", "numpy.arange", "numpy.minimum", "enumerate", "np.empty.sum", "np.empty.sum", "float", "float", "numpy.zeros", "float", "numpy.count_nonzero", "true_positives_temporal_iou[].sum"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou"], ["", "def", "average_recall_at_avg_proposals", "(", "ground_truth", ",", "\n", "proposals", ",", "\n", "total_num_proposals", ",", "\n", "max_avg_proposals", "=", "None", ",", "\n", "temporal_iou_thresholds", "=", "np", ".", "linspace", "(", "\n", "0.5", ",", "0.95", ",", "10", ")", ")", ":", "\n", "    ", "\"\"\"Computes the average recall given an average number (percentile) of\n    proposals per video.\n\n    Args:\n        ground_truth (dict): Dict containing the ground truth instances.\n        proposals (dict): Dict containing the proposal instances.\n        total_num_proposals (int): Total number of proposals in the\n            proposal dict.\n        max_avg_proposals (int | None): Max number of proposals for one video.\n            Default: None.\n        temporal_iou_thresholds (np.ndarray): 1D array with temporal_iou\n            thresholds. Default: ``np.linspace(0.5, 0.95, 10)``.\n\n    Returns:\n        tuple([np.ndarray, np.ndarray, np.ndarray, float]):\n            (recall, average_recall, proposals_per_video, auc)\n            In recall, ``recall[i,j]`` is recall at i-th temporal_iou threshold\n            at the j-th average number (percentile) of average number of\n            proposals per video. The average_recall is recall averaged\n            over a list of temporal_iou threshold (1D array). This is\n            equivalent to ``recall.mean(axis=0)``. The ``proposals_per_video``\n            is the average number of proposals per video. The auc is the area\n            under ``AR@AN`` curve.\n    \"\"\"", "\n", "\n", "total_num_videos", "=", "len", "(", "ground_truth", ")", "\n", "\n", "if", "not", "max_avg_proposals", ":", "\n", "        ", "max_avg_proposals", "=", "float", "(", "total_num_proposals", ")", "/", "total_num_videos", "\n", "\n", "", "ratio", "=", "(", "max_avg_proposals", "*", "float", "(", "total_num_videos", ")", "/", "total_num_proposals", ")", "\n", "\n", "# For each video, compute temporal_iou scores among the retrieved proposals", "\n", "score_list", "=", "[", "]", "\n", "total_num_retrieved_proposals", "=", "0", "\n", "for", "video_id", "in", "ground_truth", ":", "\n", "# Get proposals for this video.", "\n", "        ", "proposals_video_id", "=", "proposals", "[", "video_id", "]", "\n", "this_video_proposals", "=", "proposals_video_id", "[", ":", ",", ":", "2", "]", "\n", "# Sort proposals by score.", "\n", "sort_idx", "=", "proposals_video_id", "[", ":", ",", "2", "]", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "this_video_proposals", "=", "this_video_proposals", "[", "sort_idx", ",", ":", "]", ".", "astype", "(", "\n", "np", ".", "float32", ")", "\n", "\n", "# Get ground-truth instances associated to this video.", "\n", "ground_truth_video_id", "=", "ground_truth", "[", "video_id", "]", "\n", "this_video_ground_truth", "=", "ground_truth_video_id", "[", ":", ",", ":", "2", "]", ".", "astype", "(", "\n", "np", ".", "float32", ")", "\n", "if", "this_video_proposals", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "n", "=", "this_video_ground_truth", ".", "shape", "[", "0", "]", "\n", "score_list", ".", "append", "(", "np", ".", "zeros", "(", "(", "n", ",", "1", ")", ")", ")", "\n", "continue", "\n", "\n", "", "if", "this_video_proposals", ".", "ndim", "!=", "2", ":", "\n", "            ", "this_video_proposals", "=", "np", ".", "expand_dims", "(", "this_video_proposals", ",", "axis", "=", "0", ")", "\n", "", "if", "this_video_ground_truth", ".", "ndim", "!=", "2", ":", "\n", "            ", "this_video_ground_truth", "=", "np", ".", "expand_dims", "(", "\n", "this_video_ground_truth", ",", "axis", "=", "0", ")", "\n", "\n", "", "num_retrieved_proposals", "=", "np", ".", "minimum", "(", "\n", "int", "(", "this_video_proposals", ".", "shape", "[", "0", "]", "*", "ratio", ")", ",", "\n", "this_video_proposals", ".", "shape", "[", "0", "]", ")", "\n", "total_num_retrieved_proposals", "+=", "num_retrieved_proposals", "\n", "this_video_proposals", "=", "this_video_proposals", "[", ":", "\n", "num_retrieved_proposals", ",", ":", "]", "\n", "\n", "# Compute temporal_iou scores.", "\n", "t_iou", "=", "pairwise_temporal_iou", "(", "this_video_proposals", ",", "\n", "this_video_ground_truth", ")", "\n", "score_list", ".", "append", "(", "t_iou", ")", "\n", "\n", "# Given that the length of the videos is really varied, we", "\n", "# compute the number of proposals in terms of a ratio of the total", "\n", "# proposals retrieved, i.e. average recall at a percentage of proposals", "\n", "# retrieved per video.", "\n", "\n", "# Computes average recall.", "\n", "", "pcn_list", "=", "np", ".", "arange", "(", "1", ",", "101", ")", "/", "100.0", "*", "(", "\n", "max_avg_proposals", "*", "float", "(", "total_num_videos", ")", "/", "\n", "total_num_retrieved_proposals", ")", "\n", "matches", "=", "np", ".", "empty", "(", "(", "total_num_videos", ",", "pcn_list", ".", "shape", "[", "0", "]", ")", ")", "\n", "positives", "=", "np", ".", "empty", "(", "total_num_videos", ")", "\n", "recall", "=", "np", ".", "empty", "(", "(", "temporal_iou_thresholds", ".", "shape", "[", "0", "]", ",", "pcn_list", ".", "shape", "[", "0", "]", ")", ")", "\n", "# Iterates over each temporal_iou threshold.", "\n", "for", "ridx", ",", "temporal_iou", "in", "enumerate", "(", "temporal_iou_thresholds", ")", ":", "\n", "# Inspect positives retrieved per video at different", "\n", "# number of proposals (percentage of the total retrieved).", "\n", "        ", "for", "i", ",", "score", "in", "enumerate", "(", "score_list", ")", ":", "\n", "# Total positives per video.", "\n", "            ", "positives", "[", "i", "]", "=", "score", ".", "shape", "[", "0", "]", "\n", "# Find proposals that satisfies minimum temporal_iou threshold.", "\n", "true_positives_temporal_iou", "=", "score", ">=", "temporal_iou", "\n", "# Get number of proposals as a percentage of total retrieved.", "\n", "pcn_proposals", "=", "np", ".", "minimum", "(", "\n", "(", "score", ".", "shape", "[", "1", "]", "*", "pcn_list", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "score", ".", "shape", "[", "1", "]", ")", "\n", "\n", "for", "j", ",", "num_retrieved_proposals", "in", "enumerate", "(", "pcn_proposals", ")", ":", "\n", "# Compute the number of matches", "\n", "# for each percentage of the proposals", "\n", "                ", "matches", "[", "i", ",", "j", "]", "=", "np", ".", "count_nonzero", "(", "\n", "(", "true_positives_temporal_iou", "[", ":", ",", ":", "num_retrieved_proposals", "]", "\n", ")", ".", "sum", "(", "axis", "=", "1", ")", ")", "\n", "\n", "# Computes recall given the set of matches per video.", "\n", "", "", "recall", "[", "ridx", ",", ":", "]", "=", "matches", ".", "sum", "(", "axis", "=", "0", ")", "/", "positives", ".", "sum", "(", ")", "\n", "\n", "# Recall is averaged.", "\n", "", "avg_recall", "=", "recall", ".", "mean", "(", "axis", "=", "0", ")", "\n", "\n", "# Get the average number of proposals per video.", "\n", "proposals_per_video", "=", "pcn_list", "*", "(", "\n", "float", "(", "total_num_retrieved_proposals", ")", "/", "total_num_videos", ")", "\n", "# Get AUC", "\n", "area_under_curve", "=", "np", ".", "trapz", "(", "avg_recall", ",", "proposals_per_video", ")", "\n", "auc", "=", "100.", "*", "float", "(", "area_under_curve", ")", "/", "proposals_per_video", "[", "-", "1", "]", "\n", "return", "recall", ",", "avg_recall", ",", "proposals_per_video", ",", "auc", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.get_weighted_score": [[389, 414], ["len", "range", "numpy.array", "numpy.array", "list", "len", "len", "len", "len", "numpy.dot"], "function", ["None"], ["", "def", "get_weighted_score", "(", "score_list", ",", "coeff_list", ")", ":", "\n", "    ", "\"\"\"Get weighted score with given scores and coefficients.\n\n    Given n predictions by different classifier: [score_1, score_2, ...,\n    score_n] (score_list) and their coefficients: [coeff_1, coeff_2, ...,\n    coeff_n] (coeff_list), return weighted score: weighted_score =\n    score_1 * coeff_1 + score_2 * coeff_2 + ... + score_n * coeff_n\n\n    Args:\n        score_list (list[list[np.ndarray]]): List of list of scores, with shape\n            n(number of predictions) X num_samples X num_classes\n        coeff_list (list[float]): List of coefficients, with shape n.\n\n    Returns:\n        list[np.ndarray]: List of weighted scores.\n    \"\"\"", "\n", "assert", "len", "(", "score_list", ")", "==", "len", "(", "coeff_list", ")", "\n", "num_samples", "=", "len", "(", "score_list", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "score_list", ")", ")", ":", "\n", "        ", "assert", "len", "(", "score_list", "[", "i", "]", ")", "==", "num_samples", "\n", "\n", "", "scores", "=", "np", ".", "array", "(", "score_list", ")", "# (num_coeff, num_samples, num_classes)", "\n", "coeff", "=", "np", ".", "array", "(", "coeff_list", ")", "# (num_coeff, )", "\n", "weighted_scores", "=", "list", "(", "np", ".", "dot", "(", "scores", ".", "T", ",", "coeff", ")", ".", "T", ")", "\n", "return", "weighted_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax": [[416, 420], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["", "def", "softmax", "(", "x", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\"Compute softmax values for each sets of scores in x.\"\"\"", "\n", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ",", "axis", "=", "dim", ",", "keepdims", "=", "True", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", "axis", "=", "dim", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.interpolated_precision_recall": [[422, 439], ["numpy.hstack", "numpy.hstack", "numpy.sum", "range", "max", "numpy.where", "len"], "function", ["None"], ["", "def", "interpolated_precision_recall", "(", "precision", ",", "recall", ")", ":", "\n", "    ", "\"\"\"Interpolated AP - VOCdevkit from VOC 2011.\n\n    Args:\n        precision (np.ndarray): The precision of different thresholds.\n        recall (np.ndarray): The recall of different thresholds.\n\n    Returns\uff1a\n        float: Average precision score.\n    \"\"\"", "\n", "mprecision", "=", "np", ".", "hstack", "(", "[", "[", "0", "]", ",", "precision", ",", "[", "0", "]", "]", ")", "\n", "mrecall", "=", "np", ".", "hstack", "(", "[", "[", "0", "]", ",", "recall", ",", "[", "1", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "mprecision", ")", "-", "1", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "mprecision", "[", "i", "]", "=", "max", "(", "mprecision", "[", "i", "]", ",", "mprecision", "[", "i", "+", "1", "]", ")", "\n", "", "idx", "=", "np", ".", "where", "(", "mrecall", "[", "1", ":", ":", "]", "!=", "mrecall", "[", "0", ":", "-", "1", "]", ")", "[", "0", "]", "+", "1", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrecall", "[", "idx", "]", "-", "mrecall", "[", "idx", "-", "1", "]", ")", "*", "mprecision", "[", "idx", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_precision_at_temporal_iou": [[441, 525], ["numpy.linspace", "numpy.zeros", "dict", "numpy.array", "prediction[].astype", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.cumsum().astype", "numpy.cumsum().astype", "range", "len", "len", "len", "numpy.argsort", "accuracy.pairwise_temporal_iou", "enumerate", "len", "accuracy.interpolated_precision_recall", "numpy.ones", "len", "len", "len", "len", "numpy.array", "this_pred[].astype", "pairwise_temporal_iou.argsort", "numpy.cumsum", "numpy.cumsum", "len", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.interpolated_precision_recall"], ["", "def", "average_precision_at_temporal_iou", "(", "ground_truth", ",", "\n", "prediction", ",", "\n", "temporal_iou_thresholds", "=", "(", "np", ".", "linspace", "(", "\n", "0.5", ",", "0.95", ",", "10", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute average precision (in detection task) between ground truth and\n    predicted data frames. If multiple predictions match the same predicted\n    segment, only the one with highest score is matched as true positive. This\n    code is greatly inspired by Pascal VOC devkit.\n\n    Args:\n        ground_truth (dict): Dict containing the ground truth instances.\n            Key: 'video_id'\n            Value (np.ndarray): 1D array of 't-start' and 't-end'.\n        prediction (np.ndarray): 2D array containing the information of\n            proposal instances, including 'video_id', 'class_id', 't-start',\n            't-end' and 'score'.\n        temporal_iou_thresholds (np.ndarray): 1D array with temporal_iou\n            thresholds. Default: ``np.linspace(0.5, 0.95, 10)``.\n\n    Returns:\n        np.ndarray: 1D array of average precision score.\n    \"\"\"", "\n", "ap", "=", "np", ".", "zeros", "(", "len", "(", "temporal_iou_thresholds", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "len", "(", "prediction", ")", "<", "1", ":", "\n", "        ", "return", "ap", "\n", "\n", "", "num_gts", "=", "0.", "\n", "lock_gt", "=", "dict", "(", ")", "\n", "for", "key", "in", "ground_truth", ":", "\n", "        ", "lock_gt", "[", "key", "]", "=", "np", ".", "ones", "(", "\n", "(", "len", "(", "temporal_iou_thresholds", ")", ",", "len", "(", "ground_truth", "[", "key", "]", ")", ")", ")", "*", "-", "1", "\n", "num_gts", "+=", "len", "(", "ground_truth", "[", "key", "]", ")", "\n", "\n", "# Sort predictions by decreasing score order.", "\n", "", "prediction", "=", "np", ".", "array", "(", "prediction", ")", "\n", "scores", "=", "prediction", "[", ":", ",", "4", "]", ".", "astype", "(", "float", ")", "\n", "sort_idx", "=", "np", ".", "argsort", "(", "scores", ")", "[", ":", ":", "-", "1", "]", "\n", "prediction", "=", "prediction", "[", "sort_idx", "]", "\n", "\n", "# Initialize true positive and false positive vectors.", "\n", "tp", "=", "np", ".", "zeros", "(", "(", "len", "(", "temporal_iou_thresholds", ")", ",", "len", "(", "prediction", ")", ")", ",", "\n", "dtype", "=", "np", ".", "int32", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "(", "len", "(", "temporal_iou_thresholds", ")", ",", "len", "(", "prediction", ")", ")", ",", "\n", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "# Assigning true positive to truly grount truth instances.", "\n", "for", "idx", ",", "this_pred", "in", "enumerate", "(", "prediction", ")", ":", "\n", "\n", "# Check if there is at least one ground truth in the video.", "\n", "        ", "if", "this_pred", "[", "0", "]", "in", "ground_truth", ":", "\n", "            ", "this_gt", "=", "np", ".", "array", "(", "ground_truth", "[", "this_pred", "[", "0", "]", "]", ",", "dtype", "=", "float", ")", "\n", "", "else", ":", "\n", "            ", "fp", "[", ":", ",", "idx", "]", "=", "1", "\n", "continue", "\n", "\n", "", "t_iou", "=", "pairwise_temporal_iou", "(", "this_pred", "[", "2", ":", "4", "]", ".", "astype", "(", "float", ")", ",", "this_gt", ")", "\n", "# We would like to retrieve the predictions with highest t_iou score.", "\n", "t_iou_sorted_idx", "=", "t_iou", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "for", "t_idx", ",", "t_iou_threshold", "in", "enumerate", "(", "temporal_iou_thresholds", ")", ":", "\n", "            ", "for", "jdx", "in", "t_iou_sorted_idx", ":", "\n", "                ", "if", "t_iou", "[", "jdx", "]", "<", "t_iou_threshold", ":", "\n", "                    ", "fp", "[", "t_idx", ",", "idx", "]", "=", "1", "\n", "break", "\n", "", "if", "lock_gt", "[", "this_pred", "[", "0", "]", "]", "[", "t_idx", ",", "jdx", "]", ">=", "0", ":", "\n", "                    ", "continue", "\n", "# Assign as true positive after the filters above.", "\n", "", "tp", "[", "t_idx", ",", "idx", "]", "=", "1", "\n", "lock_gt", "[", "this_pred", "[", "0", "]", "]", "[", "t_idx", ",", "jdx", "]", "=", "idx", "\n", "break", "\n", "\n", "", "if", "fp", "[", "t_idx", ",", "idx", "]", "==", "0", "and", "tp", "[", "t_idx", ",", "idx", "]", "==", "0", ":", "\n", "                ", "fp", "[", "t_idx", ",", "idx", "]", "=", "1", "\n", "\n", "", "", "", "tp_cumsum", "=", "np", ".", "cumsum", "(", "tp", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "fp_cumsum", "=", "np", ".", "cumsum", "(", "fp", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "recall_cumsum", "=", "tp_cumsum", "/", "num_gts", "\n", "\n", "precision_cumsum", "=", "tp_cumsum", "/", "(", "tp_cumsum", "+", "fp_cumsum", ")", "\n", "\n", "for", "t_idx", "in", "range", "(", "len", "(", "temporal_iou_thresholds", ")", ")", ":", "\n", "        ", "ap", "[", "t_idx", "]", "=", "interpolated_precision_recall", "(", "precision_cumsum", "[", "t_idx", ",", ":", "]", ",", "\n", "recall_cumsum", "[", "t_idx", ",", ":", "]", ")", "\n", "\n", "", "return", "ap", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.det2csv": [[12, 30], ["range", "len", "enumerate", "tuple", "csv_results.append", "bbox.tolist"], "function", ["None"], ["def", "det2csv", "(", "dataset", ",", "results", ",", "custom_classes", ")", ":", "\n", "    ", "csv_results", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "video_id", "=", "dataset", ".", "video_infos", "[", "idx", "]", "[", "'video_id'", "]", "\n", "timestamp", "=", "dataset", ".", "video_infos", "[", "idx", "]", "[", "'timestamp'", "]", "\n", "result", "=", "results", "[", "idx", "]", "\n", "for", "label", ",", "_", "in", "enumerate", "(", "result", ")", ":", "\n", "            ", "for", "bbox", "in", "result", "[", "label", "]", ":", "\n", "                ", "bbox_", "=", "tuple", "(", "bbox", ".", "tolist", "(", ")", ")", "\n", "if", "custom_classes", "is", "not", "None", ":", "\n", "                    ", "actual_label", "=", "custom_classes", "[", "label", "+", "1", "]", "\n", "", "else", ":", "\n", "                    ", "actual_label", "=", "label", "+", "1", "\n", "", "csv_results", ".", "append", "(", "(", "\n", "video_id", ",", "\n", "timestamp", ",", "\n", ")", "+", "bbox_", "[", ":", "4", "]", "+", "(", "actual_label", ",", ")", "+", "bbox_", "[", "4", ":", "]", ")", "\n", "", "", "", "return", "csv_results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.results2csv": [[33, 47], ["isinstance", "ava_utils.det2csv", "isinstance", "str", "open", "f.write", "f.write", "map"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.det2csv"], ["", "def", "results2csv", "(", "dataset", ",", "results", ",", "out_file", ",", "custom_classes", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "results", "[", "0", "]", ",", "list", ")", ":", "\n", "        ", "csv_results", "=", "det2csv", "(", "dataset", ",", "results", ",", "custom_classes", ")", "\n", "\n", "# save space for float", "\n", "", "def", "to_str", "(", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "float", ")", ":", "\n", "            ", "return", "f'{item:.3f}'", "\n", "", "return", "str", "(", "item", ")", "\n", "\n", "", "with", "open", "(", "out_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "csv_result", "in", "csv_results", ":", "\n", "            ", "f", ".", "write", "(", "','", ".", "join", "(", "map", "(", "to_str", ",", "csv_result", ")", ")", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time": [[49, 51], ["print", "time.time"], "function", ["None"], ["", "", "", "def", "print_time", "(", "message", ",", "start", ")", ":", "\n", "    ", "print", "(", "'==> %g seconds to %s'", "%", "(", "time", ".", "time", "(", ")", "-", "start", ",", "message", ")", ",", "flush", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.make_image_key": [[53, 56], ["int"], "function", ["None"], ["", "def", "make_image_key", "(", "video_id", ",", "timestamp", ")", ":", "\n", "    ", "\"\"\"Returns a unique identifier for a video id & timestamp.\"\"\"", "\n", "return", "f'{video_id},{int(timestamp):04d}'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_csv": [[58, 106], ["time.time", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "csv.reader", "ava_utils.print_time", "ava_utils.make_image_key", "int", "entries[].append", "sorted", "len", "float", "len", "float"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.make_image_key"], ["", "def", "read_csv", "(", "csv_file", ",", "class_whitelist", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads boxes and class labels from a CSV file in the AVA format.\n\n    CSV file format described at https://research.google.com/ava/download.html.\n\n    Args:\n        csv_file: A file object.\n        class_whitelist: If provided, boxes corresponding to (integer) class\n        labels not in this set are skipped.\n\n    Returns:\n        boxes: A dictionary mapping each unique image key (string) to a list of\n        boxes, given as coordinates [y1, x1, y2, x2].\n        labels: A dictionary mapping each unique image key (string) to a list\n        of integer class lables, matching the corresponding box in `boxes`.\n        scores: A dictionary mapping each unique image key (string) to a list\n        of score values lables, matching the corresponding label in `labels`.\n        If scores are not provided in the csv, then they will default to 1.0.\n    \"\"\"", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "entries", "=", "defaultdict", "(", "list", ")", "\n", "boxes", "=", "defaultdict", "(", "list", ")", "\n", "labels", "=", "defaultdict", "(", "list", ")", "\n", "scores", "=", "defaultdict", "(", "list", ")", "\n", "reader", "=", "csv", ".", "reader", "(", "csv_file", ")", "\n", "for", "row", "in", "reader", ":", "\n", "        ", "assert", "len", "(", "row", ")", "in", "[", "7", ",", "8", "]", ",", "'Wrong number of columns: '", "+", "row", "\n", "image_key", "=", "make_image_key", "(", "row", "[", "0", "]", ",", "row", "[", "1", "]", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "float", "(", "n", ")", "for", "n", "in", "row", "[", "2", ":", "6", "]", "]", "\n", "action_id", "=", "int", "(", "row", "[", "6", "]", ")", "\n", "if", "class_whitelist", "and", "action_id", "not", "in", "class_whitelist", ":", "\n", "            ", "continue", "\n", "\n", "", "score", "=", "1.0", "\n", "if", "len", "(", "row", ")", "==", "8", ":", "\n", "            ", "score", "=", "float", "(", "row", "[", "7", "]", ")", "\n", "\n", "", "entries", "[", "image_key", "]", ".", "append", "(", "(", "score", ",", "action_id", ",", "y1", ",", "x1", ",", "y2", ",", "x2", ")", ")", "\n", "\n", "", "for", "image_key", "in", "entries", ":", "\n", "# Evaluation API assumes boxes with descending scores", "\n", "        ", "entry", "=", "sorted", "(", "entries", "[", "image_key", "]", ",", "key", "=", "lambda", "tup", ":", "-", "tup", "[", "0", "]", ")", "\n", "boxes", "[", "image_key", "]", "=", "[", "x", "[", "2", ":", "]", "for", "x", "in", "entry", "]", "\n", "labels", "[", "image_key", "]", "=", "[", "x", "[", "1", "]", "for", "x", "in", "entry", "]", "\n", "scores", "[", "image_key", "]", "=", "[", "x", "[", "0", "]", "for", "x", "in", "entry", "]", "\n", "\n", "", "print_time", "(", "'read file '", "+", "csv_file", ".", "name", ",", "start", ")", "\n", "return", "boxes", ",", "labels", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_exclusions": [[108, 126], ["set", "csv.reader", "set.add", "len", "ava_utils.make_image_key"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.make_image_key"], ["", "def", "read_exclusions", "(", "exclusions_file", ")", ":", "\n", "    ", "\"\"\"Reads a CSV file of excluded timestamps.\n\n    Args:\n        exclusions_file: A file object containing a csv of video-id,timestamp.\n\n    Returns:\n        A set of strings containing excluded image keys, e.g.\n        \"aaaaaaaaaaa,0904\",\n        or an empty set if exclusions file is None.\n    \"\"\"", "\n", "excluded", "=", "set", "(", ")", "\n", "if", "exclusions_file", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "exclusions_file", ")", "\n", "", "for", "row", "in", "reader", ":", "\n", "        ", "assert", "len", "(", "row", ")", "==", "2", ",", "'Expected only 2 columns, got: '", "+", "row", "\n", "excluded", ".", "add", "(", "make_image_key", "(", "row", "[", "0", "]", ",", "row", "[", "1", "]", ")", ")", "\n", "", "return", "excluded", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_labelmap": [[128, 152], ["set", "line.startswith", "line.split", "line.startswith", "line.startswith", "int", "labelmap.append", "set.add", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "read_labelmap", "(", "labelmap_file", ")", ":", "\n", "    ", "\"\"\"Reads a labelmap without the dependency on protocol buffers.\n\n    Args:\n        labelmap_file: A file object containing a label map protocol buffer.\n\n    Returns:\n        labelmap: The label map in the form used by the\n        object_detection_evaluation\n        module - a list of {\"id\": integer, \"name\": classname } dicts.\n        class_ids: A set containing all of the valid class id integers.\n    \"\"\"", "\n", "labelmap", "=", "[", "]", "\n", "class_ids", "=", "set", "(", ")", "\n", "name", "=", "''", "\n", "class_id", "=", "''", "\n", "for", "line", "in", "labelmap_file", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'  name:'", ")", ":", "\n", "            ", "name", "=", "line", ".", "split", "(", "'\"'", ")", "[", "1", "]", "\n", "", "elif", "line", ".", "startswith", "(", "'  id:'", ")", "or", "line", ".", "startswith", "(", "'  label_id:'", ")", ":", "\n", "            ", "class_id", "=", "int", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "-", "1", "]", ")", "\n", "labelmap", ".", "append", "(", "{", "'id'", ":", "class_id", ",", "'name'", ":", "name", "}", ")", "\n", "class_ids", ".", "add", "(", "class_id", ")", "\n", "", "", "return", "labelmap", ",", "class_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.ava_eval": [[155, 236], ["time.time", "ava_utils.read_labelmap", "ava_utils.read_csv", "time.time", "ava_utils.read_csv", "ava_evaluation.object_detection_evaluation.PascalDetectionEvaluator", "time.time", "time.time", "time.time", "det_eval.PascalDetectionEvaluator.evaluate", "open", "set().issubset", "open", "ava_utils.print_time", "ava_utils.read_exclusions", "list", "open", "ava_utils.print_time", "det_eval.PascalDetectionEvaluator.add_single_ground_truth_image_info", "ava_utils.print_time", "det_eval.PascalDetectionEvaluator.add_single_detected_image_info", "ava_utils.print_time", "ava_utils.print_time", "print", "set", "open", "logging.info", "logging.info", "set", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_labelmap", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_csv", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_csv", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.read_exclusions", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.add_single_ground_truth_image_info", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.add_single_detected_image_info", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.print_time"], ["", "def", "ava_eval", "(", "result_file", ",", "\n", "result_type", ",", "\n", "label_file", ",", "\n", "ann_file", ",", "\n", "exclude_file", ",", "\n", "verbose", "=", "True", ",", "\n", "custom_classes", "=", "None", ")", ":", "\n", "\n", "    ", "assert", "result_type", "in", "[", "'mAP'", "]", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "categories", ",", "class_whitelist", "=", "read_labelmap", "(", "open", "(", "label_file", ")", ")", "\n", "if", "custom_classes", "is", "not", "None", ":", "\n", "        ", "custom_classes", "=", "custom_classes", "[", "1", ":", "]", "\n", "assert", "set", "(", "custom_classes", ")", ".", "issubset", "(", "set", "(", "class_whitelist", ")", ")", "\n", "class_whitelist", "=", "custom_classes", "\n", "categories", "=", "[", "cat", "for", "cat", "in", "categories", "if", "cat", "[", "'id'", "]", "in", "custom_classes", "]", "\n", "\n", "# loading gt, do not need gt score", "\n", "", "gt_boxes", ",", "gt_labels", ",", "_", "=", "read_csv", "(", "open", "(", "ann_file", ")", ",", "class_whitelist", ")", "\n", "if", "verbose", ":", "\n", "        ", "print_time", "(", "'Reading detection results'", ",", "start", ")", "\n", "\n", "", "if", "exclude_file", "is", "not", "None", ":", "\n", "        ", "excluded_keys", "=", "read_exclusions", "(", "open", "(", "exclude_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "excluded_keys", "=", "list", "(", ")", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "boxes", ",", "labels", ",", "scores", "=", "read_csv", "(", "open", "(", "result_file", ")", ",", "class_whitelist", ")", "\n", "if", "verbose", ":", "\n", "        ", "print_time", "(", "'Reading detection results'", ",", "start", ")", "\n", "\n", "# Evaluation for mAP", "\n", "", "pascal_evaluator", "=", "det_eval", ".", "PascalDetectionEvaluator", "(", "categories", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "image_key", "in", "gt_boxes", ":", "\n", "        ", "if", "verbose", "and", "image_key", "in", "excluded_keys", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "'Found excluded timestamp in detections: %s.'", "\n", "'It will be ignored.'", ",", "image_key", ")", "\n", "continue", "\n", "", "pascal_evaluator", ".", "add_single_ground_truth_image_info", "(", "\n", "image_key", ",", "{", "\n", "standard_fields", ".", "InputDataFields", ".", "groundtruth_boxes", ":", "\n", "np", ".", "array", "(", "gt_boxes", "[", "image_key", "]", ",", "dtype", "=", "float", ")", ",", "\n", "standard_fields", ".", "InputDataFields", ".", "groundtruth_classes", ":", "\n", "np", ".", "array", "(", "gt_labels", "[", "image_key", "]", ",", "dtype", "=", "int", ")", "\n", "}", ")", "\n", "", "if", "verbose", ":", "\n", "        ", "print_time", "(", "'Convert groundtruth'", ",", "start", ")", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "image_key", "in", "boxes", ":", "\n", "        ", "if", "verbose", "and", "image_key", "in", "excluded_keys", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "'Found excluded timestamp in detections: %s.'", "\n", "'It will be ignored.'", ",", "image_key", ")", "\n", "continue", "\n", "", "pascal_evaluator", ".", "add_single_detected_image_info", "(", "\n", "image_key", ",", "{", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_boxes", ":", "\n", "np", ".", "array", "(", "boxes", "[", "image_key", "]", ",", "dtype", "=", "float", ")", ",", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_classes", ":", "\n", "np", ".", "array", "(", "labels", "[", "image_key", "]", ",", "dtype", "=", "int", ")", ",", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_scores", ":", "\n", "np", ".", "array", "(", "scores", "[", "image_key", "]", ",", "dtype", "=", "float", ")", "\n", "}", ")", "\n", "", "if", "verbose", ":", "\n", "        ", "print_time", "(", "'convert detections'", ",", "start", ")", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "metrics", "=", "pascal_evaluator", ".", "evaluate", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print_time", "(", "'run_evaluator'", ",", "start", ")", "\n", "", "for", "display_name", "in", "metrics", ":", "\n", "        ", "print", "(", "f'{display_name}=\\t{metrics[display_name]}'", ")", "\n", "", "return", "{", "\n", "display_name", ":", "metrics", "[", "display_name", "]", "\n", "for", "display_name", "in", "metrics", "if", "'ByCategory'", "not", "in", "display_name", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation.__init__": [[31, 42], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_groundtruth_classes", ",", "matching_iou_threshold", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"Initialized PerImageEvaluation by evaluation parameters.\n\n        Args:\n            num_groundtruth_classes: Number of ground truth object classes\n            matching_iou_threshold: A ratio of area intersection to union,\n                which is the threshold to consider whether a detection is true\n                positive or not\n        \"\"\"", "\n", "self", ".", "matching_iou_threshold", "=", "matching_iou_threshold", "\n", "self", ".", "num_groundtruth_classes", "=", "num_groundtruth_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation.compute_object_detection_metrics": [[43, 105], ["per_image_evaluation.PerImageEvaluation._remove_invalid_boxes", "per_image_evaluation.PerImageEvaluation._compute_tp_fp"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._remove_invalid_boxes", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._compute_tp_fp"], ["", "def", "compute_object_detection_metrics", "(", "self", ",", "\n", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "detected_class_labels", ",", "\n", "groundtruth_boxes", ",", "\n", "groundtruth_class_labels", ",", "\n", "detected_masks", "=", "None", ",", "\n", "groundtruth_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Evaluates detections as being tp, fp or ignored from a single image.\n\n        The evaluation is done in two stages:\n        1. All detections are matched to non group-of boxes.\n\n        Args:\n            detected_boxes: A float numpy array of shape [N, 4], representing N\n                regions of detected object regions.\n                Each row is of the format [y_min, x_min, y_max, x_max]\n            detected_scores: A float numpy array of shape [N, 1], representing\n                the confidence scores of the detected N object instances.\n            detected_class_labels: A integer numpy array of shape [N, 1],\n                repreneting the class labels of the detected N object\n                instances.\n            groundtruth_boxes: A float numpy array of shape [M, 4],\n                representing M regions of object instances in ground truth\n            groundtruth_class_labels: An integer numpy array of shape [M, 1],\n                representing M class labels of object instances in ground truth\n            detected_masks: (optional) A uint8 numpy array of shape\n                [N, height, width]. If not None, the metrics will be computed\n                based on masks.\n            groundtruth_masks: (optional) A uint8 numpy array of shape\n                [M, height, width].\n\n        Returns:\n            scores: A list of C float numpy arrays. Each numpy array is of\n                shape [K, 1], representing K scores detected with object class\n                label c\n            tp_fp_labels: A list of C boolean numpy arrays. Each numpy array\n                is of shape [K, 1], representing K True/False positive label of\n                object instances detected with class label c\n        \"\"\"", "\n", "(", "\n", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "detected_class_labels", ",", "\n", "detected_masks", ",", "\n", ")", "=", "self", ".", "_remove_invalid_boxes", "(", "\n", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "detected_class_labels", ",", "\n", "detected_masks", ",", "\n", ")", "\n", "scores", ",", "tp_fp_labels", "=", "self", ".", "_compute_tp_fp", "(", "\n", "detected_boxes", "=", "detected_boxes", ",", "\n", "detected_scores", "=", "detected_scores", ",", "\n", "detected_class_labels", "=", "detected_class_labels", ",", "\n", "groundtruth_boxes", "=", "groundtruth_boxes", ",", "\n", "groundtruth_class_labels", "=", "groundtruth_class_labels", ",", "\n", "detected_masks", "=", "detected_masks", ",", "\n", "groundtruth_masks", "=", "groundtruth_masks", ",", "\n", ")", "\n", "\n", "return", "scores", ",", "tp_fp_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._compute_tp_fp": [[106, 174], ["range", "ValueError", "ValueError", "per_image_evaluation.PerImageEvaluation._get_ith_class_arrays", "per_image_evaluation.PerImageEvaluation._compute_tp_fp_for_single_class", "result_scores.append", "result_tp_fp_labels.append"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._get_ith_class_arrays", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._compute_tp_fp_for_single_class"], ["", "def", "_compute_tp_fp", "(", "self", ",", "\n", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "detected_class_labels", ",", "\n", "groundtruth_boxes", ",", "\n", "groundtruth_class_labels", ",", "\n", "detected_masks", "=", "None", ",", "\n", "groundtruth_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Labels true/false positives of detections of an image across all\n        classes.\n\n        Args:\n            detected_boxes: A float numpy array of shape [N, 4], representing N\n                regions of detected object regions.\n                Each row is of the format [y_min, x_min, y_max, x_max]\n            detected_scores: A float numpy array of shape [N, 1], representing\n                the confidence scores of the detected N object instances.\n            detected_class_labels: A integer numpy array of shape [N, 1],\n                repreneting the class labels of the detected N object\n                instances.\n            groundtruth_boxes: A float numpy array of shape [M, 4],\n                representing M regions of object instances in ground truth\n            groundtruth_class_labels: An integer numpy array of shape [M, 1],\n                representing M class labels of object instances in ground truth\n            detected_masks: (optional) A np.uint8 numpy array of shape\n                [N, height, width]. If not None, the scores will be computed\n                based on masks.\n            groundtruth_masks: (optional) A np.uint8 numpy array of shape\n                [M, height, width].\n\n        Returns:\n            result_scores: A list of float numpy arrays. Each numpy array is of\n                shape [K, 1], representing K scores detected with object class\n                label c\n            result_tp_fp_labels: A list of boolean numpy array. Each numpy\n                array is of shape [K, 1], representing K True/False positive\n                label of object instances detected with class label c\n\n        Raises:\n            ValueError: If detected masks is not None but groundtruth masks are\n                None, or the other way around.\n        \"\"\"", "\n", "if", "detected_masks", "is", "not", "None", "and", "groundtruth_masks", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Detected masks is available but groundtruth masks is not.'", ")", "\n", "", "if", "detected_masks", "is", "None", "and", "groundtruth_masks", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Groundtruth masks is available but detected masks is not.'", ")", "\n", "\n", "", "result_scores", "=", "[", "]", "\n", "result_tp_fp_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_groundtruth_classes", ")", ":", "\n", "            ", "(", "gt_boxes_at_ith_class", ",", "gt_masks_at_ith_class", ",", "\n", "detected_boxes_at_ith_class", ",", "detected_scores_at_ith_class", ",", "\n", "detected_masks_at_ith_class", ")", "=", "self", ".", "_get_ith_class_arrays", "(", "\n", "detected_boxes", ",", "detected_scores", ",", "detected_masks", ",", "\n", "detected_class_labels", ",", "groundtruth_boxes", ",", "groundtruth_masks", ",", "\n", "groundtruth_class_labels", ",", "i", ")", "\n", "scores", ",", "tp_fp_labels", "=", "self", ".", "_compute_tp_fp_for_single_class", "(", "\n", "detected_boxes", "=", "detected_boxes_at_ith_class", ",", "\n", "detected_scores", "=", "detected_scores_at_ith_class", ",", "\n", "groundtruth_boxes", "=", "gt_boxes_at_ith_class", ",", "\n", "detected_masks", "=", "detected_masks_at_ith_class", ",", "\n", "groundtruth_masks", "=", "gt_masks_at_ith_class", ",", "\n", ")", "\n", "result_scores", ".", "append", "(", "scores", ")", "\n", "result_tp_fp_labels", ".", "append", "(", "tp_fp_labels", ")", "\n", "", "return", "result_scores", ",", "result_tp_fp_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._get_overlaps_and_scores_box_mode": [[175, 207], ["np_box_list.BoxList", "np_box_list.BoxList.add_field", "np_box_list.BoxList", "np_box_ops.iou", "np_box_list.BoxList.get_field", "np_box_list.BoxList.num_boxes", "np_box_list.BoxList.get", "np_box_list.BoxList.get"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.add_field", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get_field", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.num_boxes", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "@", "staticmethod", "\n", "def", "_get_overlaps_and_scores_box_mode", "(", "detected_boxes", ",", "detected_scores", ",", "\n", "groundtruth_boxes", ")", ":", "\n", "        ", "\"\"\"Computes overlaps and scores between detected and groudntruth boxes.\n\n        Args:\n            detected_boxes: A numpy array of shape [N, 4] representing detected\n                box coordinates\n            detected_scores: A 1-d numpy array of length N representing\n                classification score\n            groundtruth_boxes: A numpy array of shape [M, 4] representing\n                ground truth box coordinates\n\n        Returns:\n            iou: A float numpy array of size [num_detected_boxes,\n                num_gt_boxes]. If gt_non_group_of_boxlist.num_boxes() == 0 it\n                will be None.\n            ioa: A float numpy array of size [num_detected_boxes,\n                num_gt_boxes]. If gt_group_of_boxlist.num_boxes() == 0 it will\n                be None.\n            scores: The score of the detected boxlist.\n            num_boxes: Number of non-maximum suppressed detected boxes.\n        \"\"\"", "\n", "detected_boxlist", "=", "np_box_list", ".", "BoxList", "(", "detected_boxes", ")", "\n", "detected_boxlist", ".", "add_field", "(", "'scores'", ",", "detected_scores", ")", "\n", "gt_non_group_of_boxlist", "=", "np_box_list", ".", "BoxList", "(", "groundtruth_boxes", ")", "\n", "\n", "iou", "=", "np_box_ops", ".", "iou", "(", "detected_boxlist", ".", "get", "(", ")", ",", "\n", "gt_non_group_of_boxlist", ".", "get", "(", ")", ")", "\n", "scores", "=", "detected_boxlist", ".", "get_field", "(", "'scores'", ")", "\n", "num_boxes", "=", "detected_boxlist", ".", "num_boxes", "(", ")", "\n", "return", "iou", ",", "None", ",", "scores", ",", "num_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._compute_tp_fp_for_single_class": [[208, 269], ["per_image_evaluation.PerImageEvaluation._get_overlaps_and_scores_box_mode", "numpy.zeros", "numpy.argmax", "numpy.zeros", "range", "numpy.array", "numpy.array", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._get_overlaps_and_scores_box_mode"], ["", "def", "_compute_tp_fp_for_single_class", "(", "self", ",", "\n", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "groundtruth_boxes", ",", "\n", "detected_masks", "=", "None", ",", "\n", "groundtruth_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Labels boxes detected with the same class from the same image as\n        tp/fp.\n\n        Args:\n            detected_boxes: A numpy array of shape [N, 4] representing detected\n                box coordinates\n            detected_scores: A 1-d numpy array of length N representing\n                classification score\n            groundtruth_boxes: A numpy array of shape [M, 4] representing\n                groundtruth box coordinates\n            detected_masks: (optional) A uint8 numpy array of shape\n                [N, height, width]. If not None, the scores will be computed\n                based on masks.\n            groundtruth_masks: (optional) A uint8 numpy array of shape\n                [M, height, width].\n\n        Returns:\n            Two arrays of the same size, containing all boxes that were\n            evaluated as being true positives or false positives.\n\n            scores: A numpy array representing the detection scores.\n            tp_fp_labels: a boolean numpy array indicating whether a detection\n                is a true positive.\n        \"\"\"", "\n", "if", "detected_boxes", ".", "size", "==", "0", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "float", ")", ",", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "bool", ")", "\n", "\n", "", "(", "iou", ",", "_", ",", "scores", ",", "\n", "num_detected_boxes", ")", "=", "self", ".", "_get_overlaps_and_scores_box_mode", "(", "\n", "detected_boxes", "=", "detected_boxes", ",", "\n", "detected_scores", "=", "detected_scores", ",", "\n", "groundtruth_boxes", "=", "groundtruth_boxes", ")", "\n", "\n", "if", "groundtruth_boxes", ".", "size", "==", "0", ":", "\n", "            ", "return", "scores", ",", "np", ".", "zeros", "(", "num_detected_boxes", ",", "dtype", "=", "bool", ")", "\n", "\n", "", "tp_fp_labels", "=", "np", ".", "zeros", "(", "num_detected_boxes", ",", "dtype", "=", "bool", ")", "\n", "\n", "# The evaluation is done in two stages:", "\n", "# 1. All detections are matched to non group-of boxes.", "\n", "# 2. Detections that are determined as false positives are matched", "\n", "#    against group-of boxes and ignored if matched.", "\n", "\n", "# Tp-fp evaluation for non-group of boxes (if any).", "\n", "if", "iou", ".", "shape", "[", "1", "]", ">", "0", ":", "\n", "            ", "max_overlap_gt_ids", "=", "np", ".", "argmax", "(", "iou", ",", "axis", "=", "1", ")", "\n", "is_gt_box_detected", "=", "np", ".", "zeros", "(", "iou", ".", "shape", "[", "1", "]", ",", "dtype", "=", "bool", ")", "\n", "for", "i", "in", "range", "(", "num_detected_boxes", ")", ":", "\n", "                ", "gt_id", "=", "max_overlap_gt_ids", "[", "i", "]", "\n", "if", "iou", "[", "i", ",", "gt_id", "]", ">=", "self", ".", "matching_iou_threshold", ":", "\n", "                    ", "if", "not", "is_gt_box_detected", "[", "gt_id", "]", ":", "\n", "                        ", "tp_fp_labels", "[", "i", "]", "=", "True", "\n", "is_gt_box_detected", "[", "gt_id", "]", "=", "True", "\n", "\n", "", "", "", "", "return", "scores", ",", "tp_fp_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._get_ith_class_arrays": [[270, 317], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_ith_class_arrays", "(", "detected_boxes", ",", "detected_scores", ",", "detected_masks", ",", "\n", "detected_class_labels", ",", "groundtruth_boxes", ",", "\n", "groundtruth_masks", ",", "groundtruth_class_labels", ",", "\n", "class_index", ")", ":", "\n", "        ", "\"\"\"Returns numpy arrays belonging to class with index `class_index`.\n\n        Args:\n            detected_boxes: A numpy array containing detected boxes.\n            detected_scores: A numpy array containing detected scores.\n            detected_masks: A numpy array containing detected masks.\n            detected_class_labels: A numpy array containing detected class\n                labels.\n            groundtruth_boxes: A numpy array containing groundtruth boxes.\n            groundtruth_masks: A numpy array containing groundtruth masks.\n            groundtruth_class_labels: A numpy array containing groundtruth\n                class labels.\n            class_index: An integer index.\n\n        Returns:\n            gt_boxes_at_ith_class: A numpy array containing groundtruth boxes\n                labeled as ith class.\n            gt_masks_at_ith_class: A numpy array containing groundtruth masks\n                labeled as ith class.\n            detected_boxes_at_ith_class: A numpy array containing detected\n                boxes corresponding to the ith class.\n            detected_scores_at_ith_class: A numpy array containing detected\n                scores corresponding to the ith class.\n            detected_masks_at_ith_class: A numpy array containing detected\n                masks corresponding to the ith class.\n        \"\"\"", "\n", "selected_groundtruth", "=", "groundtruth_class_labels", "==", "class_index", "\n", "gt_boxes_at_ith_class", "=", "groundtruth_boxes", "[", "selected_groundtruth", "]", "\n", "if", "groundtruth_masks", "is", "not", "None", ":", "\n", "            ", "gt_masks_at_ith_class", "=", "groundtruth_masks", "[", "selected_groundtruth", "]", "\n", "", "else", ":", "\n", "            ", "gt_masks_at_ith_class", "=", "None", "\n", "", "selected_detections", "=", "detected_class_labels", "==", "class_index", "\n", "detected_boxes_at_ith_class", "=", "detected_boxes", "[", "selected_detections", "]", "\n", "detected_scores_at_ith_class", "=", "detected_scores", "[", "selected_detections", "]", "\n", "if", "detected_masks", "is", "not", "None", ":", "\n", "            ", "detected_masks_at_ith_class", "=", "detected_masks", "[", "selected_detections", "]", "\n", "", "else", ":", "\n", "            ", "detected_masks_at_ith_class", "=", "None", "\n", "", "return", "(", "gt_boxes_at_ith_class", ",", "gt_masks_at_ith_class", ",", "\n", "detected_boxes_at_ith_class", ",", "detected_scores_at_ith_class", ",", "\n", "detected_masks_at_ith_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation._remove_invalid_boxes": [[318, 358], ["numpy.logical_and"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_remove_invalid_boxes", "(", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "detected_class_labels", ",", "\n", "detected_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Removes entries with invalid boxes.\n\n        A box is invalid if either its xmax is smaller than its xmin, or its\n        ymax is smaller than its ymin.\n\n        Args:\n            detected_boxes: A float numpy array of size [num_boxes, 4]\n                containing box coordinates in [ymin, xmin, ymax, xmax] format.\n            detected_scores: A float numpy array of size [num_boxes].\n            detected_class_labels: A int32 numpy array of size [num_boxes].\n            detected_masks: A uint8 numpy array of size\n                [num_boxes, height, width].\n\n        Returns:\n            valid_detected_boxes: A float numpy array of size\n                [num_valid_boxes, 4] containing box coordinates in\n                [ymin, xmin, ymax, xmax] format.\n            valid_detected_scores: A float numpy array of size\n                [num_valid_boxes].\n            valid_detected_class_labels: A int32 numpy array of size\n                [num_valid_boxes].\n            valid_detected_masks: A uint8 numpy array of size\n                [num_valid_boxes, height, width].\n        \"\"\"", "\n", "valid_indices", "=", "np", ".", "logical_and", "(", "\n", "detected_boxes", "[", ":", ",", "0", "]", "<", "detected_boxes", "[", ":", ",", "2", "]", ",", "\n", "detected_boxes", "[", ":", ",", "1", "]", "<", "detected_boxes", "[", ":", ",", "3", "]", ")", "\n", "detected_boxes", "=", "detected_boxes", "[", "valid_indices", "]", "\n", "detected_scores", "=", "detected_scores", "[", "valid_indices", "]", "\n", "detected_class_labels", "=", "detected_class_labels", "[", "valid_indices", "]", "\n", "if", "detected_masks", "is", "not", "None", ":", "\n", "            ", "detected_masks", "=", "detected_masks", "[", "valid_indices", "]", "\n", "", "return", "[", "\n", "detected_boxes", ",", "detected_scores", ",", "detected_class_labels", ",", "\n", "detected_masks", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.__init__": [[32, 53], ["isinstance", "ValueError", "ValueError", "ValueError", "np_box_list.BoxList._is_valid_boxes", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList._is_valid_boxes"], ["def", "__init__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"Constructs box collection.\n\n        Args:\n            data: a numpy array of shape [N, 4] representing box coordinates\n\n        Raises:\n            ValueError: if bbox data is not a numpy array\n            ValueError: if invalid dimensions for bbox data\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'data must be a numpy array.'", ")", "\n", "", "if", "len", "(", "data", ".", "shape", ")", "!=", "2", "or", "data", ".", "shape", "[", "1", "]", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid dimensions for box data.'", ")", "\n", "", "if", "data", ".", "dtype", "!=", "np", ".", "float32", "and", "data", ".", "dtype", "!=", "np", ".", "float64", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Invalid data type for box data: float is required.'", ")", "\n", "", "if", "not", "self", ".", "_is_valid_boxes", "(", "data", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid box data. data must be a numpy array of '", "\n", "'N*[y_min, x_min, y_max, x_max]'", ")", "\n", "", "self", ".", "data", "=", "{", "'boxes'", ":", "data", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.num_boxes": [[54, 57], ["None"], "methods", ["None"], ["", "def", "num_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return number of boxes held in collections.\"\"\"", "\n", "return", "self", ".", "data", "[", "'boxes'", "]", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get_extra_fields": [[58, 61], ["None"], "methods", ["None"], ["", "def", "get_extra_fields", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return all non-box fields.\"\"\"", "\n", "return", "[", "k", "for", "k", "in", "self", ".", "data", "if", "k", "!=", "'boxes'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.has_field": [[62, 64], ["None"], "methods", ["None"], ["", "def", "has_field", "(", "self", ",", "field", ")", ":", "\n", "        ", "return", "field", "in", "self", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.add_field": [[65, 83], ["np_box_list.BoxList.has_field", "ValueError", "ValueError", "len", "np_box_list.BoxList.num_boxes"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.has_field", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.num_boxes"], ["", "def", "add_field", "(", "self", ",", "field", ",", "field_data", ")", ":", "\n", "        ", "\"\"\"Add data to a specified field.\n\n        Args:\n            field: a string parameter used to speficy a related field to be\n                accessed.\n            field_data: a numpy array of [N, ...] representing the data\n                associated with the field.\n        Raises:\n            ValueError: if the field is already exist or the dimension of the\n                field data does not matches the number of boxes.\n        \"\"\"", "\n", "if", "self", ".", "has_field", "(", "field", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Field '", "+", "field", "+", "'already exists'", ")", "\n", "", "if", "len", "(", "field_data", ".", "shape", ")", "<", "1", "or", "field_data", ".", "shape", "[", "0", "]", "!=", "self", ".", "num_boxes", "(", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid dimensions for field data'", ")", "\n", "", "self", ".", "data", "[", "field", "]", "=", "field_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get": [[84, 91], ["np_box_list.BoxList.get_field"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get_field"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\"Convenience function for accesssing box coordinates.\n\n        Returns:\n            a numpy array of shape [N, 4] representing box corners\n        \"\"\"", "\n", "return", "self", ".", "get_field", "(", "'boxes'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get_field": [[92, 109], ["np_box_list.BoxList.has_field", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.has_field"], ["", "def", "get_field", "(", "self", ",", "field", ")", ":", "\n", "        ", "\"\"\"Accesses data associated with the specified field in the box\n        collection.\n\n        Args:\n            field: a string parameter used to speficy a related field to be\n                accessed.\n\n        Returns:\n            a numpy 1-d array representing data of an associated field\n\n        Raises:\n            ValueError: if invalid field\n        \"\"\"", "\n", "if", "not", "self", ".", "has_field", "(", "field", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'field {field} does not exist'", ")", "\n", "", "return", "self", ".", "data", "[", "field", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get_coordinates": [[110, 122], ["np_box_list.BoxList.get"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get"], ["", "def", "get_coordinates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get corner coordinates of boxes.\n\n        Returns:\n            a list of 4 1-d numpy arrays [y_min, x_min, y_max, x_max]\n        \"\"\"", "\n", "box_coordinates", "=", "self", ".", "get", "(", ")", "\n", "y_min", "=", "box_coordinates", "[", ":", ",", "0", "]", "\n", "x_min", "=", "box_coordinates", "[", ":", ",", "1", "]", "\n", "y_max", "=", "box_coordinates", "[", ":", ",", "2", "]", "\n", "x_max", "=", "box_coordinates", "[", ":", ",", "3", "]", "\n", "return", "[", "y_min", ",", "x_min", ",", "y_max", ",", "x_max", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList._is_valid_boxes": [[123, 140], ["len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_valid_boxes", "(", "data", ")", ":", "\n", "        ", "\"\"\"Check whether data fulfills the format of N*[ymin, xmin, ymax,\n        xmin].\n\n        Args:\n            data: a numpy array of shape [N, 4] representing box coordinates\n\n        Returns:\n            a boolean indicating whether all ymax of boxes are equal or greater\n            than ymin, and all xmax of boxes are equal or greater than xmin.\n        \"\"\"", "\n", "if", "len", "(", "data", ")", "!=", "0", ":", "\n", "            ", "for", "v", "in", "data", ":", "\n", "                ", "if", "v", "[", "0", "]", ">", "v", "[", "2", "]", "or", "v", "[", "1", "]", ">", "v", "[", "3", "]", ":", "\n", "                    ", "return", "False", "\n", "", "", "", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_precision_recall": [[20, 66], ["numpy.argsort", "labels.astype.astype", "numpy.cumsum", "numpy.cumsum", "ValueError", "ValueError", "numpy.sum", "ValueError", "len", "len", "ValueError", "np.cumsum.astype", "np.cumsum.astype", "isinstance", "len", "isinstance", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_average_precision": [[68, 117], ["numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "ValueError", "ValueError", "len", "len", "ValueError", "ValueError", "ValueError", "all", "ValueError", "numpy.maximum", "ValueError", "isinstance", "isinstance", "numpy.amin", "numpy.amax", "numpy.amin", "numpy.amax", "len", "numpy.where", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_cor_loc": [[119, 143], ["numpy.errstate", "numpy.where"], "function", ["None"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.area": [[25, 35], ["None"], "function", ["None"], ["def", "area", "(", "boxes", ")", ":", "\n", "    ", "\"\"\"Computes area of boxes.\n\n    Args:\n        boxes: Numpy array with shape [N, 4] holding N boxes\n\n    Returns:\n        a numpy array with shape [N*1] representing box areas\n    \"\"\"", "\n", "return", "(", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", ")", "*", "(", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.intersection": [[37, 61], ["numpy.split", "numpy.split", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.transpose", "numpy.transpose", "numpy.zeros", "numpy.transpose", "numpy.transpose", "numpy.zeros"], "function", ["None"], ["", "def", "intersection", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "    ", "\"\"\"Compute pairwise intersection areas between boxes.\n\n    Args:\n        boxes1: a numpy array with shape [N, 4] holding N boxes\n        boxes2: a numpy array with shape [M, 4] holding M boxes\n\n    Returns:\n        a numpy array with shape [N*M] representing pairwise intersection area\n    \"\"\"", "\n", "[", "y_min1", ",", "x_min1", ",", "y_max1", ",", "x_max1", "]", "=", "np", ".", "split", "(", "boxes1", ",", "4", ",", "axis", "=", "1", ")", "\n", "[", "y_min2", ",", "x_min2", ",", "y_max2", ",", "x_max2", "]", "=", "np", ".", "split", "(", "boxes2", ",", "4", ",", "axis", "=", "1", ")", "\n", "\n", "all_pairs_min_ymax", "=", "np", ".", "minimum", "(", "y_max1", ",", "np", ".", "transpose", "(", "y_max2", ")", ")", "\n", "all_pairs_max_ymin", "=", "np", ".", "maximum", "(", "y_min1", ",", "np", ".", "transpose", "(", "y_min2", ")", ")", "\n", "intersect_heights", "=", "np", ".", "maximum", "(", "\n", "np", ".", "zeros", "(", "all_pairs_max_ymin", ".", "shape", ")", ",", "\n", "all_pairs_min_ymax", "-", "all_pairs_max_ymin", ")", "\n", "all_pairs_min_xmax", "=", "np", ".", "minimum", "(", "x_max1", ",", "np", ".", "transpose", "(", "x_max2", ")", ")", "\n", "all_pairs_max_xmin", "=", "np", ".", "maximum", "(", "x_min1", ",", "np", ".", "transpose", "(", "x_min2", ")", ")", "\n", "intersect_widths", "=", "np", ".", "maximum", "(", "\n", "np", ".", "zeros", "(", "all_pairs_max_xmin", ".", "shape", ")", ",", "\n", "all_pairs_min_xmax", "-", "all_pairs_max_xmin", ")", "\n", "return", "intersect_heights", "*", "intersect_widths", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.iou": [[63, 80], ["np_box_ops.intersection", "np_box_ops.area", "np_box_ops.area", "numpy.expand_dims", "numpy.expand_dims"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.intersection", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.area", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.area"], ["", "def", "iou", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "    ", "\"\"\"Computes pairwise intersection-over-union between box collections.\n\n    Args:\n        boxes1: a numpy array with shape [N, 4] holding N boxes.\n        boxes2: a numpy array with shape [M, 4] holding N boxes.\n\n    Returns:\n        a numpy array with shape [N, M] representing pairwise iou scores.\n    \"\"\"", "\n", "intersect", "=", "intersection", "(", "boxes1", ",", "boxes2", ")", "\n", "area1", "=", "area", "(", "boxes1", ")", "\n", "area2", "=", "area", "(", "boxes2", ")", "\n", "union", "=", "(", "\n", "np", ".", "expand_dims", "(", "area1", ",", "axis", "=", "1", ")", "+", "np", ".", "expand_dims", "(", "area2", ",", "axis", "=", "0", ")", "-", "\n", "intersect", ")", "\n", "return", "intersect", "/", "union", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.ioa": [[82, 99], ["np_box_ops.intersection", "numpy.expand_dims", "np_box_ops.area"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.intersection", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_ops.area"], ["", "def", "ioa", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "    ", "\"\"\"Computes pairwise intersection-over-area between box collections.\n\n    Intersection-over-area (ioa) between two boxes box1 and box2 is defined as\n    their intersection area over box2's area. Note that ioa is not symmetric,\n    that is, IOA(box1, box2) != IOA(box2, box1).\n\n    Args:\n        boxes1: a numpy array with shape [N, 4] holding N boxes.\n        boxes2: a numpy array with shape [M, 4] holding N boxes.\n\n    Returns:\n        a numpy array with shape [N, M] representing pairwise ioa scores.\n    \"\"\"", "\n", "intersect", "=", "intersection", "(", "boxes1", ",", "boxes2", ")", "\n", "areas", "=", "np", ".", "expand_dims", "(", "area", "(", "boxes2", ")", ",", "axis", "=", "0", ")", "\n", "return", "intersect", "/", "areas", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.DetectionEvaluator.__init__": [[61, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "categories", ")", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            categories: A list of dicts, each of which has the following keys -\n                'id': (required) an integer id uniquely identifying this\n                    category.\n                'name': (required) string representing category name e.g.,\n                    'cat', 'dog'.\n        \"\"\"", "\n", "self", ".", "_categories", "=", "categories", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.DetectionEvaluator.add_single_ground_truth_image_info": [[73, 82], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "add_single_ground_truth_image_info", "(", "self", ",", "image_id", ",", "groundtruth_dict", ")", ":", "\n", "        ", "\"\"\"Adds groundtruth for a single image to be used for evaluation.\n\n        Args:\n            image_id: A unique string/integer identifier for the image.\n            groundtruth_dict: A dictionary of groundtruth numpy arrays required\n                for evaluations.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.DetectionEvaluator.add_single_detected_image_info": [[83, 92], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "add_single_detected_image_info", "(", "self", ",", "image_id", ",", "detections_dict", ")", ":", "\n", "        ", "\"\"\"Adds detections for a single image to be used for evaluation.\n\n        Args:\n            image_id: A unique string/integer identifier for the image.\n            detections_dict: A dictionary of detection numpy arrays required\n                for evaluation.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.DetectionEvaluator.evaluate": [[93, 96], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Evaluates detections and returns a dictionary of metrics.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.DetectionEvaluator.clear": [[97, 100], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "clear", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the state to prepare for a fresh evaluation.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.__init__": [[105, 152], ["object_detection_evaluation.DetectionEvaluator.__init__", "max", "object_detection_evaluation.ObjectDetectionEvaluation", "set", "min", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "categories", ",", "\n", "matching_iou_threshold", "=", "0.5", ",", "\n", "evaluate_corlocs", "=", "False", ",", "\n", "metric_prefix", "=", "None", ",", "\n", "use_weighted_mean_ap", "=", "False", ",", "\n", "evaluate_masks", "=", "False", ")", ":", "\n", "        ", "\"\"\"Constructor.\n\n        Args:\n            categories: A list of dicts, each of which has the following keys -\n                'id': (required) an integer id uniquely identifying this\n                    category.\n                'name': (required) string representing category name e.g.,\n                    'cat', 'dog'.\n            matching_iou_threshold: IOU threshold to use for matching\n                groundtruth boxes to detection boxes.\n            evaluate_corlocs: (optional) boolean which determines if corloc\n                scores are to be returned or not.\n            metric_prefix: (optional) string prefix for metric name; if None,\n                no prefix is used.\n            use_weighted_mean_ap: (optional) boolean which determines if the\n                mean average precision is computed directly from the scores and\n                tp_fp_labels of all classes.\n            evaluate_masks: If False, evaluation will be performed based on\n                boxes. If True, mask evaluation will be performed instead.\n\n        Raises:\n            ValueError: If the category ids are not 1-indexed.\n        \"\"\"", "\n", "super", "(", "ObjectDetectionEvaluator", ",", "self", ")", ".", "__init__", "(", "categories", ")", "\n", "self", ".", "_num_classes", "=", "max", "(", "[", "cat", "[", "'id'", "]", "for", "cat", "in", "categories", "]", ")", "\n", "if", "min", "(", "cat", "[", "'id'", "]", "for", "cat", "in", "categories", ")", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Classes should be 1-indexed.'", ")", "\n", "", "self", ".", "_matching_iou_threshold", "=", "matching_iou_threshold", "\n", "self", ".", "_use_weighted_mean_ap", "=", "use_weighted_mean_ap", "\n", "self", ".", "_label_id_offset", "=", "1", "\n", "self", ".", "_evaluate_masks", "=", "evaluate_masks", "\n", "self", ".", "_evaluation", "=", "ObjectDetectionEvaluation", "(", "\n", "num_groundtruth_classes", "=", "self", ".", "_num_classes", ",", "\n", "matching_iou_threshold", "=", "self", ".", "_matching_iou_threshold", ",", "\n", "use_weighted_mean_ap", "=", "self", ".", "_use_weighted_mean_ap", ",", "\n", "label_id_offset", "=", "self", ".", "_label_id_offset", ",", "\n", ")", "\n", "self", ".", "_image_ids", "=", "set", "(", "[", "]", ")", "\n", "self", ".", "_evaluate_corlocs", "=", "evaluate_corlocs", "\n", "self", ".", "_metric_prefix", "=", "(", "metric_prefix", "+", "'_'", ")", "if", "metric_prefix", "else", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.add_single_ground_truth_image_info": [[153, 200], ["object_detection_evaluation.ObjectDetectionEvaluator._evaluation.add_single_ground_truth_image_info", "object_detection_evaluation.ObjectDetectionEvaluator._image_ids.update", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.add_single_ground_truth_image_info"], ["", "def", "add_single_ground_truth_image_info", "(", "self", ",", "image_id", ",", "groundtruth_dict", ")", ":", "\n", "        ", "\"\"\"Adds groundtruth for a single image to be used for evaluation.\n\n        Args:\n            image_id: A unique string/integer identifier for the image.\n            groundtruth_dict: A dictionary containing -\n                standard_fields.InputDataFields.groundtruth_boxes: float32\n                    numpy array of shape [num_boxes, 4] containing `num_boxes`\n                    groundtruth boxes of the format [ymin, xmin, ymax, xmax] in\n                    absolute image coordinates.\n                standard_fields.InputDataFields.groundtruth_classes: integer\n                    numpy array of shape [num_boxes] containing 1-indexed\n                    groundtruth classes for the boxes.\n                standard_fields.InputDataFields.groundtruth_instance_masks:\n                    Optional numpy array of shape [num_boxes, height, width]\n                    with values in {0, 1}.\n\n        Raises:\n            ValueError: On adding groundtruth for an image more than once. Will\n                also raise error if instance masks are not in groundtruth\n                dictionary.\n        \"\"\"", "\n", "if", "image_id", "in", "self", ".", "_image_ids", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Image with id {} already added.'", ".", "format", "(", "image_id", ")", ")", "\n", "\n", "", "groundtruth_classes", "=", "(", "\n", "groundtruth_dict", "[", "\n", "standard_fields", ".", "InputDataFields", ".", "groundtruth_classes", "]", "-", "\n", "self", ".", "_label_id_offset", ")", "\n", "\n", "groundtruth_masks", "=", "None", "\n", "if", "self", ".", "_evaluate_masks", ":", "\n", "            ", "if", "(", "standard_fields", ".", "InputDataFields", ".", "groundtruth_instance_masks", "\n", "not", "in", "groundtruth_dict", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Instance masks not in groundtruth dictionary.'", ")", "\n", "", "groundtruth_masks", "=", "groundtruth_dict", "[", "\n", "standard_fields", ".", "InputDataFields", ".", "groundtruth_instance_masks", "]", "\n", "", "self", ".", "_evaluation", ".", "add_single_ground_truth_image_info", "(", "\n", "image_key", "=", "image_id", ",", "\n", "groundtruth_boxes", "=", "groundtruth_dict", "[", "\n", "standard_fields", ".", "InputDataFields", ".", "groundtruth_boxes", "]", ",", "\n", "groundtruth_class_labels", "=", "groundtruth_classes", ",", "\n", "groundtruth_masks", "=", "groundtruth_masks", ",", "\n", ")", "\n", "self", ".", "_image_ids", ".", "update", "(", "[", "image_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.add_single_detected_image_info": [[201, 244], ["object_detection_evaluation.ObjectDetectionEvaluator._evaluation.add_single_detected_image_info", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.add_single_detected_image_info"], ["", "def", "add_single_detected_image_info", "(", "self", ",", "image_id", ",", "detections_dict", ")", ":", "\n", "        ", "\"\"\"Adds detections for a single image to be used for evaluation.\n\n        Args:\n            image_id: A unique string/integer identifier for the image.\n            detections_dict: A dictionary containing -\n                standard_fields.DetectionResultFields.detection_boxes: float32\n                    numpy array of shape [num_boxes, 4] containing `num_boxes`\n                    detection boxes of the format [ymin, xmin, ymax, xmax] in\n                    absolute image coordinates.\n                standard_fields.DetectionResultFields.detection_scores: float32\n                    numpy array of shape [num_boxes] containing detection\n                    scores for the boxes.\n                standard_fields.DetectionResultFields.detection_classes:\n                    integer numpy array of shape [num_boxes] containing\n                    1-indexed detection classes for the boxes.\n                standard_fields.DetectionResultFields.detection_masks: uint8\n                    numpy array of shape [num_boxes, height, width] containing\n                    `num_boxes` masks of values ranging between 0 and 1.\n\n        Raises:\n            ValueError: If detection masks are not in detections dictionary.\n        \"\"\"", "\n", "detection_classes", "=", "(", "\n", "detections_dict", "[", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_classes", "]", "-", "\n", "self", ".", "_label_id_offset", ")", "\n", "detection_masks", "=", "None", "\n", "if", "self", ".", "_evaluate_masks", ":", "\n", "            ", "if", "(", "standard_fields", ".", "DetectionResultFields", ".", "detection_masks", "\n", "not", "in", "detections_dict", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'Detection masks not in detections dictionary.'", ")", "\n", "", "detection_masks", "=", "detections_dict", "[", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_masks", "]", "\n", "", "self", ".", "_evaluation", ".", "add_single_detected_image_info", "(", "\n", "image_key", "=", "image_id", ",", "\n", "detected_boxes", "=", "detections_dict", "[", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_boxes", "]", ",", "\n", "detected_scores", "=", "detections_dict", "[", "\n", "standard_fields", ".", "DetectionResultFields", ".", "detection_scores", "]", ",", "\n", "detected_class_labels", "=", "detection_classes", ",", "\n", "detected_masks", "=", "detection_masks", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.create_category_index": [[246, 266], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_category_index", "(", "categories", ")", ":", "\n", "        ", "\"\"\"Creates dictionary of COCO compatible categories keyed by category\n        id.\n\n        Args:\n            categories: a list of dicts, each of which has the following keys:\n                'id': (required) an integer id uniquely identifying this\n                    category.\n                'name': (required) string representing category name\n                    e.g., 'cat', 'dog', 'pizza'.\n\n        Returns:\n            category_index: a dict containing the same entries as categories,\n                but keyed by the 'id' field of each category.\n        \"\"\"", "\n", "category_index", "=", "{", "}", "\n", "for", "cat", "in", "categories", ":", "\n", "            ", "category_index", "[", "cat", "[", "'id'", "]", "]", "=", "cat", "\n", "", "return", "category_index", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.evaluate": [[267, 312], ["object_detection_evaluation.ObjectDetectionEvaluator._evaluation.evaluate", "object_detection_evaluation.ObjectDetectionEvaluator.create_category_index", "range"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.create_category_index"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Compute evaluation result.\n\n        Returns:\n            A dictionary of metrics with the following fields -\n\n            1. summary_metrics:\n                'Precision/mAP@<matching_iou_threshold>IOU': mean average\n                precision at the specified IOU threshold\n\n            2. per_category_ap: category specific results with keys of the form\n               'PerformanceByCategory/mAP@<matching_iou_threshold>IOU/category'\n        \"\"\"", "\n", "(", "per_class_ap", ",", "mean_ap", ",", "_", ",", "_", ",", "per_class_corloc", ",", "\n", "mean_corloc", ")", "=", "self", ".", "_evaluation", ".", "evaluate", "(", ")", "\n", "\n", "metric", "=", "f'mAP@{self._matching_iou_threshold}IOU'", "\n", "pascal_metrics", "=", "{", "self", ".", "_metric_prefix", "+", "metric", ":", "mean_ap", "}", "\n", "if", "self", ".", "_evaluate_corlocs", ":", "\n", "            ", "pascal_metrics", "[", "self", ".", "_metric_prefix", "+", "\n", "'Precision/meanCorLoc@{}IOU'", ".", "format", "(", "\n", "self", ".", "_matching_iou_threshold", ")", "]", "=", "mean_corloc", "\n", "", "category_index", "=", "self", ".", "create_category_index", "(", "self", ".", "_categories", ")", "\n", "for", "idx", "in", "range", "(", "per_class_ap", ".", "size", ")", ":", "\n", "            ", "if", "idx", "+", "self", ".", "_label_id_offset", "in", "category_index", ":", "\n", "                ", "display_name", "=", "(", "\n", "self", ".", "_metric_prefix", "+", "\n", "'PerformanceByCategory/AP@{}IOU/{}'", ".", "format", "(", "\n", "self", ".", "_matching_iou_threshold", ",", "\n", "category_index", "[", "idx", "+", "self", ".", "_label_id_offset", "]", "[", "'name'", "]", ",", "\n", ")", ")", "\n", "pascal_metrics", "[", "display_name", "]", "=", "per_class_ap", "[", "idx", "]", "\n", "\n", "# Optionally add CorLoc metrics.classes", "\n", "if", "self", ".", "_evaluate_corlocs", ":", "\n", "                    ", "display_name", "=", "(", "\n", "self", ".", "_metric_prefix", "+", "\n", "'PerformanceByCategory/CorLoc@{}IOU/{}'", ".", "format", "(", "\n", "self", ".", "_matching_iou_threshold", ",", "\n", "category_index", "[", "idx", "+", "\n", "self", ".", "_label_id_offset", "]", "[", "'name'", "]", ",", "\n", ")", ")", "\n", "pascal_metrics", "[", "display_name", "]", "=", "per_class_corloc", "[", "idx", "]", "\n", "\n", "", "", "", "return", "pascal_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.clear": [[313, 322], ["object_detection_evaluation.ObjectDetectionEvaluation", "object_detection_evaluation.ObjectDetectionEvaluator._image_ids.clear"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluator.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears the state to prepare for a fresh evaluation.\"\"\"", "\n", "self", ".", "_evaluation", "=", "ObjectDetectionEvaluation", "(", "\n", "num_groundtruth_classes", "=", "self", ".", "_num_classes", ",", "\n", "matching_iou_threshold", "=", "self", ".", "_matching_iou_threshold", ",", "\n", "use_weighted_mean_ap", "=", "self", ".", "_use_weighted_mean_ap", ",", "\n", "label_id_offset", "=", "self", ".", "_label_id_offset", ",", "\n", ")", "\n", "self", ".", "_image_ids", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.PascalDetectionEvaluator.__init__": [[327, 333], ["object_detection_evaluation.ObjectDetectionEvaluator.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["def", "__init__", "(", "self", ",", "categories", ",", "matching_iou_threshold", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "PascalDetectionEvaluator", ",", "self", ")", ".", "__init__", "(", "\n", "categories", ",", "\n", "matching_iou_threshold", "=", "matching_iou_threshold", ",", "\n", "evaluate_corlocs", "=", "False", ",", "\n", "use_weighted_mean_ap", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.__init__": [[352, 378], ["per_image_evaluation.PerImageEvaluation", "numpy.zeros", "numpy.zeros", "object_detection_evaluation.ObjectDetectionEvaluation._initialize_detections", "ValueError"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation._initialize_detections"], ["def", "__init__", "(", "self", ",", "\n", "num_groundtruth_classes", ",", "\n", "matching_iou_threshold", "=", "0.5", ",", "\n", "nms_iou_threshold", "=", "1.0", ",", "\n", "nms_max_output_boxes", "=", "10000", ",", "\n", "use_weighted_mean_ap", "=", "False", ",", "\n", "label_id_offset", "=", "0", ")", ":", "\n", "        ", "if", "num_groundtruth_classes", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'Need at least 1 groundtruth class for evaluation.'", ")", "\n", "\n", "", "self", ".", "per_image_eval", "=", "per_image_evaluation", ".", "PerImageEvaluation", "(", "\n", "num_groundtruth_classes", "=", "num_groundtruth_classes", ",", "\n", "matching_iou_threshold", "=", "matching_iou_threshold", ",", "\n", ")", "\n", "self", ".", "num_class", "=", "num_groundtruth_classes", "\n", "self", ".", "use_weighted_mean_ap", "=", "use_weighted_mean_ap", "\n", "self", ".", "label_id_offset", "=", "label_id_offset", "\n", "\n", "self", ".", "groundtruth_boxes", "=", "{", "}", "\n", "self", ".", "groundtruth_class_labels", "=", "{", "}", "\n", "self", ".", "groundtruth_masks", "=", "{", "}", "\n", "self", ".", "num_gt_instances_per_class", "=", "np", ".", "zeros", "(", "self", ".", "num_class", ",", "dtype", "=", "int", ")", "\n", "self", ".", "num_gt_imgs_per_class", "=", "np", ".", "zeros", "(", "self", ".", "num_class", ",", "dtype", "=", "int", ")", "\n", "\n", "self", ".", "_initialize_detections", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation._initialize_detections": [[379, 390], ["set", "numpy.zeros", "numpy.empty", "object_detection_evaluation.ObjectDetectionEvaluation.average_precision_per_class.fill", "numpy.ones", "range", "range"], "methods", ["None"], ["", "def", "_initialize_detections", "(", "self", ")", ":", "\n", "        ", "self", ".", "detection_keys", "=", "set", "(", ")", "\n", "self", ".", "scores_per_class", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_class", ")", "]", "\n", "self", ".", "tp_fp_labels_per_class", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_class", ")", "]", "\n", "self", ".", "num_images_correctly_detected_per_class", "=", "np", ".", "zeros", "(", "self", ".", "num_class", ")", "\n", "self", ".", "average_precision_per_class", "=", "np", ".", "empty", "(", "\n", "self", ".", "num_class", ",", "dtype", "=", "float", ")", "\n", "self", ".", "average_precision_per_class", ".", "fill", "(", "np", ".", "nan", ")", "\n", "self", ".", "precisions_per_class", "=", "[", "]", "\n", "self", ".", "recalls_per_class", "=", "[", "]", "\n", "self", ".", "corloc_per_class", "=", "np", ".", "ones", "(", "self", ".", "num_class", ",", "dtype", "=", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.clear_detections": [[391, 393], ["object_detection_evaluation.ObjectDetectionEvaluation._initialize_detections"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation._initialize_detections"], ["", "def", "clear_detections", "(", "self", ")", ":", "\n", "        ", "self", ".", "_initialize_detections", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.add_single_ground_truth_image_info": [[394, 422], ["object_detection_evaluation.ObjectDetectionEvaluation._update_ground_truth_statistics", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation._update_ground_truth_statistics"], ["", "def", "add_single_ground_truth_image_info", "(", "self", ",", "\n", "image_key", ",", "\n", "groundtruth_boxes", ",", "\n", "groundtruth_class_labels", ",", "\n", "groundtruth_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Adds groundtruth for a single image to be used for evaluation.\n\n        Args:\n            image_key: A unique string/integer identifier for the image.\n            groundtruth_boxes: float32 numpy array of shape [num_boxes, 4]\n                containing `num_boxes` groundtruth boxes of the format\n                [ymin, xmin, ymax, xmax] in absolute image coordinates.\n            groundtruth_class_labels: integer numpy array of shape [num_boxes]\n                containing 0-indexed groundtruth classes for the boxes.\n            groundtruth_masks: uint8 numpy array of shape\n                [num_boxes, height, width] containing `num_boxes` groundtruth\n                masks. The mask values range from 0 to 1.\n        \"\"\"", "\n", "if", "image_key", "in", "self", ".", "groundtruth_boxes", ":", "\n", "            ", "warnings", ".", "warn", "(", "(", "'image %s has already been added to the ground '", "\n", "'truth database.'", ")", ",", "image_key", ")", "\n", "return", "\n", "\n", "", "self", ".", "groundtruth_boxes", "[", "image_key", "]", "=", "groundtruth_boxes", "\n", "self", ".", "groundtruth_class_labels", "[", "image_key", "]", "=", "groundtruth_class_labels", "\n", "self", ".", "groundtruth_masks", "[", "image_key", "]", "=", "groundtruth_masks", "\n", "\n", "self", ".", "_update_ground_truth_statistics", "(", "groundtruth_class_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.add_single_detected_image_info": [[423, 494], ["object_detection_evaluation.ObjectDetectionEvaluation.detection_keys.add", "object_detection_evaluation.ObjectDetectionEvaluation.per_image_eval.compute_object_detection_metrics", "range", "ValueError", "warnings.warn", "object_detection_evaluation.ObjectDetectionEvaluation.groundtruth_masks.pop", "numpy.empty", "numpy.array", "len", "len", "len", "len", "len", "len", "numpy.empty", "object_detection_evaluation.ObjectDetectionEvaluation.scores_per_class[].append", "object_detection_evaluation.ObjectDetectionEvaluation.tp_fp_labels_per_class[].append", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.per_image_evaluation.PerImageEvaluation.compute_object_detection_metrics"], ["", "def", "add_single_detected_image_info", "(", "self", ",", "\n", "image_key", ",", "\n", "detected_boxes", ",", "\n", "detected_scores", ",", "\n", "detected_class_labels", ",", "\n", "detected_masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"Adds detections for a single image to be used for evaluation.\n\n        Args:\n            image_key: A unique string/integer identifier for the image.\n            detected_boxes: float32 numpy array of shape [num_boxes, 4]\n                containing `num_boxes` detection boxes of the format\n                [ymin, xmin, ymax, xmax] in absolute image coordinates.\n            detected_scores: float32 numpy array of shape [num_boxes]\n                containing detection scores for the boxes.\n            detected_class_labels: integer numpy array of shape [num_boxes]\n                containing 0-indexed detection classes for the boxes.\n            detected_masks: np.uint8 numpy array of shape\n                [num_boxes, height, width] containing `num_boxes` detection\n                masks with values ranging between 0 and 1.\n\n        Raises:\n            ValueError: if the number of boxes, scores and class labels differ\n                in length.\n        \"\"\"", "\n", "if", "len", "(", "detected_boxes", ")", "!=", "len", "(", "detected_scores", ")", "or", "len", "(", "\n", "detected_boxes", ")", "!=", "len", "(", "detected_class_labels", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'detected_boxes, detected_scores and '", "\n", "'detected_class_labels should all have same lengths. Got'", "\n", "'[%d, %d, %d]'", "%", "len", "(", "detected_boxes", ")", ",", "\n", "len", "(", "detected_scores", ")", ",", "\n", "len", "(", "detected_class_labels", ")", ",", "\n", ")", "\n", "\n", "", "if", "image_key", "in", "self", ".", "detection_keys", ":", "\n", "            ", "warnings", ".", "warn", "(", "(", "'image %s has already been added to the ground '", "\n", "'truth database.'", ")", ",", "image_key", ")", "\n", "return", "\n", "\n", "", "self", ".", "detection_keys", ".", "add", "(", "image_key", ")", "\n", "if", "image_key", "in", "self", ".", "groundtruth_boxes", ":", "\n", "            ", "groundtruth_boxes", "=", "self", ".", "groundtruth_boxes", "[", "image_key", "]", "\n", "groundtruth_class_labels", "=", "self", ".", "groundtruth_class_labels", "[", "image_key", "]", "\n", "# Masks are popped instead of look up. The reason is that we do not", "\n", "# want to keep all masks in memory which can cause memory overflow.", "\n", "groundtruth_masks", "=", "self", ".", "groundtruth_masks", ".", "pop", "(", "image_key", ")", "\n", "", "else", ":", "\n", "            ", "groundtruth_boxes", "=", "np", ".", "empty", "(", "shape", "=", "[", "0", ",", "4", "]", ",", "dtype", "=", "float", ")", "\n", "groundtruth_class_labels", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "int", ")", "\n", "if", "detected_masks", "is", "None", ":", "\n", "                ", "groundtruth_masks", "=", "None", "\n", "", "else", ":", "\n", "                ", "groundtruth_masks", "=", "np", ".", "empty", "(", "shape", "=", "[", "0", ",", "1", ",", "1", "]", ",", "dtype", "=", "float", ")", "\n", "", "", "(", "\n", "scores", ",", "\n", "tp_fp_labels", ",", "\n", ")", "=", "self", ".", "per_image_eval", ".", "compute_object_detection_metrics", "(", "\n", "detected_boxes", "=", "detected_boxes", ",", "\n", "detected_scores", "=", "detected_scores", ",", "\n", "detected_class_labels", "=", "detected_class_labels", ",", "\n", "groundtruth_boxes", "=", "groundtruth_boxes", ",", "\n", "groundtruth_class_labels", "=", "groundtruth_class_labels", ",", "\n", "detected_masks", "=", "detected_masks", ",", "\n", "groundtruth_masks", "=", "groundtruth_masks", ",", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_class", ")", ":", "\n", "            ", "if", "scores", "[", "i", "]", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                ", "self", ".", "scores_per_class", "[", "i", "]", ".", "append", "(", "scores", "[", "i", "]", ")", "\n", "self", ".", "tp_fp_labels_per_class", "[", "i", "]", ".", "append", "(", "tp_fp_labels", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation._update_ground_truth_statistics": [[495, 508], ["collections.defaultdict"], "methods", ["None"], ["", "", "", "def", "_update_ground_truth_statistics", "(", "self", ",", "groundtruth_class_labels", ")", ":", "\n", "        ", "\"\"\"Update grouth truth statitistics.\n\n        Args:\n            groundtruth_class_labels: An integer numpy array of length M,\n                representing M class labels of object instances in ground truth\n        \"\"\"", "\n", "count", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "for", "label", "in", "groundtruth_class_labels", ":", "\n", "            ", "count", "[", "label", "]", "+=", "1", "\n", "", "for", "k", "in", "count", ":", "\n", "            ", "self", ".", "num_gt_instances_per_class", "[", "k", "]", "+=", "count", "[", "k", "]", "\n", "self", ".", "num_gt_imgs_per_class", "[", "k", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.object_detection_evaluation.ObjectDetectionEvaluation.evaluate": [[509, 574], ["range", "metrics.compute_cor_loc", "numpy.nanmean", "ObjectDetectionEvalMetrics", "logging.info", "numpy.array", "numpy.array", "metrics.compute_precision_recall", "object_detection_evaluation.ObjectDetectionEvaluation.precisions_per_class.append", "object_detection_evaluation.ObjectDetectionEvaluation.recalls_per_class.append", "metrics.compute_average_precision", "numpy.sum", "metrics.compute_precision_recall", "metrics.compute_average_precision", "numpy.nanmean", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "numpy.append", "numpy.append", "numpy.squeeze", "numpy.argwhere"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_cor_loc", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_precision_recall", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_average_precision", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_precision_recall", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.metrics.compute_average_precision"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Compute evaluation result.\n\n        Returns:\n            A named tuple with the following fields -\n                average_precision: float numpy array of average precision for\n                    each class.\n                mean_ap: mean average precision of all classes, float scalar\n                precisions: List of precisions, each precision is a float numpy\n                    array\n                recalls: List of recalls, each recall is a float numpy array\n                corloc: numpy float array\n                mean_corloc: Mean CorLoc score for each class, float scalar\n        \"\"\"", "\n", "if", "(", "self", ".", "num_gt_instances_per_class", "==", "0", ")", ".", "any", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "'The following classes have no ground truth examples: %s'", ",", "\n", "np", ".", "squeeze", "(", "np", ".", "argwhere", "(", "self", ".", "num_gt_instances_per_class", "==", "0", ")", ")", "+", "\n", "self", ".", "label_id_offset", ")", "\n", "\n", "", "if", "self", ".", "use_weighted_mean_ap", ":", "\n", "            ", "all_scores", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "float", ")", "\n", "all_tp_fp_labels", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "bool", ")", "\n", "\n", "", "for", "class_index", "in", "range", "(", "self", ".", "num_class", ")", ":", "\n", "            ", "if", "self", ".", "num_gt_instances_per_class", "[", "class_index", "]", "==", "0", ":", "\n", "                ", "continue", "\n", "", "if", "not", "self", ".", "scores_per_class", "[", "class_index", "]", ":", "\n", "                ", "scores", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "float", ")", "\n", "tp_fp_labels", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "bool", ")", "\n", "", "else", ":", "\n", "                ", "scores", "=", "np", ".", "concatenate", "(", "self", ".", "scores_per_class", "[", "class_index", "]", ")", "\n", "tp_fp_labels", "=", "np", ".", "concatenate", "(", "\n", "self", ".", "tp_fp_labels_per_class", "[", "class_index", "]", ")", "\n", "", "if", "self", ".", "use_weighted_mean_ap", ":", "\n", "                ", "all_scores", "=", "np", ".", "append", "(", "all_scores", ",", "scores", ")", "\n", "all_tp_fp_labels", "=", "np", ".", "append", "(", "all_tp_fp_labels", ",", "tp_fp_labels", ")", "\n", "", "precision", ",", "recall", "=", "metrics", ".", "compute_precision_recall", "(", "\n", "scores", ",", "tp_fp_labels", ",", "\n", "self", ".", "num_gt_instances_per_class", "[", "class_index", "]", ")", "\n", "self", ".", "precisions_per_class", ".", "append", "(", "precision", ")", "\n", "self", ".", "recalls_per_class", ".", "append", "(", "recall", ")", "\n", "average_precision", "=", "metrics", ".", "compute_average_precision", "(", "\n", "precision", ",", "recall", ")", "\n", "self", ".", "average_precision_per_class", "[", "class_index", "]", "=", "average_precision", "\n", "\n", "", "self", ".", "corloc_per_class", "=", "metrics", ".", "compute_cor_loc", "(", "\n", "self", ".", "num_gt_imgs_per_class", ",", "\n", "self", ".", "num_images_correctly_detected_per_class", ")", "\n", "\n", "if", "self", ".", "use_weighted_mean_ap", ":", "\n", "            ", "num_gt_instances", "=", "np", ".", "sum", "(", "self", ".", "num_gt_instances_per_class", ")", "\n", "precision", ",", "recall", "=", "metrics", ".", "compute_precision_recall", "(", "\n", "all_scores", ",", "all_tp_fp_labels", ",", "num_gt_instances", ")", "\n", "mean_ap", "=", "metrics", ".", "compute_average_precision", "(", "precision", ",", "recall", ")", "\n", "", "else", ":", "\n", "            ", "mean_ap", "=", "np", ".", "nanmean", "(", "self", ".", "average_precision_per_class", ")", "\n", "", "mean_corloc", "=", "np", ".", "nanmean", "(", "self", ".", "corloc_per_class", ")", "\n", "return", "ObjectDetectionEvalMetrics", "(", "\n", "self", ".", "average_precision_per_class", ",", "\n", "mean_ap", ",", "\n", "self", ".", "precisions_per_class", ",", "\n", "self", ".", "recalls_per_class", ",", "\n", "self", ".", "corloc_per_class", ",", "\n", "mean_corloc", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.optimizer.tsm_optimizer_constructor.TSMOptimizerConstructor.add_params": [[21, 109], ["model.modules", "normal_weight.pop", "normal_bias.pop", "params.append", "params.append", "params.append", "params.append", "params.append", "params.append", "params.append", "isinstance", "lr5_weight.append", "lr10_bias.append", "normal_weight.append", "normal_bias.append", "list", "isinstance", "m.parameters", "first_conv_weight.append", "normal_weight.append", "list", "normal_weight.append", "isinstance", "len", "first_conv_bias.append", "len", "normal_bias.append", "m.parameters", "len", "normal_bias.append", "list", "m.parameters", "len", "bn.append", "len", "ValueError", "list", "m.parameters", "type"], "methods", ["None"], ["def", "add_params", "(", "self", ",", "params", ",", "model", ")", ":", "\n", "        ", "\"\"\"Add parameters and their corresponding lr and wd to the params.\n\n        Args:\n            params (list): The list to be modified, containing all parameter\n                groups and their corresponding lr and wd configurations.\n            model (nn.Module): The model to be trained with the optimizer.\n        \"\"\"", "\n", "# use fc_lr5 to determine whether to specify higher multi-factor", "\n", "# for fc layer weights and bias.", "\n", "fc_lr5", "=", "self", ".", "paramwise_cfg", "[", "'fc_lr5'", "]", "\n", "first_conv_weight", "=", "[", "]", "\n", "first_conv_bias", "=", "[", "]", "\n", "normal_weight", "=", "[", "]", "\n", "normal_bias", "=", "[", "]", "\n", "lr5_weight", "=", "[", "]", "\n", "lr10_bias", "=", "[", "]", "\n", "bn", "=", "[", "]", "\n", "\n", "conv_cnt", "=", "0", "\n", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "_ConvNd", ")", ":", "\n", "                ", "m_params", "=", "list", "(", "m", ".", "parameters", "(", ")", ")", "\n", "conv_cnt", "+=", "1", "\n", "if", "conv_cnt", "==", "1", ":", "\n", "                    ", "first_conv_weight", ".", "append", "(", "m_params", "[", "0", "]", ")", "\n", "if", "len", "(", "m_params", ")", "==", "2", ":", "\n", "                        ", "first_conv_bias", ".", "append", "(", "m_params", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "normal_weight", ".", "append", "(", "m_params", "[", "0", "]", ")", "\n", "if", "len", "(", "m_params", ")", "==", "2", ":", "\n", "                        ", "normal_bias", ".", "append", "(", "m_params", "[", "1", "]", ")", "\n", "", "", "", "elif", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "                ", "m_params", "=", "list", "(", "m", ".", "parameters", "(", ")", ")", "\n", "normal_weight", ".", "append", "(", "m_params", "[", "0", "]", ")", "\n", "if", "len", "(", "m_params", ")", "==", "2", ":", "\n", "                    ", "normal_bias", ".", "append", "(", "m_params", "[", "1", "]", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "\n", "(", "_BatchNorm", ",", "SyncBatchNorm", ",", "torch", ".", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "for", "param", "in", "list", "(", "m", ".", "parameters", "(", ")", ")", ":", "\n", "                    ", "if", "param", ".", "requires_grad", ":", "\n", "                        ", "bn", ".", "append", "(", "param", ")", "\n", "", "", "", "elif", "len", "(", "m", ".", "_modules", ")", "==", "0", ":", "\n", "                ", "if", "len", "(", "list", "(", "m", ".", "parameters", "(", ")", ")", ")", ">", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "f'New atomic module type: {type(m)}. '", "\n", "'Need to give it a learning policy'", ")", "\n", "\n", "# pop the cls_head fc layer params", "\n", "", "", "", "last_fc_weight", "=", "normal_weight", ".", "pop", "(", ")", "\n", "last_fc_bias", "=", "normal_bias", ".", "pop", "(", ")", "\n", "if", "fc_lr5", ":", "\n", "            ", "lr5_weight", ".", "append", "(", "last_fc_weight", ")", "\n", "lr10_bias", ".", "append", "(", "last_fc_bias", ")", "\n", "", "else", ":", "\n", "            ", "normal_weight", ".", "append", "(", "last_fc_weight", ")", "\n", "normal_bias", ".", "append", "(", "last_fc_bias", ")", "\n", "\n", "", "params", ".", "append", "(", "{", "\n", "'params'", ":", "first_conv_weight", ",", "\n", "'lr'", ":", "self", ".", "base_lr", ",", "\n", "'weight_decay'", ":", "self", ".", "base_wd", "\n", "}", ")", "\n", "params", ".", "append", "(", "{", "\n", "'params'", ":", "first_conv_bias", ",", "\n", "'lr'", ":", "self", ".", "base_lr", "*", "2", ",", "\n", "'weight_decay'", ":", "0", "\n", "}", ")", "\n", "params", ".", "append", "(", "{", "\n", "'params'", ":", "normal_weight", ",", "\n", "'lr'", ":", "self", ".", "base_lr", ",", "\n", "'weight_decay'", ":", "self", ".", "base_wd", "\n", "}", ")", "\n", "params", ".", "append", "(", "{", "\n", "'params'", ":", "normal_bias", ",", "\n", "'lr'", ":", "self", ".", "base_lr", "*", "2", ",", "\n", "'weight_decay'", ":", "0", "\n", "}", ")", "\n", "params", ".", "append", "(", "{", "'params'", ":", "bn", ",", "'lr'", ":", "self", ".", "base_lr", ",", "'weight_decay'", ":", "0", "}", ")", "\n", "params", ".", "append", "(", "{", "\n", "'params'", ":", "lr5_weight", ",", "\n", "'lr'", ":", "self", ".", "base_lr", "*", "5", ",", "\n", "'weight_decay'", ":", "self", ".", "base_wd", "\n", "}", ")", "\n", "params", ".", "append", "(", "{", "\n", "'params'", ":", "lr10_bias", ",", "\n", "'lr'", ":", "self", ".", "base_lr", "*", "10", ",", "\n", "'weight_decay'", ":", "0", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.bbox.transforms.bbox2result": [[4, 37], ["bboxes.cpu().numpy.cpu().numpy", "labels.cpu().numpy.cpu().numpy", "range", "list", "isinstance", "len", "result.append", "numpy.zeros", "bboxes.cpu().numpy.cpu", "labels.cpu().numpy.cpu", "numpy.concatenate"], "function", ["None"], ["import", "operator", "\n", "import", "weakref", "\n", "from", "typing", "import", "List", "\n", "\n", "import", "torch", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "torch", ".", "distributions", "import", "constraints", "\n", "from", "torch", ".", "distributions", ".", "utils", "import", "(", "_sum_rightmost", ",", "broadcast_all", ",", "\n", "lazy_property", ",", "tril_matrix_to_vec", ",", "\n", "vec_to_tril_matrix", ")", "\n", "from", "torch", ".", "nn", ".", "functional", "import", "pad", "\n", "from", "torch", ".", "nn", ".", "functional", "import", "softplus", "\n", "\n", "__all__", "=", "[", "\n", "'AbsTransform'", ",", "\n", "'AffineTransform'", ",", "\n", "'CatTransform'", ",", "\n", "'ComposeTransform'", ",", "\n", "'CorrCholeskyTransform'", ",", "\n", "'CumulativeDistributionTransform'", ",", "\n", "'ExpTransform'", ",", "\n", "'IndependentTransform'", ",", "\n", "'LowerCholeskyTransform'", ",", "\n", "'PowerTransform'", ",", "\n", "'ReshapeTransform'", ",", "\n", "'SigmoidTransform'", ",", "\n", "'SoftplusTransform'", ",", "\n", "'TanhTransform'", ",", "\n", "'SoftmaxTransform'", ",", "\n", "'StackTransform'", ",", "\n", "'StickBreakingTransform'", ",", "\n", "'Transform'", ",", "\n", "'identity_transform'", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.bbox.bbox_target.bbox_target": [[5, 42], ["len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "len", "len", "pos_bboxes.size", "neg_bboxes.size", "torch.pad", "pos_bboxes.new_zeros", "torch.cat.append", "torch.cat.append"], "function", ["None"], ["def", "bbox_target", "(", "pos_bboxes_list", ",", "neg_bboxes_list", ",", "gt_labels", ",", "cfg", ")", ":", "\n", "    ", "\"\"\"Generate classification targets for bboxes.\n\n    Args:\n        pos_bboxes_list (list[Tensor]): Positive bboxes list.\n        neg_bboxes_list (list[Tensor]): Negative bboxes list.\n        gt_labels (list[Tensor]): Groundtruth classification label list.\n        cfg (Config): RCNN config.\n\n    Returns:\n        (Tensor, Tensor): Label and label_weight for bboxes.\n    \"\"\"", "\n", "labels", ",", "label_weights", "=", "[", "]", ",", "[", "]", "\n", "pos_weight", "=", "1.0", "if", "cfg", ".", "pos_weight", "<=", "0", "else", "cfg", ".", "pos_weight", "\n", "\n", "assert", "len", "(", "pos_bboxes_list", ")", "==", "len", "(", "neg_bboxes_list", ")", "==", "len", "(", "gt_labels", ")", "\n", "length", "=", "len", "(", "pos_bboxes_list", ")", "\n", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "        ", "pos_bboxes", "=", "pos_bboxes_list", "[", "i", "]", "\n", "neg_bboxes", "=", "neg_bboxes_list", "[", "i", "]", "\n", "gt_label", "=", "gt_labels", "[", "i", "]", "\n", "\n", "num_pos", "=", "pos_bboxes", ".", "size", "(", "0", ")", "\n", "num_neg", "=", "neg_bboxes", ".", "size", "(", "0", ")", "\n", "num_samples", "=", "num_pos", "+", "num_neg", "\n", "label", "=", "F", ".", "pad", "(", "gt_label", ",", "(", "0", ",", "0", ",", "0", ",", "num_neg", ")", ")", "\n", "label_weight", "=", "pos_bboxes", ".", "new_zeros", "(", "num_samples", ")", "\n", "label_weight", "[", ":", "num_pos", "]", "=", "pos_weight", "\n", "label_weight", "[", "-", "num_neg", ":", "]", "=", "1.", "\n", "\n", "labels", ".", "append", "(", "label", ")", "\n", "label_weights", ".", "append", "(", "label_weight", ")", "\n", "\n", "", "labels", "=", "torch", ".", "cat", "(", "labels", ",", "0", ")", "\n", "label_weights", "=", "torch", ".", "cat", "(", "label_weights", ",", "0", ")", "\n", "return", "labels", ",", "label_weights", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.__init__": [[17, 23], ["output.OutputHook.register"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.register"], ["def", "__init__", "(", "self", ",", "module", ",", "outputs", "=", "None", ",", "as_tensor", "=", "False", ")", ":", "\n", "        ", "self", ".", "outputs", "=", "outputs", "\n", "self", ".", "as_tensor", "=", "as_tensor", "\n", "self", ".", "layer_outputs", "=", "{", "}", "\n", "self", ".", "handles", "=", "[", "]", "\n", "self", ".", "register", "(", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.register": [[24, 48], ["isinstance", "output.OutputHook.handles.append", "isinstance", "warnings.warn", "output.rgetattr", "rgetattr.register_forward_hook", "output.detach().cpu().numpy", "output.OutputHook.register.hook_wrapper"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.rgetattr"], ["", "def", "register", "(", "self", ",", "module", ")", ":", "\n", "\n", "        ", "def", "hook_wrapper", "(", "name", ")", ":", "\n", "\n", "            ", "def", "hook", "(", "model", ",", "input", ",", "output", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "output", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "warnings", ".", "warn", "(", "f'Directly return the output from {name}, '", "\n", "f'since it is not a tensor'", ")", "\n", "self", ".", "layer_outputs", "[", "name", "]", "=", "output", "\n", "", "elif", "self", ".", "as_tensor", ":", "\n", "                    ", "self", ".", "layer_outputs", "[", "name", "]", "=", "output", "\n", "", "else", ":", "\n", "                    ", "self", ".", "layer_outputs", "[", "name", "]", "=", "output", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "return", "hook", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "for", "name", "in", "self", ".", "outputs", ":", "\n", "                ", "try", ":", "\n", "                    ", "layer", "=", "rgetattr", "(", "module", ",", "name", ")", "\n", "h", "=", "layer", ".", "register_forward_hook", "(", "hook_wrapper", "(", "name", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "raise", "AttributeError", "(", "f'Module {name} not found'", ")", "\n", "", "self", ".", "handles", ".", "append", "(", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove": [[49, 52], ["h.remove"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove"], ["", "", "", "def", "remove", "(", "self", ")", ":", "\n", "        ", "for", "h", "in", "self", ".", "handles", ":", "\n", "            ", "h", ".", "remove", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.__enter__": [[53, 55], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.__exit__": [[56, 58], ["output.OutputHook.remove"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "self", ".", "remove", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.rgetattr": [[62, 68], ["functools.reduce", "getattr", "attr.split"], "function", ["None"], ["", "", "def", "rgetattr", "(", "obj", ",", "attr", ",", "*", "args", ")", ":", "\n", "\n", "    ", "def", "_getattr", "(", "obj", ",", "attr", ")", ":", "\n", "        ", "return", "getattr", "(", "obj", ",", "attr", ",", "*", "args", ")", "\n", "\n", "", "return", "functools", ".", "reduce", "(", "_getattr", ",", "[", "obj", "]", "+", "attr", ".", "split", "(", "'.'", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs_zh_CN.conf.get_version": [[27, 31], ["open", "exec", "locals", "compile", "f.read"], "function", ["None"], ["def", "get_version", "(", ")", ":", "\n", "    ", "with", "open", "(", "version_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "exec", "(", "compile", "(", "f", ".", "read", "(", ")", ",", "version_file", ",", "'exec'", ")", ")", "\n", "", "return", "locals", "(", ")", "[", "'__version__'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs_zh_CN.conf.builder_inited_handler": [[75, 78], ["subprocess.run", "subprocess.run"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["def", "builder_inited_handler", "(", "app", ")", ":", "\n", "    ", "subprocess", ".", "run", "(", "[", "'./merge_docs.sh'", "]", ")", "\n", "subprocess", ".", "run", "(", "[", "'./stat.py'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs_zh_CN.conf.setup": [[80, 82], ["app.connect"], "function", ["None"], ["", "def", "setup", "(", "app", ")", ":", "\n", "    ", "app", ".", "connect", "(", "'builder-inited'", ",", "builder_inited_handler", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.docs_zh_CN.stat.anchor": [[11, 14], ["re.sub().strip", "re.sub", "re.sub", "name.strip().lower", "name.strip"], "function", ["None"], ["def", "anchor", "(", "name", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "r'-+'", ",", "'-'", ",", "re", ".", "sub", "(", "r'[^a-zA-Z0-9]'", ",", "'-'", ",", "\n", "name", ".", "strip", "(", ")", ".", "lower", "(", ")", ")", ")", ".", "strip", "(", "'-'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._get_target_shapes": [[9, 28], ["ValueError"], "function", ["None"], ["def", "_get_target_shapes", "(", "input_shape", ",", "num_classes", "=", "400", ",", "model_type", "=", "'2D'", ")", ":", "\n", "    ", "if", "model_type", "not", "in", "[", "'2D'", ",", "'3D'", "]", ":", "\n", "        ", "raise", "ValueError", "(", "f'Data type {model_type} is not available'", ")", "\n", "\n", "", "preds_target_shape", "=", "(", "input_shape", "[", "0", "]", ",", "num_classes", ")", "\n", "if", "model_type", "==", "'3D'", ":", "\n", "# input shape (batch_size, num_crops*num_clips, C, clip_len, H, W)", "\n", "# target shape (batch_size*num_crops*num_clips, clip_len, H, W, C)", "\n", "        ", "blended_imgs_target_shape", "=", "(", "input_shape", "[", "0", "]", "*", "input_shape", "[", "1", "]", ",", "\n", "input_shape", "[", "3", "]", ",", "input_shape", "[", "4", "]", ",", "\n", "input_shape", "[", "5", "]", ",", "input_shape", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "# input shape (batch_size, num_segments, C, H, W)", "\n", "# target shape (batch_size, num_segments, H, W, C)", "\n", "        ", "blended_imgs_target_shape", "=", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ",", "\n", "input_shape", "[", "3", "]", ",", "input_shape", "[", "4", "]", ",", "\n", "input_shape", "[", "2", "]", ")", "\n", "\n", "", "return", "blended_imgs_target_shape", ",", "preds_target_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_2D_models": [[30, 52], ["base.generate_gradcam_inputs", "demo_inputs[].to", "demo_inputs[].to", "recognizer.to.to", "mmaction.utils.gradcam_utils.GradCAM", "test_gradcam._get_target_shapes", "mmaction.utils.gradcam_utils.GradCAM.", "mmaction.utils.gradcam_utils.GradCAM.", "blended_imgs.size", "preds.size", "blended_imgs.size", "preds.size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_gradcam_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._get_target_shapes"], ["", "def", "_do_test_2D_models", "(", "recognizer", ",", "\n", "target_layer_name", ",", "\n", "input_shape", ",", "\n", "num_classes", "=", "400", ",", "\n", "device", "=", "'cpu'", ")", ":", "\n", "    ", "demo_inputs", "=", "generate_gradcam_inputs", "(", "input_shape", ")", "\n", "demo_inputs", "[", "'imgs'", "]", "=", "demo_inputs", "[", "'imgs'", "]", ".", "to", "(", "device", ")", "\n", "demo_inputs", "[", "'label'", "]", "=", "demo_inputs", "[", "'label'", "]", ".", "to", "(", "device", ")", "\n", "\n", "recognizer", "=", "recognizer", ".", "to", "(", "device", ")", "\n", "gradcam", "=", "GradCAM", "(", "recognizer", ",", "target_layer_name", ")", "\n", "\n", "blended_imgs_target_shape", ",", "preds_target_shape", "=", "_get_target_shapes", "(", "\n", "input_shape", ",", "num_classes", "=", "num_classes", ",", "model_type", "=", "'2D'", ")", "\n", "\n", "blended_imgs", ",", "preds", "=", "gradcam", "(", "demo_inputs", ")", "\n", "assert", "blended_imgs", ".", "size", "(", ")", "==", "blended_imgs_target_shape", "\n", "assert", "preds", ".", "size", "(", ")", "==", "preds_target_shape", "\n", "\n", "blended_imgs", ",", "preds", "=", "gradcam", "(", "demo_inputs", ",", "True", ")", "\n", "assert", "blended_imgs", ".", "size", "(", ")", "==", "blended_imgs_target_shape", "\n", "assert", "preds", ".", "size", "(", ")", "==", "preds_target_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models": [[54, 87], ["test_gradcam._get_target_shapes", "base.generate_gradcam_inputs", "torch.cuda.is_available", "mmaction.utils.gradcam_utils.GradCAM", "mmaction.utils.gradcam_utils.GradCAM.", "mmaction.utils.gradcam_utils.GradCAM.", "recognizer.cuda.cuda", "demo_inputs[].cuda", "demo_inputs[].cuda", "mmaction.utils.gradcam_utils.GradCAM", "mmaction.utils.gradcam_utils.GradCAM.", "mmaction.utils.gradcam_utils.GradCAM.", "blended_imgs.size", "preds.size", "blended_imgs.size", "preds.size", "blended_imgs.size", "preds.size", "blended_imgs.size", "preds.size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._get_target_shapes", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_gradcam_inputs"], ["", "def", "_do_test_3D_models", "(", "recognizer", ",", "\n", "target_layer_name", ",", "\n", "input_shape", ",", "\n", "num_classes", "=", "400", ")", ":", "\n", "    ", "blended_imgs_target_shape", ",", "preds_target_shape", "=", "_get_target_shapes", "(", "\n", "input_shape", ",", "num_classes", "=", "num_classes", ",", "model_type", "=", "'3D'", ")", "\n", "demo_inputs", "=", "generate_gradcam_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "recognizer", "=", "recognizer", ".", "cuda", "(", ")", "\n", "demo_inputs", "[", "'imgs'", "]", "=", "demo_inputs", "[", "'imgs'", "]", ".", "cuda", "(", ")", "\n", "demo_inputs", "[", "'label'", "]", "=", "demo_inputs", "[", "'label'", "]", ".", "cuda", "(", ")", "\n", "gradcam", "=", "GradCAM", "(", "recognizer", ",", "target_layer_name", ")", "\n", "\n", "blended_imgs", ",", "preds", "=", "gradcam", "(", "demo_inputs", ")", "\n", "assert", "blended_imgs", ".", "size", "(", ")", "==", "blended_imgs_target_shape", "\n", "assert", "preds", ".", "size", "(", ")", "==", "preds_target_shape", "\n", "\n", "blended_imgs", ",", "preds", "=", "gradcam", "(", "demo_inputs", ",", "True", ")", "\n", "assert", "blended_imgs", ".", "size", "(", ")", "==", "blended_imgs_target_shape", "\n", "assert", "preds", ".", "size", "(", ")", "==", "preds_target_shape", "\n", "", "", "else", ":", "\n", "        ", "gradcam", "=", "GradCAM", "(", "recognizer", ",", "target_layer_name", ")", "\n", "\n", "blended_imgs", ",", "preds", "=", "gradcam", "(", "demo_inputs", ")", "\n", "assert", "blended_imgs", ".", "size", "(", ")", "==", "blended_imgs_target_shape", "\n", "assert", "preds", ".", "size", "(", ")", "==", "preds_target_shape", "\n", "\n", "blended_imgs", ",", "preds", "=", "gradcam", "(", "demo_inputs", ",", "True", ")", "\n", "assert", "blended_imgs", ".", "size", "(", ")", "==", "blended_imgs_target_shape", "\n", "assert", "preds", ".", "size", "(", ")", "==", "preds_target_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_tsn": [[89, 99], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_2D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_2D_models"], ["", "", "def", "test_tsn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'tsn/tsn_r50_1x1x3_100e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "\n", "input_shape", "=", "(", "1", ",", "25", ",", "3", ",", "32", ",", "32", ")", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "_do_test_2D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_i3d": [[101, 113], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_i3d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'i3d/i3d_r50_32x2x1_100e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained2d'", "]", "=", "False", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "\n", "input_shape", "=", "[", "1", ",", "1", ",", "3", ",", "32", ",", "32", ",", "32", "]", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_r2plus1d": [[115, 129], ["base.get_recognizer_cfg", "dict", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_r2plus1d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'r2plus1d/r2plus1d_r34_8x8x1_180e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained2d'", "]", "=", "False", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'norm_cfg'", "]", "=", "dict", "(", "type", "=", "'BN3d'", ")", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "8", ",", "32", ",", "32", ")", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_slowfast": [[131, 142], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_slowfast", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb.py'", ")", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "\n", "input_shape", "=", "(", "1", ",", "1", ",", "3", ",", "32", ",", "32", ",", "32", ")", "\n", "target_layer_name", "=", "'backbone/slow_path/layer4/1/relu'", "\n", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_tsm": [[144, 161], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_2D_models", "dict", "mmaction.models.build_recognizer", "test_gradcam._do_test_2D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_2D_models", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_2D_models"], ["", "def", "test_tsm", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'tsm/tsm_r50_1x1x8_50e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "# base config", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "32", ",", "32", ")", "\n", "_do_test_2D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n", "# test twice sample + 3 crops, 2*3*8=48", "\n", "config", ".", "model", ".", "test_cfg", "=", "dict", "(", "average_clips", "=", "'prob'", ")", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "48", ",", "3", ",", "32", ",", "32", ")", "\n", "_do_test_2D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_csn": [[163, 175], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_csn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained2d'", "]", "=", "False", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "1", ",", "3", ",", "32", ",", "32", ",", "32", ")", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_tpn": [[177, 195], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_2D_models", "base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_2D_models", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_tpn", "(", ")", ":", "\n", "    ", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "config", "=", "get_recognizer_cfg", "(", "'tpn/tpn_tsm_r50_1x1x8_150e_sthv1_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "32", ",", "32", ")", "\n", "_do_test_2D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ",", "174", ")", "\n", "\n", "config", "=", "get_recognizer_cfg", "(", "\n", "'tpn/tpn_slowonly_r50_8x8x1_150e_kinetics_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "8", ",", "32", ",", "32", ")", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_c3d": [[197, 205], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_c3d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'c3d/c3d_sports1m_16x1x1_45e_ucf101_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "1", ",", "3", ",", "16", ",", "112", ",", "112", ")", "\n", "target_layer_name", "=", "'backbone/conv5a/activate'", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ",", "101", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_tin": [[207, 220], ["pytest.mark.skipif", "base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_2D_models", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_2D_models"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "\n", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "reason", "=", "'requires CUDA support'", ")", "\n", "def", "test_tin", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'tin/tin_tsm_finetune_r50_1x1x8_50e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "64", ",", "64", ")", "\n", "_do_test_2D_models", "(", "\n", "recognizer", ",", "target_layer_name", ",", "input_shape", ",", "device", "=", "'cuda:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam.test_x3d": [[222, 230], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "test_gradcam._do_test_3D_models"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_gradcam._do_test_3D_models"], ["", "def", "test_x3d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'x3d/x3d_s_13x6x1_facebook_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "recognizer", ".", "cfg", "=", "config", "\n", "input_shape", "=", "(", "1", ",", "1", ",", "3", ",", "13", ",", "32", ",", "32", ")", "\n", "target_layer_name", "=", "'backbone/layer4/1/relu'", "\n", "_do_test_3D_models", "(", "recognizer", ",", "target_layer_name", ",", "input_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_neck.test_tpn": [[10, 87], ["dict", "base.generate_backbone_demo_inputs().long().squeeze", "base.generate_backbone_demo_inputs", "base.generate_backbone_demo_inputs", "copy.deepcopy", "mmaction.models.TPN", "mmaction.models.TPN.", "copy.deepcopy", "mmaction.models.TPN", "mmaction.models.TPN.", "mmaction.models.TPN.", "mmaction.models.TPN.", "pytest.raises", "copy.deepcopy", "list", "mmaction.models.TPN", "pytest.raises", "copy.deepcopy", "float", "mmaction.models.TPN", "pytest.raises", "copy.deepcopy", "mmaction.models.TPN", "copy.deepcopy", "list", "pytest.raises", "copy.deepcopy", "mmaction.models.TPN", "torch.Size", "len", "torch.Size", "len", "torch.Size", "len", "torch.Size", "len", "dict", "dict", "dict", "dict", "dict", "dict", "k.endswith", "pytest.raises", "mmaction.models.TPN", "base.generate_backbone_demo_inputs().long", "base.generate_backbone_demo_inputs"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["def", "test_tpn", "(", ")", ":", "\n", "    ", "\"\"\"Test TPN backbone.\"\"\"", "\n", "\n", "tpn_cfg", "=", "dict", "(", "\n", "in_channels", "=", "(", "1024", ",", "2048", ")", ",", "\n", "out_channels", "=", "1024", ",", "\n", "spatial_modulation_cfg", "=", "dict", "(", "\n", "in_channels", "=", "(", "1024", ",", "2048", ")", ",", "out_channels", "=", "2048", ")", ",", "\n", "temporal_modulation_cfg", "=", "dict", "(", "downsample_scales", "=", "(", "8", ",", "8", ")", ")", ",", "\n", "upsample_cfg", "=", "dict", "(", "scale_factor", "=", "(", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "downsample_cfg", "=", "dict", "(", "downsample_scale", "=", "(", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "level_fusion_cfg", "=", "dict", "(", "\n", "in_channels", "=", "(", "1024", ",", "1024", ")", ",", "\n", "mid_channels", "=", "(", "1024", ",", "1024", ")", ",", "\n", "out_channels", "=", "2048", ",", "\n", "downsample_scales", "=", "(", "(", "1", ",", "1", ",", "1", ")", ",", "(", "1", ",", "1", ",", "1", ")", ")", ")", ",", "\n", "aux_head_cfg", "=", "dict", "(", "out_channels", "=", "400", ",", "loss_weight", "=", "0.5", ")", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_cfg_", "[", "'in_channels'", "]", "=", "list", "(", "tpn_cfg_", "[", "'in_channels'", "]", ")", "\n", "TPN", "(", "**", "tpn_cfg_", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_cfg_", "[", "'out_channels'", "]", "=", "float", "(", "tpn_cfg_", "[", "'out_channels'", "]", ")", "\n", "TPN", "(", "**", "tpn_cfg_", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_cfg_", "[", "'downsample_cfg'", "]", "[", "'downsample_position'", "]", "=", "'unsupport'", "\n", "TPN", "(", "**", "tpn_cfg_", ")", "\n", "\n", "", "for", "k", "in", "tpn_cfg", ":", "\n", "        ", "if", "not", "k", ".", "endswith", "(", "'_cfg'", ")", ":", "\n", "            ", "continue", "\n", "", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_cfg_", "[", "k", "]", "=", "list", "(", ")", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "TPN", "(", "**", "tpn_cfg_", ")", "\n", "\n", "", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_cfg_", "[", "'flow_type'", "]", "=", "'unsupport'", "\n", "TPN", "(", "**", "tpn_cfg_", ")", "\n", "\n", "", "target_shape", "=", "(", "32", ",", "1", ")", "\n", "target", "=", "generate_backbone_demo_inputs", "(", "target_shape", ")", ".", "long", "(", ")", ".", "squeeze", "(", ")", "\n", "x0_shape", "=", "(", "32", ",", "1024", ",", "1", ",", "4", ",", "4", ")", "\n", "x1_shape", "=", "(", "32", ",", "2048", ",", "1", ",", "2", ",", "2", ")", "\n", "x0", "=", "generate_backbone_demo_inputs", "(", "x0_shape", ")", "\n", "x1", "=", "generate_backbone_demo_inputs", "(", "x1_shape", ")", "\n", "x", "=", "[", "x0", ",", "x1", "]", "\n", "\n", "# ResNetTPN with 'cascade' flow_type", "\n", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_cascade", "=", "TPN", "(", "**", "tpn_cfg_", ")", "\n", "feat", ",", "loss_aux", "=", "tpn_cascade", "(", "x", ",", "target", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "32", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "assert", "len", "(", "loss_aux", ")", "==", "1", "\n", "\n", "# ResNetTPN with 'parallel' flow_type", "\n", "tpn_cfg_", "=", "copy", ".", "deepcopy", "(", "tpn_cfg", ")", "\n", "tpn_parallel", "=", "TPN", "(", "flow_type", "=", "'parallel'", ",", "**", "tpn_cfg_", ")", "\n", "feat", ",", "loss_aux", "=", "tpn_parallel", "(", "x", ",", "target", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "32", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "assert", "len", "(", "loss_aux", ")", "==", "1", "\n", "\n", "# ResNetTPN with 'cascade' flow_type and target is None", "\n", "feat", ",", "loss_aux", "=", "tpn_cascade", "(", "x", ",", "None", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "32", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "assert", "len", "(", "loss_aux", ")", "==", "0", "\n", "\n", "# ResNetTPN with 'parallel' flow_type and target is None", "\n", "feat", ",", "loss_aux", "=", "tpn_parallel", "(", "x", ",", "None", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "32", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "assert", "len", "(", "loss_aux", ")", "==", "0", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state": [[9, 16], ["isinstance"], "function", ["None"], ["import", "torch", "\n", "from", "mmcv", ".", "utils", "import", "print_log", "\n", "from", "torch", ".", "utils", ".", "data", "import", "Dataset", "\n", "\n", "from", ".", ".", "core", "import", "(", "mean_average_precision", ",", "mean_class_accuracy", ",", "\n", "mmit_mean_average_precision", ",", "top_k_accuracy", ")", "\n", "from", ".", "pipelines", "import", "Compose", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs": [[18, 29], ["numpy.random.random", "torch.FloatTensor"], "function", ["None"], ["class", "BaseDataset", "(", "Dataset", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs": [[31, 59], ["numpy.random.random", "len", "torch.LongTensor", "torch.FloatTensor", "len", "torch.LongTensor", "torch.LongTensor", "ValueError"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_detector_demo_inputs": [[61, 103], ["torch.FloatTensor", "dict", "torch.randn", "numpy.random.random", "img.cuda.cuda", "base.generate_detector_demo_inputs.random_box"], "function", ["None"], ["data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n", "                ", "class_prob", ".", "append", "(", "len", "(", "samples", ")", "/", "len", "(", "self", ".", "video_infos", ")", ")", "\n", "", "class_prob", "=", "[", "x", "**", "self", ".", "power", "for", "x", "in", "class_prob", "]", "\n", "\n", "summ", "=", "sum", "(", "class_prob", ")", "\n", "class_prob", "=", "[", "x", "/", "summ", "for", "x", "in", "class_prob", "]", "\n", "\n", "self", ".", "class_prob", "=", "dict", "(", "zip", "(", "self", ".", "video_infos_by_class", ",", "class_prob", ")", ")", "\n", "\n", "", "", "@", "abstractmethod", "\n", "def", "load_annotations", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_gradcam_inputs": [[105, 128], ["numpy.random.random", "torch.LongTensor", "ValueError", "torch.FloatTensor"], "function", ["None"], ["\n", "# json annotations already looks like video_infos, so for each dataset,", "\n", "# this func should be the same", "\n", "", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "path_key", "=", "'frame_dir'", "if", "'frame_dir'", "in", "video_infos", "[", "0", "]", "else", "'filename'", "\n", "for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n", "if", "self", ".", "multi_class", ":", "\n", "                ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "video_infos", "[", "i", "]", "[", "'label'", "]", ")", "==", "1", "\n", "video_infos", "[", "i", "]", "[", "'label'", "]", "=", "video_infos", "[", "i", "]", "[", "'label'", "]", "[", "0", "]", "\n", "", "", "return", "video_infos", "\n", "\n", "", "def", "parse_by_class", "(", "self", ")", ":", "\n", "        ", "video_infos_by_class", "=", "defaultdict", "(", "list", ")", "\n", "for", "item", "in", "self", ".", "video_infos", ":", "\n", "            ", "label", "=", "item", "[", "'label'", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_cfg": [[130, 147], ["os.dirname", "os.join", "os.join", "mmcv.Config.fromfile", "os.dirname", "os.exists", "Exception", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "return", "video_infos_by_class", "\n", "\n", "", "@", "staticmethod", "\n", "def", "label2array", "(", "num", ",", "label", ")", ":", "\n", "        ", "arr", "=", "np", ".", "zeros", "(", "num", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr", "[", "label", "]", "=", "1.", "\n", "return", "arr", "\n", "\n", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'top_k_accuracy'", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "(", "1", ",", "5", ")", ")", ")", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg": [[149, 151], ["base.get_cfg"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_cfg"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_audio_recognizer_cfg": [[153, 155], ["base.get_cfg"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_cfg"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_localizer_cfg": [[157, 159], ["base.get_cfg"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_cfg"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_detector_cfg": [[161, 163], ["base.get_cfg"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_cfg"], ["# Protect ``metric_options`` since it uses mutable value as default", "\n", "metric_options", "=", "copy", ".", "deepcopy", "(", "metric_options", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_common.test_conv2plus1d": [[9, 25], ["mmaction.models.common.Conv2plus1d", "mmaction.models.common.Conv2plus1d.init_weights", "torch.equal", "torch.equal", "torch.rand", "mmaction.models.common.Conv2plus1d.", "pytest.raises", "mmaction.models.common.Conv2plus1d", "torch.ones_like", "torch.zeros_like", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["self", ".", "fc1", "=", "nn", ".", "Linear", "(", "*", "linear_size", "[", "0", "]", ")", "\n", "self", ".", "gelu", "=", "nn", ".", "GELU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "*", "linear_size", "[", "1", "]", ")", "\n", "if", "rank", ":", "\n", "            ", "self", ".", "fc1", ".", "cuda", "(", "rank", ")", "\n", "self", ".", "fc2", ".", "cuda", "(", "rank", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "fc2", "(", "self", ".", "gelu", "(", "self", ".", "fc1", "(", "inp", ")", ")", ")", "\n", "\n", "", "def", "get_weights", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "fc1", ".", "weight", ",", "ShardedTensor", ")", ":", "\n", "            ", "weight1", "=", "self", ".", "fc1", ".", "weight", ".", "local_tensor", "(", ")", "\n", "", "else", ":", "\n", "            ", "weight1", "=", "self", ".", "fc1", ".", "weight", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "fc2", ".", "weight", ",", "ShardedTensor", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_common.test_conv_audio": [[27, 38], ["mmaction.models.common.ConvAudio", "mmaction.models.common.ConvAudio.init_weights", "torch.rand", "mmaction.models.common.ConvAudio.", "mmaction.models.common.ConvAudio", "mmaction.models.common.ConvAudio.", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "else", ":", "\n", "            ", "weight2", "=", "self", ".", "fc2", ".", "weight", "\n", "\n", "", "return", "(", "weight1", ",", "weight2", ")", "\n", "\n", "", "def", "get_biases", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "fc1", ".", "bias", ",", "self", ".", "fc2", ".", "bias", ")", "\n", "\n", "", "def", "get_weight_grads", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "fc1", ".", "weight", ".", "grad", ",", "self", ".", "fc2", ".", "weight", ".", "grad", ")", "\n", "\n", "", "def", "get_bias_grads", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_common.test_TAM": [[40, 60], ["mmaction.models.common.TAM", "torch.rand", "mmaction.models.common.TAM.", "pytest.raises", "mmaction.models.common.TAM", "pytest.raises", "mmaction.models.common.TAM", "pytest.raises", "mmaction.models.common.TAM", "torch.rand", "mmaction.models.common.TAM.", "torch.Size"], "function", ["None"], ["", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_common.test_LFB": [[62, 100], ["os.normpath", "mmaction.models.common.LFB", "mmaction.models.common.LFB", "pytest.raises", "mmaction.models.common.LFB", "os.join", "pytest.raises", "mmaction.models.common.LFB", "pytest.raises", "mmaction.models.common.LFB", "len", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], []], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_roi_extractor.test_single_roi_extractor3d": [[6, 58], ["mmaction.models.SingleRoIExtractor3D", "torch.randn", "torch.tensor", "mmaction.models.SingleRoIExtractor3D.", "mmaction.models.SingleRoIExtractor3D.", "torch.randn", "mmaction.models.SingleRoIExtractor3D", "mmaction.models.SingleRoIExtractor3D.", "mmaction.models.SingleRoIExtractor3D.", "torch.randn", "mmaction.models.SingleRoIExtractor3D", "mmaction.models.SingleRoIExtractor3D.", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "function", ["None"], ["def", "test_single_roi_extractor3d", "(", ")", ":", "\n", "    ", "roi_extractor", "=", "SingleRoIExtractor3D", "(", "\n", "roi_layer_type", "=", "'RoIAlign'", ",", "\n", "featmap_stride", "=", "16", ",", "\n", "output_size", "=", "8", ",", "\n", "sampling_ratio", "=", "0", ",", "\n", "pool_mode", "=", "'avg'", ",", "\n", "aligned", "=", "True", ",", "\n", "with_temporal_pool", "=", "True", ")", "\n", "feat", "=", "torch", ".", "randn", "(", "[", "4", ",", "64", ",", "8", ",", "16", ",", "16", "]", ")", "\n", "rois", "=", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "1.", ",", "1.", ",", "6.", ",", "6.", "]", ",", "[", "1.", ",", "2.", ",", "2.", ",", "7.", ",", "7.", "]", ",", "\n", "[", "3.", ",", "2.", ",", "2.", ",", "9.", ",", "9.", "]", ",", "[", "2.", ",", "2.", ",", "0.", ",", "10.", ",", "9.", "]", "]", ")", "\n", "roi_feat", ",", "feat", "=", "roi_extractor", "(", "feat", ",", "rois", ")", "\n", "assert", "roi_feat", ".", "shape", "==", "(", "4", ",", "64", ",", "1", ",", "8", ",", "8", ")", "\n", "assert", "feat", ".", "shape", "==", "(", "4", ",", "64", ",", "1", ",", "16", ",", "16", ")", "\n", "\n", "feat", "=", "(", "torch", ".", "randn", "(", "[", "4", ",", "64", ",", "8", ",", "16", ",", "16", "]", ")", ",", "torch", ".", "randn", "(", "[", "4", ",", "32", ",", "16", ",", "16", ",", "16", "]", ")", ")", "\n", "roi_feat", ",", "feat", "=", "roi_extractor", "(", "feat", ",", "rois", ")", "\n", "assert", "roi_feat", ".", "shape", "==", "(", "4", ",", "96", ",", "1", ",", "8", ",", "8", ")", "\n", "assert", "feat", ".", "shape", "==", "(", "4", ",", "96", ",", "1", ",", "16", ",", "16", ")", "\n", "\n", "feat", "=", "torch", ".", "randn", "(", "[", "4", ",", "64", ",", "8", ",", "16", ",", "16", "]", ")", "\n", "roi_extractor", "=", "SingleRoIExtractor3D", "(", "\n", "roi_layer_type", "=", "'RoIAlign'", ",", "\n", "featmap_stride", "=", "16", ",", "\n", "output_size", "=", "8", ",", "\n", "sampling_ratio", "=", "0", ",", "\n", "pool_mode", "=", "'avg'", ",", "\n", "aligned", "=", "True", ",", "\n", "with_temporal_pool", "=", "False", ")", "\n", "roi_feat", ",", "feat", "=", "roi_extractor", "(", "feat", ",", "rois", ")", "\n", "assert", "roi_feat", ".", "shape", "==", "(", "4", ",", "64", ",", "8", ",", "8", ",", "8", ")", "\n", "assert", "feat", ".", "shape", "==", "(", "4", ",", "64", ",", "8", ",", "16", ",", "16", ")", "\n", "\n", "feat", "=", "(", "torch", ".", "randn", "(", "[", "4", ",", "64", ",", "8", ",", "16", ",", "16", "]", ")", ",", "torch", ".", "randn", "(", "[", "4", ",", "32", ",", "16", ",", "16", ",", "16", "]", ")", ")", "\n", "roi_feat", ",", "feat", "=", "roi_extractor", "(", "feat", ",", "rois", ")", "\n", "assert", "roi_feat", ".", "shape", "==", "(", "4", ",", "96", ",", "16", ",", "8", ",", "8", ")", "\n", "assert", "feat", ".", "shape", "==", "(", "4", ",", "96", ",", "16", ",", "16", ",", "16", ")", "\n", "\n", "feat", "=", "torch", ".", "randn", "(", "[", "4", ",", "64", ",", "8", ",", "16", ",", "16", "]", ")", "\n", "roi_extractor", "=", "SingleRoIExtractor3D", "(", "\n", "roi_layer_type", "=", "'RoIAlign'", ",", "\n", "featmap_stride", "=", "16", ",", "\n", "output_size", "=", "8", ",", "\n", "sampling_ratio", "=", "0", ",", "\n", "pool_mode", "=", "'avg'", ",", "\n", "aligned", "=", "True", ",", "\n", "with_temporal_pool", "=", "True", ",", "\n", "with_global", "=", "True", ")", "\n", "roi_feat", ",", "feat", "=", "roi_extractor", "(", "feat", ",", "rois", ")", "\n", "assert", "roi_feat", ".", "shape", "==", "(", "4", ",", "128", ",", "1", ",", "8", ",", "8", ")", "\n", "assert", "feat", ".", "shape", "==", "(", "4", ",", "64", ",", "1", ",", "16", ",", "16", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_x3d_backbone": [[15, 129], ["mmaction.models.X3D", "mmaction.models.X3D.init_weights", "mmaction.models.X3D.train", "base.check_norm_state", "mmaction.models.X3D", "mmaction.models.X3D.init_weights", "mmaction.models.X3D.train", "base.check_norm_state", "mmaction.models.X3D", "mmaction.models.X3D.init_weights", "mmaction.models.X3D.train", "base.check_norm_state", "mmaction.models.X3D", "mmaction.models.X3D.init_weights", "mmaction.models.X3D.train", "base.check_norm_state", "mmaction.models.X3D", "x3d_s_frozen.cuda.init_weights", "x3d_s_frozen.cuda.train", "x3d_s_frozen.cuda.conv1_s.parameters", "x3d_s_frozen.cuda.conv1_t.parameters", "range", "x3d_s_frozen.cuda.modules", "base.generate_backbone_demo_inputs", "base.generate_backbone_demo_inputs", "pytest.raises", "mmaction.models.X3D", "pytest.raises", "mmaction.models.X3D", "pytest.raises", "mmaction.models.X3D", "pytest.raises", "mmaction.models.X3D", "pytest.raises", "mmaction.models.X3D", "mmaction.models.X3D.modules", "mmaction.models.X3D.modules", "mmaction.models.X3D.modules", "mmaction.models.X3D.modules", "getattr", "getattr.modules", "getattr.parameters", "hasattr", "torch.cuda.is_available", "torch.cuda.is_available", "x3d_s_frozen.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "x3d_s_frozen.cuda.", "isinstance", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "x3d_s_frozen.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "x3d_s_frozen.cuda.", "torch.Size", "torch.Size", "x3d_s_frozen.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "x3d_s_frozen.cuda.", "torch.Size", "torch.Size", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["def", "test_x3d_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test x3d backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In X3D: 1 <= num_stages <= 4", "\n", "        ", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "2.2", ",", "num_stages", "=", "0", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In X3D: 1 <= num_stages <= 4", "\n", "        ", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "2.2", ",", "num_stages", "=", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# len(spatial_strides) == num_stages", "\n", "        ", "X3D", "(", "gamma_w", "=", "1.0", ",", "\n", "gamma_b", "=", "2.25", ",", "\n", "gamma_d", "=", "2.2", ",", "\n", "spatial_strides", "=", "(", "1", ",", "2", ")", ",", "\n", "num_stages", "=", "4", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# se_style in ['half', 'all']", "\n", "        ", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "2.2", ",", "se_style", "=", "None", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# se_ratio should be None or > 0", "\n", "        ", "X3D", "(", "gamma_w", "=", "1.0", ",", "\n", "gamma_b", "=", "2.25", ",", "\n", "gamma_d", "=", "2.2", ",", "\n", "se_style", "=", "'half'", ",", "\n", "se_ratio", "=", "0", ")", "\n", "\n", "# x3d_s, no pretrained, norm_eval True", "\n", "", "x3d_s", "=", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "2.2", ",", "norm_eval", "=", "True", ")", "\n", "x3d_s", ".", "init_weights", "(", ")", "\n", "x3d_s", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "x3d_s", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# x3d_l, no pretrained, norm_eval True", "\n", "x3d_l", "=", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "5.0", ",", "norm_eval", "=", "True", ")", "\n", "x3d_l", ".", "init_weights", "(", ")", "\n", "x3d_l", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "x3d_l", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# x3d_s, no pretrained, norm_eval False", "\n", "x3d_s", "=", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "2.2", ",", "norm_eval", "=", "False", ")", "\n", "x3d_s", ".", "init_weights", "(", ")", "\n", "x3d_s", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "x3d_s", ".", "modules", "(", ")", ",", "True", ")", "\n", "\n", "# x3d_l, no pretrained, norm_eval False", "\n", "x3d_l", "=", "X3D", "(", "gamma_w", "=", "1.0", ",", "gamma_b", "=", "2.25", ",", "gamma_d", "=", "5.0", ",", "norm_eval", "=", "False", ")", "\n", "x3d_l", ".", "init_weights", "(", ")", "\n", "x3d_l", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "x3d_l", ".", "modules", "(", ")", ",", "True", ")", "\n", "\n", "# x3d_s, no pretrained, frozen_stages, norm_eval False", "\n", "frozen_stages", "=", "1", "\n", "x3d_s_frozen", "=", "X3D", "(", "\n", "gamma_w", "=", "1.0", ",", "\n", "gamma_b", "=", "2.25", ",", "\n", "gamma_d", "=", "2.2", ",", "\n", "norm_eval", "=", "False", ",", "\n", "frozen_stages", "=", "frozen_stages", ")", "\n", "\n", "x3d_s_frozen", ".", "init_weights", "(", ")", "\n", "x3d_s_frozen", ".", "train", "(", ")", "\n", "assert", "x3d_s_frozen", ".", "conv1_t", ".", "bn", ".", "training", "is", "False", "\n", "for", "param", "in", "x3d_s_frozen", ".", "conv1_s", ".", "parameters", "(", ")", ":", "\n", "        ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "for", "param", "in", "x3d_s_frozen", ".", "conv1_t", ".", "parameters", "(", ")", ":", "\n", "        ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "x3d_s_frozen", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "\n", "# test zero_init_residual, zero_init_residual is True by default", "\n", "", "", "for", "m", "in", "x3d_s_frozen", ".", "modules", "(", ")", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'conv3'", ")", ":", "\n", "            ", "assert", "torch", ".", "equal", "(", "m", ".", "conv3", ".", "bn", ".", "weight", ",", "\n", "torch", ".", "zeros_like", "(", "m", ".", "conv3", ".", "bn", ".", "weight", ")", ")", "\n", "assert", "torch", ".", "equal", "(", "m", ".", "conv3", ".", "bn", ".", "bias", ",", "\n", "torch", ".", "zeros_like", "(", "m", ".", "conv3", ".", "bn", ".", "bias", ")", ")", "\n", "\n", "# x3d_s inference", "\n", "", "", "input_shape", "=", "(", "1", ",", "3", ",", "13", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "x3d_s_frozen", "=", "x3d_s_frozen", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "x3d_s_frozen", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "432", ",", "13", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "x3d_s_frozen", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "432", ",", "13", ",", "2", ",", "2", "]", ")", "\n", "\n", "# x3d_m inference", "\n", "", "input_shape", "=", "(", "1", ",", "3", ",", "16", ",", "96", ",", "96", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "x3d_s_frozen", "=", "x3d_s_frozen", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "x3d_s_frozen", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "432", ",", "16", ",", "3", ",", "3", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "x3d_s_frozen", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "432", ",", "16", ",", "3", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_resnet2plus1d_backbone": [[131, 220], ["mmaction.models.ResNet2Plus1d", "r2plus1d_34_frozen.cuda.init_weights", "r2plus1d_34_frozen.cuda.train", "r2plus1d_34_frozen.cuda.conv1.parameters", "range", "base.generate_backbone_demo_inputs", "mmaction.models.ResNet2Plus1d", "r2plus1d_50_frozen.cuda.init_weights", "r2plus1d_50_frozen.cuda.train", "r2plus1d_50_frozen.cuda.conv1.parameters", "range", "base.generate_backbone_demo_inputs", "pytest.raises", "mmaction.models.ResNet2Plus1d", "pytest.raises", "mmaction.models.ResNet2Plus1d", "getattr", "getattr.modules", "getattr.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "r2plus1d_34_frozen.cuda.", "getattr", "getattr.modules", "getattr.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "r2plus1d_50_frozen.cuda.", "dict", "isinstance", "r2plus1d_34_frozen.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "r2plus1d_34_frozen.cuda.", "torch.Size", "torch.Size", "dict", "isinstance", "r2plus1d_50_frozen.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "r2plus1d_50_frozen.cuda.", "torch.Size", "torch.Size", "dict", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["", "", "def", "test_resnet2plus1d_backbone", "(", ")", ":", "\n", "# Test r2+1d backbone", "\n", "    ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# r2+1d does not support inflation", "\n", "        ", "ResNet2Plus1d", "(", "50", ",", "None", ",", "pretrained2d", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# r2+1d requires conv(2+1)d module", "\n", "        ", "ResNet2Plus1d", "(", "\n", "50", ",", "None", ",", "pretrained2d", "=", "False", ",", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv3d'", ")", ")", "\n", "\n", "", "frozen_stages", "=", "1", "\n", "r2plus1d_34_frozen", "=", "ResNet2Plus1d", "(", "\n", "34", ",", "\n", "None", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv2plus1d'", ")", ",", "\n", "pretrained2d", "=", "False", ",", "\n", "frozen_stages", "=", "frozen_stages", ",", "\n", "conv1_kernel", "=", "(", "3", ",", "7", ",", "7", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "spatial_strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "temporal_strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ")", "\n", "r2plus1d_34_frozen", ".", "init_weights", "(", ")", "\n", "r2plus1d_34_frozen", ".", "train", "(", ")", "\n", "assert", "r2plus1d_34_frozen", ".", "conv1", ".", "conv", ".", "bn_s", ".", "training", "is", "False", "\n", "assert", "r2plus1d_34_frozen", ".", "conv1", ".", "bn", ".", "training", "is", "False", "\n", "for", "param", "in", "r2plus1d_34_frozen", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "        ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "r2plus1d_34_frozen", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "", "input_shape", "=", "(", "1", ",", "3", ",", "8", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "r2plus1d_34_frozen", "=", "r2plus1d_34_frozen", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "r2plus1d_34_frozen", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "r2plus1d_34_frozen", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "\n", "", "r2plus1d_50_frozen", "=", "ResNet2Plus1d", "(", "\n", "50", ",", "\n", "None", ",", "\n", "conv_cfg", "=", "dict", "(", "type", "=", "'Conv2plus1d'", ")", ",", "\n", "pretrained2d", "=", "False", ",", "\n", "conv1_kernel", "=", "(", "3", ",", "7", ",", "7", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "spatial_strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "temporal_strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "frozen_stages", "=", "frozen_stages", ")", "\n", "r2plus1d_50_frozen", ".", "init_weights", "(", ")", "\n", "\n", "r2plus1d_50_frozen", ".", "train", "(", ")", "\n", "assert", "r2plus1d_50_frozen", ".", "conv1", ".", "conv", ".", "bn_s", ".", "training", "is", "False", "\n", "assert", "r2plus1d_50_frozen", ".", "conv1", ".", "bn", ".", "training", "is", "False", "\n", "for", "param", "in", "r2plus1d_50_frozen", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "        ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "r2plus1d_50_frozen", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "", "input_shape", "=", "(", "1", ",", "3", ",", "8", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "r2plus1d_50_frozen", "=", "r2plus1d_50_frozen", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "r2plus1d_50_frozen", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "r2plus1d_50_frozen", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_resnet_tsm_backbone": [[222, 323], ["base.generate_backbone_demo_inputs", "mmaction.models.ResNetTSM", "mmaction.models.ResNetTSM.init_weights", "mmaction.models.ResNetTSM", "mmaction.models.ResNetTSM.init_weights", "mmaction.models.ResNetTSM", "mmaction.models.ResNetTSM.init_weights", "dict", "mmaction.models.ResNetTSM", "mmaction.models.ResNetTSM.init_weights", "mmaction.models.ResNetTSM", "mmaction.models.ResNetTSM.init_weights", "mmaction.models.ResNetTSM.", "mmaction.models.ResNetTSM.", "mmaction.models.ResNetTSM.", "base.generate_backbone_demo_inputs", "mmaction.models.ResNetTSM.", "pytest.raises", "mmaction.models.ResNetTSM", "mmaction.models.ResNetTSM.init_weights", "getattr", "list", "getattr", "list", "getattr", "list", "getattr", "enumerate", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "getattr.children", "isinstance", "isinstance", "getattr.children", "isinstance", "isinstance", "getattr.children", "isinstance", "copy.deepcopy", "isinstance", "isinstance", "dict", "len", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "def", "test_resnet_tsm_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test resnet_tsm backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "# shift_place must be block or blockres", "\n", "        ", "resnet_tsm_50_block", "=", "ResNetTSM", "(", "50", ",", "shift_place", "=", "'Block'", ")", "\n", "resnet_tsm_50_block", ".", "init_weights", "(", ")", "\n", "\n", "", "from", "mmaction", ".", "models", ".", "backbones", ".", "resnet", "import", "Bottleneck", "\n", "from", "mmaction", ".", "models", ".", "backbones", ".", "resnet_tsm", "import", "TemporalShift", "\n", "\n", "input_shape", "=", "(", "8", ",", "3", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "# resnet_tsm with depth 50", "\n", "resnet_tsm_50", "=", "ResNetTSM", "(", "50", ")", "\n", "resnet_tsm_50", ".", "init_weights", "(", ")", "\n", "for", "layer_name", "in", "resnet_tsm_50", ".", "res_layers", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet_tsm_50", ",", "layer_name", ")", "\n", "blocks", "=", "list", "(", "layer", ".", "children", "(", ")", ")", "\n", "for", "block", "in", "blocks", ":", "\n", "            ", "assert", "isinstance", "(", "block", ".", "conv1", ".", "conv", ",", "TemporalShift", ")", "\n", "assert", "block", ".", "conv1", ".", "conv", ".", "num_segments", "==", "resnet_tsm_50", ".", "num_segments", "\n", "assert", "block", ".", "conv1", ".", "conv", ".", "shift_div", "==", "resnet_tsm_50", ".", "shift_div", "\n", "assert", "isinstance", "(", "block", ".", "conv1", ".", "conv", ".", "net", ",", "nn", ".", "Conv2d", ")", "\n", "\n", "# resnet_tsm with depth 50, no pretrained, shift_place is block", "\n", "", "", "resnet_tsm_50_block", "=", "ResNetTSM", "(", "50", ",", "shift_place", "=", "'block'", ")", "\n", "resnet_tsm_50_block", ".", "init_weights", "(", ")", "\n", "for", "layer_name", "in", "resnet_tsm_50_block", ".", "res_layers", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet_tsm_50_block", ",", "layer_name", ")", "\n", "blocks", "=", "list", "(", "layer", ".", "children", "(", ")", ")", "\n", "for", "block", "in", "blocks", ":", "\n", "            ", "assert", "isinstance", "(", "block", ",", "TemporalShift", ")", "\n", "assert", "block", ".", "num_segments", "==", "resnet_tsm_50_block", ".", "num_segments", "\n", "assert", "block", ".", "num_segments", "==", "resnet_tsm_50_block", ".", "num_segments", "\n", "assert", "block", ".", "shift_div", "==", "resnet_tsm_50_block", ".", "shift_div", "\n", "assert", "isinstance", "(", "block", ".", "net", ",", "Bottleneck", ")", "\n", "\n", "# resnet_tsm with depth 50, no pretrained, use temporal_pool", "\n", "", "", "resnet_tsm_50_temporal_pool", "=", "ResNetTSM", "(", "50", ",", "temporal_pool", "=", "True", ")", "\n", "resnet_tsm_50_temporal_pool", ".", "init_weights", "(", ")", "\n", "for", "layer_name", "in", "resnet_tsm_50_temporal_pool", ".", "res_layers", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet_tsm_50_temporal_pool", ",", "layer_name", ")", "\n", "blocks", "=", "list", "(", "layer", ".", "children", "(", ")", ")", "\n", "\n", "if", "layer_name", "==", "'layer2'", ":", "\n", "            ", "assert", "len", "(", "blocks", ")", "==", "2", "\n", "assert", "isinstance", "(", "blocks", "[", "1", "]", ",", "nn", ".", "MaxPool3d", ")", "\n", "blocks", "=", "copy", ".", "deepcopy", "(", "blocks", "[", "0", "]", ")", "\n", "\n", "", "for", "block", "in", "blocks", ":", "\n", "            ", "assert", "isinstance", "(", "block", ".", "conv1", ".", "conv", ",", "TemporalShift", ")", "\n", "if", "layer_name", "==", "'layer1'", ":", "\n", "                ", "assert", "block", ".", "conv1", ".", "conv", ".", "num_segments", "==", "resnet_tsm_50_temporal_pool", ".", "num_segments", "\n", "", "else", ":", "\n", "                ", "assert", "block", ".", "conv1", ".", "conv", ".", "num_segments", "==", "resnet_tsm_50_temporal_pool", ".", "num_segments", "//", "2", "\n", "", "assert", "block", ".", "conv1", ".", "conv", ".", "shift_div", "==", "resnet_tsm_50_temporal_pool", ".", "shift_div", "# noqa: E501", "\n", "assert", "isinstance", "(", "block", ".", "conv1", ".", "conv", ".", "net", ",", "nn", ".", "Conv2d", ")", "\n", "\n", "# resnet_tsm with non-local module", "\n", "", "", "non_local_cfg", "=", "dict", "(", "\n", "sub_sample", "=", "True", ",", "\n", "use_scale", "=", "False", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "mode", "=", "'embedded_gaussian'", ")", "\n", "non_local", "=", "(", "(", "0", ",", "0", ",", "0", ")", ",", "(", "1", ",", "0", ",", "1", ",", "0", ")", ",", "(", "1", ",", "0", ",", "1", ",", "0", ",", "1", ",", "0", ")", ",", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "resnet_tsm_nonlocal", "=", "ResNetTSM", "(", "\n", "50", ",", "non_local", "=", "non_local", ",", "non_local_cfg", "=", "non_local_cfg", ")", "\n", "resnet_tsm_nonlocal", ".", "init_weights", "(", ")", "\n", "for", "layer_name", "in", "[", "'layer2'", ",", "'layer3'", "]", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet_tsm_nonlocal", ",", "layer_name", ")", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "layer", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "assert", "isinstance", "(", "layer", "[", "i", "]", ",", "NL3DWrapper", ")", "\n", "\n", "", "", "", "resnet_tsm_50_full", "=", "ResNetTSM", "(", "\n", "50", ",", "\n", "non_local", "=", "non_local", ",", "\n", "non_local_cfg", "=", "non_local_cfg", ",", "\n", "temporal_pool", "=", "True", ")", "\n", "resnet_tsm_50_full", ".", "init_weights", "(", ")", "\n", "\n", "# TSM forword", "\n", "feat", "=", "resnet_tsm_50", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "# TSM with non-local forward", "\n", "feat", "=", "resnet_tsm_nonlocal", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "# TSM with temporal pool forward", "\n", "feat", "=", "resnet_tsm_50_temporal_pool", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "4", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "# TSM with temporal pool + non-local forward", "\n", "input_shape", "=", "(", "16", ",", "3", ",", "32", ",", "32", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "feat", "=", "resnet_tsm_50_full", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "2048", ",", "1", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_mobilenetv2_tsm_backbone": [[325, 362], ["base.generate_backbone_demo_inputs", "mmaction.models.MobileNetV2TSM", "mmaction.models.MobileNetV2TSM.init_weights", "mmaction.models.MobileNetV2TSM.modules", "mmaction.models.MobileNetV2TSM.", "mmaction.models.MobileNetV2TSM", "mmaction.models.MobileNetV2TSM.init_weights", "mmaction.models.MobileNetV2TSM.", "mmaction.models.MobileNetV2TSM", "mmaction.models.MobileNetV2TSM.init_weights", "mmaction.models.MobileNetV2TSM.", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "isinstance", "isinstance", "isinstance", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_mobilenetv2_tsm_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test mobilenetv2_tsm backbone.\"\"\"", "\n", "from", "mmaction", ".", "models", ".", "backbones", ".", "resnet_tsm", "import", "TemporalShift", "\n", "from", "mmaction", ".", "models", ".", "backbones", ".", "mobilenet_v2", "import", "InvertedResidual", "\n", "from", "mmcv", ".", "cnn", "import", "ConvModule", "\n", "\n", "input_shape", "=", "(", "8", ",", "3", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "# mobilenetv2_tsm with width_mult = 1.0", "\n", "mobilenetv2_tsm", "=", "MobileNetV2TSM", "(", ")", "\n", "mobilenetv2_tsm", ".", "init_weights", "(", ")", "\n", "for", "cur_module", "in", "mobilenetv2_tsm", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "cur_module", ",", "InvertedResidual", ")", "and", "len", "(", "cur_module", ".", "conv", ")", "==", "3", "and", "cur_module", ".", "use_res_connect", ":", "\n", "            ", "assert", "isinstance", "(", "cur_module", ".", "conv", "[", "0", "]", ",", "TemporalShift", ")", "\n", "assert", "cur_module", ".", "conv", "[", "0", "]", ".", "num_segments", "==", "mobilenetv2_tsm", ".", "num_segments", "\n", "assert", "cur_module", ".", "conv", "[", "0", "]", ".", "shift_div", "==", "mobilenetv2_tsm", ".", "shift_div", "\n", "assert", "isinstance", "(", "cur_module", ".", "conv", "[", "0", "]", ".", "net", ",", "ConvModule", ")", "\n", "\n", "# TSM-MobileNetV2 with widen_factor = 1.0 forword", "\n", "", "", "feat", "=", "mobilenetv2_tsm", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "1280", ",", "2", ",", "2", "]", ")", "\n", "\n", "# mobilenetv2 with widen_factor = 0.5 forword", "\n", "mobilenetv2_tsm_05", "=", "MobileNetV2TSM", "(", "widen_factor", "=", "0.5", ")", "\n", "mobilenetv2_tsm_05", ".", "init_weights", "(", ")", "\n", "feat", "=", "mobilenetv2_tsm_05", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "1280", ",", "2", ",", "2", "]", ")", "\n", "\n", "# mobilenetv2 with widen_factor = 1.5 forword", "\n", "mobilenetv2_tsm_15", "=", "MobileNetV2TSM", "(", "widen_factor", "=", "1.5", ")", "\n", "mobilenetv2_tsm_15", ".", "init_weights", "(", ")", "\n", "feat", "=", "mobilenetv2_tsm_15", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "1920", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_slowfast_backbone": [[364, 480], ["mmaction.models.ResNet3dSlowFast", "mmaction.models.ResNet3dSlowFast.init_weights", "mmaction.models.ResNet3dSlowFast.train", "mmaction.models.ResNet3dSlowFast", "sf_50_wo_lateral.cuda.init_weights", "sf_50_wo_lateral.cuda.train", "base.generate_backbone_demo_inputs", "isinstance", "mmaction.models.ResNet3dSlowFast", "sf_50.cuda.init_weights", "sf_50.cuda.train", "range", "mmaction.models.ResNet3dSlowFast", "sf_50.cuda.init_weights", "sf_50.cuda.train", "base.generate_backbone_demo_inputs", "isinstance", "pytest.raises", "mmaction.models.ResNet3dSlowFast", "pytest.raises", "mmaction.models.ResNet3dSlowFast", "sf_50.cuda.init_weights", "pytest.raises", "mmaction.models.ResNet3dSlowFast", "torch.cuda.is_available", "torch.cuda.is_available", "sf_50_wo_lateral.cuda.", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "getattr", "getattr.modules", "getattr.parameters", "torch.cuda.is_available", "torch.cuda.is_available", "sf_50.cuda.", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "dict", "dict", "dict", "sf_50_wo_lateral.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "sf_50_wo_lateral.cuda.", "dict", "isinstance", "sf_50.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "sf_50.cuda.", "list", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_slowfast_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test SlowFast backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# cfg should be a dict", "\n", "        ", "ResNet3dSlowFast", "(", "None", ",", "slow_pathway", "=", "list", "(", "[", "'foo'", ",", "'bar'", "]", ")", ")", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# pretrained should be a str", "\n", "        ", "sf_50", "=", "ResNet3dSlowFast", "(", "dict", "(", "foo", "=", "'bar'", ")", ")", "\n", "sf_50", ".", "init_weights", "(", ")", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# pathway type should be implemented", "\n", "        ", "ResNet3dSlowFast", "(", "None", ",", "slow_pathway", "=", "dict", "(", "type", "=", "'resnext'", ")", ")", "\n", "\n", "# test slowfast with slow inflated", "\n", "", "sf_50_inflate", "=", "ResNet3dSlowFast", "(", "\n", "None", ",", "\n", "slow_pathway", "=", "dict", "(", "\n", "type", "=", "'resnet3d'", ",", "\n", "depth", "=", "50", ",", "\n", "pretrained", "=", "'torchvision://resnet50'", ",", "\n", "pretrained2d", "=", "True", ",", "\n", "lateral", "=", "True", ",", "\n", "conv1_kernel", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "0", ",", "0", ",", "1", ",", "1", ")", ")", ")", "\n", "sf_50_inflate", ".", "init_weights", "(", ")", "\n", "sf_50_inflate", ".", "train", "(", ")", "\n", "\n", "# test slowfast with no lateral connection", "\n", "sf_50_wo_lateral", "=", "ResNet3dSlowFast", "(", "\n", "None", ",", "\n", "slow_pathway", "=", "dict", "(", "\n", "type", "=", "'resnet3d'", ",", "\n", "depth", "=", "50", ",", "\n", "pretrained", "=", "None", ",", "\n", "lateral", "=", "False", ",", "\n", "conv1_kernel", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "0", ",", "0", ",", "1", ",", "1", ")", ")", ")", "\n", "sf_50_wo_lateral", ".", "init_weights", "(", ")", "\n", "sf_50_wo_lateral", ".", "train", "(", ")", "\n", "\n", "# slowfast w/o lateral connection inference test", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "8", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "sf_50_wo_lateral", "=", "sf_50_wo_lateral", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "sf_50_wo_lateral", "(", "imgs_gpu", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "sf_50_wo_lateral", "(", "imgs", ")", "\n", "\n", "", "assert", "isinstance", "(", "feat", ",", "tuple", ")", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "256", ",", "8", ",", "2", ",", "2", "]", ")", "\n", "\n", "# test slowfast with frozen stages config", "\n", "frozen_slow", "=", "3", "\n", "sf_50", "=", "ResNet3dSlowFast", "(", "\n", "None", ",", "\n", "slow_pathway", "=", "dict", "(", "\n", "type", "=", "'resnet3d'", ",", "\n", "depth", "=", "50", ",", "\n", "pretrained", "=", "None", ",", "\n", "pretrained2d", "=", "True", ",", "\n", "lateral", "=", "True", ",", "\n", "conv1_kernel", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "conv1_stride_t", "=", "1", ",", "\n", "pool1_stride_t", "=", "1", ",", "\n", "inflate", "=", "(", "0", ",", "0", ",", "1", ",", "1", ")", ",", "\n", "frozen_stages", "=", "frozen_slow", ")", ")", "\n", "sf_50", ".", "init_weights", "(", ")", "\n", "sf_50", ".", "train", "(", ")", "\n", "\n", "for", "stage", "in", "range", "(", "1", ",", "sf_50", ".", "slow_path", ".", "num_stages", ")", ":", "\n", "        ", "lateral_name", "=", "sf_50", ".", "slow_path", ".", "lateral_connections", "[", "stage", "-", "1", "]", "\n", "conv_lateral", "=", "getattr", "(", "sf_50", ".", "slow_path", ",", "lateral_name", ")", "\n", "for", "mod", "in", "conv_lateral", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "if", "stage", "<=", "frozen_slow", ":", "\n", "                    ", "assert", "mod", ".", "training", "is", "False", "\n", "", "else", ":", "\n", "                    ", "assert", "mod", ".", "training", "is", "True", "\n", "", "", "", "for", "param", "in", "conv_lateral", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "stage", "<=", "frozen_slow", ":", "\n", "                ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "else", ":", "\n", "                ", "assert", "param", ".", "requires_grad", "is", "True", "\n", "\n", "# test slowfast with normal config", "\n", "", "", "", "sf_50", "=", "ResNet3dSlowFast", "(", "None", ")", "\n", "sf_50", ".", "init_weights", "(", ")", "\n", "sf_50", ".", "train", "(", ")", "\n", "\n", "# slowfast inference test", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "8", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "sf_50", "=", "sf_50", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "sf_50", "(", "imgs_gpu", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "sf_50", "(", "imgs", ")", "\n", "\n", "", "assert", "isinstance", "(", "feat", ",", "tuple", ")", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "256", ",", "8", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_slowonly_backbone": [[482, 523], ["mmaction.models.ResNet3dSlowOnly", "so_50.cuda.init_weights", "so_50.cuda.train", "mmaction.models.ResNet3dSlowOnly", "so_50.cuda.init_weights", "so_50.cuda.train", "base.generate_backbone_demo_inputs", "pytest.raises", "mmaction.models.ResNet3dSlowOnly", "torch.cuda.is_available", "torch.cuda.is_available", "so_50.cuda.", "torch.Size", "torch.Size", "so_50.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "so_50.cuda."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["", "def", "test_slowonly_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test SlowOnly backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# SlowOnly should contain no lateral connection", "\n", "        ", "ResNet3dSlowOnly", "(", "50", ",", "None", ",", "lateral", "=", "True", ")", "\n", "\n", "# test SlowOnly for PoseC3D", "\n", "", "so_50", "=", "ResNet3dSlowOnly", "(", "\n", "depth", "=", "50", ",", "\n", "pretrained", "=", "None", ",", "\n", "in_channels", "=", "17", ",", "\n", "base_channels", "=", "32", ",", "\n", "num_stages", "=", "3", ",", "\n", "out_indices", "=", "(", "2", ",", ")", ",", "\n", "stage_blocks", "=", "(", "4", ",", "6", ",", "3", ")", ",", "\n", "conv1_stride_s", "=", "1", ",", "\n", "pool1_stride_s", "=", "1", ",", "\n", "inflate", "=", "(", "0", ",", "1", ",", "1", ")", ",", "\n", "spatial_strides", "=", "(", "2", ",", "2", ",", "2", ")", ",", "\n", "temporal_strides", "=", "(", "1", ",", "1", ",", "2", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "so_50", ".", "init_weights", "(", ")", "\n", "so_50", ".", "train", "(", ")", "\n", "\n", "# test SlowOnly with normal config", "\n", "so_50", "=", "ResNet3dSlowOnly", "(", "50", ",", "None", ")", "\n", "so_50", ".", "init_weights", "(", ")", "\n", "so_50", ".", "train", "(", ")", "\n", "\n", "# SlowOnly inference test", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "8", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "so_50", "=", "so_50", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "so_50", "(", "imgs_gpu", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "so_50", "(", "imgs", ")", "\n", "", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "8", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_resnet_csn_backbone": [[525, 592], ["base.generate_backbone_demo_inputs", "mmaction.models.ResNet3dCSN", "mmaction.models.ResNet3dCSN.train", "mmaction.models.ResNet3dCSN.modules", "mmaction.models.ResNet3dCSN", "resnet3d_csn_ip.cuda.init_weights", "resnet3d_csn_ip.cuda.train", "enumerate", "mmaction.models.ResNet3dCSN", "resnet3d_csn_ir.cuda.init_weights", "resnet3d_csn_ir.cuda.train", "enumerate", "mmaction.models.ResNet3dCSN", "resnet3d_csn_ip.cuda.init_weights", "resnet3d_csn_ip.cuda.train", "resnet3d_csn_ip.cuda.children", "pytest.raises", "mmaction.models.ResNet3dCSN", "isinstance", "getattr", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_csn_ip.cuda.", "getattr", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_csn_ir.cuda.", "m.parameters", "len", "isinstance", "resnet3d_csn_ip.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_csn_ip.cuda.", "torch.Size", "torch.Size", "len", "isinstance", "resnet3d_csn_ir.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_csn_ir.cuda.", "torch.Size", "torch.Size", "len", "torch.Size", "torch.Size", "len", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train"], ["", "def", "test_resnet_csn_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test resnet_csn backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# Bottleneck mode must be \"ip\" or \"ir\"", "\n", "        ", "ResNet3dCSN", "(", "152", ",", "None", ",", "bottleneck_mode", "=", "'id'", ")", "\n", "\n", "", "input_shape", "=", "(", "2", ",", "3", ",", "6", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "resnet3d_csn_frozen", "=", "ResNet3dCSN", "(", "\n", "152", ",", "None", ",", "bn_frozen", "=", "True", ",", "norm_eval", "=", "True", ")", "\n", "resnet3d_csn_frozen", ".", "train", "(", ")", "\n", "for", "m", "in", "resnet3d_csn_frozen", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "            ", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "\n", "# Interaction-preserved channel-separated bottleneck block", "\n", "", "", "", "resnet3d_csn_ip", "=", "ResNet3dCSN", "(", "152", ",", "None", ",", "bottleneck_mode", "=", "'ip'", ")", "\n", "resnet3d_csn_ip", ".", "init_weights", "(", ")", "\n", "resnet3d_csn_ip", ".", "train", "(", ")", "\n", "for", "i", ",", "layer_name", "in", "enumerate", "(", "resnet3d_csn_ip", ".", "res_layers", ")", ":", "\n", "        ", "layers", "=", "getattr", "(", "resnet3d_csn_ip", ",", "layer_name", ")", "\n", "num_blocks", "=", "resnet3d_csn_ip", ".", "stage_blocks", "[", "i", "]", "\n", "assert", "len", "(", "layers", ")", "==", "num_blocks", "\n", "for", "layer", "in", "layers", ":", "\n", "            ", "assert", "isinstance", "(", "layer", ".", "conv2", ",", "nn", ".", "Sequential", ")", "\n", "assert", "len", "(", "layer", ".", "conv2", ")", "==", "2", "\n", "assert", "layer", ".", "conv2", "[", "1", "]", ".", "groups", "==", "layer", ".", "planes", "\n", "", "", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_csn_ip", "=", "resnet3d_csn_ip", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_csn_ip", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_csn_ip", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "\n", "# Interaction-reduced channel-separated bottleneck block", "\n", "", "resnet3d_csn_ir", "=", "ResNet3dCSN", "(", "152", ",", "None", ",", "bottleneck_mode", "=", "'ir'", ")", "\n", "resnet3d_csn_ir", ".", "init_weights", "(", ")", "\n", "resnet3d_csn_ir", ".", "train", "(", ")", "\n", "for", "i", ",", "layer_name", "in", "enumerate", "(", "resnet3d_csn_ir", ".", "res_layers", ")", ":", "\n", "        ", "layers", "=", "getattr", "(", "resnet3d_csn_ir", ",", "layer_name", ")", "\n", "num_blocks", "=", "resnet3d_csn_ir", ".", "stage_blocks", "[", "i", "]", "\n", "assert", "len", "(", "layers", ")", "==", "num_blocks", "\n", "for", "layer", "in", "layers", ":", "\n", "            ", "assert", "isinstance", "(", "layer", ".", "conv2", ",", "nn", ".", "Sequential", ")", "\n", "assert", "len", "(", "layer", ".", "conv2", ")", "==", "1", "\n", "assert", "layer", ".", "conv2", "[", "0", "]", ".", "groups", "==", "layer", ".", "planes", "\n", "", "", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_csn_ir", "=", "resnet3d_csn_ir", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_csn_ir", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_csn_ir", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "\n", "# Set training status = False", "\n", "", "resnet3d_csn_ip", "=", "ResNet3dCSN", "(", "152", ",", "None", ",", "bottleneck_mode", "=", "'ip'", ")", "\n", "resnet3d_csn_ip", ".", "init_weights", "(", ")", "\n", "resnet3d_csn_ip", ".", "train", "(", "False", ")", "\n", "for", "module", "in", "resnet3d_csn_ip", ".", "children", "(", ")", ":", "\n", "        ", "assert", "module", ".", "training", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_tanet_backbone": [[594, 626], ["mmaction.models.TANet", "mmaction.models.TANet.init_weights", "base.generate_backbone_demo_inputs", "mmaction.models.TANet.", "base.generate_backbone_demo_inputs", "mmaction.models.TANet.", "pytest.raises", "mmaction.models.TANet", "mmaction.models.TANet.init_weights", "getattr", "list", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "getattr.children", "isinstance", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "", "def", "test_tanet_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test tanet backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "# TA-Blocks are only based on Bottleneck block now", "\n", "        ", "tanet_18", "=", "TANet", "(", "18", ",", "8", ")", "\n", "tanet_18", ".", "init_weights", "(", ")", "\n", "\n", "", "from", "mmaction", ".", "models", ".", "backbones", ".", "resnet", "import", "Bottleneck", "\n", "from", "mmaction", ".", "models", ".", "backbones", ".", "tanet", "import", "TABlock", "\n", "\n", "# tanet with depth 50", "\n", "tanet_50", "=", "TANet", "(", "50", ",", "8", ")", "\n", "tanet_50", ".", "init_weights", "(", ")", "\n", "\n", "for", "layer_name", "in", "tanet_50", ".", "res_layers", ":", "\n", "        ", "layer", "=", "getattr", "(", "tanet_50", ",", "layer_name", ")", "\n", "blocks", "=", "list", "(", "layer", ".", "children", "(", ")", ")", "\n", "for", "block", "in", "blocks", ":", "\n", "            ", "assert", "isinstance", "(", "block", ",", "TABlock", ")", "\n", "assert", "isinstance", "(", "block", ".", "block", ",", "Bottleneck", ")", "\n", "assert", "block", ".", "tam", ".", "num_segments", "==", "block", ".", "num_segments", "\n", "assert", "block", ".", "tam", ".", "in_channels", "==", "block", ".", "block", ".", "conv1", ".", "out_channels", "\n", "\n", "", "", "input_shape", "=", "(", "8", ",", "3", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "feat", "=", "tanet_50", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "input_shape", "=", "(", "16", ",", "3", ",", "32", ",", "32", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "feat", "=", "tanet_50", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "16", ",", "2048", ",", "1", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_c3d_backbone": [[628, 646], ["base.generate_backbone_demo_inputs", "mmaction.models.C3D", "mmaction.models.C3D.init_weights", "mmaction.models.C3D.train", "mmaction.models.C3D.", "mmaction.models.C3D", "mmaction.models.C3D.init_weights", "mmaction.models.C3D.train", "mmaction.models.C3D.", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train"], ["", "def", "test_c3d_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test c3d backbone.\"\"\"", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "16", ",", "112", ",", "112", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "# c3d inference test", "\n", "c3d", "=", "C3D", "(", ")", "\n", "c3d", ".", "init_weights", "(", ")", "\n", "c3d", ".", "train", "(", ")", "\n", "feat", "=", "c3d", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4096", "]", ")", "\n", "\n", "# c3d with bn inference test", "\n", "c3d_bn", "=", "C3D", "(", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ")", ")", "\n", "c3d_bn", ".", "init_weights", "(", ")", "\n", "c3d_bn", ".", "train", "(", ")", "\n", "feat", "=", "c3d_bn", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4096", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_resnet_audio_backbone": [[648, 658], ["base.generate_backbone_demo_inputs", "mmaction.models.ResNetAudio", "mmaction.models.ResNetAudio.init_weights", "mmaction.models.ResNetAudio.train", "mmaction.models.ResNetAudio.", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train"], ["", "def", "test_resnet_audio_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test ResNetAudio backbone.\"\"\"", "\n", "input_shape", "=", "(", "1", ",", "1", ",", "16", ",", "16", ")", "\n", "spec", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# inference", "\n", "audioonly", "=", "ResNetAudio", "(", "50", ",", "None", ")", "\n", "audioonly", ".", "init_weights", "(", ")", "\n", "audioonly", ".", "train", "(", ")", "\n", "feat", "=", "audioonly", "(", "spec", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "1024", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_backbones.test_resnet_tin_backbone": [[660, 708], ["pytest.mark.skipif", "mmaction.models.ResNetTIN", "mmaction.models.ResNetTIN.init_weights", "mmaction.models.ResNetTIN", "mmaction.models.ResNetTIN.train", "mmaction.models.ResNetTIN.modules", "base.generate_backbone_demo_inputs().cuda", "mmaction.models.ResNetTIN.cuda", "mmaction.models.ResNetTIN.", "pytest.raises", "mmaction.models.ResNetTIN", "mmaction.models.ResNetTIN.init_weights", "getattr", "list", "isinstance", "torch.Size", "torch.Size", "torch.cuda.is_available", "torch.cuda.is_available", "getattr.children", "isinstance", "isinstance", "base.generate_backbone_demo_inputs"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "\n", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "reason", "=", "'requires CUDA support'", ")", "\n", "def", "test_resnet_tin_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test resnet_tin backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# num_segments should be positive", "\n", "        ", "resnet_tin", "=", "ResNetTIN", "(", "50", ",", "num_segments", "=", "-", "1", ")", "\n", "resnet_tin", ".", "init_weights", "(", ")", "\n", "\n", "", "from", "mmaction", ".", "models", ".", "backbones", ".", "resnet_tin", "import", "(", "CombineNet", ",", "\n", "TemporalInterlace", ")", "\n", "\n", "# resnet_tin with normal config", "\n", "resnet_tin", "=", "ResNetTIN", "(", "50", ")", "\n", "resnet_tin", ".", "init_weights", "(", ")", "\n", "for", "layer_name", "in", "resnet_tin", ".", "res_layers", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet_tin", ",", "layer_name", ")", "\n", "blocks", "=", "list", "(", "layer", ".", "children", "(", ")", ")", "\n", "for", "block", "in", "blocks", ":", "\n", "            ", "assert", "isinstance", "(", "block", ".", "conv1", ".", "conv", ",", "CombineNet", ")", "\n", "assert", "isinstance", "(", "block", ".", "conv1", ".", "conv", ".", "net1", ",", "TemporalInterlace", ")", "\n", "assert", "(", "\n", "block", ".", "conv1", ".", "conv", ".", "net1", ".", "num_segments", "==", "resnet_tin", ".", "num_segments", ")", "\n", "assert", "block", ".", "conv1", ".", "conv", ".", "net1", ".", "shift_div", "==", "resnet_tin", ".", "shift_div", "\n", "\n", "# resnet_tin with partial batchnorm", "\n", "", "", "resnet_tin_pbn", "=", "ResNetTIN", "(", "50", ",", "partial_bn", "=", "True", ")", "\n", "resnet_tin_pbn", ".", "train", "(", ")", "\n", "count_bn", "=", "0", "\n", "for", "m", "in", "resnet_tin_pbn", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "count_bn", "+=", "1", "\n", "if", "count_bn", ">=", "2", ":", "\n", "                ", "assert", "m", ".", "training", "is", "False", "\n", "assert", "m", ".", "weight", ".", "requires_grad", "is", "False", "\n", "assert", "m", ".", "bias", ".", "requires_grad", "is", "False", "\n", "", "else", ":", "\n", "                ", "assert", "m", ".", "training", "is", "True", "\n", "assert", "m", ".", "weight", ".", "requires_grad", "is", "True", "\n", "assert", "m", ".", "bias", ".", "requires_grad", "is", "True", "\n", "\n", "", "", "", "input_shape", "=", "(", "8", ",", "3", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", ".", "cuda", "(", ")", "\n", "resnet_tin", "=", "resnet_tin", ".", "cuda", "(", ")", "\n", "\n", "# resnet_tin with normal cfg inference", "\n", "feat", "=", "resnet_tin", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_i3d_head": [[17, 44], ["mmaction.models.I3DHead", "mmaction.models.I3DHead.init_weights", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.I3DHead.", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "test_i3d_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    i3d head.\"\"\"", "\n", "i3d_head", "=", "I3DHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2048", ")", "\n", "i3d_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "i3d_head", ".", "num_classes", "==", "4", "\n", "assert", "i3d_head", ".", "dropout_ratio", "==", "0.5", "\n", "assert", "i3d_head", ".", "in_channels", "==", "2048", "\n", "assert", "i3d_head", ".", "init_std", "==", "0.01", "\n", "\n", "assert", "isinstance", "(", "i3d_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "i3d_head", ".", "dropout", ".", "p", "==", "i3d_head", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "i3d_head", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "i3d_head", ".", "fc_cls", ".", "in_features", "==", "i3d_head", ".", "in_channels", "\n", "assert", "i3d_head", ".", "fc_cls", ".", "out_features", "==", "i3d_head", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "i3d_head", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool3d", ")", "\n", "assert", "i3d_head", ".", "avg_pool", ".", "output_size", "==", "(", "1", ",", "1", ",", "1", ")", "\n", "\n", "input_shape", "=", "(", "3", ",", "2048", ",", "4", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# i3d head inference", "\n", "cls_scores", "=", "i3d_head", "(", "feat", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "3", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_bbox_head_ava": [[46, 112], ["mmaction.models.BBoxHeadAVA", "torch.randn", "torch.randn", "mmaction.models.BBoxHeadAVA.", "mmaction.models.BBoxHeadAVA", "mmaction.models.BBoxHeadAVA.init_weights", "mmaction.models.BBoxHeadAVA", "mmaction.models.BBoxHeadAVA.init_weights", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BBoxHeadAVA.loss", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.tensor", "torch.tensor", "numpy.array", "torch.tensor", "torch.tensor", "mmaction.models.BBoxHeadAVA.get_det_bboxes", "torch.all", "torch.all", "torch.all", "torch.all", "pytest.raises", "mmaction.models.BBoxHeadAVA", "pytest.raises", "mmaction.models.BBoxHeadAVA", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.isclose", "torch.isclose", "torch.isclose", "torch.isclose", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.get_det_bboxes"], ["", "def", "test_bbox_head_ava", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    bbox head.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# topk must be None, int or tuple[int]", "\n", "        ", "BBoxHeadAVA", "(", "topk", "=", "0.1", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# topk should be smaller than num_classes", "\n", "        ", "BBoxHeadAVA", "(", "num_classes", "=", "5", ",", "topk", "=", "(", "3", ",", "5", ")", ")", "\n", "\n", "", "bbox_head", "=", "BBoxHeadAVA", "(", "in_channels", "=", "10", ",", "num_classes", "=", "4", ",", "topk", "=", "1", ")", "\n", "input", "=", "torch", ".", "randn", "(", "[", "3", ",", "10", ",", "2", ",", "2", ",", "2", "]", ")", "\n", "ret", ",", "_", "=", "bbox_head", "(", "input", ")", "\n", "assert", "ret", ".", "shape", "==", "(", "3", ",", "4", ")", "\n", "\n", "bbox_head", "=", "BBoxHeadAVA", "(", ")", "\n", "bbox_head", ".", "init_weights", "(", ")", "\n", "bbox_head", "=", "BBoxHeadAVA", "(", "temporal_pool_type", "=", "'max'", ",", "spatial_pool_type", "=", "'avg'", ")", "\n", "bbox_head", ".", "init_weights", "(", ")", "\n", "\n", "cls_score", "=", "torch", ".", "tensor", "(", "\n", "[", "[", "0.568", ",", "-", "0.162", ",", "0.273", ",", "-", "0.390", ",", "0.447", ",", "0.102", ",", "-", "0.409", "]", ",", "\n", "[", "2.388", ",", "0.609", ",", "0.369", ",", "1.630", ",", "-", "0.808", ",", "-", "0.212", ",", "0.296", "]", ",", "\n", "[", "0.252", ",", "-", "0.533", ",", "-", "0.644", ",", "-", "0.591", ",", "0.148", ",", "0.963", ",", "-", "0.525", "]", ",", "\n", "[", "0.134", ",", "-", "0.311", ",", "-", "0.764", ",", "-", "0.752", ",", "0.656", ",", "-", "1.517", ",", "0.185", "]", "]", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "0.", ",", "1.", ",", "0.", ",", "0.", ",", "1.", ",", "0.", "]", ",", "\n", "[", "0.", ",", "0.", ",", "0.", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.", ",", "1.", ",", "0.", ",", "0.", ",", "1.", ",", "0.", ",", "1.", "]", ",", "\n", "[", "0.", ",", "0.", ",", "1.", ",", "1.", ",", "0.", ",", "0.", ",", "1.", "]", "]", ")", "\n", "label_weights", "=", "torch", ".", "tensor", "(", "[", "1.", ",", "1.", ",", "1.", ",", "1.", "]", ")", "\n", "losses", "=", "bbox_head", ".", "loss", "(", "\n", "cls_score", "=", "cls_score", ",", "\n", "bbox_pred", "=", "None", ",", "\n", "rois", "=", "None", ",", "\n", "labels", "=", "labels", ",", "\n", "label_weights", "=", "label_weights", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'loss_action_cls'", "]", ",", "torch", ".", "tensor", "(", "0.7162495", ")", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'recall@thr=0.5'", "]", ",", "torch", ".", "tensor", "(", "0.6666666", ")", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'prec@thr=0.5'", "]", ",", "torch", ".", "tensor", "(", "0.4791665", ")", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'recall@top3'", "]", ",", "torch", ".", "tensor", "(", "0.75", ")", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'prec@top3'", "]", ",", "torch", ".", "tensor", "(", "0.5", ")", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'recall@top5'", "]", ",", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "assert", "torch", ".", "isclose", "(", "losses", "[", "'prec@top5'", "]", ",", "torch", ".", "tensor", "(", "0.45", ")", ")", "\n", "\n", "rois", "=", "torch", ".", "tensor", "(", "[", "[", "0.0", ",", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", "]", ",", "[", "0.0", ",", "0.5", ",", "0.6", ",", "0.7", ",", "0.8", "]", "]", ")", "\n", "rois", "[", "1", ":", ":", "2", "]", "*=", "380", "\n", "rois", "[", "2", ":", ":", "2", "]", "*=", "220", "\n", "crop_quadruple", "=", "np", ".", "array", "(", "[", "0.1", ",", "0.2", ",", "0.8", ",", "0.7", "]", ")", "\n", "cls_score", "=", "torch", ".", "tensor", "(", "[", "0.995", ",", "0.728", "]", ")", "\n", "img_shape", "=", "(", "320", ",", "480", ")", "\n", "flip", "=", "True", "\n", "\n", "bboxes", ",", "scores", "=", "bbox_head", ".", "get_det_bboxes", "(", "\n", "rois", "=", "rois", ",", "\n", "cls_score", "=", "cls_score", ",", "\n", "img_shape", "=", "img_shape", ",", "\n", "flip", "=", "flip", ",", "\n", "crop_quadruple", "=", "crop_quadruple", ")", "\n", "assert", "torch", ".", "all", "(", "\n", "torch", ".", "isclose", "(", "\n", "bboxes", ",", "\n", "torch", ".", "tensor", "(", "[", "[", "0.89783341", ",", "0.20043750", ",", "0.89816672", ",", "0.20087500", "]", ",", "\n", "[", "0.45499998", ",", "0.69875002", ",", "0.58166665", ",", "0.86499995", "]", "]", ")", ")", ")", "\n", "assert", "torch", ".", "all", "(", "\n", "torch", ".", "isclose", "(", "scores", ",", "torch", ".", "tensor", "(", "[", "0.73007441", ",", "0.67436624", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_x3d_head": [[114, 146], ["mmaction.models.X3DHead", "mmaction.models.X3DHead.init_weights", "isinstance", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.X3DHead.", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_x3d_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    x3d head.\"\"\"", "\n", "x3d_head", "=", "X3DHead", "(", "in_channels", "=", "432", ",", "num_classes", "=", "4", ",", "fc1_bias", "=", "False", ")", "\n", "x3d_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "x3d_head", ".", "num_classes", "==", "4", "\n", "assert", "x3d_head", ".", "dropout_ratio", "==", "0.5", "\n", "assert", "x3d_head", ".", "in_channels", "==", "432", "\n", "assert", "x3d_head", ".", "init_std", "==", "0.01", "\n", "\n", "assert", "isinstance", "(", "x3d_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "x3d_head", ".", "dropout", ".", "p", "==", "x3d_head", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "x3d_head", ".", "fc1", ",", "nn", ".", "Linear", ")", "\n", "assert", "x3d_head", ".", "fc1", ".", "in_features", "==", "x3d_head", ".", "in_channels", "\n", "assert", "x3d_head", ".", "fc1", ".", "out_features", "==", "x3d_head", ".", "mid_channels", "\n", "assert", "x3d_head", ".", "fc1", ".", "bias", "is", "None", "\n", "\n", "assert", "isinstance", "(", "x3d_head", ".", "fc2", ",", "nn", ".", "Linear", ")", "\n", "assert", "x3d_head", ".", "fc2", ".", "in_features", "==", "x3d_head", ".", "mid_channels", "\n", "assert", "x3d_head", ".", "fc2", ".", "out_features", "==", "x3d_head", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "x3d_head", ".", "pool", ",", "nn", ".", "AdaptiveAvgPool3d", ")", "\n", "assert", "x3d_head", ".", "pool", ".", "output_size", "==", "(", "1", ",", "1", ",", "1", ")", "\n", "\n", "input_shape", "=", "(", "3", ",", "432", ",", "4", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# i3d head inference", "\n", "cls_scores", "=", "x3d_head", "(", "feat", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "3", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_slowfast_head": [[148, 178], ["mmaction.models.SlowFastHead", "mmaction.models.SlowFastHead.init_weights", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "mmaction.models.SlowFastHead", "mmaction.models.SlowFastHead.", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_slowfast_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    slowfast head.\"\"\"", "\n", "sf_head", "=", "SlowFastHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2304", ")", "\n", "sf_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "sf_head", ".", "num_classes", "==", "4", "\n", "assert", "sf_head", ".", "dropout_ratio", "==", "0.8", "\n", "assert", "sf_head", ".", "in_channels", "==", "2304", "\n", "assert", "sf_head", ".", "init_std", "==", "0.01", "\n", "\n", "assert", "isinstance", "(", "sf_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "sf_head", ".", "dropout", ".", "p", "==", "sf_head", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "sf_head", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "sf_head", ".", "fc_cls", ".", "in_features", "==", "sf_head", ".", "in_channels", "\n", "assert", "sf_head", ".", "fc_cls", ".", "out_features", "==", "sf_head", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "sf_head", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool3d", ")", "\n", "assert", "sf_head", ".", "avg_pool", ".", "output_size", "==", "(", "1", ",", "1", ",", "1", ")", "\n", "\n", "input_shape", "=", "(", "3", ",", "2048", ",", "32", ",", "7", ",", "7", ")", "\n", "feat_slow", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "input_shape", "=", "(", "3", ",", "256", ",", "4", ",", "7", ",", "7", ")", "\n", "feat_fast", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "sf_head", "=", "SlowFastHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2304", ")", "\n", "cls_scores", "=", "sf_head", "(", "(", "feat_slow", ",", "feat_fast", ")", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "3", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_tsn_head": [[180, 242], ["mmaction.models.TSNHead", "mmaction.models.TSNHead.init_weights", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.TSNHead.", "mmaction.models.TSNHead", "mmaction.models.TSNHead.init_weights", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.TSNHead.", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_tsn_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    tsn head.\"\"\"", "\n", "tsn_head", "=", "TSNHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2048", ")", "\n", "tsn_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "tsn_head", ".", "num_classes", "==", "4", "\n", "assert", "tsn_head", ".", "dropout_ratio", "==", "0.4", "\n", "assert", "tsn_head", ".", "in_channels", "==", "2048", "\n", "assert", "tsn_head", ".", "init_std", "==", "0.01", "\n", "assert", "tsn_head", ".", "consensus", ".", "dim", "==", "1", "\n", "assert", "tsn_head", ".", "spatial_type", "==", "'avg'", "\n", "\n", "assert", "isinstance", "(", "tsn_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "tsn_head", ".", "dropout", ".", "p", "==", "tsn_head", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "tsn_head", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "tsn_head", ".", "fc_cls", ".", "in_features", "==", "tsn_head", ".", "in_channels", "\n", "assert", "tsn_head", ".", "fc_cls", ".", "out_features", "==", "tsn_head", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "tsn_head", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool2d", ")", "\n", "assert", "tsn_head", ".", "avg_pool", ".", "output_size", "==", "(", "1", ",", "1", ")", "\n", "\n", "input_shape", "=", "(", "8", ",", "2048", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# tsn head inference", "\n", "num_segs", "=", "input_shape", "[", "0", "]", "\n", "cls_scores", "=", "tsn_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4", "]", ")", "\n", "\n", "# Test multi-class recognition", "\n", "multi_tsn_head", "=", "TSNHead", "(", "\n", "num_classes", "=", "4", ",", "\n", "in_channels", "=", "2048", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'BCELossWithLogits'", ",", "loss_weight", "=", "160.0", ")", ",", "\n", "multi_class", "=", "True", ",", "\n", "label_smooth_eps", "=", "0.01", ")", "\n", "multi_tsn_head", ".", "init_weights", "(", ")", "\n", "assert", "multi_tsn_head", ".", "num_classes", "==", "4", "\n", "assert", "multi_tsn_head", ".", "dropout_ratio", "==", "0.4", "\n", "assert", "multi_tsn_head", ".", "in_channels", "==", "2048", "\n", "assert", "multi_tsn_head", ".", "init_std", "==", "0.01", "\n", "assert", "multi_tsn_head", ".", "consensus", ".", "dim", "==", "1", "\n", "\n", "assert", "isinstance", "(", "multi_tsn_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "multi_tsn_head", ".", "dropout", ".", "p", "==", "multi_tsn_head", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "multi_tsn_head", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "multi_tsn_head", ".", "fc_cls", ".", "in_features", "==", "multi_tsn_head", ".", "in_channels", "\n", "assert", "multi_tsn_head", ".", "fc_cls", ".", "out_features", "==", "multi_tsn_head", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "multi_tsn_head", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool2d", ")", "\n", "assert", "multi_tsn_head", ".", "avg_pool", ".", "output_size", "==", "(", "1", ",", "1", ")", "\n", "\n", "input_shape", "=", "(", "8", ",", "2048", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# multi-class tsn head inference", "\n", "num_segs", "=", "input_shape", "[", "0", "]", "\n", "cls_scores", "=", "tsn_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_tsn_head_audio": [[244, 272], ["mmaction.models.AudioTSNHead", "mmaction.models.AudioTSNHead.init_weights", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.AudioTSNHead.", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_tsn_head_audio", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    tsn head.\"\"\"", "\n", "tsn_head_audio", "=", "AudioTSNHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "5", ")", "\n", "tsn_head_audio", ".", "init_weights", "(", ")", "\n", "\n", "assert", "tsn_head_audio", ".", "num_classes", "==", "4", "\n", "assert", "tsn_head_audio", ".", "dropout_ratio", "==", "0.4", "\n", "assert", "tsn_head_audio", ".", "in_channels", "==", "5", "\n", "assert", "tsn_head_audio", ".", "init_std", "==", "0.01", "\n", "assert", "tsn_head_audio", ".", "spatial_type", "==", "'avg'", "\n", "\n", "assert", "isinstance", "(", "tsn_head_audio", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "tsn_head_audio", ".", "dropout", ".", "p", "==", "tsn_head_audio", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "tsn_head_audio", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "tsn_head_audio", ".", "fc_cls", ".", "in_features", "==", "tsn_head_audio", ".", "in_channels", "\n", "assert", "tsn_head_audio", ".", "fc_cls", ".", "out_features", "==", "tsn_head_audio", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "tsn_head_audio", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool2d", ")", "\n", "assert", "tsn_head_audio", ".", "avg_pool", ".", "output_size", "==", "(", "1", ",", "1", ")", "\n", "\n", "input_shape", "=", "(", "8", ",", "5", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# tsn head inference", "\n", "cls_scores", "=", "tsn_head_audio", "(", "feat", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "8", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_tsm_head": [[274, 310], ["mmaction.models.TSMHead", "mmaction.models.TSMHead.init_weights", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.TSMHead.", "mmaction.models.TSMHead", "mmaction.models.TSMHead.init_weights", "mmaction.models.TSMHead.", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_tsm_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    tsm head.\"\"\"", "\n", "tsm_head", "=", "TSMHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2048", ")", "\n", "tsm_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "tsm_head", ".", "num_classes", "==", "4", "\n", "assert", "tsm_head", ".", "dropout_ratio", "==", "0.8", "\n", "assert", "tsm_head", ".", "in_channels", "==", "2048", "\n", "assert", "tsm_head", ".", "init_std", "==", "0.001", "\n", "assert", "tsm_head", ".", "consensus", ".", "dim", "==", "1", "\n", "assert", "tsm_head", ".", "spatial_type", "==", "'avg'", "\n", "\n", "assert", "isinstance", "(", "tsm_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "tsm_head", ".", "dropout", ".", "p", "==", "tsm_head", ".", "dropout_ratio", "\n", "\n", "assert", "isinstance", "(", "tsm_head", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "tsm_head", ".", "fc_cls", ".", "in_features", "==", "tsm_head", ".", "in_channels", "\n", "assert", "tsm_head", ".", "fc_cls", ".", "out_features", "==", "tsm_head", ".", "num_classes", "\n", "\n", "assert", "isinstance", "(", "tsm_head", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool2d", ")", "\n", "assert", "tsm_head", ".", "avg_pool", ".", "output_size", "==", "1", "\n", "\n", "input_shape", "=", "(", "8", ",", "2048", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# tsm head inference with no init", "\n", "num_segs", "=", "input_shape", "[", "0", "]", "\n", "cls_scores", "=", "tsm_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4", "]", ")", "\n", "\n", "# tsm head inference with init", "\n", "tsm_head", "=", "TSMHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2048", ",", "temporal_pool", "=", "True", ")", "\n", "tsm_head", ".", "init_weights", "(", ")", "\n", "cls_scores", "=", "tsm_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_trn_head": [[312, 367], ["mmaction.models.TRNHead", "mmaction.models.TRNHead.init_weights", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.rand", "torch.rand", "mmaction.models.TRNHead.", "mmaction.models.TRNHead", "mmaction.models.TRNHead.init_weights", "isinstance", "mmaction.models.TRNHead.", "torch.Size", "torch.Size", "range", "torch.Size", "torch.Size", "pytest.raises", "mmaction.models.TRNHead"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_trn_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    trn head.\"\"\"", "\n", "from", "mmaction", ".", "models", ".", "heads", ".", "trn_head", "import", "(", "RelationModule", ",", "\n", "RelationModuleMultiScale", ")", "\n", "trn_head", "=", "TRNHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2048", ",", "relation_type", "=", "'TRN'", ")", "\n", "trn_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "trn_head", ".", "num_classes", "==", "4", "\n", "assert", "trn_head", ".", "dropout_ratio", "==", "0.8", "\n", "assert", "trn_head", ".", "in_channels", "==", "2048", "\n", "assert", "trn_head", ".", "init_std", "==", "0.001", "\n", "assert", "trn_head", ".", "spatial_type", "==", "'avg'", "\n", "\n", "relation_module", "=", "trn_head", ".", "consensus", "\n", "assert", "isinstance", "(", "relation_module", ",", "RelationModule", ")", "\n", "assert", "relation_module", ".", "hidden_dim", "==", "256", "\n", "assert", "isinstance", "(", "relation_module", ".", "classifier", "[", "3", "]", ",", "nn", ".", "Linear", ")", "\n", "assert", "relation_module", ".", "classifier", "[", "3", "]", ".", "out_features", "==", "trn_head", ".", "num_classes", "\n", "\n", "assert", "trn_head", ".", "dropout", ".", "p", "==", "trn_head", ".", "dropout_ratio", "\n", "assert", "isinstance", "(", "trn_head", ".", "dropout", ",", "nn", ".", "Dropout", ")", "\n", "assert", "isinstance", "(", "trn_head", ".", "fc_cls", ",", "nn", ".", "Linear", ")", "\n", "assert", "trn_head", ".", "fc_cls", ".", "in_features", "==", "trn_head", ".", "in_channels", "\n", "assert", "trn_head", ".", "fc_cls", ".", "out_features", "==", "trn_head", ".", "hidden_dim", "\n", "\n", "assert", "isinstance", "(", "trn_head", ".", "avg_pool", ",", "nn", ".", "AdaptiveAvgPool2d", ")", "\n", "assert", "trn_head", ".", "avg_pool", ".", "output_size", "==", "1", "\n", "\n", "input_shape", "=", "(", "8", ",", "2048", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# tsm head inference with no init", "\n", "num_segs", "=", "input_shape", "[", "0", "]", "\n", "cls_scores", "=", "trn_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4", "]", ")", "\n", "\n", "# tsm head inference with init", "\n", "trn_head", "=", "TRNHead", "(", "\n", "num_classes", "=", "4", ",", "\n", "in_channels", "=", "2048", ",", "\n", "num_segments", "=", "8", ",", "\n", "relation_type", "=", "'TRNMultiScale'", ")", "\n", "trn_head", ".", "init_weights", "(", ")", "\n", "assert", "isinstance", "(", "trn_head", ".", "consensus", ",", "RelationModuleMultiScale", ")", "\n", "assert", "trn_head", ".", "consensus", ".", "scales", "==", "range", "(", "8", ",", "1", ",", "-", "1", ")", "\n", "cls_scores", "=", "trn_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "4", "]", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "trn_head", "=", "TRNHead", "(", "\n", "num_classes", "=", "4", ",", "\n", "in_channels", "=", "2048", ",", "\n", "num_segments", "=", "8", ",", "\n", "relation_type", "=", "'RelationModlue'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_lfb_infer_head": [[369, 387], ["unittest.mock.patch.object", "mmaction.models.LFBInferHead.init_weights", "base.generate_backbone_demo_inputs", "torch.cat", "torch.cat", "mmaction.models.LFBInferHead.", "base.generate_backbone_demo_inputs.equal", "tempfile.TemporaryDirectory", "mmaction.models.LFBInferHead", "dict", "dict", "len", "torch.tensor().float().view", "torch.tensor().float().view", "torch.randn", "torch.randn", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["", "", "@", "patch", ".", "object", "(", "mmaction", ".", "models", ".", "LFBInferHead", ",", "'__del__'", ",", "Mock", ")", "\n", "def", "test_lfb_infer_head", "(", ")", ":", "\n", "    ", "\"\"\"Test layer construction, attributes and forward function in lfb infer\n    head.\"\"\"", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "lfb_infer_head", "=", "LFBInferHead", "(", "\n", "lfb_prefix_path", "=", "tmpdir", ",", "use_half_precision", "=", "True", ")", "\n", "", "lfb_infer_head", ".", "init_weights", "(", ")", "\n", "\n", "st_feat_shape", "=", "(", "3", ",", "16", ",", "1", ",", "8", ",", "8", ")", "\n", "st_feat", "=", "generate_backbone_demo_inputs", "(", "st_feat_shape", ")", "\n", "rois", "=", "torch", ".", "cat", "(", "\n", "(", "torch", ".", "tensor", "(", "[", "0", ",", "1", ",", "0", "]", ")", ".", "float", "(", ")", ".", "view", "(", "3", ",", "1", ")", ",", "torch", ".", "randn", "(", "3", ",", "4", ")", ")", ",", "dim", "=", "1", ")", "\n", "img_metas", "=", "[", "dict", "(", "img_key", "=", "'video_1,777'", ")", ",", "dict", "(", "img_key", "=", "'video_2, 888'", ")", "]", "\n", "result", "=", "lfb_infer_head", "(", "st_feat", ",", "rois", ",", "img_metas", ")", "\n", "assert", "st_feat", ".", "equal", "(", "result", ")", "\n", "assert", "len", "(", "lfb_infer_head", ".", "all_features", ")", "==", "3", "\n", "assert", "lfb_infer_head", ".", "all_features", "[", "0", "]", ".", "shape", "==", "(", "16", ",", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_fbo_head": [[389, 448], ["os.normpath", "base.generate_backbone_demo_inputs", "torch.randn", "torch.randn", "mmaction.models.FBOHead", "mmaction.models.FBOHead.init_weights", "mmaction.models.FBOHead.", "mmaction.models.FBOHead", "mmaction.models.FBOHead.init_weights", "mmaction.models.FBOHead.", "mmaction.models.FBOHead", "mmaction.models.FBOHead.init_weights", "mmaction.models.FBOHead.", "os.join", "dict", "os.dirname", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_fbo_head", "(", ")", ":", "\n", "    ", "\"\"\"Test layer construction, attributes and forward function in fbo head.\"\"\"", "\n", "lfb_prefix_path", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/lfb'", ")", ")", "\n", "\n", "st_feat_shape", "=", "(", "1", ",", "16", ",", "1", ",", "8", ",", "8", ")", "\n", "st_feat", "=", "generate_backbone_demo_inputs", "(", "st_feat_shape", ")", "\n", "rois", "=", "torch", ".", "randn", "(", "1", ",", "5", ")", "\n", "rois", "[", "0", "]", "[", "0", "]", "=", "0", "\n", "img_metas", "=", "[", "dict", "(", "img_key", "=", "'video_1, 930'", ")", "]", "\n", "\n", "# non local fbo", "\n", "fbo_head", "=", "FBOHead", "(", "\n", "lfb_cfg", "=", "dict", "(", "\n", "lfb_prefix_path", "=", "lfb_prefix_path", ",", "\n", "max_num_sampled_feat", "=", "5", ",", "\n", "window_size", "=", "60", ",", "\n", "lfb_channels", "=", "16", ",", "\n", "dataset_modes", "=", "(", "'unittest'", ")", ",", "\n", "device", "=", "'cpu'", ")", ",", "\n", "fbo_cfg", "=", "dict", "(", "\n", "type", "=", "'non_local'", ",", "\n", "st_feat_channels", "=", "16", ",", "\n", "lt_feat_channels", "=", "16", ",", "\n", "latent_channels", "=", "8", ",", "\n", "num_st_feat", "=", "1", ",", "\n", "num_lt_feat", "=", "5", "*", "60", ",", "\n", ")", ")", "\n", "fbo_head", ".", "init_weights", "(", ")", "\n", "out", "=", "fbo_head", "(", "st_feat", ",", "rois", ",", "img_metas", ")", "\n", "assert", "out", ".", "shape", "==", "(", "1", ",", "24", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "# avg fbo", "\n", "fbo_head", "=", "FBOHead", "(", "\n", "lfb_cfg", "=", "dict", "(", "\n", "lfb_prefix_path", "=", "lfb_prefix_path", ",", "\n", "max_num_sampled_feat", "=", "5", ",", "\n", "window_size", "=", "60", ",", "\n", "lfb_channels", "=", "16", ",", "\n", "dataset_modes", "=", "(", "'unittest'", ")", ",", "\n", "device", "=", "'cpu'", ")", ",", "\n", "fbo_cfg", "=", "dict", "(", "type", "=", "'avg'", ")", ")", "\n", "fbo_head", ".", "init_weights", "(", ")", "\n", "out", "=", "fbo_head", "(", "st_feat", ",", "rois", ",", "img_metas", ")", "\n", "assert", "out", ".", "shape", "==", "(", "1", ",", "32", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "# max fbo", "\n", "fbo_head", "=", "FBOHead", "(", "\n", "lfb_cfg", "=", "dict", "(", "\n", "lfb_prefix_path", "=", "lfb_prefix_path", ",", "\n", "max_num_sampled_feat", "=", "5", ",", "\n", "window_size", "=", "60", ",", "\n", "lfb_channels", "=", "16", ",", "\n", "dataset_modes", "=", "(", "'unittest'", ")", ",", "\n", "device", "=", "'cpu'", ")", ",", "\n", "fbo_cfg", "=", "dict", "(", "type", "=", "'max'", ")", ")", "\n", "fbo_head", ".", "init_weights", "(", ")", "\n", "out", "=", "fbo_head", "(", "st_feat", ",", "rois", ",", "img_metas", ")", "\n", "assert", "out", ".", "shape", "==", "(", "1", ",", "32", ",", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_tpn_head": [[450, 479], ["mmaction.models.TPNHead", "mmaction.models.TPNHead.init_weights", "hasattr", "hasattr", "isinstance", "torch.rand", "torch.rand", "mmaction.models.TPNHead.", "isinstance", "torch.rand", "torch.rand", "mmaction.models.TPNHead.", "isinstance", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_tpn_head", "(", ")", ":", "\n", "    ", "\"\"\"Test loss method, layer construction, attributes and forward function in\n    tpn head.\"\"\"", "\n", "tpn_head", "=", "TPNHead", "(", "num_classes", "=", "4", ",", "in_channels", "=", "2048", ")", "\n", "tpn_head", ".", "init_weights", "(", ")", "\n", "\n", "assert", "hasattr", "(", "tpn_head", ",", "'avg_pool2d'", ")", "\n", "assert", "hasattr", "(", "tpn_head", ",", "'avg_pool3d'", ")", "\n", "assert", "isinstance", "(", "tpn_head", ".", "avg_pool3d", ",", "nn", ".", "AdaptiveAvgPool3d", ")", "\n", "assert", "tpn_head", ".", "avg_pool3d", ".", "output_size", "==", "(", "1", ",", "1", ",", "1", ")", "\n", "assert", "tpn_head", ".", "avg_pool2d", "is", "None", "\n", "\n", "input_shape", "=", "(", "4", ",", "2048", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "\n", "# tpn head inference with num_segs", "\n", "num_segs", "=", "2", "\n", "cls_scores", "=", "tpn_head", "(", "feat", ",", "num_segs", ")", "\n", "assert", "isinstance", "(", "tpn_head", ".", "avg_pool2d", ",", "nn", ".", "AvgPool3d", ")", "\n", "assert", "tpn_head", ".", "avg_pool2d", ".", "kernel_size", "==", "(", "1", ",", "7", ",", "7", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "4", "]", ")", "\n", "\n", "# tpn head inference with no num_segs", "\n", "input_shape", "=", "(", "2", ",", "2048", ",", "3", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "rand", "(", "input_shape", ")", "\n", "cls_scores", "=", "tpn_head", "(", "feat", ")", "\n", "assert", "isinstance", "(", "tpn_head", ".", "avg_pool2d", ",", "nn", ".", "AvgPool3d", ")", "\n", "assert", "tpn_head", ".", "avg_pool2d", ".", "kernel_size", "==", "(", "1", ",", "7", ",", "7", ")", "\n", "assert", "cls_scores", ".", "shape", "==", "torch", ".", "Size", "(", "[", "2", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.test_head.test_acrn_head": [[481, 501], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.Tensor", "torch.Tensor", "mmaction.models.ACRNHead", "mmaction.models.ACRNHead.init_weights", "mmaction.models.ACRNHead.", "mmaction.models.ACRNHead", "mmaction.models.ACRNHead.", "mmaction.models.ACRNHead", "mmaction.models.ACRNHead."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["", "def", "test_acrn_head", "(", ")", ":", "\n", "    ", "roi_feat", "=", "torch", ".", "randn", "(", "4", ",", "16", ",", "1", ",", "7", ",", "7", ")", "\n", "feat", "=", "torch", ".", "randn", "(", "2", ",", "16", ",", "1", ",", "16", ",", "16", ")", "\n", "rois", "=", "torch", ".", "Tensor", "(", "[", "[", "0", ",", "2.2268", ",", "0.5926", ",", "10.6142", ",", "8.0029", "]", ",", "\n", "[", "0", ",", "2.2577", ",", "0.1519", ",", "11.6451", ",", "8.9282", "]", ",", "\n", "[", "1", ",", "1.9874", ",", "1.0000", ",", "11.1585", ",", "8.2840", "]", ",", "\n", "[", "1", ",", "3.3338", ",", "3.7166", ",", "8.4174", ",", "11.2785", "]", "]", ")", "\n", "\n", "acrn_head", "=", "ACRNHead", "(", "32", ",", "16", ")", "\n", "acrn_head", ".", "init_weights", "(", ")", "\n", "new_feat", "=", "acrn_head", "(", "roi_feat", ",", "feat", ",", "rois", ")", "\n", "assert", "new_feat", ".", "shape", "==", "(", "4", ",", "16", ",", "1", ",", "16", ",", "16", ")", "\n", "\n", "acrn_head", "=", "ACRNHead", "(", "32", ",", "16", ",", "stride", "=", "2", ")", "\n", "new_feat", "=", "acrn_head", "(", "roi_feat", ",", "feat", ",", "rois", ")", "\n", "assert", "new_feat", ".", "shape", "==", "(", "4", ",", "16", ",", "1", ",", "8", ",", "8", ")", "\n", "\n", "acrn_head", "=", "ACRNHead", "(", "32", ",", "16", ",", "stride", "=", "2", ",", "num_convs", "=", "2", ")", "\n", "new_feat", "=", "acrn_head", "(", "roi_feat", ",", "feat", ",", "rois", ")", "\n", "assert", "new_feat", ".", "shape", "==", "(", "4", ",", "16", ",", "1", ",", "8", ",", "8", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer2d.test_tsn": [[7, 121], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.forward_dummy", "dict", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "dict", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "dict", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "torch.no_grad", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.forward_dummy", "torch.min", "torch.max", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy"], ["def", "test_tsn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'tsn/tsn_r50_1x1x3_100e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n", "# test forward dummy", "\n", "", "recognizer", ".", "forward_dummy", "(", "imgs", ",", "softmax", "=", "False", ")", "\n", "res", "=", "recognizer", ".", "forward_dummy", "(", "imgs", ",", "softmax", "=", "True", ")", "[", "0", "]", "\n", "assert", "torch", ".", "min", "(", "res", ")", ">=", "0", "\n", "assert", "torch", ".", "max", "(", "res", ")", "<=", "1", "\n", "\n", "mmcls_backbone", "=", "dict", "(", "\n", "type", "=", "'mmcls.ResNeXt'", ",", "\n", "depth", "=", "101", ",", "\n", "num_stages", "=", "4", ",", "\n", "out_indices", "=", "(", "3", ",", ")", ",", "\n", "groups", "=", "32", ",", "\n", "width_per_group", "=", "4", ",", "\n", "style", "=", "'pytorch'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "=", "mmcls_backbone", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# test mixup forward", "\n", "", "", "config", "=", "get_recognizer_cfg", "(", "\n", "'tsn/tsn_r50_video_mixup_1x1x8_100e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "input_shape", "=", "(", "2", ",", "8", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# test torchvision backbones", "\n", "tv_backbone", "=", "dict", "(", "type", "=", "'torchvision.densenet161'", ",", "pretrained", "=", "True", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "=", "tv_backbone", "\n", "config", ".", "model", "[", "'cls_head'", "]", "[", "'in_channels'", "]", "=", "2208", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# test timm backbones", "\n", "", "", "timm_backbone", "=", "dict", "(", "type", "=", "'timm.efficientnet_b0'", ",", "pretrained", "=", "False", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "=", "timm_backbone", "\n", "config", ".", "model", "[", "'cls_head'", "]", "[", "'in_channels'", "]", "=", "1280", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer2d.test_tsm": [[123, 162], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "base.generate_recognizer_demo_inputs", "dict", "mmaction.models.build_recognizer", "mmaction.models.build_recognizer.", "torch.no_grad", "torch.no_grad", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["", "", "", "def", "test_tsm", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'tsm/tsm_r50_1x1x8_50e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# test twice sample + 3 crops", "\n", "", "", "input_shape", "=", "(", "2", ",", "48", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "\n", "config", ".", "model", ".", "test_cfg", "=", "dict", "(", "average_clips", "=", "'prob'", ")", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer2d.test_trn": [[164, 203], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "base.generate_recognizer_demo_inputs", "dict", "mmaction.models.build_recognizer", "mmaction.models.build_recognizer.", "torch.no_grad", "torch.no_grad", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["", "", "def", "test_trn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'trn/trn_r50_1x1x8_50e_sthv1_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# test twice sample + 3 crops", "\n", "", "", "input_shape", "=", "(", "2", ",", "48", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "\n", "config", ".", "model", ".", "test_cfg", "=", "dict", "(", "average_clips", "=", "'prob'", ")", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer2d.test_tpn": [[205, 240], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "mmaction.models.build_recognizer.", "torch.no_grad", "mmaction.models.build_recognizer.", "torch.no_grad", "mmaction.models.build_recognizer", "hasattr", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["", "", "def", "test_tpn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'tpn/tpn_tsm_r50_1x1x8_150e_sthv1_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "224", ",", "224", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "assert", "'loss_aux'", "in", "losses", "and", "'loss_cls'", "in", "losses", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n", "# Test forward dummy", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "_recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "if", "hasattr", "(", "_recognizer", ",", "'forward_dummy'", ")", ":", "\n", "            ", "_recognizer", ".", "forward", "=", "_recognizer", ".", "forward_dummy", "\n", "", "for", "one_img", "in", "img_list", ":", "\n", "            ", "_recognizer", "(", "one_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer2d.test_tanet": [[242, 282], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "base.generate_recognizer_demo_inputs", "dict", "mmaction.models.build_recognizer", "mmaction.models.build_recognizer.", "torch.no_grad", "torch.no_grad", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["", "", "", "def", "test_tanet", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'tanet/tanet_r50_dense_1x1x8_100e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# test twice sample + 3 crops", "\n", "", "", "input_shape", "=", "(", "2", ",", "48", ",", "3", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ")", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "\n", "config", ".", "model", ".", "test_cfg", "=", "dict", "(", "average_clips", "=", "'prob'", ")", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_audio_recognizer.test_audio_recognizer": [[7, 29], ["base.get_audio_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "torch.no_grad", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_audio_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs"], ["def", "test_audio_recognizer", "(", ")", ":", "\n", "    ", "config", "=", "get_audio_recognizer_cfg", "(", "\n", "'resnet/tsn_r18_64x1x1_100e_kinetics400_audio_feature.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "1", ",", "128", ",", "80", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "\n", "input_shape", ",", "model_type", "=", "'audio'", ")", "\n", "\n", "audios", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "audios", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "audio_list", "=", "[", "audio", "[", "None", ",", ":", "]", "for", "audio", "in", "audios", "]", "\n", "for", "one_spectro", "in", "audio_list", ":", "\n", "            ", "recognizer", "(", "one_spectro", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer3d.test_i3d": [[7, 66], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "torch.cuda.is_available", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "recognizer.cuda.forward_dummy", "recognizer.cuda.cuda", "imgs.cuda.cuda", "gt_labels.cuda.cuda", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "recognizer.cuda.forward_dummy", "torch.no_grad", "recognizer.cuda.", "recognizer.cuda.forward_dummy", "torch.min", "torch.max", "torch.no_grad", "recognizer.cuda.", "recognizer.cuda.forward_dummy", "torch.min", "torch.max", "recognizer.cuda.", "recognizer.cuda."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy"], ["def", "test_i3d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'i3d/i3d_r50_32x2x1_100e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained2d'", "]", "=", "False", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "8", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "recognizer", "=", "recognizer", ".", "cuda", "(", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "gt_labels", "=", "gt_labels", ".", "cuda", "(", ")", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                    ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n", "# Test forward dummy", "\n", "", "recognizer", ".", "forward_dummy", "(", "imgs", ",", "softmax", "=", "False", ")", "\n", "res", "=", "recognizer", ".", "forward_dummy", "(", "imgs", ",", "softmax", "=", "True", ")", "[", "0", "]", "\n", "assert", "torch", ".", "min", "(", "res", ")", ">=", "0", "\n", "assert", "torch", ".", "max", "(", "res", ")", "<=", "1", "\n", "\n", "", "", "else", ":", "\n", "        ", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n", "# Test forward dummy", "\n", "", "recognizer", ".", "forward_dummy", "(", "imgs", ",", "softmax", "=", "False", ")", "\n", "res", "=", "recognizer", ".", "forward_dummy", "(", "imgs", ",", "softmax", "=", "True", ")", "[", "0", "]", "\n", "assert", "torch", ".", "min", "(", "res", ")", ">=", "0", "\n", "assert", "torch", ".", "max", "(", "res", ")", "<=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer3d.test_r2plus1d": [[68, 116], ["base.get_recognizer_cfg", "dict", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "torch.cuda.is_available", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "recognizer.cuda.cuda", "imgs.cuda.cuda", "gt_labels.cuda.cuda", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "torch.no_grad", "recognizer.cuda.", "torch.no_grad", "recognizer.cuda.", "recognizer.cuda.", "recognizer.cuda."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs"], ["", "", "def", "test_r2plus1d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'r2plus1d/r2plus1d_r34_8x8x1_180e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained2d'", "]", "=", "False", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'norm_cfg'", "]", "=", "dict", "(", "type", "=", "'BN3d'", ")", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "8", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "recognizer", "=", "recognizer", ".", "cuda", "(", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "gt_labels", "=", "gt_labels", ".", "cuda", "(", ")", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                    ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "", "", "", "else", ":", "\n", "        ", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer3d.test_slowfast": [[118, 171], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "torch.cuda.is_available", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "mmaction.models.build_recognizer", "recognizer.cuda.cuda", "imgs.cuda.cuda", "gt_labels.cuda.cuda", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "torch.no_grad", "recognizer.cuda.", "torch.no_grad", "torch.no_grad", "recognizer.cuda.", "recognizer.cuda.", "recognizer.cuda.", "recognizer.cuda."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["", "", "", "def", "test_slowfast", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'slowfast/slowfast_r50_4x16x1_256e_kinetics400_rgb.py'", ")", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "16", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "recognizer", "=", "recognizer", ".", "cuda", "(", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "gt_labels", "=", "gt_labels", ".", "cuda", "(", ")", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                    ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "", "", "", "else", ":", "\n", "        ", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n", "# Test the feature max_testing_views", "\n", "", "config", ".", "model", ".", "test_cfg", "[", "'max_testing_views'", "]", "=", "1", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer3d.test_csn": [[173, 220], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "torch.cuda.is_available", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "recognizer.cuda.cuda", "imgs.cuda.cuda", "gt_labels.cuda.cuda", "recognizer.cuda.", "isinstance", "recognizer.cuda.", "torch.no_grad", "recognizer.cuda.", "torch.no_grad", "recognizer.cuda.", "recognizer.cuda.", "recognizer.cuda."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs"], ["", "", "", "", "def", "test_csn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'csn/ircsn_ig65m_pretrained_r152_32x2x1_58e_kinetics400_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained2d'", "]", "=", "False", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "8", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "recognizer", "=", "recognizer", ".", "cuda", "(", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "gt_labels", "=", "gt_labels", ".", "cuda", "(", ")", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                    ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "", "", "", "else", ":", "\n", "        ", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "                ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer3d.test_tpn": [[222, 257], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "mmaction.models.build_recognizer.", "torch.no_grad", "mmaction.models.build_recognizer.", "torch.no_grad", "mmaction.models.build_recognizer", "hasattr", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer"], ["", "", "", "def", "test_tpn", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "\n", "'tpn/tpn_slowonly_r50_8x8x1_150e_kinetics_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "8", ",", "3", ",", "1", ",", "32", ",", "32", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "\n", "# Test dummy forward", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "_recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "if", "hasattr", "(", "_recognizer", ",", "'forward_dummy'", ")", ":", "\n", "            ", "_recognizer", ".", "forward", "=", "_recognizer", ".", "forward_dummy", "\n", "", "for", "one_img", "in", "img_list", ":", "\n", "            ", "_recognizer", "(", "one_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_recognizers.test_recognizer3d.test_c3d": [[259, 284], ["base.get_recognizer_cfg", "mmaction.models.build_recognizer", "base.generate_recognizer_demo_inputs", "mmaction.models.build_recognizer.", "isinstance", "mmaction.models.build_recognizer.", "torch.no_grad", "mmaction.models.build_recognizer.", "mmaction.models.build_recognizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_recognizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_recognizer_demo_inputs"], ["", "", "", "def", "test_c3d", "(", ")", ":", "\n", "    ", "config", "=", "get_recognizer_cfg", "(", "'c3d/c3d_sports1m_16x1x1_45e_ucf101_rgb.py'", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "3", ",", "16", ",", "112", ",", "112", ")", "\n", "demo_inputs", "=", "generate_recognizer_demo_inputs", "(", "input_shape", ",", "'3D'", ")", "\n", "\n", "imgs", "=", "demo_inputs", "[", "'imgs'", "]", "\n", "gt_labels", "=", "demo_inputs", "[", "'gt_labels'", "]", "\n", "\n", "losses", "=", "recognizer", "(", "imgs", ",", "gt_labels", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_list", "=", "[", "img", "[", "None", ",", ":", "]", "for", "img", "in", "imgs", "]", "\n", "for", "one_img", "in", "img_list", ":", "\n", "            ", "recognizer", "(", "one_img", ",", "None", ",", "return_loss", "=", "False", ")", "\n", "\n", "# Test forward gradcam", "\n", "", "", "recognizer", "(", "imgs", ",", "gradcam", "=", "True", ")", "\n", "for", "one_img", "in", "img_list", ":", "\n", "        ", "recognizer", "(", "one_img", ",", "gradcam", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_detectors.test_detectors.test_ava_detector": [[13, 42], ["pytest.mark.skipif", "base.get_detector_cfg", "build_detector", "torch.cuda.is_available", "base.generate_detector_demo_inputs", "base.generate_detector_demo_inputs", "detector.cuda.", "isinstance", "base.generate_detector_demo_inputs", "base.generate_detector_demo_inputs", "detector.cuda.cuda", "detector.cuda.", "isinstance", "torch.no_grad", "detector.cuda.", "torch.no_grad", "detector.cuda."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_detector_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_detector_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_detector_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_detector_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_detector_demo_inputs"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "not", "mmdet_imported", ",", "reason", "=", "'requires mmdet'", ")", "\n", "def", "test_ava_detector", "(", ")", ":", "\n", "    ", "config", "=", "get_detector_cfg", "(", "'ava/slowonly_kinetics_pretrained_r50_'", "\n", "'4x16x1_20e_ava_rgb.py'", ")", "\n", "detector", "=", "build_detector", "(", "config", ".", "model", ")", "\n", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "train_demo_inputs", "=", "generate_detector_demo_inputs", "(", "\n", "train", "=", "True", ",", "device", "=", "'cuda'", ")", "\n", "test_demo_inputs", "=", "generate_detector_demo_inputs", "(", "\n", "train", "=", "False", ",", "device", "=", "'cuda'", ")", "\n", "detector", "=", "detector", ".", "cuda", "(", ")", "\n", "\n", "losses", "=", "detector", "(", "**", "train_demo_inputs", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", "=", "detector", "(", "**", "test_demo_inputs", ",", "return_loss", "=", "False", ")", "\n", "", "", "", "else", ":", "\n", "        ", "train_demo_inputs", "=", "generate_detector_demo_inputs", "(", "train", "=", "True", ")", "\n", "test_demo_inputs", "=", "generate_detector_demo_inputs", "(", "train", "=", "False", ")", "\n", "losses", "=", "detector", "(", "**", "train_demo_inputs", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "_", "=", "detector", "(", "**", "test_demo_inputs", ",", "return_loss", "=", "False", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.forward": [[13, 15], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.test_base_head": [[17, 73], ["test_base_head.ExampleHead", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "ExampleHead.loss", "test_base_head.ExampleHead", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "ExampleHead.loss", "mmcv.utils.assert_dict_has_keys", "torch.rand", "torch.rand", "torch.LongTensor", "torch.LongTensor", "torch.one_hot().squeeze", "ExampleHead.loss", "torch.rand", "torch.rand", "torch.LongTensor", "torch.LongTensor", "torch.one_hot().squeeze", "ExampleHead.loss", "test_base_head.ExampleHead", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "ExampleHead.loss", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "ExampleHead.loss", "dict", "head.loss.keys", "head.loss.get", "dict", "head.loss.get", "head.loss.keys", "head.loss.get", "head.loss.keys", "head.loss.get", "dict", "head.loss.keys", "head.loss.get", "head.loss.keys", "head.loss.get", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.one_hot", "torch.one_hot", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.heads.bbox_head.BBoxHeadAVA.loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.one_hot", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.blending_utils.one_hot"], ["", "", "def", "test_base_head", "(", ")", ":", "\n", "    ", "head", "=", "ExampleHead", "(", "3", ",", "400", ",", "dict", "(", "type", "=", "'CrossEntropyLoss'", ")", ")", "\n", "\n", "cls_scores", "=", "torch", ".", "rand", "(", "(", "3", ",", "4", ")", ")", "\n", "# When truth is non-empty then cls loss should be nonzero for random inputs", "\n", "gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "2", "]", "*", "3", ")", ".", "squeeze", "(", ")", "\n", "losses", "=", "head", ".", "loss", "(", "cls_scores", ",", "gt_labels", ")", "\n", "assert", "'loss_cls'", "in", "losses", ".", "keys", "(", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ")", ">", "0", ",", "'cls loss should be non-zero'", "\n", "\n", "head", "=", "ExampleHead", "(", "3", ",", "400", ",", "dict", "(", "type", "=", "'CrossEntropyLoss'", ",", "loss_weight", "=", "2.0", ")", ")", "\n", "\n", "cls_scores", "=", "torch", ".", "rand", "(", "(", "3", ",", "4", ")", ")", "\n", "# When truth is non-empty then cls loss should be nonzero for random inputs", "\n", "gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "2", "]", "*", "3", ")", ".", "squeeze", "(", ")", "\n", "losses", "=", "head", ".", "loss", "(", "cls_scores", ",", "gt_labels", ")", "\n", "assert_dict_has_keys", "(", "losses", ",", "[", "'loss_cls'", "]", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ")", ">", "0", ",", "'cls loss should be non-zero'", "\n", "\n", "# Test Soft label with batch size > 1", "\n", "cls_scores", "=", "torch", ".", "rand", "(", "(", "3", ",", "3", ")", ")", "\n", "gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "[", "2", "]", "*", "3", "]", ")", "\n", "gt_one_hot_labels", "=", "F", ".", "one_hot", "(", "gt_labels", ",", "num_classes", "=", "3", ")", ".", "squeeze", "(", ")", "\n", "losses", "=", "head", ".", "loss", "(", "cls_scores", ",", "gt_one_hot_labels", ")", "\n", "assert", "'loss_cls'", "in", "losses", ".", "keys", "(", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ")", ">", "0", ",", "'cls loss should be non-zero'", "\n", "\n", "# Test Soft label with batch size = 1", "\n", "cls_scores", "=", "torch", ".", "rand", "(", "(", "1", ",", "3", ")", ")", "\n", "gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "2", "]", ")", "\n", "gt_one_hot_labels", "=", "F", ".", "one_hot", "(", "gt_labels", ",", "num_classes", "=", "3", ")", ".", "squeeze", "(", ")", "\n", "losses", "=", "head", ".", "loss", "(", "cls_scores", ",", "gt_one_hot_labels", ")", "\n", "assert", "'loss_cls'", "in", "losses", ".", "keys", "(", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ")", ">", "0", ",", "'cls loss should be non-zero'", "\n", "\n", "# test multi-class & label smoothing", "\n", "head", "=", "ExampleHead", "(", "\n", "3", ",", "\n", "400", ",", "\n", "dict", "(", "type", "=", "'BCELossWithLogits'", ")", ",", "\n", "multi_class", "=", "True", ",", "\n", "label_smooth_eps", "=", "0.1", ")", "\n", "\n", "# batch size > 1", "\n", "cls_scores", "=", "torch", ".", "rand", "(", "(", "2", ",", "3", ")", ")", "\n", "gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "[", "1", ",", "0", ",", "1", "]", ",", "[", "0", ",", "1", ",", "0", "]", "]", ")", ".", "squeeze", "(", ")", "\n", "losses", "=", "head", ".", "loss", "(", "cls_scores", ",", "gt_labels", ")", "\n", "assert", "'loss_cls'", "in", "losses", ".", "keys", "(", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ")", ">", "0", ",", "'cls loss should be non-zero'", "\n", "\n", "# batch size = 1", "\n", "cls_scores", "=", "torch", ".", "rand", "(", "(", "1", ",", "3", ")", ")", "\n", "gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "[", "1", ",", "0", ",", "1", "]", "]", ")", ".", "squeeze", "(", ")", "\n", "losses", "=", "head", ".", "loss", "(", "cls_scores", ",", "gt_labels", ")", "\n", "assert", "'loss_cls'", "in", "losses", ".", "keys", "(", ")", "\n", "assert", "losses", ".", "get", "(", "'loss_cls'", ")", ">", "0", ",", "'cls loss should be non-zero'", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.__init__": [[10, 18], ["mmaction.models.BaseRecognizer.__init__"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "train_cfg", ",", "test_cfg", ")", ":", "\n", "        ", "super", "(", "BaseRecognizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# reconstruct `__init__()` method in BaseRecognizer to avoid building", "\n", "# backbone and head which are useless to ExampleRecognizer,", "\n", "# since ExampleRecognizer is only used for model-unrelated methods", "\n", "# (like `average_clip`) testing.", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_train": [[19, 21], ["None"], "methods", ["None"], ["", "def", "forward_train", "(", "self", ",", "imgs", ",", "labels", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_test": [[22, 24], ["None"], "methods", ["None"], ["", "def", "forward_test", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.ExampleRecognizer.forward_gradcam": [[25, 27], ["None"], "methods", ["None"], ["", "def", "forward_gradcam", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_recognizers.test_base_recognizer": [[29, 66], ["torch.rand", "torch.rand", "dict", "test_base_recognizers.ExampleRecognizer", "ExampleRecognizer.average_clip", "torch.equal", "torch.equal", "dict", "test_base_recognizers.ExampleRecognizer", "ExampleRecognizer.average_clip", "torch.equal", "torch.equal", "dict", "test_base_recognizers.ExampleRecognizer", "ExampleRecognizer.average_clip", "torch.equal", "torch.equal", "pytest.raises", "dict", "test_base_recognizers.ExampleRecognizer", "ExampleRecognizer.average_clip", "pytest.raises", "dict", "test_base_recognizers.ExampleRecognizer", "ExampleRecognizer.average_clip", "pytest.raises", "test_base_recognizers.ExampleRecognizer", "ExampleRecognizer.", "torch.rand.mean", "torch.softmax().mean", "torch.tensor", "torch.tensor", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.recognizers.base.BaseRecognizer.average_clip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.softmax"], ["", "", "def", "test_base_recognizer", "(", ")", ":", "\n", "    ", "cls_score", "=", "torch", ".", "rand", "(", "5", ",", "400", ")", "\n", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# \"average_clips\" must defined in test_cfg keys", "\n", "        ", "wrong_test_cfg", "=", "dict", "(", "clip", "=", "'score'", ")", "\n", "recognizer", "=", "ExampleRecognizer", "(", "None", ",", "wrong_test_cfg", ")", "\n", "recognizer", ".", "average_clip", "(", "cls_score", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# unsupported average clips type", "\n", "        ", "wrong_test_cfg", "=", "dict", "(", "average_clips", "=", "'softmax'", ")", "\n", "recognizer", "=", "ExampleRecognizer", "(", "None", ",", "wrong_test_cfg", ")", "\n", "recognizer", ".", "average_clip", "(", "cls_score", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# Label should not be None", "\n", "        ", "recognizer", "=", "ExampleRecognizer", "(", "None", ",", "None", ")", "\n", "recognizer", "(", "torch", ".", "tensor", "(", "0", ")", ")", "\n", "\n", "# average_clips=None", "\n", "", "test_cfg", "=", "dict", "(", "average_clips", "=", "None", ")", "\n", "recognizer", "=", "ExampleRecognizer", "(", "None", ",", "test_cfg", ")", "\n", "score", "=", "recognizer", ".", "average_clip", "(", "cls_score", ",", "num_segs", "=", "5", ")", "\n", "assert", "torch", ".", "equal", "(", "score", ",", "cls_score", ")", "\n", "\n", "# average_clips='score'", "\n", "test_cfg", "=", "dict", "(", "average_clips", "=", "'score'", ")", "\n", "recognizer", "=", "ExampleRecognizer", "(", "None", ",", "test_cfg", ")", "\n", "score", "=", "recognizer", ".", "average_clip", "(", "cls_score", ",", "num_segs", "=", "5", ")", "\n", "assert", "torch", ".", "equal", "(", "score", ",", "cls_score", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "# average_clips='prob'", "\n", "test_cfg", "=", "dict", "(", "average_clips", "=", "'prob'", ")", "\n", "recognizer", "=", "ExampleRecognizer", "(", "None", ",", "test_cfg", ")", "\n", "score", "=", "recognizer", ".", "average_clip", "(", "cls_score", ",", "num_segs", "=", "5", ")", "\n", "assert", "torch", ".", "equal", "(", "score", ",", "\n", "F", ".", "softmax", "(", "cls_score", ",", "dim", "=", "1", ")", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_resnet.test_resnet_backbone": [[10, 128], ["mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet.train", "base.check_norm_state", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet.train", "base.check_norm_state", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet.train", "mmaction.models.ResNet.conv1.modules", "range", "mmaction.models.ResNet", "mmaction.models.ResNet.train", "mmaction.models.ResNet.modules", "base.generate_backbone_demo_inputs", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet.train", "mmaction.models.ResNet.", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet.train", "mmaction.models.ResNet.", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "mmaction.models.ResNet.train", "mmaction.models.ResNet.", "mmaction.models.ResNet", "base.generate_backbone_demo_inputs", "mmaction.models.ResNet.", "mmaction.models.ResNet", "base.generate_backbone_demo_inputs", "mmaction.models.ResNet.", "pytest.raises", "mmaction.models.ResNet", "pytest.raises", "mmaction.models.ResNet", "pytest.raises", "mmaction.models.ResNet", "pytest.raises", "mmaction.models.ResNet", "pytest.raises", "mmaction.models.ResNet", "mmaction.models.ResNet.init_weights", "pytest.raises", "mmaction.models.ResNet", "pytest.raises", "mmaction.models.ResNet", "mmaction.models.ResNet.modules", "mmaction.models.ResNet.modules", "getattr.parameters", "getattr", "getattr.modules", "getattr.parameters", "isinstance", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "test_resnet_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test resnet backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# ResNet depth should be in [18, 34, 50, 101, 152]", "\n", "        ", "ResNet", "(", "20", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In ResNet: 1 <= num_stages <= 4", "\n", "        ", "ResNet", "(", "50", ",", "num_stages", "=", "0", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In ResNet: 1 <= num_stages <= 4", "\n", "        ", "ResNet", "(", "50", ",", "num_stages", "=", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# len(strides) == len(dilations) == num_stages", "\n", "        ", "ResNet", "(", "50", ",", "strides", "=", "(", "1", ",", ")", ",", "dilations", "=", "(", "1", ",", "1", ")", ",", "num_stages", "=", "3", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# pretrain must be a str", "\n", "        ", "resnet50", "=", "ResNet", "(", "50", ",", "pretrained", "=", "0", ")", "\n", "resnet50", ".", "init_weights", "(", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# style must be in ['pytorch', 'caffe']", "\n", "        ", "ResNet", "(", "18", ",", "style", "=", "'tensorflow'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# assert not with_cp", "\n", "        ", "ResNet", "(", "18", ",", "with_cp", "=", "True", ")", "\n", "\n", "# resnet with depth 18, norm_eval False, initial weights", "\n", "", "resnet18", "=", "ResNet", "(", "18", ")", "\n", "resnet18", ".", "init_weights", "(", ")", "\n", "\n", "# resnet with depth 50, norm_eval True", "\n", "resnet50", "=", "ResNet", "(", "50", ",", "norm_eval", "=", "True", ")", "\n", "resnet50", ".", "init_weights", "(", ")", "\n", "resnet50", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet50", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# resnet with depth 50, norm_eval True, pretrained", "\n", "resnet50_pretrain", "=", "ResNet", "(", "\n", "pretrained", "=", "'torchvision://resnet50'", ",", "depth", "=", "50", ",", "norm_eval", "=", "True", ")", "\n", "resnet50_pretrain", ".", "init_weights", "(", ")", "\n", "resnet50_pretrain", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet50_pretrain", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# resnet with depth 50, norm_eval True, frozen_stages 1", "\n", "frozen_stages", "=", "1", "\n", "resnet50_frozen", "=", "ResNet", "(", "50", ",", "frozen_stages", "=", "frozen_stages", ")", "\n", "resnet50_frozen", ".", "init_weights", "(", ")", "\n", "resnet50_frozen", ".", "train", "(", ")", "\n", "assert", "resnet50_frozen", ".", "conv1", ".", "bn", ".", "training", "is", "False", "\n", "for", "layer", "in", "resnet50_frozen", ".", "conv1", ".", "modules", "(", ")", ":", "\n", "        ", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet50_frozen", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "\n", "# resnet with depth 50, partial batchnorm", "\n", "", "", "resnet_pbn", "=", "ResNet", "(", "50", ",", "partial_bn", "=", "True", ")", "\n", "resnet_pbn", ".", "train", "(", ")", "\n", "count_bn", "=", "0", "\n", "for", "m", "in", "resnet_pbn", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "count_bn", "+=", "1", "\n", "if", "count_bn", ">=", "2", ":", "\n", "                ", "assert", "m", ".", "weight", ".", "requires_grad", "is", "False", "\n", "assert", "m", ".", "bias", ".", "requires_grad", "is", "False", "\n", "assert", "m", ".", "training", "is", "False", "\n", "", "else", ":", "\n", "                ", "assert", "m", ".", "weight", ".", "requires_grad", "is", "True", "\n", "assert", "m", ".", "bias", ".", "requires_grad", "is", "True", "\n", "assert", "m", ".", "training", "is", "True", "\n", "\n", "", "", "", "input_shape", "=", "(", "1", ",", "3", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "# resnet with depth 18 inference", "\n", "resnet18", "=", "ResNet", "(", "18", ",", "norm_eval", "=", "False", ")", "\n", "resnet18", ".", "init_weights", "(", ")", "\n", "resnet18", ".", "train", "(", ")", "\n", "feat", "=", "resnet18", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet with depth 50 inference", "\n", "resnet50", "=", "ResNet", "(", "50", ",", "norm_eval", "=", "False", ")", "\n", "resnet50", ".", "init_weights", "(", ")", "\n", "resnet50", ".", "train", "(", ")", "\n", "feat", "=", "resnet50", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet with depth 50 in caffe style inference", "\n", "resnet50_caffe", "=", "ResNet", "(", "50", ",", "style", "=", "'caffe'", ",", "norm_eval", "=", "False", ")", "\n", "resnet50_caffe", ".", "init_weights", "(", ")", "\n", "resnet50_caffe", ".", "train", "(", ")", "\n", "feat", "=", "resnet50_caffe", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "resnet50_flow", "=", "ResNet", "(", "\n", "depth", "=", "50", ",", "pretrained", "=", "'torchvision://resnet50'", ",", "in_channels", "=", "10", ")", "\n", "input_shape", "=", "(", "1", ",", "10", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "feat", "=", "resnet50_flow", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "\n", "resnet50", "=", "ResNet", "(", "\n", "depth", "=", "50", ",", "pretrained", "=", "'torchvision://resnet50'", ",", "in_channels", "=", "3", ")", "\n", "input_shape", "=", "(", "1", ",", "3", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "feat", "=", "resnet50", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "2", ",", "2", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_resnet3d.test_resnet3d_backbone": [[10, 297], ["mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.train", "base.check_norm_state", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.train", "base.check_norm_state", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.train", "base.check_norm_state", "_load_checkpoint", "mmaction.models.ResNet3d.named_modules", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.train", "base.check_norm_state", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.train", "base.check_norm_state", "mmaction.models.ResNet3d", "resnet3d_34_frozen.cuda.init_weights", "resnet3d_34_frozen.cuda.train", "resnet3d_34_frozen.cuda.conv1.parameters", "range", "resnet3d_34_frozen.cuda.modules", "mmaction.models.ResNet3d", "resnet3d_50_frozen.cuda.init_weights", "resnet3d_50_frozen.cuda.train", "resnet3d_50_frozen.cuda.conv1.parameters", "range", "resnet3d_50_frozen.cuda.modules", "base.generate_backbone_demo_inputs", "base.generate_backbone_demo_inputs", "mmaction.models.ResNet3d", "resnet3d_50_caffe.cuda.init_weights", "resnet3d_50_caffe.cuda.train", "mmaction.models.ResNet3d", "resnet3d_34_caffe.cuda.init_weights", "resnet3d_34_caffe.cuda.train", "mmaction.models.ResNet3d", "resnet3d_50_1x1x1.cuda.init_weights", "resnet3d_50_1x1x1.cuda.train", "mmaction.models.ResNet3d", "resnet3d_34_1x1x1.cuda.init_weights", "resnet3d_34_1x1x1.cuda.train", "dict", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.", "pytest.raises", "mmaction.models.ResNet3d", "pytest.raises", "mmaction.models.ResNet3d", "pytest.raises", "mmaction.models.ResNet3d", "pytest.raises", "mmaction.models.ResNet3d", "pytest.raises", "mmaction.models.ResNet3d", "pytest.raises", "mmaction.models.ResNet3d", "pytest.raises", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "pytest.raises", "mmaction.models.ResNet3d", "mmaction.models.ResNet3d.init_weights", "mmaction.models.ResNet3d.modules", "mmaction.models.ResNet3d.modules", "mmaction.models.ResNet3d.modules", "mmaction.models.ResNet3d.modules", "mmaction.models.ResNet3d.modules", "getattr", "getattr.modules", "getattr.parameters", "hasattr", "getattr", "getattr.modules", "getattr.parameters", "hasattr", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_34_frozen.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_50_frozen.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_50_caffe.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_34_caffe.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_50_1x1x1.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "resnet3d_34_1x1x1.cuda.", "getattr", "enumerate", "torch.Size", "torch.Size", "len", "isinstance", "chkp_2d[].unsqueeze().expand_as", "chkp_2d[].unsqueeze().expand_as", "isinstance", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "isinstance", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "resnet3d_34_frozen.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_34_frozen.cuda.", "torch.Size", "torch.Size", "resnet3d_50_frozen.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_50_frozen.cuda.", "torch.Size", "torch.Size", "resnet3d_50_caffe.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_50_caffe.cuda.", "torch.Size", "torch.Size", "resnet3d_34_caffe.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_34_caffe.cuda.", "torch.Size", "torch.Size", "resnet3d_50_1x1x1.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_50_1x1x1.cuda.", "torch.Size", "torch.Size", "resnet3d_34_1x1x1.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "resnet3d_34_1x1x1.cuda.", "torch.Size", "torch.Size", "dict", "name.split", "name.split", "name.split", "name.split", "name.replace().replace", "torch.equal", "torch.equal", "isinstance", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "hasattr", "getattr", "getattr", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "chkp_2d[].unsqueeze", "chkp_2d[].unsqueeze", "name.replace", "name.split", "conv2d_weight.data.unsqueeze().expand_as", "getattr", "getattr", "conv2d_weight.data.unsqueeze"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "test_resnet3d_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test resnet3d backbone.\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In ResNet3d: 1 <= num_stages <= 4", "\n", "        ", "ResNet3d", "(", "34", ",", "None", ",", "num_stages", "=", "0", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In ResNet3d: 1 <= num_stages <= 4", "\n", "        ", "ResNet3d", "(", "34", ",", "None", ",", "num_stages", "=", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In ResNet3d: 1 <= num_stages <= 4", "\n", "        ", "ResNet3d", "(", "50", ",", "None", ",", "num_stages", "=", "0", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# In ResNet3d: 1 <= num_stages <= 4", "\n", "        ", "ResNet3d", "(", "50", ",", "None", ",", "num_stages", "=", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# len(spatial_strides) == len(temporal_strides)", "\n", "# == len(dilations) == num_stages", "\n", "        ", "ResNet3d", "(", "\n", "50", ",", "\n", "None", ",", "\n", "spatial_strides", "=", "(", "1", ",", ")", ",", "\n", "temporal_strides", "=", "(", "1", ",", "1", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "num_stages", "=", "4", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# len(spatial_strides) == len(temporal_strides)", "\n", "# == len(dilations) == num_stages", "\n", "        ", "ResNet3d", "(", "\n", "34", ",", "\n", "None", ",", "\n", "spatial_strides", "=", "(", "1", ",", ")", ",", "\n", "temporal_strides", "=", "(", "1", ",", "1", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "num_stages", "=", "4", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# pretrain must be str or None.", "\n", "        ", "resnet3d_34", "=", "ResNet3d", "(", "34", ",", "[", "'resnet'", ",", "'bninception'", "]", ")", "\n", "resnet3d_34", ".", "init_weights", "(", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# pretrain must be str or None.", "\n", "        ", "resnet3d_50", "=", "ResNet3d", "(", "50", ",", "[", "'resnet'", ",", "'bninception'", "]", ")", "\n", "resnet3d_50", ".", "init_weights", "(", ")", "\n", "\n", "# resnet3d with depth 34, no pretrained, norm_eval True", "\n", "", "resnet3d_34", "=", "ResNet3d", "(", "34", ",", "None", ",", "pretrained2d", "=", "False", ",", "norm_eval", "=", "True", ")", "\n", "resnet3d_34", ".", "init_weights", "(", ")", "\n", "resnet3d_34", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet3d_34", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# resnet3d with depth 50, no pretrained, norm_eval True", "\n", "resnet3d_50", "=", "ResNet3d", "(", "50", ",", "None", ",", "pretrained2d", "=", "False", ",", "norm_eval", "=", "True", ")", "\n", "resnet3d_50", ".", "init_weights", "(", ")", "\n", "resnet3d_50", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet3d_50", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# resnet3d with depth 50, pretrained2d, norm_eval True", "\n", "resnet3d_50_pretrain", "=", "ResNet3d", "(", "\n", "50", ",", "'torchvision://resnet50'", ",", "norm_eval", "=", "True", ")", "\n", "resnet3d_50_pretrain", ".", "init_weights", "(", ")", "\n", "resnet3d_50_pretrain", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet3d_50_pretrain", ".", "modules", "(", ")", ",", "False", ")", "\n", "from", "mmcv", ".", "runner", "import", "_load_checkpoint", "\n", "chkp_2d", "=", "_load_checkpoint", "(", "'torchvision://resnet50'", ")", "\n", "for", "name", ",", "module", "in", "resnet3d_50_pretrain", ".", "named_modules", "(", ")", ":", "\n", "        ", "if", "len", "(", "name", ".", "split", "(", "'.'", ")", ")", "==", "4", ":", "\n", "# layer.block.module.submodule", "\n", "            ", "prefix", "=", "name", ".", "split", "(", "'.'", ")", "[", ":", "2", "]", "\n", "module_type", "=", "name", ".", "split", "(", "'.'", ")", "[", "2", "]", "\n", "submodule_type", "=", "name", ".", "split", "(", "'.'", ")", "[", "3", "]", "\n", "\n", "if", "module_type", "==", "'downsample'", ":", "\n", "                ", "name2d", "=", "name", ".", "replace", "(", "'conv'", ",", "'0'", ")", ".", "replace", "(", "'bn'", ",", "'1'", ")", "\n", "", "else", ":", "\n", "                ", "layer_id", "=", "name", ".", "split", "(", "'.'", ")", "[", "2", "]", "[", "-", "1", "]", "\n", "name2d", "=", "prefix", "[", "0", "]", "+", "'.'", "+", "prefix", "[", "1", "]", "+", "'.'", "+", "submodule_type", "+", "layer_id", "\n", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "conv2d_weight", "=", "chkp_2d", "[", "name2d", "+", "'.weight'", "]", "\n", "conv3d_weight", "=", "getattr", "(", "module", ",", "'weight'", ")", ".", "data", "\n", "assert", "torch", ".", "equal", "(", "\n", "conv3d_weight", ",", "\n", "conv2d_weight", ".", "data", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "conv3d_weight", ")", "/", "\n", "conv3d_weight", ".", "shape", "[", "2", "]", ")", "\n", "if", "getattr", "(", "module", ",", "'bias'", ")", "is", "not", "None", ":", "\n", "                    ", "conv2d_bias", "=", "chkp_2d", "[", "name2d", "+", "'.bias'", "]", "\n", "conv3d_bias", "=", "getattr", "(", "module", ",", "'bias'", ")", ".", "data", "\n", "assert", "torch", ".", "equal", "(", "conv2d_bias", ",", "conv3d_bias", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "for", "pname", "in", "[", "'weight'", ",", "'bias'", ",", "'running_mean'", ",", "'running_var'", "]", ":", "\n", "                    ", "param_2d", "=", "chkp_2d", "[", "name2d", "+", "'.'", "+", "pname", "]", "\n", "param_3d", "=", "getattr", "(", "module", ",", "pname", ")", ".", "data", "\n", "", "assert", "torch", ".", "equal", "(", "param_2d", ",", "param_3d", ")", "\n", "\n", "", "", "", "conv3d", "=", "resnet3d_50_pretrain", ".", "conv1", ".", "conv", "\n", "assert", "torch", ".", "equal", "(", "\n", "conv3d", ".", "weight", ",", "\n", "chkp_2d", "[", "'conv1.weight'", "]", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "conv3d", ".", "weight", ")", "/", "\n", "conv3d", ".", "weight", ".", "shape", "[", "2", "]", ")", "\n", "conv3d", "=", "resnet3d_50_pretrain", ".", "layer3", "[", "2", "]", ".", "conv2", ".", "conv", "\n", "assert", "torch", ".", "equal", "(", "\n", "conv3d", ".", "weight", ",", "chkp_2d", "[", "'layer3.2.conv2.weight'", "]", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "conv3d", ".", "weight", ")", "/", "conv3d", ".", "weight", ".", "shape", "[", "2", "]", ")", "\n", "\n", "# resnet3d with depth 34, no pretrained, norm_eval False", "\n", "resnet3d_34_no_bn_eval", "=", "ResNet3d", "(", "\n", "34", ",", "None", ",", "pretrained2d", "=", "False", ",", "norm_eval", "=", "False", ")", "\n", "resnet3d_34_no_bn_eval", ".", "init_weights", "(", ")", "\n", "resnet3d_34_no_bn_eval", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet3d_34_no_bn_eval", ".", "modules", "(", ")", ",", "True", ")", "\n", "\n", "# resnet3d with depth 50, no pretrained, norm_eval False", "\n", "resnet3d_50_no_bn_eval", "=", "ResNet3d", "(", "\n", "50", ",", "None", ",", "pretrained2d", "=", "False", ",", "norm_eval", "=", "False", ")", "\n", "resnet3d_50_no_bn_eval", ".", "init_weights", "(", ")", "\n", "resnet3d_50_no_bn_eval", ".", "train", "(", ")", "\n", "assert", "check_norm_state", "(", "resnet3d_50_no_bn_eval", ".", "modules", "(", ")", ",", "True", ")", "\n", "\n", "# resnet3d with depth 34, no pretrained, frozen_stages, norm_eval False", "\n", "frozen_stages", "=", "1", "\n", "resnet3d_34_frozen", "=", "ResNet3d", "(", "\n", "34", ",", "None", ",", "pretrained2d", "=", "False", ",", "frozen_stages", "=", "frozen_stages", ")", "\n", "resnet3d_34_frozen", ".", "init_weights", "(", ")", "\n", "resnet3d_34_frozen", ".", "train", "(", ")", "\n", "assert", "resnet3d_34_frozen", ".", "conv1", ".", "bn", ".", "training", "is", "False", "\n", "for", "param", "in", "resnet3d_34_frozen", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "        ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet3d_34_frozen", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "# test zero_init_residual", "\n", "", "", "for", "m", "in", "resnet3d_34_frozen", ".", "modules", "(", ")", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'conv2'", ")", ":", "\n", "            ", "assert", "torch", ".", "equal", "(", "m", ".", "conv2", ".", "bn", ".", "weight", ",", "\n", "torch", ".", "zeros_like", "(", "m", ".", "conv2", ".", "bn", ".", "weight", ")", ")", "\n", "assert", "torch", ".", "equal", "(", "m", ".", "conv2", ".", "bn", ".", "bias", ",", "\n", "torch", ".", "zeros_like", "(", "m", ".", "conv2", ".", "bn", ".", "bias", ")", ")", "\n", "\n", "# resnet3d with depth 50, no pretrained, frozen_stages, norm_eval False", "\n", "", "", "frozen_stages", "=", "1", "\n", "resnet3d_50_frozen", "=", "ResNet3d", "(", "\n", "50", ",", "None", ",", "pretrained2d", "=", "False", ",", "frozen_stages", "=", "frozen_stages", ")", "\n", "resnet3d_50_frozen", ".", "init_weights", "(", ")", "\n", "resnet3d_50_frozen", ".", "train", "(", ")", "\n", "assert", "resnet3d_50_frozen", ".", "conv1", ".", "bn", ".", "training", "is", "False", "\n", "for", "param", "in", "resnet3d_50_frozen", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "        ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet3d_50_frozen", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "# test zero_init_residual", "\n", "", "", "for", "m", "in", "resnet3d_50_frozen", ".", "modules", "(", ")", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'conv3'", ")", ":", "\n", "            ", "assert", "torch", ".", "equal", "(", "m", ".", "conv3", ".", "bn", ".", "weight", ",", "\n", "torch", ".", "zeros_like", "(", "m", ".", "conv3", ".", "bn", ".", "weight", ")", ")", "\n", "assert", "torch", ".", "equal", "(", "m", ".", "conv3", ".", "bn", ".", "bias", ",", "\n", "torch", ".", "zeros_like", "(", "m", ".", "conv3", ".", "bn", ".", "bias", ")", ")", "\n", "\n", "# resnet3d frozen with depth 34 inference", "\n", "", "", "input_shape", "=", "(", "1", ",", "3", ",", "6", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_34_frozen", "=", "resnet3d_34_frozen", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_34_frozen", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_34_frozen", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet3d with depth 50 inference", "\n", "", "input_shape", "=", "(", "1", ",", "3", ",", "6", ",", "64", ",", "64", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_50_frozen", "=", "resnet3d_50_frozen", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_50_frozen", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_50_frozen", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet3d with depth 50 in caffe style inference", "\n", "", "resnet3d_50_caffe", "=", "ResNet3d", "(", "50", ",", "None", ",", "pretrained2d", "=", "False", ",", "style", "=", "'caffe'", ")", "\n", "resnet3d_50_caffe", ".", "init_weights", "(", ")", "\n", "resnet3d_50_caffe", ".", "train", "(", ")", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_50_caffe", "=", "resnet3d_50_caffe", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_50_caffe", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_50_caffe", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet3d with depth 34 in caffe style inference", "\n", "", "resnet3d_34_caffe", "=", "ResNet3d", "(", "34", ",", "None", ",", "pretrained2d", "=", "False", ",", "style", "=", "'caffe'", ")", "\n", "resnet3d_34_caffe", ".", "init_weights", "(", ")", "\n", "resnet3d_34_caffe", ".", "train", "(", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_34_caffe", "=", "resnet3d_34_caffe", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_34_caffe", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_34_caffe", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet3d with depth with 3x3x3 inflate_style inference", "\n", "", "resnet3d_50_1x1x1", "=", "ResNet3d", "(", "\n", "50", ",", "None", ",", "pretrained2d", "=", "False", ",", "inflate_style", "=", "'3x3x3'", ")", "\n", "resnet3d_50_1x1x1", ".", "init_weights", "(", ")", "\n", "resnet3d_50_1x1x1", ".", "train", "(", ")", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_50_1x1x1", "=", "resnet3d_50_1x1x1", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_50_1x1x1", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_50_1x1x1", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n", "", "resnet3d_34_1x1x1", "=", "ResNet3d", "(", "\n", "34", ",", "None", ",", "pretrained2d", "=", "False", ",", "inflate_style", "=", "'3x3x3'", ")", "\n", "resnet3d_34_1x1x1", ".", "init_weights", "(", ")", "\n", "resnet3d_34_1x1x1", ".", "train", "(", ")", "\n", "\n", "# parrots 3dconv is only implemented on gpu", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "resnet3d_34_1x1x1", "=", "resnet3d_34_1x1x1", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "resnet3d_34_1x1x1", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "resnet3d_34_1x1x1", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "512", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n", "# resnet3d with non-local module", "\n", "", "non_local_cfg", "=", "dict", "(", "\n", "sub_sample", "=", "True", ",", "\n", "use_scale", "=", "False", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN3d'", ",", "requires_grad", "=", "True", ")", ",", "\n", "mode", "=", "'embedded_gaussian'", ")", "\n", "non_local", "=", "(", "(", "0", ",", "0", ",", "0", ")", ",", "(", "1", ",", "0", ",", "1", ",", "0", ")", ",", "(", "1", ",", "0", ",", "1", ",", "0", ",", "1", ",", "0", ")", ",", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "resnet3d_nonlocal", "=", "ResNet3d", "(", "\n", "50", ",", "\n", "None", ",", "\n", "pretrained2d", "=", "False", ",", "\n", "non_local", "=", "non_local", ",", "\n", "non_local_cfg", "=", "non_local_cfg", ")", "\n", "resnet3d_nonlocal", ".", "init_weights", "(", ")", "\n", "for", "layer_name", "in", "[", "'layer2'", ",", "'layer3'", "]", ":", "\n", "        ", "layer", "=", "getattr", "(", "resnet3d_nonlocal", ",", "layer_name", ")", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "layer", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "assert", "hasattr", "(", "layer", "[", "i", "]", ",", "'non_local_block'", ")", "\n", "\n", "", "", "", "feat", "=", "resnet3d_nonlocal", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "3", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_resnet3d.test_resnet3d_layer": [[299, 335], ["mmaction.models.ResNet3dLayer", "res_layer.cuda.init_weights", "res_layer.cuda.train", "base.generate_backbone_demo_inputs", "mmaction.models.ResNet3dLayer", "res_layer.cuda.init_weights", "res_layer.cuda.train", "base.generate_backbone_demo_inputs", "pytest.raises", "mmaction.models.ResNet3dLayer", "pytest.raises", "mmaction.models.ResNet3dLayer", "torch.cuda.is_available", "torch.cuda.is_available", "res_layer.cuda.", "torch.cuda.is_available", "torch.cuda.is_available", "res_layer.cuda.", "res_layer.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "res_layer.cuda.", "torch.Size", "torch.Size", "res_layer.cuda.cuda", "base.generate_backbone_demo_inputs.cuda", "res_layer.cuda.", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs"], ["", "def", "test_resnet3d_layer", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "ResNet3dLayer", "(", "22", ",", "None", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "        ", "ResNet3dLayer", "(", "50", ",", "None", ",", "stage", "=", "4", ")", "\n", "\n", "", "res_layer", "=", "ResNet3dLayer", "(", "50", ",", "None", ",", "stage", "=", "3", ",", "norm_eval", "=", "True", ")", "\n", "res_layer", ".", "init_weights", "(", ")", "\n", "res_layer", ".", "train", "(", ")", "\n", "input_shape", "=", "(", "1", ",", "1024", ",", "1", ",", "4", ",", "4", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "res_layer", "=", "res_layer", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "res_layer", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "res_layer", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "\n", "", "res_layer", "=", "ResNet3dLayer", "(", "\n", "50", ",", "'torchvision://resnet50'", ",", "stage", "=", "3", ",", "all_frozen", "=", "True", ")", "\n", "res_layer", ".", "init_weights", "(", ")", "\n", "res_layer", ".", "train", "(", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "if", "torch", ".", "__version__", "==", "'parrots'", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "res_layer", "=", "res_layer", ".", "cuda", "(", ")", "\n", "imgs_gpu", "=", "imgs", ".", "cuda", "(", ")", "\n", "feat", "=", "res_layer", "(", "imgs_gpu", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "feat", "=", "res_layer", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "[", "1", ",", "2048", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_mobilenet_v2.test_mobilenetv2_backbone": [[9, 205], ["base.generate_backbone_demo_inputs", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.conv1.modules", "range", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "base.check_norm_state", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "base.check_norm_state", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.modules", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.modules", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.modules", "mmaction.models.MobileNetV2.init_weights", "mmaction.models.MobileNetV2.train", "mmaction.models.MobileNetV2.", "isinstance", "isinstance", "pytest.raises", "mmaction.models.MobileNetV2", "mmaction.models.MobileNetV2.init_weights", "pytest.raises", "mmaction.models.MobileNetV2", "pytest.raises", "mmaction.models.MobileNetV2", "mod.parameters", "getattr", "getattr.modules", "getattr.parameters", "mmaction.models.MobileNetV2.modules", "mmaction.models.MobileNetV2.modules", "len", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "len", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "len", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "test_mobilenet_v2.test_mobilenetv2_backbone.is_norm"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.generate_backbone_demo_inputs", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.check_norm_state", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.backbones.resnet_audio.ResNetAudio.train", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_common_modules.test_base_head.ExampleHead.init_weights"], ["def", "test_mobilenetv2_backbone", "(", ")", ":", "\n", "    ", "\"\"\"Test MobileNetV2.\n\n    Modified from mmclassification.\n    \"\"\"", "\n", "from", "torch", ".", "nn", ".", "modules", "import", "GroupNorm", "\n", "from", "mmaction", ".", "models", ".", "backbones", ".", "mobilenet_v2", "import", "InvertedResidual", "\n", "\n", "def", "is_norm", "(", "modules", ")", ":", "\n", "        ", "\"\"\"Check if is one of the norms.\"\"\"", "\n", "if", "isinstance", "(", "modules", ",", "(", "GroupNorm", ",", "_BatchNorm", ")", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "def", "is_block", "(", "modules", ")", ":", "\n", "        ", "\"\"\"Check if is ResNet building block.\"\"\"", "\n", "if", "isinstance", "(", "modules", ",", "(", "InvertedResidual", ",", ")", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# pretrained must be a string path", "\n", "        ", "model", "=", "MobileNetV2", "(", "pretrained", "=", "0", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# frozen_stages must in range(1, 8)", "\n", "        ", "MobileNetV2", "(", "frozen_stages", "=", "8", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# tout_indices in range(-1, 8)", "\n", "        ", "MobileNetV2", "(", "out_indices", "=", "[", "8", "]", ")", "\n", "\n", "", "input_shape", "=", "(", "1", ",", "3", ",", "224", ",", "224", ")", "\n", "imgs", "=", "generate_backbone_demo_inputs", "(", "input_shape", ")", "\n", "\n", "# Test MobileNetV2 with first stage frozen", "\n", "frozen_stages", "=", "1", "\n", "model", "=", "MobileNetV2", "(", "frozen_stages", "=", "frozen_stages", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "mod", "in", "model", ".", "conv1", ".", "modules", "(", ")", ":", "\n", "        ", "for", "param", "in", "mod", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "frozen_stages", "+", "1", ")", ":", "\n", "        ", "layer", "=", "getattr", "(", "model", ",", "f'layer{i}'", ")", "\n", "for", "mod", "in", "layer", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "mod", ",", "_BatchNorm", ")", ":", "\n", "                ", "assert", "mod", ".", "training", "is", "False", "\n", "", "", "for", "param", "in", "layer", ".", "parameters", "(", ")", ":", "\n", "            ", "assert", "param", ".", "requires_grad", "is", "False", "\n", "\n", "# Test MobileNetV2 with norm_eval=True", "\n", "", "", "model", "=", "MobileNetV2", "(", "norm_eval", "=", "True", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "assert", "check_norm_state", "(", "model", ".", "modules", "(", ")", ",", "False", ")", "\n", "\n", "# Test MobileNetV2 forward with widen_factor=1.0, pretrained", "\n", "model", "=", "MobileNetV2", "(", "\n", "widen_factor", "=", "1.0", ",", "\n", "out_indices", "=", "range", "(", "0", ",", "8", ")", ",", "\n", "pretrained", "=", "'mmcls://mobilenet_v2'", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "assert", "check_norm_state", "(", "model", ".", "modules", "(", ")", ",", "True", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "8", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "24", ",", "56", ",", "56", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "3", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "64", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "4", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "96", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "5", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "160", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "6", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "320", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "7", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "1280", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 forward with widen_factor=0.5", "\n", "model", "=", "MobileNetV2", "(", "widen_factor", "=", "0.5", ",", "out_indices", "=", "range", "(", "0", ",", "7", ")", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "7", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "8", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "56", ",", "56", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "3", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "4", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "48", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "5", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "80", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "6", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "160", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 forward with widen_factor=2.0", "\n", "model", "=", "MobileNetV2", "(", "widen_factor", "=", "2.0", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "2560", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 forward with out_indices=None", "\n", "model", "=", "MobileNetV2", "(", "widen_factor", "=", "1.0", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "feat", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "1280", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 forward with dict(type='ReLU')", "\n", "model", "=", "MobileNetV2", "(", "\n", "widen_factor", "=", "1.0", ",", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "out_indices", "=", "range", "(", "0", ",", "7", ")", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "7", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "24", ",", "56", ",", "56", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "3", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "64", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "4", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "96", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "5", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "160", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "6", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "320", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 with GroupNorm forward", "\n", "model", "=", "MobileNetV2", "(", "widen_factor", "=", "1.0", ",", "out_indices", "=", "range", "(", "0", ",", "7", ")", ")", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "is_norm", "(", "m", ")", ":", "\n", "            ", "assert", "isinstance", "(", "m", ",", "_BatchNorm", ")", "\n", "", "", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "7", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "24", ",", "56", ",", "56", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "3", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "64", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "4", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "96", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "5", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "160", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "6", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "320", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 with BatchNorm forward", "\n", "model", "=", "MobileNetV2", "(", "\n", "widen_factor", "=", "1.0", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'GN'", ",", "num_groups", "=", "2", ",", "requires_grad", "=", "True", ")", ",", "\n", "out_indices", "=", "range", "(", "0", ",", "7", ")", ")", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "is_norm", "(", "m", ")", ":", "\n", "            ", "assert", "isinstance", "(", "m", ",", "GroupNorm", ")", "\n", "", "", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "7", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "24", ",", "56", ",", "56", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "3", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "64", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "4", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "96", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "5", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "160", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "6", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "320", ",", "7", ",", "7", ")", ")", "\n", "\n", "# Test MobileNetV2 with layers 1, 3, 5 out forward", "\n", "model", "=", "MobileNetV2", "(", "widen_factor", "=", "1.0", ",", "out_indices", "=", "(", "0", ",", "2", ",", "4", ")", ")", "\n", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "3", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "96", ",", "14", ",", "14", ")", ")", "\n", "\n", "# Test MobileNetV2 with checkpoint forward", "\n", "model", "=", "MobileNetV2", "(", "\n", "widen_factor", "=", "1.0", ",", "with_cp", "=", "True", ",", "out_indices", "=", "range", "(", "0", ",", "7", ")", ")", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "is_block", "(", "m", ")", ":", "\n", "            ", "assert", "m", ".", "with_cp", "\n", "", "", "model", ".", "init_weights", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "feat", "=", "model", "(", "imgs", ")", "\n", "assert", "len", "(", "feat", ")", "==", "7", "\n", "assert", "feat", "[", "0", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "16", ",", "112", ",", "112", ")", ")", "\n", "assert", "feat", "[", "1", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "24", ",", "56", ",", "56", ")", ")", "\n", "assert", "feat", "[", "2", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "32", ",", "28", ",", "28", ")", ")", "\n", "assert", "feat", "[", "3", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "64", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "4", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "96", ",", "14", ",", "14", ")", ")", "\n", "assert", "feat", "[", "5", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "160", ",", "7", ",", "7", ")", ")", "\n", "assert", "feat", "[", "6", "]", ".", "shape", "==", "torch", ".", "Size", "(", "(", "1", ",", "320", ",", "7", ",", "7", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_localizers.test_localizers.test_post_processing": [[6, 34], ["numpy.array", "dict", "mmaction.models.localizers.utils.post_processing", "isinstance", "isinstance", "numpy.array", "dict", "mmaction.models.localizers.utils.post_processing", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.post_processing.post_processing", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.post_processing.post_processing"], ["def", "test_post_processing", "(", ")", ":", "\n", "# test with multiple results", "\n", "    ", "result", "=", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", ",", "1.", ",", "1.", ",", "0.5", ",", "0.5", "]", ",", "[", "0.", ",", "0.4", ",", "1.", ",", "1.", ",", "0.4", ",", "0.4", "]", ",", "\n", "[", "0.", ",", "0.95", ",", "1.", ",", "1.", ",", "0.6", ",", "0.6", "]", "]", ")", "\n", "video_info", "=", "dict", "(", "\n", "video_name", "=", "'v_test'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "960", ",", "\n", "feature_frame", "=", "960", ")", "\n", "proposal_list", "=", "post_processing", "(", "result", ",", "video_info", ",", "0.75", ",", "0.65", ",", "0.9", ",", "2", ",", "16", ")", "\n", "assert", "isinstance", "(", "proposal_list", "[", "0", "]", ",", "dict", ")", "\n", "assert", "proposal_list", "[", "0", "]", "[", "'score'", "]", "==", "0.6", "\n", "assert", "proposal_list", "[", "0", "]", "[", "'segment'", "]", "==", "[", "0.", ",", "95.0", "]", "\n", "assert", "isinstance", "(", "proposal_list", "[", "1", "]", ",", "dict", ")", "\n", "assert", "proposal_list", "[", "1", "]", "[", "'score'", "]", "==", "0.4", "\n", "assert", "proposal_list", "[", "1", "]", "[", "'segment'", "]", "==", "[", "0.", ",", "40.0", "]", "\n", "\n", "# test with only result", "\n", "result", "=", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", ",", "1.", ",", "1.", ",", "0.5", ",", "0.5", "]", "]", ")", "\n", "video_info", "=", "dict", "(", "\n", "video_name", "=", "'v_test'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "960", ",", "\n", "feature_frame", "=", "960", ")", "\n", "proposal_list", "=", "post_processing", "(", "result", ",", "video_info", ",", "0.75", ",", "0.65", ",", "0.9", ",", "1", ",", "16", ")", "\n", "assert", "isinstance", "(", "proposal_list", "[", "0", "]", ",", "dict", ")", "\n", "assert", "proposal_list", "[", "0", "]", "[", "'score'", "]", "==", "0.5", "\n", "assert", "proposal_list", "[", "0", "]", "[", "'segment'", "]", "==", "[", "0.", ",", "100.0", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_localizers.test_pem.test_pem": [[7, 45], ["base.get_localizer_cfg", "mmaction.models.build_localizer", "torch.rand", "torch.rand", "mmaction.models.build_localizer.", "isinstance", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "dict", "torch.no_grad", "one_bsp_feature.reshape.reshape", "mmaction.models.build_localizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_localizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer"], ["def", "test_pem", "(", ")", ":", "\n", "    ", "model_cfg", "=", "get_localizer_cfg", "(", "\n", "'bsn/bsn_pem_400x100_1x16_20e_activitynet_feature.py'", ")", "\n", "\n", "localizer_pem", "=", "build_localizer", "(", "model_cfg", ".", "model", ")", "\n", "bsp_feature", "=", "torch", ".", "rand", "(", "8", ",", "100", ",", "32", ")", "\n", "reference_temporal_iou", "=", "torch", ".", "rand", "(", "8", ",", "100", ")", "\n", "losses", "=", "localizer_pem", "(", "bsp_feature", ",", "reference_temporal_iou", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "tmin", "=", "torch", ".", "rand", "(", "100", ")", "\n", "tmax", "=", "torch", ".", "rand", "(", "100", ")", "\n", "tmin_score", "=", "torch", ".", "rand", "(", "100", ")", "\n", "tmax_score", "=", "torch", ".", "rand", "(", "100", ")", "\n", "\n", "video_meta", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "1000", ",", "\n", "annotations", "=", "[", "{", "\n", "'segment'", ":", "[", "0.3", ",", "0.6", "]", ",", "\n", "'label'", ":", "'Rock climbing'", "\n", "}", "]", ",", "\n", "feature_frame", "=", "900", ")", "\n", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "one_bsp_feature", "in", "bsp_feature", ":", "\n", "            ", "one_bsp_feature", "=", "one_bsp_feature", ".", "reshape", "(", "1", ",", "100", ",", "32", ")", "\n", "localizer_pem", "(", "\n", "one_bsp_feature", ",", "\n", "tmin", "=", "tmin", ",", "\n", "tmax", "=", "tmax", ",", "\n", "tmin_score", "=", "tmin_score", ",", "\n", "tmax_score", "=", "tmax_score", ",", "\n", "video_meta", "=", "video_meta", ",", "\n", "return_loss", "=", "False", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_localizers.test_ssn.test_ssn_train": [[10, 105], ["mmcv.ConfigDict", "dict", "copy.deepcopy", "copy.deepcopy", "torch.rand", "torch.Tensor", "torch.Tensor", "torch.LongTensor", "torch.Tensor", "mmaction.models.build_localizer", "mmaction.models.build_localizer", "mmaction.models.build_localizer", "torch.cuda.is_available", "localizer_ssn.cuda.", "isinstance", "localizer_ssn_dropout.cuda.", "isinstance", "localizer_ssn_non_regression.cuda.", "isinstance", "dict", "localizer_ssn.cuda.cuda", "localizer_ssn_dropout.cuda.cuda", "localizer_ssn_non_regression.cuda.cuda", "imgs.cuda.cuda", "proposal_scale_factor.cuda.cuda", "proposal_type.cuda.cuda", "proposal_labels.cuda.cuda", "reg_targets.cuda.cuda", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer"], ["def", "test_ssn_train", "(", ")", ":", "\n", "    ", "train_cfg", "=", "mmcv", ".", "ConfigDict", "(", "\n", "dict", "(", "\n", "ssn", "=", "dict", "(", "\n", "assigner", "=", "dict", "(", "\n", "positive_iou_threshold", "=", "0.7", ",", "\n", "background_iou_threshold", "=", "0.01", ",", "\n", "incomplete_iou_threshold", "=", "0.3", ",", "\n", "background_coverage_threshold", "=", "0.02", ",", "\n", "incomplete_overlap_threshold", "=", "0.01", ")", ",", "\n", "sampler", "=", "dict", "(", "\n", "num_per_video", "=", "8", ",", "\n", "positive_ratio", "=", "1", ",", "\n", "background_ratio", "=", "1", ",", "\n", "incomplete_ratio", "=", "6", ",", "\n", "add_gt_as_proposals", "=", "True", ")", ",", "\n", "loss_weight", "=", "dict", "(", "comp_loss_weight", "=", "0.1", ",", "reg_loss_weight", "=", "0.1", ")", ",", "\n", "debug", "=", "False", ")", ")", ")", "\n", "base_model_cfg", "=", "dict", "(", "\n", "type", "=", "'SSN'", ",", "\n", "backbone", "=", "dict", "(", "\n", "type", "=", "'ResNet'", ",", "pretrained", "=", "None", ",", "depth", "=", "18", ",", "norm_eval", "=", "True", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.8", ",", "\n", "loss_cls", "=", "dict", "(", "type", "=", "'SSNLoss'", ")", ",", "\n", "cls_head", "=", "dict", "(", "\n", "type", "=", "'SSNHead'", ",", "\n", "dropout_ratio", "=", "0.", ",", "\n", "in_channels", "=", "512", ",", "\n", "num_classes", "=", "20", ",", "\n", "consensus", "=", "dict", "(", "\n", "type", "=", "'STPPTrain'", ",", "\n", "stpp_stage", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "num_segments_list", "=", "(", "2", ",", "5", ",", "2", ")", ")", ",", "\n", "use_regression", "=", "True", ")", ",", "\n", "train_cfg", "=", "train_cfg", ")", "\n", "dropout_cfg", "=", "copy", ".", "deepcopy", "(", "base_model_cfg", ")", "\n", "dropout_cfg", "[", "'dropout_ratio'", "]", "=", "0", "\n", "dropout_cfg", "[", "'cls_head'", "]", "[", "'dropout_ratio'", "]", "=", "0.5", "\n", "non_regression_cfg", "=", "copy", ".", "deepcopy", "(", "base_model_cfg", ")", "\n", "non_regression_cfg", "[", "'cls_head'", "]", "[", "'use_regression'", "]", "=", "False", "\n", "\n", "imgs", "=", "torch", ".", "rand", "(", "1", ",", "8", ",", "9", ",", "3", ",", "224", ",", "224", ")", "\n", "proposal_scale_factor", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "1.0345", ",", "1.0345", "]", ",", "[", "1.0028", ",", "0.0028", "]", ",", "\n", "[", "1.0013", ",", "1.0013", "]", ",", "[", "1.0008", ",", "1.0008", "]", ",", "\n", "[", "0.3357", ",", "1.0006", "]", ",", "[", "1.0006", ",", "1.0006", "]", ",", "\n", "[", "0.0818", ",", "1.0005", "]", ",", "[", "1.0030", ",", "\n", "1.0030", "]", "]", "]", ")", "\n", "proposal_type", "=", "torch", ".", "Tensor", "(", "[", "[", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "2", "]", "]", ")", "\n", "proposal_labels", "=", "torch", ".", "LongTensor", "(", "[", "[", "8", ",", "8", ",", "8", ",", "8", ",", "8", ",", "8", ",", "8", ",", "0", "]", "]", ")", "\n", "reg_targets", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "0.2929", ",", "0.2694", "]", ",", "[", "0.0000", ",", "0.0000", "]", ",", "\n", "[", "0.0000", ",", "0.0000", "]", ",", "[", "0.0000", ",", "0.0000", "]", ",", "\n", "[", "0.0000", ",", "0.0000", "]", ",", "[", "0.0000", ",", "0.0000", "]", ",", "\n", "[", "0.0000", ",", "0.0000", "]", ",", "[", "0.0000", ",", "0.0000", "]", "]", "]", ")", "\n", "\n", "localizer_ssn", "=", "build_localizer", "(", "base_model_cfg", ")", "\n", "localizer_ssn_dropout", "=", "build_localizer", "(", "dropout_cfg", ")", "\n", "localizer_ssn_non_regression", "=", "build_localizer", "(", "non_regression_cfg", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "localizer_ssn", "=", "localizer_ssn", ".", "cuda", "(", ")", "\n", "localizer_ssn_dropout", "=", "localizer_ssn_dropout", ".", "cuda", "(", ")", "\n", "localizer_ssn_non_regression", "=", "localizer_ssn_non_regression", ".", "cuda", "(", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "proposal_scale_factor", "=", "proposal_scale_factor", ".", "cuda", "(", ")", "\n", "proposal_type", "=", "proposal_type", ".", "cuda", "(", ")", "\n", "proposal_labels", "=", "proposal_labels", ".", "cuda", "(", ")", "\n", "reg_targets", "=", "reg_targets", ".", "cuda", "(", ")", "\n", "\n", "# Train normal case", "\n", "", "losses", "=", "localizer_ssn", "(", "\n", "imgs", ",", "\n", "proposal_scale_factor", "=", "proposal_scale_factor", ",", "\n", "proposal_type", "=", "proposal_type", ",", "\n", "proposal_labels", "=", "proposal_labels", ",", "\n", "reg_targets", "=", "reg_targets", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Train SSN without dropout in model, with dropout in head", "\n", "losses", "=", "localizer_ssn_dropout", "(", "\n", "imgs", ",", "\n", "proposal_scale_factor", "=", "proposal_scale_factor", ",", "\n", "proposal_type", "=", "proposal_type", ",", "\n", "proposal_labels", "=", "proposal_labels", ",", "\n", "reg_targets", "=", "reg_targets", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Train SSN model without regression", "\n", "losses", "=", "localizer_ssn_non_regression", "(", "\n", "imgs", ",", "\n", "proposal_scale_factor", "=", "proposal_scale_factor", ",", "\n", "proposal_type", "=", "proposal_type", ",", "\n", "proposal_labels", "=", "proposal_labels", ",", "\n", "reg_targets", "=", "reg_targets", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_localizers.test_ssn.test_ssn_test": [[107, 203], ["mmcv.ConfigDict", "dict", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "torch.rand", "torch.Tensor", "torch.Tensor", "torch.LongTensor", "torch.Tensor", "mmaction.models.build_localizer", "mmaction.models.build_localizer", "mmaction.models.build_localizer", "mmaction.models.build_localizer", "torch.cuda.is_available", "dict", "pytest.raises", "mmaction.models.build_localizer", "localizer_ssn.cuda.cuda", "localizer_ssn_maxpool.cuda.cuda", "localizer_ssn_non_regression.cuda.cuda", "localizer_ssn_tuple_stage_cfg.cuda.cuda", "imgs.cuda.cuda", "relative_proposal_list.cuda.cuda", "scale_factor_list.cuda.cuda", "proposal_tick_list.cuda.cuda", "reg_norm_consts.cuda.cuda", "torch.no_grad", "localizer_ssn.cuda.", "localizer_ssn_maxpool.cuda.", "localizer_ssn_non_regression.cuda.", "localizer_ssn_tuple_stage_cfg.cuda.", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer"], ["", "def", "test_ssn_test", "(", ")", ":", "\n", "    ", "test_cfg", "=", "mmcv", ".", "ConfigDict", "(", "\n", "dict", "(", "\n", "ssn", "=", "dict", "(", "\n", "sampler", "=", "dict", "(", "test_interval", "=", "6", ",", "batch_size", "=", "16", ")", ",", "\n", "evaluater", "=", "dict", "(", "\n", "top_k", "=", "2000", ",", "\n", "nms", "=", "0.2", ",", "\n", "softmax_before_filter", "=", "True", ",", "\n", "cls_score_dict", "=", "None", ",", "\n", "cls_top_k", "=", "2", ")", ")", ")", ")", "\n", "base_model_cfg", "=", "dict", "(", "\n", "type", "=", "'SSN'", ",", "\n", "backbone", "=", "dict", "(", "\n", "type", "=", "'ResNet'", ",", "pretrained", "=", "None", ",", "depth", "=", "18", ",", "norm_eval", "=", "True", ")", ",", "\n", "spatial_type", "=", "'avg'", ",", "\n", "dropout_ratio", "=", "0.8", ",", "\n", "cls_head", "=", "dict", "(", "\n", "type", "=", "'SSNHead'", ",", "\n", "dropout_ratio", "=", "0.", ",", "\n", "in_channels", "=", "512", ",", "\n", "num_classes", "=", "20", ",", "\n", "consensus", "=", "dict", "(", "type", "=", "'STPPTest'", ",", "stpp_stage", "=", "(", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "use_regression", "=", "True", ")", ",", "\n", "test_cfg", "=", "test_cfg", ")", "\n", "maxpool_model_cfg", "=", "copy", ".", "deepcopy", "(", "base_model_cfg", ")", "\n", "maxpool_model_cfg", "[", "'spatial_type'", "]", "=", "'max'", "\n", "non_regression_cfg", "=", "copy", ".", "deepcopy", "(", "base_model_cfg", ")", "\n", "non_regression_cfg", "[", "'cls_head'", "]", "[", "'use_regression'", "]", "=", "False", "\n", "non_regression_cfg", "[", "'cls_head'", "]", "[", "'consensus'", "]", "[", "'use_regression'", "]", "=", "False", "\n", "tuple_stage_cfg", "=", "copy", ".", "deepcopy", "(", "base_model_cfg", ")", "\n", "tuple_stage_cfg", "[", "'cls_head'", "]", "[", "'consensus'", "]", "[", "'stpp_stage'", "]", "=", "(", "1", ",", "(", "1", ",", "2", ")", ",", "1", ")", "\n", "str_stage_cfg", "=", "copy", ".", "deepcopy", "(", "base_model_cfg", ")", "\n", "str_stage_cfg", "[", "'cls_head'", "]", "[", "'consensus'", "]", "[", "'stpp_stage'", "]", "=", "(", "'error'", ",", ")", "\n", "\n", "imgs", "=", "torch", ".", "rand", "(", "1", ",", "8", ",", "3", ",", "224", ",", "224", ")", "\n", "relative_proposal_list", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "0.2500", ",", "0.6250", "]", ",", "[", "0.3750", ",", "\n", "0.7500", "]", "]", "]", ")", "\n", "scale_factor_list", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "1.0000", ",", "1.0000", "]", ",", "[", "1.0000", ",", "0.2661", "]", "]", "]", ")", "\n", "proposal_tick_list", "=", "torch", ".", "LongTensor", "(", "[", "[", "[", "1", ",", "2", ",", "5", ",", "7", "]", ",", "[", "20", ",", "30", ",", "60", ",", "80", "]", "]", "]", ")", "\n", "reg_norm_consts", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "-", "0.0603", ",", "0.0325", "]", ",", "[", "0.0752", ",", "0.1596", "]", "]", "]", ")", "\n", "\n", "localizer_ssn", "=", "build_localizer", "(", "base_model_cfg", ")", "\n", "localizer_ssn_maxpool", "=", "build_localizer", "(", "maxpool_model_cfg", ")", "\n", "localizer_ssn_non_regression", "=", "build_localizer", "(", "non_regression_cfg", ")", "\n", "localizer_ssn_tuple_stage_cfg", "=", "build_localizer", "(", "tuple_stage_cfg", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "build_localizer", "(", "str_stage_cfg", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "localizer_ssn", "=", "localizer_ssn", ".", "cuda", "(", ")", "\n", "localizer_ssn_maxpool", "=", "localizer_ssn_maxpool", ".", "cuda", "(", ")", "\n", "localizer_ssn_non_regression", "=", "localizer_ssn_non_regression", ".", "cuda", "(", ")", "\n", "localizer_ssn_tuple_stage_cfg", "=", "localizer_ssn_tuple_stage_cfg", ".", "cuda", "(", ")", "\n", "imgs", "=", "imgs", ".", "cuda", "(", ")", "\n", "relative_proposal_list", "=", "relative_proposal_list", ".", "cuda", "(", ")", "\n", "scale_factor_list", "=", "scale_factor_list", ".", "cuda", "(", ")", "\n", "proposal_tick_list", "=", "proposal_tick_list", ".", "cuda", "(", ")", "\n", "reg_norm_consts", "=", "reg_norm_consts", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Test normal case", "\n", "        ", "localizer_ssn", "(", "\n", "imgs", ",", "\n", "relative_proposal_list", "=", "relative_proposal_list", ",", "\n", "scale_factor_list", "=", "scale_factor_list", ",", "\n", "proposal_tick_list", "=", "proposal_tick_list", ",", "\n", "reg_norm_consts", "=", "reg_norm_consts", ",", "\n", "return_loss", "=", "False", ")", "\n", "\n", "# Test SSN model with max spatial pooling", "\n", "localizer_ssn_maxpool", "(", "\n", "imgs", ",", "\n", "relative_proposal_list", "=", "relative_proposal_list", ",", "\n", "scale_factor_list", "=", "scale_factor_list", ",", "\n", "proposal_tick_list", "=", "proposal_tick_list", ",", "\n", "reg_norm_consts", "=", "reg_norm_consts", ",", "\n", "return_loss", "=", "False", ")", "\n", "\n", "# Test SSN model without regression", "\n", "localizer_ssn_non_regression", "(", "\n", "imgs", ",", "\n", "relative_proposal_list", "=", "relative_proposal_list", ",", "\n", "scale_factor_list", "=", "scale_factor_list", ",", "\n", "proposal_tick_list", "=", "proposal_tick_list", ",", "\n", "reg_norm_consts", "=", "reg_norm_consts", ",", "\n", "return_loss", "=", "False", ")", "\n", "\n", "# Test SSN model with tuple stage cfg.", "\n", "localizer_ssn_tuple_stage_cfg", "(", "\n", "imgs", ",", "\n", "relative_proposal_list", "=", "relative_proposal_list", ",", "\n", "scale_factor_list", "=", "scale_factor_list", ",", "\n", "proposal_tick_list", "=", "proposal_tick_list", ",", "\n", "reg_norm_consts", "=", "reg_norm_consts", ",", "\n", "return_loss", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_localizers.test_tem.test_tem": [[7, 24], ["base.get_localizer_cfg", "mmaction.models.build_localizer", "torch.rand", "torch.Tensor", "mmaction.models.build_localizer.", "isinstance", "torch.no_grad", "one_raw_feature.reshape.reshape", "mmaction.models.build_localizer."], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_localizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer"], ["def", "test_tem", "(", ")", ":", "\n", "    ", "model_cfg", "=", "get_localizer_cfg", "(", "\n", "'bsn/bsn_tem_400x100_1x16_20e_activitynet_feature.py'", ")", "\n", "\n", "localizer_tem", "=", "build_localizer", "(", "model_cfg", ".", "model", ")", "\n", "raw_feature", "=", "torch", ".", "rand", "(", "8", ",", "400", ",", "100", ")", "\n", "gt_bbox", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "1.0", ",", "3.0", "]", ",", "[", "3.0", ",", "5.0", "]", "]", "]", "*", "8", ")", "\n", "losses", "=", "localizer_tem", "(", "raw_feature", ",", "gt_bbox", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "video_meta", "=", "[", "{", "'video_name'", ":", "'v_test'", "}", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "one_raw_feature", "in", "raw_feature", ":", "\n", "            ", "one_raw_feature", "=", "one_raw_feature", ".", "reshape", "(", "1", ",", "400", ",", "100", ")", "\n", "localizer_tem", "(", "\n", "one_raw_feature", ",", "video_meta", "=", "video_meta", ",", "return_loss", "=", "False", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_localizers.test_bmn.test_bmn": [[8, 56], ["base.get_localizer_cfg", "torch.cuda.is_available", "mmaction.models.build_localizer().cuda", "torch.rand().cuda", "numpy.array", "mmaction.models.build_localizer.", "isinstance", "mmaction.models.build_localizer", "torch.rand", "torch.Tensor", "mmaction.models.build_localizer.", "isinstance", "dict", "torch.no_grad", "torch.rand().cuda", "mmaction.models.build_localizer.", "dict", "torch.no_grad", "torch.rand", "mmaction.models.build_localizer.", "mmaction.models.build_localizer", "torch.rand", "torch.rand"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_models.base.get_localizer_cfg", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer"], ["def", "test_bmn", "(", ")", ":", "\n", "    ", "model_cfg", "=", "get_localizer_cfg", "(", "\n", "'bmn/bmn_400x100_2x8_9e_activitynet_feature.py'", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "localizer_bmn", "=", "build_localizer", "(", "model_cfg", ".", "model", ")", ".", "cuda", "(", ")", "\n", "raw_feature", "=", "torch", ".", "rand", "(", "8", ",", "400", ",", "100", ")", ".", "cuda", "(", ")", "\n", "gt_bbox", "=", "np", ".", "array", "(", "[", "[", "[", "0.1", ",", "0.3", "]", ",", "[", "0.375", ",", "0.625", "]", "]", "]", "*", "8", ")", "\n", "losses", "=", "localizer_bmn", "(", "raw_feature", ",", "gt_bbox", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "video_meta", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "960", ",", "\n", "feature_frame", "=", "960", ")", "\n", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "one_raw_feature", "=", "torch", ".", "rand", "(", "1", ",", "400", ",", "100", ")", ".", "cuda", "(", ")", "\n", "localizer_bmn", "(", "\n", "one_raw_feature", ",", "\n", "gt_bbox", "=", "None", ",", "\n", "video_meta", "=", "video_meta", ",", "\n", "return_loss", "=", "False", ")", "\n", "", "", "else", ":", "\n", "        ", "localizer_bmn", "=", "build_localizer", "(", "model_cfg", ".", "model", ")", "\n", "raw_feature", "=", "torch", ".", "rand", "(", "8", ",", "400", ",", "100", ")", "\n", "gt_bbox", "=", "torch", ".", "Tensor", "(", "[", "[", "[", "0.1", ",", "0.3", "]", ",", "[", "0.375", ",", "0.625", "]", "]", "]", "*", "8", ")", "\n", "losses", "=", "localizer_bmn", "(", "raw_feature", ",", "gt_bbox", ")", "\n", "assert", "isinstance", "(", "losses", ",", "dict", ")", "\n", "\n", "# Test forward test", "\n", "video_meta", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "960", ",", "\n", "feature_frame", "=", "960", ")", "\n", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "one_raw_feature", "=", "torch", ".", "rand", "(", "1", ",", "400", ",", "100", ")", "\n", "localizer_bmn", "(", "\n", "one_raw_feature", ",", "\n", "gt_bbox", "=", "None", ",", "\n", "video_meta", "=", "video_meta", ",", "\n", "return_loss", "=", "False", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_rename": [[12, 21], ["mmaction.datasets.pipelines.Rename", "dict", "mmaction.datasets.pipelines.Rename."], "function", ["None"], ["def", "test_rename", "(", ")", ":", "\n", "    ", "org_name", "=", "'a'", "\n", "new_name", "=", "'b'", "\n", "mapping", "=", "{", "org_name", ":", "new_name", "}", "\n", "rename", "=", "Rename", "(", "mapping", ")", "\n", "results", "=", "dict", "(", "a", "=", "2", ")", "\n", "results", "=", "rename", "(", "results", ")", "\n", "assert", "results", "[", "'b'", "]", "==", "2", "\n", "assert", "'a'", "not", "in", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_to_tensor": [[23, 61], ["mmaction.datasets.pipelines.ToTensor", "mmaction.datasets.pipelines.ToTensor", "dict", "mmaction.datasets.pipelines.ToTensor.", "mmcv.utils.assert_dict_has_keys", "dict", "mmaction.datasets.pipelines.ToTensor.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "dict", "mmaction.datasets.pipelines.ToTensor.", "isinstance", "torch.equal", "isinstance", "torch.equal", "repr", "torch.randn", "numpy.random.randn", "list", "torch.randn", "numpy.random.randn", "list", "range", "range"], "function", ["None"], ["", "def", "test_to_tensor", "(", ")", ":", "\n", "    ", "to_tensor", "=", "ToTensor", "(", "[", "'str'", "]", ")", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# str cannot be converted to tensor", "\n", "        ", "results", "=", "dict", "(", "str", "=", "'0'", ")", "\n", "to_tensor", "(", "results", ")", "\n", "\n", "# convert tensor, numpy, squence, int, float to tensor", "\n", "", "target_keys", "=", "[", "'tensor'", ",", "'numpy'", ",", "'sequence'", ",", "'int'", ",", "'float'", "]", "\n", "to_tensor", "=", "ToTensor", "(", "target_keys", ")", "\n", "original_results", "=", "dict", "(", "\n", "tensor", "=", "torch", ".", "randn", "(", "2", ",", "3", ")", ",", "\n", "numpy", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "3", ")", ",", "\n", "sequence", "=", "list", "(", "range", "(", "10", ")", ")", ",", "\n", "int", "=", "1", ",", "\n", "float", "=", "0.1", ")", "\n", "results", "=", "to_tensor", "(", "original_results", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "for", "key", "in", "target_keys", ":", "\n", "        ", "assert", "isinstance", "(", "results", "[", "key", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "torch", ".", "equal", "(", "results", "[", "key", "]", ".", "data", ",", "original_results", "[", "key", "]", ")", "\n", "\n", "# Add an additional key which is not in keys.", "\n", "", "original_results", "=", "dict", "(", "\n", "tensor", "=", "torch", ".", "randn", "(", "2", ",", "3", ")", ",", "\n", "numpy", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "3", ")", ",", "\n", "sequence", "=", "list", "(", "range", "(", "10", ")", ")", ",", "\n", "int", "=", "1", ",", "\n", "float", "=", "0.1", ",", "\n", "str", "=", "'test'", ")", "\n", "results", "=", "to_tensor", "(", "original_results", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "for", "key", "in", "target_keys", ":", "\n", "        ", "assert", "isinstance", "(", "results", "[", "key", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "torch", ".", "equal", "(", "results", "[", "key", "]", ".", "data", ",", "original_results", "[", "key", "]", ")", "\n", "\n", "", "assert", "repr", "(", "to_tensor", ")", "==", "to_tensor", ".", "__class__", ".", "__name__", "+", "f'(keys={target_keys})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_to_data_container": [[63, 90], ["mmaction.datasets.pipelines.ToDataContainer", "dict", "mmaction.datasets.pipelines.ToDataContainer.", "mmcv.utils.assert_dict_has_keys", "dict", "mmaction.datasets.pipelines.ToDataContainer.", "mmcv.utils.assert_dict_has_keys", "dict", "dict", "dict.copy", "isinstance", "numpy.all", "dict.copy", "isinstance", "numpy.all", "repr", "numpy.random.randn", "numpy.random.randn"], "function", ["None"], ["", "def", "test_to_data_container", "(", ")", ":", "\n", "# check user-defined fields", "\n", "    ", "fields", "=", "(", "dict", "(", "key", "=", "'key1'", ",", "stack", "=", "True", ")", ",", "dict", "(", "key", "=", "'key2'", ")", ")", "\n", "to_data_container", "=", "ToDataContainer", "(", "fields", "=", "fields", ")", "\n", "target_keys", "=", "[", "'key1'", ",", "'key2'", "]", "\n", "original_results", "=", "dict", "(", "key1", "=", "np", ".", "random", ".", "randn", "(", "10", ",", "20", ")", ",", "key2", "=", "[", "'a'", ",", "'b'", "]", ")", "\n", "results", "=", "to_data_container", "(", "original_results", ".", "copy", "(", ")", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "for", "key", "in", "target_keys", ":", "\n", "        ", "assert", "isinstance", "(", "results", "[", "key", "]", ",", "DC", ")", "\n", "assert", "np", ".", "all", "(", "results", "[", "key", "]", ".", "data", "==", "original_results", "[", "key", "]", ")", "\n", "", "assert", "results", "[", "'key1'", "]", ".", "stack", "\n", "assert", "not", "results", "[", "'key2'", "]", ".", "stack", "\n", "\n", "# Add an additional key which is not in keys.", "\n", "original_results", "=", "dict", "(", "\n", "key1", "=", "np", ".", "random", ".", "randn", "(", "10", ",", "20", ")", ",", "key2", "=", "[", "'a'", ",", "'b'", "]", ",", "key3", "=", "'value3'", ")", "\n", "results", "=", "to_data_container", "(", "original_results", ".", "copy", "(", ")", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "for", "key", "in", "target_keys", ":", "\n", "        ", "assert", "isinstance", "(", "results", "[", "key", "]", ",", "DC", ")", "\n", "assert", "np", ".", "all", "(", "results", "[", "key", "]", ".", "data", "==", "original_results", "[", "key", "]", ")", "\n", "", "assert", "results", "[", "'key1'", "]", ".", "stack", "\n", "assert", "not", "results", "[", "'key2'", "]", ".", "stack", "\n", "\n", "assert", "repr", "(", "to_data_container", ")", "==", "(", "\n", "to_data_container", ".", "__class__", ".", "__name__", "+", "f'(fields={fields})'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_image_to_tensor": [[92, 102], ["dict", "mmaction.datasets.pipelines.ImageToTensor", "mmaction.datasets.pipelines.ImageToTensor.", "isinstance", "torch.equal", "torch.Size", "repr", "numpy.random.randn"], "function", ["None"], ["", "def", "test_image_to_tensor", "(", ")", ":", "\n", "    ", "original_results", "=", "dict", "(", "imgs", "=", "np", ".", "random", ".", "randn", "(", "256", ",", "256", ",", "3", ")", ")", "\n", "keys", "=", "[", "'imgs'", "]", "\n", "image_to_tensor", "=", "ImageToTensor", "(", "keys", ")", "\n", "results", "=", "image_to_tensor", "(", "original_results", ")", "\n", "assert", "results", "[", "'imgs'", "]", ".", "shape", "==", "torch", ".", "Size", "(", "[", "3", ",", "256", ",", "256", "]", ")", "\n", "assert", "isinstance", "(", "results", "[", "'imgs'", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "torch", ".", "equal", "(", "results", "[", "'imgs'", "]", ".", "data", ",", "original_results", "[", "'imgs'", "]", ")", "\n", "assert", "repr", "(", "image_to_tensor", ")", "==", "image_to_tensor", ".", "__class__", ".", "__name__", "+", "f'(keys={keys})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_transpose": [[104, 113], ["dict", "mmaction.datasets.pipelines.Transpose", "mmaction.datasets.pipelines.Transpose.", "repr", "numpy.random.randn"], "function", ["None"], ["", "def", "test_transpose", "(", ")", ":", "\n", "    ", "results", "=", "dict", "(", "imgs", "=", "np", ".", "random", ".", "randn", "(", "256", ",", "256", ",", "3", ")", ")", "\n", "keys", "=", "[", "'imgs'", "]", "\n", "order", "=", "[", "2", ",", "0", ",", "1", "]", "\n", "transpose", "=", "Transpose", "(", "keys", ",", "order", ")", "\n", "results", "=", "transpose", "(", "results", ")", "\n", "assert", "results", "[", "'imgs'", "]", ".", "shape", "==", "(", "3", ",", "256", ",", "256", ")", "\n", "assert", "repr", "(", "transpose", ")", "==", "transpose", ".", "__class__", ".", "__name__", "+", "f'(keys={keys}, order={order})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_collect": [[115, 145], ["dict", "mmaction.datasets.pipelines.Collect", "mmaction.datasets.pipelines.Collect.", "dict.pop", "mmaction.datasets.pipelines.Collect", "mmaction.datasets.pipelines.Collect.", "sorted", "sorted", "set", "set", "repr", "sorted", "sorted", "isinstance", "numpy.random.randn", "dict", "list", "list", "collect.keys", "collect.keys"], "function", ["None"], ["", "def", "test_collect", "(", ")", ":", "\n", "    ", "inputs", "=", "dict", "(", "\n", "imgs", "=", "np", ".", "random", ".", "randn", "(", "256", ",", "256", ",", "3", ")", ",", "\n", "label", "=", "[", "1", "]", ",", "\n", "filename", "=", "'test.txt'", ",", "\n", "original_shape", "=", "(", "256", ",", "256", ",", "3", ")", ",", "\n", "img_shape", "=", "(", "256", ",", "256", ",", "3", ")", ",", "\n", "pad_shape", "=", "(", "256", ",", "256", ",", "3", ")", ",", "\n", "flip_direction", "=", "'vertical'", ",", "\n", "img_norm_cfg", "=", "dict", "(", "to_bgr", "=", "False", ")", ")", "\n", "keys", "=", "[", "'imgs'", ",", "'label'", "]", "\n", "collect", "=", "Collect", "(", "keys", ")", "\n", "results", "=", "collect", "(", "inputs", ")", "\n", "assert", "sorted", "(", "list", "(", "results", ".", "keys", "(", ")", ")", ")", "==", "sorted", "(", "\n", "[", "'imgs'", ",", "'label'", ",", "'img_metas'", "]", ")", "\n", "imgs", "=", "inputs", ".", "pop", "(", "'imgs'", ")", "\n", "assert", "set", "(", "results", "[", "'img_metas'", "]", ".", "data", ")", "==", "set", "(", "inputs", ")", "\n", "for", "key", "in", "results", "[", "'img_metas'", "]", ".", "data", ":", "\n", "        ", "assert", "results", "[", "'img_metas'", "]", ".", "data", "[", "key", "]", "==", "inputs", "[", "key", "]", "\n", "", "assert", "repr", "(", "collect", ")", "==", "collect", ".", "__class__", ".", "__name__", "+", "(", "f'(keys={keys}, meta_keys={collect.meta_keys}, '", "\n", "f'nested={collect.nested})'", ")", "\n", "\n", "inputs", "[", "'imgs'", "]", "=", "imgs", "\n", "collect", "=", "Collect", "(", "keys", ",", "nested", "=", "True", ")", "\n", "results", "=", "collect", "(", "inputs", ")", "\n", "assert", "sorted", "(", "list", "(", "results", ".", "keys", "(", ")", ")", ")", "==", "sorted", "(", "\n", "[", "'imgs'", ",", "'label'", ",", "'img_metas'", "]", ")", "\n", "for", "k", "in", "results", ":", "\n", "        ", "assert", "isinstance", "(", "results", "[", "k", "]", ",", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_format_shape": [[147, 182], ["dict", "mmaction.datasets.pipelines.FormatShape", "dict", "mmaction.datasets.pipelines.FormatShape", "dict", "mmcv.utils.assert_dict_has_keys", "dict", "mmaction.datasets.pipelines.FormatShape", "pytest.raises", "mmaction.datasets.pipelines.FormatShape", "repr", "numpy.random.randn", "mmaction.datasets.pipelines.FormatShape.", "numpy.random.randn", "mmaction.datasets.pipelines.FormatShape.", "numpy.random.randn", "mmaction.datasets.pipelines.FormatShape.", "numpy.random.randn", "mmaction.datasets.pipelines.FormatShape."], "function", ["None"], ["", "", "def", "test_format_shape", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# invalid input format", "\n", "        ", "FormatShape", "(", "'NHWC'", ")", "\n", "\n", "# 'NCHW' input format", "\n", "", "results", "=", "dict", "(", "\n", "imgs", "=", "np", ".", "random", ".", "randn", "(", "3", ",", "224", ",", "224", ",", "3", ")", ",", "num_clips", "=", "1", ",", "clip_len", "=", "3", ")", "\n", "format_shape", "=", "FormatShape", "(", "'NCHW'", ")", "\n", "assert", "format_shape", "(", "results", ")", "[", "'input_shape'", "]", "==", "(", "3", ",", "3", ",", "224", ",", "224", ")", "\n", "\n", "# `NCTHW` input format with num_clips=1, clip_len=3", "\n", "results", "=", "dict", "(", "\n", "imgs", "=", "np", ".", "random", ".", "randn", "(", "3", ",", "224", ",", "224", ",", "3", ")", ",", "num_clips", "=", "1", ",", "clip_len", "=", "3", ")", "\n", "format_shape", "=", "FormatShape", "(", "'NCTHW'", ")", "\n", "assert", "format_shape", "(", "results", ")", "[", "'input_shape'", "]", "==", "(", "1", ",", "3", ",", "3", ",", "224", ",", "224", ")", "\n", "\n", "# `NCTHW` input format with num_clips=2, clip_len=3", "\n", "results", "=", "dict", "(", "\n", "imgs", "=", "np", ".", "random", ".", "randn", "(", "18", ",", "224", ",", "224", ",", "3", ")", ",", "num_clips", "=", "2", ",", "clip_len", "=", "3", ")", "\n", "assert", "format_shape", "(", "results", ")", "[", "'input_shape'", "]", "==", "(", "6", ",", "3", ",", "3", ",", "224", ",", "224", ")", "\n", "target_keys", "=", "[", "'imgs'", ",", "'input_shape'", "]", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "\n", "assert", "repr", "(", "format_shape", ")", "==", "format_shape", ".", "__class__", ".", "__name__", "+", "\"(input_format='NCTHW')\"", "\n", "\n", "# 'NPTCHW' input format", "\n", "results", "=", "dict", "(", "\n", "imgs", "=", "np", ".", "random", ".", "randn", "(", "72", ",", "224", ",", "224", ",", "3", ")", ",", "\n", "num_clips", "=", "9", ",", "\n", "clip_len", "=", "1", ",", "\n", "num_proposals", "=", "8", ")", "\n", "format_shape", "=", "FormatShape", "(", "'NPTCHW'", ")", "\n", "assert", "format_shape", "(", "results", ")", "[", "'input_shape'", "]", "==", "(", "8", ",", "9", ",", "3", ",", "224", ",", "224", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_formating.test_format_audio_shape": [[184, 195], ["dict", "mmaction.datasets.pipelines.FormatAudioShape", "pytest.raises", "mmaction.datasets.pipelines.FormatAudioShape", "repr", "numpy.random.randn", "mmaction.datasets.pipelines.FormatAudioShape."], "function", ["None"], ["", "def", "test_format_audio_shape", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# invalid input format", "\n", "        ", "FormatAudioShape", "(", "'XXXX'", ")", "\n", "\n", "# 'NCTF' input format", "\n", "", "results", "=", "dict", "(", "audios", "=", "np", ".", "random", ".", "randn", "(", "3", ",", "128", ",", "8", ")", ")", "\n", "format_shape", "=", "FormatAudioShape", "(", "'NCTF'", ")", "\n", "assert", "format_shape", "(", "results", ")", "[", "'input_shape'", "]", "==", "(", "3", ",", "1", ",", "128", ",", "8", ")", "\n", "assert", "repr", "(", "format_shape", ")", "==", "format_shape", ".", "__class__", ".", "__name__", "+", "\"(input_format='NCTF')\"", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_blending.test_mixup": [[6, 23], ["torch.randint", "mmaction.datasets.MixupBlending", "torch.randn", "mmaction.datasets.MixupBlending.", "torch.randn", "mmaction.datasets.MixupBlending.", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["None"], ["def", "test_mixup", "(", ")", ":", "\n", "    ", "alpha", "=", "0.2", "\n", "num_classes", "=", "10", "\n", "label", "=", "torch", ".", "randint", "(", "0", ",", "num_classes", ",", "(", "4", ",", ")", ")", "\n", "mixup", "=", "MixupBlending", "(", "num_classes", ",", "alpha", ")", "\n", "\n", "# NCHW imgs", "\n", "imgs", "=", "torch", ".", "randn", "(", "4", ",", "4", ",", "3", ",", "32", ",", "32", ")", "\n", "mixed_imgs", ",", "mixed_label", "=", "mixup", "(", "imgs", ",", "label", ")", "\n", "assert", "mixed_imgs", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "4", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "assert", "mixed_label", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "num_classes", ")", ")", "\n", "\n", "# NCTHW imgs", "\n", "imgs", "=", "torch", ".", "randn", "(", "4", ",", "4", ",", "2", ",", "3", ",", "32", ",", "32", ")", "\n", "mixed_imgs", ",", "mixed_label", "=", "mixup", "(", "imgs", ",", "label", ")", "\n", "assert", "mixed_imgs", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "4", ",", "2", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "assert", "mixed_label", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_blending.test_cutmix": [[25, 42], ["torch.randint", "mmaction.datasets.CutmixBlending", "torch.randn", "mmaction.datasets.CutmixBlending.", "torch.randn", "mmaction.datasets.CutmixBlending.", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["None"], ["", "def", "test_cutmix", "(", ")", ":", "\n", "    ", "alpha", "=", "0.2", "\n", "num_classes", "=", "10", "\n", "label", "=", "torch", ".", "randint", "(", "0", ",", "num_classes", ",", "(", "4", ",", ")", ")", "\n", "mixup", "=", "CutmixBlending", "(", "num_classes", ",", "alpha", ")", "\n", "\n", "# NCHW imgs", "\n", "imgs", "=", "torch", ".", "randn", "(", "4", ",", "4", ",", "3", ",", "32", ",", "32", ")", "\n", "mixed_imgs", ",", "mixed_label", "=", "mixup", "(", "imgs", ",", "label", ")", "\n", "assert", "mixed_imgs", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "4", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "assert", "mixed_label", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "num_classes", ")", ")", "\n", "\n", "# NCTHW imgs", "\n", "imgs", "=", "torch", ".", "randn", "(", "4", ",", "4", ",", "2", ",", "3", ",", "32", ",", "32", ")", "\n", "mixed_imgs", ",", "mixed_label", "=", "mixup", "(", "imgs", ",", "label", ")", "\n", "assert", "mixed_imgs", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "4", ",", "2", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "assert", "mixed_label", ".", "shape", "==", "torch", ".", "Size", "(", "(", "4", ",", "num_classes", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_sampler.MyDataset.__init__": [[9, 14], ["torch.utils.data.Dataset.__init__", "dict", "range", "range"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "class_prob", "=", "{", "i", ":", "1", "for", "i", "in", "range", "(", "10", ")", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "class_prob", "=", "class_prob", "\n", "self", ".", "video_infos", "=", "[", "\n", "dict", "(", "data", "=", "idx", ",", "label", "=", "idx", "%", "10", ")", "for", "idx", "in", "range", "(", "100", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_sampler.MyDataset.__len__": [[16, 18], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "video_infos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_sampler.MyDataset.__getitem__": [[19, 21], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "video_infos", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_sampler.test_distributed_sampler": [[23, 51], ["test_sampler.MyDataset", "mmaction.datasets.samplers.DistributedSampler", "torch.utils.data.DataLoader", "enumerate", "mmaction.datasets.samplers.DistributedSampler", "torch.utils.data.DataLoader", "enumerate", "mmaction.datasets.samplers.DistributedSampler", "torch.utils.data.DataLoader", "enumerate", "batches.append", "len", "sum", "batches.append", "len", "sum", "batches.append", "len", "sum", "len", "len", "len"], "function", ["None"], ["", "", "def", "test_distributed_sampler", "(", ")", ":", "\n", "    ", "dataset", "=", "MyDataset", "(", ")", "\n", "sampler", "=", "DistributedSampler", "(", "dataset", ",", "num_replicas", "=", "1", ",", "rank", "=", "0", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "_", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "25", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "100", "\n", "\n", "sampler", "=", "DistributedSampler", "(", "dataset", ",", "num_replicas", "=", "4", ",", "rank", "=", "2", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "7", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "25", "\n", "\n", "sampler", "=", "DistributedSampler", "(", "dataset", ",", "num_replicas", "=", "6", ",", "rank", "=", "3", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "5", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "17", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_sampler.test_class_specific_distributed_sampler": [[53, 96], ["dict", "test_sampler.MyDataset", "mmaction.datasets.samplers.ClassSpecificDistributedSampler", "torch.utils.data.DataLoader", "enumerate", "mmaction.datasets.samplers.ClassSpecificDistributedSampler", "torch.utils.data.DataLoader", "enumerate", "mmaction.datasets.samplers.ClassSpecificDistributedSampler", "torch.utils.data.DataLoader", "enumerate", "mmaction.datasets.samplers.ClassSpecificDistributedSampler", "torch.utils.data.DataLoader", "enumerate", "zip", "batches.append", "len", "sum", "batches.append", "len", "sum", "batches.append", "len", "sum", "batches.append", "len", "sum", "list", "range", "len", "len", "len", "len"], "function", ["None"], ["", "def", "test_class_specific_distributed_sampler", "(", ")", ":", "\n", "    ", "class_prob", "=", "dict", "(", "zip", "(", "list", "(", "range", "(", "10", ")", ")", ",", "[", "1", "]", "*", "5", "+", "[", "3", "]", "*", "5", ")", ")", "\n", "dataset", "=", "MyDataset", "(", "class_prob", "=", "class_prob", ")", "\n", "\n", "sampler", "=", "ClassSpecificDistributedSampler", "(", "\n", "dataset", ",", "num_replicas", "=", "1", ",", "rank", "=", "0", ",", "dynamic_length", "=", "True", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "_", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "50", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "200", "\n", "\n", "sampler", "=", "ClassSpecificDistributedSampler", "(", "\n", "dataset", ",", "num_replicas", "=", "1", ",", "rank", "=", "0", ",", "dynamic_length", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "25", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "100", "\n", "\n", "sampler", "=", "ClassSpecificDistributedSampler", "(", "\n", "dataset", ",", "num_replicas", "=", "6", ",", "rank", "=", "2", ",", "dynamic_length", "=", "True", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "9", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "34", "\n", "\n", "sampler", "=", "ClassSpecificDistributedSampler", "(", "\n", "dataset", ",", "num_replicas", "=", "6", ",", "rank", "=", "2", ",", "dynamic_length", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "4", ",", "sampler", "=", "sampler", ")", "\n", "batches", "=", "[", "]", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "assert", "len", "(", "batches", ")", "==", "5", "\n", "assert", "sum", "(", "[", "len", "(", "x", "[", "'data'", "]", ")", "for", "x", "in", "batches", "]", ")", "==", "17", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_data.test_compose.test_compose": [[8, 38], ["numpy.random.randn", "dict", "mmaction.datasets.pipelines.Compose", "mmaction.datasets.pipelines.Compose.", "mmcv.utils.assert_keys_equal", "mmcv.utils.assert_keys_equal", "mmaction.datasets.pipelines.ImageToTensor", "mmaction.datasets.pipelines.Compose", "mmaction.datasets.pipelines.Compose.", "pytest.raises", "mmaction.datasets.pipelines.Compose", "dict", "dict", "compose.keys", "compose_results[].data.keys", "repr"], "function", ["None"], ["def", "test_compose", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# transform must be callable or a dict", "\n", "        ", "Compose", "(", "'LoadImage'", ")", "\n", "\n", "", "target_keys", "=", "[", "'img'", ",", "'img_metas'", "]", "\n", "\n", "# test Compose given a data pipeline", "\n", "img", "=", "np", ".", "random", ".", "randn", "(", "256", ",", "256", ",", "3", ")", "\n", "results", "=", "dict", "(", "img", "=", "img", ",", "abandoned_key", "=", "None", ",", "img_name", "=", "'test_image.png'", ")", "\n", "test_pipeline", "=", "[", "\n", "dict", "(", "type", "=", "'Collect'", ",", "keys", "=", "[", "'img'", "]", ",", "meta_keys", "=", "[", "'img_name'", "]", ")", ",", "\n", "dict", "(", "type", "=", "'ImageToTensor'", ",", "keys", "=", "[", "'img'", "]", ")", "\n", "]", "\n", "compose", "=", "Compose", "(", "test_pipeline", ")", "\n", "compose_results", "=", "compose", "(", "results", ")", "\n", "assert", "assert_keys_equal", "(", "compose_results", ".", "keys", "(", ")", ",", "target_keys", ")", "\n", "assert", "assert_keys_equal", "(", "compose_results", "[", "'img_metas'", "]", ".", "data", ".", "keys", "(", ")", ",", "\n", "[", "'img_name'", "]", ")", "\n", "\n", "# test Compose when forward data is None", "\n", "results", "=", "None", "\n", "image_to_tensor", "=", "ImageToTensor", "(", "keys", "=", "[", "]", ")", "\n", "test_pipeline", "=", "[", "image_to_tensor", "]", "\n", "compose", "=", "Compose", "(", "test_pipeline", ")", "\n", "compose_results", "=", "compose", "(", "results", ")", "\n", "assert", "compose_results", "is", "None", "\n", "\n", "assert", "repr", "(", "compose", ")", "==", "compose", ".", "__class__", ".", "__name__", "+", "f'(\\n    {image_to_tensor}\\n)'", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_transform.TestTransform.test_random_rescale": [[14, 49], ["list", "dict", "mmaction.datasets.pipelines.RandomRescale", "mmaction.datasets.pipelines.RandomRescale.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "mmaction.datasets.pipelines.RandomRescale", "pytest.raises", "mmaction.datasets.pipelines.RandomRescale", "pytest.raises", "mmaction.datasets.pipelines.RandomRescale", "pytest.raises", "mmaction.datasets.pipelines.RandomRescale", "numpy.random.rand", "numpy.abs", "repr"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "test_random_rescale", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# scale_range must be a tuple of int", "\n", "            ", "RandomRescale", "(", "scale_range", "=", "224", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# scale_range must be a tuple of int", "\n", "            ", "RandomRescale", "(", "scale_range", "=", "(", "224.0", ",", "256.0", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# scale_range[0] > scale_range[1], which is wrong", "\n", "            ", "RandomRescale", "(", "scale_range", "=", "(", "320", ",", "256", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# scale_range[0] <= 0, which is wrong", "\n", "            ", "RandomRescale", "(", "scale_range", "=", "(", "0", ",", "320", ")", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'short_edge'", ",", "'img_shape'", "]", "\n", "# There will be a slight difference because of rounding", "\n", "eps", "=", "0.01", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "340", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "img_shape", "=", "(", "256", ",", "340", ")", ",", "modality", "=", "'RGB'", ")", "\n", "\n", "random_rescale", "=", "RandomRescale", "(", "scale_range", "=", "(", "300", ",", "400", ")", ")", "\n", "random_rescale_result", "=", "random_rescale", "(", "results", ")", "\n", "\n", "assert", "assert_dict_has_keys", "(", "random_rescale_result", ",", "target_keys", ")", "\n", "\n", "h", ",", "w", "=", "random_rescale_result", "[", "'img_shape'", "]", "\n", "\n", "# check rescale", "\n", "assert", "np", ".", "abs", "(", "h", "/", "256", "-", "w", "/", "340", ")", "<", "eps", "\n", "assert", "300", "/", "256", "-", "eps", "<=", "h", "/", "256", "<=", "400", "/", "256", "+", "eps", "\n", "assert", "repr", "(", "random_rescale", ")", "==", "(", "f'{random_rescale.__class__.__name__}'", "\n", "f'(scale_range={(300, 400)}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_transform.TestTransform.test_resize": [[52, 115], ["list", "numpy.array().reshape", "dict", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "numpy.testing.assert_array_almost_equal", "list", "dict", "numpy.array", "numpy.array", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "list", "dict", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "list", "dict", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "pytest.raises", "mmaction.datasets.pipelines.Resize", "pytest.raises", "mmaction.datasets.pipelines.Resize", "numpy.random.rand", "numpy.array", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "repr", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_resize", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# scale must be positive", "\n", "            ", "Resize", "(", "-", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# scale must be tuple of int", "\n", "            ", "Resize", "(", "'224'", ")", "\n", "\n", "", "target_keys", "=", "[", "\n", "'imgs'", ",", "'img_shape'", ",", "'keep_ratio'", ",", "'scale_factor'", ",", "'modality'", "\n", "]", "\n", "\n", "# test resize for flow images", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ")", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "60", ",", "60", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "1", ",", "2", "]", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "keypoint", "=", "kp", ",", "modality", "=", "'Flow'", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "160", ",", "80", ")", ",", "keep_ratio", "=", "False", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "assert", "np", ".", "all", "(", "resize_results", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", ".5", ",", "1.", "/", "3.", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results", "[", "'img_shape'", "]", "==", "(", "80", ",", "160", ")", "\n", "kp", "=", "resize_results", "[", "'keypoint'", "]", "[", "0", ",", "0", ",", "0", "]", "\n", "assert_array_almost_equal", "(", "kp", ",", "np", ".", "array", "(", "[", "30", ",", "20", "]", ")", ")", "\n", "\n", "# scale with -1 to indicate np.inf", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "320", ",", "240", "]", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "320", ",", "240", "]", "]", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "-", "1", ",", "256", ")", ",", "keep_ratio", "=", "True", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "assert", "np", ".", "all", "(", "resize_results", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", "341", "/", "320", ",", "256", "/", "240", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results", "[", "'img_shape'", "]", "==", "(", "256", ",", "341", ")", "\n", "\n", "# scale with a normal tuple (320, 320) to indicate np.inf", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "320", ",", "320", ")", ",", "keep_ratio", "=", "False", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "assert", "np", ".", "all", "(", "resize_results", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", "1", ",", "320", "/", "240", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results", "[", "'img_shape'", "]", "==", "(", "320", ",", "320", ")", "\n", "\n", "# scale with a normal tuple (341, 256) to indicate np.inf", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "341", ",", "256", ")", ",", "keep_ratio", "=", "False", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "assert", "np", ".", "all", "(", "resize_results", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", "341", "/", "320", ",", "256", "/", "240", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results", "[", "'img_shape'", "]", "==", "(", "256", ",", "341", ")", "\n", "\n", "assert", "repr", "(", "resize", ")", "==", "(", "\n", "resize", ".", "__class__", ".", "__name__", "+", "\n", "f'(scale={(341, 256)}, keep_ratio={False}, '", "+", "\n", "f'interpolation=bilinear, lazy={False})'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_transform.TestTransform.test_random_scale": [[116, 147], ["list", "dict", "copy.deepcopy", "mmaction.datasets.pipelines.RandomScale", "mmaction.datasets.pipelines.RandomScale.", "copy.deepcopy", "mmaction.datasets.pipelines.RandomScale", "mmaction.datasets.pipelines.RandomScale.", "mmaction.datasets.pipelines.RandomScale", "copy.deepcopy", "mmaction.datasets.pipelines.RandomScale.", "pytest.raises", "mmaction.datasets.pipelines.RandomScale", "pytest.raises", "mmaction.datasets.pipelines.RandomScale", "mmaction.datasets.pipelines.RandomScale.", "numpy.random.rand", "repr"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_random_scale", "(", ")", ":", "\n", "        ", "scales", "=", "(", "(", "200", ",", "64", ")", ",", "(", "250", ",", "80", ")", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "RandomScale", "(", "scales", ",", "'unsupport'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "random_scale", "=", "RandomScale", "(", "[", "(", "800", ",", "256", ")", ",", "(", "1000", ",", "320", ")", ",", "(", "800", ",", "320", ")", "]", ")", "\n", "random_scale", "(", "{", "}", ")", "\n", "\n", "", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "340", ",", "256", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "img_shape", "=", "(", "340", ",", "256", ")", ")", "\n", "\n", "results_", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "random_scale_range", "=", "RandomScale", "(", "scales", ")", "\n", "results_", "=", "random_scale_range", "(", "results_", ")", "\n", "assert", "200", "<=", "results_", "[", "'scale'", "]", "[", "0", "]", "<=", "250", "\n", "assert", "64", "<=", "results_", "[", "'scale'", "]", "[", "1", "]", "<=", "80", "\n", "\n", "results_", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "random_scale_value", "=", "RandomScale", "(", "scales", ",", "'value'", ")", "\n", "results_", "=", "random_scale_value", "(", "results_", ")", "\n", "assert", "results_", "[", "'scale'", "]", "in", "scales", "\n", "\n", "random_scale_single", "=", "RandomScale", "(", "[", "(", "200", ",", "64", ")", "]", ")", "\n", "results_", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "results_", "=", "random_scale_single", "(", "results_", ")", "\n", "assert", "results_", "[", "'scale'", "]", "==", "(", "200", ",", "64", ")", "\n", "\n", "assert", "repr", "(", "random_scale_range", ")", "==", "(", "\n", "f'{random_scale_range.__class__.__name__}'", "\n", "f'(scales={((200, 64), (250, 80))}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_transform.TestPoseCompact.test_pose_compact": [[153, 194], ["numpy.zeros", "mmaction.datasets.pipelines.augmentations.PoseCompact", "copy.deepcopy", "mmaction.datasets.pipelines.augmentations.PoseCompact.", "mmaction.datasets.pipelines.augmentations.PoseCompact", "copy.deepcopy", "mmaction.datasets.pipelines.augmentations.PoseCompact.", "mmaction.datasets.pipelines.augmentations.PoseCompact", "copy.deepcopy", "mmaction.datasets.pipelines.augmentations.PoseCompact.", "mmaction.datasets.pipelines.augmentations.PoseCompact", "copy.deepcopy", "mmaction.datasets.pipelines.augmentations.PoseCompact.", "mmaction.datasets.pipelines.augmentations.PoseCompact", "copy.deepcopy", "mmaction.datasets.pipelines.augmentations.PoseCompact.", "str"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "test_pose_compact", "(", ")", ":", "\n", "        ", "results", "=", "{", "}", "\n", "results", "[", "'img_shape'", "]", "=", "(", "100", ",", "100", ")", "\n", "fake_kp", "=", "np", ".", "zeros", "(", "[", "1", ",", "4", ",", "2", ",", "2", "]", ")", "\n", "fake_kp", "[", ":", ",", ":", ",", "0", "]", "=", "[", "10", ",", "10", "]", "\n", "fake_kp", "[", ":", ",", ":", ",", "1", "]", "=", "[", "90", ",", "90", "]", "\n", "results", "[", "'keypoint'", "]", "=", "fake_kp", "\n", "\n", "pose_compact", "=", "PoseCompact", "(", "\n", "padding", "=", "0", ",", "threshold", "=", "0", ",", "hw_ratio", "=", "None", ",", "allow_imgpad", "=", "False", ")", "\n", "inp", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "ret", "=", "pose_compact", "(", "inp", ")", "\n", "assert", "ret", "[", "'img_shape'", "]", "==", "(", "80", ",", "80", ")", "\n", "assert", "str", "(", "pose_compact", ")", "==", "(", "\n", "'PoseCompact(padding=0, threshold=0, hw_ratio=None, '", "\n", "'allow_imgpad=False)'", ")", "\n", "\n", "pose_compact", "=", "PoseCompact", "(", "\n", "padding", "=", "0.3", ",", "threshold", "=", "0", ",", "hw_ratio", "=", "None", ",", "allow_imgpad", "=", "False", ")", "\n", "inp", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "ret", "=", "pose_compact", "(", "inp", ")", "\n", "assert", "ret", "[", "'img_shape'", "]", "==", "(", "100", ",", "100", ")", "\n", "\n", "pose_compact", "=", "PoseCompact", "(", "\n", "padding", "=", "0.3", ",", "threshold", "=", "0", ",", "hw_ratio", "=", "None", ",", "allow_imgpad", "=", "True", ")", "\n", "inp", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "ret", "=", "pose_compact", "(", "inp", ")", "\n", "assert", "ret", "[", "'img_shape'", "]", "==", "(", "104", ",", "104", ")", "\n", "\n", "pose_compact", "=", "PoseCompact", "(", "\n", "padding", "=", "0", ",", "threshold", "=", "100", ",", "hw_ratio", "=", "None", ",", "allow_imgpad", "=", "False", ")", "\n", "inp", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "ret", "=", "pose_compact", "(", "inp", ")", "\n", "assert", "ret", "[", "'img_shape'", "]", "==", "(", "100", ",", "100", ")", "\n", "\n", "pose_compact", "=", "PoseCompact", "(", "\n", "padding", "=", "0", ",", "threshold", "=", "0", ",", "hw_ratio", "=", "0.75", ",", "allow_imgpad", "=", "True", ")", "\n", "inp", "=", "copy", ".", "deepcopy", "(", "results", ")", "\n", "ret", "=", "pose_compact", "(", "inp", ")", "\n", "assert", "ret", "[", "'img_shape'", "]", "==", "(", "80", ",", "106", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop": [[5, 42], ["numpy.array_equal", "base.check_crop.check_single_crop"], "function", ["None"], ["from", "collections", "import", "OrderedDict", ",", "defaultdict", "\n", "\n", "import", "mmcv", "\n", "import", "numpy", "as", "np", "\n", "import", "torch", "\n", "from", "mmcv", ".", "utils", "import", "print_log", "\n", "from", "torch", ".", "utils", ".", "data", "import", "Dataset", "\n", "\n", "from", ".", ".", "core", "import", "(", "mean_average_precision", ",", "mean_class_accuracy", ",", "\n", "mmit_mean_average_precision", ",", "top_k_accuracy", ")", "\n", "from", ".", "pipelines", "import", "Compose", "\n", "\n", "\n", "class", "BaseDataset", "(", "Dataset", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip": [[44, 59], ["numpy.shape", "range", "range", "numpy.any", "numpy.any", "numpy.fliplr", "numpy.transpose", "numpy.fliplr", "numpy.transpose"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_normalize": [[61, 70], ["result_imgs.copy", "numpy.testing.assert_array_almost_equal", "target_imgs[].copy"], "function", ["None"], ["data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_misc.TestQuadrupleOps.test_combine_quadruple": [[7, 13], ["mmaction.datasets.pipelines.augmentations._combine_quadruple"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._combine_quadruple"], ["    ", "@", "staticmethod", "\n", "def", "test_combine_quadruple", "(", ")", ":", "\n", "        ", "a", "=", "(", "0.1", ",", "0.1", ",", "0.5", ",", "0.5", ")", "\n", "b", "=", "(", "0.3", ",", "0.3", ",", "0.7", ",", "0.7", ")", "\n", "res", "=", "_combine_quadruple", "(", "a", ",", "b", ")", "\n", "assert", "res", "==", "(", "0.25", ",", "0.25", ",", "0.35", ",", "0.35", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_misc.TestQuadrupleOps.test_flip_quadruple": [[14, 19], ["mmaction.datasets.pipelines.augmentations._flip_quadruple"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._flip_quadruple"], ["", "@", "staticmethod", "\n", "def", "test_flip_quadruple", "(", ")", ":", "\n", "        ", "a", "=", "(", "0.1", ",", "0.1", ",", "0.5", ",", "0.5", ")", "\n", "res", "=", "_flip_quadruple", "(", "a", ")", "\n", "assert", "res", "==", "(", "0.4", ",", "0.1", ",", "0.5", ",", "0.5", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_audio.TestAudio.test_audio_amplify": [[10, 23], ["numpy.random.rand", "dict", "mmaction.datasets.pipelines.AudioAmplify", "mmaction.datasets.pipelines.AudioAmplify.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "mmaction.datasets.pipelines.AudioAmplify", "repr"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "test_audio_amplify", "(", ")", ":", "\n", "        ", "target_keys", "=", "[", "'audios'", ",", "'amplify_ratio'", "]", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# ratio should be float", "\n", "            ", "AudioAmplify", "(", "1", ")", "\n", "\n", "", "audio", "=", "(", "np", ".", "random", ".", "rand", "(", "8", ",", ")", ")", "\n", "results", "=", "dict", "(", "audios", "=", "audio", ")", "\n", "amplifier", "=", "AudioAmplify", "(", "1.5", ")", "\n", "results", "=", "amplifier", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "repr", "(", "amplifier", ")", "==", "(", "f'{amplifier.__class__.__name__}'", "\n", "f'(ratio={amplifier.ratio})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_audio.TestAudio.test_melspectrogram": [[25, 50], ["numpy.random.rand", "dict", "mmaction.datasets.pipelines.MelSpectrogram", "mmaction.datasets.pipelines.MelSpectrogram.", "mmcv.utils.assert_dict_has_keys", "numpy.random.rand", "dict", "mmaction.datasets.pipelines.MelSpectrogram", "mmaction.datasets.pipelines.MelSpectrogram.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "mmaction.datasets.pipelines.MelSpectrogram", "repr"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_melspectrogram", "(", ")", ":", "\n", "        ", "target_keys", "=", "[", "'audios'", "]", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# ratio should be float", "\n", "            ", "MelSpectrogram", "(", "window_size", "=", "12.5", ")", "\n", "", "audio", "=", "(", "np", ".", "random", ".", "rand", "(", "1", ",", "160000", ")", ")", "\n", "\n", "# test padding", "\n", "results", "=", "dict", "(", "audios", "=", "audio", ",", "sample_rate", "=", "16000", ")", "\n", "results", "[", "'num_clips'", "]", "=", "1", "\n", "results", "[", "'sample_rate'", "]", "=", "16000", "\n", "mel", "=", "MelSpectrogram", "(", ")", "\n", "results", "=", "mel", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "\n", "# test truncating", "\n", "audio", "=", "(", "np", ".", "random", ".", "rand", "(", "1", ",", "160000", ")", ")", "\n", "results", "=", "dict", "(", "audios", "=", "audio", ",", "sample_rate", "=", "16000", ")", "\n", "results", "[", "'num_clips'", "]", "=", "1", "\n", "results", "[", "'sample_rate'", "]", "=", "16000", "\n", "mel", "=", "MelSpectrogram", "(", "fixed_length", "=", "1", ")", "\n", "results", "=", "mel", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "repr", "(", "mel", ")", "==", "(", "f'{mel.__class__.__name__}'", "\n", "f'(window_size={mel.window_size}), '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_flip.TestFlip.test_flip": [[15, 136], ["list", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "numpy.array_equal", "list", "dict", "numpy.array", "numpy.array", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "list", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "list", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "numpy.testing.assert_array_almost_equal", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "numpy.testing.assert_array_almost_equal", "pytest.raises", "mmaction.datasets.pipelines.Flip", "numpy.random.rand", "id", "id", "numpy.shape", "numpy.shape", "numpy.random.rand", "base.check_flip", "id", "id", "numpy.shape", "numpy.shape", "numpy.arange().reshape().astype", "numpy.arange().reshape().astype", "x.reshape", "x.reshape", "base.check_flip", "base.check_flip", "id", "id", "numpy.shape", "numpy.shape", "numpy.random.rand", "base.check_flip", "id", "id", "numpy.shape", "numpy.shape", "repr", "numpy.random.rand", "numpy.array", "numpy.array", "pytest.raises", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "numpy.array().reshape", "numpy.array().reshape", "numpy.arange().reshape", "numpy.arange().reshape", "mmcv.iminvert", "numpy.array().reshape", "numpy.array", "numpy.array", "numpy.arange", "numpy.arange", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip"], ["    ", "@", "staticmethod", "\n", "def", "test_flip", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# direction must be in ['horizontal', 'vertical']", "\n", "            ", "Flip", "(", "direction", "=", "'vertically'", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'flip_direction'", ",", "'modality'", "]", "\n", "\n", "# do not flip imgs.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "copy", ".", "deepcopy", "(", "imgs", ")", ",", "modality", "=", "'RGB'", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "0", ",", "direction", "=", "'horizontal'", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "assert", "np", ".", "array_equal", "(", "imgs", ",", "results", "[", "'imgs'", "]", ")", "\n", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "np", ".", "shape", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "np", ".", "shape", "(", "imgs", ")", "\n", "\n", "# always flip imgs horizontally.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "copy", ".", "deepcopy", "(", "imgs", ")", ",", "modality", "=", "'RGB'", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "60", ",", "60", "]", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "60", ",", "60", "]", "]", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "1", ",", "direction", "=", "'horizontal'", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "if", "flip_results", "[", "'flip'", "]", "is", "True", ":", "\n", "            ", "assert", "check_flip", "(", "imgs", ",", "flip_results", "[", "'imgs'", "]", ",", "\n", "flip_results", "[", "'flip_direction'", "]", ")", "\n", "", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "np", ".", "shape", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "np", ".", "shape", "(", "imgs", ")", "\n", "\n", "# flip flow images horizontally", "\n", "imgs", "=", "[", "\n", "np", ".", "arange", "(", "16", ")", ".", "reshape", "(", "4", ",", "4", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "np", ".", "arange", "(", "16", ",", "32", ")", ".", "reshape", "(", "4", ",", "4", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "]", "\n", "results", "=", "dict", "(", "imgs", "=", "copy", ".", "deepcopy", "(", "imgs", ")", ",", "modality", "=", "'Flow'", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "1", ",", "direction", "=", "'horizontal'", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "imgs", "=", "[", "x", ".", "reshape", "(", "4", ",", "4", ",", "1", ")", "for", "x", "in", "imgs", "]", "\n", "flip_results", "[", "'imgs'", "]", "=", "[", "\n", "x", ".", "reshape", "(", "4", ",", "4", ",", "1", ")", "for", "x", "in", "flip_results", "[", "'imgs'", "]", "\n", "]", "\n", "if", "flip_results", "[", "'flip'", "]", "is", "True", ":", "\n", "            ", "assert", "check_flip", "(", "[", "imgs", "[", "0", "]", "]", ",", "\n", "[", "mmcv", ".", "iminvert", "(", "flip_results", "[", "'imgs'", "]", "[", "0", "]", ")", "]", ",", "\n", "flip_results", "[", "'flip_direction'", "]", ")", "\n", "assert", "check_flip", "(", "[", "imgs", "[", "1", "]", "]", ",", "[", "flip_results", "[", "'imgs'", "]", "[", "1", "]", "]", ",", "\n", "flip_results", "[", "'flip_direction'", "]", ")", "\n", "", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "np", ".", "shape", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "np", ".", "shape", "(", "imgs", ")", "\n", "\n", "# always flip imgs vertivally.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "copy", ".", "deepcopy", "(", "imgs", ")", ",", "modality", "=", "'RGB'", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "1", ",", "direction", "=", "'vertical'", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "if", "flip_results", "[", "'flip'", "]", "is", "True", ":", "\n", "            ", "assert", "check_flip", "(", "imgs", ",", "flip_results", "[", "'imgs'", "]", ",", "\n", "flip_results", "[", "'flip_direction'", "]", ")", "\n", "", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "np", ".", "shape", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "np", ".", "shape", "(", "imgs", ")", "\n", "\n", "assert", "repr", "(", "flip", ")", "==", "(", "f'{flip.__class__.__name__}'", "\n", "f'(flip_ratio={1}, direction=vertical, '", "\n", "f'flip_label_map={None}, lazy={False})'", ")", "\n", "\n", "# transform label for the flipped image with the specific label.", "\n", "_flip_label_map", "=", "{", "4", ":", "6", "}", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "\n", "# the label should be mapped.", "\n", "results", "=", "dict", "(", "imgs", "=", "copy", ".", "deepcopy", "(", "imgs", ")", ",", "modality", "=", "'RGB'", ",", "label", "=", "4", ")", "\n", "flip", "=", "Flip", "(", "\n", "flip_ratio", "=", "1", ",", "\n", "direction", "=", "'horizontal'", ",", "\n", "flip_label_map", "=", "_flip_label_map", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "results", "[", "'label'", "]", "==", "6", "\n", "\n", "# the label should not be mapped.", "\n", "results", "=", "dict", "(", "imgs", "=", "copy", ".", "deepcopy", "(", "imgs", ")", ",", "modality", "=", "'RGB'", ",", "label", "=", "3", ")", "\n", "flip", "=", "Flip", "(", "\n", "flip_ratio", "=", "1", ",", "\n", "direction", "=", "'horizontal'", ",", "\n", "flip_label_map", "=", "_flip_label_map", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "results", "[", "'label'", "]", "==", "3", "\n", "\n", "# flip the keypoints", "\n", "results", "=", "dict", "(", "\n", "keypoint", "=", "np", ".", "array", "(", "[", "[", "1", ",", "1", "]", ",", "[", "63", ",", "63", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", ",", "\n", "modality", "=", "'Pose'", ",", "\n", "img_shape", "=", "(", "64", ",", "64", ")", ")", "\n", "flip", "=", "Flip", "(", "\n", "flip_ratio", "=", "1", ",", "direction", "=", "'horizontal'", ",", "left_kp", "=", "[", "0", "]", ",", "right_kp", "=", "[", "1", "]", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "flip_results", "[", "'keypoint'", "]", "[", "0", ",", "0", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "63", "]", ",", "[", "63", ",", "1", "]", "]", ")", ")", "\n", "\n", "results", "=", "dict", "(", "\n", "keypoint", "=", "np", ".", "array", "(", "[", "[", "1", ",", "1", "]", ",", "[", "63", ",", "63", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", ",", "\n", "modality", "=", "'Pose'", ",", "\n", "img_shape", "=", "(", "64", ",", "64", ")", ")", "\n", "flip", "=", "Flip", "(", "\n", "flip_ratio", "=", "1", ",", "direction", "=", "'horizontal'", ",", "left_kp", "=", "[", "]", ",", "right_kp", "=", "[", "]", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "flip_results", "[", "'keypoint'", "]", "[", "0", ",", "0", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "63", ",", "1", "]", ",", "[", "1", ",", "63", "]", "]", ")", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "results", "=", "dict", "(", "\n", "keypoint", "=", "np", ".", "array", "(", "[", "[", "1", ",", "1", "]", ",", "[", "63", ",", "63", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", ",", "\n", "modality", "=", "'Pose'", ",", "\n", "img_shape", "=", "(", "64", ",", "64", ")", ")", "\n", "flip", "=", "Flip", "(", "\n", "flip_ratio", "=", "1", ",", "direction", "=", "'vertical'", ",", "left_kp", "=", "[", "]", ",", "right_kp", "=", "[", "]", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_imgaug.TestAugumentations.test_imgaug": [[12, 101], ["list", "dict", "mmaction.datasets.pipelines.Imgaug", "mmaction.datasets.pipelines.Imgaug.", "mmcv.utils.assert_dict_has_keys", "list", "dict", "mmaction.datasets.pipelines.Imgaug", "mmaction.datasets.pipelines.Imgaug.", "mmcv.utils.assert_dict_has_keys", "base.check_flip", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "iaa.Sequential", "list", "dict", "mmaction.datasets.pipelines.Imgaug", "mmaction.datasets.pipelines.Imgaug.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_almost_equal", "iaa.Sequential", "list", "dict", "iaa.Resize", "mmaction.datasets.pipelines.Imgaug", "mmaction.datasets.pipelines.Imgaug.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "mmaction.datasets.pipelines.Imgaug", "pytest.raises", "mmaction.datasets.pipelines.Imgaug", "pytest.raises", "mmaction.datasets.pipelines.Imgaug", "pytest.raises", "mmaction.datasets.pipelines.Imgaug", "pytest.raises", "mmaction.datasets.pipelines.Imgaug", "numpy.random.randint().astype", "numpy.random.rand().astype", "numpy.array", "numpy.array", "repr", "numpy.random.rand", "numpy.array", "repr", "numpy.random.rand", "repr", "numpy.array", "numpy.array", "iaa.Fliplr", "numpy.array", "iaa.CropToFixedSize", "dict", "numpy.random.randint", "numpy.random.rand", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip"], ["    ", "@", "staticmethod", "\n", "def", "test_imgaug", "(", ")", ":", "\n", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# transforms only support one string, 'default'", "\n", "            ", "Imgaug", "(", "transforms", "=", "'test'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# transforms only support string or list of dicts", "\n", "# or iaa.Augmenter object", "\n", "            ", "Imgaug", "(", "transforms", "=", "dict", "(", "type", "=", "'Rotate'", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# each dict must have a `type` key", "\n", "            ", "Imgaug", "(", "transforms", "=", "[", "dict", "(", "rotate", "=", "(", "-", "30", ",", "30", ")", ")", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AttributeError", ")", ":", "\n", "# `type` must be available in imgaug", "\n", "            ", "Imgaug", "(", "transforms", "=", "[", "dict", "(", "type", "=", "'BlaBla'", ")", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# `type` must be str or iaa available type", "\n", "            ", "Imgaug", "(", "transforms", "=", "[", "dict", "(", "type", "=", "CenterCrop", ")", "]", ")", "\n", "\n", "", "from", "imgaug", "import", "augmenters", "as", "iaa", "\n", "\n", "# check default configs", "\n", "target_keys", "=", "[", "'imgs'", ",", "'img_shape'", ",", "'modality'", "]", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "255", ",", "(", "1", ",", "64", ",", "64", ",", "3", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "default_imgaug", "=", "Imgaug", "(", "transforms", "=", "'default'", ")", "\n", "default_results", "=", "default_imgaug", "(", "results", ")", "\n", "assert_dict_has_keys", "(", "default_results", ",", "target_keys", ")", "\n", "assert", "default_results", "[", "'img_shape'", "]", "==", "(", "64", ",", "64", ")", "\n", "\n", "# check flip (both images and bboxes)", "\n", "target_keys", "=", "[", "'imgs'", ",", "'gt_bboxes'", ",", "'proposals'", ",", "'img_shape'", "]", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "1", ",", "64", ",", "64", ",", "3", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "results", "=", "dict", "(", "\n", "imgs", "=", "imgs", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "proposals", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "25", ",", "35", "]", "]", ")", ",", "\n", "img_shape", "=", "(", "64", ",", "64", ")", ",", "\n", "gt_bboxes", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "25", ",", "35", "]", "]", ")", ")", "\n", "imgaug_flip", "=", "Imgaug", "(", "transforms", "=", "[", "dict", "(", "type", "=", "'Fliplr'", ")", "]", ")", "\n", "flip_results", "=", "imgaug_flip", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "assert", "check_flip", "(", "imgs", ",", "flip_results", "[", "'imgs'", "]", ",", "'horizontal'", ")", "\n", "assert_array_almost_equal", "(", "flip_results", "[", "'gt_bboxes'", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "39", ",", "0", ",", "64", ",", "35", "]", "]", ")", ")", "\n", "assert_array_almost_equal", "(", "flip_results", "[", "'proposals'", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "39", ",", "0", ",", "64", ",", "35", "]", "]", ")", ")", "\n", "transforms", "=", "iaa", ".", "Sequential", "(", "[", "iaa", ".", "Fliplr", "(", ")", "]", ")", "\n", "assert", "repr", "(", "imgaug_flip", ")", "==", "f'Imgaug(transforms={transforms})'", "\n", "\n", "# check crop (both images and bboxes)", "\n", "target_keys", "=", "[", "'crop_bbox'", ",", "'gt_bboxes'", ",", "'imgs'", ",", "'img_shape'", "]", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "1", ",", "122", ",", "122", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "\n", "imgs", "=", "imgs", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "img_shape", "=", "(", "122", ",", "122", ")", ",", "\n", "gt_bboxes", "=", "np", ".", "array", "(", "[", "[", "1.5", ",", "2.5", ",", "110", ",", "64", "]", "]", ")", ")", "\n", "imgaug_center_crop", "=", "Imgaug", "(", "transforms", "=", "[", "\n", "dict", "(", "\n", "type", "=", "iaa", ".", "CropToFixedSize", ",", "\n", "width", "=", "100", ",", "\n", "height", "=", "100", ",", "\n", "position", "=", "'center'", ")", "\n", "]", ")", "\n", "crop_results", "=", "imgaug_center_crop", "(", "results", ")", "\n", "assert_dict_has_keys", "(", "crop_results", ",", "target_keys", ")", "\n", "assert_array_almost_equal", "(", "crop_results", "[", "'gt_bboxes'", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.", ",", "0.", ",", "99.", ",", "53.", "]", "]", ")", ")", "\n", "assert", "'proposals'", "not", "in", "results", "\n", "transforms", "=", "iaa", ".", "Sequential", "(", "\n", "[", "iaa", ".", "CropToFixedSize", "(", "width", "=", "100", ",", "height", "=", "100", ",", "position", "=", "'center'", ")", "]", ")", "\n", "assert", "repr", "(", "imgaug_center_crop", ")", "==", "f'Imgaug(transforms={transforms})'", "\n", "\n", "# check resize (images only)", "\n", "target_keys", "=", "[", "'imgs'", ",", "'img_shape'", "]", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "1", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "transforms", "=", "iaa", ".", "Resize", "(", "32", ")", "\n", "imgaug_resize", "=", "Imgaug", "(", "transforms", "=", "transforms", ")", "\n", "resize_results", "=", "imgaug_resize", "(", "results", ")", "\n", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "assert", "resize_results", "[", "'img_shape'", "]", "==", "(", "32", ",", "32", ")", "\n", "assert", "repr", "(", "imgaug_resize", ")", "==", "f'Imgaug(transforms={transforms})'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_color.TestColor.test_color_jitter": [[10, 61], ["list", "dict", "numpy.array", "numpy.array", "mmaction.datasets.pipelines.ColorJitter", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "mmaction.datasets.pipelines.ColorJitter.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.ones", "numpy.ones", "list", "dict", "mmaction.datasets.pipelines.ColorJitter", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "mmaction.datasets.pipelines.ColorJitter.", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "mmaction.datasets.pipelines.ColorJitter", "numpy.random.randint", "numpy.shape", "numpy.random.randint", "numpy.shape", "repr"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "test_color_jitter", "(", ")", ":", "\n", "        ", "imgs", "=", "list", "(", "\n", "np", ".", "random", ".", "randint", "(", "0", ",", "255", ",", "size", "=", "(", "3", ",", "112", ",", "112", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "\n", "eig_val", "=", "np", ".", "array", "(", "[", "55.46", ",", "4.794", ",", "1.148", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "eig_vec", "=", "np", ".", "array", "(", "[", "[", "-", "0.5675", ",", "0.7192", ",", "0.4009", "]", ",", "\n", "[", "-", "0.5808", ",", "-", "0.0045", ",", "-", "0.8140", "]", ",", "\n", "[", "-", "0.5836", ",", "-", "0.6948", ",", "0.4203", "]", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "color_jitter", "=", "ColorJitter", "(", ")", "\n", "assert_array_equal", "(", "color_jitter", ".", "eig_val", ",", "eig_val", ")", "\n", "assert_array_equal", "(", "color_jitter", ".", "eig_vec", ",", "eig_vec", ")", "\n", "assert", "color_jitter", ".", "alpha_std", "==", "0.1", "\n", "assert", "color_jitter", ".", "color_space_aug", "is", "False", "\n", "color_jitter_results", "=", "color_jitter", "(", "results", ")", "\n", "target_keys", "=", "[", "\n", "'imgs'", ",", "'eig_val'", ",", "'eig_vec'", ",", "'alpha_std'", ",", "'color_space_aug'", "\n", "]", "\n", "assert", "assert_dict_has_keys", "(", "color_jitter_results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "color_jitter_results", "[", "'imgs'", "]", ")", "==", "(", "3", ",", "112", ",", "112", ",", "3", ")", "\n", "assert_array_equal", "(", "color_jitter_results", "[", "'eig_val'", "]", ",", "eig_val", ")", "\n", "assert_array_equal", "(", "color_jitter_results", "[", "'eig_vec'", "]", ",", "eig_vec", ")", "\n", "assert", "color_jitter_results", "[", "'alpha_std'", "]", "==", "0.1", "\n", "assert", "color_jitter_results", "[", "'color_space_aug'", "]", "is", "False", "\n", "\n", "custom_eig_val", "=", "np", ".", "ones", "(", "3", ",", ")", "\n", "custom_eig_vec", "=", "np", ".", "ones", "(", "(", "3", ",", "3", ")", ")", "\n", "\n", "imgs", "=", "list", "(", "\n", "np", ".", "random", ".", "randint", "(", "0", ",", "255", ",", "size", "=", "(", "3", ",", "64", ",", "80", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "custom_color_jitter", "=", "ColorJitter", "(", "True", ",", "0.5", ",", "custom_eig_val", ",", "\n", "custom_eig_vec", ")", "\n", "assert_array_equal", "(", "color_jitter", ".", "eig_val", ",", "eig_val", ")", "\n", "assert_array_equal", "(", "color_jitter", ".", "eig_vec", ",", "eig_vec", ")", "\n", "assert", "custom_color_jitter", ".", "alpha_std", "==", "0.5", "\n", "assert", "custom_color_jitter", ".", "color_space_aug", "is", "True", "\n", "custom_color_jitter_results", "=", "custom_color_jitter", "(", "results", ")", "\n", "assert", "np", ".", "shape", "(", "custom_color_jitter_results", "[", "'imgs'", "]", ")", "==", "(", "3", ",", "64", ",", "80", ",", "3", ")", "\n", "assert_array_equal", "(", "custom_color_jitter_results", "[", "'eig_val'", "]", ",", "\n", "custom_eig_val", ")", "\n", "assert_array_equal", "(", "custom_color_jitter_results", "[", "'eig_vec'", "]", ",", "\n", "custom_eig_vec", ")", "\n", "assert", "custom_color_jitter_results", "[", "'alpha_std'", "]", "==", "0.5", "\n", "assert", "custom_color_jitter_results", "[", "'color_space_aug'", "]", "is", "True", "\n", "\n", "color_jitter", "=", "ColorJitter", "(", ")", "\n", "assert", "repr", "(", "color_jitter", ")", "==", "(", "f'{color_jitter.__class__.__name__}('", "\n", "f'color_space_aug={False}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_init_lazy": [[13, 44], ["dict", "_init_lazy_if_proper", "mmcv.utils.assert_dict_has_keys", "mmcv.utils.assert_dict_has_keys", "dict", "_init_lazy_if_proper", "mmcv.utils.assert_dict_has_keys", "mmcv.utils.assert_dict_has_keys", "dict", "_init_lazy_if_proper", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "dict", "_init_lazy_if_proper", "list", "dict", "numpy.random.randn"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.augmentations._init_lazy_if_proper"], ["    ", "@", "staticmethod", "\n", "def", "test_init_lazy", "(", ")", ":", "\n", "        ", "from", "mmaction", ".", "datasets", ".", "pipelines", ".", "augmentations", "import", "_init_lazy_if_proper", "# noqa: E501", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# use lazy operation but \"lazy\" not in results", "\n", "            ", "result", "=", "dict", "(", "lazy", "=", "dict", "(", ")", ",", "img_shape", "=", "[", "64", ",", "64", "]", ")", "\n", "_init_lazy_if_proper", "(", "result", ",", "False", ")", "\n", "\n", "", "lazy_keys", "=", "[", "\n", "'original_shape'", ",", "'crop_bbox'", ",", "'flip'", ",", "'flip_direction'", ",", "\n", "'interpolation'", "\n", "]", "\n", "\n", "# 'img_shape' not in results", "\n", "result", "=", "dict", "(", "imgs", "=", "list", "(", "np", ".", "random", ".", "randn", "(", "3", ",", "64", ",", "64", ",", "3", ")", ")", ")", "\n", "_init_lazy_if_proper", "(", "result", ",", "True", ")", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "[", "'imgs'", ",", "'lazy'", ",", "'img_shape'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "result", "[", "'lazy'", "]", ",", "lazy_keys", ")", "\n", "\n", "# 'img_shape' in results", "\n", "result", "=", "dict", "(", "img_shape", "=", "[", "64", ",", "64", "]", ")", "\n", "_init_lazy_if_proper", "(", "result", ",", "True", ")", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "[", "'lazy'", ",", "'img_shape'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "result", "[", "'lazy'", "]", ",", "lazy_keys", ")", "\n", "\n", "# do not use lazy operation", "\n", "result", "=", "dict", "(", "img_shape", "=", "[", "64", ",", "64", "]", ")", "\n", "_init_lazy_if_proper", "(", "result", ",", "False", ")", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "[", "'img_shape'", "]", ")", "\n", "assert", "'lazy'", "not", "in", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_random_crop_lazy": [[45, 102], ["list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.RandomCrop", "pytest.raises", "list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "repr", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_random_crop_lazy", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# size must be an int", "\n", "            ", "RandomCrop", "(", "size", "=", "(", "112", ",", "112", ")", ",", "lazy", "=", "True", ")", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# \"size > height\" or \"size > width\" is not allowed", "\n", "            ", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "320", ",", "lazy", "=", "True", ")", "\n", "random_crop", "(", "results", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", ",", "'lazy'", "]", "\n", "\n", "# General case", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "224", ",", "lazy", "=", "True", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "random_crop_result", "[", "'imgs'", "]", ")", "\n", "random_crop_result_fuse", "=", "Fuse", "(", ")", "(", "random_crop_result", ")", "\n", "assert", "'lazy'", "not", "in", "random_crop_result_fuse", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result_fuse", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "224", "\n", "\n", "# Test the case that no need for cropping", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "224", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "224", ",", "lazy", "=", "True", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "random_crop_result", "[", "'imgs'", "]", ")", "\n", "random_crop_result_fuse", "=", "Fuse", "(", ")", "(", "random_crop_result", ")", "\n", "assert", "'lazy'", "not", "in", "random_crop_result_fuse", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result_fuse", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "224", "\n", "\n", "# Test the one-side-equal case", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "225", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "224", ",", "lazy", "=", "True", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "random_crop_result", "[", "'imgs'", "]", ")", "\n", "random_crop_result_fuse", "=", "Fuse", "(", ")", "(", "random_crop_result", ")", "\n", "assert", "'lazy'", "not", "in", "random_crop_result_fuse", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result_fuse", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "224", "\n", "\n", "assert", "repr", "(", "random_crop", ")", "==", "(", "f'{random_crop.__class__.__name__}'", "\n", "f'(size={224}, lazy={True})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_random_resized_crop_lazy": [[104, 152], ["list", "dict", "mmaction.datasets.pipelines.RandomResizedCrop", "mmaction.datasets.pipelines.RandomResizedCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "mmaction.datasets.pipelines.RandomResizedCrop", "numpy.random.rand", "dict", "mmaction.datasets.pipelines.RandomResizedCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "numpy.random.rand", "pytest.raises", "mmaction.datasets.pipelines.RandomResizedCrop", "mmaction.datasets.pipelines.RandomResizedCrop.", "pytest.raises", "mmaction.datasets.pipelines.RandomResizedCrop", "mmaction.datasets.pipelines.RandomResizedCrop.", "id", "id", "mmaction.datasets.pipelines.Fuse", "repr", "id", "id", "mmaction.datasets.pipelines.Fuse"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_random_resized_crop_lazy", "(", ")", ":", "\n", "\n", "        ", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", ",", "'lazy'", "]", "\n", "# There will be a slight difference because of rounding", "\n", "eps", "=", "0.01", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# area_range[0] > area_range[1], which is wrong", "\n", "            ", "random_crop", "=", "RandomResizedCrop", "(", "area_range", "=", "(", "0.9", ",", "0.7", ")", ",", "lazy", "=", "True", ")", "\n", "random_crop", "(", "results", ")", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# 0 > area_range[0] and area_range[1] > 1, which is wrong", "\n", "            ", "random_crop", "=", "RandomResizedCrop", "(", "\n", "aspect_ratio_range", "=", "(", "-", "0.1", ",", "2.0", ")", ",", "lazy", "=", "True", ")", "\n", "random_crop", "(", "results", ")", "\n", "\n", "", "random_crop", "=", "RandomResizedCrop", "(", "lazy", "=", "True", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "random_crop_result", "[", "'imgs'", "]", ")", "\n", "random_crop_result_fuse", "=", "Fuse", "(", ")", "(", "random_crop_result", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "(", "(", "0.08", "-", "eps", "<=", "h", "*", "w", "/", "256", "/", "341", ")", "\n", "and", "(", "h", "*", "w", "/", "256", "/", "341", "<=", "1", "+", "eps", ")", ")", "\n", "assert", "(", "3.", "/", "4.", "-", "eps", "<=", "h", "/", "w", ")", "and", "(", "h", "/", "w", "-", "eps", "<=", "4.", "/", "3.", ")", "\n", "assert", "repr", "(", "random_crop", ")", "==", "(", "f'{random_crop.__class__.__name__}'", "\n", "f'(area_range={(0.08, 1.0)}, '", "\n", "f'aspect_ratio_range={(3 / 4, 4 / 3)}, '", "\n", "f'lazy={True})'", ")", "\n", "\n", "random_crop", "=", "RandomResizedCrop", "(", "\n", "area_range", "=", "(", "0.9", ",", "0.9", ")", ",", "aspect_ratio_range", "=", "(", "10.0", ",", "10.1", ")", ",", "lazy", "=", "True", ")", "\n", "# Test fallback cases by very big area range", "\n", "imgs", "=", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "random_crop_result", "[", "'imgs'", "]", ")", "\n", "random_crop_result_fuse", "=", "Fuse", "(", ")", "(", "random_crop_result", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "256", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_multi_scale_crop_lazy": [[153, 240], ["list", "dict", "dict", "mmaction.datasets.pipelines.MultiScaleCrop", "mmaction.datasets.pipelines.MultiScaleCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "dict", "mmaction.datasets.pipelines.MultiScaleCrop", "mmaction.datasets.pipelines.MultiScaleCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "dict", "mmaction.datasets.pipelines.MultiScaleCrop", "mmaction.datasets.pipelines.MultiScaleCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "repr"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_multi_scale_crop_lazy", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# input_size must be int or tuple of int", "\n", "            ", "MultiScaleCrop", "(", "0.5", ",", "lazy", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# input_size must be int or tuple of int", "\n", "            ", "MultiScaleCrop", "(", "'224'", ",", "lazy", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# input_size must be int or tuple of int", "\n", "            ", "MultiScaleCrop", "(", "[", "224", ",", "224", "]", ",", "lazy", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# scales must be tuple.", "\n", "            ", "MultiScaleCrop", "(", "\n", "224", ",", "scales", "=", "[", "\n", "1", ",", "\n", "]", ",", "lazy", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# num_fix_crops must be in [5, 13]", "\n", "            ", "MultiScaleCrop", "(", "224", ",", "num_fixed_crops", "=", "6", ",", "lazy", "=", "True", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", ",", "'scales'", "]", "\n", "\n", "# MultiScaleCrop with normal crops.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "config", "=", "dict", "(", "\n", "input_size", "=", "224", ",", "\n", "scales", "=", "(", "1", ",", "0.8", ")", ",", "\n", "random_crop", "=", "False", ",", "\n", "max_wh_scale_gap", "=", "0", ",", "\n", "lazy", "=", "True", ")", "\n", "multi_scale_crop", "=", "MultiScaleCrop", "(", "**", "config", ")", "\n", "multi_scale_crop_result", "=", "multi_scale_crop", "(", "results", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "multi_scale_crop_result", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_scale_crop_result", ",", "target_keys", ")", "\n", "multi_scale_crop_result_fuse", "=", "Fuse", "(", ")", "(", "multi_scale_crop_result", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_scale_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "multi_scale_crop_result", "[", "'crop_bbox'", "]", ")", "\n", "assert", "multi_scale_crop_result_fuse", "[", "'img_shape'", "]", "in", "[", "(", "256", ",", "256", ")", ",", "\n", "(", "204", ",", "204", ")", "]", "\n", "\n", "# MultiScaleCrop with more fixed crops.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "config", "=", "dict", "(", "\n", "input_size", "=", "224", ",", "\n", "scales", "=", "(", "1", ",", "0.8", ")", ",", "\n", "random_crop", "=", "False", ",", "\n", "max_wh_scale_gap", "=", "0", ",", "\n", "num_fixed_crops", "=", "13", ",", "\n", "lazy", "=", "True", ")", "\n", "multi_scale_crop", "=", "MultiScaleCrop", "(", "**", "config", ")", "\n", "multi_scale_crop_result", "=", "multi_scale_crop", "(", "results", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "multi_scale_crop_result", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_scale_crop_result", ",", "target_keys", ")", "\n", "multi_scale_crop_result_fuse", "=", "Fuse", "(", ")", "(", "multi_scale_crop_result", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_scale_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "multi_scale_crop_result", "[", "'crop_bbox'", "]", ")", "\n", "assert", "multi_scale_crop_result_fuse", "[", "'img_shape'", "]", "in", "[", "(", "256", ",", "256", ")", ",", "\n", "(", "204", ",", "204", ")", "]", "\n", "\n", "# MultiScaleCrop with random crop.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "config", "=", "dict", "(", "\n", "input_size", "=", "224", ",", "\n", "scales", "=", "(", "1", ",", "0.8", ")", ",", "\n", "random_crop", "=", "True", ",", "\n", "max_wh_scale_gap", "=", "0", ",", "\n", "lazy", "=", "True", ")", "\n", "multi_scale_crop", "=", "MultiScaleCrop", "(", "**", "config", ")", "\n", "multi_scale_crop_result", "=", "multi_scale_crop", "(", "results", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "multi_scale_crop_result", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_scale_crop_result", ",", "target_keys", ")", "\n", "multi_scale_crop_result_fuse", "=", "Fuse", "(", ")", "(", "multi_scale_crop_result", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_scale_crop_result_fuse", "[", "'imgs'", "]", ",", "\n", "multi_scale_crop_result", "[", "'crop_bbox'", "]", ")", "\n", "assert", "(", "multi_scale_crop_result_fuse", "[", "'img_shape'", "]", "in", "[", "(", "256", ",", "256", ")", ",", "\n", "(", "204", ",", "204", ")", "]", ")", "\n", "\n", "assert", "repr", "(", "multi_scale_crop", ")", "==", "(", "\n", "f'{multi_scale_crop.__class__.__name__}'", "\n", "f'(input_size={(224, 224)}, scales={(1, 0.8)}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_resize_lazy": [[244, 297], ["list", "dict", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "list", "dict", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "list", "dict", "mmaction.datasets.pipelines.Resize", "mmaction.datasets.pipelines.Resize.", "mmcv.utils.assert_dict_has_keys", "numpy.all", "pytest.raises", "mmaction.datasets.pipelines.Resize", "pytest.raises", "mmaction.datasets.pipelines.Resize", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "repr", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_resize_lazy", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# scale must be positive", "\n", "            ", "Resize", "(", "-", "0.5", ",", "lazy", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# scale must be tuple of int", "\n", "            ", "Resize", "(", "'224'", ",", "lazy", "=", "True", ")", "\n", "\n", "", "target_keys", "=", "[", "\n", "'imgs'", ",", "'img_shape'", ",", "'keep_ratio'", ",", "'scale_factor'", ",", "'modality'", "\n", "]", "\n", "\n", "# scale with -1 to indicate np.inf", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "-", "1", ",", "256", ")", ",", "keep_ratio", "=", "True", ",", "lazy", "=", "True", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "resize_results", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "resize_results_fuse", "=", "Fuse", "(", ")", "(", "resize_results", ")", "\n", "assert", "np", ".", "all", "(", "resize_results_fuse", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", "341", "/", "320", ",", "256", "/", "240", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results_fuse", "[", "'img_shape'", "]", "==", "(", "256", ",", "341", ")", "\n", "\n", "# scale with a normal tuple (320, 320) to indicate np.inf", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "320", ",", "320", ")", ",", "keep_ratio", "=", "False", ",", "lazy", "=", "True", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "resize_results", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "resize_results_fuse", "=", "Fuse", "(", ")", "(", "resize_results", ")", "\n", "assert", "np", ".", "all", "(", "resize_results_fuse", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", "1", ",", "320", "/", "240", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results_fuse", "[", "'img_shape'", "]", "==", "(", "320", ",", "320", ")", "\n", "\n", "# scale with a normal tuple (341, 256) to indicate np.inf", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "resize", "=", "Resize", "(", "scale", "=", "(", "341", ",", "256", ")", ",", "keep_ratio", "=", "False", ",", "lazy", "=", "True", ")", "\n", "resize_results", "=", "resize", "(", "results", ")", "\n", "assert", "id", "(", "imgs", ")", "==", "id", "(", "resize_results", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "resize_results", ",", "target_keys", ")", "\n", "resize_results_fuse", "=", "Fuse", "(", ")", "(", "resize_results", ")", "\n", "assert", "np", ".", "all", "(", "resize_results_fuse", "[", "'scale_factor'", "]", "==", "np", ".", "array", "(", "\n", "[", "341", "/", "320", ",", "256", "/", "240", "]", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "assert", "resize_results_fuse", "[", "'img_shape'", "]", "==", "(", "256", ",", "341", ")", "\n", "\n", "assert", "repr", "(", "resize", ")", "==", "(", "f'{resize.__class__.__name__ }'", "\n", "f'(scale={(341, 256)}, keep_ratio={False}, '", "+", "\n", "f'interpolation=bilinear, lazy={True})'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_flip_lazy": [[298, 347], ["list", "list.copy", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "numpy.equal().all", "list", "list.copy", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "base.check_flip", "list", "list.copy", "dict", "mmaction.datasets.pipelines.Flip", "mmaction.datasets.pipelines.Flip.", "mmcv.utils.assert_dict_has_keys", "base.check_flip", "pytest.raises", "mmaction.datasets.pipelines.Flip", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "id", "id", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "id", "id", "numpy.random.rand", "id", "id", "mmaction.datasets.pipelines.Fuse", "id", "id", "repr", "numpy.equal"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_flip"], ["", "@", "staticmethod", "\n", "def", "test_flip_lazy", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "            ", "Flip", "(", "direction", "=", "'vertically'", ",", "lazy", "=", "True", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'flip_direction'", ",", "'modality'", "]", "\n", "\n", "# do not flip imgs.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "imgs_tmp", "=", "imgs", ".", "copy", "(", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs_tmp", ",", "modality", "=", "'RGB'", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "0", ",", "direction", "=", "'horizontal'", ",", "lazy", "=", "True", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "id", "(", "imgs_tmp", ")", "==", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "flip_results_fuse", "=", "Fuse", "(", ")", "(", "flip_results", ")", "\n", "assert", "np", ".", "equal", "(", "imgs", ",", "results", "[", "'imgs'", "]", ")", ".", "all", "(", ")", "\n", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "flip_results_fuse", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "==", "(", "64", ",", "64", ",", "3", ")", "\n", "\n", "# always flip imgs horizontally.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "imgs_tmp", "=", "imgs", ".", "copy", "(", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs_tmp", ",", "modality", "=", "'RGB'", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "1", ",", "direction", "=", "'horizontal'", ",", "lazy", "=", "True", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "id", "(", "imgs_tmp", ")", "==", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "flip_results_fuse", "=", "Fuse", "(", ")", "(", "flip_results", ")", "\n", "assert", "check_flip", "(", "imgs", ",", "flip_results", "[", "'imgs'", "]", ",", "\n", "flip_results", "[", "'flip_direction'", "]", ")", "\n", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "flip_results_fuse", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "==", "(", "64", ",", "64", ",", "3", ")", "\n", "\n", "# always flip imgs vertivally.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "64", ",", "64", ",", "3", ")", ")", "\n", "imgs_tmp", "=", "imgs", ".", "copy", "(", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs_tmp", ",", "modality", "=", "'RGB'", ")", "\n", "flip", "=", "Flip", "(", "flip_ratio", "=", "1", ",", "direction", "=", "'vertical'", ",", "lazy", "=", "True", ")", "\n", "flip_results", "=", "flip", "(", "results", ")", "\n", "assert", "id", "(", "imgs_tmp", ")", "==", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "\n", "assert", "assert_dict_has_keys", "(", "flip_results", ",", "target_keys", ")", "\n", "flip_results_fuse", "=", "Fuse", "(", ")", "(", "flip_results", ")", "\n", "assert", "check_flip", "(", "imgs", ",", "flip_results", "[", "'imgs'", "]", ",", "\n", "flip_results", "[", "'flip_direction'", "]", ")", "\n", "assert", "id", "(", "flip_results", "[", "'imgs'", "]", ")", "==", "id", "(", "results", "[", "'imgs'", "]", ")", "\n", "assert", "flip_results_fuse", "[", "'imgs'", "]", "[", "0", "]", ".", "shape", "==", "(", "64", ",", "64", ",", "3", ")", "\n", "\n", "assert", "repr", "(", "flip", ")", "==", "(", "f'{flip.__class__.__name__}'", "\n", "f'(flip_ratio={1}, direction=vertical, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_lazy.TestLazy.test_center_crop_lazy": [[350, 380], ["list", "dict", "mmaction.datasets.pipelines.CenterCrop", "mmaction.datasets.pipelines.CenterCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "numpy.all", "pytest.raises", "mmaction.datasets.pipelines.CenterCrop", "pytest.raises", "mmaction.datasets.pipelines.CenterCrop", "pytest.raises", "mmaction.datasets.pipelines.CenterCrop", "numpy.random.rand", "mmaction.datasets.pipelines.Fuse", "repr", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_center_crop_lazy", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "CenterCrop", "(", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "CenterCrop", "(", "'224'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "CenterCrop", "(", "[", "224", ",", "224", "]", ")", "\n", "\n", "# center crop with crop_size 224", "\n", "", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "center_crop", "=", "CenterCrop", "(", "crop_size", "=", "224", ",", "lazy", "=", "True", ")", "\n", "center_crop_results", "=", "center_crop", "(", "results", ")", "\n", "\n", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "assert", "assert_dict_has_keys", "(", "center_crop_results", ",", "target_keys", ")", "\n", "center_crop_results_fuse", "=", "Fuse", "(", ")", "(", "center_crop_results", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "center_crop_results_fuse", "[", "'imgs'", "]", ",", "\n", "center_crop_results", "[", "'crop_bbox'", "]", ")", "\n", "assert", "np", ".", "all", "(", "center_crop_results_fuse", "[", "'crop_bbox'", "]", "==", "np", ".", "array", "(", "\n", "[", "48", ",", "8", ",", "272", ",", "232", "]", ")", ")", "\n", "assert", "center_crop_results_fuse", "[", "'img_shape'", "]", "==", "(", "224", ",", "224", ")", "\n", "\n", "assert", "repr", "(", "center_crop", ")", "==", "(", "f'{center_crop.__class__.__name__}'", "\n", "f'(crop_size={(224, 224)}, lazy={True})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_random_crop": [[13, 65], ["list", "dict", "mmaction.datasets.pipelines.RandomCrop", "numpy.array", "numpy.array", "numpy.array().reshape", "mmaction.datasets.pipelines.RandomCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.RandomCrop", "pytest.raises", "list", "dict", "mmaction.datasets.pipelines.RandomCrop", "mmaction.datasets.pipelines.RandomCrop.", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "repr", "numpy.random.rand", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["    ", "@", "staticmethod", "\n", "def", "test_random_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# size must be an int", "\n", "            ", "RandomCrop", "(", "size", "=", "(", "112", ",", "112", ")", ")", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# \"size > height\" or \"size > width\" is not allowed", "\n", "            ", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "320", ")", "\n", "random_crop", "(", "results", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "\n", "# General case", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "224", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "340", ",", "224", "]", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "340", ",", "224", "]", "]", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "160", ",", "120", "]", ",", "[", "160", ",", "120", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "results", "[", "'keypoint'", "]", "=", "kp", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "224", "\n", "\n", "# Test the case that no need for cropping", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "224", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "224", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "224", "\n", "\n", "# Test the one-side-equal case", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "225", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop", "=", "RandomCrop", "(", "size", "=", "224", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "224", "\n", "\n", "assert", "repr", "(", "random_crop", ")", "==", "(", "f'{random_crop.__class__.__name__}'", "\n", "f'(size={224}, lazy={False})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_random_resized_crop": [[67, 120], ["list", "dict", "numpy.array", "numpy.array", "numpy.array().reshape", "mmaction.datasets.pipelines.RandomResizedCrop", "mmaction.datasets.pipelines.RandomResizedCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "mmaction.datasets.pipelines.RandomResizedCrop", "list", "dict", "mmaction.datasets.pipelines.RandomResizedCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.RandomResizedCrop", "pytest.raises", "mmaction.datasets.pipelines.RandomResizedCrop", "numpy.random.rand", "pytest.raises", "mmaction.datasets.pipelines.RandomResizedCrop", "mmaction.datasets.pipelines.RandomResizedCrop.", "pytest.raises", "mmaction.datasets.pipelines.RandomResizedCrop", "mmaction.datasets.pipelines.RandomResizedCrop.", "repr", "numpy.random.rand", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_random_resized_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# area_range must be a tuple of float", "\n", "            ", "RandomResizedCrop", "(", "area_range", "=", "0.5", ")", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# aspect_ratio_range must be a tuple of float", "\n", "            ", "RandomResizedCrop", "(", "area_range", "=", "(", "0.08", ",", "1.0", ")", ",", "aspect_ratio_range", "=", "0.1", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "# There will be a slight difference because of rounding", "\n", "eps", "=", "0.01", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "340", ",", "256", "]", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "340", ",", "256", "]", "]", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "160", ",", "120", "]", ",", "[", "160", ",", "120", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "results", "[", "'keypoint'", "]", "=", "kp", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# area_range[0] > area_range[1], which is wrong", "\n", "            ", "random_crop", "=", "RandomResizedCrop", "(", "area_range", "=", "(", "0.9", ",", "0.7", ")", ")", "\n", "random_crop", "(", "results", ")", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# 0 > area_range[0] and area_range[1] > 1, which is wrong", "\n", "            ", "random_crop", "=", "RandomResizedCrop", "(", "aspect_ratio_range", "=", "(", "-", "0.1", ",", "2.0", ")", ")", "\n", "random_crop", "(", "results", ")", "\n", "\n", "", "random_crop", "=", "RandomResizedCrop", "(", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "(", "(", "0.08", "-", "eps", "<=", "h", "*", "w", "/", "256", "/", "341", ")", "\n", "and", "(", "h", "*", "w", "/", "256", "/", "341", "<=", "1", "+", "eps", ")", ")", "\n", "assert", "(", "3.", "/", "4.", "-", "eps", "<=", "h", "/", "w", ")", "and", "(", "h", "/", "w", "-", "eps", "<=", "4.", "/", "3.", ")", "\n", "assert", "repr", "(", "random_crop", ")", "==", "(", "f'{random_crop.__class__.__name__}'", "\n", "f'(area_range={(0.08, 1.0)}, '", "\n", "f'aspect_ratio_range={(3 / 4, 4 / 3)}, '", "\n", "f'lazy={False})'", ")", "\n", "\n", "random_crop", "=", "RandomResizedCrop", "(", "\n", "area_range", "=", "(", "0.9", ",", "0.9", ")", ",", "aspect_ratio_range", "=", "(", "10.0", ",", "10.1", ")", ")", "\n", "# Test fallback cases by very big area range", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "random_crop_result", "=", "random_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "random_crop_result", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "random_crop_result", "[", "'imgs'", "]", ",", "\n", "results", "[", "'crop_bbox'", "]", ")", "\n", "h", ",", "w", "=", "random_crop_result", "[", "'img_shape'", "]", "\n", "assert", "h", "==", "w", "==", "256", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_multi_scale_crop": [[121, 203], ["list", "dict", "numpy.array", "numpy.array", "numpy.array().reshape", "dict", "mmaction.datasets.pipelines.MultiScaleCrop", "mmaction.datasets.pipelines.MultiScaleCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "dict", "mmaction.datasets.pipelines.MultiScaleCrop", "mmaction.datasets.pipelines.MultiScaleCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "dict", "mmaction.datasets.pipelines.MultiScaleCrop", "mmaction.datasets.pipelines.MultiScaleCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiScaleCrop", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "repr", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_multi_scale_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# input_size must be int or tuple of int", "\n", "            ", "MultiScaleCrop", "(", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# input_size must be int or tuple of int", "\n", "            ", "MultiScaleCrop", "(", "'224'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# input_size must be int or tuple of int", "\n", "            ", "MultiScaleCrop", "(", "[", "224", ",", "224", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# scales must be tuple.", "\n", "            ", "MultiScaleCrop", "(", "\n", "224", ",", "scales", "=", "[", "\n", "1", ",", "\n", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# num_fix_crops must be in [5, 13]", "\n", "            ", "MultiScaleCrop", "(", "224", ",", "num_fixed_crops", "=", "6", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", ",", "'scales'", "]", "\n", "\n", "# MultiScaleCrop with normal crops.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "results", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "340", ",", "256", "]", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "340", ",", "256", "]", "]", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "160", ",", "120", "]", ",", "[", "160", ",", "120", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "results", "[", "'keypoint'", "]", "=", "kp", "\n", "config", "=", "dict", "(", "\n", "input_size", "=", "224", ",", "\n", "scales", "=", "(", "1", ",", "0.8", ")", ",", "\n", "random_crop", "=", "False", ",", "\n", "max_wh_scale_gap", "=", "0", ")", "\n", "multi_scale_crop", "=", "MultiScaleCrop", "(", "**", "config", ")", "\n", "multi_scale_crop_results", "=", "multi_scale_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_scale_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_scale_crop_results", "[", "'imgs'", "]", ",", "\n", "multi_scale_crop_results", "[", "'crop_bbox'", "]", ")", "\n", "assert", "multi_scale_crop_results", "[", "'img_shape'", "]", "in", "[", "(", "256", ",", "256", ")", ",", "\n", "(", "204", ",", "204", ")", "]", "\n", "\n", "# MultiScaleCrop with more fixed crops.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "config", "=", "dict", "(", "\n", "input_size", "=", "224", ",", "\n", "scales", "=", "(", "1", ",", "0.8", ")", ",", "\n", "random_crop", "=", "False", ",", "\n", "max_wh_scale_gap", "=", "0", ",", "\n", "num_fixed_crops", "=", "13", ")", "\n", "multi_scale_crop", "=", "MultiScaleCrop", "(", "**", "config", ")", "\n", "multi_scale_crop_results", "=", "multi_scale_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_scale_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_scale_crop_results", "[", "'imgs'", "]", ",", "\n", "multi_scale_crop_results", "[", "'crop_bbox'", "]", ")", "\n", "assert", "multi_scale_crop_results", "[", "'img_shape'", "]", "in", "[", "(", "256", ",", "256", ")", ",", "\n", "(", "204", ",", "204", ")", "]", "\n", "\n", "# MultiScaleCrop with random crop.", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "config", "=", "dict", "(", "\n", "input_size", "=", "224", ",", "\n", "scales", "=", "(", "1", ",", "0.8", ")", ",", "\n", "random_crop", "=", "True", ",", "\n", "max_wh_scale_gap", "=", "0", ")", "\n", "multi_scale_crop", "=", "MultiScaleCrop", "(", "**", "config", ")", "\n", "multi_scale_crop_results", "=", "multi_scale_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_scale_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_scale_crop_results", "[", "'imgs'", "]", ",", "\n", "multi_scale_crop_results", "[", "'crop_bbox'", "]", ")", "\n", "assert", "(", "multi_scale_crop_results", "[", "'img_shape'", "]", "in", "[", "(", "256", ",", "256", ")", ",", "\n", "(", "204", ",", "204", ")", "]", ")", "\n", "\n", "assert", "repr", "(", "multi_scale_crop", ")", "==", "(", "\n", "f'{multi_scale_crop.__class__.__name__}'", "\n", "f'(input_size={(224, 224)}, scales={(1, 0.8)}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_center_crop": [[207, 242], ["list", "dict", "numpy.array().reshape", "numpy.array", "numpy.array", "mmaction.datasets.pipelines.CenterCrop", "mmaction.datasets.pipelines.CenterCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "numpy.all", "numpy.all", "pytest.raises", "mmaction.datasets.pipelines.CenterCrop", "pytest.raises", "mmaction.datasets.pipelines.CenterCrop", "pytest.raises", "mmaction.datasets.pipelines.CenterCrop", "numpy.random.rand", "repr", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_center_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "CenterCrop", "(", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "CenterCrop", "(", "'224'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "CenterCrop", "(", "[", "224", ",", "224", "]", ")", "\n", "\n", "# center crop with crop_size 224", "\n", "# add kps in test_center_crop", "\n", "", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "160", ",", "120", "]", ",", "[", "160", ",", "120", "]", "]", ")", ".", "reshape", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", "\n", "results", "[", "'keypoint'", "]", "=", "kp", "\n", "\n", "results", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "320", ",", "240", "]", "]", ")", "\n", "results", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "320", ",", "240", "]", "]", ")", "\n", "center_crop", "=", "CenterCrop", "(", "crop_size", "=", "224", ")", "\n", "center_crop_results", "=", "center_crop", "(", "results", ")", "\n", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", ",", "'keypoint'", "]", "\n", "assert", "assert_dict_has_keys", "(", "center_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "center_crop_results", "[", "'imgs'", "]", ",", "\n", "center_crop_results", "[", "'crop_bbox'", "]", ")", "\n", "assert", "np", ".", "all", "(", "\n", "center_crop_results", "[", "'crop_bbox'", "]", "==", "np", ".", "array", "(", "[", "48", ",", "8", ",", "272", ",", "232", "]", ")", ")", "\n", "assert", "center_crop_results", "[", "'img_shape'", "]", "==", "(", "224", ",", "224", ")", "\n", "assert", "np", ".", "all", "(", "center_crop_results", "[", "'keypoint'", "]", "==", "112", ")", "\n", "\n", "assert", "repr", "(", "center_crop", ")", "==", "(", "f'{center_crop.__class__.__name__}'", "\n", "f'(crop_size={(224, 224)}, lazy={False})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_three_crop": [[244, 281], ["list", "dict", "mmaction.datasets.pipelines.ThreeCrop", "mmaction.datasets.pipelines.ThreeCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "list", "dict", "mmaction.datasets.pipelines.ThreeCrop", "mmaction.datasets.pipelines.ThreeCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.ThreeCrop", "pytest.raises", "mmaction.datasets.pipelines.ThreeCrop", "pytest.raises", "mmaction.datasets.pipelines.ThreeCrop", "numpy.random.rand", "numpy.random.rand", "repr"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_three_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "ThreeCrop", "(", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "ThreeCrop", "(", "'224'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "ThreeCrop", "(", "[", "224", ",", "224", "]", ")", "\n", "\n", "# three crop with crop_size 120", "\n", "", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "120", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "three_crop", "=", "ThreeCrop", "(", "crop_size", "=", "120", ")", "\n", "three_crop_results", "=", "three_crop", "(", "results", ")", "\n", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "assert", "assert_dict_has_keys", "(", "three_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "three_crop_results", "[", "'imgs'", "]", ",", "\n", "three_crop_results", "[", "'crop_bbox'", "]", ",", "3", ")", "\n", "assert", "three_crop_results", "[", "'img_shape'", "]", "==", "(", "120", ",", "120", ")", "\n", "\n", "# three crop with crop_size 224", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "224", ",", "224", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "three_crop", "=", "ThreeCrop", "(", "crop_size", "=", "224", ")", "\n", "three_crop_results", "=", "three_crop", "(", "results", ")", "\n", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "assert", "assert_dict_has_keys", "(", "three_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "three_crop_results", "[", "'imgs'", "]", ",", "\n", "three_crop_results", "[", "'crop_bbox'", "]", ",", "3", ")", "\n", "assert", "three_crop_results", "[", "'img_shape'", "]", "==", "(", "224", ",", "224", ")", "\n", "\n", "assert", "repr", "(", "three_crop", ")", "==", "(", "f'{three_crop.__class__.__name__}'", "\n", "f'(crop_size={(224, 224)})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_ten_crop": [[283, 309], ["list", "dict", "mmaction.datasets.pipelines.TenCrop", "mmaction.datasets.pipelines.TenCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.TenCrop", "pytest.raises", "mmaction.datasets.pipelines.TenCrop", "pytest.raises", "mmaction.datasets.pipelines.TenCrop", "numpy.random.rand", "repr"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_ten_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "TenCrop", "(", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "TenCrop", "(", "'224'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "TenCrop", "(", "[", "224", ",", "224", "]", ")", "\n", "\n", "# ten crop with crop_size 256", "\n", "", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "256", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "ten_crop", "=", "TenCrop", "(", "crop_size", "=", "224", ")", "\n", "ten_crop_results", "=", "ten_crop", "(", "results", ")", "\n", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "assert", "assert_dict_has_keys", "(", "ten_crop_results", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "ten_crop_results", "[", "'imgs'", "]", ",", "\n", "ten_crop_results", "[", "'crop_bbox'", "]", ",", "10", ")", "\n", "assert", "ten_crop_results", "[", "'img_shape'", "]", "==", "(", "224", ",", "224", ")", "\n", "\n", "assert", "repr", "(", "ten_crop", ")", "==", "(", "f'{ten_crop.__class__.__name__}'", "\n", "f'(crop_size={(224, 224)})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_crop.TestCrops.test_multi_group_crop": [[311, 348], ["list", "dict", "mmaction.datasets.pipelines.MultiGroupCrop", "mmaction.datasets.pipelines.MultiGroupCrop.", "mmcv.utils.assert_dict_has_keys", "base.check_crop", "pytest.raises", "mmaction.datasets.pipelines.MultiGroupCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiGroupCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiGroupCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiGroupCrop", "pytest.raises", "mmaction.datasets.pipelines.MultiGroupCrop", "numpy.random.rand", "repr"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_crop"], ["", "@", "staticmethod", "\n", "def", "test_multi_group_crop", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "MultiGroupCrop", "(", "0.5", ",", "1", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "MultiGroupCrop", "(", "'224'", ",", "1", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# crop_size must be int or tuple of int", "\n", "            ", "MultiGroupCrop", "(", "[", "224", ",", "224", "]", ",", "1", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# groups must be int", "\n", "            ", "MultiGroupCrop", "(", "224", ",", "'1'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# groups must be positive", "\n", "            ", "MultiGroupCrop", "(", "224", ",", "0", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'crop_bbox'", ",", "'img_shape'", "]", "\n", "\n", "# multi_group_crop with crop_size 224, groups 3", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "256", ",", "341", ",", "3", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ")", "\n", "multi_group_crop", "=", "MultiGroupCrop", "(", "224", ",", "3", ")", "\n", "multi_group_crop_result", "=", "multi_group_crop", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "multi_group_crop_result", ",", "target_keys", ")", "\n", "assert", "check_crop", "(", "imgs", ",", "multi_group_crop_result", "[", "'imgs'", "]", ",", "\n", "multi_group_crop_result", "[", "'crop_bbox'", "]", ",", "\n", "multi_group_crop", ".", "groups", ")", "\n", "assert", "multi_group_crop_result", "[", "'img_shape'", "]", "==", "(", "224", ",", "224", ")", "\n", "\n", "assert", "repr", "(", "multi_group_crop", ")", "==", "(", "\n", "f'{multi_group_crop.__class__.__name__}'", "\n", "f'(crop_size={(224, 224)}, groups={3})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.test_normalization.TestNormalization.test_normalize": [[11, 70], ["list", "dict", "dict", "mmaction.datasets.pipelines.Normalize", "mmaction.datasets.pipelines.Normalize.", "mmcv.utils.assert_dict_has_keys", "base.check_normalize", "list", "dict", "dict", "mmaction.datasets.pipelines.Normalize", "mmaction.datasets.pipelines.Normalize.", "mmcv.utils.assert_dict_has_keys", "numpy.array", "numpy.array", "numpy.stack", "numpy.all", "list", "dict", "dict", "mmaction.datasets.pipelines.Normalize", "mmaction.datasets.pipelines.Normalize.", "mmcv.utils.assert_dict_has_keys", "base.check_normalize", "pytest.raises", "mmaction.datasets.pipelines.Normalize", "pytest.raises", "mmaction.datasets.pipelines.Normalize", "numpy.random.rand().astype", "numpy.random.rand().astype", "numpy.isclose", "numpy.random.rand().astype", "mmaction.datasets.pipelines.Normalize.__repr__", "dict", "dict", "numpy.random.rand", "numpy.random.rand", "numpy.random.rand", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_normalize", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_normalize", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.pipelines.compose.Compose.__repr__"], ["    ", "@", "staticmethod", "\n", "def", "test_normalize", "(", ")", ":", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# mean must be list, tuple or np.ndarray", "\n", "            ", "Normalize", "(", "\n", "dict", "(", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ")", ",", "[", "58.395", ",", "57.12", ",", "57.375", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# std must be list, tuple or np.ndarray", "\n", "            ", "Normalize", "(", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "dict", "(", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ")", ")", "\n", "\n", "", "target_keys", "=", "[", "'imgs'", ",", "'img_norm_cfg'", ",", "'modality'", "]", "\n", "\n", "# normalize imgs in RGB format", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "config", "=", "dict", "(", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ",", "\n", "to_bgr", "=", "False", ")", "\n", "normalize", "=", "Normalize", "(", "**", "config", ")", "\n", "normalize_results", "=", "normalize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "normalize_results", ",", "target_keys", ")", "\n", "check_normalize", "(", "imgs", ",", "normalize_results", "[", "'imgs'", "]", ",", "\n", "normalize_results", "[", "'img_norm_cfg'", "]", ")", "\n", "\n", "# normalize flow imgs", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "4", ",", "240", ",", "320", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'Flow'", ")", "\n", "config", "=", "dict", "(", "mean", "=", "[", "128", ",", "128", "]", ",", "std", "=", "[", "128", ",", "128", "]", ")", "\n", "normalize", "=", "Normalize", "(", "**", "config", ")", "\n", "normalize_results", "=", "normalize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "normalize_results", ",", "target_keys", ")", "\n", "assert", "normalize_results", "[", "'imgs'", "]", ".", "shape", "==", "(", "2", ",", "240", ",", "320", ",", "2", ")", "\n", "x_components", "=", "np", ".", "array", "(", "imgs", "[", "0", ":", ":", "2", "]", ")", "\n", "y_components", "=", "np", ".", "array", "(", "imgs", "[", "1", ":", ":", "2", "]", ")", "\n", "x_components", "=", "(", "x_components", "-", "config", "[", "'mean'", "]", "[", "0", "]", ")", "/", "config", "[", "'std'", "]", "[", "0", "]", "\n", "y_components", "=", "(", "y_components", "-", "config", "[", "'mean'", "]", "[", "1", "]", ")", "/", "config", "[", "'std'", "]", "[", "1", "]", "\n", "result_imgs", "=", "np", ".", "stack", "(", "[", "x_components", ",", "y_components", "]", ",", "axis", "=", "-", "1", ")", "\n", "assert", "np", ".", "all", "(", "np", ".", "isclose", "(", "result_imgs", ",", "normalize_results", "[", "'imgs'", "]", ")", ")", "\n", "\n", "# normalize imgs in BGR format", "\n", "imgs", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "240", ",", "320", ",", "3", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "results", "=", "dict", "(", "imgs", "=", "imgs", ",", "modality", "=", "'RGB'", ")", "\n", "config", "=", "dict", "(", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ",", "\n", "to_bgr", "=", "True", ")", "\n", "normalize", "=", "Normalize", "(", "**", "config", ")", "\n", "normalize_results", "=", "normalize", "(", "results", ")", "\n", "assert", "assert_dict_has_keys", "(", "normalize_results", ",", "target_keys", ")", "\n", "check_normalize", "(", "imgs", ",", "normalize_results", "[", "'imgs'", "]", ",", "\n", "normalize_results", "[", "'img_norm_cfg'", "]", ")", "\n", "\n", "assert", "normalize", ".", "__repr__", "(", ")", "==", "(", "\n", "normalize", ".", "__class__", ".", "__name__", "+", "\n", "f'(mean={np.array([123.675, 116.28, 103.53])}, '", "+", "\n", "f'std={np.array([58.395, 57.12, 57.375])}, to_bgr={True}, '", "\n", "f'adjust_magnitude={False})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.base.BaseTestLoading.setup_class": [[9, 93], ["os.normpath", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "len", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "os.join", "mmcv.VideoReader", "os.dirname", "numpy.random.randn", "numpy.random.randn", "dict", "dict", "SSNInstance", "SSNInstance"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["import", "torch", "\n", "from", "mmcv", ".", "utils", "import", "print_log", "\n", "from", "torch", ".", "utils", ".", "data", "import", "Dataset", "\n", "\n", "from", ".", ".", "core", "import", "(", "mean_average_precision", ",", "mean_class_accuracy", ",", "\n", "mmit_mean_average_precision", ",", "top_k_accuracy", ")", "\n", "from", ".", "pipelines", "import", "Compose", "\n", "\n", "\n", "class", "BaseDataset", "(", "Dataset", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    ", "\"\"\"Base class for datasets.\n\n    All datasets to process video should subclass it.\n    All subclasses should overwrite:\n\n    - Methods:`load_annotations`, supporting to load information from an\n    annotation file.\n    - Methods:`prepare_train_frames`, providing train data.\n    - Methods:`prepare_test_frames`, providing test data.\n\n    Args:\n        ann_file (str): Path to the annotation file.\n        pipeline (list[dict | callable]): A sequence of data transforms.\n        data_prefix (str | None): Path to a directory where videos are held.\n            Default: None.\n        test_mode (bool): Store True when building test or validation dataset.\n            Default: False.\n        multi_class (bool): Determines whether the dataset is a multi-class\n            dataset. Default: False.\n        num_classes (int | None): Number of classes of the dataset, used in\n            multi-class datasets. Default: None.\n        start_index (int): Specify a start index for frames in consideration of\n            different filename format. However, when taking videos as input,\n            it should be set to 0, since frames loaded from videos count\n            from 0. Default: 1.\n        modality (str): Modality of data. Support 'RGB', 'Flow', 'Audio'.\n            Default: 'RGB'.\n        sample_by_class (bool): Sampling by class, should be set `True` when\n            performing inter-class data balancing. Only compatible with\n            `multi_class == False`. Only applies for training. Default: False.\n        power (float): We support sampling data with the probability\n            proportional to the power of its label frequency (freq ^ power)\n            when sampling data. `power == 1` indicates uniformly sampling all\n            data; `power == 0` indicates uniformly sampling all classes.\n            Default: 0.\n        dynamic_length (bool): If the dataset length is dynamic (used by\n            ClassSpecificDistributedSampler). Default: False.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_load.TestLoad.test_load_hvu_label": [[17, 58], ["copy.deepcopy", "copy.deepcopy", "sum", "len", "mmaction.datasets.pipelines.LoadHVULabel", "mmaction.datasets.pipelines.LoadHVULabel.", "torch.zeros", "torch.zeros", "torch.zeros", "torch.all", "torch.all", "torch.all", "mmaction.datasets.pipelines.LoadHVULabel.", "torch.zeros", "torch.zeros", "torch.zeros", "torch.all", "torch.all", "torch.all", "repr", "repr", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["None"], ["    ", "def", "test_load_hvu_label", "(", "self", ")", ":", "\n", "        ", "hvu_label_example1", "=", "copy", ".", "deepcopy", "(", "self", ".", "hvu_label_example1", ")", "\n", "hvu_label_example2", "=", "copy", ".", "deepcopy", "(", "self", ".", "hvu_label_example2", ")", "\n", "categories", "=", "hvu_label_example1", "[", "'categories'", "]", "\n", "category_nums", "=", "hvu_label_example1", "[", "'category_nums'", "]", "\n", "num_tags", "=", "sum", "(", "category_nums", ")", "\n", "num_categories", "=", "len", "(", "categories", ")", "\n", "\n", "loader", "=", "LoadHVULabel", "(", ")", "\n", "assert", "repr", "(", "loader", ")", "==", "(", "f'{loader.__class__.__name__}('", "\n", "f'hvu_initialized={False})'", ")", "\n", "\n", "result1", "=", "loader", "(", "hvu_label_example1", ")", "\n", "label1", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "mask1", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "category_mask1", "=", "torch", ".", "zeros", "(", "num_categories", ")", "\n", "\n", "assert", "repr", "(", "loader", ")", "==", "(", "f'{loader.__class__.__name__}('", "\n", "f'hvu_initialized={True})'", ")", "\n", "\n", "label1", "[", "[", "0", ",", "4", ",", "5", ",", "7", ",", "8", "]", "]", "=", "1.", "\n", "mask1", "[", ":", "10", "]", "=", "1.", "\n", "category_mask1", "[", ":", "3", "]", "=", "1.", "\n", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "eq", "(", "label1", ",", "result1", "[", "'label'", "]", ")", ")", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "eq", "(", "mask1", ",", "result1", "[", "'mask'", "]", ")", ")", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "eq", "(", "category_mask1", ",", "result1", "[", "'category_mask'", "]", ")", ")", "\n", "\n", "result2", "=", "loader", "(", "hvu_label_example2", ")", "\n", "label2", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "mask2", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "category_mask2", "=", "torch", ".", "zeros", "(", "num_categories", ")", "\n", "\n", "label2", "[", "[", "1", ",", "8", ",", "9", ",", "11", "]", "]", "=", "1.", "\n", "mask2", "[", ":", "2", "]", "=", "1.", "\n", "mask2", "[", "7", ":", "]", "=", "1.", "\n", "category_mask2", "[", "[", "0", ",", "2", ",", "3", "]", "]", "=", "1.", "\n", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "eq", "(", "label2", ",", "result2", "[", "'label'", "]", ")", ")", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "eq", "(", "mask2", ",", "result2", "[", "'mask'", "]", ")", ")", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "eq", "(", "category_mask2", ",", "result2", "[", "'category_mask'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_load.TestLoad.test_load_localization_feature": [[59, 79], ["copy.deepcopy", "mmaction.datasets.pipelines.LoadLocalizationFeature", "mmaction.datasets.pipelines.LoadLocalizationFeature.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "mmaction.datasets.pipelines.LoadLocalizationFeature", "repr"], "methods", ["None"], ["", "def", "test_load_localization_feature", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'raw_feature'", "]", "\n", "\n", "action_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "action_results", ")", "\n", "\n", "# test error cases", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "load_localization_feature", "=", "LoadLocalizationFeature", "(", "\n", "'unsupport_ext'", ")", "\n", "\n", "# test normal cases", "\n", "", "load_localization_feature", "=", "LoadLocalizationFeature", "(", ")", "\n", "load_localization_feature_result", "=", "load_localization_feature", "(", "\n", "action_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "load_localization_feature_result", ",", "\n", "target_keys", ")", "\n", "assert", "load_localization_feature_result", "[", "'raw_feature'", "]", ".", "shape", "==", "(", "400", ",", "\n", "5", ")", "\n", "assert", "repr", "(", "load_localization_feature", ")", "==", "(", "\n", "f'{load_localization_feature.__class__.__name__}('", "\n", "f'raw_feature_ext=.csv)'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_load.TestLoad.test_load_proposals": [[81, 129], ["copy.deepcopy", "mmaction.datasets.pipelines.LoadProposals", "mmaction.datasets.pipelines.LoadProposals.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "pytest.raises", "mmaction.datasets.pipelines.LoadProposals", "pytest.raises", "mmaction.datasets.pipelines.LoadProposals", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "repr"], "methods", ["None"], ["", "def", "test_load_proposals", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'bsp_feature'", ",", "'tmin'", ",", "'tmax'", ",", "'tmin_score'", ",", "'tmax_score'", ",", "\n", "'reference_temporal_iou'", "\n", "]", "\n", "\n", "action_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "action_results", ")", "\n", "\n", "# test error cases", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "load_proposals", "=", "LoadProposals", "(", "5", ",", "self", ".", "proposals_dir", ",", "\n", "self", ".", "bsp_feature_dir", ",", "\n", "'unsupport_ext'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "load_proposals", "=", "LoadProposals", "(", "5", ",", "self", ".", "proposals_dir", ",", "\n", "self", ".", "bsp_feature_dir", ",", "'.csv'", ",", "\n", "'unsupport_ext'", ")", "\n", "\n", "# test normal cases", "\n", "", "load_proposals", "=", "LoadProposals", "(", "5", ",", "self", ".", "proposals_dir", ",", "\n", "self", ".", "bsp_feature_dir", ")", "\n", "load_proposals_result", "=", "load_proposals", "(", "action_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "load_proposals_result", ",", "target_keys", ")", "\n", "assert", "load_proposals_result", "[", "'bsp_feature'", "]", ".", "shape", "[", "0", "]", "==", "5", "\n", "assert", "load_proposals_result", "[", "'tmin'", "]", ".", "shape", "==", "(", "5", ",", ")", "\n", "assert_array_almost_equal", "(", "\n", "load_proposals_result", "[", "'tmin'", "]", ",", "np", ".", "arange", "(", "0.1", ",", "0.6", ",", "0.1", ")", ",", "decimal", "=", "4", ")", "\n", "assert", "load_proposals_result", "[", "'tmax'", "]", ".", "shape", "==", "(", "5", ",", ")", "\n", "assert_array_almost_equal", "(", "\n", "load_proposals_result", "[", "'tmax'", "]", ",", "np", ".", "arange", "(", "0.2", ",", "0.7", ",", "0.1", ")", ",", "decimal", "=", "4", ")", "\n", "assert", "load_proposals_result", "[", "'tmin_score'", "]", ".", "shape", "==", "(", "5", ",", ")", "\n", "assert_array_almost_equal", "(", "\n", "load_proposals_result", "[", "'tmin_score'", "]", ",", "\n", "np", ".", "arange", "(", "0.95", ",", "0.90", ",", "-", "0.01", ")", ",", "\n", "decimal", "=", "4", ")", "\n", "assert", "load_proposals_result", "[", "'tmax_score'", "]", ".", "shape", "==", "(", "5", ",", ")", "\n", "assert_array_almost_equal", "(", "\n", "load_proposals_result", "[", "'tmax_score'", "]", ",", "\n", "np", ".", "arange", "(", "0.96", ",", "0.91", ",", "-", "0.01", ")", ",", "\n", "decimal", "=", "4", ")", "\n", "assert", "load_proposals_result", "[", "'reference_temporal_iou'", "]", ".", "shape", "==", "(", "5", ",", ")", "\n", "assert_array_almost_equal", "(", "\n", "load_proposals_result", "[", "'reference_temporal_iou'", "]", ",", "\n", "np", ".", "arange", "(", "0.85", ",", "0.80", ",", "-", "0.01", ")", ",", "\n", "decimal", "=", "4", ")", "\n", "assert", "repr", "(", "load_proposals", ")", "==", "(", "\n", "f'{load_proposals.__class__.__name__}('", "\n", "f'top_k={5}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_load.TestLoad.test_load_audio_feature": [[135, 151], ["copy.deepcopy", "mmaction.datasets.pipelines.LoadAudioFeature", "mmaction.datasets.pipelines.LoadAudioFeature.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "mmaction.datasets.pipelines.LoadAudioFeature", "mmaction.datasets.pipelines.LoadAudioFeature.", "mmcv.utils.assert_dict_has_keys", "repr"], "methods", ["None"], ["", "def", "test_load_audio_feature", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'audios'", "]", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "audio_feature_results", ")", "\n", "load_audio_feature", "=", "LoadAudioFeature", "(", ")", "\n", "results", "=", "load_audio_feature", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "\n", "# test when no audio feature file exists", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "audio_feature_results", ")", "\n", "inputs", "[", "'audio_path'", "]", "=", "'foo/foo/bar.npy'", "\n", "load_audio_feature", "=", "LoadAudioFeature", "(", ")", "\n", "results", "=", "load_audio_feature", "(", "inputs", ")", "\n", "assert", "results", "[", "'audios'", "]", ".", "shape", "==", "(", "640", ",", "80", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "repr", "(", "load_audio_feature", ")", "==", "(", "\n", "f'{load_audio_feature.__class__.__name__}('", "\n", "f'pad_method=zero)'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_pyav_init": [[18, 27], ["copy.deepcopy", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmcv.utils.assert_dict_has_keys", "repr"], "methods", ["None"], ["    ", "def", "test_pyav_init", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'video_reader'", ",", "'total_frames'", "]", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_init_result", ",", "target_keys", ")", "\n", "assert", "pyav_init_result", "[", "'total_frames'", "]", "==", "300", "\n", "assert", "repr", "(", "\n", "pyav_init", ")", "==", "f'{pyav_init.__class__.__name__}(io_backend=disk)'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_pyav_decode": [[28, 123], ["copy.deepcopy", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecode", "mmaction.datasets.pipelines.PyAVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecode", "mmaction.datasets.pipelines.PyAVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecode", "mmaction.datasets.pipelines.PyAVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecode", "mmaction.datasets.pipelines.PyAVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecode", "mmaction.datasets.pipelines.PyAVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecode", "mmaction.datasets.pipelines.PyAVDecode.", "mmcv.utils.assert_dict_has_keys", "numpy.arange", "numpy.shape", "repr", "numpy.shape", "numpy.shape", "repr", "numpy.arange", "numpy.shape", "numpy.shape", "numpy.shape", "repr", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "test_pyav_decode", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'frame_inds'", ",", "'imgs'", ",", "'original_shape'", "]", "\n", "\n", "# test PyAV with 2 dim input and start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "\n", "2", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "pyav_init_result", "[", "'video_reader'", "]", "\n", "\n", "pyav_decode", "=", "PyAVDecode", "(", ")", "\n", "pyav_decode_result", "=", "pyav_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_decode_result", ",", "target_keys", ")", "\n", "assert", "pyav_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "pyav_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "assert", "repr", "(", "pyav_decode", ")", "==", "(", "f'{pyav_decode.__class__.__name__}('", "\n", "f'multi_thread={False})'", ")", "\n", "\n", "# test PyAV with 1 dim input and start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "pyav_init_result", "[", "'video_reader'", "]", "\n", "\n", "pyav_decode", "=", "PyAVDecode", "(", ")", "\n", "pyav_decode_result", "=", "pyav_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_decode_result", ",", "target_keys", ")", "\n", "assert", "pyav_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "pyav_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# PyAV with multi thread and start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "pyav_init_result", "[", "'video_reader'", "]", "\n", "\n", "pyav_decode", "=", "PyAVDecode", "(", "multi_thread", "=", "True", ")", "\n", "pyav_decode_result", "=", "pyav_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_decode_result", ",", "target_keys", ")", "\n", "assert", "pyav_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "pyav_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "assert", "repr", "(", "pyav_decode", ")", "==", "(", "f'{pyav_decode.__class__.__name__}('", "\n", "f'multi_thread={True})'", ")", "\n", "\n", "# test PyAV with 2 dim input", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "\n", "2", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "pyav_init_result", "[", "'video_reader'", "]", "\n", "\n", "pyav_decode", "=", "PyAVDecode", "(", ")", "\n", "pyav_decode_result", "=", "pyav_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_decode_result", ",", "target_keys", ")", "\n", "assert", "pyav_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "pyav_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# test PyAV with 1 dim input", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "pyav_init_result", "[", "'video_reader'", "]", "\n", "\n", "pyav_decode", "=", "PyAVDecode", "(", ")", "\n", "pyav_decode_result", "=", "pyav_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_decode_result", ",", "target_keys", ")", "\n", "assert", "pyav_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "pyav_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# PyAV with multi thread", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav_init_result", "=", "pyav_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "pyav_init_result", "[", "'video_reader'", "]", "\n", "\n", "pyav_decode", "=", "PyAVDecode", "(", "multi_thread", "=", "True", ")", "\n", "pyav_decode_result", "=", "pyav_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "pyav_decode_result", ",", "target_keys", ")", "\n", "assert", "pyav_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "pyav_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "assert", "repr", "(", "pyav_decode", ")", "==", "pyav_decode", ".", "__class__", ".", "__name__", "+", "f'(multi_thread={True})'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_decord_init": [[124, 133], ["copy.deepcopy", "mmaction.datasets.pipelines.DecordInit", "mmaction.datasets.pipelines.DecordInit.", "mmcv.utils.assert_dict_has_keys", "len", "repr"], "methods", ["None"], ["", "def", "test_decord_init", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'video_reader'", ",", "'total_frames'", "]", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "decord_init", "=", "DecordInit", "(", ")", "\n", "decord_init_result", "=", "decord_init", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "decord_init_result", ",", "target_keys", ")", "\n", "assert", "decord_init_result", "[", "'total_frames'", "]", "==", "len", "(", "\n", "decord_init_result", "[", "'video_reader'", "]", ")", "\n", "assert", "repr", "(", "decord_init", ")", "==", "(", "f'{decord_init.__class__.__name__}('", "\n", "f'io_backend=disk, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_decord_decode": [[136, 196], ["copy.deepcopy", "mmaction.datasets.pipelines.DecordInit", "mmaction.datasets.pipelines.DecordInit.", "mmaction.datasets.pipelines.DecordDecode", "mmaction.datasets.pipelines.DecordDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.DecordInit", "mmaction.datasets.pipelines.DecordInit.", "mmaction.datasets.pipelines.DecordDecode", "mmaction.datasets.pipelines.DecordDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "mmaction.datasets.pipelines.DecordInit", "mmaction.datasets.pipelines.DecordInit.", "mmaction.datasets.pipelines.DecordDecode", "mmaction.datasets.pipelines.DecordDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.DecordInit", "mmaction.datasets.pipelines.DecordInit.", "mmaction.datasets.pipelines.DecordDecode", "mmaction.datasets.pipelines.DecordDecode.", "mmcv.utils.assert_dict_has_keys", "numpy.arange", "numpy.shape", "numpy.shape", "numpy.arange", "numpy.shape", "numpy.shape", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "test_decord_decode", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'frame_inds'", ",", "'imgs'", ",", "'original_shape'", "]", "\n", "\n", "# test Decord with 2 dim input and start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "\n", "3", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "decord_init", "=", "DecordInit", "(", ")", "\n", "decord_init_result", "=", "decord_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "decord_init_result", "[", "'video_reader'", "]", "\n", "\n", "decord_decode", "=", "DecordDecode", "(", ")", "\n", "decord_decode_result", "=", "decord_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "decord_decode_result", ",", "target_keys", ")", "\n", "assert", "decord_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "decord_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# test Decord with 1 dim input and start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "3", ")", "\n", "decord_init", "=", "DecordInit", "(", ")", "\n", "decord_init_result", "=", "decord_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "decord_init_result", "[", "'video_reader'", "]", "\n", "\n", "decord_decode", "=", "DecordDecode", "(", ")", "\n", "decord_decode_result", "=", "decord_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "decord_decode_result", ",", "target_keys", ")", "\n", "assert", "decord_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "decord_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# test Decord with 2 dim input and start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "\n", "3", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "decord_init", "=", "DecordInit", "(", ")", "\n", "decord_init_result", "=", "decord_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "decord_init_result", "[", "'video_reader'", "]", "\n", "\n", "decord_decode", "=", "DecordDecode", "(", ")", "\n", "decord_decode_result", "=", "decord_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "decord_decode_result", ",", "target_keys", ")", "\n", "assert", "decord_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "decord_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# test Decord with 1 dim input", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "3", ")", "\n", "decord_init", "=", "DecordInit", "(", ")", "\n", "decord_init_result", "=", "decord_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "decord_init_result", "[", "'video_reader'", "]", "\n", "\n", "decord_decode", "=", "DecordDecode", "(", ")", "\n", "decord_decode_result", "=", "decord_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "decord_decode_result", ",", "target_keys", ")", "\n", "assert", "decord_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "decord_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_opencv_init": [[197, 206], ["copy.deepcopy", "mmaction.datasets.pipelines.OpenCVInit", "mmaction.datasets.pipelines.OpenCVInit.", "mmcv.utils.assert_dict_has_keys", "len", "repr"], "methods", ["None"], ["", "def", "test_opencv_init", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'new_path'", ",", "'video_reader'", ",", "'total_frames'", "]", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "opencv_init", "=", "OpenCVInit", "(", ")", "\n", "opencv_init_result", "=", "opencv_init", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "opencv_init_result", ",", "target_keys", ")", "\n", "assert", "opencv_init_result", "[", "'total_frames'", "]", "==", "len", "(", "\n", "opencv_init_result", "[", "'video_reader'", "]", ")", "\n", "assert", "repr", "(", "opencv_init", ")", "==", "(", "f'{opencv_init.__class__.__name__}('", "\n", "f'io_backend=disk)'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_opencv_decode": [[208, 261], ["copy.deepcopy", "mmaction.datasets.pipelines.OpenCVInit", "mmaction.datasets.pipelines.OpenCVInit.", "mmaction.datasets.pipelines.OpenCVDecode", "mmaction.datasets.pipelines.OpenCVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "mmaction.datasets.pipelines.OpenCVInit", "mmaction.datasets.pipelines.OpenCVInit.", "mmaction.datasets.pipelines.OpenCVDecode", "mmaction.datasets.pipelines.OpenCVDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.OpenCVInit", "mmaction.datasets.pipelines.OpenCVInit.", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.OpenCVInit", "mmaction.datasets.pipelines.OpenCVInit.", "mmaction.datasets.pipelines.OpenCVDecode", "mmaction.datasets.pipelines.OpenCVDecode.", "mmcv.utils.assert_dict_has_keys", "numpy.arange", "numpy.shape", "numpy.arange", "numpy.shape", "numpy.shape", "len", "len", "len"], "methods", ["None"], ["", "def", "test_opencv_decode", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'frame_inds'", ",", "'imgs'", ",", "'original_shape'", "]", "\n", "\n", "# test OpenCV with 2 dim input when start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "\n", "2", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "opencv_init", "=", "OpenCVInit", "(", ")", "\n", "opencv_init_result", "=", "opencv_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "opencv_init_result", "[", "'video_reader'", "]", "\n", "\n", "opencv_decode", "=", "OpenCVDecode", "(", ")", "\n", "opencv_decode_result", "=", "opencv_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "opencv_decode_result", ",", "target_keys", ")", "\n", "assert", "opencv_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "opencv_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# test OpenCV with 2 dim input", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "\n", "2", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "opencv_init", "=", "OpenCVInit", "(", ")", "\n", "opencv_init_result", "=", "opencv_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "opencv_init_result", "[", "'video_reader'", "]", "\n", "\n", "opencv_decode", "=", "OpenCVDecode", "(", ")", "\n", "opencv_decode_result", "=", "opencv_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "opencv_decode_result", ",", "target_keys", ")", "\n", "assert", "opencv_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "opencv_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n", "# test OpenCV with 1 dim input when start_index = 0", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "3", ")", "\n", "opencv_init", "=", "OpenCVInit", "(", ")", "\n", "opencv_init_result", "=", "opencv_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "opencv_init_result", "[", "'video_reader'", "]", "\n", "\n", "# test OpenCV with 1 dim input", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "video_result", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "3", ")", "\n", "opencv_init", "=", "OpenCVInit", "(", ")", "\n", "opencv_init_result", "=", "opencv_init", "(", "video_result", ")", "\n", "video_result", "[", "'video_reader'", "]", "=", "opencv_init_result", "[", "'video_reader'", "]", "\n", "\n", "opencv_decode", "=", "OpenCVDecode", "(", ")", "\n", "opencv_decode_result", "=", "opencv_decode", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "opencv_decode_result", ",", "target_keys", ")", "\n", "assert", "opencv_decode_result", "[", "'original_shape'", "]", "==", "(", "256", ",", "340", ")", "\n", "assert", "np", ".", "shape", "(", "opencv_decode_result", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "\n", "video_result", "[", "'frame_inds'", "]", ")", ",", "256", ",", "340", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_rawframe_selector": [[262, 267], ["pytest.warns", "mmaction.datasets.pipelines.FrameSelector"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_rawframe_selector", "(", ")", ":", "\n", "\n", "        ", "with", "pytest", ".", "warns", "(", "UserWarning", ")", ":", "\n", "            ", "FrameSelector", "(", "io_backend", "=", "'disk'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_rawframe_decode": [[268, 394], ["copy.deepcopy", "numpy.array", "numpy.array", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "numpy.arange", "mmaction.datasets.pipelines.RawFrameDecode", "mmaction.datasets.pipelines.RawFrameDecode.", "mmcv.utils.assert_dict_has_keys", "numpy.arange", "numpy.shape", "numpy.arange", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "repr", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "def", "test_rawframe_decode", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'frame_inds'", ",", "'imgs'", ",", "'original_shape'", ",", "'modality'", "]", "\n", "\n", "# test frame selector with 2 dim input", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "2", ")", "[", ":", ",", "\n", "np", ".", "newaxis", "]", "\n", "# since the test images start with index 1, we plus 1 to frame_inds", "\n", "# in order to pass the CI", "\n", "inputs", "[", "'frame_inds'", "]", "=", "inputs", "[", "'frame_inds'", "]", "+", "1", "\n", "\n", "inputs", "[", "'gt_bboxes'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "inputs", "[", "'proposals'", "]", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 2 dim input", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "2", ")", "[", ":", ",", "\n", "np", ".", "newaxis", "]", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 1 dim input when start_index = 0", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "# since the test images start with index 1, we plus 1 to frame_inds", "\n", "# in order to pass the CI", "\n", "inputs", "[", "'frame_inds'", "]", "=", "inputs", "[", "'frame_inds'", "]", "+", "1", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 1 dim input", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 1 dim input", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "2", ")", "\n", "# since the test images start with index 1, we plus 1 to frame_inds", "\n", "# in order to pass the CI", "\n", "inputs", "[", "'frame_inds'", "]", "=", "inputs", "[", "'frame_inds'", "]", "+", "1", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 1 dim input", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "2", ")", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 1 dim input for flow images", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "flow_frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "2", ")", "\n", "# since the test images start with index 1, we plus 1 to frame_inds", "\n", "# in order to pass the CI", "\n", "inputs", "[", "'frame_inds'", "]", "=", "inputs", "[", "'frame_inds'", "]", "+", "1", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", "*", "2", ",", "\n", "240", ",", "320", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector with 1 dim input for flow images", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "flow_frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "2", ")", "\n", "frame_selector", "=", "RawFrameDecode", "(", "io_backend", "=", "'disk'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", "*", "2", ",", "\n", "240", ",", "320", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector in turbojpeg decording backend", "\n", "# when start_index = 0", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "# since the test images start with index 1, we plus 1 to frame_inds", "\n", "# in order to pass the CI", "\n", "inputs", "[", "'frame_inds'", "]", "=", "inputs", "[", "'frame_inds'", "]", "+", "1", "\n", "frame_selector", "=", "RawFrameDecode", "(", "\n", "io_backend", "=", "'disk'", ",", "decoding_backend", "=", "'turbojpeg'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "\n", "# test frame selector in turbojpeg decording backend", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "1", ",", "self", ".", "total_frames", ",", "5", ")", "\n", "frame_selector", "=", "RawFrameDecode", "(", "\n", "io_backend", "=", "'disk'", ",", "decoding_backend", "=", "'turbojpeg'", ")", "\n", "results", "=", "frame_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "np", ".", "shape", "(", "results", "[", "'imgs'", "]", ")", "==", "(", "len", "(", "inputs", "[", "'frame_inds'", "]", ")", ",", "240", ",", "\n", "320", ",", "3", ")", "\n", "assert", "results", "[", "'original_shape'", "]", "==", "(", "240", ",", "320", ")", "\n", "assert", "repr", "(", "frame_selector", ")", "==", "(", "f'{frame_selector.__class__.__name__}('", "\n", "f'io_backend=disk, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_audio_decode_init": [[397, 414], ["copy.deepcopy", "mmaction.datasets.pipelines.AudioDecodeInit", "mmaction.datasets.pipelines.AudioDecodeInit.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "mmaction.datasets.pipelines.AudioDecodeInit", "mmaction.datasets.pipelines.AudioDecodeInit.", "mmcv.utils.assert_dict_has_keys", "repr"], "methods", ["None"], ["", "def", "test_audio_decode_init", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'audios'", ",", "'length'", ",", "'sample_rate'", "]", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "audio_results", ")", "\n", "audio_decode_init", "=", "AudioDecodeInit", "(", ")", "\n", "results", "=", "audio_decode_init", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "\n", "# test when no audio file exists", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "audio_results", ")", "\n", "inputs", "[", "'audio_path'", "]", "=", "'foo/foo/bar.wav'", "\n", "audio_decode_init", "=", "AudioDecodeInit", "(", ")", "\n", "results", "=", "audio_decode_init", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "results", "[", "'audios'", "]", ".", "shape", "==", "(", "10.0", "*", "\n", "audio_decode_init", ".", "sample_rate", ",", ")", "\n", "assert", "repr", "(", "audio_decode_init", ")", "==", "(", "\n", "f'{audio_decode_init.__class__.__name__}('", "\n", "f'io_backend=disk, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_audio_decode": [[418, 428], ["copy.deepcopy", "mmaction.datasets.pipelines.AudioDecode", "mmaction.datasets.pipelines.AudioDecode.", "mmcv.utils.assert_dict_has_keys", "numpy.arange"], "methods", ["None"], ["", "def", "test_audio_decode", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'frame_inds'", ",", "'audios'", "]", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "audio_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "audio_total_frames", ",", "\n", "2", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "inputs", "[", "'num_clips'", "]", "=", "1", "\n", "inputs", "[", "'length'", "]", "=", "1280", "\n", "audio_selector", "=", "AudioDecode", "(", ")", "\n", "results", "=", "audio_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_decode.TestDecode.test_pyav_decode_motion_vector": [[429, 454], ["mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVDecodeMotionVector", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecodeMotionVector.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.PyAVInit", "mmaction.datasets.pipelines.PyAVInit.", "mmaction.datasets.pipelines.PyAVDecodeMotionVector", "mmaction.datasets.pipelines.PyAVDecodeMotionVector.", "mmcv.utils.assert_dict_has_keys", "numpy.arange", "numpy.arange"], "methods", ["None"], ["", "def", "test_pyav_decode_motion_vector", "(", "self", ")", ":", "\n", "        ", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "pyav", "=", "PyAVDecodeMotionVector", "(", ")", "\n", "\n", "# test pyav with 2-dim input", "\n", "results", "=", "{", "\n", "'filename'", ":", "self", ".", "video_path", ",", "\n", "'frame_inds'", ":", "np", ".", "arange", "(", "0", ",", "32", ",", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "}", "\n", "results", "=", "pyav_init", "(", "results", ")", "\n", "results", "=", "pyav", "(", "results", ")", "\n", "target_keys", "=", "[", "'motion_vectors'", "]", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "\n", "# test pyav with 1 dim input", "\n", "results", "=", "{", "\n", "'filename'", ":", "self", ".", "video_path", ",", "\n", "'frame_inds'", ":", "np", ".", "arange", "(", "0", ",", "32", ",", "1", ")", "\n", "}", "\n", "pyav_init", "=", "PyAVInit", "(", ")", "\n", "results", "=", "pyav_init", "(", "results", ")", "\n", "pyav", "=", "PyAVDecodeMotionVector", "(", ")", "\n", "results", "=", "pyav", "(", "results", ")", "\n", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_sampling.TestSampling.test_sample_frames": [[17, 310], ["copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "sample_frames_results[].reshape", "range", "mmaction.datasets.pipelines.SampleFrames.", "sample_frames_results[].reshape", "range", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "numpy.testing.assert_array_equal", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "numpy.testing.assert_array_equal", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "numpy.testing.assert_array_equal", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "numpy.testing.assert_array_equal", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleFrames", "mmaction.datasets.pipelines.SampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.SampleFrames.", "pytest.warns", "dict", "mmaction.datasets.pipelines.SampleFrames", "len", "len", "numpy.max", "numpy.min", "repr", "repr", "range", "len", "test_sampling.TestSampling.test_sample_frames.check_monotonous"], "methods", ["None"], ["    ", "def", "test_sample_frames", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_inds'", ",", "'clip_len'", ",", "'frame_interval'", ",", "'num_clips'", ",", "\n", "'total_frames'", "\n", "]", "\n", "\n", "with", "pytest", ".", "warns", "(", "UserWarning", ")", ":", "\n", "# start_index has been deprecated", "\n", "            ", "config", "=", "dict", "(", "\n", "clip_len", "=", "3", ",", "frame_interval", "=", "1", ",", "num_clips", "=", "5", ",", "start_index", "=", "1", ")", "\n", "SampleFrames", "(", "**", "config", ")", "\n", "\n", "# Sample Frame with no temporal_jitter", "\n", "# clip_len=3, frame_interval=1, num_clips=5", "\n", "", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "3", ",", "frame_interval", "=", "1", ",", "num_clips", "=", "5", ",", "temporal_jitter", "=", "False", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "15", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "15", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "5", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={3}, '", "\n", "f'frame_interval={1}, '", "\n", "f'num_clips={5}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'twice_sample={False}, '", "\n", "f'out_of_bound_opt=loop, '", "\n", "f'test_mode={False})'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter", "\n", "# clip_len=5, frame_interval=1, num_clips=5,", "\n", "# out_of_bound_opt='repeat_last'", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "5", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "5", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "out_of_bound_opt", "=", "'repeat_last'", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={5}, '", "\n", "f'frame_interval={1}, '", "\n", "f'num_clips={5}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'twice_sample={False}, '", "\n", "f'out_of_bound_opt=repeat_last, '", "\n", "f'test_mode={False})'", ")", "\n", "\n", "def", "check_monotonous", "(", "arr", ")", ":", "\n", "            ", "length", "=", "arr", ".", "shape", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "length", "-", "1", ")", ":", "\n", "                ", "if", "arr", "[", "i", "]", ">", "arr", "[", "i", "+", "1", "]", ":", "\n", "                    ", "return", "False", "\n", "", "", "return", "True", "\n", "\n", "", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "25", "\n", "frame_inds", "=", "sample_frames_results", "[", "'frame_inds'", "]", ".", "reshape", "(", "[", "5", ",", "5", "]", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "assert", "check_monotonous", "(", "frame_inds", "[", "i", "]", ")", "\n", "\n", "", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "25", "\n", "frame_inds", "=", "sample_frames_results", "[", "'frame_inds'", "]", ".", "reshape", "(", "[", "5", ",", "5", "]", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "assert", "check_monotonous", "(", "frame_inds", "[", "i", "]", ")", "\n", "", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "5", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "\n", "# Sample Frame with temporal_jitter", "\n", "# clip_len=4, frame_interval=2, num_clips=5", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "frame_interval", "=", "2", ",", "num_clips", "=", "5", ",", "temporal_jitter", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "20", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "20", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "5", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={4}, '", "\n", "f'frame_interval={2}, '", "\n", "f'num_clips={5}, '", "\n", "f'temporal_jitter={True}, '", "\n", "f'twice_sample={False}, '", "\n", "f'out_of_bound_opt=loop, '", "\n", "f'test_mode={False})'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter in test mode", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "5", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={4}, '", "\n", "f'frame_interval={1}, '", "\n", "f'num_clips={6}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'twice_sample={False}, '", "\n", "f'out_of_bound_opt=loop, '", "\n", "f'test_mode={True})'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter in test mode", "\n", "# clip_len=3, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "3", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "18", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "18", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "5", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "\n", "# Sample Frame with no temporal_jitter to get clip_offsets", "\n", "# clip_len=1, frame_interval=1, num_clips=8", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "6", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "8", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "1", ",", "2", ",", "2", ",", "3", ",", "4", ",", "5", ",", "5", ",", "6", "]", ")", ")", "\n", "\n", "# Sample Frame with no temporal_jitter to get clip_offsets", "\n", "# clip_len=1, frame_interval=1, num_clips=8", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "6", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "8", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "1", ",", "2", ",", "2", ",", "3", ",", "4", ",", "5", ",", "5", ",", "6", "]", ")", ")", "\n", "\n", "# Sample Frame with no temporal_jitter to get clip_offsets zero", "\n", "# clip_len=6, frame_interval=1, num_clips=1", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "5", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "6", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "1", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "6", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "6", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "1", "]", ")", "\n", "\n", "# Sample Frame with no temporal_jitter to get avg_interval <= 0", "\n", "# clip_len=12, frame_interval=1, num_clips=20", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "30", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "12", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "20", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "False", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "240", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "240", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "30", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "\n", "# Sample Frame with no temporal_jitter to get clip_offsets", "\n", "# clip_len=1, frame_interval=1, num_clips=8", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "6", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "8", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "False", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", ",", "3", ",", "4", ",", "5", ",", "5", ",", "6", "]", ")", ")", "\n", "\n", "# Sample Frame with no temporal_jitter to get clip_offsets zero", "\n", "# clip_len=12, frame_interval=1, num_clips=2", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "10", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "12", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "2", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "False", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "10", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "\n", "# Sample Frame using twice sample", "\n", "# clip_len=12, frame_interval=1, num_clips=2", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "frame_result", "[", "'total_frames'", "]", "=", "40", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "12", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "2", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "twice_sample", "=", "True", ",", "\n", "test_mode", "=", "True", ")", "\n", "sample_frames", "=", "SampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "48", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "48", "\n", "assert", "np", ".", "max", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "<=", "40", "\n", "assert", "np", ".", "min", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", ">=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_sampling.TestSampling.test_dense_sample_frames": [[311, 446], ["copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.DenseSampleFrames", "mmaction.datasets.pipelines.DenseSampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.DenseSampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.DenseSampleFrames", "mmaction.datasets.pipelines.DenseSampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.DenseSampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.DenseSampleFrames", "mmaction.datasets.pipelines.DenseSampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.DenseSampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.DenseSampleFrames", "mmaction.datasets.pipelines.DenseSampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.DenseSampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.DenseSampleFrames", "mmaction.datasets.pipelines.DenseSampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.DenseSampleFrames.", "copy.deepcopy", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.DenseSampleFrames", "mmaction.datasets.pipelines.DenseSampleFrames.", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.pipelines.DenseSampleFrames.", "len", "len", "repr", "len", "len", "len", "len", "len", "len", "repr", "len", "len", "len", "len", "repr"], "methods", ["None"], ["", "def", "test_dense_sample_frames", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_inds'", ",", "'clip_len'", ",", "'frame_interval'", ",", "'num_clips'", ",", "\n", "'total_frames'", "\n", "]", "\n", "\n", "# Dense sample with no temporal_jitter in test mode", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "dense_sample_frames", "=", "DenseSampleFrames", "(", "**", "config", ")", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "video_result", ")", "\n", "assert", "dense_sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "dense_sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "240", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "240", "\n", "assert", "repr", "(", "dense_sample_frames", ")", "==", "(", "\n", "f'{dense_sample_frames.__class__.__name__}('", "\n", "f'clip_len={4}, '", "\n", "f'frame_interval={1}, '", "\n", "f'num_clips={6}, '", "\n", "f'sample_range={64}, '", "\n", "f'num_sample_positions={10}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'out_of_bound_opt=loop, '", "\n", "f'test_mode={True})'", ")", "\n", "\n", "# Dense sample with no temporal_jitter", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "frame_interval", "=", "1", ",", "num_clips", "=", "6", ",", "temporal_jitter", "=", "False", ")", "\n", "dense_sample_frames", "=", "DenseSampleFrames", "(", "**", "config", ")", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "video_result", ")", "\n", "assert", "dense_sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "dense_sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "\n", "# Dense sample with no temporal_jitter, sample_range=32 in test mode", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "sample_range", "=", "32", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "dense_sample_frames", "=", "DenseSampleFrames", "(", "**", "config", ")", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "video_result", ")", "\n", "assert", "dense_sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "dense_sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "240", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "240", "\n", "\n", "# Dense sample with no temporal_jitter, sample_range=32", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "sample_range", "=", "32", ",", "\n", "temporal_jitter", "=", "False", ")", "\n", "dense_sample_frames", "=", "DenseSampleFrames", "(", "**", "config", ")", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "video_result", ")", "\n", "assert", "dense_sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "dense_sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "assert", "repr", "(", "dense_sample_frames", ")", "==", "(", "\n", "f'{dense_sample_frames.__class__.__name__}('", "\n", "f'clip_len={4}, '", "\n", "f'frame_interval={1}, '", "\n", "f'num_clips={6}, '", "\n", "f'sample_range={32}, '", "\n", "f'num_sample_positions={10}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'out_of_bound_opt=loop, '", "\n", "f'test_mode={False})'", ")", "\n", "\n", "# Dense sample with no temporal_jitter, sample_range=1000 to check mod", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "sample_range", "=", "1000", ",", "\n", "temporal_jitter", "=", "False", ")", "\n", "dense_sample_frames", "=", "DenseSampleFrames", "(", "**", "config", ")", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "video_result", ")", "\n", "assert", "dense_sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "dense_sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "24", "\n", "\n", "# Dense sample with no temporal_jitter in test mode", "\n", "# sample_range=32, num_sample_positions=5", "\n", "# clip_len=4, frame_interval=1, num_clips=6", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "frame_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "frame_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "4", ",", "\n", "frame_interval", "=", "1", ",", "\n", "num_clips", "=", "6", ",", "\n", "num_sample_positions", "=", "5", ",", "\n", "sample_range", "=", "32", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "test_mode", "=", "True", ")", "\n", "dense_sample_frames", "=", "DenseSampleFrames", "(", "**", "config", ")", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "video_result", ")", "\n", "assert", "dense_sample_frames_results", "[", "'start_index'", "]", "==", "0", "\n", "assert", "assert_dict_has_keys", "(", "dense_sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "120", "\n", "dense_sample_frames_results", "=", "dense_sample_frames", "(", "frame_result", ")", "\n", "assert", "len", "(", "dense_sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "120", "\n", "assert", "repr", "(", "dense_sample_frames", ")", "==", "(", "\n", "f'{dense_sample_frames.__class__.__name__}('", "\n", "f'clip_len={4}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_sampling.TestSampling.test_untrim_sample_frames": [[455, 518], ["dict", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.UntrimmedSampleFrames", "mmaction.datasets.pipelines.UntrimmedSampleFrames.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UntrimmedSampleFrames", "mmaction.datasets.pipelines.UntrimmedSampleFrames.", "mmcv.utils.assert_dict_has_keys", "numpy.array", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UntrimmedSampleFrames", "copy.deepcopy", "mmaction.datasets.pipelines.UntrimmedSampleFrames.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UntrimmedSampleFrames", "mmaction.datasets.pipelines.UntrimmedSampleFrames.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_equal", "len", "numpy.array", "repr", "list", "len", "repr", "len", "repr", "len", "numpy.array", "repr", "range", "numpy.array"], "methods", ["None"], ["", "def", "test_untrim_sample_frames", "(", "self", ")", ":", "\n", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_inds'", ",", "'clip_len'", ",", "'frame_interval'", ",", "'num_clips'", ",", "\n", "'total_frames'", "\n", "]", "\n", "\n", "frame_result", "=", "dict", "(", "\n", "frame_dir", "=", "None", ",", "\n", "total_frames", "=", "100", ",", "\n", "filename_tmpl", "=", "None", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "start_index", "=", "0", ",", "\n", "label", "=", "1", ")", "\n", "video_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "video_results", ")", "\n", "\n", "config", "=", "dict", "(", "clip_len", "=", "1", ",", "frame_interval", "=", "16", ",", "start_index", "=", "0", ")", "\n", "sample_frames", "=", "UntrimmedSampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "6", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "8", ",", "24", ",", "40", ",", "56", ",", "72", ",", "88", "]", ")", ")", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'frame_interval={16})'", ")", "\n", "\n", "config", "=", "dict", "(", "clip_len", "=", "1", ",", "frame_interval", "=", "16", ",", "start_index", "=", "0", ")", "\n", "sample_frames", "=", "UntrimmedSampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "video_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "frame_inds", "=", "np", ".", "array", "(", "list", "(", "range", "(", "8", ",", "300", ",", "16", ")", ")", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "frame_inds", ".", "shape", "[", "0", "]", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "frame_inds", ")", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'frame_interval={16})'", ")", "\n", "\n", "config", "=", "dict", "(", "clip_len", "=", "1", ",", "frame_interval", "=", "16", ")", "\n", "sample_frames", "=", "UntrimmedSampleFrames", "(", "**", "config", ")", "\n", "frame_result_", "=", "copy", ".", "deepcopy", "(", "frame_result", ")", "\n", "frame_result_", "[", "'start_index'", "]", "=", "1", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result_", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "6", "\n", "assert_array_equal", "(", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "8", ",", "24", ",", "40", ",", "56", ",", "72", ",", "88", "]", ")", "+", "1", ")", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'frame_interval={16})'", ")", "\n", "\n", "config", "=", "dict", "(", "clip_len", "=", "3", ",", "frame_interval", "=", "16", ",", "start_index", "=", "0", ")", "\n", "sample_frames", "=", "UntrimmedSampleFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "frame_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "18", "\n", "assert_array_equal", "(", "\n", "sample_frames_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "\n", "7", ",", "8", ",", "9", ",", "23", ",", "24", ",", "25", ",", "39", ",", "40", ",", "41", ",", "55", ",", "56", ",", "57", ",", "71", ",", "72", ",", "73", ",", "87", ",", "\n", "88", ",", "89", "\n", "]", ")", ")", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={3}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_sampling.TestSampling.test_sample_ava_frames": [[521, 549], ["dict", "mmaction.datasets.pipelines.SampleAVAFrames", "mmaction.datasets.pipelines.SampleAVAFrames.", "mmcv.utils.assert_dict_has_keys", "dict", "mmaction.datasets.pipelines.SampleAVAFrames", "mmaction.datasets.pipelines.SampleAVAFrames.", "mmcv.utils.assert_dict_has_keys", "len", "repr", "len", "repr"], "methods", ["None"], ["", "def", "test_sample_ava_frames", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'fps'", ",", "'timestamp'", ",", "'timestamp_start'", ",", "'shot_info'", ",", "'frame_inds'", ",", "\n", "'clip_len'", ",", "'frame_interval'", "\n", "]", "\n", "config", "=", "dict", "(", "clip_len", "=", "32", ",", "frame_interval", "=", "2", ")", "\n", "sample_ava_dataset", "=", "SampleAVAFrames", "(", "**", "config", ")", "\n", "ava_result", "=", "sample_ava_dataset", "(", "results", "=", "self", ".", "ava_results", ")", "\n", "assert", "assert_dict_has_keys", "(", "ava_result", ",", "target_keys", ")", "\n", "assert", "ava_result", "[", "'clip_len'", "]", "==", "32", "\n", "assert", "ava_result", "[", "'frame_interval'", "]", "==", "2", "\n", "assert", "len", "(", "ava_result", "[", "'frame_inds'", "]", ")", "==", "32", "\n", "assert", "repr", "(", "sample_ava_dataset", ")", "==", "(", "\n", "f'{sample_ava_dataset.__class__.__name__}('", "\n", "f'clip_len={32}, '", "\n", "f'frame_interval={2}, '", "\n", "f'test_mode={False})'", ")", "\n", "\n", "# add test case in Issue #306", "\n", "config", "=", "dict", "(", "clip_len", "=", "8", ",", "frame_interval", "=", "8", ")", "\n", "sample_ava_dataset", "=", "SampleAVAFrames", "(", "**", "config", ")", "\n", "ava_result", "=", "sample_ava_dataset", "(", "results", "=", "self", ".", "ava_results", ")", "\n", "assert", "assert_dict_has_keys", "(", "ava_result", ",", "target_keys", ")", "\n", "assert", "ava_result", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "ava_result", "[", "'frame_interval'", "]", "==", "8", "\n", "assert", "len", "(", "ava_result", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert", "repr", "(", "sample_ava_dataset", ")", "==", "(", "\n", "f'{sample_ava_dataset.__class__.__name__}('", "\n", "f'clip_len={8}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_sampling.TestSampling.test_sample_proposal_frames": [[553, 725], ["copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "mmcv.utils.assert_dict_has_keys", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "mmcv.utils.assert_dict_has_keys", "pytest.raises", "copy.deepcopy", "dict", "mmaction.datasets.pipelines.SampleProposalFrames", "mmaction.datasets.pipelines.SampleProposalFrames.", "len", "repr", "len", "repr", "len", "repr", "len", "repr", "len", "repr", "len", "repr"], "methods", ["None"], ["", "def", "test_sample_proposal_frames", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_inds'", ",", "'clip_len'", ",", "'frame_interval'", ",", "'num_clips'", ",", "\n", "'total_frames'", ",", "'start_index'", "\n", "]", "\n", "\n", "# test error cases", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "            ", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "2", ",", "\n", "aug_segments", "=", "(", "'error'", ",", "'error'", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "temporal_jitter", "=", "False", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames", "(", "proposal_result", ")", "\n", "\n", "# test normal cases", "\n", "# Sample Frame with no temporal_jitter", "\n", "# clip_len=1, frame_interval=1", "\n", "# body_segments=2, aug_segments=(1, 1)", "\n", "", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "proposal_result", "[", "'total_frames'", "]", "=", "9", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "2", ",", "\n", "aug_segments", "=", "(", "1", ",", "1", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "temporal_jitter", "=", "False", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "proposal_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'body_segments={2}, '", "\n", "f'aug_segments={(1, 1)}, '", "\n", "f'aug_ratio={(0.5, 0.5)}, '", "\n", "f'frame_interval={1}, '", "\n", "f'test_interval={6}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'mode=train)'", ")", "\n", "\n", "# Sample Frame with temporal_jitter", "\n", "# clip_len=1, frame_interval=1", "\n", "# body_segments=2, aug_segments=(1, 1)", "\n", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "proposal_result", "[", "'total_frames'", "]", "=", "9", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "2", ",", "\n", "aug_segments", "=", "(", "1", ",", "1", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "temporal_jitter", "=", "True", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "proposal_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'body_segments={2}, '", "\n", "f'aug_segments={(1, 1)}, '", "\n", "f'aug_ratio={(0.5, 0.5)}, '", "\n", "f'frame_interval={1}, '", "\n", "f'test_interval={6}, '", "\n", "f'temporal_jitter={True}, '", "\n", "f'mode=train)'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter in val mode", "\n", "# clip_len=1, frame_interval=1", "\n", "# body_segments=2, aug_segments=(1, 1)", "\n", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "proposal_result", "[", "'total_frames'", "]", "=", "9", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "2", ",", "\n", "aug_segments", "=", "(", "1", ",", "1", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "mode", "=", "'val'", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "proposal_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'body_segments={2}, '", "\n", "f'aug_segments={(1, 1)}, '", "\n", "f'aug_ratio={(0.5, 0.5)}, '", "\n", "f'frame_interval={1}, '", "\n", "f'test_interval={6}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'mode=val)'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter in test mode", "\n", "# test_interval=2", "\n", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "proposal_result", "[", "'out_proposals'", "]", "=", "None", "\n", "proposal_result", "[", "'total_frames'", "]", "=", "10", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "2", ",", "\n", "aug_segments", "=", "(", "1", ",", "1", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "test_interval", "=", "2", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "mode", "=", "'test'", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "proposal_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "5", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'body_segments={2}, '", "\n", "f'aug_segments={(1, 1)}, '", "\n", "f'aug_ratio={(0.5, 0.5)}, '", "\n", "f'frame_interval={1}, '", "\n", "f'test_interval={2}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'mode=test)'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter to get clip_offsets zero", "\n", "# clip_len=1, frame_interval=1", "\n", "# body_segments=2, aug_segments=(1, 1)", "\n", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "proposal_result", "[", "'total_frames'", "]", "=", "3", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "2", ",", "\n", "aug_segments", "=", "(", "1", ",", "1", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "temporal_jitter", "=", "False", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "proposal_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n", "f'body_segments={2}, '", "\n", "f'aug_segments={(1, 1)}, '", "\n", "f'aug_ratio={(0.5, 0.5)}, '", "\n", "f'frame_interval={1}, '", "\n", "f'test_interval={6}, '", "\n", "f'temporal_jitter={False}, '", "\n", "f'mode=train)'", ")", "\n", "\n", "# Sample Frame with no temporal_jitter to", "\n", "# get clip_offsets zero in val mode", "\n", "# clip_len=1, frame_interval=1", "\n", "# body_segments=4, aug_segments=(2, 2)", "\n", "proposal_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "proposal_results", ")", "\n", "proposal_result", "[", "'total_frames'", "]", "=", "3", "\n", "config", "=", "dict", "(", "\n", "clip_len", "=", "1", ",", "\n", "frame_interval", "=", "1", ",", "\n", "body_segments", "=", "4", ",", "\n", "aug_segments", "=", "(", "2", ",", "2", ")", ",", "\n", "aug_ratio", "=", "0.5", ",", "\n", "temporal_jitter", "=", "False", ",", "\n", "mode", "=", "'val'", ")", "\n", "sample_frames", "=", "SampleProposalFrames", "(", "**", "config", ")", "\n", "sample_frames_results", "=", "sample_frames", "(", "proposal_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "sample_frames_results", ",", "target_keys", ")", "\n", "assert", "len", "(", "sample_frames_results", "[", "'frame_inds'", "]", ")", "==", "16", "\n", "assert", "repr", "(", "sample_frames", ")", "==", "(", "f'{sample_frames.__class__.__name__}('", "\n", "f'clip_len={1}, '", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_sampling.TestSampling.test_audio_feature_selector": [[734, 747], ["copy.deepcopy", "mmaction.datasets.pipelines.AudioFeatureSelector", "mmaction.datasets.pipelines.AudioFeatureSelector.", "mmcv.utils.assert_dict_has_keys", "numpy.arange", "repr"], "methods", ["None"], ["", "def", "test_audio_feature_selector", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'audios'", "]", "\n", "# test frame selector with 2 dim input", "\n", "inputs", "=", "copy", ".", "deepcopy", "(", "self", ".", "audio_feature_results", ")", "\n", "inputs", "[", "'frame_inds'", "]", "=", "np", ".", "arange", "(", "0", ",", "self", ".", "audio_total_frames", ",", "\n", "2", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "inputs", "[", "'num_clips'", "]", "=", "1", "\n", "inputs", "[", "'length'", "]", "=", "1280", "\n", "audio_feature_selector", "=", "AudioFeatureSelector", "(", ")", "\n", "results", "=", "audio_feature_selector", "(", "inputs", ")", "\n", "assert", "assert_dict_has_keys", "(", "results", ",", "target_keys", ")", "\n", "assert", "repr", "(", "audio_feature_selector", ")", "==", "(", "\n", "f'{audio_feature_selector.__class__.__name__}('", "\n", "f'fix_length={128})'", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_pose_loading.TestPoseLoading.test_uniform_sample_frames": [[15, 99], ["dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "numpy.testing.assert_array_equal", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "dict", "mmaction.datasets.pipelines.UniformSampleFrames", "mmaction.datasets.pipelines.UniformSampleFrames.", "str", "numpy.array", "numpy.array", "numpy.array", "len", "numpy.array", "len", "len", "len"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "test_uniform_sample_frames", "(", ")", ":", "\n", "        ", "results", "=", "dict", "(", "total_frames", "=", "64", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "1", ",", "test_mode", "=", "True", ",", "seed", "=", "0", ")", "\n", "\n", "assert", "str", "(", "sampling", ")", "==", "(", "'UniformSampleFrames(clip_len=8, '", "\n", "'num_clips=1, test_mode=True, seed=0)'", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "1", "\n", "assert_array_equal", "(", "sampling_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "4", ",", "15", ",", "21", ",", "24", ",", "35", ",", "43", ",", "51", ",", "63", "]", ")", ")", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "15", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "1", ",", "test_mode", "=", "True", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "1", "\n", "assert_array_equal", "(", "sampling_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "2", ",", "4", ",", "6", ",", "8", ",", "9", ",", "11", ",", "13", "]", ")", ")", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "7", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "1", ",", "test_mode", "=", "True", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "1", "\n", "assert_array_equal", "(", "sampling_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "0", "]", ")", ")", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "7", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "8", ",", "test_mode", "=", "True", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "8", "\n", "assert", "len", "(", "sampling_results", "[", "'frame_inds'", "]", ")", "==", "64", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "64", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "4", ",", "test_mode", "=", "True", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "4", "\n", "assert_array_equal", "(", "\n", "sampling_results", "[", "'frame_inds'", "]", ",", "\n", "np", ".", "array", "(", "[", "\n", "4", ",", "15", ",", "21", ",", "24", ",", "35", ",", "43", ",", "51", ",", "63", ",", "1", ",", "11", ",", "21", ",", "26", ",", "36", ",", "47", ",", "54", ",", "56", ",", "\n", "0", ",", "12", ",", "18", ",", "25", ",", "38", ",", "47", ",", "55", ",", "62", ",", "0", ",", "9", ",", "21", ",", "25", ",", "37", ",", "40", ",", "49", ",", "60", "\n", "]", ")", ")", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "64", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "1", ",", "test_mode", "=", "False", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "1", "\n", "assert", "len", "(", "sampling_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "7", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "1", ",", "test_mode", "=", "False", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "1", "\n", "assert", "len", "(", "sampling_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "\n", "results", "=", "dict", "(", "total_frames", "=", "15", ",", "start_index", "=", "0", ")", "\n", "sampling", "=", "UniformSampleFrames", "(", "\n", "clip_len", "=", "8", ",", "num_clips", "=", "1", ",", "test_mode", "=", "False", ",", "seed", "=", "0", ")", "\n", "sampling_results", "=", "sampling", "(", "results", ")", "\n", "assert", "sampling_results", "[", "'clip_len'", "]", "==", "8", "\n", "assert", "sampling_results", "[", "'frame_interval'", "]", "is", "None", "\n", "assert", "sampling_results", "[", "'num_clips'", "]", "==", "1", "\n", "assert", "len", "(", "sampling_results", "[", "'frame_inds'", "]", ")", "==", "8", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_pose_loading.TestPoseLoading.test_pose_decode": [[100, 120], ["numpy.random.random", "numpy.random.random", "numpy.array", "dict", "mmaction.datasets.pipelines.PoseDecode", "mmaction.datasets.pipelines.PoseDecode.", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "dict", "mmaction.datasets.pipelines.PoseDecode", "mmaction.datasets.pipelines.PoseDecode.", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_pose_decode", "(", ")", ":", "\n", "        ", "kp", "=", "np", ".", "random", ".", "random", "(", "[", "1", ",", "16", ",", "17", ",", "2", "]", ")", "\n", "kpscore", "=", "np", ".", "random", ".", "random", "(", "[", "1", ",", "16", ",", "17", "]", ")", "\n", "frame_inds", "=", "np", ".", "array", "(", "[", "2", ",", "4", ",", "6", ",", "8", ",", "10", "]", ")", "\n", "results", "=", "dict", "(", "\n", "keypoint", "=", "kp", ",", "keypoint_score", "=", "kpscore", ",", "frame_inds", "=", "frame_inds", ")", "\n", "pose_decode", "=", "PoseDecode", "(", ")", "\n", "assert", "str", "(", "pose_decode", ")", "==", "(", "'PoseDecode()'", ")", "\n", "decode_results", "=", "pose_decode", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "decode_results", "[", "'keypoint'", "]", ",", "kp", "[", ":", ",", "\n", "frame_inds", "]", ")", "\n", "assert_array_almost_equal", "(", "decode_results", "[", "'keypoint_score'", "]", ",", "\n", "kpscore", "[", ":", ",", "frame_inds", "]", ")", "\n", "\n", "results", "=", "dict", "(", "keypoint", "=", "kp", ",", "keypoint_score", "=", "kpscore", ",", "total_frames", "=", "16", ")", "\n", "pose_decode", "=", "PoseDecode", "(", ")", "\n", "decode_results", "=", "pose_decode", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "decode_results", "[", "'keypoint'", "]", ",", "kp", ")", "\n", "assert_array_almost_equal", "(", "decode_results", "[", "'keypoint_score'", "]", ",", "kpscore", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_pose_loading.TestPoseLoading.test_load_kinetics_pose": [[121, 209], ["numpy.random.choice", "numpy.random.choice.sort", "numpy.array", "numpy.random.random", "mmcv.dump", "dict", "copy.deepcopy", "mmaction.datasets.pipelines.LoadKineticsPose", "mmaction.datasets.pipelines.LoadKineticsPose.", "copy.deepcopy", "mmaction.datasets.pipelines.LoadKineticsPose", "mmaction.datasets.pipelines.LoadKineticsPose.", "copy.deepcopy", "mmaction.datasets.pipelines.LoadKineticsPose", "mmaction.datasets.pipelines.LoadKineticsPose.", "copy.deepcopy", "mmaction.datasets.pipelines.LoadKineticsPose", "mmaction.datasets.pipelines.LoadKineticsPose.", "collections.defaultdict", "max", "range", "numpy.random.random", "pytest.raises", "mmaction.datasets.pipelines.LoadKineticsPose", "str", "numpy.max", "len", "numpy.max", "numpy.max", "len", "numpy.max", "len", "collections.defaultdict.values", "test_pose_loading.TestPoseLoading.test_load_kinetics_pose.get_mode"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_load_kinetics_pose", "(", ")", ":", "\n", "\n", "        ", "def", "get_mode", "(", "arr", ")", ":", "\n", "            ", "cnt", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "for", "num", "in", "arr", ":", "\n", "                ", "cnt", "[", "num", "]", "+=", "1", "\n", "", "max_val", "=", "max", "(", "cnt", ".", "values", "(", ")", ")", "\n", "return", "[", "k", "for", "k", "in", "cnt", "if", "cnt", "[", "k", "]", "==", "max_val", "]", ",", "max_val", "\n", "\n", "", "filename", "=", "'/tmp/tmp.pkl'", "\n", "total_frames", "=", "100", "\n", "img_shape", "=", "(", "224", ",", "224", ")", "\n", "frame_inds", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "100", ")", ",", "size", "=", "120", ")", "\n", "frame_inds", ".", "sort", "(", ")", "\n", "anno_flag", "=", "np", ".", "random", ".", "random", "(", "120", ")", ">", "0.1", "\n", "anno_inds", "=", "np", ".", "array", "(", "[", "i", "for", "i", ",", "f", "in", "enumerate", "(", "anno_flag", ")", "if", "f", "]", ")", "\n", "kp", "=", "np", ".", "random", ".", "random", "(", "[", "120", ",", "17", ",", "3", "]", ")", "\n", "dump", "(", "kp", ",", "filename", ")", "\n", "results", "=", "dict", "(", "\n", "filename", "=", "filename", ",", "\n", "total_frames", "=", "total_frames", ",", "\n", "img_shape", "=", "img_shape", ",", "\n", "frame_inds", "=", "frame_inds", ")", "\n", "\n", "inp", "=", "cp", ".", "deepcopy", "(", "results", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "            ", "LoadKineticsPose", "(", "squeeze", "=", "True", ",", "max_person", "=", "100", ",", "source", "=", "'xxx'", ")", "\n", "\n", "", "load_kinetics_pose", "=", "LoadKineticsPose", "(", "\n", "squeeze", "=", "True", ",", "max_person", "=", "100", ",", "source", "=", "'openpose'", ")", "\n", "\n", "assert", "str", "(", "load_kinetics_pose", ")", "==", "(", "'LoadKineticsPose(io_backend=disk, '", "\n", "'squeeze=True, max_person=100, '", "\n", "\"keypoint_weight={'face': 1, \"", "\n", "\"'torso': 2, 'limb': 3}, \"", "\n", "'source=openpose, kwargs={})'", ")", "\n", "return_results", "=", "load_kinetics_pose", "(", "inp", ")", "\n", "assert", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", ":", "-", "1", "]", "==", "return_results", "[", "'keypoint_score'", "]", ".", "shape", "\n", "\n", "num_person", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "0", "]", "\n", "num_frame", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "1", "]", "\n", "assert", "num_person", "==", "get_mode", "(", "frame_inds", ")", "[", "1", "]", "\n", "assert", "np", ".", "max", "(", "return_results", "[", "'keypoint'", "]", ")", ">", "1", "\n", "assert", "num_frame", "==", "len", "(", "set", "(", "frame_inds", ")", ")", "\n", "\n", "inp", "=", "cp", ".", "deepcopy", "(", "results", ")", "\n", "load_kinetics_pose", "=", "LoadKineticsPose", "(", "\n", "squeeze", "=", "False", ",", "max_person", "=", "100", ",", "source", "=", "'openpose'", ")", "\n", "return_results", "=", "load_kinetics_pose", "(", "inp", ")", "\n", "assert", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", ":", "-", "1", "]", "==", "return_results", "[", "'keypoint_score'", "]", ".", "shape", "\n", "\n", "num_person", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "0", "]", "\n", "num_frame", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "1", "]", "\n", "assert", "num_person", "==", "get_mode", "(", "frame_inds", ")", "[", "1", "]", "\n", "assert", "np", ".", "max", "(", "return_results", "[", "'keypoint'", "]", ")", ">", "1", "\n", "assert", "num_frame", "==", "total_frames", "\n", "\n", "inp", "=", "cp", ".", "deepcopy", "(", "results", ")", "\n", "inp", "[", "'anno_inds'", "]", "=", "anno_inds", "\n", "load_kinetics_pose", "=", "LoadKineticsPose", "(", "\n", "squeeze", "=", "True", ",", "max_person", "=", "100", ",", "source", "=", "'mmpose'", ")", "\n", "return_results", "=", "load_kinetics_pose", "(", "inp", ")", "\n", "assert", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", ":", "-", "1", "]", "==", "return_results", "[", "'keypoint_score'", "]", ".", "shape", "\n", "\n", "num_person", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "0", "]", "\n", "num_frame", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "1", "]", "\n", "assert", "num_person", "==", "get_mode", "(", "frame_inds", "[", "anno_inds", "]", ")", "[", "1", "]", "\n", "assert", "np", ".", "max", "(", "return_results", "[", "'keypoint'", "]", ")", "<=", "1", "\n", "assert", "num_frame", "==", "len", "(", "set", "(", "frame_inds", "[", "anno_inds", "]", ")", ")", "\n", "\n", "inp", "=", "cp", ".", "deepcopy", "(", "results", ")", "\n", "inp", "[", "'anno_inds'", "]", "=", "anno_inds", "\n", "load_kinetics_pose", "=", "LoadKineticsPose", "(", "\n", "squeeze", "=", "True", ",", "max_person", "=", "2", ",", "source", "=", "'mmpose'", ")", "\n", "return_results", "=", "load_kinetics_pose", "(", "inp", ")", "\n", "assert", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", ":", "-", "1", "]", "==", "return_results", "[", "'keypoint_score'", "]", ".", "shape", "\n", "\n", "num_person", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "0", "]", "\n", "num_frame", "=", "return_results", "[", "'keypoint'", "]", ".", "shape", "[", "1", "]", "\n", "assert", "num_person", "<=", "2", "\n", "assert", "np", ".", "max", "(", "return_results", "[", "'keypoint'", "]", ")", "<=", "1", "\n", "assert", "num_frame", "==", "len", "(", "set", "(", "frame_inds", "[", "anno_inds", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_pose_loading.TestPoseLoading.test_generate_pose_target": [[210, 353], ["numpy.array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "dict", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "dict", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "dict", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "dict", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "dict", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "numpy.array", "numpy.array", "numpy.concatenate", "numpy.concatenate", "dict", "mmaction.datasets.pipelines.GeneratePoseTarget", "mmaction.datasets.pipelines.GeneratePoseTarget.", "numpy.testing.assert_array_almost_equal", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_generate_pose_target", "(", ")", ":", "\n", "        ", "img_shape", "=", "(", "64", ",", "64", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "[", "[", "24", ",", "24", "]", ",", "[", "40", ",", "40", "]", ",", "[", "24", ",", "40", "]", "]", "]", "]", ")", "\n", "kpscore", "=", "np", ".", "array", "(", "[", "[", "[", "1.", ",", "1.", ",", "1.", "]", "]", "]", ")", "\n", "kp", "=", "np", ".", "concatenate", "(", "[", "kp", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "kpscore", "=", "np", ".", "concatenate", "(", "[", "kpscore", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "results", "=", "dict", "(", "\n", "img_shape", "=", "img_shape", ",", "\n", "keypoint", "=", "kp", ",", "\n", "keypoint_score", "=", "kpscore", ",", "\n", "modality", "=", "'Pose'", ")", "\n", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "with_kp", "=", "True", ",", "left_kp", "=", "(", "0", ",", ")", ",", "right_kp", "=", "(", "1", ",", ")", ",", "skeletons", "=", "(", ")", ")", "\n", "assert", "str", "(", "generate_pose_target", ")", "==", "(", "'GeneratePoseTarget(sigma=1, '", "\n", "'use_score=True, with_kp=True, '", "\n", "'with_limb=False, skeletons=(), '", "\n", "'double=False, left_kp=(0,), '", "\n", "'right_kp=(1,))'", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert", "return_results", "[", "'imgs'", "]", ".", "shape", "==", "(", "8", ",", "64", ",", "64", ",", "3", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", "[", "0", "]", ",", "\n", "return_results", "[", "'imgs'", "]", "[", "1", "]", ")", "\n", "\n", "results", "=", "dict", "(", "img_shape", "=", "img_shape", ",", "keypoint", "=", "kp", ",", "modality", "=", "'Pose'", ")", "\n", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "with_kp", "=", "True", ",", "left_kp", "=", "(", "0", ",", ")", ",", "right_kp", "=", "(", "1", ",", ")", ",", "skeletons", "=", "(", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert", "return_results", "[", "'imgs'", "]", ".", "shape", "==", "(", "8", ",", "64", ",", "64", ",", "3", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", "[", "0", "]", ",", "\n", "return_results", "[", "'imgs'", "]", "[", "1", "]", ")", "\n", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "\n", "with_kp", "=", "False", ",", "\n", "with_limb", "=", "True", ",", "\n", "left_kp", "=", "(", "0", ",", ")", ",", "\n", "right_kp", "=", "(", "1", ",", ")", ",", "\n", "skeletons", "=", "(", "(", "0", ",", "1", ")", ",", "(", "1", ",", "2", ")", ",", "(", "0", ",", "2", ")", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert", "return_results", "[", "'imgs'", "]", ".", "shape", "==", "(", "8", ",", "64", ",", "64", ",", "3", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", "[", "0", "]", ",", "\n", "return_results", "[", "'imgs'", "]", "[", "1", "]", ")", "\n", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "\n", "with_kp", "=", "True", ",", "\n", "with_limb", "=", "True", ",", "\n", "left_kp", "=", "(", "0", ",", ")", ",", "\n", "right_kp", "=", "(", "1", ",", ")", ",", "\n", "skeletons", "=", "(", "(", "0", ",", "1", ")", ",", "(", "1", ",", "2", ")", ",", "(", "0", ",", "2", ")", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert", "return_results", "[", "'imgs'", "]", ".", "shape", "==", "(", "8", ",", "64", ",", "64", ",", "6", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", "[", "0", "]", ",", "\n", "return_results", "[", "'imgs'", "]", "[", "1", "]", ")", "\n", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "\n", "with_kp", "=", "True", ",", "\n", "with_limb", "=", "True", ",", "\n", "double", "=", "True", ",", "\n", "left_kp", "=", "(", "0", ",", ")", ",", "\n", "right_kp", "=", "(", "1", ",", ")", ",", "\n", "skeletons", "=", "(", "(", "0", ",", "1", ")", ",", "(", "1", ",", "2", ")", ",", "(", "0", ",", "2", ")", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "imgs", "=", "return_results", "[", "'imgs'", "]", "\n", "assert", "imgs", ".", "shape", "==", "(", "16", ",", "64", ",", "64", ",", "6", ")", "\n", "assert_array_almost_equal", "(", "imgs", "[", "0", "]", ",", "imgs", "[", "1", "]", ")", "\n", "assert_array_almost_equal", "(", "imgs", "[", ":", "8", ",", "2", "]", ",", "imgs", "[", "8", ":", ",", "2", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "assert_array_almost_equal", "(", "imgs", "[", ":", "8", ",", "0", "]", ",", "imgs", "[", "8", ":", ",", "1", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "assert_array_almost_equal", "(", "imgs", "[", ":", "8", ",", "1", "]", ",", "imgs", "[", "8", ":", ",", "0", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "\n", "img_shape", "=", "(", "64", ",", "64", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "[", "[", "24", ",", "24", "]", ",", "[", "40", ",", "40", "]", ",", "[", "24", ",", "40", "]", "]", "]", "]", ")", "\n", "kpscore", "=", "np", ".", "array", "(", "[", "[", "[", "0.", ",", "0.", ",", "0.", "]", "]", "]", ")", "\n", "kp", "=", "np", ".", "concatenate", "(", "[", "kp", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "kpscore", "=", "np", ".", "concatenate", "(", "[", "kpscore", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "results", "=", "dict", "(", "\n", "img_shape", "=", "img_shape", ",", "\n", "keypoint", "=", "kp", ",", "\n", "keypoint_score", "=", "kpscore", ",", "\n", "modality", "=", "'Pose'", ")", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "with_kp", "=", "True", ",", "left_kp", "=", "(", "0", ",", ")", ",", "right_kp", "=", "(", "1", ",", ")", ",", "skeletons", "=", "(", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", ",", "0", ")", "\n", "\n", "img_shape", "=", "(", "64", ",", "64", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "[", "[", "24", ",", "24", "]", ",", "[", "40", ",", "40", "]", ",", "[", "24", ",", "40", "]", "]", "]", "]", ")", "\n", "kpscore", "=", "np", ".", "array", "(", "[", "[", "[", "0.", ",", "0.", ",", "0.", "]", "]", "]", ")", "\n", "kp", "=", "np", ".", "concatenate", "(", "[", "kp", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "kpscore", "=", "np", ".", "concatenate", "(", "[", "kpscore", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "results", "=", "dict", "(", "\n", "img_shape", "=", "img_shape", ",", "\n", "keypoint", "=", "kp", ",", "\n", "keypoint_score", "=", "kpscore", ",", "\n", "modality", "=", "'Pose'", ")", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "\n", "with_kp", "=", "False", ",", "\n", "with_limb", "=", "True", ",", "\n", "left_kp", "=", "(", "0", ",", ")", ",", "\n", "right_kp", "=", "(", "1", ",", ")", ",", "\n", "skeletons", "=", "(", "(", "0", ",", "1", ")", ",", "(", "1", ",", "2", ")", ",", "(", "0", ",", "2", ")", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", ",", "0", ")", "\n", "\n", "img_shape", "=", "(", "64", ",", "64", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "[", "[", "124", ",", "124", "]", ",", "[", "140", ",", "140", "]", ",", "[", "124", ",", "140", "]", "]", "]", "]", ")", "\n", "kpscore", "=", "np", ".", "array", "(", "[", "[", "[", "0.", ",", "0.", ",", "0.", "]", "]", "]", ")", "\n", "kp", "=", "np", ".", "concatenate", "(", "[", "kp", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "kpscore", "=", "np", ".", "concatenate", "(", "[", "kpscore", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "results", "=", "dict", "(", "\n", "img_shape", "=", "img_shape", ",", "\n", "keypoint", "=", "kp", ",", "\n", "keypoint_score", "=", "kpscore", ",", "\n", "modality", "=", "'Pose'", ")", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "with_kp", "=", "True", ",", "left_kp", "=", "(", "0", ",", ")", ",", "right_kp", "=", "(", "1", ",", ")", ",", "skeletons", "=", "(", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", ",", "0", ")", "\n", "\n", "img_shape", "=", "(", "64", ",", "64", ")", "\n", "kp", "=", "np", ".", "array", "(", "[", "[", "[", "[", "124", ",", "124", "]", ",", "[", "140", ",", "140", "]", ",", "[", "124", ",", "140", "]", "]", "]", "]", ")", "\n", "kpscore", "=", "np", ".", "array", "(", "[", "[", "[", "0.", ",", "0.", ",", "0.", "]", "]", "]", ")", "\n", "kp", "=", "np", ".", "concatenate", "(", "[", "kp", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "kpscore", "=", "np", ".", "concatenate", "(", "[", "kpscore", "]", "*", "8", ",", "axis", "=", "1", ")", "\n", "results", "=", "dict", "(", "\n", "img_shape", "=", "img_shape", ",", "\n", "keypoint", "=", "kp", ",", "\n", "keypoint_score", "=", "kpscore", ",", "\n", "modality", "=", "'Pose'", ")", "\n", "generate_pose_target", "=", "GeneratePoseTarget", "(", "\n", "sigma", "=", "1", ",", "\n", "with_kp", "=", "False", ",", "\n", "with_limb", "=", "True", ",", "\n", "left_kp", "=", "(", "0", ",", ")", ",", "\n", "right_kp", "=", "(", "1", ",", ")", ",", "\n", "skeletons", "=", "(", "(", "0", ",", "1", ")", ",", "(", "1", ",", "2", ")", ",", "(", "0", ",", "2", ")", ")", ")", "\n", "return_results", "=", "generate_pose_target", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "return_results", "[", "'imgs'", "]", ",", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_loadings.test_localization.TestLocalization.test_generate_localization_label": [[13, 28], ["copy.deepcopy", "numpy.random.randn", "mmaction.datasets.pipelines.GenerateLocalizationLabels", "mmaction.datasets.pipelines.GenerateLocalizationLabels.", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_almost_equal"], "methods", ["None"], ["    ", "def", "test_generate_localization_label", "(", "self", ")", ":", "\n", "        ", "action_result", "=", "copy", ".", "deepcopy", "(", "self", ".", "action_results", ")", "\n", "action_result", "[", "'raw_feature'", "]", "=", "np", ".", "random", ".", "randn", "(", "400", ",", "5", ")", "\n", "\n", "# test default setting", "\n", "target_keys", "=", "[", "'gt_bbox'", "]", "\n", "generate_localization_labels", "=", "GenerateLocalizationLabels", "(", ")", "\n", "generate_localization_labels_result", "=", "generate_localization_labels", "(", "\n", "action_result", ")", "\n", "assert", "assert_dict_has_keys", "(", "generate_localization_labels_result", ",", "\n", "target_keys", ")", "\n", "\n", "assert_array_almost_equal", "(", "\n", "generate_localization_labels_result", "[", "'gt_bbox'", "]", ",", "[", "[", "0.375", ",", "0.625", "]", "]", ",", "\n", "decimal", "=", "4", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.base.BaseTestDataset.setup_class": [[8, 150], ["os.normpath", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "mmcv.ConfigDict", "mmcv.ConfigDict", "mmcv.ConfigDict", "os.join", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "os.dirname", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["import", "numpy", "as", "np", "\n", "import", "torch", "\n", "from", "mmcv", ".", "utils", "import", "print_log", "\n", "from", "torch", ".", "utils", ".", "data", "import", "Dataset", "\n", "\n", "from", ".", ".", "core", "import", "(", "mean_average_precision", ",", "mean_class_accuracy", ",", "\n", "mmit_mean_average_precision", ",", "top_k_accuracy", ")", "\n", "from", ".", "pipelines", "import", "Compose", "\n", "\n", "\n", "class", "BaseDataset", "(", "Dataset", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    ", "\"\"\"Base class for datasets.\n\n    All datasets to process video should subclass it.\n    All subclasses should overwrite:\n\n    - Methods:`load_annotations`, supporting to load information from an\n    annotation file.\n    - Methods:`prepare_train_frames`, providing train data.\n    - Methods:`prepare_test_frames`, providing test data.\n\n    Args:\n        ann_file (str): Path to the annotation file.\n        pipeline (list[dict | callable]): A sequence of data transforms.\n        data_prefix (str | None): Path to a directory where videos are held.\n            Default: None.\n        test_mode (bool): Store True when building test or validation dataset.\n            Default: False.\n        multi_class (bool): Determines whether the dataset is a multi-class\n            dataset. Default: False.\n        num_classes (int | None): Number of classes of the dataset, used in\n            multi-class datasets. Default: None.\n        start_index (int): Specify a start index for frames in consideration of\n            different filename format. However, when taking videos as input,\n            it should be set to 0, since frames loaded from videos count\n            from 0. Default: 1.\n        modality (str): Modality of data. Support 'RGB', 'Flow', 'Audio'.\n            Default: 'RGB'.\n        sample_by_class (bool): Sampling by class, should be set `True` when\n            performing inter-class data balancing. Only compatible with\n            `multi_class == False`. Only applies for training. Default: False.\n        power (float): We support sampling data with the probability\n            proportional to the power of its label frequency (freq ^ power)\n            when sampling data. `power == 1` indicates uniformly sampling all\n            data; `power == 0` indicates uniformly sampling all classes.\n            Default: 0.\n        dynamic_length (bool): If the dataset length is dynamic (used by\n            ClassSpecificDistributedSampler). Default: False.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "ann_file", ",", "\n", "pipeline", ",", "\n", "data_prefix", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "multi_class", "=", "False", ",", "\n", "num_classes", "=", "None", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ",", "\n", "sample_by_class", "=", "False", ",", "\n", "power", "=", "0", ",", "\n", "dynamic_length", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "ann_file", "=", "ann_file", "\n", "self", ".", "data_prefix", "=", "osp", ".", "realpath", "(", "\n", "data_prefix", ")", "if", "data_prefix", "is", "not", "None", "and", "osp", ".", "isdir", "(", "\n", "data_prefix", ")", "else", "data_prefix", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "multi_class", "=", "multi_class", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "start_index", "=", "start_index", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "sample_by_class", "=", "sample_by_class", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "dynamic_length", "=", "dynamic_length", "\n", "\n", "assert", "not", "(", "self", ".", "multi_class", "and", "self", ".", "sample_by_class", ")", "\n", "\n", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "video_infos", "=", "self", ".", "load_annotations", "(", ")", "\n", "if", "self", ".", "sample_by_class", ":", "\n", "            ", "self", ".", "video_infos_by_class", "=", "self", ".", "parse_by_class", "(", ")", "\n", "\n", "class_prob", "=", "[", "]", "\n", "for", "_", ",", "samples", "in", "self", ".", "video_infos_by_class", ".", "items", "(", ")", ":", "\n", "                ", "class_prob", ".", "append", "(", "len", "(", "samples", ")", "/", "len", "(", "self", ".", "video_infos", ")", ")", "\n", "", "class_prob", "=", "[", "x", "**", "self", ".", "power", "for", "x", "in", "class_prob", "]", "\n", "\n", "summ", "=", "sum", "(", "class_prob", ")", "\n", "class_prob", "=", "[", "x", "/", "summ", "for", "x", "in", "class_prob", "]", "\n", "\n", "self", ".", "class_prob", "=", "dict", "(", "zip", "(", "self", ".", "video_infos_by_class", ",", "class_prob", ")", ")", "\n", "\n", "", "", "@", "abstractmethod", "\n", "def", "load_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load the annotation according to ann_file into video_infos.\"\"\"", "\n", "\n", "# json annotations already looks like video_infos, so for each dataset,", "\n", "# this func should be the same", "\n", "", "def", "load_json_annotations", "(", "self", ")", ":", "\n", "        ", "\"\"\"Load json annotation file to get video information.\"\"\"", "\n", "video_infos", "=", "mmcv", ".", "load", "(", "self", ".", "ann_file", ")", "\n", "num_videos", "=", "len", "(", "video_infos", ")", "\n", "path_key", "=", "'frame_dir'", "if", "'frame_dir'", "in", "video_infos", "[", "0", "]", "else", "'filename'", "\n", "for", "i", "in", "range", "(", "num_videos", ")", ":", "\n", "            ", "path_value", "=", "video_infos", "[", "i", "]", "[", "path_key", "]", "\n", "if", "self", ".", "data_prefix", "is", "not", "None", ":", "\n", "                ", "path_value", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "path_value", ")", "\n", "", "video_infos", "[", "i", "]", "[", "path_key", "]", "=", "path_value", "\n", "if", "self", ".", "multi_class", ":", "\n", "                ", "assert", "self", ".", "num_classes", "is", "not", "None", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "video_infos", "[", "i", "]", "[", "'label'", "]", ")", "==", "1", "\n", "video_infos", "[", "i", "]", "[", "'label'", "]", "=", "video_infos", "[", "i", "]", "[", "'label'", "]", "[", "0", "]", "\n", "", "", "return", "video_infos", "\n", "\n", "", "def", "parse_by_class", "(", "self", ")", ":", "\n", "        ", "video_infos_by_class", "=", "defaultdict", "(", "list", ")", "\n", "for", "item", "in", "self", ".", "video_infos", ":", "\n", "            ", "label", "=", "item", "[", "'label'", "]", "\n", "video_infos_by_class", "[", "label", "]", ".", "append", "(", "item", ")", "\n", "", "return", "video_infos_by_class", "\n", "\n", "", "@", "staticmethod", "\n", "def", "label2array", "(", "num", ",", "label", ")", ":", "\n", "        ", "arr", "=", "np", ".", "zeros", "(", "num", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "arr", "[", "label", "]", "=", "1.", "\n", "return", "arr", "\n", "\n", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metrics", "=", "'top_k_accuracy'", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "(", "1", ",", "5", ")", ")", ")", ",", "\n", "logger", "=", "None", ",", "\n", "**", "deprecated_kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_dataset.TestAudioDataset.test_audio_dataset": [[13, 23], ["mmaction.datasets.AudioDataset", "os.join", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "def", "test_audio_dataset", "(", "self", ")", ":", "\n", "        ", "audio_dataset", "=", "AudioDataset", "(", "\n", "self", ".", "audio_ann_file", ",", "\n", "self", ".", "audio_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "audio_infos", "=", "audio_dataset", ".", "video_infos", "\n", "wav_path", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'test.wav'", ")", "\n", "assert", "audio_infos", "==", "[", "\n", "dict", "(", "audio_path", "=", "wav_path", ",", "total_frames", "=", "100", ",", "label", "=", "127", ")", "\n", "]", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_dataset.TestAudioDataset.test_audio_pipeline": [[24, 47], ["mmaction.datasets.AudioDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.AudioDataset", "mmcv.utils.assert_dict_has_keys"], "methods", ["None"], ["", "def", "test_audio_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'audio_path'", ",", "'label'", ",", "'start_index'", ",", "'modality'", ",", "'audios_shape'", ",", "\n", "'length'", ",", "'sample_rate'", ",", "'total_frames'", "\n", "]", "\n", "\n", "# Audio dataset not in test mode", "\n", "audio_dataset", "=", "AudioDataset", "(", "\n", "self", ".", "audio_ann_file", ",", "\n", "self", ".", "audio_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "audio_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# Audio dataset in test mode", "\n", "audio_dataset", "=", "AudioDataset", "(", "\n", "self", ".", "audio_ann_file", ",", "\n", "self", ".", "audio_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "audio_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_dataset.TestAudioDataset.test_audio_evaluate": [[48, 78], ["mmaction.datasets.AudioDataset", "mmaction.datasets.AudioDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioDataset.evaluate", "set", "set", "numpy.array", "len", "dict", "len", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "test_audio_evaluate", "(", "self", ")", ":", "\n", "        ", "audio_dataset", "=", "AudioDataset", "(", "\n", "self", ".", "audio_ann_file", ",", "\n", "self", ".", "audio_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# results must be a list", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "'0.5'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The length of results must be equal to the dataset len", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# topk must be int or tuple of int", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "\n", "[", "0", "]", "*", "len", "(", "audio_dataset", ")", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "1.", ")", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# unsupported metric", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "len", "(", "audio_dataset", ")", ",", "metrics", "=", "'iou'", ")", "\n", "\n", "# evaluate top_k_accuracy and mean_class_accuracy metric", "\n", "", "results", "=", "[", "np", ".", "array", "(", "[", "0.1", ",", "0.5", ",", "0.4", "]", ")", "]", "*", "2", "\n", "eval_result", "=", "audio_dataset", ".", "evaluate", "(", "\n", "results", ",", "metrics", "=", "[", "'top_k_accuracy'", ",", "'mean_class_accuracy'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "\n", "[", "'top1_acc'", ",", "'top5_acc'", ",", "'mean_class_accuracy'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawframe_dataset.TestRawframDataset.test_rawframe_dataset": [[13, 23], ["mmaction.datasets.RawframeDataset", "os.join", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "def", "test_rawframe_dataset", "(", "self", ")", ":", "\n", "        ", "rawframe_dataset", "=", "RawframeDataset", "(", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "rawframe_infos", "=", "rawframe_dataset", ".", "video_infos", "\n", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs'", ")", "\n", "assert", "rawframe_infos", "==", "[", "\n", "dict", "(", "frame_dir", "=", "frame_dir", ",", "total_frames", "=", "5", ",", "label", "=", "127", ")", "\n", "]", "*", "2", "\n", "assert", "rawframe_dataset", ".", "start_index", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawframe_dataset.TestRawframDataset.test_rawframe_dataset_with_offset": [[24, 36], ["mmaction.datasets.RawframeDataset", "os.join", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_rawframe_dataset_with_offset", "(", "self", ")", ":", "\n", "        ", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file_with_offset", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "with_offset", "=", "True", ")", "\n", "rawframe_infos", "=", "rawframe_dataset", ".", "video_infos", "\n", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs'", ")", "\n", "assert", "rawframe_infos", "==", "[", "\n", "dict", "(", "frame_dir", "=", "frame_dir", ",", "offset", "=", "2", ",", "total_frames", "=", "5", ",", "label", "=", "127", ")", "\n", "]", "*", "2", "\n", "assert", "rawframe_dataset", ".", "start_index", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawframe_dataset.TestRawframDataset.test_rawframe_dataset_multi_label": [[37, 54], ["mmaction.datasets.RawframeDataset", "os.join", "zip", "set", "set"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_rawframe_dataset_multi_label", "(", "self", ")", ":", "\n", "        ", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file_multi_label", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "multi_class", "=", "True", ",", "\n", "num_classes", "=", "100", ")", "\n", "rawframe_infos", "=", "rawframe_dataset", ".", "video_infos", "\n", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs'", ")", "\n", "label0", "=", "[", "1", "]", "\n", "label1", "=", "[", "3", ",", "5", "]", "\n", "labels", "=", "[", "label0", ",", "label1", "]", "\n", "for", "info", ",", "label", "in", "zip", "(", "rawframe_infos", ",", "labels", ")", ":", "\n", "            ", "assert", "info", "[", "'frame_dir'", "]", "==", "frame_dir", "\n", "assert", "info", "[", "'total_frames'", "]", "==", "5", "\n", "assert", "set", "(", "info", "[", "'label'", "]", ")", "==", "set", "(", "label", ")", "\n", "", "assert", "rawframe_dataset", ".", "start_index", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawframe_dataset.TestRawframDataset.test_dataset_realpath": [[55, 66], ["mmaction.datasets.RawframeDataset", "mmaction.datasets.RawframeDataset", "mmaction.datasets.RawframeDataset", "os.realpath"], "methods", ["None"], ["", "def", "test_dataset_realpath", "(", "self", ")", ":", "\n", "        ", "dataset", "=", "RawframeDataset", "(", "self", ".", "frame_ann_file", ",", "self", ".", "frame_pipeline", ",", "\n", "'.'", ")", "\n", "assert", "dataset", ".", "data_prefix", "==", "osp", ".", "realpath", "(", "'.'", ")", "\n", "dataset", "=", "RawframeDataset", "(", "self", ".", "frame_ann_file", ",", "self", ".", "frame_pipeline", ",", "\n", "'s3://good'", ")", "\n", "assert", "dataset", ".", "data_prefix", "==", "'s3://good'", "\n", "\n", "dataset", "=", "RawframeDataset", "(", "self", ".", "frame_ann_file", ",", "self", ".", "frame_pipeline", ")", "\n", "assert", "dataset", ".", "data_prefix", "is", "None", "\n", "assert", "dataset", ".", "video_infos", "[", "0", "]", "[", "'frame_dir'", "]", "==", "'imgs'", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawframe_dataset.TestRawframDataset.test_rawframe_pipeline": [[67, 134], ["mmaction.datasets.RawframeDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.RawframeDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.RawframeDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.RawframeDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.RawframeDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.RawframeDataset", "mmcv.utils.assert_dict_has_keys"], "methods", ["None"], ["", "def", "test_rawframe_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_dir'", ",", "'total_frames'", ",", "'label'", ",", "'filename_tmpl'", ",", "\n", "'start_index'", ",", "'modality'", "\n", "]", "\n", "\n", "# RawframeDataset not in test mode", "\n", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "rawframe_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# RawframeDataset in multi-class tasks", "\n", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "multi_class", "=", "True", ",", "\n", "num_classes", "=", "400", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "rawframe_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# RawframeDataset with offset", "\n", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file_with_offset", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "with_offset", "=", "True", ",", "\n", "num_classes", "=", "400", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "rawframe_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", "+", "[", "'offset'", "]", ")", "\n", "\n", "# RawframeDataset in test mode", "\n", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "rawframe_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# RawframeDataset in multi-class tasks in test mode", "\n", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "multi_class", "=", "True", ",", "\n", "num_classes", "=", "400", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "rawframe_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# RawframeDataset with offset", "\n", "rawframe_dataset", "=", "RawframeDataset", "(", "\n", "self", ".", "frame_ann_file_with_offset", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "with_offset", "=", "True", ",", "\n", "num_classes", "=", "400", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "rawframe_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", "+", "[", "'offset'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawframe_dataset.TestRawframDataset.test_rawframe_evaluate": [[135, 165], ["mmaction.datasets.RawframeDataset", "mmaction.datasets.RawframeDataset.evaluate", "pytest.raises", "mmaction.datasets.RawframeDataset.evaluate", "pytest.raises", "mmaction.datasets.RawframeDataset.evaluate", "pytest.raises", "mmaction.datasets.RawframeDataset.evaluate", "pytest.raises", "mmaction.datasets.RawframeDataset.evaluate", "set", "set", "numpy.array", "len", "dict", "len", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "test_rawframe_evaluate", "(", "self", ")", ":", "\n", "        ", "rawframe_dataset", "=", "RawframeDataset", "(", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# results must be a list", "\n", "            ", "rawframe_dataset", ".", "evaluate", "(", "'0.5'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The length of results must be equal to the dataset len", "\n", "            ", "rawframe_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# topk must be int or tuple of int", "\n", "            ", "rawframe_dataset", ".", "evaluate", "(", "\n", "[", "0", "]", "*", "len", "(", "rawframe_dataset", ")", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "1.", ")", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# unsupported metric", "\n", "            ", "rawframe_dataset", ".", "evaluate", "(", "\n", "[", "0", "]", "*", "len", "(", "rawframe_dataset", ")", ",", "metrics", "=", "'iou'", ")", "\n", "\n", "# evaluate top_k_accuracy and mean_class_accuracy metric", "\n", "", "results", "=", "[", "np", ".", "array", "(", "[", "0.1", ",", "0.5", ",", "0.4", "]", ")", "]", "*", "2", "\n", "eval_result", "=", "rawframe_dataset", ".", "evaluate", "(", "\n", "results", ",", "metrics", "=", "[", "'top_k_accuracy'", ",", "'mean_class_accuracy'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "\n", "[", "'top1_acc'", ",", "'top5_acc'", ",", "'mean_class_accuracy'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_repeat_dataset.TestRepeatDataset.test_repeat_dataset": [[9, 27], ["mmaction.datasets.RawframeDataset", "mmaction.datasets.RepeatDataset", "len", "set", "set", "isinstance", "numpy.equal().all", "isinstance", "all", "numpy.equal", "numpy.array_equal", "zip"], "methods", ["None"], ["    ", "def", "test_repeat_dataset", "(", "self", ")", ":", "\n", "        ", "rawframe_dataset", "=", "RawframeDataset", "(", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "repeat_dataset", "=", "RepeatDataset", "(", "rawframe_dataset", ",", "5", ")", "\n", "assert", "len", "(", "repeat_dataset", ")", "==", "10", "\n", "result_a", "=", "repeat_dataset", "[", "0", "]", "\n", "result_b", "=", "repeat_dataset", "[", "2", "]", "\n", "assert", "set", "(", "result_a", ")", "==", "set", "(", "result_b", ")", "\n", "for", "key", "in", "result_a", ":", "\n", "            ", "if", "isinstance", "(", "result_a", "[", "key", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "assert", "np", ".", "equal", "(", "result_a", "[", "key", "]", ",", "result_b", "[", "key", "]", ")", ".", "all", "(", ")", "\n", "", "elif", "isinstance", "(", "result_a", "[", "key", "]", ",", "list", ")", ":", "\n", "                ", "assert", "all", "(", "\n", "np", ".", "array_equal", "(", "a", ",", "b", ")", "\n", "for", "(", "a", ",", "b", ")", "in", "zip", "(", "result_a", "[", "key", "]", ",", "result_b", "[", "key", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "assert", "result_a", "[", "key", "]", "==", "result_b", "[", "key", "]", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_visual_dataset.TestAudioVisualDataset.test_audio_visual_dataset": [[9, 29], ["mmaction.datasets.AudioVisualDataset", "os.join", "os.join", "os.join", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "def", "test_audio_visual_dataset", "(", "self", ")", ":", "\n", "        ", "test_dataset", "=", "AudioVisualDataset", "(", "\n", "self", ".", "frame_ann_file", ",", "\n", "self", ".", "frame_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "video_prefix", "=", "self", ".", "data_prefix", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "video_infos", "=", "test_dataset", ".", "video_infos", "\n", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs'", ")", "\n", "audio_path", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs.npy'", ")", "\n", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs.mp4'", ")", "\n", "assert", "video_infos", "==", "[", "\n", "dict", "(", "\n", "frame_dir", "=", "frame_dir", ",", "\n", "audio_path", "=", "audio_path", ",", "\n", "filename", "=", "filename", ",", "\n", "total_frames", "=", "5", ",", "\n", "label", "=", "127", ")", "\n", "]", "*", "2", "\n", "assert", "test_dataset", ".", "start_index", "==", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ssn_dataset.TestSSNDataset.test_proposal_pipeline": [[11, 57], ["mmaction.datasets.SSNDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.SSNDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.SSNDataset", "mmcv.utils.assert_dict_has_keys"], "methods", ["None"], ["    ", "def", "test_proposal_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_dir'", ",", "'video_id'", ",", "'total_frames'", ",", "'gts'", ",", "'proposals'", ",", "\n", "'filename_tmpl'", ",", "'modality'", ",", "'out_proposals'", ",", "'reg_targets'", ",", "\n", "'proposal_scale_factor'", ",", "'proposal_labels'", ",", "'proposal_type'", ",", "\n", "'start_index'", "\n", "]", "\n", "\n", "# SSN Dataset not in test mode", "\n", "proposal_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "result", "=", "proposal_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# SSN Dataset with random sampling proposals", "\n", "proposal_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "video_centric", "=", "False", ")", "\n", "result", "=", "proposal_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "target_keys", "=", "[", "\n", "'frame_dir'", ",", "'video_id'", ",", "'total_frames'", ",", "'gts'", ",", "'proposals'", ",", "\n", "'filename_tmpl'", ",", "'modality'", ",", "'relative_proposal_list'", ",", "\n", "'scale_factor_list'", ",", "'proposal_tick_list'", ",", "'reg_norm_consts'", ",", "\n", "'start_index'", "\n", "]", "\n", "\n", "# SSN Dataset in test mode", "\n", "proposal_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_test_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "proposal_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ssn_dataset.TestSSNDataset.test_ssn_dataset": [[58, 114], ["mmaction.datasets.SSNDataset", "mmaction.datasets.SSNDataset", "mmaction.datasets.SSNDataset", "pytest.raises", "mmaction.datasets.SSNDataset", "pytest.raises", "mmaction.datasets.SSNDataset"], "methods", ["None"], ["", "def", "test_ssn_dataset", "(", "self", ")", ":", "\n", "# test ssn dataset", "\n", "        ", "ssn_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "ssn_infos", "=", "ssn_dataset", ".", "video_infos", "\n", "assert", "ssn_infos", "[", "0", "]", "[", "'video_id'", "]", "==", "'imgs'", "\n", "assert", "ssn_infos", "[", "0", "]", "[", "'total_frames'", "]", "==", "5", "\n", "\n", "# test ssn dataset with verbose", "\n", "ssn_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "verbose", "=", "True", ")", "\n", "ssn_infos", "=", "ssn_dataset", ".", "video_infos", "\n", "assert", "ssn_infos", "[", "0", "]", "[", "'video_id'", "]", "==", "'imgs'", "\n", "assert", "ssn_infos", "[", "0", "]", "[", "'total_frames'", "]", "==", "5", "\n", "\n", "# test ssn datatset with normalized proposal file", "\n", "with", "pytest", ".", "raises", "(", "Exception", ")", ":", "\n", "            ", "ssn_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_norm_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "ssn_infos", "=", "ssn_dataset", ".", "video_infos", "\n", "\n", "# test ssn dataset with reg_normalize_constants", "\n", "", "ssn_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "reg_normalize_constants", "=", "[", "[", "[", "-", "0.0603", ",", "0.0325", "]", ",", "[", "0.0752", ",", "0.1596", "]", "]", "]", ")", "\n", "ssn_infos", "=", "ssn_dataset", ".", "video_infos", "\n", "assert", "ssn_infos", "[", "0", "]", "[", "'video_id'", "]", "==", "'imgs'", "\n", "assert", "ssn_infos", "[", "0", "]", "[", "'total_frames'", "]", "==", "5", "\n", "\n", "# test error case", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "            ", "ssn_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "aug_ratio", "=", "(", "'error'", ",", "'error'", ")", ")", "\n", "ssn_infos", "=", "ssn_dataset", ".", "video_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ssn_dataset.TestSSNDataset.test_ssn_evaluate": [[115, 175], ["mmaction.datasets.SSNDataset", "mmaction.datasets.SSNDataset", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "mmaction.datasets.SSNDataset.evaluate", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "mmaction.datasets.SSNDataset.evaluate", "pytest.raises", "mmaction.datasets.SSNDataset.evaluate", "pytest.raises", "mmaction.datasets.SSNDataset.evaluate", "pytest.raises", "mmaction.datasets.SSNDataset.evaluate", "dict", "set", "set", "dict", "set", "set", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "", "def", "test_ssn_evaluate", "(", "self", ")", ":", "\n", "        ", "ssn_dataset", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "ssn_dataset_topall", "=", "SSNDataset", "(", "\n", "self", ".", "proposal_ann_file", ",", "\n", "self", ".", "proposal_pipeline", ",", "\n", "self", ".", "proposal_train_cfg", ",", "\n", "self", ".", "proposal_test_cfg_topall", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# results must be a list", "\n", "            ", "ssn_dataset", ".", "evaluate", "(", "'0.5'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The length of results must be equal to the dataset len", "\n", "            ", "ssn_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# unsupported metric", "\n", "            ", "ssn_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "len", "(", "ssn_dataset", ")", ",", "metrics", "=", "'iou'", ")", "\n", "\n", "# evaluate mAP metric", "\n", "", "results_relative_proposal_list", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "2", ")", "\n", "results_activity_scores", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "21", ")", "\n", "results_completeness_scores", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "20", ")", "\n", "results_bbox_preds", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "20", ",", "2", ")", "\n", "results", "=", "[", "\n", "dict", "(", "\n", "relative_proposal_list", "=", "results_relative_proposal_list", ",", "\n", "activity_scores", "=", "results_activity_scores", ",", "\n", "completeness_scores", "=", "results_completeness_scores", ",", "\n", "bbox_preds", "=", "results_bbox_preds", ")", "\n", "]", "\n", "eval_result", "=", "ssn_dataset", ".", "evaluate", "(", "results", ",", "metrics", "=", "[", "'mAP'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "[", "\n", "'mAP@0.10'", ",", "'mAP@0.20'", ",", "'mAP@0.30'", ",", "'mAP@0.40'", ",", "'mAP@0.50'", ",", "\n", "'mAP@0.50'", ",", "'mAP@0.60'", ",", "'mAP@0.70'", ",", "'mAP@0.80'", ",", "'mAP@0.90'", "\n", "]", ")", "\n", "\n", "# evaluate mAP metric without filtering topk", "\n", "results_relative_proposal_list", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "2", ")", "\n", "results_activity_scores", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "21", ")", "\n", "results_completeness_scores", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "20", ")", "\n", "results_bbox_preds", "=", "np", ".", "random", ".", "randn", "(", "16", ",", "20", ",", "2", ")", "\n", "results", "=", "[", "\n", "dict", "(", "\n", "relative_proposal_list", "=", "results_relative_proposal_list", ",", "\n", "activity_scores", "=", "results_activity_scores", ",", "\n", "completeness_scores", "=", "results_completeness_scores", ",", "\n", "bbox_preds", "=", "results_bbox_preds", ")", "\n", "]", "\n", "eval_result", "=", "ssn_dataset_topall", ".", "evaluate", "(", "results", ",", "metrics", "=", "[", "'mAP'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "[", "\n", "'mAP@0.10'", ",", "'mAP@0.20'", ",", "'mAP@0.30'", ",", "'mAP@0.40'", ",", "'mAP@0.50'", ",", "\n", "'mAP@0.50'", ",", "'mAP@0.60'", ",", "'mAP@0.70'", ",", "'mAP@0.80'", ",", "'mAP@0.90'", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_feature_dataset.TestAudioFeatureDataset.test_audio_feature_dataset": [[13, 23], ["mmaction.datasets.AudioFeatureDataset", "os.join", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "def", "test_audio_feature_dataset", "(", "self", ")", ":", "\n", "        ", "audio_dataset", "=", "AudioFeatureDataset", "(", "\n", "self", ".", "audio_feature_ann_file", ",", "\n", "self", ".", "audio_feature_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "audio_infos", "=", "audio_dataset", ".", "video_infos", "\n", "feature_path", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'test.npy'", ")", "\n", "assert", "audio_infos", "==", "[", "\n", "dict", "(", "audio_path", "=", "feature_path", ",", "total_frames", "=", "100", ",", "label", "=", "127", ")", "\n", "]", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_feature_dataset.TestAudioFeatureDataset.test_audio_feature_pipeline": [[24, 47], ["mmaction.datasets.AudioFeatureDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.AudioFeatureDataset", "mmcv.utils.assert_dict_has_keys"], "methods", ["None"], ["", "def", "test_audio_feature_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'audio_path'", ",", "'label'", ",", "'start_index'", ",", "'modality'", ",", "'audios'", ",", "\n", "'total_frames'", "\n", "]", "\n", "\n", "# Audio feature dataset not in test mode", "\n", "audio_feature_dataset", "=", "AudioFeatureDataset", "(", "\n", "self", ".", "audio_feature_ann_file", ",", "\n", "self", ".", "audio_feature_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "audio_feature_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# Audio dataset in test mode", "\n", "audio_feature_dataset", "=", "AudioFeatureDataset", "(", "\n", "self", ".", "audio_feature_ann_file", ",", "\n", "self", ".", "audio_feature_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "audio_feature_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_audio_feature_dataset.TestAudioFeatureDataset.test_audio_feature_evaluate": [[48, 78], ["mmaction.datasets.AudioFeatureDataset", "mmaction.datasets.AudioFeatureDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioFeatureDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioFeatureDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioFeatureDataset.evaluate", "pytest.raises", "mmaction.datasets.AudioFeatureDataset.evaluate", "set", "set", "numpy.array", "len", "dict", "len", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "test_audio_feature_evaluate", "(", "self", ")", ":", "\n", "        ", "audio_dataset", "=", "AudioFeatureDataset", "(", "\n", "self", ".", "audio_feature_ann_file", ",", "\n", "self", ".", "audio_feature_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# results must be a list", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "'0.5'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The length of results must be equal to the dataset len", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# topk must be int or tuple of int", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "\n", "[", "0", "]", "*", "len", "(", "audio_dataset", ")", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "1.", ")", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# unsupported metric", "\n", "            ", "audio_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "len", "(", "audio_dataset", ")", ",", "metrics", "=", "'iou'", ")", "\n", "\n", "# evaluate top_k_accuracy and mean_class_accuracy metric", "\n", "", "results", "=", "[", "np", ".", "array", "(", "[", "0.1", ",", "0.5", ",", "0.4", "]", ")", "]", "*", "2", "\n", "eval_result", "=", "audio_dataset", ".", "evaluate", "(", "\n", "results", ",", "metrics", "=", "[", "'top_k_accuracy'", ",", "'mean_class_accuracy'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "\n", "[", "'top1_acc'", ",", "'top5_acc'", ",", "'mean_class_accuracy'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ava_dataset.TestAVADataset.setup_class": [[13, 27], ["os.normpath", "os.join", "os.join", "os.join", "os.join", "mmcv.load", "os.join", "dict", "os.dirname", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "@", "classmethod", "\n", "def", "setup_class", "(", "cls", ")", ":", "\n", "        ", "cls", ".", "data_prefix", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../../data'", ",", "'ava_dataset'", ")", ")", "\n", "cls", ".", "label_file", "=", "osp", ".", "join", "(", "cls", ".", "data_prefix", ",", "'action_list.txt'", ")", "\n", "cls", ".", "ann_file", "=", "osp", ".", "join", "(", "cls", ".", "data_prefix", ",", "'ava_sample.csv'", ")", "\n", "cls", ".", "exclude_file", "=", "osp", ".", "join", "(", "cls", ".", "data_prefix", ",", "\n", "'ava_excluded_timestamps_sample.csv'", ")", "\n", "cls", ".", "proposal_file", "=", "osp", ".", "join", "(", "cls", ".", "data_prefix", ",", "\n", "'ava_proposals_sample.pkl'", ")", "\n", "cls", ".", "pipeline", "=", "[", "\n", "dict", "(", "dict", "(", "type", "=", "'SampleAVAFrames'", ",", "clip_len", "=", "32", ",", "frame_interval", "=", "2", ")", ")", "\n", "]", "\n", "cls", ".", "proposal", "=", "mmcv", ".", "load", "(", "cls", ".", "proposal_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ava_dataset.TestAVADataset.test_ava_dataset": [[28, 111], ["mmaction.datasets.AVADataset", "mmcv.utils.assert_dict_has_keys", "mmcv.utils.assert_dict_has_keys", "mmcv.utils.assert_dict_has_keys", "numpy.array", "numpy.zeros", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "mmaction.datasets.AVADataset", "numpy.array", "numpy.zeros", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "mmaction.datasets.AVADataset", "mmaction.datasets.AVADataset", "mmaction.datasets.AVADataset", "len", "os.join", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_ava_dataset", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_dir'", ",", "'video_id'", ",", "'timestamp'", ",", "'img_key'", ",", "'shot_info'", ",", "\n", "'fps'", ",", "'ann'", "\n", "]", "\n", "ann_keys", "=", "[", "'gt_labels'", ",", "'gt_bboxes'", ",", "'entity_ids'", "]", "\n", "pkl_keys", "=", "[", "'0f39OWEqJ24,0902'", ",", "'0f39OWEqJ24,0903'", ",", "'_-Z6wFjXtGQ,0902'", "]", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "self", ".", "exclude_file", ",", "\n", "self", ".", "pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "ava_infos", "=", "ava_dataset", ".", "video_infos", "\n", "assert", "assert_dict_has_keys", "(", "ava_dataset", ".", "proposals", ",", "pkl_keys", ")", "\n", "\n", "assert", "assert_dict_has_keys", "(", "ava_infos", "[", "0", "]", ",", "target_keys", ")", "\n", "assert", "assert_dict_has_keys", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", ",", "ann_keys", ")", "\n", "assert", "len", "(", "ava_infos", ")", "==", "1", "\n", "assert", "ava_infos", "[", "0", "]", "[", "'frame_dir'", "]", "==", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "\n", "'0f39OWEqJ24'", ")", "\n", "assert", "ava_infos", "[", "0", "]", "[", "'video_id'", "]", "==", "'0f39OWEqJ24'", "\n", "assert", "ava_infos", "[", "0", "]", "[", "'timestamp'", "]", "==", "902", "\n", "assert", "ava_infos", "[", "0", "]", "[", "'img_key'", "]", "==", "'0f39OWEqJ24,0902'", "\n", "assert", "ava_infos", "[", "0", "]", "[", "'shot_info'", "]", "==", "(", "0", ",", "27000", ")", "\n", "assert", "ava_infos", "[", "0", "]", "[", "'fps'", "]", "==", "30", "\n", "assert", "len", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", ")", "==", "3", "\n", "target_labels", "=", "np", ".", "array", "(", "[", "12", ",", "17", ",", "79", "]", ")", "\n", "labels", "=", "np", ".", "zeros", "(", "[", "81", "]", ")", "\n", "labels", "[", "target_labels", "]", "=", "1.", "\n", "target_labels", "=", "labels", "[", "None", ",", "...", "]", "\n", "assert_array_equal", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", "[", "'gt_labels'", "]", ",", "target_labels", ")", "\n", "assert_array_equal", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", "[", "'gt_bboxes'", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.031", ",", "0.162", ",", "0.67", ",", "0.995", "]", "]", ")", ")", "\n", "assert_array_equal", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", "[", "'entity_ids'", "]", ",", "np", ".", "array", "(", "[", "0", "]", ")", ")", "\n", "\n", "# custom classes", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "self", ".", "exclude_file", ",", "\n", "self", ".", "pipeline", ",", "\n", "label_file", "=", "self", ".", "label_file", ",", "\n", "custom_classes", "=", "[", "17", ",", "79", "]", ",", "\n", "num_classes", "=", "3", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "ava_infos", "=", "ava_dataset", ".", "video_infos", "\n", "target_labels", "=", "np", ".", "array", "(", "[", "1", ",", "2", "]", ")", "\n", "labels", "=", "np", ".", "zeros", "(", "[", "3", "]", ")", "\n", "labels", "[", "target_labels", "]", "=", "1.", "\n", "target_labels", "=", "labels", "[", "None", ",", "...", "]", "\n", "assert_array_equal", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", "[", "'gt_labels'", "]", ",", "target_labels", ")", "\n", "assert_array_equal", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", "[", "'gt_bboxes'", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.031", ",", "0.162", ",", "0.67", ",", "0.995", "]", "]", ")", ")", "\n", "assert_array_equal", "(", "ava_infos", "[", "0", "]", "[", "'ann'", "]", "[", "'entity_ids'", "]", ",", "np", ".", "array", "(", "[", "0", "]", ")", ")", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "None", ",", "\n", "self", ".", "pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "ava_infos", "=", "ava_dataset", ".", "video_infos", "\n", "assert", "len", "(", "ava_infos", ")", "==", "3", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "None", ",", "\n", "self", ".", "pipeline", ",", "\n", "test_mode", "=", "True", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "ava_infos", "=", "ava_dataset", ".", "video_infos", "\n", "assert", "len", "(", "ava_infos", ")", "==", "3", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "None", ",", "\n", "self", ".", "pipeline", ",", "\n", "test_mode", "=", "True", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ava_dataset.TestAVADataset.test_ava_pipeline": [[112, 157], ["mmaction.datasets.AVADataset", "mmcv.utils.assert_dict_has_keys", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "mmaction.datasets.AVADataset", "numpy.array", "numpy.array", "len"], "methods", ["None"], ["", "def", "test_ava_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "\n", "'frame_dir'", ",", "'video_id'", ",", "'timestamp'", ",", "'img_key'", ",", "'shot_info'", ",", "\n", "'fps'", ",", "'filename_tmpl'", ",", "'modality'", ",", "'start_index'", ",", "\n", "'timestamp_start'", ",", "'timestamp_end'", ",", "'proposals'", ",", "'scores'", ",", "\n", "'frame_inds'", ",", "'clip_len'", ",", "'frame_interval'", ",", "'gt_labels'", ",", "\n", "'gt_bboxes'", ",", "'entity_ids'", "\n", "]", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "self", ".", "exclude_file", ",", "\n", "self", ".", "pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "result", "=", "ava_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "assert", "result", "[", "'filename_tmpl'", "]", "==", "'img_{:05}.jpg'", "\n", "assert", "result", "[", "'modality'", "]", "==", "'RGB'", "\n", "assert", "result", "[", "'start_index'", "]", "==", "1", "\n", "assert", "result", "[", "'timestamp_start'", "]", "==", "900", "\n", "assert", "result", "[", "'timestamp_end'", "]", "==", "1800", "\n", "assert_array_equal", "(", "result", "[", "'proposals'", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.011", ",", "0.157", ",", "0.655", ",", "0.983", "]", "]", ")", ")", "\n", "assert_array_equal", "(", "result", "[", "'scores'", "]", ",", "np", ".", "array", "(", "[", "0.998163", "]", ")", ")", "\n", "\n", "assert", "result", "[", "'clip_len'", "]", "==", "32", "\n", "assert", "result", "[", "'frame_interval'", "]", "==", "2", "\n", "assert", "len", "(", "result", "[", "'frame_inds'", "]", ")", "==", "32", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "self", ".", "ann_file", ",", "\n", "None", ",", "\n", "self", ".", "pipeline", ",", "\n", "test_mode", "=", "True", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "proposal_file", "=", "self", ".", "proposal_file", ")", "\n", "# Try to get a sample", "\n", "result", "=", "ava_dataset", "[", "0", "]", "\n", "assert", "result", "[", "'filename_tmpl'", "]", "==", "'img_{:05}.jpg'", "\n", "assert", "result", "[", "'modality'", "]", "==", "'RGB'", "\n", "assert", "result", "[", "'start_index'", "]", "==", "1", "\n", "assert", "result", "[", "'timestamp_start'", "]", "==", "900", "\n", "assert", "result", "[", "'timestamp_end'", "]", "==", "1800", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_ava_dataset.TestAVADataset.test_ava_evaluate": [[158, 221], ["os.normpath", "os.join", "os.join", "mmaction.datasets.AVADataset", "mmaction.datasets.AVADataset.evaluate", "numpy.testing.assert_array_almost_equal", "mmaction.datasets.AVADataset", "mmaction.datasets.AVADataset.evaluate", "numpy.testing.assert_array_almost_equal", "os.join", "os.dirname", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "@", "staticmethod", "\n", "def", "test_ava_evaluate", "(", ")", ":", "\n", "        ", "data_prefix", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../../data'", ",", "'eval_detection'", ")", ")", "\n", "ann_file", "=", "osp", ".", "join", "(", "data_prefix", ",", "'gt.csv'", ")", "\n", "label_file", "=", "osp", ".", "join", "(", "data_prefix", ",", "'action_list.txt'", ")", "\n", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "ann_file", ",", "None", ",", "[", "]", ",", "label_file", "=", "label_file", ",", "num_classes", "=", "4", ")", "\n", "fake_result", "=", "[", "[", "\n", "np", ".", "array", "(", "[", "[", "0.362", ",", "0.156", ",", "0.969", ",", "0.666", ",", "0.106", "]", ",", "\n", "[", "0.442", ",", "0.083", ",", "0.721", ",", "0.947", ",", "0.162", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.288", ",", "0.365", ",", "0.766", ",", "0.551", ",", "0.706", "]", ",", "\n", "[", "0.178", ",", "0.296", ",", "0.707", ",", "0.995", ",", "0.223", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.417", ",", "0.167", ",", "0.843", ",", "0.939", ",", "0.015", "]", ",", "\n", "[", "0.35", ",", "0.421", ",", "0.57", ",", "0.689", ",", "0.427", "]", "]", ")", "\n", "]", ",", "\n", "[", "\n", "np", ".", "array", "(", "[", "[", "0.256", ",", "0.338", ",", "0.726", ",", "0.799", ",", "0.563", "]", ",", "\n", "[", "0.071", ",", "0.256", ",", "0.64", ",", "0.75", ",", "0.297", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.326", ",", "0.036", ",", "0.513", ",", "0.991", ",", "0.405", "]", ",", "\n", "[", "0.351", ",", "0.035", ",", "0.729", ",", "0.936", ",", "0.945", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.051", ",", "0.005", ",", "0.975", ",", "0.942", ",", "0.424", "]", ",", "\n", "[", "0.347", ",", "0.05", ",", "0.97", ",", "0.944", ",", "0.396", "]", "]", ")", "\n", "]", ",", "\n", "[", "\n", "np", ".", "array", "(", "[", "[", "0.39", ",", "0.087", ",", "0.833", ",", "0.616", ",", "0.447", "]", ",", "\n", "[", "0.461", ",", "0.212", ",", "0.627", ",", "0.527", ",", "0.036", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.022", ",", "0.394", ",", "0.93", ",", "0.527", ",", "0.109", "]", ",", "\n", "[", "0.208", ",", "0.462", ",", "0.874", ",", "0.948", ",", "0.954", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.206", ",", "0.456", ",", "0.564", ",", "0.725", ",", "0.685", "]", ",", "\n", "[", "0.106", ",", "0.445", ",", "0.782", ",", "0.673", ",", "0.367", "]", "]", ")", "\n", "]", "]", "\n", "res", "=", "ava_dataset", ".", "evaluate", "(", "fake_result", ")", "\n", "assert_array_almost_equal", "(", "res", "[", "'mAP@0.5IOU'", "]", ",", "0.027777778", ")", "\n", "\n", "# custom classes", "\n", "ava_dataset", "=", "AVADataset", "(", "\n", "ann_file", ",", "\n", "None", ",", "[", "]", ",", "\n", "label_file", "=", "label_file", ",", "\n", "num_classes", "=", "3", ",", "\n", "custom_classes", "=", "[", "1", ",", "3", "]", ")", "\n", "fake_result", "=", "[", "[", "\n", "np", ".", "array", "(", "[", "[", "0.362", ",", "0.156", ",", "0.969", ",", "0.666", ",", "0.106", "]", ",", "\n", "[", "0.442", ",", "0.083", ",", "0.721", ",", "0.947", ",", "0.162", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.417", ",", "0.167", ",", "0.843", ",", "0.939", ",", "0.015", "]", ",", "\n", "[", "0.35", ",", "0.421", ",", "0.57", ",", "0.689", ",", "0.427", "]", "]", ")", "\n", "]", ",", "\n", "[", "\n", "np", ".", "array", "(", "[", "[", "0.256", ",", "0.338", ",", "0.726", ",", "0.799", ",", "0.563", "]", ",", "\n", "[", "0.071", ",", "0.256", ",", "0.64", ",", "0.75", ",", "0.297", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.051", ",", "0.005", ",", "0.975", ",", "0.942", ",", "0.424", "]", ",", "\n", "[", "0.347", ",", "0.05", ",", "0.97", ",", "0.944", ",", "0.396", "]", "]", ")", "\n", "]", ",", "\n", "[", "\n", "np", ".", "array", "(", "[", "[", "0.39", ",", "0.087", ",", "0.833", ",", "0.616", ",", "0.447", "]", ",", "\n", "[", "0.461", ",", "0.212", ",", "0.627", ",", "0.527", ",", "0.036", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "0.206", ",", "0.456", ",", "0.564", ",", "0.725", ",", "0.685", "]", ",", "\n", "[", "0.106", ",", "0.445", ",", "0.782", ",", "0.673", ",", "0.367", "]", "]", ")", "\n", "]", "]", "\n", "res", "=", "ava_dataset", ".", "evaluate", "(", "fake_result", ")", "\n", "assert_array_almost_equal", "(", "res", "[", "'mAP@0.5IOU'", "]", ",", "0.04166667", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_pose_dataset.TestPoseDataset.test_pose_dataset": [[10, 62], ["mmaction.datasets.PoseDataset", "item[].startswith", "mmaction.datasets.PoseDataset", "mmaction.datasets.PoseDataset", "mmaction.datasets.PoseDataset", "len", "len", "item[].startswith", "numpy.all", "len", "item[].startswith", "numpy.all", "pytest.raises", "mmaction.datasets.PoseDataset", "range"], "methods", ["None"], ["    ", "def", "test_pose_dataset", "(", "self", ")", ":", "\n", "        ", "ann_file", "=", "self", ".", "pose_ann_file", "\n", "data_prefix", "=", "'root'", "\n", "dataset", "=", "PoseDataset", "(", "\n", "ann_file", "=", "ann_file", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "box_thr", "=", "'0.5'", ",", "\n", "data_prefix", "=", "data_prefix", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "100", "\n", "item", "=", "dataset", "[", "0", "]", "\n", "assert", "item", "[", "'filename'", "]", ".", "startswith", "(", "data_prefix", ")", "\n", "\n", "dataset", "=", "PoseDataset", "(", "\n", "ann_file", "=", "ann_file", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "valid_ratio", "=", "0.2", ",", "\n", "box_thr", "=", "'0.9'", ",", "\n", "data_prefix", "=", "data_prefix", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "84", "\n", "for", "item", "in", "dataset", ":", "\n", "            ", "assert", "item", "[", "'filename'", "]", ".", "startswith", "(", "data_prefix", ")", "\n", "assert", "np", ".", "all", "(", "item", "[", "'box_score'", "]", "[", "item", "[", "'anno_inds'", "]", "]", ">=", "0.9", ")", "\n", "assert", "item", "[", "'valid@0.9'", "]", "/", "item", "[", "'total_frames'", "]", ">=", "0.2", "\n", "\n", "", "dataset", "=", "PoseDataset", "(", "\n", "ann_file", "=", "ann_file", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "valid_ratio", "=", "0.3", ",", "\n", "box_thr", "=", "'0.7'", ",", "\n", "data_prefix", "=", "data_prefix", ")", "\n", "assert", "len", "(", "dataset", ")", "==", "87", "\n", "for", "item", "in", "dataset", ":", "\n", "            ", "assert", "item", "[", "'filename'", "]", ".", "startswith", "(", "data_prefix", ")", "\n", "assert", "np", ".", "all", "(", "item", "[", "'box_score'", "]", "[", "item", "[", "'anno_inds'", "]", "]", ">=", "0.7", ")", "\n", "assert", "item", "[", "'valid@0.7'", "]", "/", "item", "[", "'total_frames'", "]", ">=", "0.3", "\n", "\n", "", "class_prob", "=", "{", "i", ":", "1", "for", "i", "in", "range", "(", "400", ")", "}", "\n", "dataset", "=", "PoseDataset", "(", "\n", "ann_file", "=", "ann_file", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "valid_ratio", "=", "0.3", ",", "\n", "box_thr", "=", "'0.7'", ",", "\n", "data_prefix", "=", "data_prefix", ",", "\n", "class_prob", "=", "class_prob", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "dataset", "=", "PoseDataset", "(", "\n", "ann_file", "=", "ann_file", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "valid_ratio", "=", "0.2", ",", "\n", "box_thr", "=", "'0.55'", ",", "\n", "data_prefix", "=", "data_prefix", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_rawvideo_dataset.TestRawVideoDataset.test_rawvideo_dataset": [[9, 30], ["mmaction.datasets.RawVideoDataset", "os.join", "mmaction.datasets.RawVideoDataset"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "def", "test_rawvideo_dataset", "(", "self", ")", ":", "\n", "# Try to load txt file", "\n", "        ", "rawvideo_dataset", "=", "RawVideoDataset", "(", "\n", "ann_file", "=", "self", ".", "rawvideo_test_anno_txt", ",", "\n", "pipeline", "=", "self", ".", "rawvideo_pipeline", ",", "\n", "clipname_tmpl", "=", "'part_{}.mp4'", ",", "\n", "sampling_strategy", "=", "'positive'", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "result", "=", "rawvideo_dataset", "[", "0", "]", "\n", "clipname", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'rawvideo_dataset'", ",", "'part_0.mp4'", ")", "\n", "assert", "result", "[", "'filename'", "]", "==", "clipname", "\n", "\n", "# Try to load json file", "\n", "rawvideo_dataset", "=", "RawVideoDataset", "(", "\n", "ann_file", "=", "self", ".", "rawvideo_test_anno_json", ",", "\n", "pipeline", "=", "self", ".", "rawvideo_pipeline", ",", "\n", "clipname_tmpl", "=", "'part_{}.mp4'", ",", "\n", "sampling_strategy", "=", "'random'", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "rawvideo_dataset", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_video_dataset.TestVideoDataset.test_video_dataset": [[13, 30], ["mmaction.datasets.VideoDataset", "mmaction.datasets.VideoDataset", "os.join", "len", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["    ", "def", "test_video_dataset", "(", "self", ")", ":", "\n", "        ", "video_dataset", "=", "VideoDataset", "(", "\n", "self", ".", "video_ann_file", ",", "\n", "self", ".", "video_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "start_index", "=", "3", ")", "\n", "assert", "len", "(", "video_dataset", ")", "==", "2", "\n", "assert", "video_dataset", ".", "start_index", "==", "3", "\n", "\n", "video_dataset", "=", "VideoDataset", "(", "\n", "self", ".", "video_ann_file", ",", "\n", "self", ".", "video_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "video_infos", "=", "video_dataset", ".", "video_infos", "\n", "video_filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'test.mp4'", ")", "\n", "assert", "video_infos", "==", "[", "dict", "(", "filename", "=", "video_filename", ",", "label", "=", "0", ")", "]", "*", "2", "\n", "assert", "video_dataset", ".", "start_index", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_video_dataset.TestVideoDataset.test_video_dataset_multi_label": [[31, 48], ["mmaction.datasets.VideoDataset", "os.join", "zip", "print", "set", "set"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_video_dataset_multi_label", "(", "self", ")", ":", "\n", "        ", "video_dataset", "=", "VideoDataset", "(", "\n", "self", ".", "video_ann_file_multi_label", ",", "\n", "self", ".", "video_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "multi_class", "=", "True", ",", "\n", "num_classes", "=", "100", ")", "\n", "video_infos", "=", "video_dataset", ".", "video_infos", "\n", "video_filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'test.mp4'", ")", "\n", "label0", "=", "[", "0", ",", "3", "]", "\n", "label1", "=", "[", "0", ",", "2", ",", "4", "]", "\n", "labels", "=", "[", "label0", ",", "label1", "]", "\n", "for", "info", ",", "label", "in", "zip", "(", "video_infos", ",", "labels", ")", ":", "\n", "            ", "print", "(", "info", ",", "video_filename", ")", "\n", "assert", "info", "[", "'filename'", "]", "==", "video_filename", "\n", "assert", "set", "(", "info", "[", "'label'", "]", ")", "==", "set", "(", "label", ")", "\n", "", "assert", "video_dataset", ".", "start_index", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_video_dataset.TestVideoDataset.test_video_pipeline": [[49, 69], ["mmaction.datasets.VideoDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.VideoDataset", "mmcv.utils.assert_dict_has_keys"], "methods", ["None"], ["", "def", "test_video_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'filename'", ",", "'label'", ",", "'start_index'", ",", "'modality'", "]", "\n", "\n", "# VideoDataset not in test mode", "\n", "video_dataset", "=", "VideoDataset", "(", "\n", "self", ".", "video_ann_file", ",", "\n", "self", ".", "video_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "video_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# VideoDataset in test mode", "\n", "video_dataset", "=", "VideoDataset", "(", "\n", "self", ".", "video_ann_file", ",", "\n", "self", ".", "video_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "video_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_video_dataset.TestVideoDataset.test_video_evaluate": [[70, 100], ["mmaction.datasets.VideoDataset", "mmaction.datasets.VideoDataset.evaluate", "pytest.raises", "mmaction.datasets.VideoDataset.evaluate", "pytest.raises", "mmaction.datasets.VideoDataset.evaluate", "pytest.raises", "mmaction.datasets.VideoDataset.evaluate", "pytest.raises", "mmaction.datasets.VideoDataset.evaluate", "set", "set", "numpy.array", "len", "dict", "len", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "test_video_evaluate", "(", "self", ")", ":", "\n", "        ", "video_dataset", "=", "VideoDataset", "(", "\n", "self", ".", "video_ann_file", ",", "\n", "self", ".", "video_pipeline", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# results must be a list", "\n", "            ", "video_dataset", ".", "evaluate", "(", "'0.5'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The length of results must be equal to the dataset len", "\n", "            ", "video_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# topk must be int or tuple of int", "\n", "            ", "video_dataset", ".", "evaluate", "(", "\n", "[", "0", "]", "*", "len", "(", "video_dataset", ")", ",", "\n", "metric_options", "=", "dict", "(", "top_k_accuracy", "=", "dict", "(", "topk", "=", "1.", ")", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# unsupported metric", "\n", "            ", "video_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "len", "(", "video_dataset", ")", ",", "metrics", "=", "'iou'", ")", "\n", "\n", "# evaluate top_k_accuracy and mean_class_accuracy metric", "\n", "", "results", "=", "[", "np", ".", "array", "(", "[", "0.1", ",", "0.5", ",", "0.4", "]", ")", "]", "*", "2", "\n", "eval_result", "=", "video_dataset", ".", "evaluate", "(", "\n", "results", ",", "metrics", "=", "[", "'top_k_accuracy'", ",", "'mean_class_accuracy'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "\n", "[", "'top1_acc'", ",", "'top5_acc'", ",", "'mean_class_accuracy'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_hvu_dataset.TestHVUDataset.test_hvu_dataset": [[12, 82], ["mmaction.datasets.HVUDataset", "os.join", "mmaction.datasets.HVUDataset", "os.join", "mmaction.datasets.HVUDataset", "mmaction.datasets.HVUDataset.evaluate", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.array", "numpy.array", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["    ", "def", "test_hvu_dataset", "(", "self", ")", ":", "\n", "        ", "hvu_frame_dataset", "=", "HVUDataset", "(", "\n", "ann_file", "=", "self", ".", "hvu_frame_ann_file", ",", "\n", "pipeline", "=", "self", ".", "frame_pipeline", ",", "\n", "tag_categories", "=", "self", ".", "hvu_categories", ",", "\n", "tag_category_nums", "=", "self", ".", "hvu_category_nums", ",", "\n", "filename_tmpl", "=", "self", ".", "filename_tmpl", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ",", "\n", "start_index", "=", "1", ")", "\n", "hvu_frame_infos", "=", "hvu_frame_dataset", ".", "video_infos", "\n", "frame_dir", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'imgs'", ")", "\n", "assert", "hvu_frame_infos", "==", "[", "\n", "dict", "(", "\n", "frame_dir", "=", "frame_dir", ",", "\n", "total_frames", "=", "5", ",", "\n", "label", "=", "dict", "(", "\n", "concept", "=", "[", "250", ",", "131", ",", "42", ",", "51", ",", "57", ",", "155", ",", "122", "]", ",", "\n", "object", "=", "[", "1570", ",", "508", "]", ",", "\n", "event", "=", "[", "16", "]", ",", "\n", "action", "=", "[", "180", "]", ",", "\n", "scene", "=", "[", "206", "]", ")", ",", "\n", "categories", "=", "self", ".", "hvu_categories", ",", "\n", "category_nums", "=", "self", ".", "hvu_category_nums", ",", "\n", "filename_tmpl", "=", "self", ".", "filename_tmpl", ",", "\n", "start_index", "=", "1", ",", "\n", "modality", "=", "'RGB'", ")", "\n", "]", "*", "2", "\n", "\n", "hvu_video_dataset", "=", "HVUDataset", "(", "\n", "ann_file", "=", "self", ".", "hvu_video_ann_file", ",", "\n", "pipeline", "=", "self", ".", "video_pipeline", ",", "\n", "tag_categories", "=", "self", ".", "hvu_categories", ",", "\n", "tag_category_nums", "=", "self", ".", "hvu_category_nums", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "hvu_video_infos", "=", "hvu_video_dataset", ".", "video_infos", "\n", "filename", "=", "osp", ".", "join", "(", "self", ".", "data_prefix", ",", "'tmp.mp4'", ")", "\n", "assert", "hvu_video_infos", "==", "[", "\n", "dict", "(", "\n", "filename", "=", "filename", ",", "\n", "label", "=", "dict", "(", "\n", "concept", "=", "[", "250", ",", "131", ",", "42", ",", "51", ",", "57", ",", "155", ",", "122", "]", ",", "\n", "object", "=", "[", "1570", ",", "508", "]", ",", "\n", "event", "=", "[", "16", "]", ",", "\n", "action", "=", "[", "180", "]", ",", "\n", "scene", "=", "[", "206", "]", ")", ",", "\n", "categories", "=", "self", ".", "hvu_categories", ",", "\n", "category_nums", "=", "self", ".", "hvu_category_nums", ")", "\n", "]", "*", "2", "\n", "\n", "hvu_video_eval_dataset", "=", "HVUDataset", "(", "\n", "ann_file", "=", "self", ".", "hvu_video_eval_ann_file", ",", "\n", "pipeline", "=", "self", ".", "video_pipeline", ",", "\n", "tag_categories", "=", "self", ".", "hvu_categories_for_eval", ",", "\n", "tag_category_nums", "=", "self", ".", "hvu_category_nums_for_eval", ",", "\n", "data_prefix", "=", "self", ".", "data_prefix", ")", "\n", "\n", "results", "=", "[", "\n", "np", ".", "array", "(", "[", "\n", "-", "1.59812844", ",", "0.24459082", ",", "1.38486497", ",", "0.28801252", ",", "1.09813449", ",", "\n", "-", "0.28696971", ",", "0.0637848", ",", "0.22877678", ",", "-", "1.82406999", "\n", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "\n", "0.87904563", ",", "1.64264224", ",", "0.46382051", ",", "0.72865088", ",", "-", "2.13712525", ",", "\n", "1.28571358", ",", "1.01320328", ",", "0.59292737", ",", "-", "0.05502892", "\n", "]", ")", "\n", "]", "\n", "mAP", "=", "hvu_video_eval_dataset", ".", "evaluate", "(", "results", ")", "\n", "assert_array_almost_equal", "(", "mAP", "[", "'action_mAP'", "]", ",", "1.0", ")", "\n", "assert_array_almost_equal", "(", "mAP", "[", "'scene_mAP'", "]", ",", "0.5", ")", "\n", "assert_array_almost_equal", "(", "mAP", "[", "'object_mAP'", "]", ",", "0.75", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_activitynet_dataset.TestActivitynetDataset.test_activitynet_dataset": [[17, 39], ["mmaction.datasets.ActivityNetDataset", "dict", "dict", "dict", "dict"], "methods", ["None"], ["    ", "def", "test_activitynet_dataset", "(", "self", ")", ":", "\n", "        ", "activitynet_dataset", "=", "ActivityNetDataset", "(", "self", ".", "action_ann_file", ",", "\n", "self", ".", "action_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "activitynet_infos", "=", "activitynet_dataset", ".", "video_infos", "\n", "assert", "activitynet_infos", "==", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test1'", ",", "\n", "duration_second", "=", "1", ",", "\n", "duration_frame", "=", "30", ",", "\n", "annotations", "=", "[", "dict", "(", "segment", "=", "[", "0.3", ",", "0.6", "]", ",", "label", "=", "'Rock climbing'", ")", "]", ",", "\n", "feature_frame", "=", "30", ",", "\n", "fps", "=", "30.0", ",", "\n", "rfps", "=", "30", ")", ",", "\n", "dict", "(", "\n", "video_name", "=", "'v_test2'", ",", "\n", "duration_second", "=", "2", ",", "\n", "duration_frame", "=", "48", ",", "\n", "annotations", "=", "[", "dict", "(", "segment", "=", "[", "1.0", ",", "2.0", "]", ",", "label", "=", "'Drinking beer'", ")", "]", ",", "\n", "feature_frame", "=", "48", ",", "\n", "fps", "=", "24.0", ",", "\n", "rfps", "=", "24.0", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_activitynet_dataset.TestActivitynetDataset.test_activitynet_proposals2json": [[41, 72], ["mmaction.datasets.ActivityNetDataset", "mmaction.datasets.ActivityNetDataset.proposals2json", "mmaction.datasets.ActivityNetDataset.proposals2json", "dict", "dict", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.proposals2json", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.activitynet_dataset.ActivityNetDataset.proposals2json"], ["", "def", "test_activitynet_proposals2json", "(", "self", ")", ":", "\n", "        ", "activitynet_dataset", "=", "ActivityNetDataset", "(", "self", ".", "action_ann_file", ",", "\n", "self", ".", "action_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "results", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test1'", ",", "\n", "proposal_list", "=", "[", "dict", "(", "segment", "=", "[", "0.1", ",", "0.9", "]", ",", "score", "=", "0.1", ")", "]", ")", ",", "\n", "dict", "(", "\n", "video_name", "=", "'v_test2'", ",", "\n", "proposal_list", "=", "[", "dict", "(", "segment", "=", "[", "10.1", ",", "20.9", "]", ",", "score", "=", "0.9", ")", "]", ")", "\n", "]", "\n", "result_dict", "=", "activitynet_dataset", ".", "proposals2json", "(", "results", ")", "\n", "assert", "result_dict", "==", "dict", "(", "\n", "test1", "=", "[", "{", "\n", "'segment'", ":", "[", "0.1", ",", "0.9", "]", ",", "\n", "'score'", ":", "0.1", "\n", "}", "]", ",", "\n", "test2", "=", "[", "{", "\n", "'segment'", ":", "[", "10.1", ",", "20.9", "]", ",", "\n", "'score'", ":", "0.9", "\n", "}", "]", ")", "\n", "result_dict", "=", "activitynet_dataset", ".", "proposals2json", "(", "results", ",", "True", ")", "\n", "assert", "result_dict", "==", "dict", "(", "\n", "test1", "=", "[", "{", "\n", "'segment'", ":", "[", "0.1", ",", "0.9", "]", ",", "\n", "'score'", ":", "0.1", "\n", "}", "]", ",", "\n", "test2", "=", "[", "{", "\n", "'segment'", ":", "[", "10.1", ",", "20.9", "]", ",", "\n", "'score'", ":", "0.9", "\n", "}", "]", ")", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_activitynet_dataset.TestActivitynetDataset.test_activitynet_evaluate": [[74, 104], ["mmaction.datasets.ActivityNetDataset", "mmaction.datasets.ActivityNetDataset.evaluate", "pytest.raises", "mmaction.datasets.ActivityNetDataset.evaluate", "pytest.raises", "mmaction.datasets.ActivityNetDataset.evaluate", "pytest.raises", "mmaction.datasets.ActivityNetDataset.evaluate", "dict", "dict", "set", "set", "len", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate"], ["", "def", "test_activitynet_evaluate", "(", "self", ")", ":", "\n", "        ", "activitynet_dataset", "=", "ActivityNetDataset", "(", "self", ".", "action_ann_file", ",", "\n", "self", ".", "action_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# results must be a list", "\n", "            ", "activitynet_dataset", ".", "evaluate", "(", "'0.5'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# The length of results must be equal to the dataset len", "\n", "            ", "activitynet_dataset", ".", "evaluate", "(", "[", "0", "]", "*", "5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# unsupported metric", "\n", "            ", "activitynet_dataset", ".", "evaluate", "(", "\n", "[", "0", "]", "*", "len", "(", "activitynet_dataset", ")", ",", "metrics", "=", "'iou'", ")", "\n", "\n", "# evaluate AR@AN metric", "\n", "", "results", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test1'", ",", "\n", "proposal_list", "=", "[", "dict", "(", "segment", "=", "[", "0.1", ",", "0.9", "]", ",", "score", "=", "0.1", ")", "]", ")", ",", "\n", "dict", "(", "\n", "video_name", "=", "'v_test2'", ",", "\n", "proposal_list", "=", "[", "dict", "(", "segment", "=", "[", "10.1", ",", "20.9", "]", ",", "score", "=", "0.9", ")", "]", ")", "\n", "]", "\n", "eval_result", "=", "activitynet_dataset", ".", "evaluate", "(", "results", ",", "metrics", "=", "[", "'AR@AN'", "]", ")", "\n", "assert", "set", "(", "eval_result", ")", "==", "set", "(", "\n", "[", "'auc'", ",", "'AR@1'", ",", "'AR@5'", ",", "'AR@10'", ",", "'AR@100'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_activitynet_dataset.TestActivitynetDataset.test_activitynet_dump_results": [[105, 155], ["mmaction.datasets.ActivityNetDataset", "os.join", "os.join", "mmaction.datasets.ActivityNetDataset.dump_results", "os.isfile", "os.isfile", "os.remove", "os.remove", "os.remove", "os.remove", "dict", "dict", "tempfile.gettempdir", "open", "mmcv.load", "tempfile.TemporaryDirectory", "mmaction.datasets.ActivityNetDataset.dump_results", "numpy.loadtxt", "numpy.testing.assert_array_equal", "numpy.array", "os.join", "os.join", "numpy.array", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.dump_results", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.hooks.output.OutputHook.remove", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.datasets.ava_dataset.AVADataset.dump_results", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_activitynet_dump_results", "(", "self", ")", ":", "\n", "        ", "activitynet_dataset", "=", "ActivityNetDataset", "(", "self", ".", "action_ann_file", ",", "\n", "self", ".", "action_pipeline", ",", "\n", "self", ".", "data_prefix", ")", "\n", "# test dumping json file", "\n", "results", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test1'", ",", "\n", "proposal_list", "=", "[", "dict", "(", "segment", "=", "[", "0.1", ",", "0.9", "]", ",", "score", "=", "0.1", ")", "]", ")", ",", "\n", "dict", "(", "\n", "video_name", "=", "'v_test2'", ",", "\n", "proposal_list", "=", "[", "dict", "(", "segment", "=", "[", "10.1", ",", "20.9", "]", ",", "score", "=", "0.9", ")", "]", ")", "\n", "]", "\n", "dump_results", "=", "{", "\n", "'version'", ":", "'VERSION 1.3'", ",", "\n", "'results'", ":", "{", "\n", "'test1'", ":", "[", "{", "\n", "'segment'", ":", "[", "0.1", ",", "0.9", "]", ",", "\n", "'score'", ":", "0.1", "\n", "}", "]", ",", "\n", "'test2'", ":", "[", "{", "\n", "'segment'", ":", "[", "10.1", ",", "20.9", "]", ",", "\n", "'score'", ":", "0.9", "\n", "}", "]", "\n", "}", ",", "\n", "'external_data'", ":", "{", "}", "\n", "}", "\n", "\n", "tmp_filename", "=", "osp", ".", "join", "(", "tempfile", ".", "gettempdir", "(", ")", ",", "'result.json'", ")", "\n", "activitynet_dataset", ".", "dump_results", "(", "results", ",", "tmp_filename", ",", "'json'", ")", "\n", "assert", "osp", ".", "isfile", "(", "tmp_filename", ")", "\n", "with", "open", "(", "tmp_filename", ",", "'r+'", ")", "as", "f", ":", "\n", "            ", "load_obj", "=", "mmcv", ".", "load", "(", "f", ",", "file_format", "=", "'json'", ")", "\n", "", "assert", "load_obj", "==", "dump_results", "\n", "os", ".", "remove", "(", "tmp_filename", ")", "\n", "\n", "# test dumping csv file", "\n", "results", "=", "[", "(", "'test_video'", ",", "np", ".", "array", "(", "[", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "[", "6", ",", "7", ",", "8", ",", "9", ",", "\n", "10", "]", "]", ")", ")", "]", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "            ", "activitynet_dataset", ".", "dump_results", "(", "results", ",", "tmpdir", ",", "'csv'", ")", "\n", "load_obj", "=", "np", ".", "loadtxt", "(", "\n", "osp", ".", "join", "(", "tmpdir", ",", "'test_video.csv'", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ",", "\n", "delimiter", "=", "','", ",", "\n", "skiprows", "=", "1", ")", "\n", "assert_array_equal", "(", "\n", "load_obj", ",", "\n", "np", ".", "array", "(", "[", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "[", "6", ",", "7", ",", "8", ",", "9", ",", "10", "]", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_datasets.test_activitynet_dataset.TestActivitynetDataset.test_action_pipeline": [[156, 176], ["mmaction.datasets.ActivityNetDataset", "mmcv.utils.assert_dict_has_keys", "mmaction.datasets.ActivityNetDataset", "mmcv.utils.assert_dict_has_keys"], "methods", ["None"], ["", "", "def", "test_action_pipeline", "(", "self", ")", ":", "\n", "        ", "target_keys", "=", "[", "'video_name'", ",", "'data_prefix'", "]", "\n", "\n", "# ActivityNet Dataset not in test mode", "\n", "action_dataset", "=", "ActivityNetDataset", "(", "\n", "self", ".", "action_ann_file", ",", "\n", "self", ".", "action_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "False", ")", "\n", "result", "=", "action_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "\n", "# ActivityNet Dataset in test mode", "\n", "action_dataset", "=", "ActivityNetDataset", "(", "\n", "self", ".", "action_ann_file", ",", "\n", "self", ".", "action_pipeline", ",", "\n", "self", ".", "data_prefix", ",", "\n", "test_mode", "=", "True", ")", "\n", "result", "=", "action_dataset", "[", "0", "]", "\n", "assert", "assert_dict_has_keys", "(", "result", ",", "target_keys", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_decorator.test_import_module_error_class": [[6, 23], ["mmaction.utils.import_module_error_class", "mmaction.utils.import_module_error_class", "pytest.raises", "ExampleClass", "pytest.raises", "ExampleClass"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.decorators.import_module_error_class", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.decorators.import_module_error_class"], ["def", "test_import_module_error_class", "(", ")", ":", "\n", "\n", "    ", "@", "import_module_error_class", "(", "'mmdet'", ")", "\n", "class", "ExampleClass", ":", "\n", "        ", "pass", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ImportError", ")", ":", "\n", "        ", "ExampleClass", "(", ")", "\n", "\n", "", "@", "import_module_error_class", "(", "'mmdet'", ")", "\n", "class", "ExampleClass", ":", "\n", "\n", "        ", "def", "__init__", "(", "self", ",", "a", ",", "b", "=", "3", ")", ":", "\n", "            ", "self", ".", "c", "=", "a", "+", "b", "\n", "\n", "", "", "with", "pytest", ".", "raises", "(", "ImportError", ")", ":", "\n", "        ", "ExampleClass", "(", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_decorator.test_import_module_error_func": [[25, 33], ["mmaction.utils.import_module_error_func", "pytest.raises", "test_decorator.test_import_module_error_func.ExampleFunc"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.decorators.import_module_error_func"], ["", "", "def", "test_import_module_error_func", "(", ")", ":", "\n", "\n", "    ", "@", "import_module_error_func", "(", "'_add'", ")", "\n", "def", "ExampleFunc", "(", "a", ",", "b", ")", ":", "\n", "        ", "return", "a", "+", "b", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ImportError", ")", ":", "\n", "        ", "ExampleFunc", "(", "3", ",", "4", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_localization_utils.test_temporal_iou": [[12, 20], ["numpy.array", "numpy.array", "mmaction.localization.temporal_iou", "numpy.testing.assert_array_equal", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iou"], ["def", "test_temporal_iou", "(", ")", ":", "\n", "    ", "anchors_min", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.5", "]", ")", "\n", "anchors_max", "=", "np", ".", "array", "(", "[", "1.0", ",", "1.5", "]", ")", "\n", "box_min", "=", "0.5", "\n", "box_max", "=", "1.0", "\n", "\n", "iou", "=", "temporal_iou", "(", "anchors_min", ",", "anchors_max", ",", "box_min", ",", "box_max", ")", "\n", "assert_array_equal", "(", "iou", ",", "np", ".", "array", "(", "[", "0.5", ",", "0.5", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_localization_utils.test_temporal_iop": [[22, 30], ["numpy.array", "numpy.array", "mmaction.localization.temporal_iop", "numpy.testing.assert_array_almost_equal", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.temporal_iop"], ["", "def", "test_temporal_iop", "(", ")", ":", "\n", "    ", "anchors_min", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.5", "]", ")", "\n", "anchors_max", "=", "np", ".", "array", "(", "[", "1.0", ",", "1.5", "]", ")", "\n", "box_min", "=", "0.4", "\n", "box_max", "=", "1.1", "\n", "\n", "ioa", "=", "temporal_iop", "(", "anchors_min", ",", "anchors_max", ",", "box_min", ",", "box_max", ")", "\n", "assert_array_almost_equal", "(", "ioa", ",", "np", ".", "array", "(", "[", "0.6", ",", "0.6", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_localization_utils.test_soft_nms": [[32, 38], ["numpy.array", "mmaction.localization.soft_nms", "numpy.testing.assert_array_equal"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.proposal_utils.soft_nms"], ["", "def", "test_soft_nms", "(", ")", ":", "\n", "    ", "proposals", "=", "np", ".", "array", "(", "[", "[", "0.", ",", "1.", ",", "1.", ",", "1.", ",", "0.5", ",", "0.5", "]", ",", "\n", "[", "0.", ",", "0.4", ",", "1.", ",", "1.", ",", "0.4", ",", "0.4", "]", ",", "\n", "[", "0.", ",", "0.95", ",", "1.", ",", "1.", ",", "0.6", ",", "0.6", "]", "]", ")", "\n", "proposal_list", "=", "soft_nms", "(", "proposals", ",", "0.75", ",", "0.65", ",", "0.9", ",", "1", ")", "\n", "assert_array_equal", "(", "proposal_list", ",", "[", "[", "0.", ",", "0.95", ",", "0.6", "]", ",", "[", "0.", ",", "0.4", ",", "0.4", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_localization_utils.test_generate_candidate_proposals": [[40, 103], ["os.normpath", "numpy.array", "numpy.array", "mmaction.localization.generate_candidate_proposals", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "mmaction.localization.generate_candidate_proposals", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "dict", "dict", "os.join", "pytest.raises", "mmaction.localization.generate_candidate_proposals", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_candidate_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_candidate_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_candidate_proposals"], ["", "def", "test_generate_candidate_proposals", "(", ")", ":", "\n", "    ", "video_list", "=", "[", "0", ",", "1", "]", "\n", "video_infos", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test1'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "1000", ",", "\n", "annotations", "=", "[", "{", "\n", "'segment'", ":", "[", "30.0", ",", "60.0", "]", ",", "\n", "'label'", ":", "'Rock climbing'", "\n", "}", "]", ",", "\n", "feature_frame", "=", "900", ")", ",", "\n", "dict", "(", "\n", "video_name", "=", "'v_test2'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "1000", ",", "\n", "annotations", "=", "[", "{", "\n", "'segment'", ":", "[", "6.0", ",", "8.0", "]", ",", "\n", "'label'", ":", "'Drinking beer'", "\n", "}", "]", ",", "\n", "feature_frame", "=", "900", ")", "\n", "]", "\n", "tem_results_dir", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/tem_results'", ")", ")", "\n", "# test when tem_result_ext is not valid", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "        ", "result_dict", "=", "generate_candidate_proposals", "(", "\n", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "5", ",", "\n", "0.5", ",", "\n", "tem_results_ext", "=", "'unsupport_ext'", ")", "\n", "# test without result_dict", "\n", "", "assert_result1", "=", "np", ".", "array", "(", "[", "\n", "[", "0.1", ",", "0.7", ",", "0.58390868", ",", "0.35708317", ",", "0.20850396", ",", "0.55555556", ",", "0.55555556", "]", ",", "\n", "[", "0.1", ",", "0.5", ",", "0.58390868", ",", "0.32605207", ",", "0.19038463", ",", "0.29411765", ",", "0.41666667", "]", ",", "\n", "[", "0.1", ",", "0.3", ",", "0.58390868", ",", "0.26221931", ",", "0.15311213", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.3", ",", "0.7", ",", "0.30626667", ",", "0.35708317", ",", "0.10936267", ",", "0.83333333", ",", "0.83333333", "]", ",", "\n", "[", "0.3", ",", "0.5", ",", "0.30626667", ",", "0.32605207", ",", "0.09985888", ",", "0.45454545", ",", "0.83333333", "]", "\n", "]", ")", "\n", "assert_result2", "=", "np", ".", "array", "(", "\n", "[", "[", "0.1", ",", "0.3", ",", "0.78390867", ",", "0.3622193", ",", "0.28394685", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.1", ",", "0.7", ",", "0.78390867", ",", "0.35708317", ",", "0.27992059", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.1", ",", "0.5", ",", "0.78390867", ",", "0.32605207", ",", "0.25559504", ",", "0.", ",", "0.", "]", "]", ")", "\n", "result_dict", "=", "generate_candidate_proposals", "(", "video_list", ",", "video_infos", ",", "\n", "tem_results_dir", ",", "5", ",", "0.5", ")", "\n", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test1'", "]", ",", "assert_result1", ")", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test2'", "]", ",", "assert_result2", ")", "\n", "\n", "# test with result_dict", "\n", "result_dict", "=", "{", "}", "\n", "generate_candidate_proposals", "(", "\n", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "5", ",", "\n", "0.5", ",", "\n", "result_dict", "=", "result_dict", ")", "\n", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test1'", "]", ",", "assert_result1", ")", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test2'", "]", ",", "assert_result2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_localization_utils.test_generate_bsp_feature": [[105, 204], ["os.normpath", "os.normpath", "mmaction.localization.generate_bsp_feature", "numpy.array", "numpy.array", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "mmaction.localization.generate_bsp_feature", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "dict", "dict", "os.join", "os.join", "pytest.raises", "mmaction.localization.generate_bsp_feature", "pytest.raises", "mmaction.localization.generate_bsp_feature", "os.dirname", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_bsp_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_bsp_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_bsp_feature", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.localization.bsn_utils.generate_bsp_feature"], ["", "def", "test_generate_bsp_feature", "(", ")", ":", "\n", "    ", "video_list", "=", "[", "0", ",", "1", "]", "\n", "video_infos", "=", "[", "\n", "dict", "(", "\n", "video_name", "=", "'v_test1'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "1000", ",", "\n", "annotations", "=", "[", "{", "\n", "'segment'", ":", "[", "30.0", ",", "60.0", "]", ",", "\n", "'label'", ":", "'Rock climbing'", "\n", "}", "]", ",", "\n", "feature_frame", "=", "900", ")", ",", "\n", "dict", "(", "\n", "video_name", "=", "'v_test2'", ",", "\n", "duration_second", "=", "100", ",", "\n", "duration_frame", "=", "1000", ",", "\n", "annotations", "=", "[", "{", "\n", "'segment'", ":", "[", "6.0", ",", "8.0", "]", ",", "\n", "'label'", ":", "'Drinking beer'", "\n", "}", "]", ",", "\n", "feature_frame", "=", "900", ")", "\n", "]", "\n", "tem_results_dir", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/tem_results'", ")", ")", "\n", "pgm_proposals_dir", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/proposals'", ")", ")", "\n", "\n", "# test when extension is not valid", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "        ", "result_dict", "=", "generate_bsp_feature", "(", "\n", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "\n", "tem_results_ext", "=", "'unsupport_ext'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "        ", "result_dict", "=", "generate_bsp_feature", "(", "\n", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "\n", "pgm_proposal_ext", "=", "'unsupport_ext'", ")", "\n", "\n", "# test without result_dict", "\n", "", "result_dict", "=", "generate_bsp_feature", "(", "\n", "video_list", ",", "video_infos", ",", "tem_results_dir", ",", "pgm_proposals_dir", ",", "top_k", "=", "2", ")", "\n", "assert_result1", "=", "np", ".", "array", "(", "\n", "[", "[", "\n", "0.02633105", ",", "0.02489364", ",", "0.02345622", ",", "0.0220188", ",", "0.02058138", ",", "\n", "0.01914396", ",", "0.01770654", ",", "0.01626912", ",", "0.01541432", ",", "0.01514214", ",", "\n", "0.01486995", ",", "0.01459776", ",", "0.01432558", ",", "0.01405339", ",", "0.01378121", ",", "\n", "0.01350902", ",", "0.03064331", ",", "0.02941124", ",", "0.02817916", ",", "0.02694709", ",", "\n", "0.02571502", ",", "0.02448295", ",", "0.02325087", ",", "0.0220188", ",", "0.01432558", ",", "\n", "0.01409228", ",", "0.01385897", ",", "0.01362567", ",", "0.01339237", ",", "0.01315907", ",", "\n", "0.01292577", ",", "0.01269246", "\n", "]", ",", "\n", "[", "\n", "0.01350902", ",", "0.01323684", ",", "0.01296465", ",", "0.01269246", ",", "0.01242028", ",", "\n", "0.01214809", ",", "0.01187591", ",", "0.01160372", ",", "0.01154264", ",", "0.01169266", ",", "\n", "0.01184269", ",", "0.01199271", ",", "0.01214273", ",", "0.01229275", ",", "0.01244278", ",", "\n", "0.0125928", ",", "0.01432558", ",", "0.01409228", ",", "0.01385897", ",", "0.01362567", ",", "\n", "0.01339237", ",", "0.01315907", ",", "0.01292577", ",", "0.01269246", ",", "0.01214273", ",", "\n", "0.01227132", ",", "0.01239991", ",", "0.0125285", ",", "0.0126571", ",", "0.01278569", ",", "\n", "0.01291428", ",", "0.01304287", "\n", "]", "]", ")", "\n", "assert_result2", "=", "np", ".", "array", "(", "\n", "[", "[", "\n", "0.04133105", ",", "0.03922697", ",", "0.03712288", ",", "0.0350188", ",", "0.03291471", ",", "\n", "0.03081063", ",", "0.02870654", ",", "0.02660246", ",", "0.02541432", ",", "0.02514214", ",", "\n", "0.02486995", ",", "0.02459776", ",", "0.02432558", ",", "0.02405339", ",", "0.02378121", ",", "\n", "0.02350902", ",", "0.04764331", ",", "0.04583981", ",", "0.04403631", ",", "0.04223281", ",", "\n", "0.0404293", ",", "0.0386258", ",", "0.0368223", ",", "0.0350188", ",", "0.02432558", ",", "0.02409228", ",", "\n", "0.02385897", ",", "0.02362567", ",", "0.02339237", ",", "0.02315907", ",", "0.02292577", ",", "\n", "0.02269246", "\n", "]", ",", "\n", "[", "\n", "0.02350902", ",", "0.02323684", ",", "0.02296465", ",", "0.02269246", ",", "0.02242028", ",", "\n", "0.02214809", ",", "0.02187591", ",", "0.02160372", ",", "0.02120931", ",", "0.02069266", ",", "\n", "0.02017602", ",", "0.01965937", ",", "0.01914273", ",", "0.01862609", ",", "0.01810944", ",", "\n", "0.0175928", ",", "0.02432558", ",", "0.02409228", ",", "0.02385897", ",", "0.02362567", ",", "\n", "0.02339237", ",", "0.02315907", ",", "0.02292577", ",", "0.02269246", ",", "0.01914273", ",", "\n", "0.01869989", ",", "0.01825706", ",", "0.01781422", ",", "0.01737138", ",", "0.01692854", ",", "\n", "0.0164857", ",", "0.01604287", "\n", "]", "]", ")", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test1'", "]", ",", "assert_result1", ")", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test2'", "]", ",", "assert_result2", ")", "\n", "\n", "# test with result_dict", "\n", "result_dict", "=", "{", "}", "\n", "generate_bsp_feature", "(", "\n", "video_list", ",", "\n", "video_infos", ",", "\n", "tem_results_dir", ",", "\n", "pgm_proposals_dir", ",", "\n", "top_k", "=", "2", ",", "\n", "result_dict", "=", "result_dict", ")", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test1'", "]", ",", "assert_result1", ")", "\n", "assert_array_almost_equal", "(", "result_dict", "[", "'v_test2'", "]", ",", "assert_result2", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_module_hooks.test_register_module_hooks": [[14, 68], ["os.dirname", "os.join", "mmcv.Config.fromfile", "copy.deepcopy", "mmaction.models.build_recognizer", "mmaction.utils.register_module_hooks", "copy.deepcopy", "mmaction.models.build_recognizer", "mmaction.utils.register_module_hooks", "copy.deepcopy", "mmaction.models.build_recognizer", "mmaction.utils.register_module_hooks", "copy.deepcopy", "mmaction.models.build_recognizer", "copy.deepcopy", "mmaction.models.build_recognizer", "dict", "os.dirname", "pytest.raises", "mmaction.utils.register_module_hooks", "pytest.raises", "mmaction.utils.register_module_hooks", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.register_module_hooks"], ["def", "test_register_module_hooks", "(", ")", ":", "\n", "    ", "_module_hooks", "=", "[", "\n", "dict", "(", "\n", "type", "=", "'GPUNormalize'", ",", "\n", "hooked_module", "=", "'backbone'", ",", "\n", "hook_pos", "=", "'forward_pre'", ",", "\n", "input_format", "=", "'NCHW'", ",", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ")", "\n", "]", "\n", "\n", "repo_dpath", "=", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "__file__", ")", ")", ")", "\n", "config_fpath", "=", "osp", ".", "join", "(", "repo_dpath", ",", "'configs/_base_/models/tsm_r50.py'", ")", "\n", "config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "config_fpath", ")", "\n", "config", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "# case 1", "\n", "module_hooks", "=", "copy", ".", "deepcopy", "(", "_module_hooks", ")", "\n", "module_hooks", "[", "0", "]", "[", "'hook_pos'", "]", "=", "'forward_pre'", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "handles", "=", "register_module_hooks", "(", "recognizer", ",", "module_hooks", ")", "\n", "assert", "recognizer", ".", "backbone", ".", "_forward_pre_hooks", "[", "\n", "handles", "[", "0", "]", ".", "id", "]", ".", "__name__", "==", "'normalize_hook'", "\n", "\n", "# case 2", "\n", "module_hooks", "=", "copy", ".", "deepcopy", "(", "_module_hooks", ")", "\n", "module_hooks", "[", "0", "]", "[", "'hook_pos'", "]", "=", "'forward'", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "handles", "=", "register_module_hooks", "(", "recognizer", ",", "module_hooks", ")", "\n", "assert", "recognizer", ".", "backbone", ".", "_forward_hooks", "[", "\n", "handles", "[", "0", "]", ".", "id", "]", ".", "__name__", "==", "'normalize_hook'", "\n", "\n", "# case 3", "\n", "module_hooks", "=", "copy", ".", "deepcopy", "(", "_module_hooks", ")", "\n", "module_hooks", "[", "0", "]", "[", "'hooked_module'", "]", "=", "'cls_head'", "\n", "module_hooks", "[", "0", "]", "[", "'hook_pos'", "]", "=", "'backward'", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "handles", "=", "register_module_hooks", "(", "recognizer", ",", "module_hooks", ")", "\n", "assert", "recognizer", ".", "cls_head", ".", "_backward_hooks", "[", "\n", "handles", "[", "0", "]", ".", "id", "]", ".", "__name__", "==", "'normalize_hook'", "\n", "\n", "# case 4", "\n", "module_hooks", "=", "copy", ".", "deepcopy", "(", "_module_hooks", ")", "\n", "module_hooks", "[", "0", "]", "[", "'hook_pos'", "]", "=", "'_other_pos'", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "handles", "=", "register_module_hooks", "(", "recognizer", ",", "module_hooks", ")", "\n", "\n", "# case 5", "\n", "", "module_hooks", "=", "copy", ".", "deepcopy", "(", "_module_hooks", ")", "\n", "module_hooks", "[", "0", "]", "[", "'hooked_module'", "]", "=", "'_other_module'", "\n", "recognizer", "=", "build_recognizer", "(", "config", ".", "model", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "handles", "=", "register_module_hooks", "(", "recognizer", ",", "module_hooks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_module_hooks.test_gpu_normalize": [[70, 121], ["dict", "copy.deepcopy", "mmaction.utils.module_hooks.GPUNormalize", "numpy.random.randint", "mmaction.utils.module_hooks.GPUNormalize.hook_func", "gpu_normalize.hook_func.", "numpy.array", "test_module_hooks.test_gpu_normalize.check_normalize"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.utils.module_hooks.GPUNormalize.hook_func", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_augmentations.base.check_normalize"], ["", "", "def", "test_gpu_normalize", "(", ")", ":", "\n", "\n", "    ", "def", "check_normalize", "(", "origin_imgs", ",", "result_imgs", ",", "norm_cfg", ")", ":", "\n", "        ", "\"\"\"Check if the origin_imgs are normalized correctly into result_imgs\n        in a given norm_cfg.\"\"\"", "\n", "from", "numpy", ".", "testing", "import", "assert_array_almost_equal", "\n", "target_imgs", "=", "result_imgs", ".", "copy", "(", ")", "\n", "target_imgs", "*=", "norm_cfg", "[", "'std'", "]", "\n", "target_imgs", "+=", "norm_cfg", "[", "'mean'", "]", "\n", "assert_array_almost_equal", "(", "origin_imgs", ",", "target_imgs", ",", "decimal", "=", "4", ")", "\n", "\n", "", "_gpu_normalize_cfg", "=", "dict", "(", "\n", "input_format", "=", "'NCTHW'", ",", "\n", "mean", "=", "[", "123.675", ",", "116.28", ",", "103.53", "]", ",", "\n", "std", "=", "[", "58.395", ",", "57.12", ",", "57.375", "]", ")", "\n", "\n", "# case 1", "\n", "gpu_normalize_cfg", "=", "copy", ".", "deepcopy", "(", "_gpu_normalize_cfg", ")", "\n", "gpu_normalize_cfg", "[", "'input_format'", "]", "=", "'NCHW'", "\n", "gpu_normalize", "=", "GPUNormalize", "(", "**", "gpu_normalize_cfg", ")", "\n", "assert", "gpu_normalize", ".", "_mean", ".", "shape", "==", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "imgs", "=", "np", ".", "random", ".", "randint", "(", "256", ",", "size", "=", "(", "2", ",", "240", ",", "320", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "_input", "=", "(", "torch", ".", "tensor", "(", "imgs", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", ")", "\n", "normalize_hook", "=", "gpu_normalize", ".", "hook_func", "(", ")", "\n", "_input", "=", "normalize_hook", "(", "torch", ".", "nn", ".", "Module", ",", "_input", ")", "\n", "result_imgs", "=", "np", ".", "array", "(", "_input", "[", "0", "]", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "check_normalize", "(", "imgs", ",", "result_imgs", ",", "gpu_normalize_cfg", ")", "\n", "\n", "# case 2", "\n", "gpu_normalize_cfg", "=", "copy", ".", "deepcopy", "(", "_gpu_normalize_cfg", ")", "\n", "gpu_normalize_cfg", "[", "'input_format'", "]", "=", "'NCTHW'", "\n", "gpu_normalize", "=", "GPUNormalize", "(", "**", "gpu_normalize_cfg", ")", "\n", "assert", "gpu_normalize", ".", "_mean", ".", "shape", "==", "(", "1", ",", "3", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "# case 3", "\n", "gpu_normalize_cfg", "=", "copy", ".", "deepcopy", "(", "_gpu_normalize_cfg", ")", "\n", "gpu_normalize_cfg", "[", "'input_format'", "]", "=", "'NCHW_Flow'", "\n", "gpu_normalize", "=", "GPUNormalize", "(", "**", "gpu_normalize_cfg", ")", "\n", "assert", "gpu_normalize", ".", "_mean", ".", "shape", "==", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "\n", "# case 4", "\n", "gpu_normalize_cfg", "=", "copy", ".", "deepcopy", "(", "_gpu_normalize_cfg", ")", "\n", "gpu_normalize_cfg", "[", "'input_format'", "]", "=", "'NPTCHW'", "\n", "gpu_normalize", "=", "GPUNormalize", "(", "**", "gpu_normalize_cfg", ")", "\n", "assert", "gpu_normalize", ".", "_mean", ".", "shape", "==", "(", "1", ",", "1", ",", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "\n", "# case 5", "\n", "gpu_normalize_cfg", "=", "copy", ".", "deepcopy", "(", "_gpu_normalize_cfg", ")", "\n", "gpu_normalize_cfg", "[", "'input_format'", "]", "=", "'_format'", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "gpu_normalize", "=", "GPUNormalize", "(", "**", "gpu_normalize_cfg", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_bbox.test_assigner_sampler": [[24, 80], ["os.normpath", "os.join", "os.join", "os.join", "mmaction.datasets.AVADataset", "dict", "build_assigner", "torch.tensor", "torch.tensor", "torch.tensor", "build_assigner.assign", "torch.all", "torch.all", "torch.all", "dict", "build_sampler", "build_sampler.sample", "os.join", "torch.isclose", "torch.isclose", "os.dirname", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "test_assigner_sampler", "(", ")", ":", "\n", "    ", "data_prefix", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/eval_detection'", ")", ")", "\n", "ann_file", "=", "osp", ".", "join", "(", "data_prefix", ",", "'gt.csv'", ")", "\n", "label_file", "=", "osp", ".", "join", "(", "data_prefix", ",", "'action_list.txt'", ")", "\n", "proposal_file", "=", "osp", ".", "join", "(", "data_prefix", ",", "'proposal.pkl'", ")", "\n", "dataset", "=", "AVADataset", "(", "\n", "ann_file", "=", "ann_file", ",", "\n", "exclude_file", "=", "None", ",", "\n", "pipeline", "=", "[", "]", ",", "\n", "label_file", "=", "label_file", ",", "\n", "proposal_file", "=", "proposal_file", ",", "\n", "num_classes", "=", "4", ")", "\n", "\n", "assigner", "=", "dict", "(", "\n", "type", "=", "'MaxIoUAssignerAVA'", ",", "\n", "pos_iou_thr", "=", "0.5", ",", "\n", "neg_iou_thr", "=", "0.5", ",", "\n", "min_pos_iou", "=", "0.5", ")", "\n", "assigner", "=", "build_assigner", "(", "assigner", ")", "\n", "proposal", "=", "torch", ".", "tensor", "(", "dataset", "[", "0", "]", "[", "'proposals'", "]", ")", "\n", "\n", "gt_bboxes", "=", "torch", ".", "tensor", "(", "dataset", "[", "0", "]", "[", "'gt_bboxes'", "]", ")", "\n", "gt_labels", "=", "torch", ".", "tensor", "(", "dataset", "[", "0", "]", "[", "'gt_labels'", "]", ")", "\n", "assign_result", "=", "assigner", ".", "assign", "(", "\n", "bboxes", "=", "proposal", ",", "\n", "gt_bboxes", "=", "gt_bboxes", ",", "\n", "gt_bboxes_ignore", "=", "None", ",", "\n", "gt_labels", "=", "gt_labels", ")", "\n", "assert", "assign_result", ".", "num_gts", "==", "4", "\n", "assert", "torch", ".", "all", "(", "\n", "assign_result", ".", "gt_inds", "==", "torch", ".", "tensor", "(", "[", "0", ",", "0", ",", "3", ",", "3", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", ")", "\n", "assert", "torch", ".", "all", "(", "\n", "torch", ".", "isclose", "(", "\n", "assign_result", ".", "max_overlaps", ",", "\n", "torch", ".", "tensor", "(", "[", "\n", "0.40386841", ",", "0.47127257", ",", "0.53544776", ",", "0.58797631", ",", "0.29281288", ",", "\n", "0.40979504", ",", "0.45902917", ",", "0.50093938", ",", "0.21560125", ",", "0.32948171", "\n", "]", ",", "\n", "dtype", "=", "torch", ".", "float64", ")", ")", ")", "\n", "assert", "torch", ".", "all", "(", "\n", "torch", ".", "isclose", "(", "\n", "assign_result", ".", "labels", ",", "\n", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "1.", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.", ",", "1.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "1.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", "]", ")", ")", ")", "\n", "sampler", "=", "dict", "(", "type", "=", "'RandomSampler'", ",", "num", "=", "32", ",", "pos_fraction", "=", "1", ")", "\n", "sampler", "=", "build_sampler", "(", "sampler", ")", "\n", "sampling_result", "=", "sampler", ".", "sample", "(", "assign_result", ",", "proposal", ",", "gt_bboxes", ",", "\n", "gt_labels", ")", "\n", "assert", "(", "sampling_result", ".", "pos_inds", ".", "shape", "[", "0", "]", "==", "\n", "sampling_result", ".", "pos_bboxes", ".", "shape", "[", "0", "]", ")", "\n", "assert", "(", "sampling_result", ".", "neg_inds", ".", "shape", "[", "0", "]", "==", "\n", "sampling_result", ".", "neg_bboxes", ".", "shape", "[", "0", "]", ")", "\n", "return", "sampling_result", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_bbox.test_bbox2result": [[82, 117], ["torch.tensor", "torch.tensor", "mmaction.core.bbox.bbox2result", "numpy.all", "numpy.all", "numpy.all", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.bbox.transforms.bbox2result"], ["", "def", "test_bbox2result", "(", ")", ":", "\n", "    ", "bboxes", "=", "torch", ".", "tensor", "(", "[", "[", "0.072", ",", "0.47", ",", "0.84", ",", "0.898", "]", ",", "\n", "[", "0.23", ",", "0.215", ",", "0.781", ",", "0.534", "]", ",", "\n", "[", "0.195", ",", "0.128", ",", "0.643", ",", "0.944", "]", ",", "\n", "[", "0.236", ",", "0.189", ",", "0.689", ",", "0.74", "]", ",", "\n", "[", "0.375", ",", "0.371", ",", "0.726", ",", "0.804", "]", ",", "\n", "[", "0.024", ",", "0.398", ",", "0.776", ",", "0.719", "]", "]", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "[", "[", "-", "1.650", ",", "0.515", ",", "0.798", ",", "1.240", "]", ",", "\n", "[", "1.368", ",", "-", "1.128", ",", "0.037", ",", "-", "1.087", "]", ",", "\n", "[", "0.481", ",", "-", "1.303", ",", "0.501", ",", "-", "0.463", "]", ",", "\n", "[", "-", "0.356", ",", "0.126", ",", "-", "0.840", ",", "0.438", "]", ",", "\n", "[", "0.079", ",", "1.269", ",", "-", "0.263", ",", "-", "0.538", "]", ",", "\n", "[", "-", "0.853", ",", "0.391", ",", "0.103", ",", "0.398", "]", "]", ")", "\n", "num_classes", "=", "4", "\n", "result", "=", "bbox2result", "(", "bboxes", ",", "labels", ",", "num_classes", ")", "\n", "assert", "np", ".", "all", "(", "\n", "np", ".", "isclose", "(", "\n", "result", "[", "0", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.072", ",", "0.47", ",", "0.84", ",", "0.898", ",", "0.515", "]", ",", "\n", "[", "0.236", ",", "0.189", ",", "0.689", ",", "0.74", ",", "0.126", "]", ",", "\n", "[", "0.375", ",", "0.371", ",", "0.726", ",", "0.804", ",", "1.269", "]", ",", "\n", "[", "0.024", ",", "0.398", ",", "0.776", ",", "0.719", ",", "0.391", "]", "]", ")", ")", ")", "\n", "assert", "np", ".", "all", "(", "\n", "np", ".", "isclose", "(", "\n", "result", "[", "1", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.072", ",", "0.47", ",", "0.84", ",", "0.898", ",", "0.798", "]", ",", "\n", "[", "0.23", ",", "0.215", ",", "0.781", ",", "0.534", ",", "0.037", "]", ",", "\n", "[", "0.195", ",", "0.128", ",", "0.643", ",", "0.944", ",", "0.501", "]", ",", "\n", "[", "0.024", ",", "0.398", ",", "0.776", ",", "0.719", ",", "0.103", "]", "]", ")", ")", ")", "\n", "assert", "np", ".", "all", "(", "\n", "np", ".", "isclose", "(", "\n", "result", "[", "2", "]", ",", "\n", "np", ".", "array", "(", "[", "[", "0.072", ",", "0.47", ",", "0.84", ",", "0.898", ",", "1.24", "]", ",", "\n", "[", "0.236", ",", "0.189", ",", "0.689", ",", "0.74", ",", "0.438", "]", ",", "\n", "[", "0.024", ",", "0.398", ",", "0.776", ",", "0.719", ",", "0.398", "]", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_bbox.test_bbox_target": [[119, 140], ["torch.tensor", "torch.tensor", "torch.tensor", "abc.abstractproperty", "mmaction.core.bbox.bbox_target", "torch.all", "torch.all", "torch.isclose", "torch.isclose", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.bbox.bbox_target.bbox_target"], ["", "def", "test_bbox_target", "(", ")", ":", "\n", "    ", "pos_bboxes", "=", "torch", ".", "tensor", "(", "[", "[", "0.072", ",", "0.47", ",", "0.84", ",", "0.898", "]", ",", "\n", "[", "0.23", ",", "0.215", ",", "0.781", ",", "0.534", "]", ",", "\n", "[", "0.195", ",", "0.128", ",", "0.643", ",", "0.944", "]", ",", "\n", "[", "0.236", ",", "0.189", ",", "0.689", ",", "0.74", "]", "]", ")", "\n", "neg_bboxes", "=", "torch", ".", "tensor", "(", "[", "[", "0.375", ",", "0.371", ",", "0.726", ",", "0.804", "]", ",", "\n", "[", "0.024", ",", "0.398", ",", "0.776", ",", "0.719", "]", "]", ")", "\n", "pos_gt_labels", "=", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "0.", ",", "1.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "1.", "]", ",", "\n", "[", "0.", ",", "1.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "1.", ",", "0.", ",", "0.", "]", "]", ")", "\n", "cfg", "=", "abstractproperty", "(", ")", "\n", "cfg", ".", "pos_weight", "=", "0.8", "\n", "labels", ",", "label_weights", "=", "bbox_target", "(", "[", "pos_bboxes", "]", ",", "[", "neg_bboxes", "]", ",", "\n", "[", "pos_gt_labels", "]", ",", "cfg", ")", "\n", "assert", "torch", ".", "all", "(", "\n", "torch", ".", "isclose", "(", "\n", "labels", ",", "\n", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "0.", ",", "1.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "1.", "]", ",", "[", "0.", ",", "1.", ",", "0.", ",", "0.", "]", ",", "\n", "[", "0.", ",", "1.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "0.", ",", "\n", "0.", "]", "]", ")", ")", ")", "\n", "assert", "torch", ".", "all", "(", "\n", "torch", ".", "isclose", "(", "label_weights", ",", "torch", ".", "tensor", "(", "[", "0.8", "]", "*", "4", "+", "[", "1.0", "]", "*", "2", ")", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.__init__": [[10, 14], ["torch.Module.__init__", "torch.Conv3d", "torch.SyncBatchNorm"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv3d", "(", "1", ",", "2", ",", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "SyncBatchNorm", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward": [[15, 17], ["test_onnx.TestModel.bn", "test_onnx.TestModel.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "bn", "(", "self", ".", "conv", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.TestModel.forward_dummy": [[18, 21], ["test_onnx.TestModel.bn", "test_onnx.TestModel.conv"], "methods", ["None"], ["", "def", "forward_dummy", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "bn", "(", "self", ".", "conv", "(", "x", ")", ")", "\n", "return", "(", "out", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_utils.test_onnx.test_onnx_exporting": [[23, 32], ["tempfile.TemporaryDirectory", "os.join", "test_onnx.TestModel", "tools.deployment.pytorch2onnx._convert_batchnorm", "hasattr", "tools.deployment.pytorch2onnx.pytorch2onnx"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.pytorch2onnx._convert_batchnorm", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.deployment.pytorch2onnx.pytorch2onnx"], ["", "", "def", "test_onnx_exporting", "(", ")", ":", "\n", "    ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "out_file", "=", "osp", ".", "join", "(", "tmpdir", ",", "'tmp.onnx'", ")", "\n", "model", "=", "TestModel", "(", ")", "\n", "model", "=", "_convert_batchnorm", "(", "model", ")", "\n", "# test exporting", "\n", "if", "hasattr", "(", "model", ",", "'forward_dummy'", ")", ":", "\n", "            ", "model", ".", "forward", "=", "model", ".", "forward_dummy", "\n", "", "pytorch2onnx", "(", "model", ",", "(", "2", ",", "1", ",", "1", ",", "1", ",", "1", ")", ",", "output_file", "=", "out_file", ",", "verify", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.SubModel.__init__": [[8, 14], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.GroupNorm", "torch.GroupNorm", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "2", ",", "2", ",", "kernel_size", "=", "1", ",", "groups", "=", "2", ")", "\n", "self", ".", "gn", "=", "nn", ".", "GroupNorm", "(", "2", ",", "2", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "2", ",", "2", ")", "\n", "self", ".", "param1", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.SubModel.forward": [[15, 17], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.ExampleModel.__init__": [[21, 29], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "test_optimizer.SubModel", "torch.Linear", "torch.Linear", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "param1", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "4", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "2", ")", "\n", "self", ".", "sub", "=", "SubModel", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.ExampleModel.forward": [[30, 32], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.PseudoDataParallel.__init__": [[36, 39], ["torch.Module.__init__", "test_optimizer.ExampleModel"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "ExampleModel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.PseudoDataParallel.forward": [[40, 42], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.check_optimizer": [[49, 127], ["isinstance", "list", "enumerate", "model.parameters", "len", "len", "torch.equal", "torch.equal"], "function", ["None"], ["def", "check_optimizer", "(", "optimizer", ",", "\n", "model", ",", "\n", "prefix", "=", "''", ",", "\n", "bias_lr_mult", "=", "1", ",", "\n", "bias_decay_mult", "=", "1", ",", "\n", "norm_decay_mult", "=", "1", ",", "\n", "dwconv_decay_mult", "=", "1", ")", ":", "\n", "    ", "param_groups", "=", "optimizer", ".", "param_groups", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "SGD", ")", "\n", "assert", "optimizer", ".", "defaults", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "optimizer", ".", "defaults", "[", "'momentum'", "]", "==", "momentum", "\n", "assert", "optimizer", ".", "defaults", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "model_parameters", "=", "list", "(", "model", ".", "parameters", "(", ")", ")", "\n", "assert", "len", "(", "param_groups", ")", "==", "len", "(", "model_parameters", ")", "\n", "for", "i", ",", "param", "in", "enumerate", "(", "model_parameters", ")", ":", "\n", "        ", "param_group", "=", "param_groups", "[", "i", "]", "\n", "assert", "torch", ".", "equal", "(", "param_group", "[", "'params'", "]", "[", "0", "]", ",", "param", ")", "\n", "assert", "param_group", "[", "'momentum'", "]", "==", "momentum", "\n", "# param1", "\n", "", "param1", "=", "param_groups", "[", "0", "]", "\n", "assert", "param1", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "param1", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# conv1.weight", "\n", "conv1_weight", "=", "param_groups", "[", "1", "]", "\n", "assert", "conv1_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "conv1_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# conv2.weight", "\n", "conv2_weight", "=", "param_groups", "[", "2", "]", "\n", "assert", "conv2_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "conv2_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# conv2.bias", "\n", "conv2_bias", "=", "param_groups", "[", "3", "]", "\n", "assert", "conv2_bias", "[", "'lr'", "]", "==", "base_lr", "*", "bias_lr_mult", "\n", "assert", "conv2_bias", "[", "'weight_decay'", "]", "==", "base_wd", "*", "bias_decay_mult", "\n", "# bn.weight", "\n", "bn_weight", "=", "param_groups", "[", "4", "]", "\n", "assert", "bn_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "bn_weight", "[", "'weight_decay'", "]", "==", "base_wd", "*", "norm_decay_mult", "\n", "# bn.bias", "\n", "bn_bias", "=", "param_groups", "[", "5", "]", "\n", "assert", "bn_bias", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "bn_bias", "[", "'weight_decay'", "]", "==", "base_wd", "*", "norm_decay_mult", "\n", "# sub.param1", "\n", "sub_param1", "=", "param_groups", "[", "6", "]", "\n", "assert", "sub_param1", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "sub_param1", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# sub.conv1.weight", "\n", "sub_conv1_weight", "=", "param_groups", "[", "7", "]", "\n", "assert", "sub_conv1_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "sub_conv1_weight", "[", "'weight_decay'", "]", "==", "base_wd", "*", "dwconv_decay_mult", "\n", "# sub.conv1.bias", "\n", "sub_conv1_bias", "=", "param_groups", "[", "8", "]", "\n", "assert", "sub_conv1_bias", "[", "'lr'", "]", "==", "base_lr", "*", "bias_lr_mult", "\n", "assert", "sub_conv1_bias", "[", "'weight_decay'", "]", "==", "base_wd", "*", "dwconv_decay_mult", "\n", "# sub.gn.weight", "\n", "sub_gn_weight", "=", "param_groups", "[", "9", "]", "\n", "assert", "sub_gn_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "sub_gn_weight", "[", "'weight_decay'", "]", "==", "base_wd", "*", "norm_decay_mult", "\n", "# sub.gn.bias", "\n", "sub_gn_bias", "=", "param_groups", "[", "10", "]", "\n", "assert", "sub_gn_bias", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "sub_gn_bias", "[", "'weight_decay'", "]", "==", "base_wd", "*", "norm_decay_mult", "\n", "# sub.fc1.weight", "\n", "sub_fc_weight", "=", "param_groups", "[", "11", "]", "\n", "assert", "sub_fc_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "sub_fc_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# sub.fc1.bias", "\n", "sub_fc_bias", "=", "param_groups", "[", "12", "]", "\n", "assert", "sub_fc_bias", "[", "'lr'", "]", "==", "base_lr", "*", "bias_lr_mult", "\n", "assert", "sub_fc_bias", "[", "'weight_decay'", "]", "==", "base_wd", "*", "bias_decay_mult", "\n", "# fc1.weight", "\n", "fc_weight", "=", "param_groups", "[", "13", "]", "\n", "assert", "fc_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "fc_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# fc1.bias", "\n", "fc_bias", "=", "param_groups", "[", "14", "]", "\n", "assert", "fc_bias", "[", "'lr'", "]", "==", "base_lr", "*", "bias_lr_mult", "\n", "assert", "fc_bias", "[", "'weight_decay'", "]", "==", "base_wd", "*", "bias_decay_mult", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.check_tsm_optimizer": [[129, 189], ["isinstance", "list", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "model.parameters", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal"], "function", ["None"], ["", "def", "check_tsm_optimizer", "(", "optimizer", ",", "model", ",", "fc_lr5", "=", "True", ")", ":", "\n", "    ", "param_groups", "=", "optimizer", ".", "param_groups", "\n", "assert", "isinstance", "(", "optimizer", ",", "torch", ".", "optim", ".", "SGD", ")", "\n", "assert", "optimizer", ".", "defaults", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "optimizer", ".", "defaults", "[", "'momentum'", "]", "==", "momentum", "\n", "assert", "optimizer", ".", "defaults", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "model_parameters", "=", "list", "(", "model", ".", "parameters", "(", ")", ")", "\n", "# first_conv_weight", "\n", "first_conv_weight", "=", "param_groups", "[", "0", "]", "\n", "assert", "torch", ".", "equal", "(", "first_conv_weight", "[", "'params'", "]", "[", "0", "]", ",", "model_parameters", "[", "1", "]", ")", "\n", "assert", "first_conv_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "first_conv_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# first_conv_bias", "\n", "first_conv_bias", "=", "param_groups", "[", "1", "]", "\n", "assert", "first_conv_bias", "[", "'params'", "]", "==", "[", "]", "\n", "assert", "first_conv_bias", "[", "'lr'", "]", "==", "base_lr", "*", "2", "\n", "assert", "first_conv_bias", "[", "'weight_decay'", "]", "==", "0", "\n", "# normal_weight", "\n", "normal_weight", "=", "param_groups", "[", "2", "]", "\n", "assert", "torch", ".", "equal", "(", "normal_weight", "[", "'params'", "]", "[", "0", "]", ",", "model_parameters", "[", "2", "]", ")", "\n", "assert", "torch", ".", "equal", "(", "normal_weight", "[", "'params'", "]", "[", "1", "]", ",", "model_parameters", "[", "7", "]", ")", "\n", "assert", "normal_weight", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "normal_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "# normal_bias", "\n", "normal_bias", "=", "param_groups", "[", "3", "]", "\n", "assert", "torch", ".", "equal", "(", "normal_bias", "[", "'params'", "]", "[", "0", "]", ",", "model_parameters", "[", "3", "]", ")", "\n", "assert", "torch", ".", "equal", "(", "normal_bias", "[", "'params'", "]", "[", "1", "]", ",", "model_parameters", "[", "8", "]", ")", "\n", "assert", "normal_bias", "[", "'lr'", "]", "==", "base_lr", "*", "2", "\n", "assert", "normal_bias", "[", "'weight_decay'", "]", "==", "0", "\n", "# bn", "\n", "bn", "=", "param_groups", "[", "4", "]", "\n", "assert", "torch", ".", "equal", "(", "bn", "[", "'params'", "]", "[", "0", "]", ",", "model_parameters", "[", "4", "]", ")", "\n", "assert", "torch", ".", "equal", "(", "bn", "[", "'params'", "]", "[", "1", "]", ",", "model_parameters", "[", "5", "]", ")", "\n", "assert", "torch", ".", "equal", "(", "bn", "[", "'params'", "]", "[", "2", "]", ",", "model_parameters", "[", "9", "]", ")", "\n", "assert", "torch", ".", "equal", "(", "bn", "[", "'params'", "]", "[", "3", "]", ",", "model_parameters", "[", "10", "]", ")", "\n", "assert", "bn", "[", "'lr'", "]", "==", "base_lr", "\n", "assert", "bn", "[", "'weight_decay'", "]", "==", "0", "\n", "# normal linear weight", "\n", "assert", "torch", ".", "equal", "(", "normal_weight", "[", "'params'", "]", "[", "2", "]", ",", "model_parameters", "[", "11", "]", ")", "\n", "# normal linear bias", "\n", "assert", "torch", ".", "equal", "(", "normal_bias", "[", "'params'", "]", "[", "2", "]", ",", "model_parameters", "[", "12", "]", ")", "\n", "# fc_lr5", "\n", "lr5_weight", "=", "param_groups", "[", "5", "]", "\n", "lr10_bias", "=", "param_groups", "[", "6", "]", "\n", "assert", "lr5_weight", "[", "'lr'", "]", "==", "base_lr", "*", "5", "\n", "assert", "lr5_weight", "[", "'weight_decay'", "]", "==", "base_wd", "\n", "assert", "lr10_bias", "[", "'lr'", "]", "==", "base_lr", "*", "10", "\n", "assert", "lr10_bias", "[", "'weight_decay'", "]", "==", "0", "\n", "if", "fc_lr5", ":", "\n", "# lr5_weight", "\n", "        ", "assert", "torch", ".", "equal", "(", "lr5_weight", "[", "'params'", "]", "[", "0", "]", ",", "model_parameters", "[", "13", "]", ")", "\n", "# lr10_bias", "\n", "assert", "torch", ".", "equal", "(", "lr10_bias", "[", "'params'", "]", "[", "0", "]", ",", "model_parameters", "[", "14", "]", ")", "\n", "", "else", ":", "\n", "# lr5_weight", "\n", "        ", "assert", "lr5_weight", "[", "'params'", "]", "==", "[", "]", "\n", "# lr10_bias", "\n", "assert", "lr10_bias", "[", "'params'", "]", "==", "[", "]", "\n", "assert", "torch", ".", "equal", "(", "normal_weight", "[", "'params'", "]", "[", "3", "]", ",", "model_parameters", "[", "13", "]", ")", "\n", "assert", "torch", ".", "equal", "(", "normal_bias", "[", "'params'", "]", "[", "3", "]", ",", "model_parameters", "[", "14", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.test_tsm_optimizer_constructor": [[191, 214], ["test_optimizer.ExampleModel", "dict", "dict", "dict", "mmcv.runner.build_optimizer_constructor", "mmcv.runner.build_optimizer_constructor.", "test_optimizer.check_tsm_optimizer", "dict", "dict", "mmcv.runner.build_optimizer_constructor", "mmcv.runner.build_optimizer_constructor.", "test_optimizer.check_tsm_optimizer"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.check_tsm_optimizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_optimizer.check_tsm_optimizer"], ["", "", "def", "test_tsm_optimizer_constructor", "(", ")", ":", "\n", "    ", "model", "=", "ExampleModel", "(", ")", "\n", "optimizer_cfg", "=", "dict", "(", "\n", "type", "=", "'SGD'", ",", "lr", "=", "base_lr", ",", "weight_decay", "=", "base_wd", ",", "momentum", "=", "momentum", ")", "\n", "# fc_lr5 is True", "\n", "paramwise_cfg", "=", "dict", "(", "fc_lr5", "=", "True", ")", "\n", "optim_constructor_cfg", "=", "dict", "(", "\n", "type", "=", "'TSMOptimizerConstructor'", ",", "\n", "optimizer_cfg", "=", "optimizer_cfg", ",", "\n", "paramwise_cfg", "=", "paramwise_cfg", ")", "\n", "optim_constructor", "=", "build_optimizer_constructor", "(", "optim_constructor_cfg", ")", "\n", "optimizer", "=", "optim_constructor", "(", "model", ")", "\n", "check_tsm_optimizer", "(", "optimizer", ",", "model", ",", "**", "paramwise_cfg", ")", "\n", "\n", "# fc_lr5 is False", "\n", "paramwise_cfg", "=", "dict", "(", "fc_lr5", "=", "False", ")", "\n", "optim_constructor_cfg", "=", "dict", "(", "\n", "type", "=", "'TSMOptimizerConstructor'", ",", "\n", "optimizer_cfg", "=", "optimizer_cfg", ",", "\n", "paramwise_cfg", "=", "paramwise_cfg", ")", "\n", "optim_constructor", "=", "build_optimizer_constructor", "(", "optim_constructor_cfg", ")", "\n", "optimizer", "=", "optim_constructor", "(", "model", ")", "\n", "check_tsm_optimizer", "(", "optimizer", ",", "model", ",", "**", "paramwise_cfg", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.ExampleDataset.__init__": [[30, 33], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "index", "=", "0", "\n", "self", ".", "eval_result", "=", "[", "1", ",", "4", ",", "3", ",", "7", ",", "2", ",", "-", "3", ",", "4", ",", "6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.ExampleDataset.__getitem__": [[34, 37], ["dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "results", "=", "dict", "(", "x", "=", "torch", ".", "tensor", "(", "[", "1", "]", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.ExampleDataset.__len__": [[38, 40], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.ExampleDataset.evaluate": [[41, 44], ["None"], "methods", ["None"], ["", "@", "mock", ".", "create_autospec", "\n", "def", "evaluate", "(", "self", ",", "results", ",", "logger", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.EvalDataset.evaluate": [[48, 53], ["collections.OrderedDict"], "methods", ["None"], ["    ", "def", "evaluate", "(", "self", ",", "results", ",", "logger", "=", "None", ")", ":", "\n", "        ", "acc", "=", "self", ".", "eval_result", "[", "self", ".", "index", "]", "\n", "output", "=", "OrderedDict", "(", "acc", "=", "acc", ",", "index", "=", "self", ".", "index", ",", "score", "=", "acc", ")", "\n", "self", ".", "index", "+=", "1", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.Model.__init__": [[57, 60], ["torch.Module.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.Model.forward": [[61, 64], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.Model.train_step": [[65, 70], ["isinstance", "dict"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "train_step", "(", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "data_batch", ",", "dict", ")", ":", "\n", "            ", "data_batch", "=", "dict", "(", "x", "=", "data_batch", ")", "\n", "", "return", "data_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.Model.val_step": [[71, 73], ["dict", "test_eval_hook.Model."], "methods", ["None"], ["", "def", "val_step", "(", "self", ",", "x", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "dict", "(", "loss", "=", "self", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook._build_epoch_runner": [[75, 83], ["test_eval_hook.Model", "tempfile.mkdtemp", "mmcv.runner.EpochBasedRunner", "mmcv.utils.get_logger"], "function", ["None"], ["", "", "def", "_build_epoch_runner", "(", ")", ":", "\n", "\n", "    ", "model", "=", "Model", "(", ")", "\n", "tmp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "work_dir", "=", "tmp_dir", ",", "logger", "=", "get_logger", "(", "'demo'", ")", ")", "\n", "return", "runner", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook._build_iter_runner": [[85, 93], ["test_eval_hook.Model", "tempfile.mkdtemp", "mmcv.runner.IterBasedRunner", "mmcv.utils.get_logger"], "function", ["None"], ["", "def", "_build_iter_runner", "(", ")", ":", "\n", "\n", "    ", "model", "=", "Model", "(", ")", "\n", "tmp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "\n", "runner", "=", "IterBasedRunner", "(", "\n", "model", "=", "model", ",", "work_dir", "=", "tmp_dir", ",", "logger", "=", "get_logger", "(", "'demo'", ")", ")", "\n", "return", "runner", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.test_eval_hook": [[95, 242], ["test_eval_hook.ExampleDataset", "torch.utils.data.DataLoader", "test_eval_hook.Model", "torch.utils.data.DataLoader", "EvalHook", "torch.utils.data.DataLoader", "test_eval_hook.Model", "torch.utils.data.DataLoader", "EvalHook", "torch.utils.data.DataLoader", "test_eval_hook.Model", "torch.utils.data.DataLoader", "EvalHook", "torch.utils.data.DataLoader", "EvalHook", "torch.utils.data.DataLoader", "EvalHook", "torch.utils.data.DataLoader", "EvalHook", "pytest.raises", "test_eval_hook.Model", "torch.utils.data.DataLoader", "EvalHook", "pytest.raises", "test_eval_hook.Model", "EvalHook", "pytest.raises", "test_eval_hook.ExampleDataset", "torch.utils.data.DataLoader", "EvalHook", "pytest.raises", "test_eval_hook.Model", "torch.utils.data.DataLoader", "EvalHook", "tempfile.TemporaryDirectory", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "Model.evaluate.assert_called_with", "test_eval_hook.EvalDataset", "test_eval_hook.EvalDataset", "tempfile.TemporaryDirectory", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_checkpoint_hook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "os.join", "os.exists", "test_eval_hook.EvalDataset", "test_eval_hook.EvalDataset", "tempfile.TemporaryDirectory", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_checkpoint_hook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "os.join", "os.exists", "test_eval_hook.EvalDataset", "tempfile.TemporaryDirectory", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_checkpoint_hook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "os.join", "os.exists", "test_eval_hook.EvalDataset", "tempfile.TemporaryDirectory", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_checkpoint_hook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "os.join", "os.exists", "test_eval_hook.EvalDataset", "tempfile.TemporaryDirectory", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_checkpoint_hook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "os.join", "os.exists", "os.join", "torch.utils.data.DataLoader", "EvalHook", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_checkpoint_hook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.resume", "mmcv.runner.EpochBasedRunner.run", "os.join", "os.exists", "torch.utils.data.DataLoader", "dict", "os.realpath", "dict", "os.realpath", "dict", "os.realpath", "dict", "os.realpath", "dict", "os.realpath", "test_eval_hook.ExampleDataset", "dict", "os.realpath", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.epoch_based_runner.EpochBasedRunnerAmp.resume", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_eval_hook", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# `save_best` should be a str", "\n", "        ", "test_dataset", "=", "Model", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "test_dataset", ")", "\n", "EvalHook", "(", "data_loader", ",", "save_best", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# dataloader must be a pytorch DataLoader", "\n", "        ", "test_dataset", "=", "Model", "(", ")", "\n", "data_loader", "=", "[", "DataLoader", "(", "test_dataset", ")", "]", "\n", "EvalHook", "(", "data_loader", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# save_best must be valid when rule_map is None", "\n", "        ", "test_dataset", "=", "ExampleDataset", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "test_dataset", ")", "\n", "EvalHook", "(", "data_loader", ",", "save_best", "=", "'unsupport'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "# rule must be in keys of rule_map", "\n", "        ", "test_dataset", "=", "Model", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "test_dataset", ")", "\n", "EvalHook", "(", "data_loader", ",", "save_best", "=", "'auto'", ",", "rule", "=", "'unsupport'", ")", "\n", "\n", "", "test_dataset", "=", "ExampleDataset", "(", ")", "\n", "loader", "=", "DataLoader", "(", "test_dataset", ")", "\n", "model", "=", "Model", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "test_dataset", ")", "\n", "eval_hook", "=", "EvalHook", "(", "data_loader", ",", "save_best", "=", "None", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "\n", "# total_epochs = 1", "\n", "        ", "logger", "=", "get_logger", "(", "'test_eval'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "test_dataset", ".", "evaluate", ".", "assert_called_with", "(", "\n", "test_dataset", ",", "[", "torch", ".", "tensor", "(", "[", "1", "]", ")", "]", ",", "logger", "=", "runner", ".", "logger", ")", "\n", "assert", "runner", ".", "meta", "is", "None", "or", "'best_score'", "not", "in", "runner", ".", "meta", "[", "\n", "'hook_msgs'", "]", "\n", "assert", "runner", ".", "meta", "is", "None", "or", "'best_ckpt'", "not", "in", "runner", ".", "meta", "[", "\n", "'hook_msgs'", "]", "\n", "\n", "# when `save_best` is set to 'auto', first metric will be used.", "\n", "", "loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "model", "=", "Model", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "eval_hook", "=", "EvalHook", "(", "data_loader", ",", "interval", "=", "1", ",", "save_best", "=", "'auto'", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "logger", "=", "get_logger", "(", "'test_eval'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "8", ")", "\n", "\n", "ckpt_path", "=", "osp", ".", "join", "(", "tmpdir", ",", "'best_acc_epoch_4.pth'", ")", "\n", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_ckpt'", "]", "==", "osp", ".", "realpath", "(", "ckpt_path", ")", "\n", "assert", "osp", ".", "exists", "(", "ckpt_path", ")", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_score'", "]", "==", "7", "\n", "\n", "# total_epochs = 8, return the best acc and corresponding epoch", "\n", "", "loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "model", "=", "Model", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "eval_hook", "=", "EvalHook", "(", "data_loader", ",", "interval", "=", "1", ",", "save_best", "=", "'acc'", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "logger", "=", "get_logger", "(", "'test_eval'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "8", ")", "\n", "\n", "ckpt_path", "=", "osp", ".", "join", "(", "tmpdir", ",", "'best_acc_epoch_4.pth'", ")", "\n", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_ckpt'", "]", "==", "osp", ".", "realpath", "(", "ckpt_path", ")", "\n", "assert", "osp", ".", "exists", "(", "ckpt_path", ")", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_score'", "]", "==", "7", "\n", "\n", "# total_epochs = 8, return the best score and corresponding epoch", "\n", "", "data_loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "eval_hook", "=", "EvalHook", "(", "\n", "data_loader", ",", "interval", "=", "1", ",", "save_best", "=", "'score'", ",", "rule", "=", "'greater'", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "logger", "=", "get_logger", "(", "'test_eval'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "8", ")", "\n", "\n", "ckpt_path", "=", "osp", ".", "join", "(", "tmpdir", ",", "'best_score_epoch_4.pth'", ")", "\n", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_ckpt'", "]", "==", "osp", ".", "realpath", "(", "ckpt_path", ")", "\n", "assert", "osp", ".", "exists", "(", "ckpt_path", ")", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_score'", "]", "==", "7", "\n", "\n", "# total_epochs = 8, return the best score using less compare func", "\n", "# and indicate corresponding epoch", "\n", "", "data_loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "eval_hook", "=", "EvalHook", "(", "data_loader", ",", "save_best", "=", "'acc'", ",", "rule", "=", "'less'", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "logger", "=", "get_logger", "(", "'test_eval'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "8", ")", "\n", "\n", "ckpt_path", "=", "osp", ".", "join", "(", "tmpdir", ",", "'best_acc_epoch_6.pth'", ")", "\n", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_ckpt'", "]", "==", "osp", ".", "realpath", "(", "ckpt_path", ")", "\n", "assert", "osp", ".", "exists", "(", "ckpt_path", ")", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_score'", "]", "==", "-", "3", "\n", "\n", "# Test the EvalHook when resume happend", "\n", "", "data_loader", "=", "DataLoader", "(", "EvalDataset", "(", ")", ")", "\n", "eval_hook", "=", "EvalHook", "(", "data_loader", ",", "save_best", "=", "'acc'", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "logger", "=", "get_logger", "(", "'test_eval'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "\n", "ckpt_path", "=", "osp", ".", "join", "(", "tmpdir", ",", "'best_acc_epoch_2.pth'", ")", "\n", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_ckpt'", "]", "==", "osp", ".", "realpath", "(", "ckpt_path", ")", "\n", "assert", "osp", ".", "exists", "(", "ckpt_path", ")", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_score'", "]", "==", "4", "\n", "\n", "resume_from", "=", "osp", ".", "join", "(", "tmpdir", ",", "'latest.pth'", ")", "\n", "loader", "=", "DataLoader", "(", "ExampleDataset", "(", ")", ")", "\n", "eval_hook", "=", "EvalHook", "(", "data_loader", ",", "save_best", "=", "'acc'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "model", "=", "model", ",", "work_dir", "=", "tmpdir", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_hook", "(", "eval_hook", ")", "\n", "runner", ".", "resume", "(", "resume_from", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "8", ")", "\n", "\n", "ckpt_path", "=", "osp", ".", "join", "(", "tmpdir", ",", "'best_acc_epoch_4.pth'", ")", "\n", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_ckpt'", "]", "==", "osp", ".", "realpath", "(", "ckpt_path", ")", "\n", "assert", "osp", ".", "exists", "(", "ckpt_path", ")", "\n", "assert", "runner", ".", "meta", "[", "'hook_msgs'", "]", "[", "'best_score'", "]", "==", "7", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_eval_hook.test_start_param": [[244, 344], ["unittest.mock.patch", "unittest.mock.patch", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.utils.data.DataLoader", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "_build_demo_runner", "EvalHookParam", "unittest.mock.MagicMock", "_build_demo_runner.register_hook", "_build_demo_runner.run", "torch.ones", "torch.ones", "pytest.raises", "EvalHookParam", "pytest.raises", "EvalHookParam", "pytest.warns", "EvalHookParam", "unittest.mock.MagicMock"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["", "", "@", "patch", "(", "'mmaction.apis.single_gpu_test'", ",", "MagicMock", ")", "\n", "@", "patch", "(", "'mmaction.apis.multi_gpu_test'", ",", "MagicMock", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'EvalHookParam'", ",", "[", "EvalHook", ",", "DistEvalHook", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'_build_demo_runner,by_epoch'", ",", "\n", "[", "(", "_build_epoch_runner", ",", "True", ")", ",", "\n", "(", "_build_iter_runner", ",", "False", ")", "]", ")", "\n", "def", "test_start_param", "(", "EvalHookParam", ",", "_build_demo_runner", ",", "by_epoch", ")", ":", "\n", "# create dummy data", "\n", "    ", "dataloader", "=", "DataLoader", "(", "torch", ".", "ones", "(", "(", "5", ",", "2", ")", ")", ")", "\n", "\n", "# 0.1. dataloader is not a DataLoader object", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "EvalHookParam", "(", "dataloader", "=", "MagicMock", "(", ")", ",", "interval", "=", "-", "1", ")", "\n", "\n", "# 0.2. negative interval", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "EvalHookParam", "(", "dataloader", ",", "interval", "=", "-", "1", ")", "\n", "\n", "# 1. start=None, interval=1: perform evaluation after each epoch.", "\n", "", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "interval", "=", "1", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 1 & 2", "\n", "\n", "# 2. start=1, interval=1: perform evaluation after each epoch.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "start", "=", "1", ",", "interval", "=", "1", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 1 & 2", "\n", "\n", "# 3. start=None, interval=2: perform evaluation after epoch 2, 4, 6, etc", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "interval", "=", "2", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "1", "# after epoch 2", "\n", "\n", "# 4. start=1, interval=2: perform evaluation after epoch 1, 3, 5, etc", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "start", "=", "1", ",", "interval", "=", "2", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "3", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 1 & 3", "\n", "\n", "# 5. start=0/negative, interval=1: perform evaluation after each epoch and", "\n", "#    before epoch 1.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "start", "=", "0", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "3", "# before epoch1 and after e1 & e2", "\n", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "with", "pytest", ".", "warns", "(", "UserWarning", ")", ":", "\n", "        ", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "start", "=", "-", "2", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "2", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "3", "# before epoch1 and after e1 & e2", "\n", "\n", "# 6. resuming from epoch i, start = x (x<=i), interval =1: perform", "\n", "#    evaluation after each epoch and before the first epoch.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "start", "=", "1", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "if", "by_epoch", ":", "\n", "        ", "runner", ".", "_epoch", "=", "2", "\n", "", "else", ":", "\n", "        ", "runner", ".", "_iter", "=", "2", "\n", "", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "3", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# before & after epoch 3", "\n", "\n", "# 7. resuming from epoch i, start = i+1/None, interval =1: perform", "\n", "#    evaluation after each epoch.", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "evalhook", "=", "EvalHookParam", "(", "\n", "dataloader", ",", "start", "=", "2", ",", "by_epoch", "=", "by_epoch", ",", "save_best", "=", "None", ")", "\n", "evalhook", ".", "evaluate", "=", "MagicMock", "(", ")", "\n", "runner", ".", "register_hook", "(", "evalhook", ")", "\n", "if", "by_epoch", ":", "\n", "        ", "runner", ".", "_epoch", "=", "1", "\n", "", "else", ":", "\n", "        ", "runner", ".", "_iter", "=", "1", "\n", "", "runner", ".", "run", "(", "[", "dataloader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "3", ")", "\n", "assert", "evalhook", ".", "evaluate", ".", "call_count", "==", "2", "# after epoch 2 & 3", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_config._get_config_path": [[11, 24], ["os.dirname", "os.join", "list", "print", "os.dirname", "os.exists", "Exception", "glob.glob", "os.path.relpath", "os.path.relpath", "os.join", "os.dirname", "os.join", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["def", "_get_config_path", "(", ")", ":", "\n", "    ", "\"\"\"Find the predefined recognizer config path.\"\"\"", "\n", "repo_dir", "=", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "__file__", ")", ")", ")", "\n", "config_dpath", "=", "osp", ".", "join", "(", "repo_dir", ",", "'configs'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "config_dpath", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Cannot find config path'", ")", "\n", "", "config_fpaths", "=", "list", "(", "glob", ".", "glob", "(", "osp", ".", "join", "(", "config_dpath", ",", "'*.py'", ")", ")", ")", "\n", "config_names", "=", "[", "os", ".", "path", ".", "relpath", "(", "p", ",", "config_dpath", ")", "for", "p", "in", "config_fpaths", "]", "\n", "print", "(", "f'Using {len(config_names)} config files'", ")", "\n", "config_fpaths", "=", "[", "\n", "osp", ".", "join", "(", "config_dpath", ",", "config_fpath", ")", "for", "config_fpath", "in", "config_fpaths", "\n", "]", "\n", "return", "config_fpaths", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_config.test_config_build_recognizer": [[26, 45], ["os.dirname", "os.join", "list", "os.dirname", "os.exists", "Exception", "glob.glob", "mmcv.Config.fromfile", "print", "mmaction.models.build_recognizer", "isinstance", "os.dirname", "os.join"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_config_build_recognizer", "(", ")", ":", "\n", "    ", "\"\"\"Test that all mmaction models defined in the configs can be\n    initialized.\"\"\"", "\n", "repo_dir", "=", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "__file__", ")", ")", ")", "\n", "config_dpath", "=", "osp", ".", "join", "(", "repo_dir", ",", "'configs/recognition'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "config_dpath", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Cannot find config path'", ")", "\n", "", "config_fpaths", "=", "list", "(", "glob", ".", "glob", "(", "osp", ".", "join", "(", "config_dpath", ",", "'*.py'", ")", ")", ")", "\n", "# test all config file in `configs` directory", "\n", "for", "config_fpath", "in", "config_fpaths", ":", "\n", "        ", "config_mod", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "config_fpath", ")", "\n", "print", "(", "f'Building recognizer, config_fpath = {config_fpath!r}'", ")", "\n", "\n", "# Remove pretrained keys to allow for testing in an offline environment", "\n", "if", "'pretrained'", "in", "config_mod", ".", "model", "[", "'backbone'", "]", ":", "\n", "            ", "config_mod", ".", "model", "[", "'backbone'", "]", "[", "'pretrained'", "]", "=", "None", "\n", "\n", "", "recognizer", "=", "build_recognizer", "(", "config_mod", ".", "model", ")", "\n", "assert", "isinstance", "(", "recognizer", ",", "nn", ".", "Module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_config._get_config_path_for_localizer": [[47, 60], ["os.dirname", "os.join", "list", "print", "os.dirname", "os.exists", "Exception", "glob.glob", "os.path.relpath", "os.path.relpath", "os.join", "os.dirname", "os.join", "len"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "", "def", "_get_config_path_for_localizer", "(", ")", ":", "\n", "    ", "\"\"\"Find the predefined localizer config path for localizer.\"\"\"", "\n", "repo_dir", "=", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "osp", ".", "dirname", "(", "__file__", ")", ")", ")", "\n", "config_dpath", "=", "osp", ".", "join", "(", "repo_dir", ",", "'configs/localization'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "config_dpath", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Cannot find config path'", ")", "\n", "", "config_fpaths", "=", "list", "(", "glob", ".", "glob", "(", "osp", ".", "join", "(", "config_dpath", ",", "'*.py'", ")", ")", ")", "\n", "config_names", "=", "[", "os", ".", "path", ".", "relpath", "(", "p", ",", "config_dpath", ")", "for", "p", "in", "config_fpaths", "]", "\n", "print", "(", "f'Using {len(config_names)} config files'", ")", "\n", "config_fpaths", "=", "[", "\n", "osp", ".", "join", "(", "config_dpath", ",", "config_fpath", ")", "for", "config_fpath", "in", "config_fpaths", "\n", "]", "\n", "return", "config_fpaths", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_config.test_config_build_localizer": [[62, 74], ["test_config._get_config_path_for_localizer", "mmcv.Config.fromfile", "print", "mmcv.Config.fromfile.get", "mmaction.models.build_localizer", "isinstance"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_config._get_config_path_for_localizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.ava_evaluation.np_box_list.BoxList.get", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.models.builder.build_localizer"], ["", "def", "test_config_build_localizer", "(", ")", ":", "\n", "    ", "\"\"\"Test that all mmaction models defined in the configs can be\n    initialized.\"\"\"", "\n", "config_fpaths", "=", "_get_config_path_for_localizer", "(", ")", "\n", "\n", "# test all config file in `configs/localization` directory", "\n", "for", "config_fpath", "in", "config_fpaths", ":", "\n", "        ", "config_mod", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "config_fpath", ")", "\n", "print", "(", "f'Building localizer, config_fpath = {config_fpath!r}'", ")", "\n", "if", "config_mod", ".", "get", "(", "'model'", ",", "None", ")", ":", "\n", "            ", "localizer", "=", "build_localizer", "(", "config_mod", ".", "model", ")", "\n", "assert", "isinstance", "(", "localizer", ",", "nn", ".", "Module", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr.test_tin_lr_updater_hook": [[13, 75], ["unittest.mock.MagicMock", "torch.utils.data.DataLoader", "test_lr._build_demo_runner", "dict", "_build_demo_runner.register_hook_from_cfg", "dict", "_build_demo_runner.register_hook_from_cfg", "_build_demo_runner.register_hook_from_cfg", "_build_demo_runner.register_hook", "dict", "_build_demo_runner.register_hook_from_cfg", "_build_demo_runner.register_hook_from_cfg", "_build_demo_runner.register_hook", "dict", "_build_demo_runner.register_hook_from_cfg", "_build_demo_runner.register_hook_from_cfg", "_build_demo_runner.register_hook", "mmcv.runner.PaviLoggerHook", "_build_demo_runner.register_hook", "_build_demo_runner.run", "shutil.rmtree", "hasattr", "mmcv.runner.PaviLoggerHook.writer.add_scalars.assert_has_calls", "torch.ones", "torch.ones", "dict", "mmcv.runner.IterTimerHook", "dict", "mmcv.runner.IterTimerHook", "dict", "mmcv.runner.IterTimerHook", "unittest.mock.call", "unittest.mock.call", "unittest.mock.call"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["def", "test_tin_lr_updater_hook", "(", ")", ":", "\n", "    ", "sys", ".", "modules", "[", "'pavi'", "]", "=", "MagicMock", "(", ")", "\n", "loader", "=", "DataLoader", "(", "torch", ".", "ones", "(", "(", "10", ",", "2", ")", ")", ")", "\n", "runner", "=", "_build_demo_runner", "(", ")", "\n", "\n", "hook_cfg", "=", "dict", "(", "type", "=", "'TINLrUpdaterHook'", ",", "min_lr", "=", "0.1", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "hook_cfg", ")", "\n", "\n", "hook_cfg", "=", "dict", "(", "\n", "type", "=", "'TINLrUpdaterHook'", ",", "\n", "by_epoch", "=", "False", ",", "\n", "min_lr", "=", "0.1", ",", "\n", "warmup", "=", "'exp'", ",", "\n", "warmup_iters", "=", "2", ",", "\n", "warmup_ratio", "=", "0.9", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "hook_cfg", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "dict", "(", "type", "=", "'IterTimerHook'", ")", ")", "\n", "runner", ".", "register_hook", "(", "IterTimerHook", "(", ")", ")", "\n", "\n", "hook_cfg", "=", "dict", "(", "\n", "type", "=", "'TINLrUpdaterHook'", ",", "\n", "by_epoch", "=", "False", ",", "\n", "min_lr", "=", "0.1", ",", "\n", "warmup", "=", "'constant'", ",", "\n", "warmup_iters", "=", "2", ",", "\n", "warmup_ratio", "=", "0.9", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "hook_cfg", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "dict", "(", "type", "=", "'IterTimerHook'", ")", ")", "\n", "runner", ".", "register_hook", "(", "IterTimerHook", "(", ")", ")", "\n", "\n", "hook_cfg", "=", "dict", "(", "\n", "type", "=", "'TINLrUpdaterHook'", ",", "\n", "by_epoch", "=", "False", ",", "\n", "min_lr", "=", "0.1", ",", "\n", "warmup", "=", "'linear'", ",", "\n", "warmup_iters", "=", "2", ",", "\n", "warmup_ratio", "=", "0.9", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "hook_cfg", ")", "\n", "runner", ".", "register_hook_from_cfg", "(", "dict", "(", "type", "=", "'IterTimerHook'", ")", ")", "\n", "runner", ".", "register_hook", "(", "IterTimerHook", "(", ")", ")", "\n", "# add pavi hook", "\n", "hook", "=", "PaviLoggerHook", "(", "interval", "=", "1", ",", "add_graph", "=", "False", ",", "add_last_ckpt", "=", "True", ")", "\n", "runner", ".", "register_hook", "(", "hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ")", "\n", "shutil", ".", "rmtree", "(", "runner", ".", "work_dir", ")", "\n", "\n", "assert", "hasattr", "(", "hook", ",", "'writer'", ")", "\n", "calls", "=", "[", "\n", "call", "(", "'train'", ",", "{", "\n", "'learning_rate'", ":", "0.028544155877284292", ",", "\n", "'momentum'", ":", "0.95", "\n", "}", ",", "1", ")", ",", "\n", "call", "(", "'train'", ",", "{", "\n", "'learning_rate'", ":", "0.04469266270539641", ",", "\n", "'momentum'", ":", "0.95", "\n", "}", ",", "6", ")", ",", "\n", "call", "(", "'train'", ",", "{", "\n", "'learning_rate'", ":", "0.09695518130045147", ",", "\n", "'momentum'", ":", "0.95", "\n", "}", ",", "10", ")", "\n", "]", "\n", "hook", ".", "writer", ".", "add_scalars", ".", "assert_has_calls", "(", "calls", ",", "any_order", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_lr._build_demo_runner": [[77, 118], ["Model", "torch.optim.SGD", "torch.optim.SGD", "dict", "tempfile.mkdtemp", "mmcv.runner.build_runner", "mmcv.runner.build_runner.register_checkpoint_hook", "mmcv.runner.build_runner.register_logger_hooks", "Model.parameters", "dict", "dict", "super().__init__", "torch.Linear", "test_lr..linear", "dict", "dict", "dict", "dict", "test_lr..", "test_lr..", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["", "def", "_build_demo_runner", "(", "runner_type", "=", "'EpochBasedRunner'", ",", "\n", "max_epochs", "=", "1", ",", "\n", "max_iters", "=", "None", ")", ":", "\n", "\n", "    ", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "2", ",", "1", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "            ", "return", "self", ".", "linear", "(", "x", ")", "\n", "\n", "", "def", "train_step", "(", "self", ",", "x", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "dict", "(", "loss", "=", "self", "(", "x", ")", ")", "\n", "\n", "", "def", "val_step", "(", "self", ",", "x", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "dict", "(", "loss", "=", "self", "(", "x", ")", ")", "\n", "\n", "", "", "model", "=", "Model", "(", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0.02", ",", "momentum", "=", "0.95", ")", "\n", "\n", "log_config", "=", "dict", "(", "\n", "interval", "=", "1", ",", "hooks", "=", "[", "\n", "dict", "(", "type", "=", "'TextLoggerHook'", ")", ",", "\n", "]", ")", "\n", "\n", "tmp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "runner", "=", "build_runner", "(", "\n", "dict", "(", "type", "=", "runner_type", ")", ",", "\n", "default_args", "=", "dict", "(", "\n", "model", "=", "model", ",", "\n", "work_dir", "=", "tmp_dir", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", ",", "\n", "max_epochs", "=", "max_epochs", ",", "\n", "max_iters", "=", "max_iters", ")", ")", "\n", "runner", ".", "register_checkpoint_hook", "(", "dict", "(", "interval", "=", "1", ")", ")", "\n", "runner", ".", "register_logger_hooks", "(", "log_config", ")", "\n", "return", "runner", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.__init__": [[18, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "self", ".", "test_mode", "=", "test_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate": [[21, 26], ["collections.OrderedDict"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "evaluate", "(", "results", ",", "logger", "=", "None", ")", ":", "\n", "        ", "eval_results", "=", "OrderedDict", "(", ")", "\n", "eval_results", "[", "'acc'", "]", "=", "1", "\n", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.__getitem__": [[27, 30], ["dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "results", "=", "dict", "(", "imgs", "=", "torch", ".", "tensor", "(", "[", "1", "]", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.__len__": [[31, 33], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleModel.__init__": [[37, 42], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "test_cfg", "=", "None", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "norm1", "=", "nn", ".", "BatchNorm1d", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleModel.forward": [[43, 48], ["test_train.ExampleModel.norm1", "dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand().cuda", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "imgs", ",", "return_loss", "=", "False", ")", ":", "\n", "        ", "self", ".", "norm1", "(", "torch", ".", "rand", "(", "3", ",", "2", ")", ".", "cuda", "(", ")", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "losses", "[", "'test_loss'", "]", "=", "torch", ".", "tensor", "(", "[", "0.5", "]", ",", "requires_grad", "=", "True", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleModel.train_step": [[49, 55], ["test_train.ExampleModel.forward", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.forward"], ["", "def", "train_step", "(", "self", ",", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "imgs", "=", "data_batch", "[", "'imgs'", "]", "\n", "losses", "=", "self", ".", "forward", "(", "imgs", ",", "True", ")", "\n", "loss", "=", "torch", ".", "tensor", "(", "[", "0.5", "]", ",", "requires_grad", "=", "True", ")", "\n", "outputs", "=", "dict", "(", "loss", "=", "loss", ",", "log_vars", "=", "losses", ",", "num_samples", "=", "3", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleModel.val_step": [[56, 61], ["test_train.ExampleModel.forward", "dict"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.forward"], ["", "def", "val_step", "(", "self", ",", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "imgs", "=", "data_batch", "[", "'imgs'", "]", "\n", "self", ".", "forward", "(", "imgs", ",", "False", ")", "\n", "outputs", "=", "dict", "(", "results", "=", "0.5", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.test_train_model": [[63, 134], ["pytest.mark.skipif", "test_train.ExampleModel", "test_train.ExampleDataset", "dict", "test_train.ExampleDataset", "test_train.ExampleDataset", "tempfile.TemporaryDirectory", "copy.deepcopy", "mmcv.Config", "mmaction.apis.train_model", "tempfile.TemporaryDirectory", "copy.deepcopy", "mmcv.Config", "mmaction.apis.train_model", "tempfile.TemporaryDirectory", "copy.deepcopy", "dict", "mmcv.Config", "mmaction.apis.train_model", "tempfile.TemporaryDirectory", "copy.deepcopy", "mmcv.Config", "mmaction.apis.train_model", "tempfile.TemporaryDirectory", "copy.deepcopy", "dict", "dict", "mmcv.Config", "mmaction.apis.train_model", "torch.cuda.is_available", "torch.cuda.is_available", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.train.train_model"], ["", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "\n", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "reason", "=", "'requires CUDA support'", ")", "\n", "def", "test_train_model", "(", ")", ":", "\n", "    ", "model", "=", "ExampleModel", "(", ")", "\n", "dataset", "=", "ExampleDataset", "(", ")", "\n", "datasets", "=", "[", "ExampleDataset", "(", ")", ",", "ExampleDataset", "(", ")", "]", "\n", "_cfg", "=", "dict", "(", "\n", "seed", "=", "0", ",", "\n", "gpus", "=", "1", ",", "\n", "gpu_ids", "=", "[", "0", "]", ",", "\n", "resume_from", "=", "None", ",", "\n", "load_from", "=", "None", ",", "\n", "workflow", "=", "[", "(", "'train'", ",", "1", ")", "]", ",", "\n", "total_epochs", "=", "5", ",", "\n", "evaluation", "=", "dict", "(", "interval", "=", "1", ",", "save_best", "=", "'acc'", ")", ",", "\n", "data", "=", "dict", "(", "\n", "videos_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "0", ",", "\n", "val", "=", "dict", "(", "type", "=", "'ExampleDataset'", ")", ")", ",", "\n", "optimizer", "=", "dict", "(", "type", "=", "'SGD'", ",", "lr", "=", "0.01", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "0.0001", ")", ",", "\n", "optimizer_config", "=", "dict", "(", "grad_clip", "=", "dict", "(", "max_norm", "=", "40", ",", "norm_type", "=", "2", ")", ")", ",", "\n", "lr_config", "=", "dict", "(", "policy", "=", "'step'", ",", "step", "=", "[", "40", ",", "80", "]", ")", ",", "\n", "omnisource", "=", "False", ",", "\n", "precise_bn", "=", "False", ",", "\n", "checkpoint_config", "=", "dict", "(", "interval", "=", "1", ")", ",", "\n", "log_level", "=", "'INFO'", ",", "\n", "log_config", "=", "dict", "(", "interval", "=", "20", ",", "hooks", "=", "[", "dict", "(", "type", "=", "'TextLoggerHook'", ")", "]", ")", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# normal train", "\n", "        ", "cfg", "=", "copy", ".", "deepcopy", "(", "_cfg", ")", "\n", "cfg", "[", "'work_dir'", "]", "=", "tmpdir", "\n", "config", "=", "Config", "(", "cfg", ")", "\n", "train_model", "(", "model", ",", "dataset", ",", "config", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# train with validation", "\n", "        ", "cfg", "=", "copy", ".", "deepcopy", "(", "_cfg", ")", "\n", "cfg", "[", "'work_dir'", "]", "=", "tmpdir", "\n", "config", "=", "Config", "(", "cfg", ")", "\n", "train_model", "(", "model", ",", "dataset", ",", "config", ",", "validate", "=", "True", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# train with Fp16OptimizerHook", "\n", "        ", "cfg", "=", "copy", ".", "deepcopy", "(", "_cfg", ")", "\n", "cfg", "[", "'work_dir'", "]", "=", "tmpdir", "\n", "cfg", "[", "'fp16'", "]", "=", "dict", "(", "loss_scale", "=", "512.", ")", "\n", "config", "=", "Config", "(", "cfg", ")", "\n", "model", ".", "fp16_enabled", "=", "None", "\n", "train_model", "(", "model", ",", "dataset", ",", "config", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "cfg", "=", "copy", ".", "deepcopy", "(", "_cfg", ")", "\n", "cfg", "[", "'work_dir'", "]", "=", "tmpdir", "\n", "cfg", "[", "'omnisource'", "]", "=", "True", "\n", "config", "=", "Config", "(", "cfg", ")", "\n", "train_model", "(", "model", ",", "datasets", ",", "config", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# train with precise_bn on", "\n", "        ", "cfg", "=", "copy", ".", "deepcopy", "(", "_cfg", ")", "\n", "cfg", "[", "'work_dir'", "]", "=", "tmpdir", "\n", "cfg", "[", "'workflow'", "]", "=", "[", "(", "'train'", ",", "1", ")", ",", "(", "'val'", ",", "1", ")", "]", "\n", "cfg", "[", "'data'", "]", "=", "dict", "(", "\n", "videos_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "0", ",", "\n", "train", "=", "dict", "(", "type", "=", "'ExampleDataset'", ")", ",", "\n", "val", "=", "dict", "(", "type", "=", "'ExampleDataset'", ")", ")", "\n", "cfg", "[", "'precise_bn'", "]", "=", "dict", "(", "num_iters", "=", "1", ",", "interval", "=", "1", ")", "\n", "config", "=", "Config", "(", "cfg", ")", "\n", "train_model", "(", "model", ",", "datasets", ",", "config", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.OldStyleModel.__init__": [[27, 31], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "3", ",", "3", ",", "1", ")", "\n", "self", ".", "cnt", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.OldStyleModel.forward": [[32, 36], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "result", "=", "[", "self", ".", "cnt", "]", "\n", "self", ".", "cnt", "+=", "1", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.Model.train_step": [[40, 42], ["None"], "methods", ["None"], ["    ", "def", "train_step", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.Model.val_step": [[43, 45], ["None"], "methods", ["None"], ["", "def", "val_step", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.ExampleDataset.__init__": [[49, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "index", "=", "0", "\n", "self", ".", "eval_result", "=", "[", "1", ",", "4", ",", "3", ",", "7", ",", "2", ",", "-", "3", ",", "4", ",", "6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.ExampleDataset.__getitem__": [[53, 56], ["dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "results", "=", "dict", "(", "imgs", "=", "torch", ".", "tensor", "(", "[", "1", "]", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.ExampleDataset.__len__": [[57, 59], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "eval_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.test_single_gpu_test": [[61, 68], ["test_apis_test.ExampleDataset", "torch.utils.data.DataLoader", "test_apis_test.Model", "single_gpu_test", "list", "range"], "function", ["None"], ["", "", "def", "test_single_gpu_test", "(", ")", ":", "\n", "    ", "test_dataset", "=", "ExampleDataset", "(", ")", "\n", "loader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "1", ")", "\n", "model", "=", "Model", "(", ")", "\n", "\n", "results", "=", "single_gpu_test", "(", "model", ",", "loader", ")", "\n", "assert", "results", "==", "list", "(", "range", "(", "8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.mock_tensor_without_cuda": [[70, 74], ["torch.IntTensor", "torch.IntTensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "def", "mock_tensor_without_cuda", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "'device'", "not", "in", "kwargs", ":", "\n", "        ", "return", "torch", ".", "Tensor", "(", "*", "args", ")", "\n", "", "return", "torch", ".", "IntTensor", "(", "*", "args", ",", "device", "=", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.test_multi_gpu_test": [[76, 90], ["unittest.mock.patch", "unittest.mock.patch", "test_apis_test.ExampleDataset", "torch.utils.data.DataLoader", "test_apis_test.Model", "multi_gpu_test", "multi_gpu_test", "unittest.mock.Mock", "unittest.mock.Mock", "list", "list", "range", "range", "list", "list", "range", "range"], "function", ["None"], ["", "@", "patch", "(", "'mmaction.apis.test.collect_results_gpu'", ",", "\n", "Mock", "(", "return_value", "=", "list", "(", "range", "(", "8", ")", ")", ")", ")", "\n", "@", "patch", "(", "'mmaction.apis.test.collect_results_cpu'", ",", "\n", "Mock", "(", "return_value", "=", "list", "(", "range", "(", "8", ")", ")", ")", ")", "\n", "def", "test_multi_gpu_test", "(", ")", ":", "\n", "    ", "test_dataset", "=", "ExampleDataset", "(", ")", "\n", "loader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "1", ")", "\n", "model", "=", "Model", "(", ")", "\n", "\n", "results", "=", "multi_gpu_test", "(", "model", ",", "loader", ")", "\n", "assert", "results", "==", "list", "(", "range", "(", "8", ")", ")", "\n", "\n", "results", "=", "multi_gpu_test", "(", "model", ",", "loader", ",", "gpu_collect", "=", "False", ")", "\n", "assert", "results", "==", "list", "(", "range", "(", "8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_apis_test.test_collect_results_cpu": [[92, 119], ["unittest.mock.patch", "unittest.mock.patch", "unittest.mock.patch", "pytest.mark.skipif", "unittest.mock.Mock", "list", "collect_results_cpu", "collect_results_cpu", "torch.cuda.is_available", "torch.cuda.is_available", "test_apis_test.test_collect_results_cpu.content_for_unittest"], "function", ["None"], ["", "@", "patch", "(", "'mmcv.runner.get_dist_info'", ",", "Mock", "(", "return_value", "=", "(", "0", ",", "1", ")", ")", ")", "\n", "@", "patch", "(", "'torch.distributed.broadcast'", ",", "MagicMock", ")", "\n", "@", "patch", "(", "'torch.distributed.barrier'", ",", "Mock", ")", "\n", "@", "pytest", ".", "mark", ".", "skipif", "(", "\n", "sys", ".", "version_info", "[", ":", "2", "]", "==", "(", "3", ",", "8", ")", ",", "reason", "=", "'Not for python 3.8'", ")", "\n", "def", "test_collect_results_cpu", "(", ")", ":", "\n", "\n", "    ", "def", "content_for_unittest", "(", ")", ":", "\n", "        ", "results_part", "=", "list", "(", "range", "(", "8", ")", ")", "\n", "size", "=", "8", "\n", "\n", "results", "=", "collect_results_cpu", "(", "results_part", ",", "size", ")", "\n", "assert", "results", "==", "list", "(", "range", "(", "8", ")", ")", "\n", "\n", "results", "=", "collect_results_cpu", "(", "results_part", ",", "size", ",", "'unittest'", ")", "\n", "assert", "results", "==", "list", "(", "range", "(", "8", ")", ")", "\n", "\n", "", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "with", "patch", "(", "\n", "'torch.full'", ",", "\n", "Mock", "(", "\n", "return_value", "=", "torch", ".", "full", "(", "\n", "(", "512", ",", ")", ",", "32", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "'cpu'", ")", ")", ")", ":", "\n", "            ", "with", "patch", "(", "'torch.tensor'", ",", "mock_tensor_without_cuda", ")", ":", "\n", "                ", "content_for_unittest", "(", ")", "\n", "", "", "", "else", ":", "\n", "        ", "content_for_unittest", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_inference.test_init_recognizer": [[17, 46], ["torch.cuda.is_available", "torch.cuda.is_available", "mmaction.apis.init_recognizer", "mmcv.Config.fromfile", "isinstance", "torch.cuda.is_available", "torch.cuda.is_available", "pytest.raises", "mmaction.apis.init_recognizer", "pytest.raises", "mmaction.apis.init_recognizer", "pytest.raises", "mmaction.apis.init_recognizer", "dict", "next", "next", "mmaction.apis.init_recognizer.parameters", "mmaction.apis.init_recognizer.parameters"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer"], ["def", "test_init_recognizer", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# config must be a filename or Config object", "\n", "        ", "init_recognizer", "(", "dict", "(", "config_file", "=", "None", ")", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# input data type should be consist with the dataset type", "\n", "        ", "init_recognizer", "(", "frame_config_file", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# input data type should be consist with the dataset type", "\n", "        ", "init_recognizer", "(", "video_config_file", ",", "use_frames", "=", "True", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "'cuda:0'", "\n", "", "else", ":", "\n", "        ", "device", "=", "'cpu'", "\n", "\n", "", "model", "=", "init_recognizer", "(", "video_config_file", ",", "None", ",", "device", ")", "\n", "\n", "config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "video_config_file", ")", "\n", "config", ".", "model", ".", "backbone", ".", "pretrained", "=", "None", "\n", "\n", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "assert", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", "is", "True", "\n", "", "else", ":", "\n", "        ", "assert", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", "is", "False", "\n", "", "assert", "model", ".", "cfg", ".", "model", ".", "backbone", ".", "pretrained", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_inference.test_video_inference_recognizer": [[48, 119], ["torch.cuda.is_available", "torch.cuda.is_available", "mmaction.apis.init_recognizer", "mmaction.apis.inference_recognizer", "mmaction.apis.inference_recognizer", "isinstance", "isinstance", "isinstance", "mmaction.apis.inference_recognizer", "isinstance", "isinstance", "mmaction.apis.init_recognizer", "mmaction.apis.inference_recognizer", "isinstance", "isinstance", "pytest.raises", "mmaction.apis.inference_recognizer", "pytest.raises", "mmaction.apis.inference_recognizer", "pytest.raises", "mmaction.apis.inference_recognizer", "len", "sorted", "feat[].size", "feat[].size", "isinstance", "isinstance", "len", "[].size", "[].size", "feat[].size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer"], ["", "def", "test_video_inference_recognizer", "(", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "'cuda:0'", "\n", "", "else", ":", "\n", "        ", "device", "=", "'cpu'", "\n", "", "model", "=", "init_recognizer", "(", "video_config_file", ",", "None", ",", "device", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# video path doesn't exist", "\n", "        ", "inference_recognizer", "(", "model", ",", "'missing.mp4'", ",", "label_path", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# ``video_path`` should be consist with the ``use_frames``", "\n", "        ", "inference_recognizer", "(", "model", ",", "video_path", ",", "label_path", ",", "use_frames", "=", "True", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# ``video_path`` should be consist with the ``use_frames``", "\n", "        ", "inference_recognizer", "(", "model", ",", "'demo/'", ",", "label_path", ")", "\n", "\n", "", "for", "ops", "in", "model", ".", "cfg", ".", "data", ".", "test", ".", "pipeline", ":", "\n", "        ", "if", "ops", "[", "'type'", "]", "in", "(", "'TenCrop'", ",", "'ThreeCrop'", ")", ":", "\n", "# Use CenterCrop to reduce memory in order to pass CI", "\n", "            ", "ops", "[", "'type'", "]", "=", "'CenterCrop'", "\n", "\n", "", "", "top5_label", "=", "inference_recognizer", "(", "model", ",", "video_path", ",", "label_path", ")", "\n", "scores", "=", "[", "item", "[", "1", "]", "for", "item", "in", "top5_label", "]", "\n", "assert", "len", "(", "top5_label", ")", "==", "5", "\n", "assert", "scores", "==", "sorted", "(", "scores", ",", "reverse", "=", "True", ")", "\n", "\n", "_", ",", "feat", "=", "inference_recognizer", "(", "\n", "model", ",", "\n", "video_path", ",", "\n", "label_path", ",", "\n", "outputs", "=", "(", "'backbone'", ",", "'cls_head'", ")", ",", "\n", "as_tensor", "=", "False", ")", "\n", "assert", "isinstance", "(", "feat", ",", "dict", ")", "\n", "assert", "'backbone'", "in", "feat", "and", "'cls_head'", "in", "feat", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone'", "]", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "feat", "[", "'cls_head'", "]", ",", "np", ".", "ndarray", ")", "\n", "assert", "feat", "[", "'backbone'", "]", ".", "shape", "==", "(", "25", ",", "2048", ",", "7", ",", "7", ")", "\n", "assert", "feat", "[", "'cls_head'", "]", ".", "shape", "==", "(", "1", ",", "400", ")", "\n", "\n", "_", ",", "feat", "=", "inference_recognizer", "(", "\n", "model", ",", "\n", "video_path", ",", "\n", "label_path", ",", "\n", "outputs", "=", "(", "'backbone.layer3'", ",", "'backbone.layer3.1.conv1'", ")", ")", "\n", "assert", "'backbone.layer3.1.conv1'", "in", "feat", "and", "'backbone.layer3'", "in", "feat", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone.layer3.1.conv1'", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone.layer3'", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "feat", "[", "'backbone.layer3'", "]", ".", "size", "(", ")", "==", "(", "25", ",", "1024", ",", "14", ",", "14", ")", "\n", "assert", "feat", "[", "'backbone.layer3.1.conv1'", "]", ".", "size", "(", ")", "==", "(", "25", ",", "256", ",", "14", ",", "14", ")", "\n", "\n", "cfg_file", "=", "'configs/recognition/slowfast/slowfast_r50_video_inference_4x16x1_256e_kinetics400_rgb.py'", "# noqa: E501", "\n", "sf_model", "=", "init_recognizer", "(", "cfg_file", ",", "None", ",", "device", ")", "\n", "for", "ops", "in", "sf_model", ".", "cfg", ".", "data", ".", "test", ".", "pipeline", ":", "\n", "# Changes to reduce memory in order to pass CI", "\n", "        ", "if", "ops", "[", "'type'", "]", "in", "(", "'TenCrop'", ",", "'ThreeCrop'", ")", ":", "\n", "            ", "ops", "[", "'type'", "]", "=", "'CenterCrop'", "\n", "", "if", "ops", "[", "'type'", "]", "==", "'SampleFrames'", ":", "\n", "            ", "ops", "[", "'num_clips'", "]", "=", "1", "\n", "", "", "_", ",", "feat", "=", "inference_recognizer", "(", "\n", "sf_model", ",", "video_path", ",", "label_path", ",", "outputs", "=", "(", "'backbone'", ",", "'cls_head'", ")", ")", "\n", "assert", "isinstance", "(", "feat", ",", "dict", ")", "and", "isinstance", "(", "feat", "[", "'backbone'", "]", ",", "tuple", ")", "\n", "assert", "'backbone'", "in", "feat", "and", "'cls_head'", "in", "feat", "\n", "assert", "len", "(", "feat", "[", "'backbone'", "]", ")", "==", "2", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone'", "]", "[", "0", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone'", "]", "[", "1", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "feat", "[", "'backbone'", "]", "[", "0", "]", ".", "size", "(", ")", "==", "(", "1", ",", "2048", ",", "4", ",", "8", ",", "8", ")", "\n", "assert", "feat", "[", "'backbone'", "]", "[", "1", "]", ".", "size", "(", ")", "==", "(", "1", ",", "256", ",", "32", ",", "8", ",", "8", ")", "\n", "assert", "feat", "[", "'cls_head'", "]", ".", "size", "(", ")", "==", "(", "1", ",", "400", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_inference.test_frames_inference_recognizer": [[121, 182], ["torch.cuda.is_available", "torch.cuda.is_available", "mmaction.apis.init_recognizer", "mmaction.apis.init_recognizer", "mmaction.apis.inference_recognizer", "mmaction.apis.inference_recognizer", "isinstance", "isinstance", "isinstance", "mmaction.apis.inference_recognizer", "isinstance", "isinstance", "pytest.raises", "mmaction.apis.inference_recognizer", "pytest.raises", "mmaction.apis.inference_recognizer", "len", "sorted", "feat[].size", "feat[].size"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.init_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.apis.inference.inference_recognizer"], ["", "def", "test_frames_inference_recognizer", "(", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "'cuda:0'", "\n", "", "else", ":", "\n", "        ", "device", "=", "'cpu'", "\n", "", "rgb_model", "=", "init_recognizer", "(", "\n", "frame_config_file", ",", "None", ",", "device", ",", "use_frames", "=", "True", ")", "\n", "flow_model", "=", "init_recognizer", "(", "\n", "flow_frame_config_file", ",", "None", ",", "device", ",", "use_frames", "=", "True", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# video path doesn't exist", "\n", "        ", "inference_recognizer", "(", "rgb_model", ",", "'missing_path'", ",", "label_path", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "# ``video_path`` should be consist with the ``use_frames``", "\n", "        ", "inference_recognizer", "(", "\n", "flow_model", ",", "frames_path", ",", "label_path", ",", "use_frames", "=", "False", ")", "\n", "\n", "", "for", "ops", "in", "rgb_model", ".", "cfg", ".", "data", ".", "test", ".", "pipeline", ":", "\n", "        ", "if", "ops", "[", "'type'", "]", "in", "(", "'TenCrop'", ",", "'ThreeCrop'", ")", ":", "\n", "# Use CenterCrop to reduce memory in order to pass CI", "\n", "            ", "ops", "[", "'type'", "]", "=", "'CenterCrop'", "\n", "ops", "[", "'crop_size'", "]", "=", "224", "\n", "", "", "for", "ops", "in", "flow_model", ".", "cfg", ".", "data", ".", "test", ".", "pipeline", ":", "\n", "        ", "if", "ops", "[", "'type'", "]", "in", "(", "'TenCrop'", ",", "'ThreeCrop'", ")", ":", "\n", "# Use CenterCrop to reduce memory in order to pass CI", "\n", "            ", "ops", "[", "'type'", "]", "=", "'CenterCrop'", "\n", "ops", "[", "'crop_size'", "]", "=", "224", "\n", "\n", "", "", "top5_label", "=", "inference_recognizer", "(", "\n", "rgb_model", ",", "frames_path", ",", "label_path", ",", "use_frames", "=", "True", ")", "\n", "scores", "=", "[", "item", "[", "1", "]", "for", "item", "in", "top5_label", "]", "\n", "assert", "len", "(", "top5_label", ")", "==", "5", "\n", "assert", "scores", "==", "sorted", "(", "scores", ",", "reverse", "=", "True", ")", "\n", "\n", "_", ",", "feat", "=", "inference_recognizer", "(", "\n", "flow_model", ",", "\n", "frames_path", ",", "\n", "label_path", ",", "\n", "outputs", "=", "(", "'backbone'", ",", "'cls_head'", ")", ",", "\n", "as_tensor", "=", "False", ",", "\n", "use_frames", "=", "True", ")", "\n", "assert", "isinstance", "(", "feat", ",", "dict", ")", "\n", "assert", "'backbone'", "in", "feat", "and", "'cls_head'", "in", "feat", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone'", "]", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "feat", "[", "'cls_head'", "]", ",", "np", ".", "ndarray", ")", "\n", "assert", "feat", "[", "'backbone'", "]", ".", "shape", "==", "(", "25", ",", "2048", ",", "7", ",", "7", ")", "\n", "assert", "feat", "[", "'cls_head'", "]", ".", "shape", "==", "(", "1", ",", "400", ")", "\n", "\n", "_", ",", "feat", "=", "inference_recognizer", "(", "\n", "rgb_model", ",", "\n", "frames_path", ",", "\n", "label_path", ",", "\n", "use_frames", "=", "True", ",", "\n", "outputs", "=", "(", "'backbone.layer3'", ",", "'backbone.layer3.1.conv1'", ")", ")", "\n", "assert", "'backbone.layer3.1.conv1'", "in", "feat", "and", "'backbone.layer3'", "in", "feat", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone.layer3.1.conv1'", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "isinstance", "(", "feat", "[", "'backbone.layer3'", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "feat", "[", "'backbone.layer3'", "]", ".", "size", "(", ")", "==", "(", "25", ",", "1024", ",", "14", ",", "14", ")", "\n", "assert", "feat", "[", "'backbone.layer3.1.conv1'", "]", ".", "size", "(", ")", "==", "(", "25", ",", "256", ",", "14", ",", "14", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleDataset.__init__": [[17, 19], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "index", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleDataset.__getitem__": [[20, 23], ["dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "results", "=", "dict", "(", "imgs", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleDataset.__len__": [[24, 26], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.BiggerDataset.__init__": [[30, 33], ["range", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fixed_values", "=", "range", "(", "0", ",", "12", ")", ")", ":", "\n", "        ", "assert", "len", "(", "self", ")", "==", "len", "(", "fixed_values", ")", "\n", "self", ".", "fixed_values", "=", "fixed_values", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.BiggerDataset.__getitem__": [[34, 38], ["dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "results", "=", "dict", "(", "\n", "imgs", "=", "torch", ".", "tensor", "(", "[", "self", ".", "fixed_values", "[", "idx", "]", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.BiggerDataset.__len__": [[39, 42], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# a bigger dataset", "\n", "        ", "return", "12", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleModel.__init__": [[46, 51], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Linear", "(", "1", ",", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "1", ")", "\n", "self", ".", "test_cfg", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleModel.forward": [[52, 54], ["test_precise_bn.ExampleModel.bn", "test_precise_bn.ExampleModel.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "imgs", ",", "return_loss", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "bn", "(", "self", ".", "conv", "(", "imgs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.ExampleModel.train_step": [[55, 65], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "train_step", "(", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "{", "\n", "'loss'", ":", "0.5", ",", "\n", "'log_vars'", ":", "{", "\n", "'accuracy'", ":", "0.98", "\n", "}", ",", "\n", "'num_samples'", ":", "1", "\n", "}", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.SingleBNModel.__init__": [[69, 73], ["test_precise_bn.ExampleModel.__init__", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "1", ")", "\n", "self", ".", "test_cfg", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.SingleBNModel.forward": [[74, 76], ["test_precise_bn.SingleBNModel.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "imgs", ",", "return_loss", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "bn", "(", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.GNExampleModel.__init__": [[80, 85], ["test_precise_bn.ExampleModel.__init__", "torch.Linear", "torch.Linear", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Linear", "(", "1", ",", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "GroupNorm", "(", "1", ",", "1", ")", "\n", "self", ".", "test_cfg", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__": [[89, 93], ["test_precise_bn.ExampleModel.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Linear", "(", "1", ",", "1", ")", "\n", "self", ".", "test_cfg", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.NoBNExampleModel.forward": [[94, 96], ["test_precise_bn.NoBNExampleModel.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "imgs", ",", "return_loss", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "conv", "(", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_precise_bn.test_precise_bn": [[98, 205], ["dict", "test_precise_bn.ExampleDataset", "torch.utils.data.DataLoader", "test_precise_bn.ExampleModel", "mmcv.runner.build_optimizer", "torch.utils.data.DataLoader", "copy.deepcopy", "mmcv.utils.get_logger", "mmcv.runner.EpochBasedRunner", "test_precise_bn.BiggerDataset", "torch.utils.data.DataLoader", "mmaction.utils.PreciseBNHook", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "torch.utils.data.DataLoader", "mmaction.utils.PreciseBNHook", "test_precise_bn.GNExampleModel", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "torch.utils.data.DataLoader", "mmaction.utils.PreciseBNHook", "test_precise_bn.NoBNExampleModel", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "torch.utils.data.DataLoader", "mmaction.utils.PreciseBNHook", "test_precise_bn.SingleBNModel", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "list", "enumerate", "numpy.mean", "numpy.mean", "numpy.equal", "numpy.equal", "pytest.mark.skipif", "pytest.raises", "test_precise_bn.ExampleModel", "torch.utils.data.DataLoader", "mmaction.utils.PreciseBNHook", "pytest.raises", "mmaction.utils.PreciseBNHook", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "list.append", "numpy.array", "numpy.array", "test_precise_bn.BiggerDataset", "torch.utils.data.DataLoader", "mmaction.utils.PreciseBNHook", "test_precise_bn.ExampleModel", "mmcv.parallel.MMDistributedDataParallel", "mmcv.runner.EpochBasedRunner", "mmcv.runner.EpochBasedRunner.register_hook", "mmcv.runner.EpochBasedRunner.run", "numpy.array", "numpy.mean", "numpy.var", "mmcv.parallel.MMDistributedDataParallel.cuda", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.current_device", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.runner.omnisource_runner.OmniSourceRunner.run"], ["", "", "def", "test_precise_bn", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# `data_loader` must be a Pytorch DataLoader", "\n", "        ", "test_dataset", "=", "ExampleModel", "(", ")", "\n", "data_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "\n", "batch_size", "=", "2", ",", "\n", "sampler", "=", "None", ",", "\n", "num_workers", "=", "0", ",", "\n", "shuffle", "=", "False", ")", "\n", "PreciseBNHook", "(", "'data_loader'", ")", "\n", "\n", "", "optimizer_cfg", "=", "dict", "(", "\n", "type", "=", "'SGD'", ",", "lr", "=", "0.01", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "0.0001", ")", "\n", "\n", "test_dataset", "=", "ExampleDataset", "(", ")", "\n", "loader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "2", ")", "\n", "model", "=", "ExampleModel", "(", ")", "\n", "optimizer", "=", "build_optimizer", "(", "model", ",", "optimizer_cfg", ")", "\n", "\n", "data_loader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "2", ")", "\n", "precise_bn_loader", "=", "copy", ".", "deepcopy", "(", "data_loader", ")", "\n", "logger", "=", "get_logger", "(", "'precise_bn'", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "batch_processor", "=", "None", ",", "optimizer", "=", "optimizer", ",", "logger", "=", "logger", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "# num_iters should be no larget than total", "\n", "# iters", "\n", "        ", "precise_bn_hook", "=", "PreciseBNHook", "(", "precise_bn_loader", ",", "num_iters", "=", "5", ")", "\n", "runner", ".", "register_hook", "(", "precise_bn_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "\n", "# test non-DDP model", "\n", "", "test_bigger_dataset", "=", "BiggerDataset", "(", ")", "\n", "loader", "=", "DataLoader", "(", "test_bigger_dataset", ",", "batch_size", "=", "2", ")", "\n", "precise_bn_hook", "=", "PreciseBNHook", "(", "loader", ",", "num_iters", "=", "5", ")", "\n", "assert", "precise_bn_hook", ".", "num_iters", "==", "5", "\n", "assert", "precise_bn_hook", ".", "interval", "==", "1", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "batch_processor", "=", "None", ",", "optimizer", "=", "optimizer", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_hook", "(", "precise_bn_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "\n", "# test model w/ gn layer", "\n", "loader", "=", "DataLoader", "(", "test_bigger_dataset", ",", "batch_size", "=", "2", ")", "\n", "precise_bn_hook", "=", "PreciseBNHook", "(", "loader", ",", "num_iters", "=", "5", ")", "\n", "assert", "precise_bn_hook", ".", "num_iters", "==", "5", "\n", "assert", "precise_bn_hook", ".", "interval", "==", "1", "\n", "model", "=", "GNExampleModel", "(", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "batch_processor", "=", "None", ",", "optimizer", "=", "optimizer", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_hook", "(", "precise_bn_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "\n", "# test model without bn layer", "\n", "loader", "=", "DataLoader", "(", "test_bigger_dataset", ",", "batch_size", "=", "2", ")", "\n", "precise_bn_hook", "=", "PreciseBNHook", "(", "loader", ",", "num_iters", "=", "5", ")", "\n", "assert", "precise_bn_hook", ".", "num_iters", "==", "5", "\n", "assert", "precise_bn_hook", ".", "interval", "==", "1", "\n", "model", "=", "NoBNExampleModel", "(", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "batch_processor", "=", "None", ",", "optimizer", "=", "optimizer", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_hook", "(", "precise_bn_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "\n", "# test how precise it is", "\n", "loader", "=", "DataLoader", "(", "test_bigger_dataset", ",", "batch_size", "=", "2", ")", "\n", "precise_bn_hook", "=", "PreciseBNHook", "(", "loader", ",", "num_iters", "=", "6", ")", "# run all", "\n", "assert", "precise_bn_hook", ".", "num_iters", "==", "6", "\n", "assert", "precise_bn_hook", ".", "interval", "==", "1", "\n", "model", "=", "SingleBNModel", "(", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "batch_processor", "=", "None", ",", "optimizer", "=", "optimizer", ",", "logger", "=", "logger", ")", "\n", "runner", ".", "register_hook", "(", "precise_bn_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "imgs_list", "=", "list", "(", ")", "\n", "for", "_", ",", "data", "in", "enumerate", "(", "loader", ")", ":", "\n", "        ", "imgs_list", ".", "append", "(", "np", ".", "array", "(", "data", "[", "'imgs'", "]", ")", ")", "\n", "", "mean", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "batch", ")", "for", "batch", "in", "imgs_list", "]", ")", "\n", "# bassel correction used in Pytorch, therefore ddof=1", "\n", "var", "=", "np", ".", "mean", "(", "[", "np", ".", "var", "(", "batch", ",", "ddof", "=", "1", ")", "for", "batch", "in", "imgs_list", "]", ")", "\n", "assert", "np", ".", "equal", "(", "mean", ",", "np", ".", "array", "(", "model", ".", "bn", ".", "running_mean", ")", ")", "\n", "assert", "np", ".", "equal", "(", "var", ",", "np", ".", "array", "(", "model", ".", "bn", ".", "running_var", ")", ")", "\n", "\n", "@", "pytest", ".", "mark", ".", "skipif", "(", "\n", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "reason", "=", "'requires CUDA support'", ")", "\n", "def", "test_ddp_model_precise_bn", "(", ")", ":", "\n", "# test DDP model", "\n", "        ", "test_bigger_dataset", "=", "BiggerDataset", "(", ")", "\n", "loader", "=", "DataLoader", "(", "test_bigger_dataset", ",", "batch_size", "=", "2", ")", "\n", "precise_bn_hook", "=", "PreciseBNHook", "(", "loader", ",", "num_iters", "=", "5", ")", "\n", "assert", "precise_bn_hook", ".", "num_iters", "==", "5", "\n", "assert", "precise_bn_hook", ".", "interval", "==", "1", "\n", "model", "=", "ExampleModel", "(", ")", "\n", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "runner", "=", "EpochBasedRunner", "(", "\n", "model", "=", "model", ",", "\n", "batch_processor", "=", "None", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "logger", "=", "logger", ")", "\n", "runner", ".", "register_hook", "(", "precise_bn_hook", ")", "\n", "runner", ".", "run", "(", "[", "loader", "]", ",", "[", "(", "'train'", ",", "1", ")", "]", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.gt_confusion_matrix": [[16, 51], ["max", "numpy.zeros", "zip", "range", "numpy.delete", "numpy.delete", "max", "max", "numpy.array", "range", "del_index.append", "numpy.sum", "print", "range", "sum", "sum", "sum", "numpy.sum"], "function", ["None"], ["def", "gt_confusion_matrix", "(", "gt_labels", ",", "pred_labels", ",", "normalize", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the ground truth confusion matrix.\"\"\"", "\n", "max_index", "=", "max", "(", "max", "(", "gt_labels", ")", ",", "max", "(", "pred_labels", ")", ")", "\n", "confusion_mat", "=", "np", ".", "zeros", "(", "(", "max_index", "+", "1", ",", "max_index", "+", "1", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "gt", ",", "pred", "in", "zip", "(", "gt_labels", ",", "pred_labels", ")", ":", "\n", "        ", "confusion_mat", "[", "gt", "]", "[", "pred", "]", "+=", "1", "\n", "", "del_index", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max_index", ")", ":", "\n", "        ", "if", "sum", "(", "confusion_mat", "[", "i", "]", ")", "==", "0", "and", "sum", "(", "confusion_mat", "[", ":", ",", "i", "]", ")", "==", "0", ":", "\n", "            ", "del_index", ".", "append", "(", "i", ")", "\n", "", "", "confusion_mat", "=", "np", ".", "delete", "(", "confusion_mat", ",", "del_index", ",", "axis", "=", "0", ")", "\n", "confusion_mat", "=", "np", ".", "delete", "(", "confusion_mat", ",", "del_index", ",", "axis", "=", "1", ")", "\n", "\n", "if", "normalize", "is", "not", "None", ":", "\n", "        ", "confusion_mat", "=", "np", ".", "array", "(", "confusion_mat", ",", "dtype", "=", "np", ".", "float", ")", "\n", "", "m", ",", "n", "=", "confusion_mat", ".", "shape", "\n", "if", "normalize", "==", "'true'", ":", "\n", "        ", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "            ", "s", "=", "np", ".", "sum", "(", "confusion_mat", "[", "i", "]", ",", "dtype", "=", "float", ")", "\n", "if", "s", "==", "0", ":", "\n", "                ", "continue", "\n", "", "confusion_mat", "[", "i", ",", ":", "]", "=", "confusion_mat", "[", "i", ",", ":", "]", "/", "s", "\n", "print", "(", "confusion_mat", "[", "i", ",", ":", "]", ")", "\n", "", "", "elif", "normalize", "==", "'pred'", ":", "\n", "        ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "s", "=", "sum", "(", "confusion_mat", "[", ":", ",", "i", "]", ")", "\n", "if", "s", "==", "0", ":", "\n", "                ", "continue", "\n", "", "confusion_mat", "[", ":", ",", "i", "]", "=", "confusion_mat", "[", ":", ",", "i", "]", "/", "s", "\n", "", "", "elif", "normalize", "==", "'all'", ":", "\n", "        ", "s", "=", "np", ".", "sum", "(", "confusion_mat", ")", "\n", "if", "s", "!=", "0", ":", "\n", "            ", "confusion_mat", "/=", "s", "\n", "\n", "", "", "return", "confusion_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_activitynet_localization": [[53, 70], ["os.normpath", "os.join", "os.join", "mmaction.core.ActivityNetLocalization", "mmaction.core.ActivityNetLocalization.evaluate", "numpy.array", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "os.join", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_runtime.test_train.ExampleDataset.evaluate", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_activitynet_localization", "(", ")", ":", "\n", "    ", "data_prefix", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/eval_localization'", ")", ")", "\n", "\n", "gt_path", "=", "osp", ".", "join", "(", "data_prefix", ",", "'gt.json'", ")", "\n", "result_path", "=", "osp", ".", "join", "(", "data_prefix", ",", "'result.json'", ")", "\n", "localization", "=", "ActivityNetLocalization", "(", "gt_path", ",", "result_path", ")", "\n", "\n", "results", "=", "localization", ".", "evaluate", "(", ")", "\n", "mAP", "=", "np", ".", "array", "(", "[", "\n", "0.71428571", ",", "0.71428571", ",", "0.71428571", ",", "0.6875", ",", "0.6875", ",", "0.59722222", ",", "\n", "0.52083333", ",", "0.52083333", ",", "0.52083333", ",", "0.5", "\n", "]", ")", "\n", "average_mAP", "=", "0.6177579365079365", "\n", "\n", "assert_array_almost_equal", "(", "results", "[", "0", "]", ",", "mAP", ")", "\n", "assert_array_almost_equal", "(", "results", "[", "1", "]", ",", "average_mAP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_ava_detection": [[72, 83], ["os.normpath", "os.join", "os.join", "os.join", "mmaction.core.evaluation.ava_utils.ava_eval", "numpy.testing.assert_array_almost_equal", "os.join", "os.dirname"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.ava_utils.ava_eval", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.demo.webcam_demo_spatiotemporal_det.ClipHelper.join"], ["", "def", "test_ava_detection", "(", ")", ":", "\n", "    ", "data_prefix", "=", "osp", ".", "normpath", "(", "\n", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "__file__", ")", ",", "'../data/eval_detection'", ")", ")", "\n", "\n", "gt_path", "=", "osp", ".", "join", "(", "data_prefix", ",", "'gt.csv'", ")", "\n", "result_path", "=", "osp", ".", "join", "(", "data_prefix", ",", "'pred.csv'", ")", "\n", "label_map", "=", "osp", ".", "join", "(", "data_prefix", ",", "'action_list.txt'", ")", "\n", "\n", "# eval bbox", "\n", "detection", "=", "ava_eval", "(", "result_path", ",", "'mAP'", ",", "label_map", ",", "gt_path", ",", "None", ")", "\n", "assert_array_almost_equal", "(", "detection", "[", "'mAP@0.5IOU'", "]", ",", "0.09385522", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_confusion_matrix": [[85, 114], ["numpy.random.randint", "numpy.int64", "mmaction.core.confusion_matrix", "test_accuracy.gt_confusion_matrix", "numpy.testing.assert_array_equal", "pytest.raises", "mmaction.core.confusion_matrix", "pytest.raises", "mmaction.core.confusion_matrix", "pytest.raises", "mmaction.core.confusion_matrix", "pytest.raises", "mmaction.core.confusion_matrix", "pytest.raises", "mmaction.core.confusion_matrix", "random.randint", "range"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.gt_confusion_matrix", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.confusion_matrix"], ["", "def", "test_confusion_matrix", "(", ")", ":", "\n", "# custom confusion_matrix", "\n", "    ", "gt_labels", "=", "[", "np", ".", "int64", "(", "random", ".", "randint", "(", "0", ",", "9", ")", ")", "for", "_", "in", "range", "(", "100", ")", "]", "\n", "pred_labels", "=", "np", ".", "random", ".", "randint", "(", "10", ",", "size", "=", "100", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "normalize", "in", "[", "None", ",", "'true'", ",", "'pred'", ",", "'all'", "]", ":", "\n", "        ", "cf_mat", "=", "confusion_matrix", "(", "pred_labels", ",", "gt_labels", ",", "normalize", ")", "\n", "gt_cf_mat", "=", "gt_confusion_matrix", "(", "gt_labels", ",", "pred_labels", ",", "normalize", ")", "\n", "assert_array_equal", "(", "cf_mat", ",", "gt_cf_mat", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# normalize must be in ['true', 'pred', 'all', None]", "\n", "        ", "confusion_matrix", "(", "[", "1", "]", ",", "[", "1", "]", ",", "'unsupport'", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# y_pred must be list or np.ndarray", "\n", "        ", "confusion_matrix", "(", "0.5", ",", "[", "1", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# y_real must be list or np.ndarray", "\n", "        ", "confusion_matrix", "(", "[", "1", "]", ",", "0.5", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# y_pred dtype must be np.int64", "\n", "        ", "confusion_matrix", "(", "[", "0.5", "]", ",", "[", "1", "]", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "# y_real dtype must be np.int64", "\n", "        ", "confusion_matrix", "(", "[", "1", "]", ",", "[", "0.5", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_topk": [[116, 162], ["mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "mmaction.core.top_k_accuracy", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.top_k_accuracy"], ["", "", "def", "test_topk", "(", ")", ":", "\n", "    ", "scores", "=", "[", "\n", "np", ".", "array", "(", "[", "-", "0.2203", ",", "-", "0.7538", ",", "1.8789", ",", "0.4451", ",", "-", "0.2526", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "-", "0.0413", ",", "0.6366", ",", "1.1155", ",", "0.3484", ",", "0.0395", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0365", ",", "0.5158", ",", "1.1067", ",", "-", "0.9276", ",", "-", "0.2124", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.6232", ",", "0.9912", ",", "-", "0.8562", ",", "0.0148", ",", "1.6413", "]", ")", "\n", "]", "\n", "\n", "# top1 acc", "\n", "k", "=", "(", "1", ",", ")", "\n", "top1_labels_0", "=", "[", "3", ",", "1", ",", "1", ",", "1", "]", "\n", "top1_labels_25", "=", "[", "2", ",", "0", ",", "4", ",", "3", "]", "\n", "top1_labels_50", "=", "[", "2", ",", "2", ",", "3", ",", "1", "]", "\n", "top1_labels_75", "=", "[", "2", ",", "2", ",", "2", ",", "3", "]", "\n", "top1_labels_100", "=", "[", "2", ",", "2", ",", "2", ",", "4", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top1_labels_0", ",", "k", ")", "\n", "assert", "res", "==", "[", "0", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top1_labels_25", ",", "k", ")", "\n", "assert", "res", "==", "[", "0.25", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top1_labels_50", ",", "k", ")", "\n", "assert", "res", "==", "[", "0.5", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top1_labels_75", ",", "k", ")", "\n", "assert", "res", "==", "[", "0.75", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top1_labels_100", ",", "k", ")", "\n", "assert", "res", "==", "[", "1.0", "]", "\n", "\n", "# top1 acc, top2 acc", "\n", "k", "=", "(", "1", ",", "2", ")", "\n", "top2_labels_0_100", "=", "[", "3", ",", "1", ",", "1", ",", "1", "]", "\n", "top2_labels_25_75", "=", "[", "3", ",", "1", ",", "2", ",", "3", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top2_labels_0_100", ",", "k", ")", "\n", "assert", "res", "==", "[", "0", ",", "1.0", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top2_labels_25_75", ",", "k", ")", "\n", "assert", "res", "==", "[", "0.25", ",", "0.75", "]", "\n", "\n", "# top1 acc, top3 acc, top5 acc", "\n", "k", "=", "(", "1", ",", "3", ",", "5", ")", "\n", "top5_labels_0_0_100", "=", "[", "1", ",", "0", ",", "3", ",", "2", "]", "\n", "top5_labels_0_50_100", "=", "[", "1", ",", "3", ",", "4", ",", "0", "]", "\n", "top5_labels_25_75_100", "=", "[", "2", ",", "3", ",", "0", ",", "2", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top5_labels_0_0_100", ",", "k", ")", "\n", "assert", "res", "==", "[", "0", ",", "0", ",", "1.0", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top5_labels_0_50_100", ",", "k", ")", "\n", "assert", "res", "==", "[", "0", ",", "0.5", ",", "1.0", "]", "\n", "res", "=", "top_k_accuracy", "(", "scores", ",", "top5_labels_25_75_100", ",", "k", ")", "\n", "assert", "res", "==", "[", "0.25", ",", "0.75", ",", "1.0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_mean_class_accuracy": [[164, 183], ["numpy.int64", "numpy.int64", "numpy.int64", "numpy.int64", "numpy.int64", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "mmaction.core.mean_class_accuracy", "mmaction.core.mean_class_accuracy", "mmaction.core.mean_class_accuracy", "mmaction.core.mean_class_accuracy", "mmaction.core.mean_class_accuracy"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mean_class_accuracy"], ["", "def", "test_mean_class_accuracy", "(", ")", ":", "\n", "    ", "scores", "=", "[", "\n", "np", ".", "array", "(", "[", "-", "0.2203", ",", "-", "0.7538", ",", "1.8789", ",", "0.4451", ",", "-", "0.2526", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "-", "0.0413", ",", "0.6366", ",", "1.1155", ",", "0.3484", ",", "0.0395", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0365", ",", "0.5158", ",", "1.1067", ",", "-", "0.9276", ",", "-", "0.2124", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.6232", ",", "0.9912", ",", "-", "0.8562", ",", "0.0148", ",", "1.6413", "]", ")", "\n", "]", "\n", "\n", "# test mean class accuracy in [0, 0.25, 1/3, 0.75, 1.0]", "\n", "mean_cls_acc_0", "=", "np", ".", "int64", "(", "[", "1", ",", "4", ",", "0", ",", "2", "]", ")", "\n", "mean_cls_acc_25", "=", "np", ".", "int64", "(", "[", "2", ",", "0", ",", "4", ",", "3", "]", ")", "\n", "mean_cls_acc_33", "=", "np", ".", "int64", "(", "[", "2", ",", "2", ",", "2", ",", "3", "]", ")", "\n", "mean_cls_acc_75", "=", "np", ".", "int64", "(", "[", "4", ",", "2", ",", "2", ",", "4", "]", ")", "\n", "mean_cls_acc_100", "=", "np", ".", "int64", "(", "[", "2", ",", "2", ",", "2", ",", "4", "]", ")", "\n", "assert", "mean_class_accuracy", "(", "scores", ",", "mean_cls_acc_0", ")", "==", "0", "\n", "assert", "mean_class_accuracy", "(", "scores", ",", "mean_cls_acc_25", ")", "==", "0.25", "\n", "assert", "mean_class_accuracy", "(", "scores", ",", "mean_cls_acc_33", ")", "==", "1", "/", "3", "\n", "assert", "mean_class_accuracy", "(", "scores", ",", "mean_cls_acc_75", ")", "==", "0.75", "\n", "assert", "mean_class_accuracy", "(", "scores", ",", "mean_cls_acc_100", ")", "==", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_mmit_mean_average_precision": [[185, 195], ["mmaction.core.mmit_mean_average_precision", "numpy.array", "numpy.array", "numpy.sum", "numpy.diff", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.mmit_mean_average_precision"], ["", "def", "test_mmit_mean_average_precision", "(", ")", ":", "\n", "# One sample", "\n", "    ", "y_true", "=", "[", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ")", "]", "\n", "y_scores", "=", "[", "np", ".", "array", "(", "[", "0.1", ",", "0.4", ",", "0.35", ",", "0.8", "]", ")", "]", "\n", "map", "=", "mmit_mean_average_precision", "(", "y_scores", ",", "y_true", ")", "\n", "\n", "precision", "=", "[", "2.0", "/", "3.0", ",", "0.5", ",", "1.", ",", "1.", "]", "\n", "recall", "=", "[", "1.", ",", "0.5", ",", "0.5", ",", "0.", "]", "\n", "target", "=", "-", "np", ".", "sum", "(", "np", ".", "diff", "(", "recall", ")", "*", "np", ".", "array", "(", "precision", ")", "[", ":", "-", "1", "]", ")", "\n", "assert", "target", "==", "map", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_pairwise_temporal_iou": [[197, 222], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "mmaction.core.pairwise_temporal_iou", "numpy.testing.assert_array_equal", "numpy.array", "numpy.array", "mmaction.core.pairwise_temporal_iou", "numpy.testing.assert_array_equal", "numpy.array", "numpy.array", "mmaction.core.pairwise_temporal_iou", "numpy.testing.assert_array_equal", "pytest.raises", "mmaction.core.pairwise_temporal_iou"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.pairwise_temporal_iou"], ["", "def", "test_pairwise_temporal_iou", "(", ")", ":", "\n", "    ", "target_segments", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "candidate_segments", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "pairwise_temporal_iou", "(", "target_segments", ",", "candidate_segments", ")", "\n", "\n", "# test temporal iou", "\n", "", "target_segments", "=", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "2", ",", "3", "]", "]", ")", "\n", "candidate_segments", "=", "np", ".", "array", "(", "[", "[", "2", ",", "3", "]", ",", "[", "2.5", ",", "3", "]", "]", ")", "\n", "temporal_iou", "=", "pairwise_temporal_iou", "(", "candidate_segments", ",", "target_segments", ")", "\n", "assert_array_equal", "(", "temporal_iou", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0.5", "]", "]", ")", "\n", "\n", "# test temporal overlap_self", "\n", "target_segments", "=", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "2", ",", "3", "]", "]", ")", "\n", "candidate_segments", "=", "np", ".", "array", "(", "[", "[", "2", ",", "3", "]", ",", "[", "2.5", ",", "3", "]", "]", ")", "\n", "temporal_iou", ",", "temporal_overlap_self", "=", "pairwise_temporal_iou", "(", "\n", "candidate_segments", ",", "target_segments", ",", "calculate_overlap_self", "=", "True", ")", "\n", "assert_array_equal", "(", "temporal_overlap_self", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", "]", ")", "\n", "\n", "# test temporal overlap_self when candidate_segments is 1d", "\n", "target_segments", "=", "np", ".", "array", "(", "[", "[", "1", ",", "2", "]", ",", "[", "2", ",", "3", "]", "]", ")", "\n", "candidate_segments", "=", "np", ".", "array", "(", "[", "2.5", ",", "3", "]", ")", "\n", "temporal_iou", ",", "temporal_overlap_self", "=", "pairwise_temporal_iou", "(", "\n", "candidate_segments", ",", "target_segments", ",", "calculate_overlap_self", "=", "True", ")", "\n", "assert_array_equal", "(", "temporal_overlap_self", ",", "[", "0", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_average_recall_at_avg_proposals": [[224, 265], ["mmaction.core.average_recall_at_avg_proposals", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_almost_equal", "mmaction.core.average_recall_at_avg_proposals", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_almost_equal", "mmaction.core.average_recall_at_avg_proposals", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_equal", "numpy.testing.assert_array_almost_equal", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.arange", "numpy.arange", "numpy.arange", "range"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_recall_at_avg_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_recall_at_avg_proposals", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.average_recall_at_avg_proposals"], ["", "def", "test_average_recall_at_avg_proposals", "(", ")", ":", "\n", "    ", "ground_truth1", "=", "{", "\n", "'v_test1'", ":", "np", ".", "array", "(", "[", "[", "0", ",", "1", "]", ",", "[", "1", ",", "2", "]", "]", ")", ",", "\n", "'v_test2'", ":", "np", ".", "array", "(", "[", "[", "0", ",", "1", "]", ",", "[", "1", ",", "2", "]", "]", ")", "\n", "}", "\n", "ground_truth2", "=", "{", "'v_test1'", ":", "np", ".", "array", "(", "[", "[", "0", ",", "1", "]", "]", ")", "}", "\n", "proposals1", "=", "{", "\n", "'v_test1'", ":", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "1", "]", ",", "[", "1", ",", "2", ",", "1", "]", "]", ")", ",", "\n", "'v_test2'", ":", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "1", "]", ",", "[", "1", ",", "2", ",", "1", "]", "]", ")", "\n", "}", "\n", "proposals2", "=", "{", "\n", "'v_test1'", ":", "np", ".", "array", "(", "[", "[", "10", ",", "11", ",", "0.6", "]", ",", "[", "11", ",", "12", ",", "0.4", "]", "]", ")", ",", "\n", "'v_test2'", ":", "np", ".", "array", "(", "[", "[", "10", ",", "11", ",", "0.6", "]", ",", "[", "11", ",", "12", ",", "0.4", "]", "]", ")", "\n", "}", "\n", "proposals3", "=", "{", "\n", "'v_test1'", ":", "np", ".", "array", "(", "[", "[", "i", ",", "i", "+", "1", ",", "1", "/", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "100", ")", "]", ")", "\n", "}", "\n", "\n", "recall", ",", "avg_recall", ",", "proposals_per_video", ",", "auc", "=", "(", "\n", "average_recall_at_avg_proposals", "(", "ground_truth1", ",", "proposals1", ",", "4", ")", ")", "\n", "assert_array_equal", "(", "recall", ",", "[", "[", "0.", "]", "*", "49", "+", "[", "0.5", "]", "*", "50", "+", "[", "1.", "]", "]", "*", "10", ")", "\n", "assert_array_equal", "(", "avg_recall", ",", "[", "0.", "]", "*", "49", "+", "[", "0.5", "]", "*", "50", "+", "[", "1.", "]", ")", "\n", "assert_array_almost_equal", "(", "\n", "proposals_per_video", ",", "np", ".", "arange", "(", "0.02", ",", "2.02", ",", "0.02", ")", ",", "decimal", "=", "10", ")", "\n", "assert", "auc", "==", "25.5", "\n", "\n", "recall", ",", "avg_recall", ",", "proposals_per_video", ",", "auc", "=", "(", "\n", "average_recall_at_avg_proposals", "(", "ground_truth1", ",", "proposals2", ",", "4", ")", ")", "\n", "assert_array_equal", "(", "recall", ",", "[", "[", "0.", "]", "*", "100", "]", "*", "10", ")", "\n", "assert_array_equal", "(", "avg_recall", ",", "[", "0.", "]", "*", "100", ")", "\n", "assert_array_almost_equal", "(", "\n", "proposals_per_video", ",", "np", ".", "arange", "(", "0.02", ",", "2.02", ",", "0.02", ")", ",", "decimal", "=", "10", ")", "\n", "assert", "auc", "==", "0", "\n", "\n", "recall", ",", "avg_recall", ",", "proposals_per_video", ",", "auc", "=", "(", "\n", "average_recall_at_avg_proposals", "(", "ground_truth2", ",", "proposals3", ",", "100", ")", ")", "\n", "assert_array_equal", "(", "recall", ",", "[", "[", "1.", "]", "*", "100", "]", "*", "10", ")", "\n", "assert_array_equal", "(", "avg_recall", ",", "(", "[", "1.", "]", "*", "100", ")", ")", "\n", "assert_array_almost_equal", "(", "\n", "proposals_per_video", ",", "np", ".", "arange", "(", "1", ",", "101", ",", "1", ")", ",", "decimal", "=", "10", ")", "\n", "assert", "auc", "==", "99.0", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_get_weighted_score": [[267, 288], ["mmaction.core.get_weighted_score", "numpy.all", "mmaction.core.get_weighted_score", "numpy.all", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.isclose", "numpy.isclose", "numpy.array", "numpy.array", "zip", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.get_weighted_score", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.evaluation.accuracy.get_weighted_score"], ["", "def", "test_get_weighted_score", "(", ")", ":", "\n", "    ", "score_a", "=", "[", "\n", "np", ".", "array", "(", "[", "-", "0.2203", ",", "-", "0.7538", ",", "1.8789", ",", "0.4451", ",", "-", "0.2526", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "-", "0.0413", ",", "0.6366", ",", "1.1155", ",", "0.3484", ",", "0.0395", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0365", ",", "0.5158", ",", "1.1067", ",", "-", "0.9276", ",", "-", "0.2124", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.6232", ",", "0.9912", ",", "-", "0.8562", ",", "0.0148", ",", "1.6413", "]", ")", "\n", "]", "\n", "score_b", "=", "[", "\n", "np", ".", "array", "(", "[", "-", "0.0413", ",", "0.6366", ",", "1.1155", ",", "0.3484", ",", "0.0395", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.0365", ",", "0.5158", ",", "1.1067", ",", "-", "0.9276", ",", "-", "0.2124", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.6232", ",", "0.9912", ",", "-", "0.8562", ",", "0.0148", ",", "1.6413", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "-", "0.2203", ",", "-", "0.7538", ",", "1.8789", ",", "0.4451", ",", "-", "0.2526", "]", ")", "\n", "]", "\n", "weighted_score", "=", "get_weighted_score", "(", "[", "score_a", "]", ",", "[", "1", "]", ")", "\n", "assert", "np", ".", "all", "(", "np", ".", "isclose", "(", "np", ".", "array", "(", "score_a", ")", ",", "np", ".", "array", "(", "weighted_score", ")", ")", ")", "\n", "coeff_a", ",", "coeff_b", "=", "2.", ",", "1.", "\n", "weighted_score", "=", "get_weighted_score", "(", "[", "score_a", ",", "score_b", "]", ",", "[", "coeff_a", ",", "coeff_b", "]", ")", "\n", "ground_truth", "=", "[", "\n", "x", "*", "coeff_a", "+", "y", "*", "coeff_b", "for", "x", ",", "y", "in", "zip", "(", "score_a", ",", "score_b", ")", "\n", "]", "\n", "assert", "np", ".", "all", "(", "np", ".", "isclose", "(", "np", ".", "array", "(", "ground_truth", ")", ",", "np", ".", "array", "(", "weighted_score", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_accuracy.test_mean_average_precision": [[290, 310], ["numpy.array", "numpy.array", "numpy.mean", "test_accuracy.test_mean_average_precision.content_for_unittest"], "function", ["None"], ["", "def", "test_mean_average_precision", "(", ")", ":", "\n", "\n", "    ", "def", "content_for_unittest", "(", "scores", ",", "labels", ",", "result", ")", ":", "\n", "        ", "gt", "=", "mean_average_precision", "(", "scores", ",", "labels", ")", "\n", "assert", "gt", "==", "result", "\n", "\n", "", "scores", "=", "[", "\n", "np", ".", "array", "(", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.2", ",", "0.3", ",", "0.4", ",", "0.1", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.3", ",", "0.4", ",", "0.1", ",", "0.2", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "0.4", ",", "0.1", ",", "0.2", ",", "0.3", "]", ")", "\n", "]", "\n", "\n", "label1", "=", "np", ".", "array", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "1", ",", "1", "]", ",", "[", "1", ",", "0", ",", "1", ",", "0", "]", ",", "[", "1", ",", "1", ",", "0", ",", "1", "]", "]", ")", "\n", "result1", "=", "2", "/", "3", "\n", "label2", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", ",", "0", ",", "1", "]", ",", "[", "0", ",", "1", ",", "1", ",", "0", "]", ",", "[", "1", ",", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "result2", "=", "np", ".", "mean", "(", "[", "0.5", ",", "0.5833333333333333", ",", "0.8055555555555556", ",", "1.0", "]", ")", "\n", "\n", "content_for_unittest", "(", "scores", ",", "label1", ",", "result1", ")", "\n", "content_for_unittest", "(", "scores", ",", "label2", ",", "result2", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_hvu_loss": [[15, 80], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.HVULoss", "mmaction.models.HVULoss.", "torch.binary_cross_entropy_with_logits", "torch.sum", "torch.sum", "torch.sum", "torch.eq", "torch.eq", "torch.eq", "mmaction.models.HVULoss", "mmaction.models.HVULoss.", "torch.binary_cross_entropy_with_logits", "torch.mean", "torch.mean", "torch.mean", "torch.eq", "torch.eq", "torch.eq", "mmaction.models.HVULoss", "mmaction.models.HVULoss.", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.eq", "torch.eq", "torch.eq", "mmaction.models.HVULoss", "mmaction.models.HVULoss.", "torch.binary_cross_entropy_with_logits", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.binary_cross_entropy_with_logits", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.eq", "torch.eq", "torch.eq", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["def", "test_hvu_loss", "(", ")", ":", "\n", "    ", "pred", "=", "torch", ".", "tensor", "(", "[", "[", "-", "1.0525", ",", "-", "0.7085", ",", "0.1819", ",", "-", "0.8011", "]", ",", "\n", "[", "0.1555", ",", "-", "1.5550", ",", "0.5586", ",", "1.9746", "]", "]", ")", "\n", "gt", "=", "torch", ".", "tensor", "(", "[", "[", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "1.", ",", "1.", "]", "]", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "[", "1.", ",", "1.", ",", "0.", ",", "0.", "]", ",", "[", "0.", ",", "0.", ",", "1.", ",", "1.", "]", "]", ")", "\n", "category_mask", "=", "torch", ".", "tensor", "(", "[", "[", "1.", ",", "0.", "]", ",", "[", "0.", ",", "1.", "]", "]", ")", "\n", "categories", "=", "[", "'action'", ",", "'scene'", "]", "\n", "category_nums", "=", "(", "2", ",", "2", ")", "\n", "category_loss_weights", "=", "(", "1", ",", "1", ")", "\n", "loss_all_nomask_sum", "=", "HVULoss", "(", "\n", "categories", "=", "categories", ",", "\n", "category_nums", "=", "category_nums", ",", "\n", "category_loss_weights", "=", "category_loss_weights", ",", "\n", "loss_type", "=", "'all'", ",", "\n", "with_mask", "=", "False", ",", "\n", "reduction", "=", "'sum'", ")", "\n", "loss", "=", "loss_all_nomask_sum", "(", "pred", ",", "gt", ",", "mask", ",", "category_mask", ")", "\n", "loss1", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "pred", ",", "gt", ",", "reduction", "=", "'none'", ")", "\n", "loss1", "=", "torch", ".", "sum", "(", "loss1", ",", "dim", "=", "1", ")", "\n", "assert", "torch", ".", "eq", "(", "loss", "[", "'loss_cls'", "]", ",", "torch", ".", "mean", "(", "loss1", ")", ")", "\n", "\n", "loss_all_mask", "=", "HVULoss", "(", "\n", "categories", "=", "categories", ",", "\n", "category_nums", "=", "category_nums", ",", "\n", "category_loss_weights", "=", "category_loss_weights", ",", "\n", "loss_type", "=", "'all'", ",", "\n", "with_mask", "=", "True", ")", "\n", "loss", "=", "loss_all_mask", "(", "pred", ",", "gt", ",", "mask", ",", "category_mask", ")", "\n", "loss1", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "pred", ",", "gt", ",", "reduction", "=", "'none'", ")", "\n", "loss1", "=", "torch", ".", "sum", "(", "loss1", "*", "mask", ",", "dim", "=", "1", ")", "/", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", "\n", "loss1", "=", "torch", ".", "mean", "(", "loss1", ")", "\n", "assert", "torch", ".", "eq", "(", "loss", "[", "'loss_cls'", "]", ",", "loss1", ")", "\n", "\n", "loss_ind_mask", "=", "HVULoss", "(", "\n", "categories", "=", "categories", ",", "\n", "category_nums", "=", "category_nums", ",", "\n", "category_loss_weights", "=", "category_loss_weights", ",", "\n", "loss_type", "=", "'individual'", ",", "\n", "with_mask", "=", "True", ")", "\n", "loss", "=", "loss_ind_mask", "(", "pred", ",", "gt", ",", "mask", ",", "category_mask", ")", "\n", "action_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "pred", "[", ":", "1", ",", ":", "2", "]", ",", "gt", "[", ":", "1", ",", ":", "2", "]", ")", "\n", "scene_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "pred", "[", "1", ":", ",", "2", ":", "]", ",", "gt", "[", "1", ":", ",", "2", ":", "]", ")", "\n", "loss1", "=", "(", "action_loss", "+", "scene_loss", ")", "/", "2", "\n", "assert", "torch", ".", "eq", "(", "loss", "[", "'loss_cls'", "]", ",", "loss1", ")", "\n", "\n", "loss_ind_nomask_sum", "=", "HVULoss", "(", "\n", "categories", "=", "categories", ",", "\n", "category_nums", "=", "category_nums", ",", "\n", "category_loss_weights", "=", "category_loss_weights", ",", "\n", "loss_type", "=", "'individual'", ",", "\n", "with_mask", "=", "False", ",", "\n", "reduction", "=", "'sum'", ")", "\n", "loss", "=", "loss_ind_nomask_sum", "(", "pred", ",", "gt", ",", "mask", ",", "category_mask", ")", "\n", "action_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "pred", "[", ":", ",", ":", "2", "]", ",", "gt", "[", ":", ",", ":", "2", "]", ",", "reduction", "=", "'none'", ")", "\n", "action_loss", "=", "torch", ".", "sum", "(", "action_loss", ",", "dim", "=", "1", ")", "\n", "action_loss", "=", "torch", ".", "mean", "(", "action_loss", ")", "\n", "\n", "scene_loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "pred", "[", ":", ",", "2", ":", "]", ",", "gt", "[", ":", ",", "2", ":", "]", ",", "reduction", "=", "'none'", ")", "\n", "scene_loss", "=", "torch", ".", "sum", "(", "scene_loss", ",", "dim", "=", "1", ")", "\n", "scene_loss", "=", "torch", ".", "mean", "(", "scene_loss", ")", "\n", "\n", "loss1", "=", "(", "action_loss", "+", "scene_loss", ")", "/", "2", "\n", "assert", "torch", ".", "eq", "(", "loss", "[", "'loss_cls'", "]", ",", "loss1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_cross_entropy_loss": [[82, 118], ["torch.rand", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.FloatTensor().squeeze", "torch.FloatTensor().squeeze", "torch.FloatTensor().squeeze", "mmaction.models.CrossEntropyLoss", "mmaction.models.CrossEntropyLoss.", "torch.equal", "torch.equal", "torch.equal", "torch.rand", "torch.rand", "torch.rand", "torch.rand.numpy().tolist", "mmaction.models.CrossEntropyLoss", "mmaction.models.CrossEntropyLoss.", "torch.equal", "torch.equal", "torch.equal", "mmaction.models.CrossEntropyLoss", "mmaction.models.CrossEntropyLoss.", "numpy.testing.assert_almost_equal", "mmaction.models.CrossEntropyLoss", "mmaction.models.CrossEntropyLoss.", "numpy.testing.assert_almost_equal", "torch.cross_entropy", "torch.cross_entropy", "cross_entropy_loss.numpy", "torch.cross_entropy().numpy", "cross_entropy_loss.numpy", "torch.cross_entropy().numpy", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.rand.numpy", "torch.cross_entropy", "torch.cross_entropy"], "function", ["None"], ["", "def", "test_cross_entropy_loss", "(", ")", ":", "\n", "    ", "cls_scores", "=", "torch", ".", "rand", "(", "(", "3", ",", "4", ")", ")", "\n", "hard_gt_labels", "=", "torch", ".", "LongTensor", "(", "[", "0", ",", "1", ",", "2", "]", ")", ".", "squeeze", "(", ")", "\n", "soft_gt_labels", "=", "torch", ".", "FloatTensor", "(", "[", "[", "1", ",", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", ",", "0", "]", "]", ")", ".", "squeeze", "(", ")", "\n", "\n", "# hard label without weight", "\n", "cross_entropy_loss", "=", "CrossEntropyLoss", "(", ")", "\n", "output_loss", "=", "cross_entropy_loss", "(", "cls_scores", ",", "hard_gt_labels", ")", "\n", "assert", "torch", ".", "equal", "(", "output_loss", ",", "F", ".", "cross_entropy", "(", "cls_scores", ",", "\n", "hard_gt_labels", ")", ")", "\n", "\n", "# hard label with class weight", "\n", "weight", "=", "torch", ".", "rand", "(", "4", ")", "\n", "class_weight", "=", "weight", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "cross_entropy_loss", "=", "CrossEntropyLoss", "(", "class_weight", "=", "class_weight", ")", "\n", "output_loss", "=", "cross_entropy_loss", "(", "cls_scores", ",", "hard_gt_labels", ")", "\n", "assert", "torch", ".", "equal", "(", "\n", "output_loss", ",", "\n", "F", ".", "cross_entropy", "(", "cls_scores", ",", "hard_gt_labels", ",", "weight", "=", "weight", ")", ")", "\n", "\n", "# soft label without class weight", "\n", "cross_entropy_loss", "=", "CrossEntropyLoss", "(", ")", "\n", "output_loss", "=", "cross_entropy_loss", "(", "cls_scores", ",", "soft_gt_labels", ")", "\n", "assert_almost_equal", "(", "\n", "output_loss", ".", "numpy", "(", ")", ",", "\n", "F", ".", "cross_entropy", "(", "cls_scores", ",", "hard_gt_labels", ")", ".", "numpy", "(", ")", ",", "\n", "decimal", "=", "4", ")", "\n", "\n", "# soft label with class weight", "\n", "cross_entropy_loss", "=", "CrossEntropyLoss", "(", "class_weight", "=", "class_weight", ")", "\n", "output_loss", "=", "cross_entropy_loss", "(", "cls_scores", ",", "soft_gt_labels", ")", "\n", "assert_almost_equal", "(", "\n", "output_loss", ".", "numpy", "(", ")", ",", "\n", "F", ".", "cross_entropy", "(", "cls_scores", ",", "hard_gt_labels", ",", "weight", "=", "weight", ")", ".", "numpy", "(", ")", ",", "\n", "decimal", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_bce_loss_with_logits": [[120, 137], ["torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "mmaction.models.BCELossWithLogits", "mmaction.models.BCELossWithLogits.", "torch.equal", "torch.equal", "torch.equal", "torch.rand", "torch.rand", "torch.rand", "torch.rand.numpy().tolist", "mmaction.models.BCELossWithLogits", "mmaction.models.BCELossWithLogits.", "torch.equal", "torch.equal", "torch.equal", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.rand.numpy"], "function", ["None"], ["", "def", "test_bce_loss_with_logits", "(", ")", ":", "\n", "    ", "cls_scores", "=", "torch", ".", "rand", "(", "(", "3", ",", "4", ")", ")", "\n", "gt_labels", "=", "torch", ".", "rand", "(", "(", "3", ",", "4", ")", ")", "\n", "\n", "bce_loss_with_logits", "=", "BCELossWithLogits", "(", ")", "\n", "output_loss", "=", "bce_loss_with_logits", "(", "cls_scores", ",", "gt_labels", ")", "\n", "assert", "torch", ".", "equal", "(", "\n", "output_loss", ",", "F", ".", "binary_cross_entropy_with_logits", "(", "cls_scores", ",", "gt_labels", ")", ")", "\n", "\n", "weight", "=", "torch", ".", "rand", "(", "4", ")", "\n", "class_weight", "=", "weight", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "bce_loss_with_logits", "=", "BCELossWithLogits", "(", "class_weight", "=", "class_weight", ")", "\n", "output_loss", "=", "bce_loss_with_logits", "(", "cls_scores", ",", "gt_labels", ")", "\n", "assert", "torch", ".", "equal", "(", "\n", "output_loss", ",", "\n", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "cls_scores", ",", "gt_labels", ",", "weight", "=", "weight", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_nll_loss": [[139, 148], ["torch.randn", "torch.randn", "torch.randn", "torch.tensor().squeeze", "torch.tensor().squeeze", "torch.tensor().squeeze", "torch.Softmax", "mmaction.models.NLLLoss", "torch.log", "torch.log", "torch.log", "mmaction.models.NLLLoss.", "torch.equal", "torch.equal", "torch.equal", "nn.Softmax.", "torch.nll_loss", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "test_nll_loss", "(", ")", ":", "\n", "    ", "cls_scores", "=", "torch", ".", "randn", "(", "3", ",", "3", ")", "\n", "gt_labels", "=", "torch", ".", "tensor", "(", "[", "0", ",", "2", ",", "1", "]", ")", ".", "squeeze", "(", ")", "\n", "\n", "sm", "=", "nn", ".", "Softmax", "(", "dim", "=", "0", ")", "\n", "nll_loss", "=", "NLLLoss", "(", ")", "\n", "cls_score_log", "=", "torch", ".", "log", "(", "sm", "(", "cls_scores", ")", ")", "\n", "output_loss", "=", "nll_loss", "(", "cls_score_log", ",", "gt_labels", ")", "\n", "assert", "torch", ".", "equal", "(", "output_loss", ",", "F", ".", "nll_loss", "(", "cls_score_log", ",", "gt_labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_binary_logistic_loss": [[150, 162], ["mmaction.models.BinaryLogisticRegressionLoss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BinaryLogisticRegressionLoss.", "numpy.testing.assert_array_almost_equal", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BinaryLogisticRegressionLoss.", "numpy.testing.assert_array_almost_equal", "binary_logistic_regression_loss.numpy", "numpy.array", "binary_logistic_regression_loss.numpy", "numpy.array"], "function", ["None"], ["", "def", "test_binary_logistic_loss", "(", ")", ":", "\n", "    ", "binary_logistic_regression_loss", "=", "BinaryLogisticRegressionLoss", "(", ")", "\n", "reg_score", "=", "torch", ".", "tensor", "(", "[", "0.", ",", "1.", "]", ")", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "0.", ",", "1.", "]", ")", "\n", "output_loss", "=", "binary_logistic_regression_loss", "(", "reg_score", ",", "label", ",", "0.5", ")", "\n", "assert_array_almost_equal", "(", "output_loss", ".", "numpy", "(", ")", ",", "np", ".", "array", "(", "[", "0.", "]", ")", ",", "decimal", "=", "4", ")", "\n", "\n", "reg_score", "=", "torch", ".", "tensor", "(", "[", "0.3", ",", "0.9", "]", ")", "\n", "label", "=", "torch", ".", "tensor", "(", "[", "0.", ",", "1.", "]", ")", "\n", "output_loss", "=", "binary_logistic_regression_loss", "(", "reg_score", ",", "label", ",", "0.5", ")", "\n", "assert_array_almost_equal", "(", "\n", "output_loss", ".", "numpy", "(", ")", ",", "np", ".", "array", "(", "[", "0.231", "]", ")", ",", "decimal", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_bmn_loss": [[164, 218], ["mmaction.models.BMNLoss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BMNLoss.tem_loss", "mmaction.models.BinaryLogisticRegressionLoss", "numpy.testing.assert_array_almost_equal", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BMNLoss.pem_reg_loss", "numpy.testing.assert_array_almost_equal", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BMNLoss.pem_cls_loss", "numpy.testing.assert_array_almost_equal", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.BMNLoss.", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "numpy.testing.assert_array_almost_equal", "mmaction.models.BinaryLogisticRegressionLoss.", "mmaction.models.BinaryLogisticRegressionLoss.", "bmn_loss.tem_loss.numpy", "assert_loss.numpy", "bmn_loss.pem_reg_loss.numpy", "numpy.array", "bmn_loss.pem_cls_loss.numpy", "numpy.array", "output_loss[].numpy", "output_loss[].numpy", "output_loss[].numpy", "output_loss[].numpy"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.tem_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.pem_reg_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.bmn_loss.BMNLoss.pem_cls_loss"], ["", "def", "test_bmn_loss", "(", ")", ":", "\n", "    ", "bmn_loss", "=", "BMNLoss", "(", ")", "\n", "\n", "# test tem_loss", "\n", "pred_start", "=", "torch", ".", "tensor", "(", "[", "0.9", ",", "0.1", "]", ")", "\n", "pred_end", "=", "torch", ".", "tensor", "(", "[", "0.1", ",", "0.9", "]", ")", "\n", "gt_start", "=", "torch", ".", "tensor", "(", "[", "1.", ",", "0.", "]", ")", "\n", "gt_end", "=", "torch", ".", "tensor", "(", "[", "0.", ",", "1.", "]", ")", "\n", "output_tem_loss", "=", "bmn_loss", ".", "tem_loss", "(", "pred_start", ",", "pred_end", ",", "gt_start", ",", "gt_end", ")", "\n", "binary_logistic_regression_loss", "=", "BinaryLogisticRegressionLoss", "(", ")", "\n", "assert_loss", "=", "(", "\n", "binary_logistic_regression_loss", "(", "pred_start", ",", "gt_start", ")", "+", "\n", "binary_logistic_regression_loss", "(", "pred_end", ",", "gt_end", ")", ")", "\n", "assert_array_almost_equal", "(", "\n", "output_tem_loss", ".", "numpy", "(", ")", ",", "assert_loss", ".", "numpy", "(", ")", ",", "decimal", "=", "4", ")", "\n", "\n", "# test pem_reg_loss", "\n", "seed", "=", "1", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "pred_bm_reg", "=", "torch", ".", "tensor", "(", "[", "[", "0.1", ",", "0.99", "]", ",", "[", "0.5", ",", "0.4", "]", "]", ")", "\n", "gt_iou_map", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "1.", "]", ",", "[", "0", ",", "1.", "]", "]", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "[", "0.1", ",", "0.4", "]", ",", "[", "0.4", ",", "0.1", "]", "]", ")", "\n", "output_pem_reg_loss", "=", "bmn_loss", ".", "pem_reg_loss", "(", "pred_bm_reg", ",", "gt_iou_map", ",", "mask", ")", "\n", "assert_array_almost_equal", "(", "\n", "output_pem_reg_loss", ".", "numpy", "(", ")", ",", "np", ".", "array", "(", "[", "0.2140", "]", ")", ",", "decimal", "=", "4", ")", "\n", "\n", "# test pem_cls_loss", "\n", "pred_bm_cls", "=", "torch", ".", "tensor", "(", "[", "[", "0.1", ",", "0.99", "]", ",", "[", "0.95", ",", "0.2", "]", "]", ")", "\n", "gt_iou_map", "=", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "1.", "]", ",", "[", "0.", ",", "1.", "]", "]", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "[", "0.1", ",", "0.4", "]", ",", "[", "0.4", ",", "0.1", "]", "]", ")", "\n", "output_pem_cls_loss", "=", "bmn_loss", ".", "pem_cls_loss", "(", "pred_bm_cls", ",", "gt_iou_map", ",", "mask", ")", "\n", "assert_array_almost_equal", "(", "\n", "output_pem_cls_loss", ".", "numpy", "(", ")", ",", "np", ".", "array", "(", "[", "1.6137", "]", ")", ",", "decimal", "=", "4", ")", "\n", "\n", "# test bmn_loss", "\n", "pred_bm", "=", "torch", ".", "tensor", "(", "[", "[", "[", "[", "0.1", ",", "0.99", "]", ",", "[", "0.5", ",", "0.4", "]", "]", ",", "\n", "[", "[", "0.1", ",", "0.99", "]", ",", "[", "0.95", ",", "0.2", "]", "]", "]", "]", ")", "\n", "pred_start", "=", "torch", ".", "tensor", "(", "[", "[", "0.9", ",", "0.1", "]", "]", ")", "\n", "pred_end", "=", "torch", ".", "tensor", "(", "[", "[", "0.1", ",", "0.9", "]", "]", ")", "\n", "gt_iou_map", "=", "torch", ".", "tensor", "(", "[", "[", "[", "0.", ",", "2.5", "]", ",", "[", "0.", ",", "10.", "]", "]", "]", ")", "\n", "gt_start", "=", "torch", ".", "tensor", "(", "[", "[", "1.", ",", "0.", "]", "]", ")", "\n", "gt_end", "=", "torch", ".", "tensor", "(", "[", "[", "0.", ",", "1.", "]", "]", ")", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "[", "0.1", ",", "0.4", "]", ",", "[", "0.4", ",", "0.1", "]", "]", ")", "\n", "output_loss", "=", "bmn_loss", "(", "pred_bm", ",", "pred_start", ",", "pred_end", ",", "gt_iou_map", ",", "gt_start", ",", "\n", "gt_end", ",", "mask", ")", "\n", "assert_array_almost_equal", "(", "\n", "output_loss", "[", "0", "]", ".", "numpy", "(", ")", ",", "\n", "output_tem_loss", "+", "10", "*", "output_pem_reg_loss", "+", "output_pem_cls_loss", ")", "\n", "assert_array_almost_equal", "(", "output_loss", "[", "1", "]", ".", "numpy", "(", ")", ",", "output_tem_loss", ")", "\n", "assert_array_almost_equal", "(", "output_loss", "[", "2", "]", ".", "numpy", "(", ")", ",", "output_pem_reg_loss", ")", "\n", "assert_array_almost_equal", "(", "output_loss", "[", "3", "]", ".", "numpy", "(", ")", ",", "output_pem_cls_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_ohem_hinge_loss": [[220, 246], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.OHEMHingeLoss.apply", "numpy.testing.assert_array_almost_equal", "OHEMHingeLoss.apply.backward", "numpy.testing.assert_array_almost_equal", "OHEMHingeLoss.apply.detach().numpy", "numpy.array", "torch.autograd.Variable", "numpy.array", "numpy.array", "pytest.raises", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.OHEMHingeLoss.apply", "torch.ones", "torch.ones", "torch.ones", "OHEMHingeLoss.apply.detach"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ohem_hinge_loss.OHEMHingeLoss.backward"], ["", "def", "test_ohem_hinge_loss", "(", ")", ":", "\n", "# test normal case", "\n", "    ", "pred", "=", "torch", ".", "tensor", "(", "[", "[", "\n", "0.5161", ",", "0.5228", ",", "0.7748", ",", "0.0573", ",", "0.1113", ",", "0.8862", ",", "0.1752", ",", "0.9448", ",", "0.0253", ",", "\n", "0.1009", ",", "0.4371", ",", "0.2232", ",", "0.0412", ",", "0.3487", ",", "0.3350", ",", "0.9294", ",", "0.7122", ",", "0.3072", ",", "\n", "0.2942", ",", "0.7679", "\n", "]", "]", ",", "\n", "requires_grad", "=", "True", ")", "\n", "gt", "=", "torch", ".", "tensor", "(", "[", "8", "]", ")", "\n", "num_video", "=", "1", "\n", "loss", "=", "OHEMHingeLoss", ".", "apply", "(", "pred", ",", "gt", ",", "1", ",", "1.0", ",", "num_video", ")", "\n", "assert_array_almost_equal", "(", "\n", "loss", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "np", ".", "array", "(", "[", "0.0552", "]", ")", ",", "decimal", "=", "4", ")", "\n", "loss", ".", "backward", "(", "Variable", "(", "torch", ".", "ones", "(", "[", "1", "]", ")", ")", ")", "\n", "assert_array_almost_equal", "(", "\n", "np", ".", "array", "(", "pred", ".", "grad", ")", ",", "\n", "np", ".", "array", "(", "[", "[", "\n", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "-", "1.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "\n", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "]", "]", ")", ",", "\n", "decimal", "=", "4", ")", "\n", "\n", "# test error case", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "gt", "=", "torch", ".", "tensor", "(", "[", "8", ",", "10", "]", ")", "\n", "loss", "=", "OHEMHingeLoss", ".", "apply", "(", "pred", ",", "gt", ",", "1", ",", "1.0", ",", "num_video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.test_metrics.test_losses.test_ssn_loss": [[248, 332], ["mmaction.models.SSNLoss", "torch.rand", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.SSNLoss.activity_loss", "torch.equal", "torch.equal", "torch.equal", "torch.rand", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.SSNLoss.completeness_loss", "pred.view.size", "pred.view.view", "gt.view.view", "pred[].contiguous().view", "pred[].contiguous().view", "mmaction.models.OHEMHingeLoss.apply", "mmaction.models.OHEMHingeLoss.apply", "pred[].contiguous().view.size", "int", "torch.equal", "torch.equal", "torch.equal", "torch.rand", "torch.rand", "torch.rand", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.LongTensor().squeeze", "torch.rand", "torch.rand", "torch.rand", "torch.tensor", "torch.tensor", "torch.tensor", "mmaction.models.SSNLoss.classwise_regression_loss", "torch.cat", "torch.cat", "torch.cat", "torch.equal", "torch.equal", "torch.equal", "torch.tensor", "torch.tensor", "torch.tensor", "mmcv.ConfigDict", "mmaction.models.SSNLoss.", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.equal", "torch.cross_entropy", "gt[].contiguous().view", "gt[].contiguous().view", "float", "dict", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "pred[].contiguous", "pred[].contiguous", "pred[].contiguous().view.size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.diag().view", "torch.smooth_l1_loss", "gt[].contiguous", "gt[].contiguous", "torch.cat.view", "reg_target.view", "dict", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.activity_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.completeness_loss", "home.repos.pwc.inspect_result.SwinTransformer_Video-Swin-Transformer.losses.ssn_loss.SSNLoss.classwise_regression_loss"], ["", "", "def", "test_ssn_loss", "(", ")", ":", "\n", "    ", "ssn_loss", "=", "SSNLoss", "(", ")", "\n", "\n", "# test activity_loss", "\n", "activity_score", "=", "torch", ".", "rand", "(", "(", "8", ",", "21", ")", ")", "\n", "labels", "=", "torch", ".", "LongTensor", "(", "[", "8", "]", "*", "8", ")", ".", "squeeze", "(", ")", "\n", "activity_indexer", "=", "torch", ".", "tensor", "(", "[", "0", ",", "7", "]", ")", "\n", "output_activity_loss", "=", "ssn_loss", ".", "activity_loss", "(", "activity_score", ",", "labels", ",", "\n", "activity_indexer", ")", "\n", "assert", "torch", ".", "equal", "(", "\n", "output_activity_loss", ",", "\n", "F", ".", "cross_entropy", "(", "activity_score", "[", "activity_indexer", ",", ":", "]", ",", "\n", "labels", "[", "activity_indexer", "]", ")", ")", "\n", "\n", "# test completeness_loss", "\n", "completeness_score", "=", "torch", ".", "rand", "(", "(", "8", ",", "20", ")", ",", "requires_grad", "=", "True", ")", "\n", "labels", "=", "torch", ".", "LongTensor", "(", "[", "8", "]", "*", "8", ")", ".", "squeeze", "(", ")", "\n", "completeness_indexer", "=", "torch", ".", "tensor", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", "]", ")", "\n", "positive_per_video", "=", "1", "\n", "incomplete_per_video", "=", "6", "\n", "output_completeness_loss", "=", "ssn_loss", ".", "completeness_loss", "(", "\n", "completeness_score", ",", "labels", ",", "completeness_indexer", ",", "positive_per_video", ",", "\n", "incomplete_per_video", ")", "\n", "\n", "pred", "=", "completeness_score", "[", "completeness_indexer", ",", ":", "]", "\n", "gt", "=", "labels", "[", "completeness_indexer", "]", "\n", "pred_dim", "=", "pred", ".", "size", "(", "1", ")", "\n", "pred", "=", "pred", ".", "view", "(", "-", "1", ",", "positive_per_video", "+", "incomplete_per_video", ",", "pred_dim", ")", "\n", "gt", "=", "gt", ".", "view", "(", "-", "1", ",", "positive_per_video", "+", "incomplete_per_video", ")", "\n", "# yapf:disable", "\n", "positive_pred", "=", "pred", "[", ":", ",", ":", "positive_per_video", ",", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "pred_dim", ")", "# noqa:E501", "\n", "incomplete_pred", "=", "pred", "[", ":", ",", "positive_per_video", ":", ",", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "pred_dim", ")", "# noqa:E501", "\n", "# yapf:enable", "\n", "ohem_ratio", "=", "0.17", "\n", "positive_loss", "=", "OHEMHingeLoss", ".", "apply", "(", "\n", "positive_pred", ",", "gt", "[", ":", ",", ":", "positive_per_video", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "1", ",", "\n", "1.0", ",", "positive_per_video", ")", "\n", "incomplete_loss", "=", "OHEMHingeLoss", ".", "apply", "(", "\n", "incomplete_pred", ",", "gt", "[", ":", ",", "positive_per_video", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "-", "1", ",", "\n", "ohem_ratio", ",", "incomplete_per_video", ")", "\n", "num_positives", "=", "positive_pred", ".", "size", "(", "0", ")", "\n", "num_incompletes", "=", "int", "(", "incomplete_pred", ".", "size", "(", "0", ")", "*", "ohem_ratio", ")", "\n", "assert_loss", "=", "(", "(", "positive_loss", "+", "incomplete_loss", ")", "/", "\n", "float", "(", "num_positives", "+", "num_incompletes", ")", ")", "\n", "assert", "torch", ".", "equal", "(", "output_completeness_loss", ",", "assert_loss", ")", "\n", "\n", "# test reg_loss", "\n", "bbox_pred", "=", "torch", ".", "rand", "(", "(", "8", ",", "20", ",", "2", ")", ")", "\n", "labels", "=", "torch", ".", "LongTensor", "(", "[", "8", "]", "*", "8", ")", ".", "squeeze", "(", ")", "\n", "bbox_targets", "=", "torch", ".", "rand", "(", "(", "8", ",", "2", ")", ")", "\n", "regression_indexer", "=", "torch", ".", "tensor", "(", "[", "0", "]", ")", "\n", "output_reg_loss", "=", "ssn_loss", ".", "classwise_regression_loss", "(", "\n", "bbox_pred", ",", "labels", ",", "bbox_targets", ",", "regression_indexer", ")", "\n", "\n", "pred", "=", "bbox_pred", "[", "regression_indexer", ",", ":", ",", ":", "]", "\n", "gt", "=", "labels", "[", "regression_indexer", "]", "\n", "reg_target", "=", "bbox_targets", "[", "regression_indexer", ",", ":", "]", "\n", "class_idx", "=", "gt", ".", "data", "-", "1", "\n", "classwise_pred", "=", "pred", "[", ":", ",", "class_idx", ",", ":", "]", "\n", "classwise_reg_pred", "=", "torch", ".", "cat", "(", "(", "torch", ".", "diag", "(", "classwise_pred", "[", ":", ",", ":", ",", "0", "]", ")", ".", "view", "(", "\n", "-", "1", ",", "1", ")", ",", "torch", ".", "diag", "(", "classwise_pred", "[", ":", ",", ":", ",", "1", "]", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "assert", "torch", ".", "equal", "(", "\n", "output_reg_loss", ",", "\n", "F", ".", "smooth_l1_loss", "(", "classwise_reg_pred", ".", "view", "(", "-", "1", ")", ",", "reg_target", ".", "view", "(", "-", "1", ")", ")", "*", "2", ")", "\n", "\n", "# test ssn_loss", "\n", "proposal_type", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "2", "]", "]", ")", "\n", "train_cfg", "=", "ConfigDict", "(", "\n", "dict", "(", "\n", "ssn", "=", "dict", "(", "\n", "sampler", "=", "dict", "(", "\n", "num_per_video", "=", "8", ",", "\n", "positive_ratio", "=", "1", ",", "\n", "background_ratio", "=", "1", ",", "\n", "incomplete_ratio", "=", "6", ",", "\n", "add_gt_as_proposals", "=", "True", ")", ",", "\n", "loss_weight", "=", "dict", "(", "comp_loss_weight", "=", "0.1", ",", "reg_loss_weight", "=", "0.1", ")", ")", ")", ")", "\n", "output_loss", "=", "ssn_loss", "(", "activity_score", ",", "completeness_score", ",", "bbox_pred", ",", "\n", "proposal_type", ",", "labels", ",", "bbox_targets", ",", "train_cfg", ")", "\n", "assert", "torch", ".", "equal", "(", "output_loss", "[", "'loss_activity'", "]", ",", "output_activity_loss", ")", "\n", "assert", "torch", ".", "equal", "(", "output_loss", "[", "'loss_completeness'", "]", ",", "\n", "output_completeness_loss", "*", "0.1", ")", "\n", "assert", "torch", ".", "equal", "(", "output_loss", "[", "'loss_reg'", "]", ",", "output_reg_loss", "*", "0.1", ")", "\n", "", ""]]}