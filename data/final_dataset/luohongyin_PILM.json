{"home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.Chomp1d.__init__": [[7, 10], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ",", "chomp_size", ")", ":", "\n", "        ", "super", "(", "Chomp1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chomp_size", "=", "chomp_size", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.Chomp1d.forward": [[11, 13], ["x[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", ":", ",", ":", ",", ":", "-", "self", ".", "chomp_size", "]", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.__init__": [[15, 47], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "tcn_bi.Chomp1d", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_inputs", ",", "n_outputs", ",", "kernal_size", ",", "stride", ",", "dilation", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "TCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "(", "kernal_size", "-", "1", ")", "*", "dilation", "\n", "# self.lockdrop = LockedDropout()", "\n", "# padding = int((kernal_size - 1) / 2)", "\n", "# '''", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "n_inputs", ",", "n_outputs", ",", "kernal_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ")", "\n", "# self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernal_size,", "\n", "#         stride=stride, padding=padding, dilation=dilation)", "\n", "self", ".", "chomp", "=", "Chomp1d", "(", "padding", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", ")", "\n", "# self.dropout = nn.Dropout(0.2)", "\n", "# self.relu2 = nn.ReLU()", "\n", "# self.conv_net = nn.Sequential(self.conv, self.relu1)", "\n", "# self.conv_net = nn.Sequential(self.conv, self.relu1,", "\n", "#         self.conv2, self.relu2)", "\n", "self", ".", "conv_net", "=", "nn", ".", "Sequential", "(", "self", ".", "conv", ",", "self", ".", "chomp", ",", "self", ".", "relu1", ")", "\n", "# self.conv_net = nn.Sequential(self.conv, self.chomp,", "\n", "#         self.relu1, self.dropout)", "\n", "# '''", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "n_outputs", ",", "1", ")", "\n", "# self.relu_linear = nn.ReLU()", "\n", "self", ".", "linear_net", "=", "nn", ".", "Sequential", "(", "self", ".", "linear", ")", "\n", "# self.linear_net = nn.Sequential(self.linear, self.relu_linear)", "\n", "self", ".", "hardtanh1", "=", "nn", ".", "Hardtanh", "(", ")", "\n", "self", ".", "hardtanh2", "=", "nn", ".", "Hardtanh", "(", ")", "\n", "self", ".", "hardtanh3", "=", "nn", ".", "Hardtanh", "(", ")", "\n", "self", ".", "hardtanh4", "=", "nn", ".", "Hardtanh", "(", ")", "\n", "\n", "# self.softmax = nn.Softmax(dim=1)", "\n", "self", ".", "temp", "=", "10.0", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.ht": [[48, 50], ["ht_func"], "methods", ["None"], ["", "def", "ht", "(", "self", ",", "ht_func", ",", "x", ")", ":", "\n", "        ", "return", "0.5", "*", "(", "ht_func", "(", "x", "*", "self", ".", "temp", ")", "+", "1", ")", "\n", "# return 0.5 * (ht_func(x * self.temp - 1 / self.temp) + 1)", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.get_span": [[52, 79], ["ones.tril().unsqueeze", "ones.triu().unsqueeze", "ones.tril().unsqueeze", "ones.tril().unsqueeze", "x_shift_down.unsqueeze", "x_output.unsqueeze", "tcn_bi.TCN.ht().unsqueeze", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "tcn_bi.TCN.ht", "ones.tril", "ones.triu", "ones.tril", "ones.tril", "tcn_bi.TCN.ht"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht", "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht"], ["", "def", "get_span", "(", "self", ",", "x_output", ",", "ones", ",", "x_shift_down", ",", "x_shift_up", ",", "\n", "hardtanh1", ",", "hardtanh2", ",", "d", ")", ":", "\n", "        ", "mask", "=", "ones", ".", "tril", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "mask_u", "=", "ones", ".", "triu", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "mask2", "=", "ones", ".", "tril", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "mask_shift", "=", "ones", ".", "tril", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "# mask_shift2 = ones.tril(2).unsqueeze(2)", "\n", "\n", "x_row", "=", "x_shift_down", ".", "unsqueeze", "(", "0", ")", "\n", "x_column", "=", "x_output", ".", "unsqueeze", "(", "1", ")", "\n", "# x_column = x_shift_up.unsqueeze(1)", "\n", "x_square1", "=", "x_row", "-", "x_column", "\n", "# square_1 = (x_square1 < 0).float()", "\n", "square_1", "=", "self", ".", "ht", "(", "hardtanh1", ",", "x_square1", ")", "*", "(", "1", "-", "mask_shift", ")", "\n", "# square_1 = self.ht(self.hardtanh1, x_square1 * (1 - mask_shift2))", "\n", "\n", "# square_2 = (x_output - x_shift_down < 0).float().unsqueeze(0)", "\n", "square_2", "=", "self", ".", "ht", "(", "hardtanh2", ",", "x_shift_down", "-", "x_output", ")", ".", "unsqueeze", "(", "0", ")", "\n", "x_span_split_index", "=", "square_1", "*", "square_2", "\n", "\n", "all_ones", "=", "torch", ".", "ones_like", "(", "x_span_split_index", ")", "\n", "span", "=", "all_ones", "-", "x_span_split_index", "\n", "\n", "final_mask", "=", "(", "1", "-", "mask", ")", "if", "d", "==", "1", "else", "mask_u", "\n", "# span = (mask + (1 - mask) * span).cumprod(dim=1) * final_mask", "\n", "span", "=", "(", "mask2", "+", "(", "1", "-", "mask2", ")", "*", "span", ")", ".", "cumprod", "(", "dim", "=", "1", ")", "*", "final_mask", "\n", "return", "span", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.get_attention": [[80, 89], ["span.unsqueeze", "x_att.unsqueeze().unsqueeze", "span_scores.sum", "x_output.min", "x_att.unsqueeze"], "methods", ["None"], ["", "def", "get_attention", "(", "self", ",", "span", ",", "x_output", ")", ":", "\n", "# Linear Normalize", "\n", "        ", "x_att", "=", "x_output", "-", "x_output", ".", "min", "(", ")", "+", "0.05", "\n", "span_scores", "=", "span", ".", "unsqueeze", "(", "3", ")", "*", "x_att", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# span_scores *= (1 - ones.triu(10)).unsqueeze(0).unsqueeze(3)", "\n", "span_scores", "=", "span_scores", "[", ":", "-", "1", "]", "\n", "attention", "=", "span_scores", "/", "(", "span_scores", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "# attention = span_scores / (span_scores.sum(1, keepdim=True) + 1e-4)", "\n", "return", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.forward": [[90, 126], ["x.transpose().transpose.transpose().transpose.size", "x.transpose().transpose.transpose().transpose.size", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "x.transpose().transpose.transpose().transpose.transpose().transpose", "tcn_bi.TCN.conv_net", "x_conv.transpose().transpose.transpose().transpose.transpose().transpose", "tcn_bi.TCN.linear_net().squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "tcn_bi.TCN.get_span", "tcn_bi.TCN.get_span().flip", "tcn_bi.TCN.get_attention", "tcn_bi.TCN.get_attention", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.triu", "torch.ones().cuda.triu", "torch.ones().cuda.triu", "torch.ones().cuda.triu", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x.transpose().transpose.transpose().transpose.transpose", "x_conv.transpose().transpose.transpose().transpose.transpose", "tcn_bi.TCN.linear_net", "tcn_bi.TCN.get_span", "tcn_bi.TCN.flip"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.get_span", "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.get_attention", "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.get_attention", "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.get_span"], ["", "def", "forward", "(", "self", ",", "x", ",", "seq_len_data", ")", ":", "\n", "        ", "seq_len", "=", "x", ".", "size", "(", "0", ")", "\n", "batch_size", "=", "x", ".", "size", "(", "1", ")", "\n", "\n", "# x = self.lockdrop(x, 0.4)", "\n", "\n", "ones", "=", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ".", "cuda", "(", ")", "\n", "shifter_down", "=", "ones", ".", "tril", "(", "-", "1", ")", "-", "ones", ".", "tril", "(", "-", "2", ")", "\n", "shifter_up", "=", "ones", ".", "triu", "(", "1", ")", "-", "ones", ".", "triu", "(", "2", ")", "\n", "# '''", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x_conv", "=", "self", ".", "conv_net", "(", "x", ")", "\n", "x_conv", "=", "x_conv", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# '''", "\n", "# x_conv = x", "\n", "x_output", "=", "self", ".", "linear_net", "(", "x_conv", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "x_shift_down", "=", "torch", ".", "mm", "(", "shifter_down", ",", "x_output", ")", "\n", "x_shift_up", "=", "torch", ".", "mm", "(", "shifter_up", ",", "x_output", ")", "\n", "\n", "span", "=", "self", ".", "get_span", "(", "x_output", ",", "ones", ",", "x_shift_down", ",", "shifter_up", ",", "\n", "self", ".", "hardtanh1", ",", "self", ".", "hardtanh2", ",", "1", ")", "\n", "\n", "span_context", "=", "self", ".", "get_span", "(", "x_output", ".", "flip", "(", "[", "0", "]", ")", ",", "ones", ",", "x_shift_down", ",", "x_shift_up", ",", "\n", "self", ".", "hardtanh3", ",", "self", ".", "hardtanh4", ",", "-", "1", ")", ".", "flip", "(", "[", "0", ",", "1", "]", ")", "\n", "\n", "attention_p", "=", "self", ".", "get_attention", "(", "span", ",", "x_output", ")", "\n", "attention_c", "=", "self", ".", "get_attention", "(", "span_context", ",", "x_output", ")", "\n", "\n", "reg_len", "=", "0", "\n", "# len_mask = ones.triu(9).unsqueeze(2)", "\n", "# reg_len = (span * len_mask).pow(2).mean()", "\n", "\n", "# attention = attention[:seq_len_data]", "\n", "# attention = span_scores / (span_scores.sum(1, keepdim=True) + 1e-4)", "\n", "return", "attention_p", ",", "attention_c", ",", "seq_len_data", ",", "reg_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn_bi.TCN.forward_raw": [[128, 145], ["x.transpose().transpose.transpose().transpose.size", "x.transpose().transpose.transpose().transpose.transpose().transpose", "tcn_bi.TCN.conv_net", "x_conv.transpose().transpose.transpose().transpose.transpose().transpose", "tcn_bi.TCN.linear_net", "tcn_bi.TCN.unsqueeze", "tcn_bi.TCN.unsqueeze", "tcn_bi.TCN.ht", "torch.ones().cuda().tril", "torch.ones().cuda().tril", "torch.ones().cuda().tril", "torch.ones().cuda().tril", "torch.ones().cuda().triu", "torch.ones().cuda().triu", "torch.ones().cuda().triu", "torch.ones().cuda().triu", "mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "mask_right.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "tcn_bi.TCN.cumprod", "x.transpose().transpose.transpose().transpose.transpose", "x_conv.transpose().transpose.transpose().transpose.transpose", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "mask_right.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht"], ["", "def", "forward_raw", "(", "self", ",", "x", ")", ":", "\n", "        ", "seq_len", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x_conv", "=", "self", ".", "conv_net", "(", "x", ")", "\n", "x_conv", "=", "x_conv", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x_output", "=", "self", ".", "linear_net", "(", "x_conv", ")", "\n", "x_row", "=", "x_output", ".", "unsqueeze", "(", "0", ")", "\n", "x_column", "=", "x_output", ".", "unsqueeze", "(", "1", ")", "\n", "x_square", "=", "self", ".", "ht", "(", "x_column", "-", "x_row", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ".", "cuda", "(", ")", ".", "tril", "(", ")", "\n", "mask_right", "=", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ".", "cuda", "(", ")", ".", "triu", "(", "diagonal", "=", "10", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "mask_right", "=", "mask_right", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# x_square *= mask_right", "\n", "x_square", "=", "mask", "+", "(", "1", "-", "mask", ")", "*", "x_square", "\n", "x_square", "=", "x_square", ".", "cumprod", "(", "dim", "=", "1", ")", "*", "(", "1", "-", "mask", ")", "\n", "return", "x_square", "\n", "", "", ""]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.splitcross.SplitCrossEntropyLoss.__init__": [[11, 25], ["torch.Module.__init__", "collections.defaultdict", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "splits", ",", "verbose", "=", "False", ")", ":", "\n", "# We assume splits is [0, split1, split2, N] where N >= |V|", "\n", "# For example, a vocab of 1000 words may have splits [0] + [100, 500] + [inf]", "\n", "        ", "super", "(", "SplitCrossEntropyLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "splits", "=", "[", "0", "]", "+", "splits", "+", "[", "100", "*", "1000000", "]", "\n", "self", ".", "nsplits", "=", "len", "(", "self", ".", "splits", ")", "-", "1", "\n", "self", ".", "stats", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "verbose", "=", "verbose", "\n", "# Each of the splits that aren't in the head require a pretend token, we'll call them tombstones", "\n", "# The probability given to this tombstone is the probability of selecting an item from the represented split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "            ", "self", ".", "tail_vectors", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "nsplits", "-", "1", ",", "hidden_size", ")", ")", "\n", "self", ".", "tail_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "nsplits", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.splitcross.SplitCrossEntropyLoss.logprob": [[26, 71], ["torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "list", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "results.append", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "softmaxed_head_res[].contiguous", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "results.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "softmaxed_head_res[].contiguous.view"], "methods", ["None"], ["", "", "def", "logprob", "(", "self", ",", "weight", ",", "bias", ",", "hiddens", ",", "splits", "=", "None", ",", "softmaxed_head_res", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "# First we perform the first softmax on the head vocabulary and the tombstones", "\n", "        ", "if", "softmaxed_head_res", "is", "None", ":", "\n", "            ", "start", ",", "end", "=", "self", ".", "splits", "[", "0", "]", ",", "self", ".", "splits", "[", "1", "]", "\n", "head_weight", "=", "None", "if", "end", "-", "start", "==", "0", "else", "weight", "[", "start", ":", "end", "]", "\n", "head_bias", "=", "None", "if", "end", "-", "start", "==", "0", "else", "bias", "[", "start", ":", "end", "]", "\n", "# We only add the tombstones if we have more than one split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "                ", "head_weight", "=", "self", ".", "tail_vectors", "if", "head_weight", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_weight", ",", "self", ".", "tail_vectors", "]", ")", "\n", "head_bias", "=", "self", ".", "tail_bias", "if", "head_bias", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_bias", ",", "self", ".", "tail_bias", "]", ")", "\n", "\n", "# Perform the softmax calculation for the word vectors in the head for all splits", "\n", "# We need to guard against empty splits as torch.cat does not like random lists", "\n", "", "head_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "hiddens", ",", "head_weight", ",", "bias", "=", "head_bias", ")", "\n", "softmaxed_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "head_res", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "if", "splits", "is", "None", ":", "\n", "            ", "splits", "=", "list", "(", "range", "(", "self", ".", "nsplits", ")", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "running_offset", "=", "0", "\n", "for", "idx", "in", "splits", ":", "\n", "\n", "# For those targets in the head (idx == 0) we only need to return their loss", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "results", ".", "append", "(", "softmaxed_head_res", "[", ":", ",", ":", "-", "(", "self", ".", "nsplits", "-", "1", ")", "]", ")", "\n", "\n", "# If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)", "\n", "", "else", ":", "\n", "                ", "start", ",", "end", "=", "self", ".", "splits", "[", "idx", "]", ",", "self", ".", "splits", "[", "idx", "+", "1", "]", "\n", "tail_weight", "=", "weight", "[", "start", ":", "end", "]", "\n", "tail_bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "\n", "# Calculate the softmax for the words in the tombstone", "\n", "tail_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "hiddens", ",", "tail_weight", ",", "bias", "=", "tail_bias", ")", "\n", "\n", "# Then we calculate p(tombstone) * p(word in tombstone)", "\n", "# Adding is equivalent to multiplication in log space", "\n", "head_entropy", "=", "(", "softmaxed_head_res", "[", ":", ",", "-", "idx", "]", ")", ".", "contiguous", "(", ")", "\n", "tail_entropy", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "tail_res", ",", "dim", "=", "-", "1", ")", "\n", "results", ".", "append", "(", "head_entropy", ".", "view", "(", "-", "1", ",", "1", ")", "+", "tail_entropy", ")", "\n", "\n", "", "", "if", "len", "(", "results", ")", ">", "1", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "results", ",", "dim", "=", "1", ")", "\n", "", "return", "results", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.splitcross.SplitCrossEntropyLoss.split_on_targets": [[72, 105], ["range", "range", "split_targets.append", "split_hiddens.append", "sum", "len", "split_targets.append", "split_hiddens.append", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "hiddens.masked_select().view", "hiddens.size", "len", "hiddens.masked_select", "tmp_mask.unsqueeze().expand_as", "tmp_mask.unsqueeze"], "methods", ["None"], ["", "def", "split_on_targets", "(", "self", ",", "hiddens", ",", "targets", ")", ":", "\n", "# Split the targets into those in the head and in the tail", "\n", "        ", "split_targets", "=", "[", "]", "\n", "split_hiddens", "=", "[", "]", "\n", "\n", "# Determine to which split each element belongs (for each start split value, add 1 if equal or greater)", "\n", "# This method appears slower at least for WT-103 values for approx softmax", "\n", "#masks = [(targets >= self.splits[idx]).view(1, -1) for idx in range(1, self.nsplits)]", "\n", "#mask = torch.sum(torch.cat(masks, dim=0), dim=0)", "\n", "###", "\n", "# This is equally fast for smaller splits as method below but scales linearly", "\n", "mask", "=", "None", "\n", "for", "idx", "in", "range", "(", "1", ",", "self", ".", "nsplits", ")", ":", "\n", "            ", "partial_mask", "=", "targets", ">=", "self", ".", "splits", "[", "idx", "]", "\n", "mask", "=", "mask", "+", "partial_mask", "if", "mask", "is", "not", "None", "else", "partial_mask", "\n", "###", "\n", "#masks = torch.stack([targets] * (self.nsplits - 1))", "\n", "#mask = torch.sum(masks >= self.split_starts, dim=0)", "\n", "", "for", "idx", "in", "range", "(", "self", ".", "nsplits", ")", ":", "\n", "# If there are no splits, avoid costly masked select", "\n", "            ", "if", "self", ".", "nsplits", "==", "1", ":", "\n", "                ", "split_targets", ",", "split_hiddens", "=", "[", "targets", "]", ",", "[", "hiddens", "]", "\n", "continue", "\n", "# If all the words are covered by earlier targets, we have empties so later stages don't freak out", "\n", "", "if", "sum", "(", "len", "(", "t", ")", "for", "t", "in", "split_targets", ")", "==", "len", "(", "targets", ")", ":", "\n", "                ", "split_targets", ".", "append", "(", "[", "]", ")", "\n", "split_hiddens", ".", "append", "(", "[", "]", ")", "\n", "continue", "\n", "# Are you in our split?", "\n", "", "tmp_mask", "=", "mask", "==", "idx", "\n", "split_targets", ".", "append", "(", "torch", ".", "masked_select", "(", "targets", ",", "tmp_mask", ")", ")", "\n", "split_hiddens", ".", "append", "(", "hiddens", ".", "masked_select", "(", "tmp_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "hiddens", ")", ")", ".", "view", "(", "-", "1", ",", "hiddens", ".", "size", "(", "1", ")", ")", ")", "\n", "", "return", "split_targets", ",", "split_hiddens", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.splitcross.SplitCrossEntropyLoss.forward": [[106, 170], ["splitcross.SplitCrossEntropyLoss.split_on_targets", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "range", "sorted", "print", "len", "hiddens.view.view.view", "splitcross.SplitCrossEntropyLoss.stats[].append", "len", "print", "hiddens.view.view.size", "hiddens.view.view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "splitcross.SplitCrossEntropyLoss.logprob", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "entropy.float().sum", "range", "len", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "splitcross.SplitCrossEntropyLoss.stats[].append", "entropy.float().sum", "len", "int", "torch.cat.size", "torch.cat.size", "head_weight.size", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "entropy.float", "numpy.mean", "len", "split_targets[].view", "len", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "entropy.float", "split_hiddens[].size", "tail_weight.size"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.splitcross.SplitCrossEntropyLoss.split_on_targets", "home.repos.pwc.inspect_result.luohongyin_PILM.None.splitcross.SplitCrossEntropyLoss.logprob"], ["", "def", "forward", "(", "self", ",", "weight", ",", "bias", ",", "hiddens", ",", "targets", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "            ", "for", "idx", "in", "sorted", "(", "self", ".", "stats", ")", ":", "\n", "                ", "print", "(", "'{}: {}'", ".", "format", "(", "idx", ",", "int", "(", "np", ".", "mean", "(", "self", ".", "stats", "[", "idx", "]", ")", ")", ")", ",", "end", "=", "', '", ")", "\n", "", "print", "(", ")", "\n", "\n", "", "total_loss", "=", "None", "\n", "if", "len", "(", "hiddens", ".", "size", "(", ")", ")", ">", "2", ":", "hiddens", "=", "hiddens", ".", "view", "(", "-", "1", ",", "hiddens", ".", "size", "(", "2", ")", ")", "\n", "\n", "split_targets", ",", "split_hiddens", "=", "self", ".", "split_on_targets", "(", "hiddens", ",", "targets", ")", "\n", "\n", "# First we perform the first softmax on the head vocabulary and the tombstones", "\n", "start", ",", "end", "=", "self", ".", "splits", "[", "0", "]", ",", "self", ".", "splits", "[", "1", "]", "\n", "head_weight", "=", "None", "if", "end", "-", "start", "==", "0", "else", "weight", "[", "start", ":", "end", "]", "\n", "head_bias", "=", "None", "if", "end", "-", "start", "==", "0", "else", "bias", "[", "start", ":", "end", "]", "\n", "\n", "# We only add the tombstones if we have more than one split", "\n", "if", "self", ".", "nsplits", ">", "1", ":", "\n", "            ", "head_weight", "=", "self", ".", "tail_vectors", "if", "head_weight", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_weight", ",", "self", ".", "tail_vectors", "]", ")", "\n", "head_bias", "=", "self", ".", "tail_bias", "if", "head_bias", "is", "None", "else", "torch", ".", "cat", "(", "[", "head_bias", ",", "self", ".", "tail_bias", "]", ")", "\n", "\n", "# Perform the softmax calculation for the word vectors in the head for all splits", "\n", "# We need to guard against empty splits as torch.cat does not like random lists", "\n", "", "combo", "=", "torch", ".", "cat", "(", "[", "split_hiddens", "[", "i", "]", "for", "i", "in", "range", "(", "self", ".", "nsplits", ")", "if", "len", "(", "split_hiddens", "[", "i", "]", ")", "]", ")", "\n", "###", "\n", "all_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "combo", ",", "head_weight", ",", "bias", "=", "head_bias", ")", "\n", "softmaxed_all_head_res", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "all_head_res", ",", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "            ", "self", ".", "stats", "[", "0", "]", ".", "append", "(", "combo", ".", "size", "(", ")", "[", "0", "]", "*", "head_weight", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "running_offset", "=", "0", "\n", "for", "idx", "in", "range", "(", "self", ".", "nsplits", ")", ":", "\n", "# If there are no targets for this split, continue", "\n", "            ", "if", "len", "(", "split_targets", "[", "idx", "]", ")", "==", "0", ":", "continue", "\n", "\n", "# For those targets in the head (idx == 0) we only need to return their loss", "\n", "if", "idx", "==", "0", ":", "\n", "                ", "softmaxed_head_res", "=", "softmaxed_all_head_res", "[", "running_offset", ":", "running_offset", "+", "len", "(", "split_hiddens", "[", "idx", "]", ")", "]", "\n", "entropy", "=", "-", "torch", ".", "gather", "(", "softmaxed_head_res", ",", "dim", "=", "1", ",", "index", "=", "split_targets", "[", "idx", "]", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "# If the target is in one of the splits, the probability is the p(tombstone) * p(word within tombstone)", "\n", "", "else", ":", "\n", "                ", "softmaxed_head_res", "=", "softmaxed_all_head_res", "[", "running_offset", ":", "running_offset", "+", "len", "(", "split_hiddens", "[", "idx", "]", ")", "]", "\n", "\n", "if", "self", ".", "verbose", "or", "verbose", ":", "\n", "                    ", "start", ",", "end", "=", "self", ".", "splits", "[", "idx", "]", ",", "self", ".", "splits", "[", "idx", "+", "1", "]", "\n", "tail_weight", "=", "weight", "[", "start", ":", "end", "]", "\n", "self", ".", "stats", "[", "idx", "]", ".", "append", "(", "split_hiddens", "[", "idx", "]", ".", "size", "(", ")", "[", "0", "]", "*", "tail_weight", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "# Calculate the softmax for the words in the tombstone", "\n", "", "tail_res", "=", "self", ".", "logprob", "(", "weight", ",", "bias", ",", "split_hiddens", "[", "idx", "]", ",", "splits", "=", "[", "idx", "]", ",", "softmaxed_head_res", "=", "softmaxed_head_res", ")", "\n", "\n", "# Then we calculate p(tombstone) * p(word in tombstone)", "\n", "# Adding is equivalent to multiplication in log space", "\n", "head_entropy", "=", "softmaxed_head_res", "[", ":", ",", "-", "idx", "]", "\n", "# All indices are shifted - if the first split handles [0,...,499] then the 500th in the second split will be 0 indexed", "\n", "indices", "=", "(", "split_targets", "[", "idx", "]", "-", "self", ".", "splits", "[", "idx", "]", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# Warning: if you don't squeeze, you get an N x 1 return, which acts oddly with broadcasting", "\n", "tail_entropy", "=", "torch", ".", "gather", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "tail_res", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "1", ",", "index", "=", "indices", ")", ".", "squeeze", "(", ")", "\n", "entropy", "=", "-", "(", "head_entropy", "+", "tail_entropy", ")", "\n", "###", "\n", "", "running_offset", "+=", "len", "(", "split_hiddens", "[", "idx", "]", ")", "\n", "total_loss", "=", "entropy", ".", "float", "(", ")", ".", "sum", "(", ")", "if", "total_loss", "is", "None", "else", "total_loss", "+", "entropy", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "\n", "", "return", "(", "total_loss", "/", "len", "(", "targets", ")", ")", ".", "type_as", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.pointer.one_hot": [[52, 58], ["numpy.zeros", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "v.cuda.cuda"], "function", ["None"], ["def", "one_hot", "(", "idx", ",", "size", ",", "cuda", "=", "True", ")", ":", "\n", "    ", "a", "=", "np", ".", "zeros", "(", "(", "1", ",", "size", ")", ",", "np", ".", "float32", ")", "\n", "a", "[", "0", "]", "[", "idx", "]", "=", "1", "\n", "v", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "a", ")", ")", "\n", "if", "cuda", ":", "v", "=", "v", ".", "cuda", "(", ")", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.pointer.evaluate": [[59, 116], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "model.decoder", "rnn_outs[].squeeze", "print", "model.decoder.view", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "enumerate", "utils.repackage_hidden", "len", "data_source.size", "print", "model.decoder.size", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.cat", "torch.cat", "len", "math.exp", "torch.mv", "torch.mv", "torch.nn.functional.softmax().view", "torch.nn.functional.softmax().view", "pointer.one_hot", "torch.cat", "torch.cat", "torch.autograd.Variable", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.log", "torch.log", "pointer.one_hot", "torch.nn.functional.softmax().view.expand_as"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.pointer.one_hot", "home.repos.pwc.inspect_result.luohongyin_PILM.None.pointer.one_hot"], ["", "def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ",", "window", "=", "args", ".", "window", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "next_word_history", "=", "None", "\n", "pointer_history", "=", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "if", "i", ">", "0", ":", "print", "(", "i", ",", "len", "(", "data_source", ")", ",", "math", ".", "exp", "(", "total_loss", "/", "i", ")", ")", "\n", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "evaluation", "=", "True", ",", "args", "=", "args", ")", "\n", "output", ",", "hidden", ",", "rnn_outs", ",", "_", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "output", "=", "model", ".", "decoder", "(", "output", ")", "\n", "rnn_out", "=", "rnn_outs", "[", "-", "1", "]", ".", "squeeze", "(", ")", "\n", "print", "(", "output", ".", "size", "(", ")", ")", "\n", "output_flat", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "###", "\n", "# Fill pointer history", "\n", "start_idx", "=", "len", "(", "next_word_history", ")", "if", "next_word_history", "is", "not", "None", "else", "0", "\n", "next_word_history", "=", "torch", ".", "cat", "(", "[", "one_hot", "(", "t", ".", "data", "[", "0", "]", ",", "ntokens", ")", "for", "t", "in", "targets", "]", ")", "if", "next_word_history", "is", "None", "else", "torch", ".", "cat", "(", "[", "next_word_history", ",", "torch", ".", "cat", "(", "[", "one_hot", "(", "t", ".", "data", "[", "0", "]", ",", "ntokens", ")", "for", "t", "in", "targets", "]", ")", "]", ")", "\n", "#print(next_word_history)", "\n", "pointer_history", "=", "Variable", "(", "rnn_out", ".", "data", ")", "if", "pointer_history", "is", "None", "else", "torch", ".", "cat", "(", "[", "pointer_history", ",", "Variable", "(", "rnn_out", ".", "data", ")", "]", ",", "dim", "=", "0", ")", "\n", "#print(pointer_history)", "\n", "###", "\n", "# Built-in cross entropy", "\n", "# total_loss += len(data) * criterion(output_flat, targets).data[0]", "\n", "###", "\n", "# Manual cross entropy", "\n", "# softmax_output_flat = torch.nn.functional.softmax(output_flat)", "\n", "# soft = torch.gather(softmax_output_flat, dim=1, index=targets.view(-1, 1))", "\n", "# entropy = -torch.log(soft)", "\n", "# total_loss += len(data) * entropy.mean().data[0]", "\n", "###", "\n", "# Pointer manual cross entropy", "\n", "loss", "=", "0", "\n", "softmax_output_flat", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "output_flat", ")", "\n", "for", "idx", ",", "vocab_loss", "in", "enumerate", "(", "softmax_output_flat", ")", ":", "\n", "            ", "p", "=", "vocab_loss", "\n", "if", "start_idx", "+", "idx", ">", "window", ":", "\n", "                ", "valid_next_word", "=", "next_word_history", "[", "start_idx", "+", "idx", "-", "window", ":", "start_idx", "+", "idx", "]", "\n", "valid_pointer_history", "=", "pointer_history", "[", "start_idx", "+", "idx", "-", "window", ":", "start_idx", "+", "idx", "]", "\n", "logits", "=", "torch", ".", "mv", "(", "valid_pointer_history", ",", "rnn_out", "[", "idx", "]", ")", "\n", "theta", "=", "args", ".", "theta", "\n", "ptr_attn", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "theta", "*", "logits", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "ptr_dist", "=", "(", "ptr_attn", ".", "expand_as", "(", "valid_next_word", ")", "*", "valid_next_word", ")", ".", "sum", "(", "0", ")", ".", "squeeze", "(", ")", "\n", "lambdah", "=", "args", ".", "lambdasm", "\n", "p", "=", "lambdah", "*", "ptr_dist", "+", "(", "1", "-", "lambdah", ")", "*", "vocab_loss", "\n", "###", "\n", "", "target_loss", "=", "p", "[", "targets", "[", "idx", "]", ".", "data", "]", "\n", "loss", "+=", "(", "-", "torch", ".", "log", "(", "target_loss", ")", ")", ".", "data", "[", "0", "]", "\n", "", "total_loss", "+=", "loss", "/", "batch_size", "\n", "###", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "next_word_history", "=", "next_word_history", "[", "-", "window", ":", "]", "\n", "pointer_history", "=", "pointer_history", "[", "-", "window", ":", "]", "\n", "", "return", "total_loss", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main.model_save": [[87, 90], ["open", "torch.save", "torch.save"], "function", ["None"], ["", "", "def", "model_save", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "[", "model_lm", ",", "model_r", ",", "criterion", ",", "optimizer", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main.model_load": [[91, 95], ["open", "torch.load", "torch.load"], "function", ["None"], ["", "", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "global", "model_lm", ",", "criterion", ",", "optimizer", "\n", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model_lm", ",", "model_r", ",", "criterion", ",", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main.evaluate": [[163, 176], ["model_lm.eval", "len", "model_lm.init_hidden", "range", "model_lm.reset", "utils.get_batch", "model_lm", "utils.repackage_hidden", "total_loss.item", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model_lm", ".", "eval", "(", ")", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model_lm", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", "=", "model_lm", "(", "data", ",", "hidden", ")", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main.train": [[178, 262], ["time.time", "len", "model_lm.init_hidden", "model_r.init_hidden", "model.reset", "max", "model_lm.train", "model_r.train", "utils.get_batch", "data.flip", "utils.repackage_hidden", "model_r.init_hidden", "optimizer.zero_grad", "model_lm", "model_r", "criterion", "loss.backward", "optimizer.step", "int", "criterion", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "sum", "sum", "sum", "sum", "dropped_rnn_hs[].size", "dropped_rnn_hs_r[].size", "dropped_rnn_hs_r[].flip", "total_loss.item", "time.time", "math.exp", "len", "math.log", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "hidden_r", "=", "model_r", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "split_idx_seq", "=", "7", "\n", "split_idx_batch", "=", "7", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model_lm", ".", "train", "(", ")", "\n", "model_r", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "targets_r", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "data_r", "=", "data", ".", "flip", "(", "[", "0", "]", ")", "\n", "# targets_r = targets_r.flip([0])", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "hidden_r", "=", "model_r", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "output_r", ",", "hidden_r", ",", "rnn_hs_r", ",", "dropped_rnn_hs_r", "=", "model_r", "(", "data_r", ",", "hidden_r", ",", "return_h", "=", "True", ")", "\n", "\n", "raw_loss", "=", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", "\n", "if", "i", "!=", "0", ":", "raw_loss", "+=", "criterion", "(", "model_r", ".", "decoder", ".", "weight", ",", "model_r", ".", "decoder", ".", "bias", ",", "output_r", ",", "targets_r", ")", "\n", "# if i != 0: raw_loss += 0 * criterion(model_r.decoder.weight, model_r.decoder.bias, output_r, targets_r)", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs_r", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", ":", "-", "1", "]", "-", "rnn_h", "[", "1", ":", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs_r", "[", "-", "1", ":", "]", ")", "\n", "\n", "if", "dropped_rnn_hs", "[", "-", "1", "]", ".", "size", "(", "0", ")", ">", "2", "and", "dropped_rnn_hs_r", "[", "-", "1", "]", ".", "size", "(", "0", ")", ">", "2", ":", "\n", "            ", "outputl", "=", "dropped_rnn_hs", "[", "-", "1", "]", "[", ":", "-", "2", "]", "\n", "outputl_r", "=", "dropped_rnn_hs_r", "[", "-", "1", "]", ".", "flip", "(", "[", "0", "]", ")", "[", "2", ":", "]", "\n", "'''\n            if args.ns:\n                outputl_r_t = outputl_r.transpose(0, 1)\n                outputl_r_neg = torch.cat([outputl_r_t[:split_idx_batch], outputl_r_t[split_idx_batch:]], 0).transpose(0, 1)\n                outputl_r_neg = torch.cat([outputl_r_neg[:split_idx_seq], outputl_r_neg[split_idx_seq:]], 0)\n                pos_loss = (1 - (outputl * outputl_r).sum(2).sigmoid()).sum()\n                neg_loss = (outputl * outputl_r_neg).sum(2).sigmoid().sum()\n                loss += args.theta * (pos_loss + neg_loss)\n                split_idx_seq = (split_idx_seq * 7) % args.bptt\n                split_idx_batch = (split_idx_batch * 7) % args.batch_size\n            else:\n                loss = loss + args.theta * (outputl - outputl_r).pow(2).mean()\n            '''", "\n", "loss", "=", "loss", "+", "args", ".", "theta", "*", "(", "outputl", "-", "outputl_r", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "if", "args", ".", "clip", ":", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span_lstm2tcn.model_save": [[88, 91], ["open", "torch.save", "torch.save"], "function", ["None"], ["", "", "def", "model_save", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "[", "model_lm", ",", "model_r", ",", "model_mlp", ",", "criterion", ",", "optimizer", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span_lstm2tcn.model_load": [[92, 96], ["open", "torch.load", "torch.load"], "function", ["None"], ["", "", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "global", "model_lm", ",", "criterion", ",", "optimizer", "\n", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model_lm", ",", "model_r", ",", "model_mlp", ",", "criterion", ",", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span_lstm2tcn.evaluate": [[173, 189], ["model_lm.eval", "len", "model_lm.init_hidden", "range", "model_lm.reset", "utils.get_batch", "model_lm", "utils.repackage_hidden", "total_loss.item", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model_lm", ".", "eval", "(", ")", "\n", "# model_mlp.eval()", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model_lm", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", ",", "_", ",", "all_outputs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "# output = model_mlp(all_outputs[-1]) + all_outputs[-1]", "\n", "# output = output.view(output.size(0)*output.size(1), output.size(2))", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span_lstm2tcn.train": [[191, 309], ["time.time", "len", "model_lm.init_hidden", "model.reset", "max", "model_lm.train", "model_r.train", "model_mlp.train", "utils.get_batch", "utils.repackage_hidden", "optimizer.zero_grad", "model_lm", "model_lm.encoder", "model_r", "model_mlp", "criterion", "loss.backward", "optimizer.step", "int", "model_mlp.transpose", "int", "int", "range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "sum", "sum", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.cat().transpose", "torch.cat().transpose", "torch.cat", "torch.cat", "int", "int", "total_loss.item", "time.time", "model_lm.encoder.unsqueeze", "int", "data.size", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "math.exp", "data.size", "torch.cat", "torch.cat", "int", "data.size", "len", "math.log", "dropped_rnn_h.pow().mean", "data.size", "data.size", "data.size", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "# hidden_r = model_r.init_hidden(args.batch_size)", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model_lm", ".", "train", "(", ")", "\n", "model_r", ".", "train", "(", ")", "\n", "model_mlp", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "targets_r", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "# data_r = data.flip([0])", "\n", "# targets_r = targets_r.flip([0])", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "# hidden_r = model_r.init_hidden(args.batch_size)", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "input_emb", "=", "model_lm", ".", "encoder", "(", "data", ")", "\n", "# attention = model_r(input_emb)", "\n", "attention", "=", "model_r", "(", "dropped_rnn_hs", "[", "-", "2", "]", ")", "\n", "span_emb", "=", "(", "input_emb", ".", "unsqueeze", "(", "0", ")", "*", "attention", ")", ".", "sum", "(", "1", ")", "\n", "# output_r, hidden_r, rnn_hs_r, dropped_rnn_hs_r = model_r(data_r, hidden_r, return_h=True)", "\n", "\n", "# output = model_mlp(dropped_rnn_hs[-1]) + dropped_rnn_hs[-1]", "\n", "# output = output.view(output.size(0)*output.size(1), output.size(2))", "\n", "\n", "span_emb", "=", "model_mlp", "(", "span_emb", ")", "# + span_emb", "\n", "\n", "raw_loss", "=", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", "\n", "# if i != 0: raw_loss += criterion(model_r.decoder.weight, model_r.decoder.bias, output_r, targets_r)", "\n", "# if i != 0: raw_loss += 0 * criterion(model_r.decoder.weight, modoyel_r.decoder.bias, output_r, targets_r)", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# if args.alpha: loss = loss + sum(args.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs_r[-1:])", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# if args.beta: loss = loss + sum(args.beta * (rnn_h[:-1] - rnn_h[1:]).pow(2).mean() for rnn_h in rnn_hs_r[-1:])", "\n", "\n", "# loss = loss + args.theta * (dropped_rnn_hs[-1] - span_emb).pow(2).mean()", "\n", "# '''", "\n", "# args.ns = False", "\n", "if", "args", ".", "ns", ":", "\n", "            ", "span_emb_t", "=", "span_emb", ".", "transpose", "(", "0", ",", "1", ")", "\n", "pos_loss", "=", "(", "1", "-", "(", "dropped_rnn_hs", "[", "-", "2", "]", "*", "span_emb", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ")", ".", "mean", "(", ")", "\n", "neg_loss", "=", "0", "\n", "\n", "split_idx_batch", "=", "int", "(", "torch", ".", "randint", "(", "args", ".", "batch_size", ",", "[", "]", ")", ")", "\n", "least_ns_seq", "=", "0", "\n", "if", "split_idx_batch", "==", "0", ":", "\n", "                ", "least_ns_seq", "=", "5", "if", "data", ".", "size", "(", "0", ")", ">", "10", "else", "int", "(", "data", ".", "size", "(", "0", ")", "/", "2", ")", "\n", "", "split_idx_seq", "=", "int", "(", "torch", ".", "randint", "(", "least_ns_seq", ",", "data", ".", "size", "(", "0", ")", ",", "[", "]", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "1", ")", ":", "\n", "                ", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_t", "[", "split_idx_batch", ":", "]", ",", "span_emb_t", "[", ":", "split_idx_batch", "]", "]", ",", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_neg", "[", "split_idx_seq", ":", "]", ",", "span_emb_neg", "[", ":", "split_idx_seq", "]", "]", ",", "0", ")", "\n", "neg_loss", "+=", "(", "dropped_rnn_hs", "[", "-", "2", "]", "*", "span_emb_neg", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ".", "mean", "(", ")", "\n", "\n", "split_idx_batch", "=", "int", "(", "torch", ".", "randint", "(", "args", ".", "batch_size", ",", "[", "]", ")", ")", "\n", "least_ns_seq", "=", "0", "\n", "if", "split_idx_batch", "==", "0", ":", "\n", "                    ", "least_ns_seq", "=", "10", "if", "data", ".", "size", "(", "0", ")", ">", "15", "else", "int", "(", "data", ".", "size", "(", "0", ")", "/", "2", ")", "\n", "", "split_idx_seq", "=", "int", "(", "torch", ".", "randint", "(", "least_ns_seq", ",", "data", ".", "size", "(", "0", ")", ",", "[", "]", ")", ")", "\n", "# print(attention.squeeze())", "\n", "# print(neg_loss)", "\n", "# print('x' + 1)", "\n", "# data_neg, _, _ = get_batch(train_data, split_idx_batch, args, seq_len = data.size(0))", "\n", "# input_emb_neg = model_lm.encoder(data_neg)", "\n", "# attention_neg = model_r(input_emb_neg)", "\n", "# span_emb_neg = (input_emb_neg.unsqueeze(0) * attention_neg).sum(1)", "\n", "# span_emb_neg = model_mlp(span_emb_neg)", "\n", "# neg_loss += (dropped_rnn_hs[-2] * span_emb_neg).sum(2).sigmoid().mean()", "\n", "# split_idx_batch = int(torch.randint(train_data.size(0) - data.size(0), []))", "\n", "\n", "# loss += 0", "\n", "", "loss", "+=", "args", ".", "theta", "*", "(", "pos_loss", "+", "neg_loss", ")", "\n", "# split_idx_seq = (split_idx_seq * 7) % args.bptt", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", "+", "args", ".", "theta", "*", "(", "dropped_rnn_hs", "[", "-", "2", "]", "-", "span_emb", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "# '''", "\n", "# print(attention.mean(2).mean(2))", "\n", "# loss += (attention > 0).float().sum() * 0.05", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "if", "args", ".", "clip", ":", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.eval.process_sentence": [[68, 75], ["s.split", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "enumerate", "torch.LongTensor.view().cuda", "torch.LongTensor.view"], "function", ["None"], ["def", "process_sentence", "(", "s", ",", "corpus", ")", ":", "\n", "    ", "words", "=", "s", ".", "split", "(", ")", "# + ['<eos>']", "\n", "num_tokens", "=", "len", "(", "words", ")", "\n", "ids", "=", "torch", ".", "LongTensor", "(", "num_tokens", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "        ", "ids", "[", "i", "]", "=", "corpus", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "", "return", "ids", ".", "view", "(", "-", "1", ",", "1", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.embed_regularize.embedded_dropout": [[5, 23], ["torch.nn.functional.embedding", "embed.weight.data.new().resize_().bernoulli_().expand_as", "scale.expand_as", "embed.weight.data.new().resize_().bernoulli_", "embed.weight.data.new().resize_", "embed.weight.data.new", "embed.weight.size"], "function", ["None"], ["def", "embedded_dropout", "(", "embed", ",", "words", ",", "dropout", "=", "0.1", ",", "scale", "=", "None", ")", ":", "\n", "  ", "if", "dropout", ":", "\n", "    ", "mask", "=", "embed", ".", "weight", ".", "data", ".", "new", "(", ")", ".", "resize_", "(", "(", "embed", ".", "weight", ".", "size", "(", "0", ")", ",", "1", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", ".", "expand_as", "(", "embed", ".", "weight", ")", "/", "(", "1", "-", "dropout", ")", "\n", "masked_embed_weight", "=", "mask", "*", "embed", ".", "weight", "\n", "", "else", ":", "\n", "    ", "masked_embed_weight", "=", "embed", ".", "weight", "\n", "", "if", "scale", ":", "\n", "    ", "masked_embed_weight", "=", "scale", ".", "expand_as", "(", "masked_embed_weight", ")", "*", "masked_embed_weight", "\n", "\n", "", "padding_idx", "=", "embed", ".", "padding_idx", "\n", "if", "padding_idx", "is", "None", ":", "\n", "      ", "padding_idx", "=", "-", "1", "\n", "\n", "", "X", "=", "torch", ".", "nn", ".", "functional", ".", "embedding", "(", "words", ",", "masked_embed_weight", ",", "\n", "padding_idx", ",", "embed", ".", "max_norm", ",", "embed", ".", "norm_type", ",", "\n", "embed", ".", "scale_grad_by_freq", ",", "embed", ".", "sparse", "\n", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop.__init__": [[6, 13], ["super().__init__", "weight_drop.WeightDrop._setup"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__", "home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop._setup"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "weights", ",", "dropout", "=", "0", ",", "variational", "=", "False", ")", ":", "\n", "        ", "super", "(", "WeightDrop", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "variational", "=", "variational", "\n", "self", ".", "_setup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop.widget_demagnetizer_y2k_edition": [[14, 20], ["None"], "methods", ["None"], ["", "def", "widget_demagnetizer_y2k_edition", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# We need to replace flatten_parameters with a nothing function", "\n", "# It must be a function rather than a lambda as otherwise pickling explodes", "\n", "# We can't write boring code though, so ... WIDGET DEMAGNETIZER Y2K EDITION!", "\n", "# (\u256f\u00b0\u25a1\u00b0\uff09\u256f\ufe35 \u253b\u2501\u253b", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop._setup": [[21, 31], ["issubclass", "type", "print", "getattr", "weight_drop.WeightDrop.module.register_parameter", "torch.nn.Parameter"], "methods", ["None"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "# Terrible temporary solution to an issue regarding compacting weights re: CUDNN RNN", "\n", "        ", "if", "issubclass", "(", "type", "(", "self", ".", "module", ")", ",", "torch", ".", "nn", ".", "RNNBase", ")", ":", "\n", "            ", "self", ".", "module", ".", "flatten_parameters", "=", "self", ".", "widget_demagnetizer_y2k_edition", "\n", "\n", "", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "print", "(", "'Applying weight drop of {} to {}'", ".", "format", "(", "self", ".", "dropout", ",", "name_w", ")", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", ")", "\n", "del", "self", ".", "module", ".", "_parameters", "[", "name_w", "]", "\n", "self", ".", "module", ".", "register_parameter", "(", "name_w", "+", "'_raw'", ",", "Parameter", "(", "w", ".", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop._setweights": [[32, 44], ["getattr", "setattr", "torch.autograd.Variable", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.ones", "mask.cuda.cuda.cuda", "mask.cuda.cuda.expand_as", "getattr.size"], "methods", ["None"], ["", "", "def", "_setweights", "(", "self", ")", ":", "\n", "        ", "for", "name_w", "in", "self", ".", "weights", ":", "\n", "            ", "raw_w", "=", "getattr", "(", "self", ".", "module", ",", "name_w", "+", "'_raw'", ")", "\n", "w", "=", "None", "\n", "if", "self", ".", "variational", ":", "\n", "                ", "mask", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "ones", "(", "raw_w", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "if", "raw_w", ".", "is_cuda", ":", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "mask", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "True", ")", "\n", "w", "=", "mask", ".", "expand_as", "(", "raw_w", ")", "*", "raw_w", "\n", "", "else", ":", "\n", "                ", "w", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "raw_w", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "", "setattr", "(", "self", ".", "module", ",", "name_w", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop.forward": [[45, 48], ["weight_drop.WeightDrop._setweights", "weight_drop.WeightDrop.module.forward"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.weight_drop.WeightDrop._setweights", "home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.forward"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_setweights", "(", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Dictionary.__init__": [[8, 13], ["collections.Counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Dictionary.add_word": [[14, 22], ["data.Dictionary.idx2word.append", "len"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "idx2word", ")", "-", "1", "\n", "", "token_id", "=", "self", ".", "word2idx", "[", "word", "]", "\n", "self", ".", "counter", "[", "token_id", "]", "+=", "1", "\n", "self", ".", "total", "+=", "1", "\n", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Dictionary.__len__": [[23, 25], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Corpus.__init__": [[28, 33], ["data.Dictionary", "data.Corpus.tokenize", "data.Corpus.tokenize", "data.Corpus.tokenize", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Corpus.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "Dictionary", "(", ")", "\n", "self", ".", "train", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "valid", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Corpus.tokenize": [[34, 57], ["os.path.exists", "open", "open", "torch.LongTensor", "len", "line.split", "data.Corpus.dictionary.add_word", "line.split"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.data.Dictionary.add_word"], ["", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "tokens", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "tokens", "+=", "len", "(", "words", ")", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n", "# Tokenize file content", "\n", "", "", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ids", "=", "torch", ".", "LongTensor", "(", "tokens", ")", "\n", "token", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "ids", "[", "token", "]", "=", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "token", "+=", "1", "\n", "\n", "", "", "", "return", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span.model_save": [[88, 91], ["open", "torch.save", "torch.save"], "function", ["None"], ["", "", "def", "model_save", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "[", "model_lm", ",", "model_r", ",", "model_mlp", ",", "criterion", ",", "optimizer", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span.model_load": [[92, 96], ["open", "torch.load", "torch.load"], "function", ["None"], ["", "", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "global", "model_lm", ",", "criterion", ",", "optimizer", "\n", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model_lm", ",", "model_r", ",", "model_mlp", ",", "criterion", ",", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span.evaluate": [[178, 194], ["model_lm.eval", "len", "model_lm.init_hidden", "range", "model_lm.reset", "utils.get_batch", "model_lm", "utils.repackage_hidden", "total_loss.item", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model_lm", ".", "eval", "(", ")", "\n", "# model_mlp.eval()", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model_lm", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", ",", "_", ",", "all_outputs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "# output = model_mlp(all_outputs[-1]) + all_outputs[-1]", "\n", "# output = output.view(output.size(0)*output.size(1), output.size(2))", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_span.train": [[196, 328], ["time.time", "len", "model_lm.init_hidden", "model.reset", "max", "model_lm.train", "model_r.train", "model_mlp.train", "utils.get_batch", "data.size", "utils.repackage_hidden", "optimizer.zero_grad", "model_lm", "model_lm.encoder", "model_r", "model_mlp", "criterion", "loss.backward", "optimizer.step", "int", "model_mlp.transpose", "int", "int", "range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "sum", "sum", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.cat().transpose", "torch.cat().transpose", "torch.cat", "torch.cat", "total_loss.item", "time.time", "model_lm.encoder.unsqueeze", "int", "data.size", "math.exp", "data.size", "torch.cat", "torch.cat", "len", "math.log", "dropped_rnn_h.pow().mean", "data.size", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "# hidden_r = model_r.init_hidden(args.batch_size)", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model_lm", ".", "train", "(", ")", "\n", "model_r", ".", "train", "(", ")", "\n", "model_mlp", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "targets_r", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "# data_long, _, _ = get_batch(train_data, i, args, seq_len=seq_len + 10)", "\n", "\n", "seq_len_data", "=", "data", ".", "size", "(", "0", ")", "\n", "# data_r = data.flip([0])", "\n", "# targets_r = targets_r.flip([0])", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "# hidden_r = model_r.init_hidden(args.batch_size)", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "\n", "input_emb", "=", "model_lm", ".", "encoder", "(", "data", ")", "\n", "# input_emb = model_lm.encoder(data).detach()", "\n", "# input_emb = model_lm.encoder(data_long)", "\n", "# input_emb = model_lm.encoder(data_long).detach()", "\n", "\n", "# input_emb_nhid = model_mlp(input_emb)", "\n", "\n", "attention", ",", "seq_len_data", ",", "reg_len", "=", "model_r", "(", "input_emb", ",", "seq_len_data", ")", "\n", "span_emb", "=", "(", "input_emb", ".", "unsqueeze", "(", "0", ")", "*", "attention", ")", ".", "sum", "(", "1", ")", "\n", "# span_emb = (input_emb_nhid.unsqueeze(0) * attention).sum(1)", "\n", "\n", "# output = model_mlp(dropped_rnn_hs[-1]) + dropped_rnn_hs[-1]", "\n", "# output = output.view(output.size(0)*output.size(1), output.size(2))", "\n", "\n", "span_emb", "=", "model_mlp", "(", "span_emb", ")", "# + span_emb", "\n", "\n", "raw_loss", "=", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", "\n", "# if i != 0: raw_loss += criterion(model_r.decoder.weight, model_r.decoder.bias, output_r, targets_r)", "\n", "# if i != 0: raw_loss += 0 * criterion(model_r.decoder.weight, modoyel_r.decoder.bias, output_r, targets_r)", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# if args.alpha: loss = loss + sum(args.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs_r[-1:])", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# if args.beta: loss = loss + sum(args.beta * (rnn_h[:-1] - rnn_h[1:]).pow(2).mean() for rnn_h in rnn_hs_r[-1:])", "\n", "\n", "# loss = loss + args.theta * (dropped_rnn_hs[-1] - span_emb).pow(2).mean()", "\n", "# '''", "\n", "# args.ns = False", "\n", "context_emb", "=", "dropped_rnn_hs", "[", "-", "2", "]", "[", ":", "seq_len_data", "]", "\n", "# context_emb = dropped_rnn_hs[-2].detach()", "\n", "if", "args", ".", "ns", ":", "\n", "            ", "span_emb_t", "=", "span_emb", ".", "transpose", "(", "0", ",", "1", ")", "\n", "pos_loss", "=", "(", "1", "-", "(", "context_emb", "*", "span_emb", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ")", ".", "mean", "(", ")", "\n", "neg_loss", "=", "0", "\n", "\n", "split_idx_batch", "=", "int", "(", "torch", ".", "randint", "(", "args", ".", "batch_size", ",", "[", "]", ")", ")", "\n", "# split_idx_batch = int(torch.randint(1, args.batch_size, []))", "\n", "least_ns_seq", "=", "0", "\n", "if", "split_idx_batch", "==", "0", ":", "\n", "                ", "least_ns_seq", "=", "10", "if", "data", ".", "size", "(", "0", ")", ">", "15", "else", "int", "(", "data", ".", "size", "(", "0", ")", "/", "2", ")", "\n", "", "split_idx_seq", "=", "int", "(", "torch", ".", "randint", "(", "least_ns_seq", ",", "data", ".", "size", "(", "0", ")", ",", "[", "]", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "0", ")", ":", "\n", "                ", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_t", "[", "split_idx_batch", ":", "]", ",", "span_emb_t", "[", ":", "split_idx_batch", "]", "]", ",", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_neg", "[", "split_idx_seq", ":", "]", ",", "span_emb_neg", "[", ":", "split_idx_seq", "]", "]", ",", "0", ")", "\n", "neg_loss", "+=", "(", "context_emb", "*", "span_emb_neg", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ".", "mean", "(", ")", "\n", "\n", "# split_idx_batch = int(torch.randint(args.batch_size, []))", "\n", "# split_idx_batch = int(torch.randint(1, args.batch_size, []))", "\n", "# least_ns_seq = 0", "\n", "# if split_idx_batch == 0:", "\n", "#     least_ns_seq = 10 if data.size(0) > 15 else int(data.size(0) / 2)", "\n", "# split_idx_seq = int(torch.randint(least_ns_seq, data.size(0), []))", "\n", "# print(attention.squeeze())", "\n", "# print(neg_loss)", "\n", "# print('x' + 1)", "\n", "# data_neg, _, _ = get_batch(train_data, split_idx_batch, args, seq_len = data.size(0))", "\n", "# input_emb_neg = model_lm.encoder(data_neg)", "\n", "# attention_neg = model_r(input_emb_neg)", "\n", "# span_emb_neg = (input_emb_neg.unsqueeze(0) * attention_neg).sum(1)", "\n", "# span_emb_neg = model_mlp(span_emb_neg)", "\n", "# neg_loss += (dropped_rnn_hs[-2] * span_emb_neg).sum(2).sigmoid().mean()", "\n", "# split_idx_batch = int(torch.randint(train_data.size(0) - data.size(0), []))", "\n", "\n", "# loss += 0", "\n", "# loss += args.theta * (pos_loss + neg_loss)", "\n", "", "loss", "+=", "args", ".", "theta", "*", "(", "pos_loss", "+", "neg_loss", ")", "# + 1e-6 * reg_len", "\n", "# split_idx_seq = (split_idx_seq * 7) % args.bptt", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", "+", "args", ".", "theta", "*", "(", "context_emb", "-", "span_emb", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "# '''", "\n", "# print(attention.mean(2).mean(2))", "\n", "# loss += (attention > 0).float().sum() * 0.05", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "if", "args", ".", "clip", ":", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.finetune.evaluate": [[104, 119], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "model.decoder", "model.decoder.view", "utils.repackage_hidden", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "output", "=", "model", ".", "decoder", "(", "output", ")", "\n", "output_flat", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "output_flat", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", "[", "0", "]", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.finetune.train": [[121, 175], ["time.time", "len", "model.init_hidden", "model.reset", "max", "min", "model.train", "utils.get_batch", "utils.repackage_hidden", "optimizer.zero_grad", "model", "model.decoder", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer.step", "int", "model.decoder.view", "sum", "sum", "model.parameters", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "time.time", "math.exp", "dropped_rnn_h.pow().mean", "len", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "seq_len", "=", "min", "(", "seq_len", ",", "args", ".", "bptt", "+", "10", ")", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "output", "=", "model", ".", "decoder", "(", "output", ")", "\n", "raw_loss", "=", "criterion", "(", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", "[", "0", "]", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.Chomp1d.__init__": [[8, 11], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ",", "chomp_size", ")", ":", "\n", "        ", "super", "(", "Chomp1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chomp_size", "=", "chomp_size", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.Chomp1d.forward": [[12, 14], ["x[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", ":", ",", ":", ",", ":", "-", "self", ".", "chomp_size", "]", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.__init__": [[16, 48], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "tcn.Chomp1d", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "torch.Hardtanh", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_inputs", ",", "n_outputs", ",", "kernal_size", ",", "stride", ",", "dilation", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "TCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "(", "kernal_size", "-", "1", ")", "*", "dilation", "\n", "# self.lockdrop = LockedDropout()", "\n", "# padding = int((kernal_size - 1) / 2)", "\n", "# '''", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "n_inputs", ",", "n_outputs", ",", "kernal_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ")", "\n", "# self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernal_size,", "\n", "#         stride=stride, padding=padding, dilation=dilation)", "\n", "self", ".", "chomp", "=", "Chomp1d", "(", "padding", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", ")", "\n", "# self.dropout = nn.Dropout(0.2)", "\n", "# self.relu2 = nn.ReLU()", "\n", "# self.conv_net = nn.Sequential(self.conv, self.relu1)", "\n", "# self.conv_net = nn.Sequential(self.conv, self.relu1,", "\n", "#         self.conv2, self.relu2)", "\n", "self", ".", "conv_net", "=", "nn", ".", "Sequential", "(", "self", ".", "conv", ",", "self", ".", "chomp", ",", "self", ".", "relu1", ")", "\n", "# self.conv_net = nn.Sequential(self.conv, self.chomp,", "\n", "#         self.relu1, self.dropout)", "\n", "# '''", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "n_outputs", ",", "1", ")", "\n", "# self.relu_linear = nn.ReLU()", "\n", "self", ".", "linear_net", "=", "nn", ".", "Sequential", "(", "self", ".", "linear", ")", "\n", "# self.linear_net = nn.Sequential(self.linear, self.relu_linear)", "\n", "self", ".", "hardtanh1", "=", "nn", ".", "Hardtanh", "(", ")", "\n", "self", ".", "hardtanh2", "=", "nn", ".", "Hardtanh", "(", ")", "\n", "\n", "self", ".", "n_outputs_rsqrt", "=", "1", "/", "math", ".", "sqrt", "(", "n_outputs", ")", "\n", "\n", "# self.softmax = nn.Softmax(dim=1)", "\n", "self", ".", "temp", "=", "10.0", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht": [[49, 51], ["ht_func"], "methods", ["None"], ["", "def", "ht", "(", "self", ",", "ht_func", ",", "x", ")", ":", "\n", "        ", "return", "0.5", "*", "(", "ht_func", "(", "x", "*", "self", ".", "temp", ")", "+", "1", ")", "\n", "# return 0.5 * (ht_func(x * self.temp - 1 / self.temp) + 1)", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.forward": [[53, 136], ["x.transpose().transpose.transpose().transpose.size", "x.transpose().transpose.transpose().transpose.size", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "x.transpose().transpose.transpose().transpose.transpose().transpose", "tcn.TCN.conv_net", "x_conv.transpose().transpose.transpose().transpose.transpose().transpose", "tcn.TCN.linear_net().squeeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.ones().cuda.tril().unsqueeze", "torch.mm.unsqueeze", "torch.mm.unsqueeze", "tcn.TCN.unsqueeze", "tcn.TCN.ht().unsqueeze", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "tcn.TCN.pow().mean", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.triu", "torch.ones().cuda.triu", "torch.ones().cuda.triu", "torch.ones().cuda.triu", "tcn.TCN.ht", "span.unsqueeze", "x_att.unsqueeze().unsqueeze", "span_scores.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x.transpose().transpose.transpose().transpose.transpose", "x_conv.transpose().transpose.transpose().transpose.transpose", "tcn.TCN.linear_net", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "torch.ones().cuda.tril", "tcn.TCN.ht", "tcn.TCN.min", "tcn.TCN.pow", "x_att.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht", "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht"], ["", "def", "forward", "(", "self", ",", "x", ",", "seq_len_data", ")", ":", "\n", "        ", "seq_len", "=", "x", ".", "size", "(", "0", ")", "\n", "batch_size", "=", "x", ".", "size", "(", "1", ")", "\n", "\n", "# x = self.lockdrop(x, 0.4)", "\n", "\n", "ones", "=", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ".", "cuda", "(", ")", "\n", "shifter_down", "=", "ones", ".", "tril", "(", "-", "1", ")", "-", "ones", ".", "tril", "(", "-", "2", ")", "\n", "shifter_up", "=", "ones", ".", "triu", "(", "1", ")", "-", "ones", ".", "triu", "(", "2", ")", "\n", "# '''", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x_conv", "=", "self", ".", "conv_net", "(", "x", ")", "\n", "x_conv", "=", "x_conv", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# '''", "\n", "# x_conv = x", "\n", "x_output", "=", "self", ".", "linear_net", "(", "x_conv", ")", ".", "squeeze", "(", "2", ")", "\n", "# x_output *= self.n_outputs_rsqrt", "\n", "# print(x_output)", "\n", "\n", "x_shift_down", "=", "torch", ".", "mm", "(", "shifter_down", ",", "x_output", ")", "\n", "x_shift_up", "=", "torch", ".", "mm", "(", "shifter_up", ",", "x_output", ")", "\n", "\n", "mask", "=", "ones", ".", "tril", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "mask2", "=", "ones", ".", "tril", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "mask_shift", "=", "ones", ".", "tril", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "mask_shift2", "=", "ones", ".", "tril", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "x_row", "=", "x_shift_down", ".", "unsqueeze", "(", "0", ")", "\n", "x_column", "=", "x_output", ".", "unsqueeze", "(", "1", ")", "\n", "# x_column = x_shift_up.unsqueeze(1)", "\n", "x_square1", "=", "x_row", "-", "x_column", "\n", "# square_1 = (x_square1 < 0).float()", "\n", "square_1", "=", "self", ".", "ht", "(", "self", ".", "hardtanh1", ",", "x_square1", ")", "*", "(", "1", "-", "mask_shift", ")", "\n", "# square_1 = self.ht(self.hardtanh1, x_square1 * (1 - mask_shift2))", "\n", "\n", "# square_2 = (x_output - x_shift_down < 0).float().unsqueeze(0)", "\n", "square_2", "=", "self", ".", "ht", "(", "self", ".", "hardtanh2", ",", "x_shift_down", "-", "x_output", ")", ".", "unsqueeze", "(", "0", ")", "\n", "x_span_split_index", "=", "square_1", "*", "square_2", "\n", "\n", "all_ones", "=", "torch", ".", "ones_like", "(", "x_span_split_index", ")", "\n", "span", "=", "all_ones", "-", "x_span_split_index", "\n", "\n", "span", "=", "(", "mask", "+", "(", "1", "-", "mask", ")", "*", "span", ")", ".", "cumprod", "(", "dim", "=", "1", ")", "*", "(", "1", "-", "mask", ")", "\n", "# span = (mask2 + (1 - mask2) * span).cumprod(dim=1) * (1 - mask)", "\n", "\n", "# Soft Softmax", "\n", "# x_att = self.softmax(x_output.unsqueeze(0).unsqueeze(3))", "\n", "# attention = span.unsqueeze(3) * x_att", "\n", "\n", "'''\n        # Hard Softmax\n        span_scores = span.unsqueeze(3) * (x_output.unsqueeze(0).unsqueeze(3))\n        mask_zero = (span_scores != 0).float()\n        span_scores += mask_zero.log()\n        span_scores = torch.cat([span_scores, torch.ones(seq_len, 1, batch_size, 1).cuda() * -10], 1)\n        attention_raw = self.softmax(span_scores)\n        attention, _ = attention_raw.split([seq_len, 1], 1)\n        '''", "\n", "\n", "# Sigmoid", "\n", "# span_scores = span.unsqueeze(3) * x_output.sigmoid().unsqueeze(0).unsqueeze(3)", "\n", "# attention = span_scores / (span_scores.sum(1, keepdim=True) + 1e-4)", "\n", "\n", "# Linear Normalize", "\n", "x_att", "=", "x_output", "-", "x_output", ".", "min", "(", ")", "+", "10", "\n", "span_scores", "=", "span", ".", "unsqueeze", "(", "3", ")", "*", "x_att", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# span_scores *= (1 - ones.triu(10)).unsqueeze(0).unsqueeze(3)", "\n", "if", "seq_len", "==", "seq_len_data", ":", "\n", "            ", "seq_len_data", "-=", "1", "\n", "", "span_scores", "=", "span_scores", "[", ":", "seq_len_data", "]", "\n", "\n", "# len_mask = ones.triu(10).unsqueeze(2)", "\n", "# reg_len = (span * len_mask).pow(2).mean()", "\n", "reg_len", "=", "x_output", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "# span_scores *= (1 - len_mask[:seq_len_data].unsqueeze(3))", "\n", "\n", "attention", "=", "span_scores", "/", "(", "span_scores", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "# attention = span_scores / (span_scores.sum(1, keepdim=True) + 1e-4)", "\n", "\n", "# attention = attention[:seq_len_data]", "\n", "# attention = span_scores / (span_scores.sum(1, keepdim=True) + 1e-4)", "\n", "return", "attention", ",", "seq_len_data", ",", "reg_len", ",", "# x_output", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.forward_raw": [[138, 155], ["x.transpose().transpose.transpose().transpose.size", "x.transpose().transpose.transpose().transpose.transpose().transpose", "tcn.TCN.conv_net", "x_conv.transpose().transpose.transpose().transpose.transpose().transpose", "tcn.TCN.linear_net", "tcn.TCN.unsqueeze", "tcn.TCN.unsqueeze", "tcn.TCN.ht", "torch.ones().cuda().tril", "torch.ones().cuda().tril", "torch.ones().cuda().tril", "torch.ones().cuda().tril", "torch.ones().cuda().triu", "torch.ones().cuda().triu", "torch.ones().cuda().triu", "torch.ones().cuda().triu", "mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "mask_right.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "tcn.TCN.cumprod", "x.transpose().transpose.transpose().transpose.transpose", "x_conv.transpose().transpose.transpose().transpose.transpose", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "mask.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "mask_right.unsqueeze().unsqueeze.unsqueeze().unsqueeze.unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.tcn.TCN.ht"], ["", "def", "forward_raw", "(", "self", ",", "x", ")", ":", "\n", "        ", "seq_len", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x_conv", "=", "self", ".", "conv_net", "(", "x", ")", "\n", "x_conv", "=", "x_conv", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x_output", "=", "self", ".", "linear_net", "(", "x_conv", ")", "\n", "x_row", "=", "x_output", ".", "unsqueeze", "(", "0", ")", "\n", "x_column", "=", "x_output", ".", "unsqueeze", "(", "1", ")", "\n", "x_square", "=", "self", ".", "ht", "(", "x_column", "-", "x_row", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ".", "cuda", "(", ")", ".", "tril", "(", ")", "\n", "mask_right", "=", "torch", ".", "ones", "(", "seq_len", ",", "seq_len", ")", ".", "cuda", "(", ")", ".", "triu", "(", "diagonal", "=", "10", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "mask_right", "=", "mask_right", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# x_square *= mask_right", "\n", "x_square", "=", "mask", "+", "(", "1", "-", "mask", ")", "*", "x_square", "\n", "x_square", "=", "x_square", ".", "cumprod", "(", "dim", "=", "1", ")", "*", "(", "1", "-", "mask", ")", "\n", "return", "x_square", "\n", "", "", ""]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.__init__": [[11, 58], ["torch.Module.__init__", "locked_dropout.LockedDropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "print", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.Linear", "torch.Linear", "model.RNNModel.init_weights", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "range", "weight_drop.WeightDrop", "range", "weight_drop.WeightDrop", "QRNNLayer", "weight_drop.WeightDrop", "range"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_weights"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "ntoken", ",", "ninp", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "0.5", ",", "dropouth", "=", "0.5", ",", "dropouti", "=", "0.5", ",", "dropoute", "=", "0.1", ",", "wdrop", "=", "0", ",", "tie_weights", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lockdrop", "=", "LockedDropout", "(", ")", "\n", "self", ".", "idrop", "=", "nn", ".", "Dropout", "(", "dropouti", ")", "\n", "self", ".", "hdrop", "=", "nn", ".", "Dropout", "(", "dropouth", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "ninp", ")", "\n", "assert", "rnn_type", "in", "[", "'LSTM'", ",", "'QRNN'", ",", "'GRU'", "]", ",", "'RNN type is not supported'", "\n", "if", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "LSTM", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "(", "ninp", "if", "tie_weights", "else", "nhid", ")", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "wdrop", ":", "\n", "                ", "self", ".", "rnns", "=", "[", "WeightDrop", "(", "rnn", ",", "[", "'weight_hh_l0'", "]", ",", "dropout", "=", "wdrop", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "", "if", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "self", ".", "rnns", "=", "[", "torch", ".", "nn", ".", "GRU", "(", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "ninp", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "if", "wdrop", ":", "\n", "                ", "self", ".", "rnns", "=", "[", "WeightDrop", "(", "rnn", ",", "[", "'weight_hh_l0'", "]", ",", "dropout", "=", "wdrop", ")", "for", "rnn", "in", "self", ".", "rnns", "]", "\n", "", "", "elif", "rnn_type", "==", "'QRNN'", ":", "\n", "            ", "from", "torchqrnn", "import", "QRNNLayer", "\n", "self", ".", "rnns", "=", "[", "QRNNLayer", "(", "input_size", "=", "ninp", "if", "l", "==", "0", "else", "nhid", ",", "hidden_size", "=", "nhid", "if", "l", "!=", "nlayers", "-", "1", "else", "(", "ninp", "if", "tie_weights", "else", "nhid", ")", ",", "save_prev_x", "=", "True", ",", "zoneout", "=", "0", ",", "window", "=", "2", "if", "l", "==", "0", "else", "1", ",", "output_gate", "=", "True", ")", "for", "l", "in", "range", "(", "nlayers", ")", "]", "\n", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "                ", "rnn", ".", "linear", "=", "WeightDrop", "(", "rnn", ".", "linear", ",", "[", "'weight'", "]", ",", "dropout", "=", "wdrop", ")", "\n", "", "", "print", "(", "self", ".", "rnns", ")", "\n", "self", ".", "rnns", "=", "torch", ".", "nn", ".", "ModuleList", "(", "self", ".", "rnns", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nhid", ",", "ntoken", ")", "\n", "\n", "# Optionally tie weights as in:", "\n", "# \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)", "\n", "# https://arxiv.org/abs/1608.05859", "\n", "# and", "\n", "# \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)", "\n", "# https://arxiv.org/abs/1611.01462", "\n", "if", "tie_weights", ":", "\n", "#if nhid != ninp:", "\n", "#    raise ValueError('When using the tied flag, nhid must be equal to emsize')", "\n", "            ", "self", ".", "decoder", ".", "weight", "=", "self", ".", "encoder", ".", "weight", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "ninp", "=", "ninp", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropouti", "=", "dropouti", "\n", "self", ".", "dropouth", "=", "dropouth", "\n", "self", ".", "dropoute", "=", "dropoute", "\n", "self", ".", "tie_weights", "=", "tie_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset": [[59, 61], ["r.reset"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "rnn_type", "==", "'QRNN'", ":", "[", "r", ".", "reset", "(", ")", "for", "r", "in", "self", ".", "rnns", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_weights": [[62, 67], ["model.RNNModel.encoder.weight.data.uniform_", "model.RNNModel.decoder.bias.data.fill_", "model.RNNModel.decoder.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.forward": [[68, 98], ["embed_regularize.embedded_dropout", "model.RNNModel.lockdrop", "enumerate", "model.RNNModel.lockdrop", "outputs.append", "model.RNNModel.view", "rnn", "new_hidden.append", "raw_outputs.append", "model.RNNModel.size", "model.RNNModel.lockdrop", "outputs.append", "model.RNNModel.size", "model.RNNModel.size"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.embed_regularize.embedded_dropout"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "return_h", "=", "False", ")", ":", "\n", "        ", "emb", "=", "embedded_dropout", "(", "self", ".", "encoder", ",", "input", ",", "dropout", "=", "self", ".", "dropoute", "if", "self", ".", "training", "else", "0", ")", "\n", "#emb = self.idrop(emb)", "\n", "\n", "# emb = self.encoder(input)", "\n", "emb", "=", "self", ".", "lockdrop", "(", "emb", ",", "self", ".", "dropouti", ")", "\n", "\n", "raw_output", "=", "emb", "\n", "new_hidden", "=", "[", "]", "\n", "#raw_output, hidden = self.rnn(emb, hidden)", "\n", "raw_outputs", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "l", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnns", ")", ":", "\n", "            ", "current_input", "=", "raw_output", "\n", "raw_output", ",", "new_h", "=", "rnn", "(", "raw_output", ",", "hidden", "[", "l", "]", ")", "\n", "new_hidden", ".", "append", "(", "new_h", ")", "\n", "raw_outputs", ".", "append", "(", "raw_output", ")", "\n", "if", "l", "!=", "self", ".", "nlayers", "-", "1", ":", "\n", "#self.hdrop(raw_output)", "\n", "                ", "raw_output", "=", "self", ".", "lockdrop", "(", "raw_output", ",", "self", ".", "dropouth", ")", "\n", "outputs", ".", "append", "(", "raw_output", ")", "\n", "", "", "hidden", "=", "new_hidden", "\n", "\n", "output", "=", "self", ".", "lockdrop", "(", "raw_output", ",", "self", ".", "dropout", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "result", "=", "output", ".", "view", "(", "output", ".", "size", "(", "0", ")", "*", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "\n", "if", "return_h", ":", "\n", "            ", "return", "result", ",", "hidden", ",", "raw_outputs", ",", "outputs", "\n", "", "return", "result", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden": [[99, 108], ["next", "model.RNNModel.parameters", "weight.new().zero_", "weight.new().zero_", "range", "weight.new().zero_", "range", "weight.new", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "[", "(", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", ",", "\n", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", "\n", "", "elif", "self", ".", "rnn_type", "==", "'QRNN'", "or", "self", ".", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "return", "[", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "nhid", "if", "l", "!=", "self", ".", "nlayers", "-", "1", "else", "(", "self", ".", "ninp", "if", "self", ".", "tie_weights", "else", "self", ".", "nhid", ")", ")", ".", "zero_", "(", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "nlayers", ")", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.finetune_span.evaluate": [[124, 139], ["model.eval", "len", "model.init_hidden", "range", "model.reset", "utils.get_batch", "model", "model.decoder", "model.decoder.view", "utils.repackage_hidden", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "output", "=", "model", ".", "decoder", "(", "output", ")", "\n", "output_flat", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "output_flat", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", "[", "0", "]", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.finetune_span.train": [[141, 244], ["time.time", "len", "model.init_hidden", "model.reset", "max", "min", "model.train", "model_r.train", "model_mlp.train", "utils.get_batch", "utils.get_batch", "data.size", "utils.repackage_hidden", "optimizer.zero_grad", "model", "model.decoder", "model.encoder", "model_r", "model_mlp", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer.step", "int", "model.decoder.view", "sum", "sum", "model_mlp.transpose", "int", "int", "range", "model.parameters", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.cat().transpose", "torch.cat().transpose", "torch.cat", "torch.cat", "time.time", "model.encoder.unsqueeze", "int", "data.size", "math.exp", "dropped_rnn_h.pow().mean", "data.size", "torch.cat", "torch.cat", "len", "data.size", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "seq_len", "=", "min", "(", "seq_len", ",", "args", ".", "bptt", "+", "10", ")", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "model_r", ".", "train", "(", ")", "\n", "model_mlp", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "data_long", ",", "_", ",", "_", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "seq_len_data", "=", "data", ".", "size", "(", "0", ")", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "output", "=", "model", ".", "decoder", "(", "output", ")", "\n", "\n", "input_emb", "=", "model", ".", "encoder", "(", "data", ")", "\n", "# input_emb = model.encoder(data).detach()", "\n", "# input_emb = model.encoder(data_long)", "\n", "# input_emb = model.encoder(data_long).detach()", "\n", "\n", "# input_emb_nhid = model_mlp(input_emb)", "\n", "\n", "attention", ",", "seq_len_data", ",", "reg_len", "=", "model_r", "(", "input_emb", ",", "seq_len_data", ")", "\n", "span_emb", "=", "(", "input_emb", ".", "unsqueeze", "(", "0", ")", "*", "attention", ")", ".", "sum", "(", "1", ")", "\n", "# span_emb = (input_emb_nhid.unsqueeze(0) * attention).sum(1)", "\n", "\n", "span_emb", "=", "model_mlp", "(", "span_emb", ")", "\n", "\n", "raw_loss", "=", "criterion", "(", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "\n", "context_emb", "=", "dropped_rnn_hs", "[", "-", "2", "]", "[", ":", "seq_len_data", "]", "\n", "if", "args", ".", "ns", ":", "\n", "            ", "span_emb_t", "=", "span_emb", ".", "transpose", "(", "0", ",", "1", ")", "\n", "pos_loss", "=", "(", "1", "-", "(", "context_emb", "*", "span_emb", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ")", ".", "mean", "(", ")", "\n", "neg_loss", "=", "0", "\n", "\n", "split_idx_batch", "=", "int", "(", "torch", ".", "randint", "(", "args", ".", "batch_size", ",", "[", "]", ")", ")", "\n", "# split_idx_batch = int(torch.randint(1, args.batch_size, []))", "\n", "least_ns_seq", "=", "0", "\n", "if", "split_idx_batch", "==", "0", ":", "\n", "                ", "least_ns_seq", "=", "10", "if", "data", ".", "size", "(", "0", ")", ">", "15", "else", "int", "(", "data", ".", "size", "(", "0", ")", "/", "2", ")", "\n", "", "split_idx_seq", "=", "int", "(", "torch", ".", "randint", "(", "least_ns_seq", ",", "data", ".", "size", "(", "0", ")", ",", "[", "]", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "1", ")", ":", "\n", "                ", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_t", "[", "split_idx_batch", ":", "]", ",", "span_emb_t", "[", ":", "split_idx_batch", "]", "]", ",", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_neg", "[", "split_idx_seq", ":", "]", ",", "span_emb_neg", "[", ":", "split_idx_seq", "]", "]", ",", "0", ")", "\n", "neg_loss", "+=", "(", "context_emb", "*", "span_emb_neg", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ".", "mean", "(", ")", "\n", "\n", "# split_idx_batch = int(torch.randint(args.batch_size, []))", "\n", "# split_idx_batch = int(torch.randint(1, args.batch_size, []))", "\n", "# least_ns_seq = 0", "\n", "# if split_idx_batch == 0:", "\n", "#     least_ns_seq = 10 if data.size(0) > 15 else int(data.size(0) / 2)", "\n", "# split_idx_seq = int(torch.randint(least_ns_seq, data.size(0), []))", "\n", "\n", "", "loss", "+=", "args", ".", "theta", "*", "(", "pos_loss", "+", "neg_loss", ")", "# + 1e-6 * reg_len", "\n", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", "+", "args", ".", "theta", "*", "(", "context_emb", "-", "span_emb", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", "[", "0", "]", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.finetune_bi.evaluate": [[108, 123], ["model_lm.eval", "len", "model_lm.init_hidden", "range", "model.reset", "utils.get_batch", "model_lm", "model_lm.decoder", "model_lm.decoder.view", "utils.repackage_hidden", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "model_lm", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", "=", "model_lm", "(", "data", ",", "hidden", ")", "\n", "output", "=", "model_lm", ".", "decoder", "(", "output", ")", "\n", "output_flat", "=", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "output_flat", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", "[", "0", "]", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.finetune_bi.train": [[125, 195], ["time.time", "len", "model_lm.init_hidden", "model_r.init_hidden", "model.reset", "max", "min", "model_lm.train", "model_r.train", "utils.get_batch", "data.flip", "utils.repackage_hidden", "utils.repackage_hidden", "optimizer.zero_grad", "model_lm", "model_r", "model_lm.decoder", "model_r.decoder", "criterion", "loss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer.step", "int", "model_lm.decoder.view", "criterion", "sum", "sum", "sum", "sum", "dropped_rnn_hs_r[].flip", "model_lm.parameters", "model_r.parameters", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "model_r.decoder.view", "time.time", "math.exp", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow().mean", "len", "dropped_rnn_h.pow", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "hidden_r", "=", "model_r", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "seq_len", "=", "min", "(", "seq_len", ",", "args", ".", "bptt", "+", "10", ")", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model_lm", ".", "train", "(", ")", "\n", "model_r", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "targets_r", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "data_r", "=", "data", ".", "flip", "(", "[", "0", "]", ")", "\n", "# targets_r = targets_r.flip([0])", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "hidden_r", "=", "repackage_hidden", "(", "hidden_r", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "output_r", ",", "hidden_r", ",", "rnn_hs_r", ",", "dropped_rnn_hs_r", "=", "model_r", "(", "data_r", ",", "hidden_r", ",", "return_h", "=", "True", ")", "\n", "output", "=", "model_lm", ".", "decoder", "(", "output", ")", "\n", "output_r", "=", "model_r", ".", "decoder", "(", "output_r", ")", "\n", "raw_loss", "=", "criterion", "(", "output", ".", "view", "(", "-", "1", ",", "ntokens", ")", ",", "targets", ")", "\n", "if", "i", "!=", "0", ":", "raw_loss", "+=", "criterion", "(", "output_r", ".", "view", "(", "-", "1", ",", "ntokens", ")", ",", "targets_r", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs_r", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", ":", "-", "1", "]", "-", "rnn_h", "[", "1", ":", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs_r", "[", "-", "1", ":", "]", ")", "\n", "\n", "outputl", "=", "dropped_rnn_hs", "[", "-", "1", "]", "[", ":", "-", "1", "]", "\n", "outputl_r", "=", "dropped_rnn_hs_r", "[", "-", "1", "]", ".", "flip", "(", "[", "0", "]", ")", "[", "1", ":", "]", "\n", "loss", "=", "loss", "+", "args", ".", "theta", "*", "(", "outputl", "-", "outputl_r", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "model_lm", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "model_r", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", "[", "0", "]", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__": [[6, 8], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.locked_dropout.LockedDropout.forward": [[9, 16], ["x.data.new().bernoulli_", "mask.expand_as.expand_as.expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "dropout", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ",", "requires_grad", "=", "False", ")", "/", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.model_save": [[88, 91], ["open", "torch.save", "torch.save"], "function", ["None"], ["", "", "def", "model_save", "(", "fn", ")", ":", "\n", "    ", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "torch", ".", "save", "(", "[", "model_lm", ",", "model_r", ",", "model_mlp", ",", "criterion", ",", "optimizer", "]", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.model_load": [[92, 96], ["open", "torch.load", "torch.load"], "function", ["None"], ["", "", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "global", "model_lm", ",", "criterion", ",", "optimizer", "\n", "with", "open", "(", "'models/{}'", ".", "format", "(", "fn", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model_lm", ",", "model_r", ",", "model_mlp", ",", "criterion", ",", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.evaluate": [[178, 194], ["model_lm.eval", "len", "model_lm.init_hidden", "range", "model_lm.reset", "utils.get_batch", "model_lm", "utils.repackage_hidden", "total_loss.item", "len", "data_source.size", "len", "criterion"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model_lm", ".", "eval", "(", ")", "\n", "# model_mlp.eval()", "\n", "if", "args", ".", "model", "==", "'QRNN'", ":", "model_lm", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", ",", "_", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "hidden", ",", "_", ",", "all_outputs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "# output = model_mlp(all_outputs[-1]) + all_outputs[-1]", "\n", "# output = output.view(output.size(0)*output.size(1), output.size(2))", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train": [[196, 328], ["time.time", "len", "model_lm.init_hidden", "model.reset", "max", "model_lm.train", "model_r.train", "model_mlp.train", "utils.get_batch", "data.size", "utils.repackage_hidden", "optimizer.zero_grad", "model_lm", "model_lm.encoder", "model_r", "model_mlp", "criterion", "loss.backward", "optimizer.step", "int", "model_mlp.transpose", "int", "int", "range", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "print", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "sum", "sum", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.cat().transpose", "torch.cat().transpose", "torch.cat", "torch.cat", "total_loss.item", "time.time", "model_lm.encoder.unsqueeze", "dropped_rnn_hs[].unsqueeze", "int", "data.size", "math.exp", "data.size", "torch.cat", "torch.cat", "len", "math.log", "dropped_rnn_h.pow().mean", "data.size", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.luohongyin_PILM.None.model.RNNModel.reset", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.main_bspan.train", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch", "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "if", "args", ".", "model", "==", "'QRNN'", ":", "model", ".", "reset", "(", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model_lm", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "# hidden_r = model_r.init_hidden(args.batch_size)", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model_lm", ".", "train", "(", ")", "\n", "model_r", ".", "train", "(", ")", "\n", "model_mlp", ".", "train", "(", ")", "\n", "data", ",", "targets", ",", "targets_r", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "# data_long, _, _ = get_batch(train_data, i, args, seq_len=seq_len + 10)", "\n", "\n", "seq_len_data", "=", "data", ".", "size", "(", "0", ")", "\n", "# data_r = data.flip([0])", "\n", "# targets_r = targets_r.flip([0])", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "# hidden_r = model_r.init_hidden(args.batch_size)", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model_lm", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "\n", "input_emb", "=", "model_lm", ".", "encoder", "(", "data", ")", "\n", "# input_emb = model_lm.encoder(data).detach()", "\n", "# input_emb = model_lm.encoder(data_long)", "\n", "# input_emb = model_lm.encoder(data_long).detach()", "\n", "\n", "# input_emb_nhid = model_mlp(input_emb)", "\n", "\n", "attention_p", ",", "attention_c", ",", "seq_len_data", ",", "reg_len", "=", "model_r", "(", "input_emb", ",", "seq_len_data", ")", "\n", "span_emb", "=", "(", "input_emb", ".", "unsqueeze", "(", "0", ")", "*", "attention_p", ")", ".", "sum", "(", "1", ")", "\n", "# span_emb = (input_emb_nhid.unsqueeze(0) * attention).sum(1)", "\n", "\n", "# output = model_mlp(dropped_rnn_hs[-1]) + dropped_rnn_hs[-1]", "\n", "# output = output.view(output.size(0)*output.size(1), output.size(2))", "\n", "\n", "span_emb", "=", "model_mlp", "(", "span_emb", ")", "# + span_emb", "\n", "\n", "raw_loss", "=", "criterion", "(", "model_lm", ".", "decoder", ".", "weight", ",", "model_lm", ".", "decoder", ".", "bias", ",", "output", ",", "targets", ")", "\n", "# if i != 0: raw_loss += criterion(model_r.decoder.weight, model_r.decoder.bias, output_r, targets_r)", "\n", "# if i != 0: raw_loss += 0 * criterion(model_r.decoder.weight, modoyel_r.decoder.bias, output_r, targets_r)", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activiation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# if args.alpha: loss = loss + sum(args.alpha * dropped_rnn_h.pow(2).mean() for dropped_rnn_h in dropped_rnn_hs_r[-1:])", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# if args.beta: loss = loss + sum(args.beta * (rnn_h[:-1] - rnn_h[1:]).pow(2).mean() for rnn_h in rnn_hs_r[-1:])", "\n", "\n", "# loss = loss + args.theta * (dropped_rnn_hs[-1] - span_emb).pow(2).mean()", "\n", "# '''", "\n", "# args.ns = False", "\n", "context_emb", "=", "(", "dropped_rnn_hs", "[", "-", "2", "]", ".", "unsqueeze", "(", "0", ")", "*", "attention_c", ")", ".", "sum", "(", "1", ")", "\n", "# context_emb = dropped_rnn_hs[-2].detach()", "\n", "if", "args", ".", "ns", ":", "\n", "            ", "span_emb_t", "=", "span_emb", ".", "transpose", "(", "0", ",", "1", ")", "\n", "pos_loss", "=", "(", "1", "-", "(", "context_emb", "*", "span_emb", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ")", ".", "mean", "(", ")", "\n", "neg_loss", "=", "0", "\n", "\n", "split_idx_batch", "=", "int", "(", "torch", ".", "randint", "(", "args", ".", "batch_size", ",", "[", "]", ")", ")", "\n", "# split_idx_batch = int(torch.randint(1, args.batch_size, []))", "\n", "least_ns_seq", "=", "0", "\n", "if", "split_idx_batch", "==", "0", ":", "\n", "                ", "least_ns_seq", "=", "10", "if", "data", ".", "size", "(", "0", ")", ">", "15", "else", "int", "(", "data", ".", "size", "(", "0", ")", "/", "2", ")", "\n", "", "split_idx_seq", "=", "int", "(", "torch", ".", "randint", "(", "least_ns_seq", ",", "data", ".", "size", "(", "0", ")", ",", "[", "]", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "1", ")", ":", "\n", "                ", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_t", "[", "split_idx_batch", ":", "]", ",", "span_emb_t", "[", ":", "split_idx_batch", "]", "]", ",", "0", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "span_emb_neg", "=", "torch", ".", "cat", "(", "[", "span_emb_neg", "[", "split_idx_seq", ":", "]", ",", "span_emb_neg", "[", ":", "split_idx_seq", "]", "]", ",", "0", ")", "\n", "neg_loss", "+=", "(", "context_emb", "*", "span_emb_neg", ")", ".", "sum", "(", "2", ")", ".", "sigmoid", "(", ")", ".", "mean", "(", ")", "\n", "\n", "# split_idx_batch = int(torch.randint(args.batch_size, []))", "\n", "# split_idx_batch = int(torch.randint(1, args.batch_size, []))", "\n", "# least_ns_seq = 0", "\n", "# if split_idx_batch == 0:", "\n", "#     least_ns_seq = 10 if data.size(0) > 15 else int(data.size(0) / 2)", "\n", "# split_idx_seq = int(torch.randint(least_ns_seq, data.size(0), []))", "\n", "# print(attention.squeeze())", "\n", "# print(neg_loss)", "\n", "# print('x' + 1)", "\n", "# data_neg, _, _ = get_batch(train_data, split_idx_batch, args, seq_len = data.size(0))", "\n", "# input_emb_neg = model_lm.encoder(data_neg)", "\n", "# attention_neg = model_r(input_emb_neg)", "\n", "# span_emb_neg = (input_emb_neg.unsqueeze(0) * attention_neg).sum(1)", "\n", "# span_emb_neg = model_mlp(span_emb_neg)", "\n", "# neg_loss += (dropped_rnn_hs[-2] * span_emb_neg).sum(2).sigmoid().mean()", "\n", "# split_idx_batch = int(torch.randint(train_data.size(0) - data.size(0), []))", "\n", "\n", "# loss += 0", "\n", "# loss += args.theta * (pos_loss + neg_loss)", "\n", "", "loss", "+=", "args", ".", "theta", "*", "(", "pos_loss", "+", "neg_loss", ")", "# + 0.1 * reg_len", "\n", "# split_idx_seq = (split_idx_seq * 7) % args.bptt", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", "+", "args", ".", "theta", "*", "(", "context_emb", "-", "span_emb", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "# '''", "\n", "# print(attention.mean(2).mean(2))", "\n", "# loss += (attention > 0).float().sum() * 0.05", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "if", "args", ".", "clip", ":", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden": [[4, 11], ["isinstance", "h.detach", "tuple", "utils.repackage_hidden"], "function", ["home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.repackage_hidden"], ["def", "repackage_hidden", "(", "h", ")", ":", "\n", "    ", "\"\"\"Wraps hidden states in new Tensors,\n    to detach them from their history.\"\"\"", "\n", "if", "isinstance", "(", "h", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "h", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tuple", "(", "repackage_hidden", "(", "v", ")", "for", "v", "in", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.batchify": [[13, 23], ["data.cuda.narrow", "data.cuda.view().t().contiguous", "data.cuda.size", "data.cuda.cuda", "data.cuda.view().t", "data.cuda.view"], "function", ["None"], ["", "", "def", "batchify", "(", "data", ",", "bsz", ",", "args", ")", ":", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "    ", "nbatch", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "nbatch", "*", "bsz", ")", "\n", "# Evenly divide the data across the bsz batches.", "\n", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.luohongyin_PILM.None.utils.get_batch": [[25, 34], ["min", "source[].view", "source[].flip().view", "source[].flip().view", "len", "source[].flip", "source[].flip"], "function", ["None"], ["", "def", "get_batch", "(", "source", ",", "i", ",", "args", ",", "seq_len", "=", "None", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "seq_len", "=", "min", "(", "seq_len", "if", "seq_len", "else", "args", ".", "bptt", ",", "len", "(", "source", ")", "-", "1", "-", "i", ")", "\n", "data", "=", "source", "[", "i", ":", "i", "+", "seq_len", "]", "\n", "target", "=", "source", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", ".", "view", "(", "-", "1", ")", "\n", "if", "i", "==", "0", ":", "\n", "        ", "target_r", "=", "source", "[", "i", ":", "i", "-", "1", "+", "seq_len", "]", ".", "flip", "(", "[", "0", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "target_r", "=", "source", "[", "i", "-", "1", ":", "i", "-", "1", "+", "seq_len", "]", ".", "flip", "(", "[", "0", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "", "return", "data", ",", "target", ",", "target_r", "\n", "", ""]]}