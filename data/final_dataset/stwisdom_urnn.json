{"home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix": [[6, 23], ["theano.shared", "theano.shared", "numpy.sqrt", "numpy.asarray", "rng.uniform", "ValueError", "numpy.float32", "numpy.concatenate", "numpy.concatenate", "numpy.eye().astype", "numpy.zeros().astype", "numpy.eye().astype", "numpy.zeros().astype", "numpy.eye", "numpy.zeros", "numpy.eye", "numpy.zeros"], "function", ["None"], ["def", "initialize_matrix", "(", "n_in", ",", "n_out", ",", "name", ",", "rng", ",", "init", "=", "'rand'", ")", ":", "\n", "    ", "if", "(", "init", "==", "'rand'", ")", "or", "(", "init", "==", "'randSmall'", ")", ":", "\n", "        ", "bin", "=", "np", ".", "sqrt", "(", "6.", "/", "(", "n_in", "+", "n_out", ")", ")", "\n", "values", "=", "np", ".", "asarray", "(", "rng", ".", "uniform", "(", "low", "=", "-", "bin", ",", "\n", "high", "=", "bin", ",", "\n", "size", "=", "(", "n_in", ",", "n_out", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "if", "(", "init", "==", "'randSmall'", ")", ":", "\n", "            ", "values", "=", "np", ".", "float32", "(", "0.01", ")", "*", "values", "\n", "", "", "elif", "(", "init", "==", "'identity'", ")", ":", "\n", "        ", "if", "(", "n_in", ">=", "n_out", ")", ":", "\n", "            ", "values", "=", "np", ".", "concatenate", "(", "[", "np", ".", "eye", "(", "n_out", ")", ".", "astype", "(", "theano", ".", "config", ".", "floatX", ")", ",", "np", ".", "zeros", "(", "(", "n_in", "-", "n_out", ",", "n_out", ")", ")", ".", "astype", "(", "theano", ".", "config", ".", "floatX", ")", "]", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "values", "=", "np", ".", "concatenate", "(", "[", "np", ".", "eye", "(", "n_in", ")", ".", "astype", "(", "theano", ".", "config", ".", "floatX", ")", ",", "np", ".", "zeros", "(", "(", "n_in", ",", "n_out", "-", "n_in", ")", ")", ".", "astype", "(", "theano", ".", "config", ".", "floatX", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "", "else", ":", "\n", "       ", "raise", "ValueError", "(", "\"Unknown initialization method [\"", "+", "init", "+", "\"]\"", ")", "\n", "", "return", "theano", ".", "shared", "(", "value", "=", "values", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix_np": [[24, 31], ["numpy.sqrt", "numpy.asarray", "rng.uniform"], "function", ["None"], ["", "def", "initialize_matrix_np", "(", "n_in", ",", "n_out", ",", "rng", ")", ":", "\n", "    ", "bin", "=", "np", ".", "sqrt", "(", "6.", "/", "(", "n_in", "+", "n_out", ")", ")", "\n", "values", "=", "np", ".", "asarray", "(", "rng", ".", "uniform", "(", "low", "=", "-", "bin", ",", "\n", "high", "=", "bin", ",", "\n", "size", "=", "(", "n_in", ",", "n_out", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "return", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.do_fft": [[32, 39], ["theano.reshape", "fft_input.dimshuffle.dimshuffle", "fft_output.dimshuffle.dimshuffle", "theano.reshape", "fftconv.cufft", "theano.sqrt"], "function", ["None"], ["", "def", "do_fft", "(", "input", ",", "n_hidden", ")", ":", "\n", "    ", "fft_input", "=", "T", ".", "reshape", "(", "input", ",", "(", "input", ".", "shape", "[", "0", "]", ",", "2", ",", "n_hidden", ")", ")", "\n", "fft_input", "=", "fft_input", ".", "dimshuffle", "(", "0", ",", "2", ",", "1", ")", "\n", "fft_output", "=", "cufft", "(", "fft_input", ")", "/", "T", ".", "sqrt", "(", "n_hidden", ")", "\n", "fft_output", "=", "fft_output", ".", "dimshuffle", "(", "0", ",", "2", ",", "1", ")", "\n", "output", "=", "T", ".", "reshape", "(", "fft_output", ",", "(", "input", ".", "shape", "[", "0", "]", ",", "2", "*", "n_hidden", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.do_ifft": [[40, 47], ["theano.reshape", "ifft_input.dimshuffle.dimshuffle", "ifft_output.dimshuffle.dimshuffle", "theano.reshape", "fftconv.cuifft", "theano.sqrt"], "function", ["None"], ["", "def", "do_ifft", "(", "input", ",", "n_hidden", ")", ":", "\n", "    ", "ifft_input", "=", "T", ".", "reshape", "(", "input", ",", "(", "input", ".", "shape", "[", "0", "]", ",", "2", ",", "n_hidden", ")", ")", "\n", "ifft_input", "=", "ifft_input", ".", "dimshuffle", "(", "0", ",", "2", ",", "1", ")", "\n", "ifft_output", "=", "cuifft", "(", "ifft_input", ")", "/", "T", ".", "sqrt", "(", "n_hidden", ")", "\n", "ifft_output", "=", "ifft_output", ".", "dimshuffle", "(", "0", ",", "2", ",", "1", ")", "\n", "output", "=", "T", ".", "reshape", "(", "ifft_output", ",", "(", "input", ".", "shape", "[", "0", "]", ",", "2", "*", "n_hidden", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_diag": [[49, 66], ["theano.concatenate", "theano.cos().dimshuffle", "theano.sin().dimshuffle", "theano.cos", "theano.sin"], "function", ["None"], ["", "def", "times_diag", "(", "input", ",", "n_hidden", ",", "diag", ",", "swap_re_im", ")", ":", "\n", "# input is a Ix2n_hidden matrix, where I is number", "\n", "# of training examples", "\n", "# diag is a n_hidden-dimensional real vector, which creates", "\n", "# the 2n_hidden x 2n_hidden complex diagonal matrix using ", "\n", "# e.^{j.*diag}=cos(diag)+j.*sin(diag)", "\n", "    ", "d", "=", "T", ".", "concatenate", "(", "[", "diag", ",", "-", "diag", "]", ")", "#d is 2n_hidden", "\n", "\n", "Re", "=", "T", ".", "cos", "(", "d", ")", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "Im", "=", "T", ".", "sin", "(", "d", ")", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "\n", "input_times_Re", "=", "input", "*", "Re", "\n", "input_times_Im", "=", "input", "*", "Im", "\n", "\n", "output", "=", "input_times_Re", "+", "input_times_Im", "[", ":", ",", "swap_re_im", "]", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.vec_permutation": [[68, 70], ["None"], "function", ["None"], ["", "def", "vec_permutation", "(", "input", ",", "index_permute", ")", ":", "\n", "    ", "return", "input", "[", ":", ",", "index_permute", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_reflection": [[72, 95], ["theano.dot", "theano.dot", "theano.dot", "theano.dot", "theano.outer", "theano.outer", "theano.outer", "theano.outer", "theano.inc_subtensor", "theano.inc_subtensor"], "function", ["None"], ["", "def", "times_reflection", "(", "input", ",", "n_hidden", ",", "reflection", ")", ":", "\n", "    ", "input_re", "=", "input", "[", ":", ",", ":", "n_hidden", "]", "\n", "input_im", "=", "input", "[", ":", ",", "n_hidden", ":", "]", "\n", "reflect_re", "=", "reflection", "[", ":", "n_hidden", "]", "\n", "reflect_im", "=", "reflection", "[", "n_hidden", ":", "]", "\n", "\n", "vstarv", "=", "(", "reflection", "**", "2", ")", ".", "sum", "(", ")", "\n", "\n", "input_re_reflect_re", "=", "T", ".", "dot", "(", "input_re", ",", "reflect_re", ")", "\n", "input_re_reflect_im", "=", "T", ".", "dot", "(", "input_re", ",", "reflect_im", ")", "\n", "input_im_reflect_re", "=", "T", ".", "dot", "(", "input_im", ",", "reflect_re", ")", "\n", "input_im_reflect_im", "=", "T", ".", "dot", "(", "input_im", ",", "reflect_im", ")", "\n", "\n", "a", "=", "T", ".", "outer", "(", "input_re_reflect_re", "-", "input_im_reflect_im", ",", "reflect_re", ")", "\n", "b", "=", "T", ".", "outer", "(", "input_re_reflect_im", "+", "input_im_reflect_re", ",", "reflect_im", ")", "\n", "c", "=", "T", ".", "outer", "(", "input_re_reflect_re", "-", "input_im_reflect_im", ",", "reflect_im", ")", "\n", "d", "=", "T", ".", "outer", "(", "input_re_reflect_im", "+", "input_im_reflect_re", ",", "reflect_re", ")", "\n", "\n", "output", "=", "input", "\n", "output", "=", "T", ".", "inc_subtensor", "(", "output", "[", ":", ",", ":", "n_hidden", "]", ",", "-", "2.", "/", "vstarv", "*", "(", "a", "+", "b", ")", ")", "\n", "output", "=", "T", ".", "inc_subtensor", "(", "output", "[", ":", ",", "n_hidden", ":", "]", ",", "-", "2.", "/", "vstarv", "*", "(", "d", "-", "c", ")", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_reflection_sub": [[96, 123], ["theano.dot", "theano.dot", "theano.dot", "theano.dot", "theano.outer", "theano.outer", "theano.outer", "theano.outer", "theano.inc_subtensor", "theano.inc_subtensor"], "function", ["None"], ["", "def", "times_reflection_sub", "(", "input", ",", "n_hidden", ",", "n_sub", ",", "reflection", ")", ":", "\n", "\n", "#print \"n_hidden=%d, n_sub=%d\" % (n_hidden,n_sub)    ", "\n", "    ", "input_re", "=", "input", "[", ":", ",", ":", "n_hidden", "]", "\n", "input_im", "=", "input", "[", ":", ",", "n_hidden", ":", "]", "\n", "n_start", "=", "n_hidden", "-", "n_sub", "\n", "#print \"n_start=%d\" % n_start", "\n", "reflect_re", "=", "reflection", "[", "n_start", ":", "n_hidden", "]", "\n", "reflect_im", "=", "reflection", "[", "(", "n_hidden", "+", "n_start", ")", ":", "]", "\n", "\n", "vstarv", "=", "(", "reflect_re", "**", "2", ")", ".", "sum", "(", ")", "+", "(", "reflect_im", "**", "2", ")", ".", "sum", "(", ")", "\n", "\n", "input_re_reflect_re", "=", "T", ".", "dot", "(", "input_re", "[", ":", ",", "n_start", ":", "]", ",", "reflect_re", ")", "\n", "input_re_reflect_im", "=", "T", ".", "dot", "(", "input_re", "[", ":", ",", "n_start", ":", "]", ",", "reflect_im", ")", "\n", "input_im_reflect_re", "=", "T", ".", "dot", "(", "input_im", "[", ":", ",", "n_start", ":", "]", ",", "reflect_re", ")", "\n", "input_im_reflect_im", "=", "T", ".", "dot", "(", "input_im", "[", ":", ",", "n_start", ":", "]", ",", "reflect_im", ")", "\n", "\n", "a", "=", "T", ".", "outer", "(", "input_re_reflect_re", "-", "input_im_reflect_im", ",", "reflect_re", ")", "\n", "b", "=", "T", ".", "outer", "(", "input_re_reflect_im", "+", "input_im_reflect_re", ",", "reflect_im", ")", "\n", "c", "=", "T", ".", "outer", "(", "input_re_reflect_re", "-", "input_im_reflect_im", ",", "reflect_im", ")", "\n", "d", "=", "T", ".", "outer", "(", "input_re_reflect_im", "+", "input_im_reflect_re", ",", "reflect_re", ")", "\n", "\n", "output", "=", "input", "\n", "output", "=", "T", ".", "inc_subtensor", "(", "output", "[", ":", ",", "n_start", ":", "n_hidden", "]", ",", "-", "2.", "/", "vstarv", "*", "(", "a", "+", "b", ")", ")", "\n", "output", "=", "T", ".", "inc_subtensor", "(", "output", "[", ":", ",", "(", "n_hidden", "+", "n_start", ")", ":", "]", ",", "-", "2.", "/", "vstarv", "*", "(", "d", "-", "c", ")", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t": [[125, 175], ["theano.nnet.softmax", "theano.nnet.categorical_crossentropy", "T.nnet.categorical_crossentropy.mean", "theano.eq().mean", "mse.mean", "theano.shared", "theano.shared", "ymask_t.dimshuffle", "theano.eq", "numpy.float32", "theano.sqrt", "mse.mean", "mseOnly.mean", "theano.argmax", "ymask_t[].dimshuffle", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.sum", "ymask_t[].dimshuffle", "numpy.float32", "numpy.float32", "theano.nnet.sigmoid", "theano.clip", "theano.nnet.binary_crossentropy", "T.nnet.binary_crossentropy.mean", "ymask_t.dimshuffle", "costs_t_fake.mean", "costs_t_real.mean"], "function", ["None"], ["", "def", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ",", "ymask_t", "=", "None", ",", "z_t", "=", "None", ",", "lam", "=", "0.0", ")", ":", "\n", "    ", "if", "(", "loss_function", "==", "'CE'", ")", "or", "(", "loss_function", "==", "'CE_of_sum'", ")", ":", "\n", "        ", "RNN_output", "=", "T", ".", "nnet", ".", "softmax", "(", "lin_output", ")", "\n", "CE", "=", "T", ".", "nnet", ".", "categorical_crossentropy", "(", "RNN_output", ",", "y_t", ")", "\n", "if", "ymask_t", "is", "not", "None", ":", "\n", "            ", "RNN_output", "=", "RNN_output", "*", "ymask_t", "\n", "CE", "=", "CE", "*", "(", "ymask_t", ".", "dimshuffle", "(", "0", ",", ")", ")", "\n", "", "cost_t", "=", "CE", ".", "mean", "(", ")", "\n", "acc_t", "=", "(", "T", ".", "eq", "(", "T", ".", "argmax", "(", "RNN_output", ",", "axis", "=", "-", "1", ")", ",", "y_t", ")", ")", ".", "mean", "(", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "", "elif", "loss_function", "==", "'MSE'", ":", "\n", "        ", "mse", "=", "(", "lin_output", "-", "y_t", ")", "**", "2", "\n", "if", "ymask_t", "is", "not", "None", ":", "\n", "            ", "mse", "=", "mse", "*", "(", "(", "ymask_t", "[", ":", ",", "0", "]", ")", ".", "dimshuffle", "(", "0", ",", "'x'", ")", ")", "\n", "#mse = mse*ymask_t[:,0:1]", "\n", "", "cost_t", "=", "mse", ".", "mean", "(", ")", "\n", "acc_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "", "elif", "loss_function", "==", "'MSEplusL1'", ":", "\n", "        ", "mseOnly", "=", "(", "lin_output", "-", "y_t", ")", "**", "2", "\n", "L1", "=", "T", ".", "sqrt", "(", "1e-5", "+", "T", ".", "sum", "(", "lin_output", "**", "2", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "mse", "=", "mseOnly", "+", "lam", "*", "L1", "\n", "if", "ymask_t", "is", "not", "None", ":", "\n", "            ", "mse", "=", "mse", "*", "(", "(", "ymask_t", "[", ":", ",", "0", "]", ")", ".", "dimshuffle", "(", "0", ",", "'x'", ")", ")", "\n", "", "cost_t", "=", "mse", ".", "mean", "(", ")", "\n", "acc_t", "=", "mseOnly", ".", "mean", "(", ")", "\n", "#elif loss_function == 'NMSE':", "\n", "#    err=(lin_output - y_t)**2", "\n", "#    err_sum=T.sum(err,axis=0)", "\n", "#    err_sum=T.sum(err_sum,axis=-1)", "\n", "#    ypow=y_t**2", "\n", "#    ypow_sum=T.sum(ypow,axis=0)", "\n", "#    ypow_sum=T.sum(ypow_sum,axis=-1)", "\n", "#    cost_t = (err_sum / (1e-5+ypow_sum)).mean()", "\n", "#    acc_t = theano.shared(np.float32(0.0))", "\n", "", "elif", "(", "loss_function", "==", "'g_loss'", ")", "or", "(", "loss_function", "==", "'none_in_scan'", ")", ":", "\n", "        ", "cost_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "acc_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "", "elif", "loss_function", "==", "'d_loss'", ":", "\n", "        ", "RNN_output", "=", "T", ".", "nnet", ".", "sigmoid", "(", "lin_output", ")", "\n", "# clip the output of the sigmoid to avoid 0s, and thus NaNs in cross entropy:", "\n", "RNN_output_clip", "=", "T", ".", "clip", "(", "RNN_output", ",", "1e-7", ",", "1.0", "-", "1e-7", ")", "\n", "costs_t", "=", "T", ".", "nnet", ".", "binary_crossentropy", "(", "RNN_output_clip", ",", "y_t", ")", "\n", "if", "ymask_t", "is", "not", "None", ":", "\n", "            ", "costs_t", "=", "costs_t", "*", "(", "ymask_t", ".", "dimshuffle", "(", "0", ",", ")", ")", "\n", "", "cost_t", "=", "costs_t", ".", "mean", "(", ")", "\n", "idx_half", "=", "costs_t", ".", "shape", "[", "0", "]", "/", "2", "\n", "costs_t_fake", "=", "costs_t", "[", ":", "idx_half", "]", "\n", "costs_t_real", "=", "costs_t", "[", "idx_half", ":", "]", "\n", "acc_t", "=", "[", "costs_t_fake", ".", "mean", "(", ")", "/", "2", ",", "costs_t_real", ".", "mean", "(", ")", "/", "2", "]", "\n", "\n", "", "return", "cost_t", ",", "acc_t", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_data_nodes": [[177, 186], ["theano.tensor3", "theano.matrix", "theano.matrix", "theano.vector", "theano.tensor3", "theano.matrix"], "function", ["None"], ["", "def", "initialize_data_nodes", "(", "loss_function", ",", "input_type", ",", "out_every_t", ")", ":", "\n", "# if input_type is real or complex, will be size n_fram x n_input x n_utt", "\n", "    ", "x", "=", "T", ".", "tensor3", "(", ")", "if", "input_type", "==", "'real'", "or", "input_type", "==", "'complex'", "else", "T", ".", "matrix", "(", "dtype", "=", "'int32'", ")", "\n", "if", "'CE'", "in", "loss_function", ":", "\n", "        ", "y", "=", "T", ".", "matrix", "(", "dtype", "=", "'int32'", ")", "if", "out_every_t", "else", "T", ".", "vector", "(", "dtype", "=", "'int32'", ")", "\n", "", "else", ":", "\n", "# y will be n_fram x n_output x n_utt", "\n", "        ", "y", "=", "T", ".", "tensor3", "(", ")", "if", "out_every_t", "else", "T", ".", "matrix", "(", ")", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.IRNN": [[189, 246], ["numpy.random.seed", "numpy.random.RandomState", "models.initialize_data_nodes", "theano.shared", "theano.shared", "models.initialize_matrix", "theano.shared", "theano.shared", "models.initialize_matrix", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.tile", "theano.scan", "theano.scan", "numpy.zeros", "numpy.identity", "numpy.zeros", "numpy.zeros", "theano.nnet.relu", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "models.compute_cost_t", "cost_steps.mean", "acc_steps.mean", "theano.dot", "models.compute_cost_t", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.tile", "numpy.float32", "numpy.float32", "theano.dot", "theano.shared.dimshuffle", "theano.shared.dimshuffle", "theano.dot", "theano.shared.dimshuffle", "numpy.float32", "numpy.float32", "theano.shared", "theano.shared", "theano.dot", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_data_nodes", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t"], ["", "def", "IRNN", "(", "n_input", ",", "n_hidden", ",", "n_output", ",", "input_type", "=", "'real'", ",", "out_every_t", "=", "False", ",", "loss_function", "=", "'CE'", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "1234", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n", "x", ",", "y", "=", "initialize_data_nodes", "(", "loss_function", ",", "input_type", ",", "out_every_t", ")", "\n", "inputs", "=", "[", "x", ",", "y", "]", "\n", "\n", "h_0", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "n_hidden", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "V", "=", "initialize_matrix", "(", "n_input", ",", "n_hidden", ",", "'V'", ",", "rng", ")", "\n", "W", "=", "theano", ".", "shared", "(", "np", ".", "identity", "(", "n_hidden", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "out_mat", "=", "initialize_matrix", "(", "n_hidden", ",", "n_output", ",", "'out_mat'", ",", "rng", ")", "\n", "hidden_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_hidden", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "out_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_output", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "\n", "parameters", "=", "[", "h_0", ",", "V", ",", "W", ",", "out_mat", ",", "hidden_bias", ",", "out_bias", "]", "\n", "\n", "def", "recurrence", "(", "x_t", ",", "y_t", ",", "h_prev", ",", "cost_prev", ",", "acc_prev", ",", "V", ",", "W", ",", "hidden_bias", ",", "out_mat", ",", "out_bias", ")", ":", "\n", "        ", "if", "loss_function", "==", "'CE'", ":", "\n", "            ", "data_lin_output", "=", "V", "[", "x_t", "]", "\n", "", "else", ":", "\n", "            ", "data_lin_output", "=", "T", ".", "dot", "(", "x_t", ",", "V", ")", "\n", "\n", "", "h_t", "=", "T", ".", "nnet", ".", "relu", "(", "T", ".", "dot", "(", "h_prev", ",", "W", ")", "+", "data_lin_output", "+", "hidden_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ")", "\n", "if", "out_every_t", ":", "\n", "            ", "lin_output", "=", "T", ".", "dot", "(", "h_t", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "cost_t", ",", "acc_t", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ")", "\n", "", "else", ":", "\n", "            ", "cost_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "acc_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "\n", "", "return", "h_t", ",", "cost_t", ",", "acc_t", "\n", "\n", "", "non_sequences", "=", "[", "V", ",", "W", ",", "hidden_bias", ",", "out_mat", ",", "out_bias", "]", "\n", "\n", "h_0_batch", "=", "T", ".", "tile", "(", "h_0", ",", "[", "x", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "\n", "if", "out_every_t", ":", "\n", "        ", "sequences", "=", "[", "x", ",", "y", "]", "\n", "", "else", ":", "\n", "        ", "sequences", "=", "[", "x", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "\n", "", "outputs_info", "=", "[", "h_0_batch", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "]", "\n", "\n", "[", "hidden_states", ",", "cost_steps", ",", "acc_steps", "]", ",", "updates", "=", "theano", ".", "scan", "(", "fn", "=", "recurrence", ",", "\n", "sequences", "=", "sequences", ",", "\n", "non_sequences", "=", "non_sequences", ",", "\n", "outputs_info", "=", "outputs_info", ")", "\n", "\n", "if", "not", "out_every_t", ":", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", "[", "-", "1", ",", ":", ",", ":", "]", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "costs", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y", ")", "\n", "", "else", ":", "\n", "        ", "cost", "=", "cost_steps", ".", "mean", "(", ")", "\n", "accuracy", "=", "acc_steps", ".", "mean", "(", ")", "\n", "costs", "=", "[", "cost", ",", "accuracy", "]", "\n", "\n", "", "return", "inputs", ",", "parameters", ",", "costs", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.tanhRNN": [[249, 305], ["numpy.random.seed", "numpy.random.RandomState", "models.initialize_data_nodes", "theano.shared", "theano.shared", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.tile", "theano.scan", "theano.scan", "numpy.zeros", "numpy.zeros", "numpy.zeros", "theano.tanh", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "models.compute_cost_t", "cost_steps.mean", "acc_steps.mean", "theano.dot", "models.compute_cost_t", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.tile", "numpy.float32", "numpy.float32", "theano.dot", "theano.shared.dimshuffle", "theano.shared.dimshuffle", "theano.dot", "theano.shared.dimshuffle", "numpy.float32", "numpy.float32", "theano.shared", "theano.shared", "theano.dot", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_data_nodes", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t"], ["", "def", "tanhRNN", "(", "n_input", ",", "n_hidden", ",", "n_output", ",", "input_type", "=", "'real'", ",", "out_every_t", "=", "False", ",", "loss_function", "=", "'CE'", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "1234", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n", "x", ",", "y", "=", "initialize_data_nodes", "(", "loss_function", ",", "input_type", ",", "out_every_t", ")", "\n", "inputs", "=", "[", "x", ",", "y", "]", "\n", "\n", "h_0", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "n_hidden", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "V", "=", "initialize_matrix", "(", "n_input", ",", "n_hidden", ",", "'V'", ",", "rng", ")", "\n", "W", "=", "initialize_matrix", "(", "n_hidden", ",", "n_hidden", ",", "'W'", ",", "rng", ")", "\n", "out_mat", "=", "initialize_matrix", "(", "n_hidden", ",", "n_output", ",", "'out_mat'", ",", "rng", ")", "\n", "hidden_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_hidden", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "out_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_output", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "parameters", "=", "[", "h_0", ",", "V", ",", "W", ",", "out_mat", ",", "hidden_bias", ",", "out_bias", "]", "\n", "\n", "def", "recurrence", "(", "x_t", ",", "y_t", ",", "h_prev", ",", "cost_prev", ",", "acc_prev", ",", "V", ",", "W", ",", "hidden_bias", ",", "out_mat", ",", "out_bias", ")", ":", "\n", "        ", "if", "loss_function", "==", "'CE'", ":", "\n", "            ", "data_lin_output", "=", "V", "[", "x_t", "]", "\n", "", "else", ":", "\n", "            ", "data_lin_output", "=", "T", ".", "dot", "(", "x_t", ",", "V", ")", "\n", "\n", "", "h_t", "=", "T", ".", "tanh", "(", "T", ".", "dot", "(", "h_prev", ",", "W", ")", "+", "data_lin_output", "+", "hidden_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ")", "\n", "if", "out_every_t", ":", "\n", "            ", "lin_output", "=", "T", ".", "dot", "(", "h_t", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "cost_t", ",", "acc_t", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ")", "\n", "", "else", ":", "\n", "            ", "cost_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "acc_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "\n", "", "return", "h_t", ",", "cost_t", ",", "acc_t", "\n", "\n", "", "non_sequences", "=", "[", "V", ",", "W", ",", "hidden_bias", ",", "out_mat", ",", "out_bias", "]", "\n", "\n", "h_0_batch", "=", "T", ".", "tile", "(", "h_0", ",", "[", "x", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "\n", "if", "out_every_t", ":", "\n", "        ", "sequences", "=", "[", "x", ",", "y", "]", "\n", "", "else", ":", "\n", "        ", "sequences", "=", "[", "x", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "\n", "", "outputs_info", "=", "[", "h_0_batch", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "]", "\n", "\n", "[", "hidden_states", ",", "cost_steps", ",", "acc_steps", "]", ",", "updates", "=", "theano", ".", "scan", "(", "fn", "=", "recurrence", ",", "\n", "sequences", "=", "sequences", ",", "\n", "non_sequences", "=", "non_sequences", ",", "\n", "outputs_info", "=", "outputs_info", ")", "\n", "\n", "if", "not", "out_every_t", ":", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", "[", "-", "1", ",", ":", ",", ":", "]", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "costs", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y", ")", "\n", "", "else", ":", "\n", "        ", "cost", "=", "cost_steps", ".", "mean", "(", ")", "\n", "accuracy", "=", "acc_steps", ".", "mean", "(", ")", "\n", "costs", "=", "[", "cost", ",", "accuracy", "]", "\n", "\n", "", "return", "inputs", ",", "parameters", ",", "costs", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.LSTM": [[308, 467], ["numpy.random.seed", "numpy.random.RandomState", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "models.initialize_matrix", "theano.shared", "theano.shared", "models.initialize_data_nodes", "theano.tile", "theano.tile", "theano.scan", "theano.scan", "numpy.zeros", "numpy.ones", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "theano.nnet.sigmoid", "theano.tanh", "theano.nnet.sigmoid", "theano.nnet.sigmoid", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "models.compute_cost_t", "T.mean.mean", "acc_steps.mean", "theano.shared", "theano.shared", "theano.dot", "theano.dot", "theano.dot", "theano.dot", "theano.tanh", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "numpy.float32", "numpy.float32", "theano.dot", "theano.shared.dimshuffle", "theano.dot", "theano.shared.dimshuffle", "theano.cos", "theano.sin", "numpy.sqrt", "theano.concatenate", "theano.mean", "theano.sum", "theano.nnet.softmax", "theano.nnet.categorical_crossentropy().mean", "theano.eq().mean", "numpy.float32", "theano.matrix", "theano.vector", "theano.tensor3", "theano.matrix", "theano.shared.dimshuffle", "theano.shared.dimshuffle", "theano.shared.dimshuffle", "theano.shared.dimshuffle", "theano.dot", "theano.shared.dimshuffle", "models.compute_cost_t", "models.compute_cost_t", "numpy.float32", "numpy.float32", "theano.tile", "theano.tile", "theano.tile", "theano.tile", "theano.tile", "theano.concatenate", "theano.concatenate", "theano.concatenate", "theano.dot", "theano.concatenate", "theano.concatenate", "theano.concatenate", "theano.dot", "theano.mean", "theano.dot", "theano.dot", "theano.dot", "theano.dot", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "ymask[].dimshuffle", "cost_weight.dimshuffle", "cost_weight.dimshuffle", "theano.nnet.categorical_crossentropy", "theano.eq", "theano.dot", "numpy.ones", "numpy.zeros", "numpy.ones", "numpy.zeros", "numpy.ones", "ymask[].dimshuffle", "theano.argmax"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_data_nodes", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t"], ["", "def", "LSTM", "(", "n_input", ",", "n_hidden", ",", "n_output", ",", "input_type", "=", "'real'", ",", "out_every_t", "=", "False", ",", "loss_function", "=", "'CE'", ",", "flag_use_mask", "=", "False", ",", "flag_return_lin_output", "=", "False", ",", "flag_return_hidden_states", "=", "False", ",", "cost_weight", "=", "None", ",", "cost_transform", "=", "None", ",", "seed", "=", "1234", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "W_i", "=", "initialize_matrix", "(", "n_input", ",", "n_hidden", ",", "'W_i'", ",", "rng", ")", "\n", "W_f", "=", "initialize_matrix", "(", "n_input", ",", "n_hidden", ",", "'W_f'", ",", "rng", ")", "\n", "W_c", "=", "initialize_matrix", "(", "n_input", ",", "n_hidden", ",", "'W_c'", ",", "rng", ")", "\n", "W_o", "=", "initialize_matrix", "(", "n_input", ",", "n_hidden", ",", "'W_o'", ",", "rng", ")", "\n", "U_i", "=", "initialize_matrix", "(", "n_hidden", ",", "n_hidden", ",", "'U_i'", ",", "rng", ")", "\n", "U_f", "=", "initialize_matrix", "(", "n_hidden", ",", "n_hidden", ",", "'U_f'", ",", "rng", ")", "\n", "U_c", "=", "initialize_matrix", "(", "n_hidden", ",", "n_hidden", ",", "'U_c'", ",", "rng", ")", "\n", "U_o", "=", "initialize_matrix", "(", "n_hidden", ",", "n_hidden", ",", "'U_o'", ",", "rng", ")", "\n", "V_o", "=", "initialize_matrix", "(", "n_hidden", ",", "n_hidden", ",", "'V_o'", ",", "rng", ")", "\n", "b_i", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_hidden", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "b_f", "=", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "n_hidden", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "b_c", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_hidden", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "b_o", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_hidden", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "h_0", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "n_hidden", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "state_0", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "n_hidden", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "out_mat", "=", "initialize_matrix", "(", "n_hidden", ",", "n_output", ",", "'out_mat'", ",", "rng", ")", "\n", "out_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_output", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "parameters", "=", "[", "W_i", ",", "W_f", ",", "W_c", ",", "W_o", ",", "U_i", ",", "U_f", ",", "U_c", ",", "U_o", ",", "V_o", ",", "b_i", ",", "b_f", ",", "b_c", ",", "b_o", ",", "h_0", ",", "state_0", ",", "out_mat", ",", "out_bias", "]", "\n", "\n", "x", ",", "y", "=", "initialize_data_nodes", "(", "loss_function", ",", "input_type", ",", "out_every_t", ")", "\n", "if", "flag_use_mask", ":", "\n", "        ", "if", "loss_function", "==", "'CE'", ":", "\n", "            ", "ymask", "=", "T", ".", "matrix", "(", "dtype", "=", "'int8'", ")", "if", "out_every_t", "else", "T", ".", "vector", "(", "dtype", "=", "'int8'", ")", "\n", "", "else", ":", "\n", "# y will be n_fram x n_output x n_utt", "\n", "            ", "ymask", "=", "T", ".", "tensor3", "(", "dtype", "=", "'int8'", ")", "if", "out_every_t", "else", "T", ".", "matrix", "(", "dtype", "=", "'int8'", ")", "\n", "\n", "", "", "def", "recurrence", "(", "x_t", ",", "y_t", ",", "ymask_t", ",", "h_prev", ",", "state_prev", ",", "cost_prev", ",", "acc_prev", ",", "\n", "W_i", ",", "W_f", ",", "W_c", ",", "W_o", ",", "U_i", ",", "U_f", ",", "U_c", ",", "U_o", ",", "V_o", ",", "b_i", ",", "b_f", ",", "b_c", ",", "b_o", ",", "out_mat", ",", "out_bias", ")", ":", "\n", "\n", "        ", "if", "(", "loss_function", "==", "'CE'", ")", "and", "(", "input_type", "==", "'categorical'", ")", ":", "\n", "            ", "x_t_W_i", "=", "W_i", "[", "x_t", "]", "\n", "x_t_W_c", "=", "W_c", "[", "x_t", "]", "\n", "x_t_W_f", "=", "W_f", "[", "x_t", "]", "\n", "x_t_W_o", "=", "W_o", "[", "x_t", "]", "\n", "", "else", ":", "\n", "            ", "x_t_W_i", "=", "T", ".", "dot", "(", "x_t", ",", "W_i", ")", "\n", "x_t_W_c", "=", "T", ".", "dot", "(", "x_t", ",", "W_c", ")", "\n", "x_t_W_f", "=", "T", ".", "dot", "(", "x_t", ",", "W_f", ")", "\n", "x_t_W_o", "=", "T", ".", "dot", "(", "x_t", ",", "W_o", ")", "\n", "\n", "", "input_t", "=", "T", ".", "nnet", ".", "sigmoid", "(", "x_t_W_i", "+", "T", ".", "dot", "(", "h_prev", ",", "U_i", ")", "+", "b_i", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ")", "\n", "candidate_t", "=", "T", ".", "tanh", "(", "x_t_W_c", "+", "T", ".", "dot", "(", "h_prev", ",", "U_c", ")", "+", "b_c", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ")", "\n", "forget_t", "=", "T", ".", "nnet", ".", "sigmoid", "(", "x_t_W_f", "+", "T", ".", "dot", "(", "h_prev", ",", "U_f", ")", "+", "b_f", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ")", "\n", "\n", "state_t", "=", "input_t", "*", "candidate_t", "+", "forget_t", "*", "state_prev", "\n", "\n", "output_t", "=", "T", ".", "nnet", ".", "sigmoid", "(", "x_t_W_o", "+", "T", ".", "dot", "(", "h_prev", ",", "U_o", ")", "+", "T", ".", "dot", "(", "state_t", ",", "V_o", ")", "+", "b_o", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ")", "\n", "\n", "h_t", "=", "output_t", "*", "T", ".", "tanh", "(", "state_t", ")", "\n", "\n", "if", "out_every_t", ":", "\n", "            ", "lin_output", "=", "T", ".", "dot", "(", "h_t", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "if", "flag_use_mask", ":", "\n", "                ", "cost_t", ",", "acc_t", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ",", "ymask_t", "=", "ymask_t", ")", "\n", "", "else", ":", "\n", "                ", "cost_t", ",", "acc_t", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ")", "\n", "", "", "else", ":", "\n", "            ", "cost_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "acc_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "\n", "", "return", "h_t", ",", "state_t", ",", "cost_t", ",", "acc_t", "\n", "\n", "", "non_sequences", "=", "[", "W_i", ",", "W_f", ",", "W_c", ",", "W_o", ",", "U_i", ",", "U_f", ",", "U_c", ",", "U_o", ",", "V_o", ",", "b_i", ",", "b_f", ",", "b_c", ",", "b_o", ",", "out_mat", ",", "out_bias", "]", "\n", "\n", "h_0_batch", "=", "T", ".", "tile", "(", "h_0", ",", "[", "x", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "state_0_batch", "=", "T", ".", "tile", "(", "state_0", ",", "[", "x", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "\n", "if", "out_every_t", ":", "\n", "        ", "if", "flag_use_mask", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "y", ",", "ymask", "]", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "y", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "flag_use_mask", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "\n", "\n", "", "", "outputs_info", "=", "[", "h_0_batch", ",", "state_0_batch", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "]", "\n", "\n", "[", "hidden_states", ",", "states", ",", "cost_steps", ",", "acc_steps", "]", ",", "updates", "=", "theano", ".", "scan", "(", "fn", "=", "recurrence", ",", "\n", "sequences", "=", "sequences", ",", "\n", "non_sequences", "=", "non_sequences", ",", "\n", "outputs_info", "=", "outputs_info", ")", "\n", "\n", "if", "flag_return_lin_output", ":", "\n", "#if output_type=='complex':", "\n", "#    lin_output = T.dot(hidden_states, out_mat) + out_bias.dimshuffle('x',0)", "\n", "#elif output_type=='real':", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "\n", "", "if", "not", "out_every_t", ":", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", "[", "-", "1", ",", ":", ",", ":", "]", ",", "out_mat", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "costs", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y", ")", "\n", "cost", "=", "costs", "[", "0", "]", "\n", "accuracy", "=", "costs", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "if", "(", "cost_transform", "==", "'magTimesPhase'", ")", ":", "\n", "            ", "cosPhase", "=", "T", ".", "cos", "(", "lin_output", ")", "\n", "sinPhase", "=", "T", ".", "sin", "(", "lin_output", ")", "\n", "linMag", "=", "np", ".", "sqrt", "(", "10", "**", "(", "x", "/", "10.0", ")", "-", "1e-5", ")", "\n", "yest_real", "=", "linMag", "*", "cosPhase", "\n", "yest_imag", "=", "linMag", "*", "sinPhase", "\n", "yest", "=", "T", ".", "concatenate", "(", "[", "yest_real", ",", "yest_imag", "]", ",", "axis", "=", "2", ")", "\n", "mse", "=", "(", "yest", "-", "y", ")", "**", "2", "\n", "cost_steps", "=", "T", ".", "mean", "(", "mse", "*", "ymask", "[", ":", ",", ":", ",", "0", "]", ".", "dimshuffle", "(", "0", ",", "1", ",", "'x'", ")", ",", "axis", "=", "2", ")", "\n", "", "elif", "cost_transform", "is", "not", "None", ":", "\n", "# assume that cost_transform is an inverse DFT followed by synthesis windowing", "\n", "            ", "lin_output_real", "=", "lin_output", "[", ":", ",", ":", ",", ":", "n_output", "//", "2", "]", "\n", "lin_output_imag", "=", "lin_output", "[", ":", ",", ":", ",", "n_output", "//", "2", ":", "]", "\n", "lin_output_sym_real", "=", "T", ".", "concatenate", "(", "[", "lin_output_real", ",", "lin_output_real", "[", ":", ",", ":", ",", "n_output", "//", "2", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "lin_output_sym_imag", "=", "T", ".", "concatenate", "(", "[", "-", "lin_output_imag", ",", "lin_output_imag", "[", ":", ",", ":", ",", "n_output", "//", "2", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "lin_output_sym", "=", "T", ".", "concatenate", "(", "[", "lin_output_sym_real", ",", "lin_output_sym_imag", "]", ",", "axis", "=", "2", ")", "\n", "yest_xform", "=", "T", ".", "dot", "(", "lin_output_sym", ",", "cost_transform", ")", "\n", "# apply synthesis window", "\n", "yest_xform", "=", "yest_xform", "*", "cost_weight", ".", "dimshuffle", "(", "'x'", ",", "'x'", ",", "0", ")", "\n", "y_real", "=", "y", "[", ":", ",", ":", ",", ":", "n_output", "//", "2", "]", "\n", "y_imag", "=", "y", "[", ":", ",", ":", ",", "n_output", "//", "2", ":", "]", "\n", "y_sym_real", "=", "T", ".", "concatenate", "(", "[", "y_real", ",", "y_real", "[", ":", ",", ":", ",", "n_output", "//", "2", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "y_sym_imag", "=", "T", ".", "concatenate", "(", "[", "-", "y_imag", ",", "y_imag", "[", ":", ",", ":", ",", "n_output", "//", "2", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "y_sym", "=", "T", ".", "concatenate", "(", "[", "y_sym_real", ",", "y_sym_imag", "]", ",", "axis", "=", "2", ")", "\n", "y_xform", "=", "T", ".", "dot", "(", "y_sym", ",", "cost_transform", ")", "\n", "# apply synthesis window", "\n", "y_xform", "=", "y_xform", "*", "cost_weight", ".", "dimshuffle", "(", "'x'", ",", "'x'", ",", "0", ")", "\n", "mse", "=", "(", "y_xform", "-", "yest_xform", ")", "**", "2", "\n", "cost_steps", "=", "T", ".", "mean", "(", "mse", "*", "ymask", "[", ":", ",", ":", ",", "0", "]", ".", "dimshuffle", "(", "0", ",", "1", ",", "'x'", ")", ",", "axis", "=", "2", ")", "\n", "", "cost", "=", "cost_steps", ".", "mean", "(", ")", "\n", "accuracy", "=", "acc_steps", ".", "mean", "(", ")", "\n", "costs", "=", "[", "cost", ",", "accuracy", "]", "\n", "\n", "if", "(", "loss_function", "==", "'CE_of_sum'", ")", ":", "\n", "            ", "yest", "=", "T", ".", "sum", "(", "lin_output", ",", "axis", "=", "0", ")", "#sum over time_steps, yest is Nseq x n_output", "\n", "yest_softmax", "=", "T", ".", "nnet", ".", "softmax", "(", "yest", ")", "\n", "cost", "=", "T", ".", "nnet", ".", "categorical_crossentropy", "(", "yest_softmax", ",", "y", "[", "0", ",", ":", "]", ")", ".", "mean", "(", ")", "\n", "accuracy", "=", "T", ".", "eq", "(", "T", ".", "argmax", "(", "yest", ",", "axis", "=", "-", "1", ")", ",", "y", "[", "0", ",", ":", "]", ")", ".", "mean", "(", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "costs", "=", "[", "cost", ",", "accuracy", "]", "\n", "\n", "", "", "if", "flag_return_lin_output", ":", "\n", "        ", "costs", "=", "[", "cost", ",", "accuracy", ",", "lin_output", "]", "\n", "\n", "if", "flag_return_hidden_states", ":", "\n", "            ", "costs", "=", "costs", "+", "[", "hidden_states", "]", "\n", "\n", "#nmse_local = ymask.dimshuffle(0,1)*( (lin_output-y)**2 )/( 1e-5 + y**2 )", "\n", "", "nmse_local", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "costs", "=", "costs", "+", "[", "nmse_local", "]", "\n", "\n", "costs", "=", "costs", "+", "[", "cost_steps", "]", "\n", "\n", "", "if", "flag_use_mask", ":", "\n", "        ", "return", "[", "x", ",", "y", ",", "ymask", "]", ",", "parameters", ",", "costs", "\n", "", "else", ":", "\n", "        ", "return", "[", "x", ",", "y", "]", ",", "parameters", ",", "costs", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_unitary": [[468, 519], ["models.initialize_matrix", "theano.shared", "theano.shared", "rng.permutation", "numpy.concatenate", "numpy.asarray", "rng.uniform", "models.initialize_matrix", "theano.shared", "theano.shared", "rng.permutation", "numpy.concatenate", "numpy.eye().astype", "numpy.zeros().astype", "numpy.concatenate", "numpy.concatenate", "models.times_unitary", "theano.shared", "theano.shared", "numpy.asarray", "times_unitary.eval().astype", "numpy.eye().astype", "numpy.zeros().astype", "numpy.concatenate", "theano.shared", "theano.shared", "rng.uniform", "numpy.eye", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.arange", "numpy.arange", "times_unitary.eval", "numpy.eye", "numpy.zeros", "numpy.concatenate", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary"], ["", "", "def", "initialize_unitary", "(", "n", ",", "impl", ",", "rng", ",", "name_suffix", "=", "''", ",", "init", "=", "'rand'", ")", ":", "\n", "\n", "    ", "if", "(", "'adhoc'", "in", "impl", ")", ":", "\n", "# restricted parameterization of Arjovsky, Shah, and Bengio 2015", "\n", "        ", "reflection", "=", "initialize_matrix", "(", "2", ",", "2", "*", "n", ",", "'reflection'", "+", "name_suffix", ",", "rng", ")", "\n", "theta", "=", "theano", ".", "shared", "(", "np", ".", "asarray", "(", "rng", ".", "uniform", "(", "low", "=", "-", "np", ".", "pi", ",", "\n", "high", "=", "np", ".", "pi", ",", "\n", "size", "=", "(", "3", ",", "n", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ",", "\n", "name", "=", "'theta'", "+", "name_suffix", ")", "\n", "\n", "index_permute", "=", "rng", ".", "permutation", "(", "n", ")", "\n", "index_permute_long", "=", "np", ".", "concatenate", "(", "(", "index_permute", ",", "index_permute", "+", "n", ")", ")", "\n", "\n", "Wparams", "=", "[", "theta", ",", "reflection", ",", "index_permute_long", "]", "\n", "", "elif", "(", "impl", "==", "'full'", ")", ":", "\n", "        ", "\"\"\"\n        # fixed full unitary matrix\n        Z=rng.randn(n,n).astype(np.complex64)+1j*rng.randn(n,n).astype(np.complex64)\n        UZ, SZ, VZ=np.linalg.svd(Z)\n        Wc=np.dot(UZ,VZ)\n        WcRe=np.transpose(np.real(Wc))\n        WcIm=np.transpose(np.imag(Wc))\n        Waug = theano.shared(np.concatenate( [np.concatenate([WcRe,WcIm],axis=1),np.concatenate([(-1)*WcIm,WcRe],axis=1)], axis=0),name='Waug'+name_suffix)\n        \"\"\"", "\n", "if", "(", "init", "==", "'rand'", ")", ":", "\n", "# use ad-hoc for initialization", "\n", "            ", "reflection", "=", "initialize_matrix", "(", "2", ",", "2", "*", "n", ",", "'reflection'", "+", "name_suffix", ",", "rng", ")", "\n", "theta", "=", "theano", ".", "shared", "(", "np", ".", "asarray", "(", "rng", ".", "uniform", "(", "low", "=", "-", "np", ".", "pi", ",", "\n", "high", "=", "np", ".", "pi", ",", "\n", "size", "=", "(", "3", ",", "n", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ",", "\n", "name", "=", "'theta'", "+", "name_suffix", ")", "\n", "\n", "index_permute", "=", "rng", ".", "permutation", "(", "n", ")", "\n", "index_permute_long", "=", "np", ".", "concatenate", "(", "(", "index_permute", ",", "index_permute", "+", "n", ")", ")", "\n", "\n", "WcRe", "=", "np", ".", "eye", "(", "n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "WcIm", "=", "np", ".", "zeros", "(", "(", "n", ",", "n", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "Waug", "=", "np", ".", "concatenate", "(", "[", "np", ".", "concatenate", "(", "[", "WcRe", ",", "WcIm", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "concatenate", "(", "[", "WcIm", ",", "WcRe", "]", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "\n", "swap_re_im", "=", "np", ".", "concatenate", "(", "(", "np", ".", "arange", "(", "n", ",", "2", "*", "n", ")", ",", "np", ".", "arange", "(", "n", ")", ")", ")", "\n", "Waug_variable", "=", "times_unitary", "(", "Waug", ",", "n", ",", "swap_re_im", ",", "[", "theta", ",", "reflection", ",", "index_permute_long", "]", ",", "'adhoc'", ")", "\n", "Waug", "=", "theano", ".", "shared", "(", "Waug_variable", ".", "eval", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "name", "=", "'Waug'", "+", "name_suffix", ")", "\n", "", "elif", "(", "init", "==", "'identity'", ")", ":", "\n", "            ", "WcRe", "=", "np", ".", "eye", "(", "n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "WcIm", "=", "np", ".", "zeros", "(", "(", "n", ",", "n", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "Waug_np", "=", "np", ".", "concatenate", "(", "[", "np", ".", "concatenate", "(", "[", "WcRe", ",", "WcIm", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "concatenate", "(", "[", "WcIm", ",", "WcRe", "]", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "\n", "Waug", "=", "theano", ".", "shared", "(", "Waug_np", ",", "name", "=", "'Waug'", "+", "name_suffix", ")", "\n", "", "Wparams", "=", "[", "Waug", "]", "\n", "\n", "", "return", "Wparams", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_complex_RNN_layer": [[520, 551], ["models.initialize_unitary", "theano.shared", "theano.shared", "numpy.sqrt", "theano.shared", "theano.shared", "numpy.asarray", "theano.shared", "theano.shared", "ValueError", "numpy.asarray", "theano.shared", "theano.shared", "ValueError", "numpy.zeros().astype", "rng.uniform", "numpy.zeros().astype", "rng.uniform", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_unitary"], ["", "def", "initialize_complex_RNN_layer", "(", "n_hidden", ",", "Wimpl", ",", "rng", ",", "hidden_bias_mean", ",", "name_suffix", "=", "''", ",", "hidden_bias_init", "=", "'rand'", ",", "h_0_init", "=", "'rand'", ",", "W_init", "=", "'rand'", ")", ":", "\n", "# hidden bias", "\n", "    ", "if", "(", "hidden_bias_init", "==", "'rand'", ")", ":", "\n", "        ", "hidden_bias", "=", "theano", ".", "shared", "(", "np", ".", "asarray", "(", "hidden_bias_mean", "+", "rng", ".", "uniform", "(", "low", "=", "-", "0.01", ",", "\n", "high", "=", "0.01", ",", "\n", "size", "=", "(", "n_hidden", ",", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ",", "\n", "name", "=", "'hidden_bias'", "+", "name_suffix", ")", "\n", "", "elif", "(", "hidden_bias_init", "==", "'zero'", ")", ":", "\n", "        ", "hidden_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_hidden", ",", ")", ")", ".", "astype", "(", "theano", ".", "config", ".", "floatX", ")", ",", "name", "=", "'hidden_bias'", "+", "name_suffix", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown initialization method %s for hidden_bias\"", "%", "hidden_bias_init", ")", "\n", "\n", "# initial state h_0", "\n", "", "h_0_size", "=", "(", "1", ",", "2", "*", "n_hidden", ")", "\n", "if", "(", "h_0_init", "==", "'rand'", ")", ":", "\n", "        ", "bucket", "=", "np", ".", "sqrt", "(", "3.", "/", "2", "/", "n_hidden", ")", "\n", "h_0", "=", "theano", ".", "shared", "(", "np", ".", "asarray", "(", "rng", ".", "uniform", "(", "low", "=", "-", "bucket", ",", "\n", "high", "=", "bucket", ",", "\n", "size", "=", "h_0_size", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ",", "\n", "name", "=", "'h_0'", "+", "name_suffix", ")", "\n", "", "elif", "(", "h_0_init", "==", "'zero'", ")", ":", "\n", "        ", "h_0", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "h_0_size", ")", ".", "astype", "(", "theano", ".", "config", ".", "floatX", ")", ",", "name", "=", "'h_0'", "+", "name_suffix", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown initialization method %s for h_0\"", "%", "h_0_init", ")", "\n", "\n", "# unitary transition matrix W", "\n", "", "Wparams", "=", "initialize_unitary", "(", "n_hidden", ",", "Wimpl", ",", "rng", ",", "name_suffix", "=", "name_suffix", ",", "init", "=", "W_init", ")", "\n", "\n", "return", "hidden_bias", ",", "h_0", ",", "Wparams", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary": [[552, 571], ["models.times_diag", "models.do_fft", "models.times_reflection", "models.vec_permutation", "models.times_diag", "models.do_ifft", "models.times_reflection", "models.times_diag", "theano.dot", "numpy.np.float32"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_diag", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.do_fft", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_reflection", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.vec_permutation", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_diag", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.do_ifft", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_reflection", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_diag"], ["", "def", "times_unitary", "(", "x", ",", "n", ",", "swap_re_im", ",", "Wparams", ",", "Wimpl", ")", ":", "\n", "# multiply tensor x on the right  by the unitary matrix W parameterized by Wparams", "\n", "    ", "if", "(", "Wimpl", "==", "'adhoc'", ")", ":", "\n", "        ", "theta", "=", "Wparams", "[", "0", "]", "\n", "reflection", "=", "Wparams", "[", "1", "]", "\n", "index_permute_long", "=", "Wparams", "[", "2", "]", "\n", "step1", "=", "times_diag", "(", "x", ",", "n", ",", "theta", "[", "0", ",", ":", "]", ",", "swap_re_im", ")", "\n", "step2", "=", "do_fft", "(", "step1", ",", "n", ")", "\n", "step3", "=", "times_reflection", "(", "step2", ",", "n", ",", "reflection", "[", "0", ",", ":", "]", ")", "\n", "step4", "=", "vec_permutation", "(", "step3", ",", "index_permute_long", ")", "\n", "step5", "=", "times_diag", "(", "step4", ",", "n", ",", "theta", "[", "1", ",", ":", "]", ",", "swap_re_im", ")", "\n", "step6", "=", "do_ifft", "(", "step5", ",", "n", ")", "\n", "step7", "=", "times_reflection", "(", "step6", ",", "n", ",", "reflection", "[", "1", ",", ":", "]", ")", "\n", "step8", "=", "times_diag", "(", "step7", ",", "n", ",", "theta", "[", "2", ",", ":", "]", ",", "swap_re_im", ")", "\n", "y", "=", "step8", "\n", "", "elif", "(", "Wimpl", "==", "'full'", ")", ":", "\n", "        ", "Waug", "=", "Wparams", "[", "0", "]", "\n", "y", "=", "T", ".", "dot", "(", "x", ",", "Waug", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.complex_RNN": [[573, 988], ["numpy.random.RandomState", "numpy.random.seed", "numpy.random.RandomState", "models.initialize_complex_RNN_layer", "numpy.concatenate", "range", "models.initialize_data_nodes", "theano.tile", "theano.scan", "theano.scan", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "models.initialize_matrix", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "numpy.eye().astype", "numpy.zeros().astype", "numpy.concatenate", "models.times_unitary", "models.initialize_unitary", "models.initialize_complex_RNN_layer", "theano.concatenate", "theano.sqrt", "range", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "models.compute_cost_t", "T.mean.mean", "acc_steps.mean", "theano.shared", "theano.shared", "theano.sqrt", "theano.concatenate", "theano.concatenate", "theano.concatenate", "theano.sqrt", "theano.concatenate", "theano.concatenate", "theano.concatenate", "numpy.zeros", "numpy.zeros", "numpy.arange", "numpy.arange", "theano.shared", "theano.shared", "numpy.eye().astype", "numpy.zeros().astype", "numpy.concatenate", "models.times_unitary", "numpy.eye().astype", "numpy.zeros().astype", "numpy.concatenate", "models.times_unitary", "models.times_unitary", "theano.dot", "theano.maximum", "models.times_unitary", "theano.sqrt", "theano.concatenate", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "numpy.float32", "numpy.float32", "theano.dot", "theano.shared.dimshuffle", "theano.cos", "theano.sin", "numpy.sqrt", "theano.concatenate", "theano.mean", "theano.sum", "theano.nnet.softmax", "theano.nnet.categorical_crossentropy().mean", "theano.eq().mean", "numpy.float32", "theano.sqrt", "theano.sqrt", "numpy.eye", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.asarray", "theano.matrix", "theano.vector", "theano.tensor3", "theano.matrix", "models.times_unitary", "theano.maximum", "theano.dot", "theano.shared.dimshuffle", "models.compute_cost_t", "models.compute_cost_t", "numpy.float32", "numpy.float32", "theano.tile", "theano.tile", "theano.tile", "theano.tile", "theano.tile", "theano.dot", "theano.shared.dimshuffle", "theano.dot", "theano.shared.dimshuffle", "theano.concatenate", "theano.concatenate", "theano.concatenate", "theano.dot", "theano.concatenate", "theano.concatenate", "theano.concatenate", "theano.dot", "theano.mean", "theano.sum", "theano.sum", "numpy.zeros", "numpy.eye", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.eye", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "theano.cast", "theano.tile().dimshuffle", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "ymask[].dimshuffle", "cost_weight.dimshuffle", "cost_weight.dimshuffle", "theano.nnet.categorical_crossentropy", "theano.eq", "theano.sum", "theano.sum", "theano.tile().dimshuffle", "numpy.ones", "numpy.zeros", "numpy.ones", "numpy.zeros", "numpy.ones", "ymask[].dimshuffle", "theano.argmax", "theano.tile", "theano.tile"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_complex_RNN_layer", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_data_nodes", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_matrix", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.initialize_complex_RNN_layer", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.times_unitary", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t", "home.repos.pwc.inspect_result.stwisdom_urnn.None.models.compute_cost_t"], ["", "def", "complex_RNN", "(", "n_input", ",", "n_hidden", ",", "n_output", ",", "input_type", "=", "'real'", ",", "out_every_t", "=", "False", ",", "loss_function", "=", "'CE'", ",", "output_type", "=", "'real'", ",", "fidx", "=", "None", ",", "flag_return_lin_output", "=", "False", ",", "name_suffix", "=", "''", ",", "x_spec", "=", "None", ",", "flag_feed_forward", "=", "False", ",", "flag_use_mask", "=", "False", ",", "hidden_bias_mean", "=", "0.0", ",", "lam", "=", "0.0", ",", "Wimpl", "=", "\"adhoc\"", ",", "prng_Givens", "=", "np", ".", "random", ".", "RandomState", "(", ")", ",", "Vnorm", "=", "0.0", ",", "Unorm", "=", "0.0", ",", "flag_return_hidden_states", "=", "False", ",", "n_layers", "=", "1", ",", "cost_weight", "=", "None", ",", "cost_transform", "=", "None", ",", "flag_noComplexConstraint", "=", "0", ",", "seed", "=", "1234", ",", "V_init", "=", "'rand'", ",", "U_init", "=", "'rand'", ",", "W_init", "=", "'rand'", ",", "h_0_init", "=", "'rand'", ",", "out_bias_init", "=", "'rand'", ",", "hidden_bias_init", "=", "'rand'", ",", "flag_add_input_to_output", "=", "False", ")", ":", "\n", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "# Initialize input and output parameters: V, U, out_bias0", "\n", "\n", "# input matrix V", "\n", "if", "flag_noComplexConstraint", "and", "(", "input_type", "==", "'complex'", ")", ":", "\n", "        ", "V", "=", "initialize_matrix", "(", "2", "*", "n_input", ",", "2", "*", "n_hidden", ",", "'V'", "+", "name_suffix", ",", "rng", ",", "init", "=", "V_init", ")", "\n", "Vaug", "=", "V", "\n", "", "else", ":", "\n", "        ", "V", "=", "initialize_matrix", "(", "n_input", ",", "2", "*", "n_hidden", ",", "'V'", "+", "name_suffix", ",", "rng", ",", "init", "=", "V_init", ")", "\n", "if", "(", "Vnorm", ">", "0.0", ")", ":", "\n", "# normalize the rows of V by the L2 norm (note that the variable V here is actually V^T, so we normalize the columns)", "\n", "            ", "Vr", "=", "V", "[", ":", ",", ":", "n_hidden", "]", "\n", "Vi", "=", "V", "[", ":", ",", "n_hidden", ":", "]", "\n", "Vnorms", "=", "T", ".", "sqrt", "(", "1e-5", "+", "T", ".", "sum", "(", "Vr", "**", "2", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "+", "T", ".", "sum", "(", "Vi", "**", "2", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "\n", "Vn", "=", "T", ".", "concatenate", "(", "[", "Vr", "/", "(", "1e-5", "+", "Vnorms", ")", ",", "Vi", "/", "(", "1e-5", "+", "Vnorms", ")", "]", ",", "axis", "=", "1", ")", "\n", "# scale so row norms are desired number", "\n", "Vn", "=", "V", "*", "T", ".", "sqrt", "(", "Vnorm", ")", "\n", "", "else", ":", "\n", "            ", "Vn", "=", "V", "\n", "\n", "", "if", "input_type", "==", "'complex'", ":", "\n", "            ", "Vim", "=", "T", ".", "concatenate", "(", "[", "(", "-", "1", ")", "*", "Vn", "[", ":", ",", "n_hidden", ":", "]", ",", "Vn", "[", ":", ",", ":", "n_hidden", "]", "]", ",", "axis", "=", "1", ")", "#concatenate along columns to make [-V_I, V_R]", "\n", "Vaug", "=", "T", ".", "concatenate", "(", "[", "Vn", ",", "Vim", "]", ",", "axis", "=", "0", ")", "#concatenate along rows to make [V_R, V_I; -V_I, V_R]", "\n", "\n", "\n", "# output matrix U", "\n", "", "", "if", "flag_noComplexConstraint", "and", "(", "input_type", "==", "'complex'", ")", ":", "\n", "        ", "U", "=", "initialize_matrix", "(", "2", "*", "n_hidden", ",", "2", "*", "n_output", ",", "'U'", "+", "name_suffix", ",", "rng", ",", "init", "=", "U_init", ")", "\n", "Uaug", "=", "U", "\n", "", "else", ":", "\n", "        ", "U", "=", "initialize_matrix", "(", "2", "*", "n_hidden", ",", "n_output", ",", "'U'", "+", "name_suffix", ",", "rng", ",", "init", "=", "U_init", ")", "\n", "if", "(", "Unorm", ">", "0.0", ")", ":", "\n", "# normalize the cols of U by the L2 norm (note that the variable U here is actually U^H, so we normalize the rows)", "\n", "            ", "Ur", "=", "U", "[", ":", "n_hidden", ",", ":", "]", "\n", "Ui", "=", "U", "[", "n_hidden", ":", ",", ":", "]", "\n", "Unorms", "=", "T", ".", "sqrt", "(", "1e-5", "+", "T", ".", "sum", "(", "Ur", "**", "2", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "+", "T", ".", "sum", "(", "Ui", "**", "2", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "Un", "=", "T", ".", "concatenate", "(", "[", "Ur", "/", "(", "1e-5", "+", "Unorms", ")", ",", "Ui", "/", "(", "1e-5", "+", "Unorms", ")", "]", ",", "axis", "=", "0", ")", "\n", "# scale so col norms are desired number", "\n", "Un", "=", "Un", "*", "T", ".", "sqrt", "(", "Unorm", ")", "\n", "", "else", ":", "\n", "            ", "Un", "=", "U", "\n", "\n", "", "if", "output_type", "==", "'complex'", ":", "\n", "            ", "Uim", "=", "T", ".", "concatenate", "(", "[", "(", "-", "1", ")", "*", "Un", "[", "n_hidden", ":", ",", ":", "]", ",", "Un", "[", ":", "n_hidden", ",", ":", "]", "]", ",", "axis", "=", "0", ")", "#concatenate along rows to make [-U_I; U_R]", "\n", "Uaug", "=", "T", ".", "concatenate", "(", "[", "Un", ",", "Uim", "]", ",", "axis", "=", "1", ")", "#concatante along cols to make [U_R, -U_I; U_I, U_R]", "\n", "# note that this is a little weird compared to the convention elsewhere in this code that", "\n", "# right-multiplication real-composite form is [A, B; -B, A]. The weirdness is because of the original", "\n", "# implementation, which initialized U for real-valued outputs as U=[A; B], which really should have", "\n", "# been U=[A; -B]", "\n", "\n", "\n", "# output bias out_bias", "\n", "", "", "if", "output_type", "==", "'complex'", ":", "\n", "        ", "out_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "2", "*", "n_output", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ",", "name", "=", "'out_bias'", "+", "name_suffix", ")", "\n", "", "else", ":", "\n", "        ", "out_bias", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "n_output", ",", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ",", "name", "=", "'out_bias'", "+", "name_suffix", ")", "\n", "\n", "\n", "# initialize layer 1 parameters", "\n", "", "hidden_bias", ",", "h_0", ",", "Wparams", "=", "initialize_complex_RNN_layer", "(", "n_hidden", ",", "Wimpl", ",", "rng", ",", "hidden_bias_mean", ",", "name_suffix", "=", "name_suffix", ",", "hidden_bias_init", "=", "hidden_bias_init", ",", "h_0_init", "=", "h_0_init", ",", "W_init", "=", "W_init", ")", "\n", "\n", "swap_re_im", "=", "np", ".", "concatenate", "(", "(", "np", ".", "arange", "(", "n_hidden", ",", "2", "*", "n_hidden", ")", ",", "np", ".", "arange", "(", "n_hidden", ")", ")", ")", "\n", "\n", "if", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "# create the full unitary matrix from the restricted parameters,", "\n", "# since we'll be using full matrix multiplies to implement the", "\n", "# unitary recurrence matrix", "\n", "        ", "Wparams_optim", "=", "Wparams", "\n", "IRe", "=", "np", ".", "eye", "(", "n_hidden", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "IIm", "=", "np", ".", "zeros", "(", "(", "n_hidden", ",", "n_hidden", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "Iaug", "=", "np", ".", "concatenate", "(", "[", "np", ".", "concatenate", "(", "[", "IRe", ",", "IIm", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "concatenate", "(", "[", "IIm", ",", "IRe", "]", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "\n", "Waug", "=", "times_unitary", "(", "Iaug", ",", "n_hidden", ",", "swap_re_im", ",", "Wparams_optim", ",", "'adhoc'", ")", "\n", "Wparams", "=", "[", "Waug", "]", "\n", "\n", "# extract recurrent parameters into this namespace ", "\n", "", "if", "flag_feed_forward", ":", "\n", "# just doing feed-foward, so remove any recurrent parameters", "\n", "        ", "if", "(", "'adhoc'", "in", "Wimpl", ")", ":", "\n", "#theta = theano.shared(np.float32(0.0))", "\n", "            ", "h_0_size", "=", "(", "1", ",", "2", "*", "n_hidden", ")", "\n", "h_0", "=", "theano", ".", "shared", "(", "np", ".", "asarray", "(", "np", ".", "zeros", "(", "h_0_size", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "\n", "\n", "", "parameters", "=", "[", "V", ",", "U", ",", "hidden_bias", ",", "out_bias", "]", "\n", "\n", "", "else", ":", "\n", "        ", "if", "(", "'adhoc'", "in", "Wimpl", ")", ":", "\n", "# restricted parameterization of Arjovsky, Shah, and Bengio 2015", "\n", "            ", "if", "(", "'fast'", "in", "Wimpl", ")", ":", "\n", "                ", "theta", "=", "Wparams_optim", "[", "0", "]", "\n", "reflection", "=", "Wparams_optim", "[", "1", "]", "\n", "index_permute_long", "=", "Wparams_optim", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "theta", "=", "Wparams", "[", "0", "]", "\n", "reflection", "=", "Wparams", "[", "1", "]", "\n", "index_permute_long", "=", "Wparams", "[", "2", "]", "\n", "\n", "", "parameters", "=", "[", "V", ",", "U", ",", "hidden_bias", ",", "reflection", ",", "out_bias", ",", "theta", ",", "h_0", "]", "\n", "#Wparams = [theta]", "\n", "", "elif", "(", "Wimpl", "==", "'full'", ")", ":", "\n", "# fixed full unitary matrix", "\n", "            ", "Waug", "=", "Wparams", "[", "0", "]", "\n", "\n", "parameters", "=", "[", "V", ",", "U", ",", "hidden_bias", ",", "out_bias", ",", "h_0", ",", "Waug", "]", "\n", "#Wparams = [Waug]", "\n", "\n", "", "", "h_0_all_layers", "=", "h_0", "\n", "\n", "# initialize additional layer parameters", "\n", "addl_layers_params", "=", "[", "]", "\n", "addl_layers_params_optim", "=", "[", "]", "\n", "for", "i_layer", "in", "range", "(", "2", ",", "n_layers", "+", "1", ")", ":", "\n", "        ", "betw_layer_suffix", "=", "'_L%d_to_L%d'", "%", "(", "i_layer", "-", "1", ",", "i_layer", ")", "\n", "layer_suffix", "=", "'_L%d'", "%", "i_layer", "\n", "\n", "# create cross-layer unitary matrix", "\n", "Wvparams_cur", "=", "initialize_unitary", "(", "n_hidden", ",", "Wimpl", ",", "rng", ",", "name_suffix", "=", "(", "name_suffix", "+", "betw_layer_suffix", ")", ",", "init", "=", "W_init", ")", "\n", "if", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "# create the full unitary matrix from the restricted parameters,", "\n", "# since we'll be using full matrix multiplies to implement the", "\n", "# unitary recurrence matrix", "\n", "            ", "Wvparams_cur_optim", "=", "Wvparams_cur", "\n", "IRe", "=", "np", ".", "eye", "(", "n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "IIm", "=", "np", ".", "zeros", "(", "(", "n_hidden", ",", "n_hidden", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "Iaug", "=", "np", ".", "concatenate", "(", "[", "np", ".", "concatenate", "(", "[", "IRe", ",", "IIm", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "concatenate", "(", "[", "IIm", ",", "IRe", "]", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "\n", "Wvaug", "=", "times_unitary", "(", "Iaug", ",", "n_hidden", ",", "swap_re_im", ",", "Wvparams_cur_optim", ",", "'adhoc'", ")", "\n", "Wvparams_cur", "=", "[", "Wvaug", "]", "\n", "\n", "# create parameters for this layer", "\n", "", "hidden_bias_cur", ",", "h_0_cur", ",", "Wparams_cur", "=", "initialize_complex_RNN_layer", "(", "n_hidden", ",", "Wimpl", ",", "rng", ",", "hidden_bias_mean", ",", "name_suffix", "=", "(", "name_suffix", "+", "layer_suffix", ")", ",", "hidden_bias_init", "=", "hidden_bias_init", ",", "h_0_init", "=", "h_0_init", ",", "W_init", "=", "W_init", ")", "\n", "if", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "# create the full unitary matrix from the restricted parameters,", "\n", "# since we'll be using full matrix multiplies to implement the", "\n", "# unitary recurrence matrix", "\n", "            ", "Wparams_cur_optim", "=", "Wparams_cur", "\n", "IRe", "=", "np", ".", "eye", "(", "n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "IIm", "=", "np", ".", "zeros", "(", "(", "n_hidden", ",", "n_hidden", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "Iaug", "=", "np", ".", "concatenate", "(", "[", "np", ".", "concatenate", "(", "[", "IRe", ",", "IIm", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "concatenate", "(", "[", "IIm", ",", "IRe", "]", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "\n", "Waug", "=", "times_unitary", "(", "Iaug", ",", "n_hidden", ",", "swap_re_im", ",", "Wparams_cur_optim", ",", "'adhoc'", ")", "\n", "Wparams_cur", "=", "[", "Waug", "]", "\n", "\n", "", "addl_layers_params", "=", "addl_layers_params", "+", "Wvparams_cur", "+", "[", "hidden_bias_cur", ",", "h_0_cur", "]", "+", "Wparams_cur", "\n", "if", "(", "Wimpl", "==", "'adhoc'", ")", ":", "\n", "# don't include permutation indices in the list of parameters to be optimized", "\n", "            ", "addl_layers_params_optim", "=", "addl_layers_params_optim", "+", "Wvparams_cur", "[", "0", ":", "2", "]", "+", "[", "hidden_bias_cur", ",", "h_0_cur", "]", "+", "Wparams_cur", "[", "0", ":", "2", "]", "\n", "", "elif", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "            ", "addl_layers_params_optim", "=", "addl_layers_params_optim", "+", "Wvparams_cur_optim", "[", "0", ":", "2", "]", "+", "[", "hidden_bias_cur", ",", "h_0_cur", "]", "+", "Wparams_cur_optim", "[", "0", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "addl_layers_params_optim", "=", "addl_layers_params", "\n", "\n", "", "h_0_all_layers", "=", "T", ".", "concatenate", "(", "[", "h_0_all_layers", ",", "h_0_cur", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "parameters", "=", "parameters", "+", "addl_layers_params_optim", "\n", "\n", "# initialize data nodes", "\n", "x", ",", "y", "=", "initialize_data_nodes", "(", "loss_function", ",", "input_type", ",", "out_every_t", ")", "\n", "if", "flag_use_mask", ":", "\n", "        ", "if", "'CE'", "in", "loss_function", ":", "\n", "            ", "ymask", "=", "T", ".", "matrix", "(", "dtype", "=", "'int8'", ")", "if", "out_every_t", "else", "T", ".", "vector", "(", "dtype", "=", "'int8'", ")", "\n", "", "else", ":", "\n", "# y will be n_fram x n_output x n_utt", "\n", "            ", "ymask", "=", "T", ".", "tensor3", "(", "dtype", "=", "'int8'", ")", "if", "out_every_t", "else", "T", ".", "matrix", "(", "dtype", "=", "'int8'", ")", "\n", "\n", "", "", "if", "x_spec", "is", "not", "None", ":", "\n", "# x is specified, set x to this:", "\n", "        ", "x", "=", "x_spec", "\n", "\n", "\n", "\n", "# define the recurrence used by theano.scan", "\n", "", "def", "recurrence", "(", "x_t", ",", "y_t", ",", "ymask_t", ",", "h_prev", ",", "cost_prev", ",", "acc_prev", ",", "V", ",", "hidden_bias", ",", "out_bias", ",", "U", ",", "*", "argv", ")", ":", "\n", "\n", "# h_prev is of size n_batch x n_layers*2*n_hidden", "\n", "\n", "# strip W parameters off variable arguments list", "\n", "        ", "if", "(", "Wimpl", "==", "'full'", ")", "or", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "            ", "Wparams", "=", "argv", "[", "0", ":", "1", "]", "\n", "argv", "=", "argv", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "Wparams", "=", "argv", "[", "0", ":", "3", "]", "\n", "argv", "=", "argv", "[", "3", ":", "]", "\n", "\n", "", "Wimpl_in_scan", "=", "Wimpl", "\n", "if", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "# just using a full matrix multiply is faster", "\n", "# than calling times_unitary with Wimpl='adhoc'", "\n", "            ", "Wimpl_in_scan", "=", "'full'", "\n", "\n", "", "if", "not", "flag_feed_forward", ":", "\n", "# Compute hidden linear transform: W h_{t-1}", "\n", "            ", "h_prev_layer1", "=", "h_prev", "[", ":", ",", "0", ":", "2", "*", "n_hidden", "]", "\n", "hidden_lin_output", "=", "times_unitary", "(", "h_prev_layer1", ",", "n_hidden", ",", "swap_re_im", ",", "Wparams", ",", "Wimpl_in_scan", ")", "\n", "\n", "# Compute data linear transform", "\n", "", "if", "(", "'CE'", "in", "loss_function", ")", "and", "(", "input_type", "==", "'categorical'", ")", ":", "\n", "# inputs are categorical, so just use them as indices into V", "\n", "            ", "data_lin_output", "=", "V", "[", "T", ".", "cast", "(", "x_t", ",", "'int32'", ")", "]", "\n", "", "else", ":", "\n", "# second dimension of real-valued x_t should be of size n_input, first dimension of V should be of size n_input", "\n", "# (or augmented, where the dimension of summation is 2*n_input and V is of real/imag. augmented form)", "\n", "            ", "data_lin_output", "=", "T", ".", "dot", "(", "x_t", ",", "V", ")", "\n", "\n", "# Total linear output        ", "\n", "", "if", "not", "flag_feed_forward", ":", "\n", "            ", "lin_output", "=", "hidden_lin_output", "+", "data_lin_output", "\n", "", "else", ":", "\n", "            ", "lin_output", "=", "data_lin_output", "\n", "\n", "# Apply non-linearity ----------------------------", "\n", "\n", "# scale RELU nonlinearity", "\n", "#  add a little bit to sqrt argument to ensure stable gradients,", "\n", "#  since gradient of sqrt(x) is -0.5/sqrt(x)", "\n", "", "modulus", "=", "T", ".", "sqrt", "(", "1e-5", "+", "lin_output", "**", "2", "+", "lin_output", "[", ":", ",", "swap_re_im", "]", "**", "2", ")", "\n", "rescale", "=", "T", ".", "maximum", "(", "modulus", "+", "T", ".", "tile", "(", "hidden_bias", ",", "[", "2", "]", ")", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ",", "0.", ")", "/", "(", "modulus", "+", "1e-5", ")", "\n", "h_t", "=", "lin_output", "*", "rescale", "\n", "\n", "h_t_all_layers", "=", "h_t", "\n", "\n", "# Compute additional recurrent layers", "\n", "for", "i_layer", "in", "range", "(", "2", ",", "n_layers", "+", "1", ")", ":", "\n", "\n", "# strip Wv parameters off variable arguments list", "\n", "            ", "if", "(", "Wimpl", "==", "'full'", ")", "or", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "                ", "Wvparams_cur", "=", "argv", "[", "0", ":", "1", "]", "\n", "argv", "=", "argv", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                ", "Wvparams_cur", "=", "argv", "[", "0", ":", "3", "]", "\n", "argv", "=", "argv", "[", "3", ":", "]", "\n", "\n", "# strip hidden_bias for this layer off argv", "\n", "", "hidden_bias_cur", "=", "argv", "[", "0", "]", "\n", "argv", "=", "argv", "[", "1", ":", "]", "\n", "\n", "# strip h_0 for this layer off argv", "\n", "#h_0_cur = argv[0] #unused, since h_0_all_layers is all layers' h_0s concatenated", "\n", "argv", "=", "argv", "[", "1", ":", "]", "\n", "\n", "# strip W parameters off variable arguments list", "\n", "if", "(", "Wimpl", "==", "'full'", ")", "or", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "                ", "Wparams_cur", "=", "argv", "[", "0", ":", "1", "]", "\n", "argv", "=", "argv", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                ", "Wparams_cur", "=", "argv", "[", "0", ":", "3", "]", "\n", "argv", "=", "argv", "[", "3", ":", "]", "\n", "\n", "", "Wimpl_in_scan", "=", "Wimpl", "\n", "if", "(", "Wimpl", "==", "'adhoc_fast'", ")", ":", "\n", "# just using a full matrix multiply is faster", "\n", "# than calling times_unitary with Wimpl='adhoc'", "\n", "                ", "Wimpl_in_scan", "=", "'full'", "\n", "\n", "# Compute the linear parts of the layer ----------", "\n", "\n", "", "if", "not", "flag_feed_forward", ":", "\n", "# get previous hidden state h_{t-1} for this layer:", "\n", "                ", "h_prev_cur", "=", "h_prev", "[", ":", ",", "(", "i_layer", "-", "1", ")", "*", "2", "*", "n_hidden", ":", "i_layer", "*", "2", "*", "n_hidden", "]", "\n", "# Compute hidden linear transform: W h_{t-1}", "\n", "hidden_lin_output_cur", "=", "times_unitary", "(", "h_prev_cur", ",", "n_hidden", ",", "swap_re_im", ",", "Wparams_cur", ",", "Wimpl_in_scan", ")", "\n", "\n", "# Compute \"data linear transform\", which for this intermediate layer is the previous layer's h_t transformed by Wv", "\n", "", "data_lin_output_cur", "=", "times_unitary", "(", "h_t", ",", "n_hidden", ",", "swap_re_im", ",", "Wvparams_cur", ",", "Wimpl_in_scan", ")", "\n", "\n", "# Total linear output        ", "\n", "if", "not", "flag_feed_forward", ":", "\n", "                ", "lin_output_cur", "=", "hidden_lin_output_cur", "+", "data_lin_output_cur", "\n", "", "else", ":", "\n", "                ", "lin_output_cur", "=", "data_lin_output_cur", "\n", "\n", "# Apply non-linearity ----------------------------", "\n", "\n", "# scale RELU nonlinearity", "\n", "#  add a little bit to sqrt argument to ensure stable gradients,", "\n", "#  since gradient of sqrt(x) is -0.5/sqrt(x)", "\n", "", "modulus", "=", "T", ".", "sqrt", "(", "1e-5", "+", "lin_output_cur", "**", "2", "+", "lin_output_cur", "[", ":", ",", "swap_re_im", "]", "**", "2", ")", "\n", "rescale", "=", "T", ".", "maximum", "(", "modulus", "+", "T", ".", "tile", "(", "hidden_bias_cur", ",", "[", "2", "]", ")", ".", "dimshuffle", "(", "'x'", ",", "0", ")", ",", "0.", ")", "/", "(", "modulus", "+", "1e-5", ")", "\n", "h_t", "=", "lin_output_cur", "*", "rescale", "\n", "h_t_all_layers", "=", "T", ".", "concatenate", "(", "[", "h_t_all_layers", ",", "h_t", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# assume we aren't passing any preactivation to compute_cost", "\n", "", "z_t", "=", "None", "\n", "\n", "if", "loss_function", "==", "'MSEplusL1'", ":", "\n", "            ", "z_t", "=", "h_t", "\n", "\n", "", "if", "out_every_t", ":", "\n", "            ", "lin_output", "=", "T", ".", "dot", "(", "h_t", ",", "U", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "\n", "if", "flag_add_input_to_output", ":", "\n", "                ", "lin_output", "=", "lin_output", "+", "x_t", "\n", "\n", "", "if", "flag_use_mask", ":", "\n", "                ", "cost_t", ",", "acc_t", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ",", "ymask_t", "=", "ymask_t", ",", "z_t", "=", "z_t", ",", "lam", "=", "lam", ")", "\n", "", "else", ":", "\n", "                ", "cost_t", ",", "acc_t", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y_t", ",", "z_t", "=", "z_t", ",", "lam", "=", "lam", ")", "\n", "", "", "else", ":", "\n", "            ", "cost_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "acc_t", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "\n", "", "return", "h_t_all_layers", ",", "cost_t", ",", "acc_t", "\n", "\n", "# compute hidden states", "\n", "#  h_0_batch should be n_utt x n_layers*2*n_hidden, since scan goes over first dimension of x, which is the maximum STFT length in frames", "\n", "", "h_0_batch", "=", "T", ".", "tile", "(", "h_0_all_layers", ",", "[", "x", ".", "shape", "[", "1", "]", ",", "1", "]", ")", "\n", "\n", "if", "input_type", "==", "'complex'", "and", "output_type", "==", "'complex'", ":", "\n", "# pass in augmented input and output transformations", "\n", "        ", "non_sequences", "=", "[", "Vaug", ",", "hidden_bias", ",", "out_bias", ",", "Uaug", "]", "+", "Wparams", "+", "addl_layers_params", "\n", "", "elif", "input_type", "==", "'complex'", ":", "\n", "        ", "non_sequences", "=", "[", "Vaug", ",", "hidden_bias", ",", "out_bias", ",", "Un", "]", "+", "Wparams", "+", "addl_layers_params", "\n", "", "elif", "output_type", "==", "'complex'", ":", "\n", "        ", "non_sequences", "=", "[", "Vn", ",", "hidden_bias", ",", "out_bias", ",", "Uaug", "]", "+", "Wparams", "+", "addl_layers_params", "\n", "", "else", ":", "\n", "        ", "non_sequences", "=", "[", "Vn", ",", "hidden_bias", ",", "out_bias", ",", "Un", "]", "+", "Wparams", "+", "addl_layers_params", "\n", "\n", "", "if", "out_every_t", ":", "\n", "        ", "if", "flag_use_mask", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "y", ",", "ymask", "]", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "y", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "if", "flag_use_mask", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "sequences", "=", "[", "x", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", ",", "T", ".", "tile", "(", "theano", ".", "shared", "(", "np", ".", "ones", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", ",", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", "]", ")", "]", "\n", "\n", "", "", "outputs_info", "=", "[", "h_0_batch", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", ",", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "]", "\n", "\n", "[", "hidden_states_all_layers", ",", "cost_steps", ",", "acc_steps", "]", ",", "updates", "=", "theano", ".", "scan", "(", "fn", "=", "recurrence", ",", "\n", "sequences", "=", "sequences", ",", "\n", "non_sequences", "=", "non_sequences", ",", "\n", "outputs_info", "=", "outputs_info", ")", "\n", "\n", "# get hidden states of last layer", "\n", "hidden_states", "=", "hidden_states_all_layers", "[", ":", ",", ":", ",", "(", "n_layers", "-", "1", ")", "*", "2", "*", "n_hidden", ":", "]", "\n", "\n", "if", "flag_return_lin_output", ":", "\n", "        ", "if", "output_type", "==", "'complex'", ":", "\n", "            ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", ",", "Uaug", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", ",", "Un", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "\n", "", "if", "flag_add_input_to_output", ":", "\n", "            ", "lin_output", "=", "lin_output", "+", "x", "\n", "\n", "", "", "if", "not", "out_every_t", ":", "\n", "#TODO: here, if flag_use_mask is set, need to use a for-loop to select the desired time-step for each utterance", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "hidden_states", "[", "-", "1", ",", ":", ",", ":", "]", ",", "Un", ")", "+", "out_bias", ".", "dimshuffle", "(", "'x'", ",", "0", ")", "\n", "z_t", "=", "None", "\n", "if", "loss_function", "==", "'MSEplusL1'", ":", "\n", "            ", "z_t", "=", "hidden_states", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "", "costs", "=", "compute_cost_t", "(", "lin_output", ",", "loss_function", ",", "y", ",", "z_t", "=", "z_t", ",", "lam", "=", "lam", ")", "\n", "cost", "=", "costs", "[", "0", "]", "\n", "accuracy", "=", "costs", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "if", "(", "cost_transform", "==", "'magTimesPhase'", ")", ":", "\n", "            ", "cosPhase", "=", "T", ".", "cos", "(", "lin_output", ")", "\n", "sinPhase", "=", "T", ".", "sin", "(", "lin_output", ")", "\n", "linMag", "=", "np", ".", "sqrt", "(", "10", "**", "(", "x", "/", "10.0", ")", "-", "1e-5", ")", "\n", "yest_real", "=", "linMag", "*", "cosPhase", "\n", "yest_imag", "=", "linMag", "*", "sinPhase", "\n", "yest", "=", "T", ".", "concatenate", "(", "[", "yest_real", ",", "yest_imag", "]", ",", "axis", "=", "2", ")", "\n", "mse", "=", "(", "yest", "-", "y", ")", "**", "2", "\n", "cost_steps", "=", "T", ".", "mean", "(", "mse", "*", "ymask", "[", ":", ",", ":", ",", "0", "]", ".", "dimshuffle", "(", "0", ",", "1", ",", "'x'", ")", ",", "axis", "=", "2", ")", "\n", "", "elif", "cost_transform", "is", "not", "None", ":", "\n", "# assume that cost_transform is an inverse DFT followed by synthesis windowing", "\n", "            ", "lin_output_real", "=", "lin_output", "[", ":", ",", ":", ",", ":", "n_output", "]", "\n", "lin_output_imag", "=", "lin_output", "[", ":", ",", ":", ",", "n_output", ":", "]", "\n", "lin_output_sym_real", "=", "T", ".", "concatenate", "(", "[", "lin_output_real", ",", "lin_output_real", "[", ":", ",", ":", ",", "n_output", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "lin_output_sym_imag", "=", "T", ".", "concatenate", "(", "[", "-", "lin_output_imag", ",", "lin_output_imag", "[", ":", ",", ":", ",", "n_output", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "lin_output_sym", "=", "T", ".", "concatenate", "(", "[", "lin_output_sym_real", ",", "lin_output_sym_imag", "]", ",", "axis", "=", "2", ")", "\n", "yest_xform", "=", "T", ".", "dot", "(", "lin_output_sym", ",", "cost_transform", ")", "\n", "# apply synthesis window", "\n", "yest_xform", "=", "yest_xform", "*", "cost_weight", ".", "dimshuffle", "(", "'x'", ",", "'x'", ",", "0", ")", "\n", "y_real", "=", "y", "[", ":", ",", ":", ",", ":", "n_output", "]", "\n", "y_imag", "=", "y", "[", ":", ",", ":", ",", "n_output", ":", "]", "\n", "y_sym_real", "=", "T", ".", "concatenate", "(", "[", "y_real", ",", "y_real", "[", ":", ",", ":", ",", "n_output", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "y_sym_imag", "=", "T", ".", "concatenate", "(", "[", "-", "y_imag", ",", "y_imag", "[", ":", ",", ":", ",", "n_output", "-", "2", ":", "0", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "y_sym", "=", "T", ".", "concatenate", "(", "[", "y_sym_real", ",", "y_sym_imag", "]", ",", "axis", "=", "2", ")", "\n", "y_xform", "=", "T", ".", "dot", "(", "y_sym", ",", "cost_transform", ")", "\n", "# apply synthesis window", "\n", "y_xform", "=", "y_xform", "*", "cost_weight", ".", "dimshuffle", "(", "'x'", ",", "'x'", ",", "0", ")", "\n", "mse", "=", "(", "y_xform", "-", "yest_xform", ")", "**", "2", "\n", "cost_steps", "=", "T", ".", "mean", "(", "mse", "*", "ymask", "[", ":", ",", ":", ",", "0", "]", ".", "dimshuffle", "(", "0", ",", "1", ",", "'x'", ")", ",", "axis", "=", "2", ")", "\n", "", "cost", "=", "cost_steps", ".", "mean", "(", ")", "\n", "accuracy", "=", "acc_steps", ".", "mean", "(", ")", "\n", "\n", "if", "(", "loss_function", "==", "'CE_of_sum'", ")", ":", "\n", "            ", "yest", "=", "T", ".", "sum", "(", "lin_output", ",", "axis", "=", "0", ")", "#sum over time_steps, yest is Nseq x n_output", "\n", "yest_softmax", "=", "T", ".", "nnet", ".", "softmax", "(", "yest", ")", "\n", "cost", "=", "T", ".", "nnet", ".", "categorical_crossentropy", "(", "yest_softmax", ",", "y", "[", "0", ",", ":", "]", ")", ".", "mean", "(", ")", "\n", "accuracy", "=", "T", ".", "eq", "(", "T", ".", "argmax", "(", "yest", ",", "axis", "=", "-", "1", ")", ",", "y", "[", "0", ",", ":", "]", ")", ".", "mean", "(", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "\n", "", "", "if", "flag_return_lin_output", ":", "\n", "\n", "        ", "costs", "=", "[", "cost", ",", "accuracy", ",", "lin_output", "]", "\n", "\n", "if", "flag_return_hidden_states", ":", "\n", "            ", "costs", "=", "costs", "+", "[", "hidden_states", "]", "\n", "\n", "#nmse_local = ymask.dimshuffle(0,1)*( (lin_output-y)**2 )/( 1e-5 + y**2 )", "\n", "", "nmse_local", "=", "theano", ".", "shared", "(", "np", ".", "float32", "(", "0.0", ")", ")", "\n", "costs", "=", "costs", "+", "[", "nmse_local", "]", "\n", "\n", "costs", "=", "costs", "+", "[", "cost_steps", "]", "\n", "\n", "", "else", ":", "\n", "        ", "costs", "=", "[", "cost", ",", "accuracy", "]", "\n", "", "if", "flag_use_mask", ":", "\n", "        ", "return", "[", "x", ",", "y", ",", "ymask", "]", ",", "parameters", ",", "costs", "\n", "", "else", ":", "\n", "        ", "return", "[", "x", ",", "y", "]", ",", "parameters", ",", "costs", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.mnist.LossHistory.__init__": [[27, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "histfile", ")", ":", "\n", "        ", "self", ".", "histfile", "=", "histfile", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.mnist.LossHistory.on_train_begin": [[30, 35], ["None"], "methods", ["None"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "train_loss", "=", "[", "]", "\n", "self", ".", "train_acc", "=", "[", "]", "\n", "self", ".", "val_loss", "=", "[", "]", "\n", "self", ".", "val_acc", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.mnist.LossHistory.on_batch_end": [[36, 39], ["keras.datasets.mnist.LossHistory.train_loss.append", "keras.datasets.mnist.LossHistory.train_acc.append", "logs.get", "logs.get"], "methods", ["None"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "train_loss", ".", "append", "(", "logs", ".", "get", "(", "'loss'", ")", ")", "\n", "self", ".", "train_acc", ".", "append", "(", "logs", ".", "get", "(", "'acc'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.mnist.LossHistory.on_epoch_end": [[40, 44], ["keras.datasets.mnist.LossHistory.val_loss.append", "keras.datasets.mnist.LossHistory.val_acc.append", "cPickle.dump", "logs.get", "logs.get", "open"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "val_loss", ".", "append", "(", "logs", ".", "get", "(", "'val_loss'", ")", ")", "\n", "self", ".", "val_acc", ".", "append", "(", "logs", ".", "get", "(", "'val_acc'", ")", ")", "\n", "cPickle", ".", "dump", "(", "{", "'train_loss'", ":", "self", ".", "train_loss", ",", "'train_acc'", ":", "self", ".", "train_acc", ",", "'val_loss'", ":", "self", ".", "val_loss", ",", "'val_acc'", ":", "self", ".", "val_acc", "}", ",", "open", "(", "self", ".", "histfile", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.mnist.main": [[46, 209], ["print", "os.path.exists", "print", "config.iteritems", "keras.datasets.mnist.load_data", "X_train.astype.reshape", "X_valid.astype.reshape", "X_test.astype.reshape", "X_train.astype.astype", "X_valid.astype.astype", "X_test.astype.astype", "print", "print", "print", "print", "keras.utils.np_utils.to_categorical", "keras.utils.np_utils.to_categorical", "keras.utils.np_utils.to_categorical", "print", "custom_optimizers.RMSprop_and_natGrad", "keras.models.Sequential.compile", "mnist.LossHistory", "keras.callbacks.ModelCheckpoint", "keras.callbacks.EarlyStopping", "keras.models.Sequential.fit", "keras.models.Sequential.evaluate", "print", "print", "cPickle.load", "cPickle.load.update", "cPickle.dump", "getopt.getopt", "open", "yaml.load", "config.update", "print", "print", "numpy.random.RandomState", "np.random.RandomState.permutation", "keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "print", "keras.models.Sequential.load_weights", "keras.models.Sequential.test_on_batch", "print", "os.path.exists", "os.makedirs", "open", "open", "print", "sys.exit", "print", "yaml.dump", "print", "print", "print", "print", "sys.exit", "open.read", "custom_layers.uRNN", "keras.layers.Dense", "keras.layers.Activation", "keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "custom_layers.complex_RNN_wrapper", "keras.layers.Activation", "keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.layers.LSTM", "keras.layers.Dense", "keras.layers.Activation"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.models.LSTM"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "config", "=", "{", "'learning_rate'", ":", "1e-4", ",", "\n", "'learning_rate_natGrad'", ":", "None", ",", "\n", "'clipnorm'", ":", "1.0", ",", "\n", "'batch_size'", ":", "32", ",", "\n", "'nb_epochs'", ":", "200", ",", "\n", "'patience'", ":", "3", ",", "\n", "'hidden_units'", ":", "100", ",", "\n", "'model_impl'", ":", "'complex_RNN'", ",", "\n", "'unitary_impl'", ":", "'ASB2016'", ",", "\n", "'histfile'", ":", "'exp/history_mnist_default'", ",", "\n", "'savefile'", ":", "'exp/model_mnist_default.hdf5'", ",", "\n", "'savefile_init'", ":", "None", "}", "\n", "\n", "configfile", "=", "''", "\n", "helpstring", "=", "'mnist_urnn.py -c <config YAML file>'", "\n", "try", ":", "\n", "        ", "opts", ",", "args", "=", "getopt", ".", "getopt", "(", "argv", ",", "\"hc:\"", ",", "[", "\"config=\"", "]", ")", "\n", "", "except", "getopt", ".", "GetoptError", ":", "\n", "        ", "print", "(", "helpstring", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "", "for", "opt", ",", "arg", "in", "opts", ":", "\n", "        ", "if", "opt", "==", "'-h'", ":", "\n", "            ", "print", "(", "helpstring", ")", "\n", "yamlstring", "=", "yaml", ".", "dump", "(", "config", ",", "default_flow_style", "=", "False", ",", "explicit_start", "=", "True", ")", "\n", "print", "(", "\"YAML configuration file format:\"", ")", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"%YAML 1.2\"", ")", "\n", "print", "(", "yamlstring", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "elif", "opt", "in", "(", "\"-c\"", ",", "\"--config\"", ")", ":", "\n", "            ", "configfile", "=", "arg", "\n", "", "", "print", "(", "\"Config file is %s\"", "%", "configfile", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "configfile", ")", ":", "\n", "        ", "f", "=", "open", "(", "configfile", ")", "\n", "user_config", "=", "yaml", ".", "load", "(", "f", ".", "read", "(", ")", ")", "\n", "config", ".", "update", "(", "user_config", ")", "\n", "\n", "", "print", "(", "\"Printing configuration:\"", ")", "\n", "for", "key", ",", "value", "in", "config", ".", "iteritems", "(", ")", ":", "\n", "        ", "print", "(", "\"  \"", ",", "key", ",", "\": \"", ",", "value", ")", "\n", "\n", "", "nb_classes", "=", "10", "\n", "\n", "learning_rate", "=", "config", "[", "'learning_rate'", "]", "\n", "if", "(", "'learning_rate_natGrad'", "in", "config", ")", "and", "(", "config", "[", "'learning_rate_natGrad'", "]", "is", "not", "None", ")", ":", "\n", "        ", "learning_rate_natGrad", "=", "config", "[", "'learning_rate_natGrad'", "]", "\n", "", "else", ":", "\n", "        ", "learning_rate_natGrad", "=", "learning_rate", "\n", "", "clipnorm", "=", "config", "[", "'clipnorm'", "]", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "nb_epochs", "=", "config", "[", "'nb_epochs'", "]", "\n", "hidden_units", "=", "config", "[", "'hidden_units'", "]", "\n", "# ASB2016 uRNN has 32N+10 parameters", "\n", "# full uRNN has N^2+25N+10 parameters", "\n", "\n", "#model_impl='uRNN_keras'", "\n", "#model_impl='complex_RNN'", "\n", "model_impl", "=", "config", "[", "'model_impl'", "]", "\n", "unitary_impl", "=", "config", "[", "'unitary_impl'", "]", "\n", "\n", "histfile", "=", "config", "[", "'histfile'", "]", "\n", "savefile", "=", "config", "[", "'savefile'", "]", "\n", "\n", "# the data, shuffled and split between train, validation, and test sets", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "mnist", ".", "load_data", "(", ")", "\n", "X_valid", "=", "X_train", "[", ":", "5000", ",", ":", ",", ":", "]", "\n", "y_valid", "=", "y_train", "[", ":", "5000", "]", "\n", "X_train", "=", "X_train", "[", "5000", ":", ",", ":", ",", ":", "]", "\n", "y_train", "=", "y_train", "[", "5000", ":", "]", "\n", "\n", "X_train", "=", "X_train", ".", "reshape", "(", "X_train", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ")", "\n", "X_valid", "=", "X_valid", ".", "reshape", "(", "X_valid", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ")", "\n", "X_test", "=", "X_test", ".", "reshape", "(", "X_test", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ")", "\n", "X_train", "=", "X_train", ".", "astype", "(", "'float32'", ")", "\n", "X_valid", "=", "X_valid", ".", "astype", "(", "'float32'", ")", "\n", "X_test", "=", "X_test", ".", "astype", "(", "'float32'", ")", "\n", "X_train", "/=", "255", "\n", "X_valid", "/=", "255", "\n", "X_test", "/=", "255", "\n", "print", "(", "'X_train shape:'", ",", "X_train", ".", "shape", ")", "\n", "print", "(", "X_train", ".", "shape", "[", "0", "]", ",", "'train samples'", ")", "\n", "print", "(", "X_valid", ".", "shape", "[", "0", "]", ",", "'validation samples'", ")", "\n", "print", "(", "X_test", ".", "shape", "[", "0", "]", ",", "'test samples'", ")", "\n", "\n", "if", "(", "'flag_permute'", "in", "config", ")", "and", "config", "[", "'flag_permute'", "]", ":", "\n", "        ", "print", "(", "\"Applying permutation to MNIST pixels\"", ")", "\n", "rng_permute", "=", "np", ".", "random", ".", "RandomState", "(", "92916", ")", "\n", "idx_permute", "=", "rng_permute", ".", "permutation", "(", "784", ")", "\n", "X_train", "=", "X_train", "[", ":", ",", "idx_permute", "]", "\n", "X_valid", "=", "X_valid", "[", ":", ",", "idx_permute", "]", "\n", "X_test", "=", "X_test", "[", ":", ",", "idx_permute", "]", "\n", "\n", "# convert class vectors to binary class matrices", "\n", "", "Y_train", "=", "np_utils", ".", "to_categorical", "(", "y_train", ",", "nb_classes", ")", "\n", "Y_valid", "=", "np_utils", ".", "to_categorical", "(", "y_valid", ",", "nb_classes", ")", "\n", "Y_test", "=", "np_utils", ".", "to_categorical", "(", "y_test", ",", "nb_classes", ")", "\n", "\n", "print", "(", "'Building model with implementation %s...'", "%", "model_impl", ")", "\n", "if", "(", "model_impl", "==", "'uRNN_keras'", ")", ":", "\n", "#unitary_init='svd'", "\n", "        ", "unitary_init", "=", "'ASB2016'", "\n", "\n", "unitary_impl", "=", "'ASB2016'", "\n", "#unitary_impl='full'", "\n", "#unitary_impl='full_natGrad'", "\n", "\n", "epsilon", "=", "1e-5", "\n", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "uRNN", "(", "output_dim", "=", "hidden_units", ",", "\n", "inner_init", "=", "unitary_init", ",", "\n", "unitary_impl", "=", "unitary_impl", ",", "\n", "input_shape", "=", "X_train", ".", "shape", "[", "1", ":", "]", ",", "\n", "consume_less", "=", "'cpu'", ",", "\n", "epsilon", "=", "epsilon", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ")", ")", "\n", "model", ".", "add", "(", "Activation", "(", "'softmax'", ")", ")", "\n", "", "elif", "(", "model_impl", "==", "'complex_RNN'", ")", ":", "\n", "        ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "complex_RNN_wrapper", "(", "output_dim", "=", "nb_classes", ",", "\n", "hidden_dim", "=", "hidden_units", ",", "\n", "unitary_impl", "=", "unitary_impl", ",", "\n", "input_shape", "=", "X_train", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "model", ".", "add", "(", "Activation", "(", "'softmax'", ")", ")", "\n", "", "elif", "(", "model_impl", "==", "'LSTM'", ")", ":", "\n", "        ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "LSTM", "(", "hidden_units", ",", "\n", "return_sequences", "=", "False", ",", "\n", "input_shape", "=", "X_train", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "nb_classes", ")", ")", "\n", "model", ".", "add", "(", "Activation", "(", "'softmax'", ")", ")", "\n", "\n", "", "rmsprop", "=", "RMSprop_and_natGrad", "(", "lr", "=", "learning_rate", ",", "clipnorm", "=", "clipnorm", ",", "lr_natGrad", "=", "learning_rate_natGrad", ")", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "\n", "optimizer", "=", "rmsprop", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "history", "=", "LossHistory", "(", "histfile", ")", "\n", "checkpointer", "=", "keras", ".", "callbacks", ".", "ModelCheckpoint", "(", "filepath", "=", "savefile", ",", "verbose", "=", "1", ",", "save_best_only", "=", "True", ")", "\n", "earlystopping", "=", "keras", ".", "callbacks", ".", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "config", "[", "'patience'", "]", ",", "verbose", "=", "1", ",", "mode", "=", "'auto'", ")", "\n", "\n", "if", "not", "(", "config", "[", "'savefile_init'", "]", "is", "None", ")", ":", "\n", "        ", "print", "(", "\"Loading weights from file %s\"", "%", "config", "[", "'savefile_init'", "]", ")", "\n", "model", ".", "load_weights", "(", "config", "[", "'savefile_init'", "]", ")", "\n", "losses", "=", "model", ".", "test_on_batch", "(", "X_valid", ",", "Y_valid", ")", "\n", "print", "(", "\"On validation set, loaded model achieves loss %f and acc %f\"", "%", "(", "losses", "[", "0", "]", ",", "losses", "[", "1", "]", ")", ")", "\n", "\n", "#make sure the experiment directory to hold results exists", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "'exp'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'exp'", ")", "\n", "\n", "", "model", ".", "fit", "(", "X_train", ",", "Y_train", ",", "batch_size", "=", "batch_size", ",", "nb_epoch", "=", "nb_epochs", ",", "\n", "verbose", "=", "1", ",", "validation_data", "=", "(", "X_valid", ",", "Y_valid", ")", ",", "callbacks", "=", "[", "history", ",", "checkpointer", ",", "earlystopping", "]", ")", "\n", "\n", "scores", "=", "model", ".", "evaluate", "(", "X_test", ",", "Y_test", ",", "verbose", "=", "0", ")", "\n", "print", "(", "'Test loss:'", ",", "scores", "[", "0", "]", ")", "\n", "print", "(", "'Test accuracy:'", ",", "scores", "[", "1", "]", ")", "\n", "\n", "# add test scores to history", "\n", "history_load", "=", "cPickle", ".", "load", "(", "open", "(", "histfile", ",", "'rb'", ")", ")", "\n", "history_load", ".", "update", "(", "{", "'test_loss'", ":", "scores", "[", "0", "]", ",", "'test_acc'", ":", "scores", "[", "1", "]", "}", ")", "\n", "cPickle", ".", "dump", "(", "history_load", ",", "open", "(", "histfile", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.ScikitsCudaOp.__eq__": [[33, 35], ["type", "type"], "methods", ["None"], ["    ", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "type", "(", "self", ")", "==", "type", "(", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.ScikitsCudaOp.__hash__": [[36, 38], ["hash", "type"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "type", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.ScikitsCudaOp.__str__": [[39, 41], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.ScikitsCudaOp.output_type": [[42, 44], ["None"], "methods", ["None"], ["", "def", "output_type", "(", "self", ",", "inp", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.ScikitsCudaOp.make_node": [[45, 52], ["basic_ops.gpu_contiguous", "theano.Apply", "theano.Apply", "theano.Apply", "theano.Apply", "basic_ops.as_cuda_ndarray_variable", "fftconv.ScikitsCudaOp.output_type"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.output_type"], ["", "def", "make_node", "(", "self", ",", "inp", ")", ":", "\n", "        ", "inp", "=", "basic_ops", ".", "gpu_contiguous", "(", "\n", "basic_ops", ".", "as_cuda_ndarray_variable", "(", "inp", ")", ")", "\n", "\n", "assert", "inp", ".", "dtype", "==", "\"float32\"", "\n", "\n", "return", "theano", ".", "Apply", "(", "self", ",", "[", "inp", "]", ",", "[", "self", ".", "output_type", "(", "inp", ")", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.ScikitsCudaOp.make_thunk": [[53, 57], ["RuntimeError"], "methods", ["None"], ["", "def", "make_thunk", "(", "self", ",", "node", ",", "storage_map", ",", "_", ",", "_2", ")", ":", "\n", "        ", "if", "not", "scikits_cuda_available", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"scikits.cuda is needed for all GPU fft implementation,\"", "\n", "\" including fftconv.\"", ")", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.CuFFTOp.output_type": [[61, 65], ["CudaNdarrayType"], "methods", ["None"], ["    ", "def", "output_type", "(", "self", ",", "inp", ")", ":", "\n", "# add one extra dim for real/imag", "\n", "        ", "return", "CudaNdarrayType", "(", "\n", "broadcastable", "=", "[", "False", "]", "*", "(", "inp", ".", "type", ".", "ndim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.CuFFTOp.make_thunk": [[66, 108], ["fftconv.ScikitsCudaOp.make_thunk", "to_gpuarray", "to_gpuarray", "fft.fft", "CudaNdarray.zeros", "fft.Plan"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.make_thunk"], ["", "def", "make_thunk", "(", "self", ",", "node", ",", "storage_map", ",", "compute_map", ",", "no_recycling", ")", ":", "\n", "        ", "super", "(", "CuFFTOp", ",", "self", ")", ".", "make_thunk", "(", "node", ",", "storage_map", ",", "compute_map", ",", "no_recycling", ")", "\n", "\n", "from", "theano", ".", "misc", ".", "pycuda_utils", "import", "to_gpuarray", "\n", "inputs", "=", "[", "storage_map", "[", "v", "]", "for", "v", "in", "node", ".", "inputs", "]", "\n", "outputs", "=", "[", "storage_map", "[", "v", "]", "for", "v", "in", "node", ".", "outputs", "]", "\n", "\n", "plan_input_shape", "=", "[", "None", "]", "\n", "plan", "=", "[", "None", "]", "\n", "\n", "def", "thunk", "(", ")", ":", "\n", "            ", "input_shape", "=", "inputs", "[", "0", "]", "[", "0", "]", ".", "shape", "\n", "output_shape", "=", "input_shape", "\n", "\n", "z", "=", "outputs", "[", "0", "]", "\n", "\n", "# only allocate if there is no previous allocation of the", "\n", "# right size.", "\n", "if", "z", "[", "0", "]", "is", "None", "or", "z", "[", "0", "]", ".", "shape", "!=", "output_shape", ":", "\n", "                ", "z", "[", "0", "]", "=", "CudaNdarray", ".", "zeros", "(", "output_shape", ")", "\n", "\n", "", "input_pycuda", "=", "to_gpuarray", "(", "inputs", "[", "0", "]", "[", "0", "]", ")", "\n", "# I thought we'd need to change the type on output_pycuda", "\n", "# so it is complex64, but as it turns out scikits.cuda.fft", "\n", "# doesn't really care either way and treats the array as", "\n", "# if it is complex64 anyway.", "\n", "output_pycuda", "=", "to_gpuarray", "(", "z", "[", "0", "]", ")", "\n", "\n", "# only initialise plan if necessary", "\n", "if", "plan", "[", "0", "]", "is", "None", "or", "plan_input_shape", "[", "0", "]", "!=", "input_shape", ":", "\n", "                ", "plan_input_shape", "[", "0", "]", "=", "input_shape", "\n", "plan", "[", "0", "]", "=", "fft", ".", "Plan", "(", "input_shape", "[", "1", ":", "-", "1", "]", ",", "np", ".", "complex64", ",", "np", ".", "complex64", ",", "\n", "batch", "=", "input_shape", "[", "0", "]", ")", "\n", "\n", "", "fft", ".", "fft", "(", "input_pycuda", ",", "output_pycuda", ",", "plan", "[", "0", "]", ")", "\n", "compute_map", "[", "node", ".", "outputs", "[", "0", "]", "]", "[", "0", "]", "=", "True", "\n", "\n", "", "thunk", ".", "inputs", "=", "inputs", "\n", "thunk", ".", "outputs", "=", "outputs", "\n", "thunk", ".", "lazy", "=", "False", "\n", "\n", "return", "thunk", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.CuFFTOp.grad": [[109, 111], ["fftconv.CuIFFTOp"], "methods", ["None"], ["", "def", "grad", "(", "self", ",", "inputs", ",", "output_grads", ")", ":", "\n", "        ", "return", "[", "CuIFFTOp", "(", ")", "(", "output_grads", "[", "0", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.CuIFFTOp.output_type": [[114, 118], ["CudaNdarrayType"], "methods", ["None"], ["    ", "def", "output_type", "(", "self", ",", "inp", ")", ":", "\n", "# remove extra real/imag dim", "\n", "        ", "return", "CudaNdarrayType", "(", "\n", "broadcastable", "=", "[", "False", "]", "*", "(", "inp", ".", "type", ".", "ndim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.CuIFFTOp.make_thunk": [[119, 163], ["fftconv.ScikitsCudaOp.make_thunk", "to_gpuarray", "to_gpuarray", "fft.ifft", "CudaNdarray.zeros", "fft.Plan"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.make_thunk"], ["", "def", "make_thunk", "(", "self", ",", "node", ",", "storage_map", ",", "compute_map", ",", "no_recycling", ")", ":", "\n", "        ", "super", "(", "CuIFFTOp", ",", "self", ")", ".", "make_thunk", "(", "node", ",", "storage_map", ",", "compute_map", ",", "no_recycling", ")", "\n", "\n", "from", "theano", ".", "misc", ".", "pycuda_utils", "import", "to_gpuarray", "\n", "inputs", "=", "[", "storage_map", "[", "v", "]", "for", "v", "in", "node", ".", "inputs", "]", "\n", "outputs", "=", "[", "storage_map", "[", "v", "]", "for", "v", "in", "node", ".", "outputs", "]", "\n", "\n", "plan_input_shape", "=", "[", "None", "]", "\n", "plan", "=", "[", "None", "]", "\n", "\n", "def", "thunk", "(", ")", ":", "\n", "            ", "input_shape", "=", "inputs", "[", "0", "]", "[", "0", "]", ".", "shape", "\n", "output_shape", "=", "input_shape", "\n", "\n", "z", "=", "outputs", "[", "0", "]", "\n", "\n", "# only allocate if there is no previous allocation of the", "\n", "# right size.", "\n", "if", "z", "[", "0", "]", "is", "None", "or", "z", "[", "0", "]", ".", "shape", "!=", "output_shape", ":", "\n", "                ", "z", "[", "0", "]", "=", "CudaNdarray", ".", "zeros", "(", "output_shape", ")", "\n", "\n", "", "input_pycuda", "=", "to_gpuarray", "(", "inputs", "[", "0", "]", "[", "0", "]", ")", "\n", "# input_pycuda is a float32 array with an extra dimension,", "\n", "# but will be interpreted by scikits.cuda as a complex64", "\n", "# array instead.", "\n", "output_pycuda", "=", "to_gpuarray", "(", "z", "[", "0", "]", ")", "\n", "\n", "# only initialise plan if necessary", "\n", "if", "plan", "[", "0", "]", "is", "None", "or", "plan_input_shape", "[", "0", "]", "!=", "input_shape", ":", "\n", "                ", "plan_input_shape", "[", "0", "]", "=", "input_shape", "\n", "plan", "[", "0", "]", "=", "fft", ".", "Plan", "(", "output_shape", "[", "1", ":", "-", "1", "]", ",", "np", ".", "complex64", ",", "np", ".", "complex64", ",", "\n", "batch", "=", "output_shape", "[", "0", "]", ")", "\n", "\n", "", "fft", ".", "ifft", "(", "input_pycuda", ",", "output_pycuda", ",", "plan", "[", "0", "]", ")", "\n", "compute_map", "[", "node", ".", "outputs", "[", "0", "]", "]", "[", "0", "]", "=", "True", "\n", "# strangely enough, enabling rescaling here makes it run", "\n", "# very, very slowly.  so do this rescaling manually", "\n", "# afterwards!", "\n", "\n", "", "thunk", ".", "inputs", "=", "inputs", "\n", "thunk", ".", "outputs", "=", "outputs", "\n", "thunk", ".", "lazy", "=", "False", "\n", "\n", "return", "thunk", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.CuIFFTOp.grad": [[164, 166], ["fftconv.CuFFTOp"], "methods", ["None"], ["", "def", "grad", "(", "self", ",", "inputs", ",", "output_grads", ")", ":", "\n", "        ", "return", "[", "CuFFTOp", "(", ")", "(", "output_grads", "[", "0", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.make_node": [[297, 309], ["basic_ops.gpu_contiguous", "basic_ops.gpu_contiguous", "theano.Apply", "theano.Apply", "theano.Apply", "theano.Apply", "basic_ops.as_cuda_ndarray_variable", "basic_ops.as_cuda_ndarray_variable", "fftconv.BatchedComplexDotOp.output_type"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.output_type"], ["def", "make_node", "(", "self", ",", "inp1", ",", "inp2", ")", ":", "\n", "        ", "inp1", "=", "basic_ops", ".", "gpu_contiguous", "(", "\n", "basic_ops", ".", "as_cuda_ndarray_variable", "(", "inp1", ")", ")", "\n", "inp2", "=", "basic_ops", ".", "gpu_contiguous", "(", "\n", "basic_ops", ".", "as_cuda_ndarray_variable", "(", "inp2", ")", ")", "\n", "\n", "assert", "inp1", ".", "dtype", "==", "\"float32\"", "\n", "assert", "inp2", ".", "dtype", "==", "\"float32\"", "\n", "assert", "inp1", ".", "ndim", "==", "4", "# (batch, a, b, real/imag)", "\n", "assert", "inp2", ".", "ndim", "==", "4", "\n", "\n", "return", "theano", ".", "Apply", "(", "self", ",", "[", "inp1", ",", "inp2", "]", ",", "[", "self", ".", "output_type", "(", "inp1", ")", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.output_type": [[310, 312], ["CudaNdarrayType"], "methods", ["None"], ["", "def", "output_type", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "CudaNdarrayType", "(", "broadcastable", "=", "[", "False", "]", "*", "inp", ".", "type", ".", "ndim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.make_thunk": [[313, 349], ["fftconv.ScikitsCudaOp.make_thunk", "fftconv.to_complex_gpuarray", "fftconv.to_complex_gpuarray", "fftconv.to_complex_gpuarray", "fftconv.sc_complex_dot_batched", "CudaNdarray.zeros"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.BatchedComplexDotOp.make_thunk", "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.to_complex_gpuarray", "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.to_complex_gpuarray", "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.to_complex_gpuarray", "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.sc_complex_dot_batched"], ["", "def", "make_thunk", "(", "self", ",", "node", ",", "storage_map", ",", "_", ",", "_2", ")", ":", "\n", "        ", "super", "(", "BatchedComplexDotOp", ",", "self", ")", ".", "make_thunk", "(", "node", ",", "storage_map", ",", "_", ",", "_2", ")", "\n", "\n", "inputs", "=", "[", "storage_map", "[", "v", "]", "for", "v", "in", "node", ".", "inputs", "]", "\n", "outputs", "=", "[", "storage_map", "[", "v", "]", "for", "v", "in", "node", ".", "outputs", "]", "\n", "\n", "def", "thunk", "(", ")", ":", "\n", "            ", "bx", "=", "inputs", "[", "0", "]", "\n", "by", "=", "inputs", "[", "1", "]", "\n", "\n", "input_shape_x", "=", "bx", "[", "0", "]", ".", "shape", "# (batch, a, b, 2)", "\n", "input_shape_y", "=", "by", "[", "0", "]", ".", "shape", "# (batch, b, c, 2)", "\n", "\n", "output_shape", "=", "(", "input_shape_x", "[", "0", "]", ",", "input_shape_x", "[", "1", "]", ",", "\n", "input_shape_y", "[", "2", "]", ",", "2", ")", "# (batch, a, c, 2)", "\n", "\n", "bz", "=", "outputs", "[", "0", "]", "\n", "\n", "# only allocate if there is no previous allocation of the", "\n", "# right size.", "\n", "if", "bz", "[", "0", "]", "is", "None", "or", "bz", "[", "0", "]", ".", "shape", "!=", "output_shape", ":", "\n", "                ", "bz", "[", "0", "]", "=", "CudaNdarray", ".", "zeros", "(", "output_shape", ")", "\n", "\n", "", "input_bx_pycuda", "=", "to_complex_gpuarray", "(", "bx", "[", "0", "]", ")", "\n", "input_by_pycuda", "=", "to_complex_gpuarray", "(", "by", "[", "0", "]", ")", "\n", "output_b_pycuda", "=", "to_complex_gpuarray", "(", "bz", "[", "0", "]", ")", "\n", "\n", "# fancy native batched version", "\n", "sc_complex_dot_batched", "(", "input_bx_pycuda", ",", "input_by_pycuda", ",", "\n", "output_b_pycuda", ")", "\n", "\n", "", "thunk", ".", "inputs", "=", "inputs", "\n", "thunk", ".", "outputs", "=", "outputs", "\n", "thunk", ".", "lazy", "=", "False", "\n", "\n", "return", "thunk", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.to_complex_gpuarray": [[168, 207], ["isinstance", "ValueError", "range", "pycuda.gpuarray.GPUArray", "x.copy.copy", "ValueError"], "function", ["None"], ["", "", "def", "to_complex_gpuarray", "(", "x", ",", "copyif", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Adapted version of theano.misc.pycuda_utils.to_gpuarray that takes\n    an array with an extra trailing dimension of length 2 for\n    real/imaginary parts, and turns it into a complex64 PyCUDA\n    GPUArray.\n\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "x", ",", "CudaNdarray", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"We can transfer only CudaNdarray \"", "\n", "\"to pycuda.gpuarray.GPUArray\"", ")", "\n", "", "else", ":", "\n", "# Check if trailing dimension has length 2", "\n", "        ", "assert", "x", ".", "shape", "[", "-", "1", "]", "==", "2", "\n", "\n", "# check if dtype is float32", "\n", "assert", "x", ".", "dtype", "==", "'float32'", "\n", "\n", "# Check if it is c contiguous", "\n", "size", "=", "1", "\n", "c_contiguous", "=", "True", "\n", "for", "i", "in", "range", "(", "x", ".", "ndim", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "if", "x", ".", "shape", "[", "i", "]", "==", "1", ":", "\n", "                ", "continue", "\n", "", "if", "x", ".", "_strides", "[", "i", "]", "!=", "size", ":", "\n", "                ", "c_contiguous", "=", "False", "\n", "break", "\n", "", "size", "*=", "x", ".", "shape", "[", "i", "]", "\n", "", "if", "not", "c_contiguous", ":", "\n", "            ", "if", "copyif", ":", "\n", "                ", "x", "=", "x", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"We were asked to not copy memory, \"", "\n", "\"but the memory is not c contiguous.\"", ")", "\n", "\n", "# Now x is always c contiguous", "\n", "", "", "px", "=", "pycuda", ".", "gpuarray", ".", "GPUArray", "(", "x", ".", "shape", "[", ":", "-", "1", "]", ",", "np", ".", "complex64", ",", "base", "=", "x", ",", "\n", "gpudata", "=", "x", ".", "gpudata", ")", "\n", "return", "px", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.bptrs": [[209, 218], ["pycuda.gpuarray.arange"], "function", ["None"], ["", "", "def", "bptrs", "(", "a", ")", ":", "\n", "    ", "\"\"\"\n    Pointer array when input represents a batch of matrices.\n\n    Taken from scikits.cuda tests/test_cublas.py.\n\n    \"\"\"", "\n", "return", "pycuda", ".", "gpuarray", ".", "arange", "(", "a", ".", "ptr", ",", "a", ".", "ptr", "+", "a", ".", "shape", "[", "0", "]", "*", "a", ".", "strides", "[", "0", "]", ",", "\n", "a", ".", "strides", "[", "0", "]", ",", "dtype", "=", "cublas", ".", "ctypes", ".", "c_void_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.sc_complex_dot_batched": [[220, 288], ["numpy.complex64", "numpy.complex64", "string.lower", "string.lower", "max", "fftconv.bptrs", "fftconv.bptrs", "fftconv.bptrs", "cublas.cublasCgemmBatched", "len", "len", "len", "ValueError", "ValueError", "max", "max", "max", "max", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.bptrs", "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.bptrs", "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.bptrs"], ["", "def", "sc_complex_dot_batched", "(", "bx_gpu", ",", "by_gpu", ",", "bc_gpu", ",", "transa", "=", "'N'", ",", "transb", "=", "'N'", ",", "\n", "handle", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Uses cublasCgemmBatched to compute a bunch of complex dot products\n    in parallel.\n\n    \"\"\"", "\n", "if", "handle", "is", "None", ":", "\n", "        ", "handle", "=", "scikits", ".", "cuda", ".", "misc", ".", "_global_cublas_handle", "\n", "\n", "", "assert", "len", "(", "bx_gpu", ".", "shape", ")", "==", "3", "\n", "assert", "len", "(", "by_gpu", ".", "shape", ")", "==", "3", "\n", "assert", "len", "(", "bc_gpu", ".", "shape", ")", "==", "3", "\n", "assert", "bx_gpu", ".", "dtype", "==", "np", ".", "complex64", "\n", "assert", "by_gpu", ".", "dtype", "==", "np", ".", "complex64", "\n", "assert", "bc_gpu", ".", "dtype", "==", "np", ".", "complex64", "\n", "\n", "# Get the shapes of the arguments", "\n", "bx_shape", "=", "bx_gpu", ".", "shape", "\n", "by_shape", "=", "by_gpu", ".", "shape", "\n", "\n", "# Perform matrix multiplication for 2D arrays:", "\n", "alpha", "=", "np", ".", "complex64", "(", "1.0", ")", "\n", "beta", "=", "np", ".", "complex64", "(", "0.0", ")", "\n", "\n", "transa", "=", "string", ".", "lower", "(", "transa", ")", "\n", "transb", "=", "string", ".", "lower", "(", "transb", ")", "\n", "\n", "if", "transb", "in", "[", "'t'", ",", "'c'", "]", ":", "\n", "        ", "N", ",", "m", ",", "k", "=", "by_shape", "\n", "", "elif", "transb", "in", "[", "'n'", "]", ":", "\n", "        ", "N", ",", "k", ",", "m", "=", "by_shape", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid value for transb'", ")", "\n", "\n", "", "if", "transa", "in", "[", "'t'", ",", "'c'", "]", ":", "\n", "        ", "N2", ",", "l", ",", "n", "=", "bx_shape", "\n", "", "elif", "transa", "in", "[", "'n'", "]", ":", "\n", "        ", "N2", ",", "n", ",", "l", "=", "bx_shape", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid value for transa'", ")", "\n", "\n", "", "if", "l", "!=", "k", ":", "\n", "        ", "raise", "ValueError", "(", "'objects are not aligned'", ")", "\n", "\n", "", "if", "N", "!=", "N2", ":", "\n", "        ", "raise", "ValueError", "(", "'batch sizes are not the same'", ")", "\n", "\n", "", "if", "transb", "==", "'n'", ":", "\n", "        ", "lda", "=", "max", "(", "1", ",", "m", ")", "\n", "", "else", ":", "\n", "        ", "lda", "=", "max", "(", "1", ",", "k", ")", "\n", "\n", "", "if", "transa", "==", "'n'", ":", "\n", "        ", "ldb", "=", "max", "(", "1", ",", "k", ")", "\n", "", "else", ":", "\n", "        ", "ldb", "=", "max", "(", "1", ",", "n", ")", "\n", "\n", "", "ldc", "=", "max", "(", "1", ",", "m", ")", "\n", "\n", "# construct pointer arrays needed for cublasCgemmBatched", "\n", "bx_arr", "=", "bptrs", "(", "bx_gpu", ")", "\n", "by_arr", "=", "bptrs", "(", "by_gpu", ")", "\n", "bc_arr", "=", "bptrs", "(", "bc_gpu", ")", "\n", "\n", "cublas", ".", "cublasCgemmBatched", "(", "handle", ",", "transb", ",", "transa", ",", "m", ",", "n", ",", "k", ",", "alpha", ",", "\n", "by_arr", ".", "gpudata", ",", "lda", ",", "bx_arr", ".", "gpudata", ",", "ldb", ",", "\n", "beta", ",", "bc_arr", ".", "gpudata", ",", "ldc", ",", "N", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.mult_and_reduce": [[356, 394], ["input_fft_v.reshape", "filters_fft_v.reshape", "input_fft_v.reshape.dimshuffle", "filters_fft_v.reshape.dimshuffle", "batched_complex_dot", "batched_complex_dot.dimshuffle", "output_s.dimshuffle.reshape"], "function", ["None"], ["def", "mult_and_reduce", "(", "input_fft_v", ",", "filters_fft_v", ",", "input_shape", "=", "None", ",", "\n", "filter_shape", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n\n    Parameters\n    ----------\n    input_fft_v \n        It's (b, ic, i0, i1//2 + 1, 2).\n    filters_fft_v\n        It's (oc, ic, i0, i1//2 + 1, 2).\n\n    \"\"\"", "\n", "if", "input_shape", "is", "None", ":", "\n", "        ", "input_shape", "=", "input_fft_v", ".", "shape", "# symbolic", "\n", "\n", "", "if", "filter_shape", "is", "None", ":", "\n", "        ", "filter_shape", "=", "filters_fft_v", ".", "shape", "# symbolic", "\n", "\n", "", "b", ",", "ic", ",", "i0", ",", "i1_f", ",", "_", "=", "input_shape", "\n", "oc", "=", "filter_shape", "[", "0", "]", "\n", "\n", "# reshape to flatten the dimensions that are multiplied elemwise", "\n", "input_r", "=", "input_fft_v", ".", "reshape", "(", "(", "b", ",", "ic", ",", "i0", "*", "i1_f", ",", "2", ")", ")", "\n", "filters_r", "=", "filters_fft_v", ".", "reshape", "(", "(", "oc", ",", "ic", ",", "i0", "*", "i1_f", ",", "2", ")", ")", "\n", "\n", "# shuffle for batched dot product", "\n", "input_s", "=", "input_r", ".", "dimshuffle", "(", "2", ",", "0", ",", "1", ",", "3", ")", "# (i0 * i1_f, b, ic, 2)", "\n", "filters_s", "=", "filters_r", ".", "dimshuffle", "(", "2", ",", "1", ",", "0", ",", "3", ")", "# (i0 * i1_f, ic, oc, 2)", "\n", "\n", "output_s", "=", "batched_complex_dot", "(", "input_s", ",", "filters_s", ")", "\n", "\n", "# shuffle again", "\n", "output_r", "=", "output_s", ".", "dimshuffle", "(", "1", ",", "2", ",", "0", ",", "3", ")", "\n", "\n", "# reshape to unflatten", "\n", "output", "=", "output_r", ".", "reshape", "(", "(", "b", ",", "oc", ",", "i0", ",", "i1_f", ",", "2", ")", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.conv2d_fft": [[396, 534], ["T.set_subtensor.reshape", "T.set_subtensor.reshape", "cufft", "cufft", "cufft.reshape", "cufft.reshape", "fftconv.mult_and_reduce", "mult_and_reduce.reshape", "cuifft", "cuifft.reshape", "basic_ops.as_cuda_ndarray_variable", "theano.zeros", "theano.set_subtensor", "theano.opt.Assert", "theano.eq", "theano.zeros", "theano.set_subtensor", "theano.zeros", "theano.set_subtensor", "theano.zeros", "theano.set_subtensor", "ValueError", "ValueError", "theano.cast"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.mult_and_reduce"], ["", "def", "conv2d_fft", "(", "input", ",", "filters", ",", "image_shape", "=", "None", ",", "filter_shape", "=", "None", ",", "\n", "border_mode", "=", "'valid'", ",", "pad_last_dim", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Perform a convolution through fft.\n\n    Only support input which will be even on the last dimension\n    (width).  All other dimensions can be anything and the filters can\n    have an even or odd width.\n\n    If you must use input which has an odd width, you can either pad\n    it or use the `pad_last_dim` argument which will do it for you and\n    take care to strip the padding before returning.  Don't use this\n    argument if you are not sure the input is odd since the padding is\n    unconditional and will make even input odd, thus leading to\n    problems.\n\n    On valid mode the filters must be smaller than the input.\n\n    Parameters\n    ----------\n    input\n        (b, ic, i0, i1).\n    filters\n        (oc, ic, f0, f1).\n    border_mode : {'valid', 'full'}\n    pad_last_dim\n        Unconditionally pad the last dimension of the input\n        to to turn it from odd to even.  Will strip the\n        padding before returning the result.\n\n    \"\"\"", "\n", "# use symbolic shapes to compute shape info at runtime if not specified", "\n", "if", "image_shape", "is", "None", ":", "\n", "        ", "image_shape", "=", "input", ".", "shape", "\n", "\n", "", "if", "filter_shape", "is", "None", ":", "\n", "        ", "filter_shape", "=", "filters", ".", "shape", "\n", "\n", "# batch size, input channels, input dim 0, input dim 1", "\n", "", "b", ",", "ic", ",", "i0", ",", "i1", "=", "image_shape", "\n", "# output channels, input channels, filter dim 0, filter dim 1", "\n", "oc", ",", "ic_", ",", "f0", ",", "f1", "=", "filter_shape", "\n", "\n", "# pad filters/image to output shape", "\n", "if", "border_mode", "==", "'valid'", ":", "\n", "        ", "o0", "=", "i0", "\n", "if", "pad_last_dim", ":", "\n", "            ", "o1", "=", "i1", "+", "1", "\n", "input_padded", "=", "T", ".", "zeros", "(", "(", "b", ",", "ic", ",", "o0", ",", "o1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "input_padded", "=", "T", ".", "set_subtensor", "(", "input_padded", "[", ":", ",", ":", ",", ":", "i0", ",", ":", "i1", "]", ",", "\n", "input", ")", "\n", "", "else", ":", "\n", "            ", "o1", "=", "i1", "\n", "input_padded", "=", "input", "\n", "\n", "", "filters_padded", "=", "T", ".", "zeros", "(", "(", "oc", ",", "ic", ",", "o0", ",", "o1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "filters_padded", "=", "T", ".", "set_subtensor", "(", "filters_padded", "[", ":", ",", ":", ",", ":", "f0", ",", ":", "f1", "]", ",", "\n", "filters", ")", "\n", "\n", "", "elif", "border_mode", "==", "'full'", ":", "\n", "\n", "# In this particular case, the values of (o0, o1) represent", "\n", "# the dimensions of the work buffer more than the actual dimensions", "\n", "# of the desired output.", "\n", "        ", "o0", "=", "i0", "+", "2", "*", "(", "f0", "-", "1", ")", "\n", "o1", "=", "i1", "+", "2", "*", "(", "f1", "-", "1", ")", "\n", "\n", "if", "pad_last_dim", ":", "\n", "            ", "o1", "=", "o1", "+", "1", "\n", "\n", "# We line up the filters and the images in a way", "\n", "# such that the filters are tightly placed against the", "\n", "# top-left of the array, and the images intersect with", "\n", "# them on one pixel. The top-left pixel of the images", "\n", "# is the bottom-right pixel of the filters when we", "\n", "# do the layout here.", "\n", "\n", "", "filters_padded", "=", "T", ".", "zeros", "(", "(", "oc", ",", "ic", ",", "o0", ",", "o1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "filters_padded", "=", "T", ".", "set_subtensor", "(", "filters_padded", "[", ":", ",", ":", ",", ":", "f0", ",", ":", "f1", "]", ",", "\n", "filters", ")", "\n", "\n", "input_padded", "=", "T", ".", "zeros", "(", "(", "b", ",", "ic", ",", "o0", ",", "o1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "input_padded", "=", "T", ".", "set_subtensor", "(", "input_padded", "[", ":", ",", ":", ",", "(", "f0", "-", "1", ")", ":", "(", "f0", "-", "1", "+", "i0", ")", ",", "(", "f1", "-", "1", ")", ":", "(", "f1", "-", "1", "+", "i1", ")", "]", ",", "\n", "input", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid mode'", ")", "\n", "\n", "", "input_padded", "=", "T", ".", "opt", ".", "Assert", "(", "\"in conv2d_fft: width is not even\"", ")", "(", "\n", "input_padded", ",", "T", ".", "eq", "(", "o1", "%", "2", ",", "0", ")", ")", "\n", "\n", "# reshape for FFT", "\n", "input_flat", "=", "input_padded", ".", "reshape", "(", "(", "b", "*", "ic", ",", "o0", ",", "o1", ")", ")", "\n", "filters_flat", "=", "filters_padded", ".", "reshape", "(", "(", "oc", "*", "ic", ",", "o0", ",", "o1", ")", ")", "\n", "\n", "# perform FFT", "\n", "input_fft_flat", "=", "cufft", "(", "input_flat", ")", "# (b * ic, o0, o1//2 + 1, 2)", "\n", "filters_fft_flat", "=", "cufft", "(", "filters_flat", ")", "# (oc * ic, o0, o1//2 + 1, 2)", "\n", "\n", "# unfold ic dimension", "\n", "input_fft_v_shape", "=", "(", "b", ",", "ic", ",", "o0", ",", "o1", "//", "2", "+", "1", ",", "2", ")", "\n", "filters_fft_v_shape", "=", "(", "oc", ",", "ic", ",", "o0", ",", "o1", "//", "2", "+", "1", ",", "2", ")", "\n", "input_fft_v", "=", "input_fft_flat", ".", "reshape", "(", "input_fft_v_shape", ")", "\n", "filters_fft_v", "=", "filters_fft_flat", ".", "reshape", "(", "filters_fft_v_shape", ")", "\n", "\n", "# (b, oc, o0, o1//2 + 1, 2)", "\n", "output_fft_s", "=", "mult_and_reduce", "(", "input_fft_v", ",", "filters_fft_v", ",", "\n", "input_shape", "=", "input_fft_v_shape", ",", "\n", "filter_shape", "=", "filters_fft_v_shape", ")", "\n", "\n", "# reshape for IFFT", "\n", "output_fft_flat", "=", "output_fft_s", ".", "reshape", "(", "(", "b", "*", "oc", ",", "o0", ",", "o1", "//", "2", "+", "1", ",", "2", ")", ")", "\n", "\n", "# perform IFFT", "\n", "output_flat", "=", "cuifft", "(", "output_fft_flat", ")", "# (b * oc, o0, o1)", "\n", "\n", "# reshape", "\n", "output_circ", "=", "output_flat", ".", "reshape", "(", "(", "b", ",", "oc", ",", "o0", ",", "o1", ")", ")", "# circular!", "\n", "\n", "# Now we extract the region of interest.", "\n", "# We just cut it out from the output_circ", "\n", "# array that was used for the computation.", "\n", "# We do not need to handle pad_last_dim in a", "\n", "# special way because we specify explicitly here", "\n", "# how much values are expected.", "\n", "if", "border_mode", "==", "'valid'", ":", "\n", "        ", "output", "=", "output_circ", "[", ":", ",", ":", ",", "(", "f0", "-", "1", ")", ":", "(", "f0", "-", "1", "+", "i0", "-", "f0", "+", "1", ")", ",", "(", "f1", "-", "1", ")", ":", "(", "f1", "-", "1", "+", "i1", "-", "f1", "+", "1", ")", "]", "\n", "", "elif", "border_mode", "==", "'full'", ":", "\n", "        ", "output", "=", "output_circ", "[", ":", ",", ":", ",", "(", "f0", "-", "1", ")", ":", "(", "f0", "-", "1", "+", "i0", "+", "f0", "-", "1", ")", ",", "(", "f1", "-", "1", ")", ":", "(", "f1", "-", "1", "+", "i1", "+", "f1", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid mode'", ")", "\n", "\n", "# Rescale manually. This is just a factor that comes in during the", "\n", "# trip through FFT and inverse FFT.", "\n", "", "output", "=", "(", "1.0", "/", "T", ".", "cast", "(", "o0", "*", "o1", ",", "'float32'", ")", ")", "*", "output", "\n", "\n", "# output should now be the result of a batched valid convolution", "\n", "# of the input with the filters.", "\n", "return", "basic_ops", ".", "as_cuda_ndarray_variable", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.conv3d_fft": [[536, 685], ["theano.eq", "T.set_subtensor.reshape", "T.set_subtensor.reshape", "cufft", "cufft", "cufft.reshape", "cufft.reshape", "fftconv.mult_and_reduce", "mult_and_reduce.reshape", "cuifft", "cuifft.reshape", "basic_ops.as_cuda_ndarray_variable", "theano.mod", "theano.zeros", "theano.set_subtensor", "theano.ifelse.ifelse", "theano.zeros", "theano.set_subtensor", "theano.zeros", "theano.set_subtensor", "theano.zeros", "theano.set_subtensor", "ValueError", "ValueError", "theano.cast", "theano.ifelse.ifelse"], "function", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.fftconv.mult_and_reduce"], ["", "def", "conv3d_fft", "(", "input", ",", "filters", ",", "image_shape", "=", "None", ",", "filter_shape", "=", "None", ",", "\n", "border_mode", "=", "'valid'", ",", "pad_last_dim", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Perform a convolution through fft.\n\n    Only supports input whose shape is even on the last dimension.\n    All other dimensions can be anything and the filters can\n    have an even or odd last dimension.\n\n    The semantics associated with the last three dimensions\n    are not important as long as they are in the same order between\n    the inputs and the filters. For example, when the convolution\n    is done on a sequence of images, they could be either\n    (duration, height, width) or (height, width, duration).\n\n    If you must use input which has an odd width, you can either pad\n    it or use the `pad_last_dim` argument which will do it for you and\n    take care to strip the padding before returning. pad_last_dim checks\n    that the last dimension is odd before the actual paddding\n\n    On valid mode the filters must be smaller than the input.\n\n    Parameters\n    ----------\n    input\n        (b, ic, i0, i1, i2).\n    filters\n        (oc, ic, f0, f1, i2).\n    border_mode : {'valid', 'full'}.\n    pad_last_dim\n        Unconditionally pad the last dimension of the input\n        to to turn it from odd to even.  Will strip the\n        padding before returning the result.\n\n    \"\"\"", "\n", "# use symbolic shapes to compute shape info at runtime if not specified", "\n", "if", "image_shape", "is", "None", ":", "\n", "        ", "image_shape", "=", "input", ".", "shape", "\n", "\n", "", "if", "filter_shape", "is", "None", ":", "\n", "        ", "filter_shape", "=", "filters", ".", "shape", "\n", "\n", "# batch size, input channels, input dim 0, input dim 1", "\n", "", "b", ",", "ic", ",", "i0", ",", "i1", ",", "i2", "=", "image_shape", "\n", "# output channels, input channels, filter dim 0, filter dim 1", "\n", "oc", ",", "ic_", ",", "f0", ",", "f1", ",", "f2", "=", "filter_shape", "\n", "\n", "# Check that the last dimension is odd", "\n", "is_odd", "=", "T", ".", "eq", "(", "T", ".", "mod", "(", "input", ".", "shape", "[", "4", "]", ",", "2", ")", ",", "1", ")", "\n", "\n", "# pad filters/image to output shape", "\n", "if", "border_mode", "==", "'valid'", ":", "\n", "        ", "o0", "=", "i0", "\n", "o1", "=", "i1", "\n", "o2", "=", "i2", "\n", "input_padded", "=", "input", "\n", "if", "pad_last_dim", ":", "\n", "            ", "o2", "=", "ifelse", "(", "is_odd", ",", "o2", "+", "1", ",", "o2", ")", "\n", "input_padded", "=", "T", ".", "zeros", "(", "(", "b", ",", "ic", ",", "o0", ",", "o1", ",", "o2", ")", ",", "dtype", "=", "'float32'", ")", "\n", "input_padded", "=", "T", ".", "set_subtensor", "(", "input_padded", "[", ":", ",", ":", ",", ":", "i0", ",", ":", "i1", ",", ":", "i2", "]", ",", "\n", "input", ")", "\n", "", "filters_padded", "=", "T", ".", "zeros", "(", "(", "oc", ",", "ic", ",", "o0", ",", "o1", ",", "o2", ")", ",", "dtype", "=", "'float32'", ")", "\n", "filters_padded", "=", "T", ".", "set_subtensor", "(", "filters_padded", "[", ":", ",", ":", ",", ":", "f0", ",", ":", "f1", ",", ":", "f2", "]", ",", "\n", "filters", ")", "\n", "\n", "", "elif", "border_mode", "==", "'full'", ":", "\n", "\n", "# In this particular case, the values of (o0, o1) represent", "\n", "# the dimensions of the work buffer more than the actual dimensions", "\n", "# of the desired output.", "\n", "        ", "o0", "=", "i0", "+", "2", "*", "(", "f0", "-", "1", ")", "\n", "o1", "=", "i1", "+", "2", "*", "(", "f1", "-", "1", ")", "\n", "o2", "=", "i2", "+", "2", "*", "(", "f2", "-", "1", ")", "\n", "\n", "if", "pad_last_dim", ":", "\n", "            ", "o2", "=", "ifelse", "(", "is_odd", ",", "o2", "+", "1", ",", "o2", ")", "\n", "\n", "# We line up the filters and the images in a way", "\n", "# such that the filters are tightly placed against the", "\n", "# top-left of the array, and the images intersect with", "\n", "# them on one pixel. The top-left pixel of the images", "\n", "# is the bottom-right pixel of the filters when we", "\n", "# do the layout here.", "\n", "\n", "", "filters_padded", "=", "T", ".", "zeros", "(", "(", "oc", ",", "ic", ",", "o0", ",", "o1", ",", "o2", ")", ",", "dtype", "=", "'float32'", ")", "\n", "filters_padded", "=", "T", ".", "set_subtensor", "(", "filters_padded", "[", ":", ",", ":", ",", ":", "f0", ",", ":", "f1", ",", ":", "f2", "]", ",", "\n", "filters", ")", "\n", "\n", "input_padded", "=", "T", ".", "zeros", "(", "(", "b", ",", "ic", ",", "o0", ",", "o1", ",", "o2", ")", ",", "dtype", "=", "'float32'", ")", "\n", "input_padded", "=", "T", ".", "set_subtensor", "(", "input_padded", "[", ":", ",", ":", ",", "(", "f0", "-", "1", ")", ":", "(", "f0", "-", "1", "+", "i0", ")", ",", "(", "f1", "-", "1", ")", ":", "(", "f1", "-", "1", "+", "i1", ")", ",", "(", "f2", "-", "1", ")", ":", "(", "f2", "-", "1", "+", "i2", ")", "]", ",", "\n", "input", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid mode'", ")", "\n", "\n", "# reshape for FFT", "\n", "", "input_flat", "=", "input_padded", ".", "reshape", "(", "(", "b", "*", "ic", ",", "o0", ",", "o1", ",", "o2", ")", ")", "\n", "filters_flat", "=", "filters_padded", ".", "reshape", "(", "(", "oc", "*", "ic", ",", "o0", ",", "o1", ",", "o2", ")", ")", "\n", "\n", "# perform FFT", "\n", "input_fft_flat", "=", "cufft", "(", "input_flat", ")", "# (b * ic, o0, o1, o2//2 + 1, 2)", "\n", "filters_fft_flat", "=", "cufft", "(", "filters_flat", ")", "# (oc * ic, o0, o1, o2//2 + 1, 2)", "\n", "\n", "# Unfold ic dimension.", "\n", "# We have to collapse two dimensions together", "\n", "# in order to reuse the same `mult_and_reduce`.", "\n", "# This explains the o0 * 01 instead of just keeping", "\n", "# the two dimensions intact.", "\n", "input_fft_v_shape", "=", "(", "b", ",", "ic", ",", "o0", "*", "o1", ",", "o2", "//", "2", "+", "1", ",", "2", ")", "\n", "filters_fft_v_shape", "=", "(", "oc", ",", "ic", ",", "o0", "*", "o1", ",", "o2", "//", "2", "+", "1", ",", "2", ")", "\n", "\n", "input_fft_v", "=", "input_fft_flat", ".", "reshape", "(", "input_fft_v_shape", ")", "\n", "filters_fft_v", "=", "filters_fft_flat", ".", "reshape", "(", "filters_fft_v_shape", ")", "\n", "\n", "# (b, oc, o0 * o1, o2//2 + 1, 2)", "\n", "output_fft_s", "=", "mult_and_reduce", "(", "input_fft_v", ",", "filters_fft_v", ",", "\n", "input_shape", "=", "input_fft_v_shape", ",", "\n", "filter_shape", "=", "filters_fft_v_shape", ")", "\n", "#output_fft_s = input_fft_v", "\n", "\n", "# reshape for IFFT", "\n", "output_fft_flat", "=", "output_fft_s", ".", "reshape", "(", "(", "b", "*", "oc", ",", "o0", ",", "o1", ",", "o2", "//", "2", "+", "1", ",", "2", ")", ")", "\n", "\n", "# perform IFFT", "\n", "output_flat", "=", "cuifft", "(", "output_fft_flat", ")", "# (b * oc, o0, o1, o2)", "\n", "\n", "# reshape", "\n", "output_circ", "=", "output_flat", ".", "reshape", "(", "(", "b", ",", "oc", ",", "o0", ",", "o1", ",", "o2", ")", ")", "# circular!", "\n", "\n", "# Now we extract the region of interest.", "\n", "# We just cut it out from the output_circ", "\n", "# array that was used for the computation.", "\n", "# We do not need to handle pad_last_dim in a", "\n", "# special way because we specify explicitly here", "\n", "# how much values are expected.", "\n", "if", "border_mode", "==", "'valid'", ":", "\n", "        ", "output", "=", "output_circ", "[", ":", ",", ":", ",", "(", "f0", "-", "1", ")", ":", "(", "f0", "-", "1", "+", "i0", "-", "f0", "+", "1", ")", ",", "(", "f1", "-", "1", ")", ":", "(", "f1", "-", "1", "+", "i1", "-", "f1", "+", "1", ")", ",", "(", "f2", "-", "1", ")", ":", "(", "f2", "-", "1", "+", "i2", "-", "f2", "+", "1", ")", "]", "\n", "", "elif", "border_mode", "==", "'full'", ":", "\n", "        ", "output", "=", "output_circ", "[", ":", ",", ":", ",", "(", "f0", "-", "1", ")", ":", "(", "f0", "-", "1", "+", "i0", "+", "f0", "-", "1", ")", ",", "(", "f1", "-", "1", ")", ":", "(", "f1", "-", "1", "+", "i1", "+", "f1", "-", "1", ")", ",", "(", "f2", "-", "1", ")", ":", "(", "f2", "-", "1", "+", "i2", "+", "f2", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'invalid mode'", ")", "\n", "#output = output_circ[:, :, :, :, :]", "\n", "\n", "# Rescale manually. This is just a factor that comes in during the", "\n", "# trip through FFT and inverse FFT.", "\n", "", "output", "=", "(", "1.0", "/", "T", ".", "cast", "(", "o0", "*", "o1", "*", "o2", ",", "'float32'", ")", ")", "*", "output", "\n", "\n", "# output should now be the result of a batched valid convolution", "\n", "# of the input with the filters.", "\n", "return", "basic_ops", ".", "as_cuda_ndarray_variable", "(", "output", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.custom_optimizers.RMSprop_and_natGrad.__init__": [[21, 34], ["keras.optimizers.Optimizer.__init__", "custom_optimizers.RMSprop_and_natGrad.__dict__.update", "keras.backend.variable", "keras.backend.variable", "keras.backend.variable", "keras.backend.variable", "locals", "keras.backend.variable", "keras.backend.variable"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.custom_optimizers.RMSprop_and_natGrad.__init__"], ["def", "__init__", "(", "self", ",", "lr", "=", "0.001", ",", "rho", "=", "0.9", ",", "epsilon", "=", "1e-8", ",", "decay", "=", "0.", ",", "lr_natGrad", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RMSprop_and_natGrad", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "__dict__", ".", "update", "(", "locals", "(", ")", ")", "\n", "self", ".", "lr", "=", "K", ".", "variable", "(", "lr", ")", "\n", "if", "lr_natGrad", "is", "None", ":", "\n", "            ", "self", ".", "lr_natGrad", "=", "K", ".", "variable", "(", "lr", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "lr_natGrad", "=", "K", ".", "variable", "(", "lr_natGrad", ")", "\n", "", "self", ".", "rho", "=", "K", ".", "variable", "(", "rho", ")", "\n", "self", ".", "decay", "=", "K", ".", "variable", "(", "decay", ")", "\n", "self", ".", "inital_decay", "=", "decay", "\n", "self", ".", "iterations", "=", "K", ".", "variable", "(", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.custom_optimizers.RMSprop_and_natGrad.get_updates": [[35, 105], ["custom_optimizers.RMSprop_and_natGrad.get_gradients", "zip", "keras.backend.get_variable_shape", "keras.backend.zeros", "custom_optimizers.RMSprop_and_natGrad.updates.append", "custom_optimizers.RMSprop_and_natGrad.updates.append", "keras.backend.update_add", "custom_optimizers.RMSprop_and_natGrad.updates.append", "c", "keras.backend.update", "custom_optimizers.RMSprop_and_natGrad.updates.append", "keras.backend.cast", "keras.backend.cast", "keras.backend.cast", "keras.backend.cast", "keras.backend.cast", "keras.backend.eye", "keras.backend.cast", "keras.backend.dot", "keras.backend.transpose", "keras.backend.transpose", "keras.backend.concatenate", "custom_optimizers.RMSprop_and_natGrad.updates.append", "keras.backend.update", "keras.backend.update", "custom_optimizers.RMSprop_and_natGrad.updates.append", "keras.backend.transpose", "keras.backend.transpose", "keras.backend.transpose", "keras.backend.transpose", "keras.backend.transpose", "keras.backend.dot", "theano.real", "theano.imag", "keras.backend.update", "keras.backend.square", "keras.backend.square", "keras.backend.sqrt", "keras.backend.update", "keras.backend.dot", "theano.conj", "theano.nlinalg.matrix_inverse", "keras.backend.concatenate", "keras.backend.concatenate", "keras.backend.square", "keras.backend.sqrt", "keras.backend.dot", "keras.backend.dot", "keras.backend.dot", "keras.backend.transpose", "keras.backend.sqrt", "keras.backend.transpose", "keras.backend.transpose", "keras.backend.transpose"], "methods", ["None"], ["", "def", "get_updates", "(", "self", ",", "params", ",", "constraints", ",", "loss", ")", ":", "\n", "        ", "grads", "=", "self", ".", "get_gradients", "(", "loss", ",", "params", ")", "\n", "shapes", "=", "[", "K", ".", "get_variable_shape", "(", "p", ")", "for", "p", "in", "params", "]", "\n", "accumulators", "=", "[", "K", ".", "zeros", "(", "shape", ")", "for", "shape", "in", "shapes", "]", "\n", "self", ".", "weights", "=", "accumulators", "\n", "self", ".", "updates", "=", "[", "]", "\n", "\n", "lr", "=", "self", ".", "lr", "\n", "if", "self", ".", "inital_decay", ">", "0", ":", "\n", "            ", "lr", "*=", "(", "1.", "/", "(", "1.", "+", "self", ".", "decay", "*", "self", ".", "iterations", ")", ")", "\n", "self", ".", "updates", ".", "append", "(", "K", ".", "update_add", "(", "self", ".", "iterations", ",", "1", ")", ")", "\n", "\n", "", "for", "param", ",", "grad", ",", "accum", ",", "shape", "in", "zip", "(", "params", ",", "grads", ",", "accumulators", ",", "shapes", ")", ":", "\n", "\n", "            ", "if", "(", "'natGrad'", "in", "param", ".", "name", ")", ":", "\n", "                ", "if", "(", "'natGradRMS'", "in", "param", ".", "name", ")", ":", "\n", "#apply RMSprop rule to gradient before natural gradient step", "\n", "                    ", "new_accum", "=", "self", ".", "rho", "*", "accum", "+", "(", "1.", "-", "self", ".", "rho", ")", "*", "K", ".", "square", "(", "grad", ")", "\n", "self", ".", "updates", ".", "append", "(", "K", ".", "update", "(", "accum", ",", "new_accum", ")", ")", "\n", "grad", "=", "grad", "/", "(", "K", ".", "sqrt", "(", "new_accum", ")", "+", "self", ".", "epsilon", ")", "\n", "", "elif", "(", "'unitaryAug'", "in", "param", ".", "name", ")", ":", "\n", "#we don't care about the accumulated RMS for the natural gradient step", "\n", "                    ", "self", ".", "updates", ".", "append", "(", "K", ".", "update", "(", "accum", ",", "accum", ")", ")", "\n", "\n", "#do a natural gradient step", "\n", "", "if", "(", "'unitaryAug'", "in", "param", ".", "name", ")", ":", "\n", "#unitary natural gradient step on augmented ReIm matrix", "\n", "                    ", "j", "=", "K", ".", "cast", "(", "1j", ",", "'complex64'", ")", "\n", "A", "=", "K", ".", "cast", "(", "K", ".", "transpose", "(", "param", "[", ":", "shape", "[", "1", "]", "/", "2", ",", ":", "shape", "[", "1", "]", "/", "2", "]", ")", ",", "'complex64'", ")", "\n", "B", "=", "K", ".", "cast", "(", "K", ".", "transpose", "(", "param", "[", ":", "shape", "[", "1", "]", "/", "2", ",", "shape", "[", "1", "]", "/", "2", ":", "]", ")", ",", "'complex64'", ")", "\n", "X", "=", "A", "+", "j", "*", "B", "\n", "C", "=", "K", ".", "cast", "(", "K", ".", "transpose", "(", "grad", "[", ":", "shape", "[", "1", "]", "/", "2", ",", ":", "shape", "[", "1", "]", "/", "2", "]", ")", ",", "'complex64'", ")", "\n", "D", "=", "K", ".", "cast", "(", "K", ".", "transpose", "(", "grad", "[", ":", "shape", "[", "1", "]", "/", "2", ",", "shape", "[", "1", "]", "/", "2", ":", "]", ")", ",", "'complex64'", ")", "\n", "# build skew-Hermitian matrix A", "\n", "# from equation (8) of [Wisdom,Powers,Hershey,Le Roux,Atlas 2016]", "\n", "# GX^H = CA^T + DB^T + jDA^T - jCB^T", "\n", "GXH", "=", "K", ".", "dot", "(", "C", ",", "K", ".", "transpose", "(", "A", ")", ")", "+", "K", ".", "dot", "(", "D", ",", "K", ".", "transpose", "(", "B", ")", ")", "+", "j", "*", "K", ".", "dot", "(", "D", ",", "K", ".", "transpose", "(", "A", ")", ")", "-", "j", "*", "K", ".", "dot", "(", "C", ",", "K", ".", "transpose", "(", "B", ")", ")", "\n", "Askew", "=", "GXH", "-", "K", ".", "transpose", "(", "T", ".", "conj", "(", "GXH", ")", ")", "\n", "I", "=", "K", ".", "eye", "(", "shape", "[", "1", "]", "/", "2", ")", "\n", "two", "=", "K", ".", "cast", "(", "2", ",", "'complex64'", ")", "\n", "CayleyDenom", "=", "I", "+", "(", "self", ".", "lr_natGrad", "/", "two", ")", "*", "Askew", "\n", "CayleyNumer", "=", "I", "-", "(", "self", ".", "lr_natGrad", "/", "two", ")", "*", "Askew", "\n", "# multiplicative gradient step along Stiefel manifold", "\n", "# equation (9) of [Wisdom,Powers,Hershey,Le Roux,Atlas 2016]", "\n", "Xnew", "=", "K", ".", "dot", "(", "K", ".", "dot", "(", "T", ".", "nlinalg", ".", "matrix_inverse", "(", "CayleyDenom", ")", ",", "CayleyNumer", ")", ",", "X", ")", "\n", "\n", "# convert to ReIm augmented form", "\n", "XnewRe", "=", "K", ".", "transpose", "(", "T", ".", "real", "(", "Xnew", ")", ")", "\n", "XnewIm", "=", "K", ".", "transpose", "(", "T", ".", "imag", "(", "Xnew", ")", ")", "\n", "new_param", "=", "K", ".", "concatenate", "(", "(", "K", ".", "concatenate", "(", "(", "XnewRe", ",", "XnewIm", ")", ",", "axis", "=", "1", ")", ",", "K", ".", "concatenate", "(", "(", "(", "-", "1", ")", "*", "XnewIm", ",", "XnewRe", ")", ",", "axis", "=", "1", ")", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "#do the usual RMSprop update using lr_natGrad as learning rate", "\n", "# update accumulator", "\n", "                    ", "new_accum", "=", "self", ".", "rho", "*", "accum", "+", "(", "1.", "-", "self", ".", "rho", ")", "*", "K", ".", "square", "(", "grad", ")", "\n", "self", ".", "updates", ".", "append", "(", "K", ".", "update", "(", "accum", ",", "new_accum", ")", ")", "\n", "new_param", "=", "param", "-", "self", ".", "lr_natGrad", "*", "grad", "/", "(", "K", ".", "sqrt", "(", "new_accum", ")", "+", "self", ".", "epsilon", ")", "\n", "", "", "else", ":", "\n", "#do the usual RMSprop update", "\n", "# update accumulator", "\n", "                ", "new_accum", "=", "self", ".", "rho", "*", "accum", "+", "(", "1.", "-", "self", ".", "rho", ")", "*", "K", ".", "square", "(", "grad", ")", "\n", "self", ".", "updates", ".", "append", "(", "K", ".", "update", "(", "accum", ",", "new_accum", ")", ")", "\n", "new_param", "=", "param", "-", "lr", "*", "grad", "/", "(", "K", ".", "sqrt", "(", "new_accum", ")", "+", "self", ".", "epsilon", ")", "\n", "\n", "# apply constraints", "\n", "", "if", "param", "in", "constraints", ":", "\n", "                ", "c", "=", "constraints", "[", "param", "]", "\n", "new_param", "=", "c", "(", "new_param", ")", "\n", "", "self", ".", "updates", ".", "append", "(", "K", ".", "update", "(", "param", ",", "new_param", ")", ")", "\n", "", "return", "self", ".", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.custom_optimizers.RMSprop_and_natGrad.get_config": [[106, 113], ["super().get_config", "dict", "float", "float", "float", "keras.backend.get_value", "keras.backend.get_value", "keras.backend.get_value", "list", "list", "super().get_config.items", "config.items"], "methods", ["home.repos.pwc.inspect_result.stwisdom_urnn.None.custom_optimizers.RMSprop_and_natGrad.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "'lr'", ":", "float", "(", "K", ".", "get_value", "(", "self", ".", "lr", ")", ")", ",", "\n", "'lr_natGrad'", ":", "float", "(", "K", ".", "get_value", "(", "self", ".", "lr_natGrad", ")", ")", ",", "\n", "'rho'", ":", "float", "(", "K", ".", "get_value", "(", "self", ".", "rho", ")", ")", ",", "\n", "'epsilon'", ":", "self", ".", "epsilon", "}", "\n", "base_config", "=", "super", "(", "RMSprop_and_natGrad", ",", "self", ")", ".", "get_config", "(", ")", "\n", "return", "dict", "(", "list", "(", "base_config", ".", "items", "(", ")", ")", "+", "list", "(", "config", ".", "items", "(", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.optimizations.clipped_gradients": [[6, 10], ["theano.clip"], "function", ["None"], ["def", "clipped_gradients", "(", "gradients", ",", "gradient_clipping", ")", ":", "\n", "    ", "clipped_grads", "=", "[", "T", ".", "clip", "(", "g", ",", "-", "gradient_clipping", ",", "gradient_clipping", ")", "\n", "for", "g", "in", "gradients", "]", "\n", "return", "clipped_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.optimizations.gradient_descent": [[11, 14], ["zip"], "function", ["None"], ["", "def", "gradient_descent", "(", "learning_rate", ",", "parameters", ",", "gradients", ")", ":", "\n", "    ", "updates", "=", "[", "(", "p", ",", "p", "-", "learning_rate", "*", "g", ")", "for", "p", ",", "g", "in", "zip", "(", "parameters", ",", "gradients", ")", "]", "\n", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.optimizations.gradient_descent_momentum": [[15, 24], ["theano.shared", "theano.shared", "numpy.zeros_like", "zip", "zip", "p.get_value"], "function", ["None"], ["", "def", "gradient_descent_momentum", "(", "learning_rate", ",", "momentum", ",", "parameters", ",", "gradients", ")", ":", "\n", "    ", "velocities", "=", "[", "theano", ".", "shared", "(", "np", ".", "zeros_like", "(", "p", ".", "get_value", "(", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", ")", "for", "p", "in", "parameters", "]", "\n", "\n", "updates1", "=", "[", "(", "vel", ",", "momentum", "*", "vel", "-", "learning_rate", "*", "g", ")", "\n", "for", "vel", ",", "g", "in", "zip", "(", "velocities", ",", "gradients", ")", "]", "\n", "updates2", "=", "[", "(", "p", ",", "p", "+", "vel", ")", "for", "p", ",", "vel", "in", "zip", "(", "parameters", ",", "velocities", ")", "]", "\n", "updates", "=", "updates1", "+", "updates2", "\n", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.stwisdom_urnn.None.optimizations.rms_prop": [[26, 97], ["zip", "theano.shared", "theano.shared", "range", "theano.cast", "theano.cast", "theano.cast", "theano.cast", "theano.identity_like", "theano.transpose", "theano.transpose", "theano.concatenate", "zip", "zip", "theano.transpose", "theano.transpose", "theano.nlinalg.svd", "theano.dot", "theano.transpose", "theano.transpose", "theano.concatenate", "len", "numpy.ones_like", "theano.transpose", "zip", "theano.transpose", "zip", "theano.transpose", "zip", "theano.transpose", "zip", "zip", "zip", "theano.transpose", "zip", "zip", "theano.dot", "theano.real", "theano.imag", "zip", "theano.real", "theano.imag", "zip", "p.get_value", "theano.cast", "theano.dot", "theano.cast", "theano.conj", "theano.dot", "zip", "theano.concatenate", "theano.concatenate", "theano.sqrt", "theano.concatenate", "theano.concatenate", "theano.dot", "theano.dot", "theano.cast", "theano.dot", "theano.transpose", "theano.cast", "theano.cast", "theano.nlinalg.matrix_inverse", "theano.cast", "theano.transpose", "theano.transpose", "theano.transpose"], "function", ["None"], ["", "def", "rms_prop", "(", "learning_rate", ",", "parameters", ",", "gradients", ",", "idx_project", "=", "None", ")", ":", "\n", "    ", "rmsprop", "=", "[", "theano", ".", "shared", "(", "1e-3", "*", "np", ".", "ones_like", "(", "p", ".", "get_value", "(", ")", ")", ")", "for", "p", "in", "parameters", "]", "\n", "\n", "if", "idx_project", "is", "not", "None", ":", "\n", "# we will use projected gradient on the Stiefel manifold on these parameters", "\n", "# we will assume these parameters are unitary matrices in real-composite form", "\n", "        ", "parameters_proj", "=", "[", "parameters", "[", "i", "]", "for", "i", "in", "idx_project", "]", "\n", "gradients_proj", "=", "[", "gradients", "[", "i", "]", "for", "i", "in", "idx_project", "]", "\n", "sizes_proj", "=", "[", "p", ".", "shape", "for", "p", "in", "parameters_proj", "]", "\n", "# compute gradient in tangent space of Stiefel manifold (see Lemma 4 of [Tagare 2011])", "\n", "# X = A+jB", "\n", "Aall", "=", "[", "T", ".", "cast", "(", "T", ".", "transpose", "(", "p", "[", ":", "s", "[", "0", "]", "/", "2", ",", ":", "s", "[", "0", "]", "/", "2", "]", ")", ",", "'complex64'", ")", "for", "s", ",", "p", "in", "zip", "(", "sizes_proj", ",", "parameters_proj", ")", "]", "\n", "Ball", "=", "[", "T", ".", "cast", "(", "T", ".", "transpose", "(", "p", "[", ":", "s", "[", "0", "]", "/", "2", ",", "s", "[", "0", "]", "/", "2", ":", "]", ")", ",", "'complex64'", ")", "for", "s", ",", "p", "in", "zip", "(", "sizes_proj", ",", "parameters_proj", ")", "]", "\n", "# G = C+jD", "\n", "Call", "=", "[", "T", ".", "cast", "(", "T", ".", "transpose", "(", "g", "[", ":", "s", "[", "0", "]", "/", "2", ",", ":", "s", "[", "0", "]", "/", "2", "]", ")", ",", "'complex64'", ")", "for", "s", ",", "g", "in", "zip", "(", "sizes_proj", ",", "gradients_proj", ")", "]", "\n", "Dall", "=", "[", "T", ".", "cast", "(", "T", ".", "transpose", "(", "g", "[", ":", "s", "[", "0", "]", "/", "2", ",", "s", "[", "0", "]", "/", "2", ":", "]", ")", ",", "'complex64'", ")", "for", "s", ",", "g", "in", "zip", "(", "sizes_proj", ",", "gradients_proj", ")", "]", "\n", "# GX^H = CA^T + DB^T + jDA^T -jCB^T", "\n", "GXHall", "=", "[", "T", ".", "dot", "(", "C", ",", "T", ".", "transpose", "(", "A", ")", ")", "+", "T", ".", "dot", "(", "D", ",", "T", ".", "transpose", "(", "B", ")", ")", "+", "T", ".", "cast", "(", "1j", ",", "'complex64'", ")", "*", "T", ".", "dot", "(", "D", ",", "T", ".", "transpose", "(", "A", ")", ")", "-", "T", ".", "cast", "(", "1j", ",", "'complex64'", ")", "*", "T", ".", "dot", "(", "C", ",", "T", ".", "transpose", "(", "B", ")", ")", "for", "A", ",", "B", ",", "C", ",", "D", "in", "zip", "(", "Aall", ",", "Ball", ",", "Call", ",", "Dall", ")", "]", "\n", "Xall", "=", "[", "A", "+", "T", ".", "cast", "(", "1j", ",", "'complex64'", ")", "*", "B", "for", "A", ",", "B", "in", "zip", "(", "Aall", ",", "Ball", ")", "]", "\n", "## Gt = (GX^H - XG^H)X", "\n", "#Gtall = [T.dot(GXH - T.transpose(T.conj(GXH)),X) for GXH, X in zip(GXHall,Xall)]", "\n", "# compute Cayley transform, which is curve of steepest descent (see section 4 of [Tagare 2011])", "\n", "Wall", "=", "[", "GXH", "-", "T", ".", "transpose", "(", "T", ".", "conj", "(", "GXH", ")", ")", "for", "GXH", "in", "GXHall", "]", "\n", "Iall", "=", "[", "T", ".", "identity_like", "(", "W", ")", "for", "W", "in", "Wall", "]", "\n", "W2pall", "=", "[", "I", "+", "(", "learning_rate", "/", "T", ".", "cast", "(", "2", ",", "'complex64'", ")", ")", "*", "W", "for", "I", ",", "W", "in", "zip", "(", "Iall", ",", "Wall", ")", "]", "\n", "W2mall", "=", "[", "I", "-", "(", "learning_rate", "/", "T", ".", "cast", "(", "2", ",", "'complex64'", ")", ")", "*", "W", "for", "I", ",", "W", "in", "zip", "(", "Iall", ",", "Wall", ")", "]", "\n", "if", "(", "learning_rate", ">", "0.0", ")", ":", "\n", "            ", "Gtall", "=", "[", "T", ".", "dot", "(", "T", ".", "dot", "(", "T", ".", "nlinalg", ".", "matrix_inverse", "(", "W2p", ")", ",", "W2m", ")", ",", "X", ")", "for", "W2p", ",", "W2m", ",", "X", "in", "zip", "(", "W2pall", ",", "W2mall", ",", "Xall", ")", "]", "\n", "", "else", ":", "\n", "            ", "Gtall", "=", "[", "X", "for", "X", "in", "Xall", "]", "\n", "# perform transposes to prepare for converting back to transposed real-composite form", "\n", "", "GtallRe", "=", "[", "T", ".", "transpose", "(", "T", ".", "real", "(", "Gt", ")", ")", "for", "Gt", "in", "Gtall", "]", "\n", "GtallIm", "=", "[", "T", ".", "transpose", "(", "T", ".", "imag", "(", "Gt", ")", ")", "for", "Gt", "in", "Gtall", "]", "\n", "# convert back to real-composite form:", "\n", "gradients_tang", "=", "[", "T", ".", "concatenate", "(", "[", "T", ".", "concatenate", "(", "[", "GtRe", ",", "GtIm", "]", ",", "axis", "=", "1", ")", ",", "T", ".", "concatenate", "(", "[", "(", "-", "1", ")", "*", "GtIm", ",", "GtRe", "]", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "for", "GtRe", ",", "GtIm", "in", "zip", "(", "GtallRe", ",", "GtallIm", ")", "]", "\n", "\n", "", "new_rmsprop", "=", "[", "0.9", "*", "vel", "+", "0.1", "*", "(", "g", "**", "2", ")", "for", "vel", ",", "g", "in", "zip", "(", "rmsprop", ",", "gradients", ")", "]", "\n", "\n", "updates1", "=", "zip", "(", "rmsprop", ",", "new_rmsprop", ")", "\n", "updates2", "=", "[", "(", "p", ",", "p", "-", "learning_rate", "*", "g", "/", "T", ".", "sqrt", "(", "rms", ")", ")", "for", "\n", "p", ",", "g", ",", "rms", "in", "zip", "(", "parameters", ",", "gradients", ",", "new_rmsprop", ")", "]", "\n", "if", "idx_project", "is", "not", "None", ":", "\n", "# project back on to the Stiefel manifold using SVD", "\n", "# see 3.3 of [Absil and Malick 2012]", "\n", "        ", "def", "proj_stiefel", "(", "X", ")", ":", "\n", "# projects a square transposed real-composite form matrix X onto the Stiefel manifold", "\n", "            ", "n", "=", "X", ".", "shape", "[", "0", "]", "\n", "# X=A+jB", "\n", "A", "=", "T", ".", "transpose", "(", "X", "[", ":", "n", "/", "2", ",", ":", "n", "/", "2", "]", ")", "\n", "B", "=", "T", ".", "transpose", "(", "X", "[", ":", "n", "/", "2", ",", "n", "/", "2", ":", "]", ")", "\n", "U", ",", "S", ",", "V", "=", "T", ".", "nlinalg", ".", "svd", "(", "A", "+", "T", ".", "cast", "(", "1j", ",", "'complex64'", ")", "*", "B", ")", "\n", "W", "=", "T", ".", "dot", "(", "U", ",", "V", ")", "\n", "# convert back to transposed real-composite form", "\n", "WRe", "=", "T", ".", "transpose", "(", "T", ".", "real", "(", "W", ")", ")", "\n", "WIm", "=", "T", ".", "transpose", "(", "T", ".", "imag", "(", "W", ")", ")", "\n", "Wrc", "=", "T", ".", "concatenate", "(", "[", "T", ".", "concatenate", "(", "[", "WRe", ",", "WIm", "]", ",", "axis", "=", "0", ")", ",", "T", ".", "concatenate", "(", "[", "(", "-", "1", ")", "*", "WIm", ",", "WRe", "]", ",", "axis", "=", "0", ")", "]", ",", "axis", "=", "1", ")", "\n", "return", "Wrc", "\n", "\n", "", "new_rmsprop_proj", "=", "[", "new_rmsprop", "[", "i", "]", "for", "i", "in", "idx_project", "]", "\n", "#updates2_proj=[(p,proj_stiefel(p - learning_rate * g )) for", "\n", "#               p, g, rms in zip(parameters_proj,gradients_tang, new_rmsprop_proj)]", "\n", "updates2_proj", "=", "[", "(", "p", ",", "g", ")", "for", "\n", "p", ",", "g", ",", "rms", "in", "zip", "(", "parameters_proj", ",", "gradients_tang", ",", "new_rmsprop_proj", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "updates2_proj", ")", ")", ":", "\n", "            ", "updates2", "[", "idx_project", "[", "i", "]", "]", "=", "updates2_proj", "[", "i", "]", "\n", "\n", "", "", "updates", "=", "updates1", "+", "updates2", "\n", "\n", "return", "updates", ",", "rmsprop", "\n", "\n"]]}