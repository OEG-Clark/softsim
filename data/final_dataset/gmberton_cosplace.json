{"home.repos.pwc.inspect_result.gmberton_cosplace.None.cosface_loss.MarginCosineProduct.__init__": [[22, 30], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "s", "=", "30.0", ",", "m", "=", "0.40", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "s", "=", "s", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "", "def", "forward", "(", "self", ",", "input", ",", "label", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.cosface_loss.MarginCosineProduct.forward": [[30, 36], ["cosface_loss.cosine_sim", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "label.view"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.None.cosface_loss.cosine_sim"], ["", "def", "forward", "(", "self", ",", "input", ",", "label", ")", ":", "\n", "        ", "cosine", "=", "cosine_sim", "(", "input", ",", "self", ".", "weight", ")", "\n", "one_hot", "=", "torch", ".", "zeros_like", "(", "cosine", ")", "\n", "one_hot", ".", "scatter_", "(", "1", ",", "label", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1.0", ")", "\n", "output", "=", "self", ".", "s", "*", "(", "cosine", "-", "one_hot", "*", "self", ".", "m", ")", "\n", "return", "output", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.cosface_loss.MarginCosineProduct.__repr__": [[36, 42], ["str", "str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'('", "+", "'in_features='", "+", "str", "(", "self", ".", "in_features", ")", "+", "', out_features='", "+", "str", "(", "self", ".", "out_features", ")", "+", "', s='", "+", "str", "(", "self", ".", "s", ")", "+", "', m='", "+", "str", "(", "self", ".", "m", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.cosface_loss.cosine_sim": [[8, 13], ["torch.mm", "torch.mm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "x2.t", "torch.ger().clamp", "torch.ger().clamp", "torch.ger", "torch.ger"], "function", ["None"], ["def", "cosine_sim", "(", "x1", ",", "x2", ",", "dim", "=", "1", ",", "eps", "=", "1e-8", ")", ":", "\n", "    ", "ip", "=", "torch", ".", "mm", "(", "x1", ",", "x2", ".", "t", "(", ")", ")", "\n", "w1", "=", "torch", ".", "norm", "(", "x1", ",", "2", ",", "dim", ")", "\n", "w2", "=", "torch", ".", "norm", "(", "x2", ",", "2", ",", "dim", ")", "\n", "return", "ip", "/", "torch", ".", "ger", "(", "w1", ",", "w2", ")", ".", "clamp", "(", "min", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.InfiniteDataLoader.__init__": [[8, 11], ["super().__init__", "super().__iter__"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__", "home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.InfiniteDataLoader.__iter__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset_iterator", "=", "super", "(", ")", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.InfiniteDataLoader.__iter__": [[12, 14], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.InfiniteDataLoader.__next__": [[15, 22], ["next", "super().__iter__", "next"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.InfiniteDataLoader.__iter__"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "batch", "=", "next", "(", "self", ".", "dataset_iterator", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "self", ".", "dataset_iterator", "=", "super", "(", ")", ".", "__iter__", "(", ")", "\n", "batch", "=", "next", "(", "self", ".", "dataset_iterator", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.make_deterministic": [[24, 38], ["int", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "", "def", "make_deterministic", "(", "seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"Make results deterministic. If seed == -1, do not make deterministic.\n        Running your script in a deterministic way might slow it down.\n        Note that for some packages (eg: sklearn's PCA) this function is not enough.\n    \"\"\"", "\n", "seed", "=", "int", "(", "seed", ")", "\n", "if", "seed", "==", "-", "1", ":", "\n", "        ", "return", "\n", "", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.commons.setup_logging": [[40, 88], ["os.makedirs", "logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "os.path.exists", "FileExistsError", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.info", "logging.info", "logging.StreamHandler.setLevel", "logging.StreamHandler.setLevel", "traceback.format_exception"], "function", ["None"], ["", "def", "setup_logging", "(", "output_folder", ",", "exist_ok", "=", "False", ",", "console", "=", "\"debug\"", ",", "\n", "info_filename", "=", "\"info.log\"", ",", "debug_filename", "=", "\"debug.log\"", ")", ":", "\n", "    ", "\"\"\"Set up logging files and console output.\n    Creates one file for INFO logs and one for DEBUG logs.\n    Args:\n        output_folder (str): creates the folder where to save the files.\n        exist_ok (boolean): if False throw a FileExistsError if output_folder already exists\n        debug (str):\n            if == \"debug\" prints on console debug messages and higher\n            if == \"info\"  prints on console info messages and higher\n            if == None does not use console (useful when a logger has already been set)\n        info_filename (str): the name of the info file. if None, don't create info file\n        debug_filename (str): the name of the debug file. if None, don't create debug file\n    \"\"\"", "\n", "import", "os", "\n", "import", "sys", "\n", "import", "logging", "\n", "import", "traceback", "\n", "if", "not", "exist_ok", "and", "os", ".", "path", ".", "exists", "(", "output_folder", ")", ":", "\n", "        ", "raise", "FileExistsError", "(", "f\"{output_folder} already exists!\"", ")", "\n", "", "os", ".", "makedirs", "(", "output_folder", ",", "exist_ok", "=", "True", ")", "\n", "base_formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s   %(message)s'", ",", "\"%Y-%m-%d %H:%M:%S\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "''", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "if", "info_filename", "!=", "None", ":", "\n", "        ", "info_file_handler", "=", "logging", ".", "FileHandler", "(", "f'{output_folder}/{info_filename}'", ")", "\n", "info_file_handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "info_file_handler", ".", "setFormatter", "(", "base_formatter", ")", "\n", "logger", ".", "addHandler", "(", "info_file_handler", ")", "\n", "\n", "", "if", "debug_filename", "!=", "None", ":", "\n", "        ", "debug_file_handler", "=", "logging", ".", "FileHandler", "(", "f'{output_folder}/{debug_filename}'", ")", "\n", "debug_file_handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "debug_file_handler", ".", "setFormatter", "(", "base_formatter", ")", "\n", "logger", ".", "addHandler", "(", "debug_file_handler", ")", "\n", "\n", "", "if", "console", "!=", "None", ":", "\n", "        ", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "if", "console", "==", "\"debug\"", ":", "console_handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "if", "console", "==", "\"info\"", ":", "console_handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "console_handler", ".", "setFormatter", "(", "base_formatter", ")", "\n", "logger", ".", "addHandler", "(", "console_handler", ")", "\n", "\n", "", "def", "my_handler", "(", "type_", ",", "value", ",", "tb", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"\\n\"", "+", "\"\"", ".", "join", "(", "traceback", ".", "format_exception", "(", "type", ",", "value", ",", "tb", ")", ")", ")", "\n", "logging", ".", "info", "(", "\"Experiment finished (with some errors)\"", ")", "\n", "", "sys", ".", "excepthook", "=", "my_handler", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.parser.parse_arguments": [[6, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.path.exists", "FileNotFoundError", "os.path.join", "os.path.join", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "Exception"], "function", ["None"], ["def", "parse_arguments", "(", "is_training", "=", "True", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "# CosPlace Groups parameters", "\n", "parser", ".", "add_argument", "(", "\"--M\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--N\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--L\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--groups_num\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_images_per_class\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"_\"", ")", "\n", "# Model parameters", "\n", "parser", ".", "add_argument", "(", "\"--backbone\"", ",", "type", "=", "str", ",", "default", "=", "\"resnet18\"", ",", "\n", "choices", "=", "[", "\"vgg16\"", ",", "\"resnet18\"", ",", "\"resnet50\"", ",", "\"resnet101\"", ",", "\"resnet152\"", "]", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fc_output_dim\"", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "\"Output dimension of final fully connected layer\"", ")", "\n", "# Training parameters", "\n", "parser", ".", "add_argument", "(", "\"--use_amp16\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use Automatic Mixed Precision\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--augmentation_device\"", ",", "type", "=", "str", ",", "default", "=", "\"cuda\"", ",", "\n", "choices", "=", "[", "\"cuda\"", ",", "\"cpu\"", "]", ",", "\n", "help", "=", "\"on which device to run data augmentation\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs_num\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--iterations_per_epoch\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.00001", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifiers_lr\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "\"_\"", ")", "\n", "# Data augmentation", "\n", "parser", ".", "add_argument", "(", "\"--brightness\"", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--contrast\"", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--hue\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--saturation\"", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--random_resized_crop\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"_\"", ")", "\n", "# Validation / test parameters", "\n", "parser", ".", "add_argument", "(", "\"--infer_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "\"Batch size for inference (validating and testing)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--positive_dist_threshold\"", ",", "type", "=", "int", ",", "default", "=", "25", ",", "\n", "help", "=", "\"distance in meters for a prediction to be considered a positive\"", ")", "\n", "# Resume parameters", "\n", "parser", ".", "add_argument", "(", "\"--resume_train\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"path to checkpoint to resume, e.g. logs/.../last_checkpoint.pth\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_model\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"path to model to resume, e.g. logs/.../best_model.pth\"", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--device\"", ",", "type", "=", "str", ",", "default", "=", "\"cuda\"", ",", "\n", "choices", "=", "[", "\"cuda\"", ",", "\"cpu\"", "]", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"_\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"_\"", ")", "\n", "# Paths parameters", "\n", "parser", ".", "add_argument", "(", "\"--dataset_folder\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"path of the folder with train/val/test sets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "type", "=", "str", ",", "default", "=", "\"default\"", ",", "\n", "help", "=", "\"name of directory on which to save the logs, under logs/save_dir\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "dataset_folder", "==", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "args", ".", "dataset_folder", "=", "os", ".", "environ", "[", "'SF_XL_PROCESSED_FOLDER'", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "raise", "Exception", "(", "\"You should set parameter --dataset_folder or export \"", "+", "\n", "\"the SF_XL_PROCESSED_FOLDER environment variable as such \\n\"", "+", "\n", "\"export SF_XL_PROCESSED_FOLDER=/path/to/sf_xl/processed\"", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "dataset_folder", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"Folder {args.dataset_folder} does not exist\"", ")", "\n", "\n", "", "if", "is_training", ":", "\n", "        ", "args", ".", "train_set_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_folder", ",", "\"train\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "train_set_folder", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Folder {args.train_set_folder} does not exist\"", ")", "\n", "\n", "", "args", ".", "val_set_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_folder", ",", "\"val\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "val_set_folder", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Folder {args.val_set_folder} does not exist\"", ")", "\n", "\n", "", "", "args", ".", "test_set_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataset_folder", ",", "\"test\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "test_set_folder", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "f\"Folder {args.test_set_folder} does not exist\"", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.test.test": [[15, 63], ["model.eval.eval", "faiss.IndexFlatL2", "faiss.IndexFlatL2.add", "logging.debug", "faiss.IndexFlatL2.search", "eval_ds.get_positives", "numpy.zeros", "enumerate", "torch.no_grad", "logging.debug", "torch.utils.data.dataset.Subset", "torch.utils.data.DataLoader", "numpy.empty", "tqdm.tqdm", "logging.debug", "torch.utils.data.dataset.Subset", "torch.utils.data.DataLoader", "tqdm.tqdm", "max", "len", "enumerate", "list", "model.eval.", "descriptors.cpu().numpy.cpu().numpy", "list", "model.eval.", "descriptors.cpu().numpy.cpu().numpy", "numpy.any", "range", "len", "images.to", "range", "images.to", "numpy.in1d", "zip", "descriptors.cpu().numpy.cpu", "descriptors.cpu().numpy.cpu", "indices.numpy", "indices.numpy"], "function", ["home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.TestDataset.get_positives"], ["def", "test", "(", "args", ",", "eval_ds", ",", "model", ")", ":", "\n", "    ", "\"\"\"Compute descriptors of the given dataset and compute the recalls.\"\"\"", "\n", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "\"Extracting database descriptors for evaluation/testing\"", ")", "\n", "database_subset_ds", "=", "Subset", "(", "eval_ds", ",", "list", "(", "range", "(", "eval_ds", ".", "database_num", ")", ")", ")", "\n", "database_dataloader", "=", "DataLoader", "(", "dataset", "=", "database_subset_ds", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "batch_size", "=", "args", ".", "infer_batch_size", ",", "pin_memory", "=", "(", "args", ".", "device", "==", "\"cuda\"", ")", ")", "\n", "all_descriptors", "=", "np", ".", "empty", "(", "(", "len", "(", "eval_ds", ")", ",", "args", ".", "fc_output_dim", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "for", "images", ",", "indices", "in", "tqdm", "(", "database_dataloader", ",", "ncols", "=", "100", ")", ":", "\n", "            ", "descriptors", "=", "model", "(", "images", ".", "to", "(", "args", ".", "device", ")", ")", "\n", "descriptors", "=", "descriptors", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_descriptors", "[", "indices", ".", "numpy", "(", ")", ",", ":", "]", "=", "descriptors", "\n", "\n", "", "logging", ".", "debug", "(", "\"Extracting queries descriptors for evaluation/testing using batch size 1\"", ")", "\n", "queries_infer_batch_size", "=", "1", "\n", "queries_subset_ds", "=", "Subset", "(", "eval_ds", ",", "list", "(", "range", "(", "eval_ds", ".", "database_num", ",", "eval_ds", ".", "database_num", "+", "eval_ds", ".", "queries_num", ")", ")", ")", "\n", "queries_dataloader", "=", "DataLoader", "(", "dataset", "=", "queries_subset_ds", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "batch_size", "=", "queries_infer_batch_size", ",", "pin_memory", "=", "(", "args", ".", "device", "==", "\"cuda\"", ")", ")", "\n", "for", "images", ",", "indices", "in", "tqdm", "(", "queries_dataloader", ",", "ncols", "=", "100", ")", ":", "\n", "            ", "descriptors", "=", "model", "(", "images", ".", "to", "(", "args", ".", "device", ")", ")", "\n", "descriptors", "=", "descriptors", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_descriptors", "[", "indices", ".", "numpy", "(", ")", ",", ":", "]", "=", "descriptors", "\n", "\n", "", "", "queries_descriptors", "=", "all_descriptors", "[", "eval_ds", ".", "database_num", ":", "]", "\n", "database_descriptors", "=", "all_descriptors", "[", ":", "eval_ds", ".", "database_num", "]", "\n", "\n", "# Use a kNN to find predictions", "\n", "faiss_index", "=", "faiss", ".", "IndexFlatL2", "(", "args", ".", "fc_output_dim", ")", "\n", "faiss_index", ".", "add", "(", "database_descriptors", ")", "\n", "del", "database_descriptors", ",", "all_descriptors", "\n", "\n", "logging", ".", "debug", "(", "\"Calculating recalls\"", ")", "\n", "_", ",", "predictions", "=", "faiss_index", ".", "search", "(", "queries_descriptors", ",", "max", "(", "RECALL_VALUES", ")", ")", "\n", "\n", "#### For each query, check if the predictions are correct", "\n", "positives_per_query", "=", "eval_ds", ".", "get_positives", "(", ")", "\n", "recalls", "=", "np", ".", "zeros", "(", "len", "(", "RECALL_VALUES", ")", ")", "\n", "for", "query_index", ",", "preds", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "for", "i", ",", "n", "in", "enumerate", "(", "RECALL_VALUES", ")", ":", "\n", "            ", "if", "np", ".", "any", "(", "np", ".", "in1d", "(", "preds", "[", ":", "n", "]", ",", "positives_per_query", "[", "query_index", "]", ")", ")", ":", "\n", "                ", "recalls", "[", "i", ":", "]", "+=", "1", "\n", "break", "\n", "# Divide by queries_num and multiply by 100, so the recalls are in percentages", "\n", "", "", "", "recalls", "=", "recalls", "/", "eval_ds", ".", "queries_num", "*", "100", "\n", "recalls_str", "=", "\", \"", ".", "join", "(", "[", "f\"R@{val}: {rec:.1f}\"", "for", "val", ",", "rec", "in", "zip", "(", "RECALL_VALUES", ",", "recalls", ")", "]", ")", "\n", "return", "recalls", ",", "recalls_str", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.augmentations.DeviceAgnosticColorJitter.__init__": [[7, 10], ["torchvision.ColorJitter.__init__"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["    ", "def", "__init__", "(", "self", ",", "brightness", "=", "0", ",", "contrast", "=", "0", ",", "saturation", "=", "0", ",", "hue", "=", "0", ")", ":", "\n", "        ", "\"\"\"This is the same as T.ColorJitter but it only accepts batches of images and works on GPU\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "brightness", "=", "brightness", ",", "contrast", "=", "contrast", ",", "saturation", "=", "saturation", ",", "hue", "=", "hue", ")", "\n", "", "def", "forward", "(", "self", ",", "images", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.augmentations.DeviceAgnosticColorJitter.forward": [[10, 19], ["torch.cat", "len", "color_jitter().unsqueeze", "torch.Size", "color_jitter"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ")", ":", "\n", "        ", "assert", "len", "(", "images", ".", "shape", ")", "==", "4", ",", "f\"images should be a batch of images, but it has shape {images.shape}\"", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "images", ".", "shape", "\n", "# Applies a different color jitter to each image", "\n", "color_jitter", "=", "super", "(", "DeviceAgnosticColorJitter", ",", "self", ")", ".", "forward", "\n", "augmented_images", "=", "[", "color_jitter", "(", "img", ")", ".", "unsqueeze", "(", "0", ")", "for", "img", "in", "images", "]", "\n", "augmented_images", "=", "torch", ".", "cat", "(", "augmented_images", ")", "\n", "assert", "augmented_images", ".", "shape", "==", "torch", ".", "Size", "(", "[", "B", ",", "C", ",", "H", ",", "W", "]", ")", "\n", "return", "augmented_images", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.augmentations.DeviceAgnosticRandomResizedCrop.__init__": [[21, 24], ["torchvision.RandomResizedCrop.__init__"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "scale", ")", ":", "\n", "        ", "\"\"\"This is the same as T.RandomResizedCrop but it only accepts batches of images and works on GPU\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "size", "=", "size", ",", "scale", "=", "scale", ")", "\n", "", "def", "forward", "(", "self", ",", "images", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.augmentations.DeviceAgnosticRandomResizedCrop.forward": [[24, 32], ["torch.cat", "len", "random_resized_crop().unsqueeze", "random_resized_crop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ")", ":", "\n", "        ", "assert", "len", "(", "images", ".", "shape", ")", "==", "4", ",", "f\"images should be a batch of images, but it has shape {images.shape}\"", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "images", ".", "shape", "\n", "# Applies a different color jitter to each image", "\n", "random_resized_crop", "=", "super", "(", "DeviceAgnosticRandomResizedCrop", ",", "self", ")", ".", "forward", "\n", "augmented_images", "=", "[", "random_resized_crop", "(", "img", ")", ".", "unsqueeze", "(", "0", ")", "for", "img", "in", "images", "]", "\n", "augmented_images", "=", "torch", ".", "cat", "(", "augmented_images", ")", "\n", "return", "augmented_images", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.util.move_to_device": [[7, 12], ["optimizer.state.values", "state.items", "torch.is_tensor", "v.to"], "function", ["None"], ["def", "move_to_device", "(", "optimizer", ",", "device", ")", ":", "\n", "    ", "for", "state", "in", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                ", "state", "[", "k", "]", "=", "v", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.util.save_checkpoint": [[14, 20], ["torch.save", "torch.save"], "function", ["None"], ["", "", "", "", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "output_folder", ",", "ckpt_filename", "=", "\"last_checkpoint.pth\"", ")", ":", "\n", "# TODO it would be better to move weights to cpu before saving", "\n", "    ", "checkpoint_path", "=", "f\"{output_folder}/{ckpt_filename}\"", "\n", "torch", ".", "save", "(", "state", ",", "checkpoint_path", ")", "\n", "if", "is_best", ":", "\n", "        ", "torch", ".", "save", "(", "state", "[", "\"model_state_dict\"", "]", ",", "f\"{output_folder}/best_model.pth\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.None.util.resume_train": [[22, 53], ["logging.info", "torch.load", "model.to.load_state_dict", "model.to.to", "model_optimizer.load_state_dict", "zip", "zip", "shutil.copy", "len", "len", "len", "len", "c.cpu.to", "c.cpu.load_state_dict", "c.cpu.load_state_dict", "c.cpu.cpu", "args.resume_train.replace", "len", "len", "len", "len"], "function", ["None"], ["", "", "def", "resume_train", "(", "args", ",", "output_folder", ",", "model", ",", "model_optimizer", ",", "classifiers", ",", "classifiers_optimizers", ")", ":", "\n", "    ", "\"\"\"Load model, optimizer, and other training parameters\"\"\"", "\n", "logging", ".", "info", "(", "f\"Loading checkpoint: {args.resume_train}\"", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume_train", ")", "\n", "start_epoch_num", "=", "checkpoint", "[", "\"epoch_num\"", "]", "\n", "\n", "model_state_dict", "=", "checkpoint", "[", "\"model_state_dict\"", "]", "\n", "model", ".", "load_state_dict", "(", "model_state_dict", ")", "\n", "\n", "model", "=", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "model_optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state_dict\"", "]", ")", "\n", "\n", "assert", "args", ".", "groups_num", "==", "len", "(", "classifiers", ")", "==", "len", "(", "classifiers_optimizers", ")", "==", "len", "(", "checkpoint", "[", "\"classifiers_state_dict\"", "]", ")", "==", "len", "(", "checkpoint", "[", "\"optimizers_state_dict\"", "]", ")", ",", "f\"{args.groups_num} , {len(classifiers)} , {len(classifiers_optimizers)} , {len(checkpoint['classifiers_state_dict'])} , {len(checkpoint['optimizers_state_dict'])}\"", "\n", "\n", "for", "c", ",", "sd", "in", "zip", "(", "classifiers", ",", "checkpoint", "[", "\"classifiers_state_dict\"", "]", ")", ":", "\n", "# Move classifiers to GPU before loading their optimizers", "\n", "        ", "c", "=", "c", ".", "to", "(", "args", ".", "device", ")", "\n", "c", ".", "load_state_dict", "(", "sd", ")", "\n", "", "for", "c", ",", "sd", "in", "zip", "(", "classifiers_optimizers", ",", "checkpoint", "[", "\"optimizers_state_dict\"", "]", ")", ":", "\n", "        ", "c", ".", "load_state_dict", "(", "sd", ")", "\n", "", "for", "c", "in", "classifiers", ":", "\n", "# Move classifiers back to CPU to save some GPU memory", "\n", "        ", "c", "=", "c", ".", "cpu", "(", ")", "\n", "\n", "", "best_val_recall1", "=", "checkpoint", "[", "\"best_val_recall1\"", "]", "\n", "\n", "# Copy best model to current output_folder", "\n", "shutil", ".", "copy", "(", "args", ".", "resume_train", ".", "replace", "(", "\"last_checkpoint.pth\"", ",", "\"best_model.pth\"", ")", ",", "output_folder", ")", "\n", "\n", "return", "model", ",", "model_optimizer", ",", "classifiers", ",", "classifiers_optimizers", ",", "best_val_recall1", ",", "start_epoch_num", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.__init__": [[21, 69], ["super().__init__", "os.path.basename", "torch.load", "os.path.exists", "os.makedirs", "logging.info", "train_dataset.TrainDataset.initialize", "len", "ValueError", "torchvision.Compose", "logging.info", "torchvision.ColorJitter", "torchvision.RandomResizedCrop", "torchvision.Normalize", "len"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__", "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.initialize"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dataset_folder", ",", "M", "=", "10", ",", "alpha", "=", "30", ",", "N", "=", "5", ",", "L", "=", "2", ",", "\n", "current_group", "=", "0", ",", "min_images_per_class", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Parameters (please check our paper for a clearer explanation of the parameters).\n        ----------\n        args : args for data augmentation\n        dataset_folder : str, the path of the folder with the train images.\n        M : int, the length of the side of each cell in meters.\n        alpha : int, size of each class in degrees.\n        N : int, distance (M-wise) between two classes of the same group.\n        L : int, distance (alpha-wise) between two classes of the same group.\n        current_group : int, which one of the groups to consider.\n        min_images_per_class : int, minimum number of image in a class.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "M", "=", "M", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "N", "=", "N", "\n", "self", ".", "L", "=", "L", "\n", "self", ".", "current_group", "=", "current_group", "\n", "self", ".", "dataset_folder", "=", "dataset_folder", "\n", "self", ".", "augmentation_device", "=", "args", ".", "augmentation_device", "\n", "\n", "# dataset_name should be either \"processed\", \"small\" or \"raw\", if you're using SF-XL", "\n", "dataset_name", "=", "os", ".", "path", ".", "basename", "(", "args", ".", "dataset_folder", ")", "\n", "filename", "=", "f\"cache/{dataset_name}_M{M}_N{N}_mipc{min_images_per_class}.torch\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "\"cache\"", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "info", "(", "f\"Cached dataset {filename} does not exist, I'll create it now.\"", ")", "\n", "self", ".", "initialize", "(", "dataset_folder", ",", "M", ",", "N", ",", "alpha", ",", "L", ",", "min_images_per_class", ",", "filename", ")", "\n", "", "elif", "current_group", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Using cached dataset {filename}\"", ")", "\n", "\n", "", "classes_per_group", ",", "self", ".", "images_per_class", "=", "torch", ".", "load", "(", "filename", ")", "\n", "if", "current_group", ">=", "len", "(", "classes_per_group", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"With this configuration there are only {len(classes_per_group)} \"", "+", "\n", "f\"groups, therefore I can't create the {current_group}th group. \"", "+", "\n", "\"You should reduce the number of groups in --groups_num\"", ")", "\n", "", "self", ".", "classes_ids", "=", "classes_per_group", "[", "current_group", "]", "\n", "\n", "if", "self", ".", "augmentation_device", "==", "\"cpu\"", ":", "\n", "            ", "self", ".", "transform", "=", "T", ".", "Compose", "(", "[", "\n", "T", ".", "ColorJitter", "(", "brightness", "=", "args", ".", "brightness", ",", "\n", "contrast", "=", "args", ".", "contrast", ",", "\n", "saturation", "=", "args", ".", "saturation", ",", "\n", "hue", "=", "args", ".", "hue", ")", ",", "\n", "T", ".", "RandomResizedCrop", "(", "[", "512", ",", "512", "]", ",", "scale", "=", "[", "1", "-", "args", ".", "random_resized_crop", ",", "1", "]", ")", ",", "\n", "T", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.__getitem__": [[72, 94], ["random.choice", "torchvision.functional.to_tensor", "train_dataset.open_image", "torch.Size", "train_dataset.TrainDataset.transform", "logging.info"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.open_image"], ["", "", "def", "__getitem__", "(", "self", ",", "class_num", ")", ":", "\n", "# This function takes as input the class_num instead of the index of", "\n", "# the image. This way each class is equally represented during training.", "\n", "\n", "        ", "class_id", "=", "self", ".", "classes_ids", "[", "class_num", "]", "\n", "# Pick a random image among those in this class.", "\n", "image_path", "=", "random", ".", "choice", "(", "self", ".", "images_per_class", "[", "class_id", "]", ")", "\n", "\n", "try", ":", "\n", "            ", "pil_image", "=", "open_image", "(", "image_path", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "logging", ".", "info", "(", "f\"ERROR image {image_path} couldn't be opened, it might be corrupted.\"", ")", "\n", "raise", "e", "\n", "\n", "", "tensor_image", "=", "T", ".", "functional", ".", "to_tensor", "(", "pil_image", ")", "\n", "assert", "tensor_image", ".", "shape", "==", "torch", ".", "Size", "(", "[", "3", ",", "512", ",", "512", "]", ")", ",", "f\"Image {image_path} should have shape [3, 512, 512] but has {tensor_image.shape}.\"", "\n", "\n", "if", "self", ".", "augmentation_device", "==", "\"cpu\"", ":", "\n", "            ", "tensor_image", "=", "self", ".", "transform", "(", "tensor_image", ")", "\n", "\n", "", "return", "tensor_image", ",", "class_num", ",", "image_path", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.get_images_num": [[96, 99], ["sum", "len"], "methods", ["None"], ["", "def", "get_images_num", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the number of images within this group.\"\"\"", "\n", "return", "sum", "(", "[", "len", "(", "self", ".", "images_per_class", "[", "c", "]", ")", "for", "c", "in", "self", ".", "classes_ids", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.__len__": [[101, 104], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the number of classes within this group.\"\"\"", "\n", "return", "len", "(", "self", ".", "classes_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.initialize": [[106, 146], ["logging.debug", "sorted", "logging.debug", "logging.debug", "numpy.array().astype", "logging.debug", "logging.debug", "collections.defaultdict", "zip", "logging.debug", "collections.defaultdict", "torch.save", "glob.glob.glob", "p.split", "train_dataset.TrainDataset.get__class_id__group_id", "images_per_class[].append", "classes_per_group[].add", "list", "numpy.array", "collections.defaultdict.items", "collections.defaultdict.values", "len", "len"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.get__class_id__group_id"], ["", "@", "staticmethod", "\n", "def", "initialize", "(", "dataset_folder", ",", "M", ",", "N", ",", "alpha", ",", "L", ",", "min_images_per_class", ",", "filename", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "f\"Searching training images in {dataset_folder}\"", ")", "\n", "\n", "images_paths", "=", "sorted", "(", "glob", "(", "f\"{dataset_folder}/**/*.jpg\"", ",", "recursive", "=", "True", ")", ")", "\n", "logging", ".", "debug", "(", "f\"Found {len(images_paths)} images\"", ")", "\n", "\n", "logging", ".", "debug", "(", "\"For each image, get its UTM east, UTM north and heading from its path\"", ")", "\n", "images_metadatas", "=", "[", "p", ".", "split", "(", "\"@\"", ")", "for", "p", "in", "images_paths", "]", "\n", "# field 1 is UTM east, field 2 is UTM north, field 9 is heading", "\n", "utmeast_utmnorth_heading", "=", "[", "(", "m", "[", "1", "]", ",", "m", "[", "2", "]", ",", "m", "[", "9", "]", ")", "for", "m", "in", "images_metadatas", "]", "\n", "utmeast_utmnorth_heading", "=", "np", ".", "array", "(", "utmeast_utmnorth_heading", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "logging", ".", "debug", "(", "\"For each image, get class and group to which it belongs\"", ")", "\n", "class_id__group_id", "=", "[", "TrainDataset", ".", "get__class_id__group_id", "(", "*", "m", ",", "M", ",", "alpha", ",", "N", ",", "L", ")", "\n", "for", "m", "in", "utmeast_utmnorth_heading", "]", "\n", "\n", "logging", ".", "debug", "(", "\"Group together images belonging to the same class\"", ")", "\n", "images_per_class", "=", "defaultdict", "(", "list", ")", "\n", "for", "image_path", ",", "(", "class_id", ",", "_", ")", "in", "zip", "(", "images_paths", ",", "class_id__group_id", ")", ":", "\n", "            ", "images_per_class", "[", "class_id", "]", ".", "append", "(", "image_path", ")", "\n", "\n", "# Images_per_class is a dict where the key is class_id, and the value", "\n", "# is a list with the paths of images within that class.", "\n", "", "images_per_class", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "images_per_class", ".", "items", "(", ")", "if", "len", "(", "v", ")", ">=", "min_images_per_class", "}", "\n", "\n", "logging", ".", "debug", "(", "\"Group together classes belonging to the same group\"", ")", "\n", "# Classes_per_group is a dict where the key is group_id, and the value", "\n", "# is a list with the class_ids belonging to that group.", "\n", "classes_per_group", "=", "defaultdict", "(", "set", ")", "\n", "for", "class_id", ",", "group_id", "in", "class_id__group_id", ":", "\n", "            ", "if", "class_id", "not", "in", "images_per_class", ":", "\n", "                ", "continue", "# Skip classes with too few images", "\n", "", "classes_per_group", "[", "group_id", "]", ".", "add", "(", "class_id", ")", "\n", "\n", "# Convert classes_per_group to a list of lists.", "\n", "# Each sublist represents the classes within a group.", "\n", "", "classes_per_group", "=", "[", "list", "(", "c", ")", "for", "c", "in", "classes_per_group", ".", "values", "(", ")", "]", "\n", "\n", "torch", ".", "save", "(", "(", "classes_per_group", ",", "images_per_class", ")", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.TrainDataset.get__class_id__group_id": [[148, 166], ["int", "int", "int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get__class_id__group_id", "(", "utm_east", ",", "utm_north", ",", "heading", ",", "M", ",", "alpha", ",", "N", ",", "L", ")", ":", "\n", "        ", "\"\"\"Return class_id and group_id for a given point.\n            The class_id is a triplet (tuple) of UTM_east, UTM_north and\n            heading (e.g. (396520, 4983800,120)).\n            The group_id represents the group to which the class belongs\n            (e.g. (0, 1, 0)), and it is between (0, 0, 0) and (N, N, L).\n        \"\"\"", "\n", "rounded_utm_east", "=", "int", "(", "utm_east", "//", "M", "*", "M", ")", "# Rounded to nearest lower multiple of M", "\n", "rounded_utm_north", "=", "int", "(", "utm_north", "//", "M", "*", "M", ")", "\n", "rounded_heading", "=", "int", "(", "heading", "//", "alpha", "*", "alpha", ")", "\n", "\n", "class_id", "=", "(", "rounded_utm_east", ",", "rounded_utm_north", ",", "rounded_heading", ")", "\n", "# group_id goes from (0, 0, 0) to (N, N, L)", "\n", "group_id", "=", "(", "rounded_utm_east", "%", "(", "M", "*", "N", ")", "//", "M", ",", "\n", "rounded_utm_north", "%", "(", "M", "*", "N", ")", "//", "M", ",", "\n", "rounded_heading", "%", "(", "alpha", "*", "L", ")", "//", "alpha", ")", "\n", "return", "class_id", ",", "group_id", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.train_dataset.open_image": [[16, 18], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["def", "open_image", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.TestDataset.__init__": [[16, 66], ["torch.Dataset.__init__", "os.path.join", "os.path.join", "os.path.basename", "torchvision.Compose", "sorted", "sorted", "numpy.array().astype", "numpy.array().astype", "sklearn.neighbors.NearestNeighbors", "sklearn.neighbors.NearestNeighbors.fit", "sklearn.neighbors.NearestNeighbors.radius_neighbors", "len", "len", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "glob.glob.glob", "glob.glob.glob", "torchvision.ToTensor", "torchvision.Normalize", "os.path.join", "os.path.join", "numpy.array", "numpy.array", "path.split", "path.split", "path.split", "path.split"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset_folder", ",", "database_folder", "=", "\"database\"", ",", "\n", "queries_folder", "=", "\"queries\"", ",", "positive_dist_threshold", "=", "25", ")", ":", "\n", "        ", "\"\"\"Dataset with images from database and queries, used for validation and test.\n        Parameters\n        ----------\n        dataset_folder : str, should contain the path to the val or test set,\n            which contains the folders {database_folder} and {queries_folder}.\n        database_folder : str, name of folder with the database.\n        queries_folder : str, name of folder with the queries.\n        positive_dist_threshold : int, distance in meters for a prediction to\n            be considered a positive.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset_folder", "=", "dataset_folder", "\n", "self", ".", "database_folder", "=", "os", ".", "path", ".", "join", "(", "dataset_folder", ",", "database_folder", ")", "\n", "self", ".", "queries_folder", "=", "os", ".", "path", ".", "join", "(", "dataset_folder", ",", "queries_folder", ")", "\n", "self", ".", "dataset_name", "=", "os", ".", "path", ".", "basename", "(", "dataset_folder", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "dataset_folder", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Folder {self.dataset_folder} does not exist\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "database_folder", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Folder {self.database_folder} does not exist\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "queries_folder", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Folder {self.queries_folder} does not exist\"", ")", "\n", "\n", "", "self", ".", "base_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "\n", "#### Read paths and UTM coordinates for all images.", "\n", "self", ".", "database_paths", "=", "sorted", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "database_folder", ",", "\"**\"", ",", "\"*.jpg\"", ")", ",", "recursive", "=", "True", ")", ")", "\n", "self", ".", "queries_paths", "=", "sorted", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "queries_folder", ",", "\"**\"", ",", "\"*.jpg\"", ")", ",", "recursive", "=", "True", ")", ")", "\n", "\n", "# The format must be path/to/file/@utm_easting@utm_northing@...@.jpg", "\n", "self", ".", "database_utms", "=", "np", ".", "array", "(", "[", "(", "path", ".", "split", "(", "\"@\"", ")", "[", "1", "]", ",", "path", ".", "split", "(", "\"@\"", ")", "[", "2", "]", ")", "for", "path", "in", "self", ".", "database_paths", "]", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "self", ".", "queries_utms", "=", "np", ".", "array", "(", "[", "(", "path", ".", "split", "(", "\"@\"", ")", "[", "1", "]", ",", "path", ".", "split", "(", "\"@\"", ")", "[", "2", "]", ")", "for", "path", "in", "self", ".", "queries_paths", "]", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "# Find positives_per_query, which are within positive_dist_threshold (default 25 meters)", "\n", "knn", "=", "NearestNeighbors", "(", "n_jobs", "=", "-", "1", ")", "\n", "knn", ".", "fit", "(", "self", ".", "database_utms", ")", "\n", "self", ".", "positives_per_query", "=", "knn", ".", "radius_neighbors", "(", "self", ".", "queries_utms", ",", "\n", "radius", "=", "positive_dist_threshold", ",", "\n", "return_distance", "=", "False", ")", "\n", "\n", "self", ".", "images_paths", "=", "[", "p", "for", "p", "in", "self", ".", "database_paths", "]", "\n", "self", ".", "images_paths", "+=", "[", "p", "for", "p", "in", "self", ".", "queries_paths", "]", "\n", "\n", "self", ".", "database_num", "=", "len", "(", "self", ".", "database_paths", ")", "\n", "self", ".", "queries_num", "=", "len", "(", "self", ".", "queries_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.TestDataset.__getitem__": [[67, 72], ["test_dataset.open_image", "test_dataset.TestDataset.base_transform"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.open_image"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_path", "=", "self", ".", "images_paths", "[", "index", "]", "\n", "pil_img", "=", "open_image", "(", "image_path", ")", "\n", "normalized_img", "=", "self", ".", "base_transform", "(", "pil_img", ")", "\n", "return", "normalized_img", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.TestDataset.__len__": [[73, 75], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.TestDataset.__repr__": [[76, 78], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "f\"< {self.dataset_name} - #q: {self.queries_num}; #db: {self.database_num} >\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.TestDataset.get_positives": [[79, 81], ["None"], "methods", ["None"], ["", "def", "get_positives", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "positives_per_query", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.datasets.test_dataset.open_image": [[11, 13], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["def", "open_image", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.network.GeoLocalizationNet.__init__": [[20, 29], ["torch.nn.Module.__init__", "network.get_backbone", "torch.nn.Sequential", "model.layers.L2Norm", "model.layers.GeM", "model.layers.Flatten", "torch.nn.Linear", "model.layers.L2Norm"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__", "home.repos.pwc.inspect_result.gmberton_cosplace.model.network.get_backbone"], ["    ", "def", "__init__", "(", "self", ",", "backbone", ",", "fc_output_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", ",", "features_dim", "=", "get_backbone", "(", "backbone", ")", "\n", "self", ".", "aggregation", "=", "nn", ".", "Sequential", "(", "\n", "L2Norm", "(", ")", ",", "\n", "GeM", "(", ")", ",", "\n", "Flatten", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "features_dim", ",", "fc_output_dim", ")", ",", "\n", "L2Norm", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.network.GeoLocalizationNet.forward": [[31, 35], ["network.GeoLocalizationNet.backbone", "network.GeoLocalizationNet.aggregation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "x", "=", "self", ".", "aggregation", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.network.get_backbone": [[37, 68], ["backbone_name.startswith", "torch.nn.Sequential", "torchvision.models.resnet152.named_children", "logging.debug", "torchvision.models.resnet18", "child.parameters", "list", "torchvision.models.vgg16", "logging.debug", "torchvision.models.resnet50", "torchvision.models.resnet152.children", "list", "l.parameters", "torchvision.models.resnet101", "torchvision.models.resnet152.features.children", "torchvision.models.resnet152"], "function", ["None"], ["", "", "def", "get_backbone", "(", "backbone_name", ")", ":", "\n", "    ", "if", "backbone_name", ".", "startswith", "(", "\"resnet\"", ")", ":", "\n", "        ", "if", "backbone_name", "==", "\"resnet18\"", ":", "\n", "            ", "backbone", "=", "torchvision", ".", "models", ".", "resnet18", "(", "pretrained", "=", "True", ")", "\n", "", "elif", "backbone_name", "==", "\"resnet50\"", ":", "\n", "            ", "backbone", "=", "torchvision", ".", "models", ".", "resnet50", "(", "pretrained", "=", "True", ")", "\n", "", "elif", "backbone_name", "==", "\"resnet101\"", ":", "\n", "            ", "backbone", "=", "torchvision", ".", "models", ".", "resnet101", "(", "pretrained", "=", "True", ")", "\n", "", "elif", "backbone_name", "==", "\"resnet152\"", ":", "\n", "            ", "backbone", "=", "torchvision", ".", "models", ".", "resnet152", "(", "pretrained", "=", "True", ")", "\n", "\n", "", "for", "name", ",", "child", "in", "backbone", ".", "named_children", "(", ")", ":", "\n", "            ", "if", "name", "==", "\"layer3\"", ":", "# Freeze layers before conv_3", "\n", "                ", "break", "\n", "", "for", "params", "in", "child", ".", "parameters", "(", ")", ":", "\n", "                ", "params", ".", "requires_grad", "=", "False", "\n", "", "", "logging", ".", "debug", "(", "f\"Train only layer3 and layer4 of the {backbone_name}, freeze the previous ones\"", ")", "\n", "layers", "=", "list", "(", "backbone", ".", "children", "(", ")", ")", "[", ":", "-", "2", "]", "# Remove avg pooling and FC layer", "\n", "\n", "", "elif", "backbone_name", "==", "\"vgg16\"", ":", "\n", "        ", "backbone", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "layers", "=", "list", "(", "backbone", ".", "features", ".", "children", "(", ")", ")", "[", ":", "-", "2", "]", "# Remove avg pooling and FC layer", "\n", "for", "l", "in", "layers", "[", ":", "-", "5", "]", ":", "\n", "            ", "for", "p", "in", "l", ".", "parameters", "(", ")", ":", "p", ".", "requires_grad", "=", "False", "\n", "", "logging", ".", "debug", "(", "\"Train last layers of the VGG-16, freeze the previous ones\"", ")", "\n", "\n", "", "backbone", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "features_dim", "=", "CHANNELS_NUM_IN_LAST_CONV", "[", "backbone_name", "]", "\n", "\n", "return", "backbone", ",", "features_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.GeM.__init__": [[13, 17], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["    ", "def", "__init__", "(", "self", ",", "p", "=", "3", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", "*", "p", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.GeM.forward": [[17, 19], ["layers.gem"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.gem"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "gem", "(", "x", ",", "p", "=", "self", ".", "p", ",", "eps", "=", "self", ".", "eps", ")", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.GeM.__repr__": [[19, 21], ["str", "layers.GeM.p.data.tolist"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'('", "+", "'p='", "+", "'{:.4f}'", ".", "format", "(", "self", ".", "p", ".", "data", ".", "tolist", "(", ")", "[", "0", "]", ")", "+", "', '", "+", "'eps='", "+", "str", "(", "self", ".", "eps", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.Flatten.__init__": [[24, 26], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.Flatten.forward": [[26, 29], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "shape", "[", "2", "]", "==", "x", ".", "shape", "[", "3", "]", "==", "1", ",", "f\"{x.shape[2]} != {x.shape[3]} != 1\"", "\n", "return", "x", "[", ":", ",", ":", ",", "0", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__": [[32, 35], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.L2Norm.forward": [[35, 37], ["torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.gmberton_cosplace.model.layers.gem": [[8, 10], ["torch.avg_pool2d().pow", "torch.avg_pool2d", "x.clamp().pow", "x.size", "x.size", "x.clamp"], "function", ["None"], ["def", "gem", "(", "x", ",", "p", "=", "3", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "return", "F", ".", "avg_pool2d", "(", "x", ".", "clamp", "(", "min", "=", "eps", ")", ".", "pow", "(", "p", ")", ",", "(", "x", ".", "size", "(", "-", "2", ")", ",", "x", ".", "size", "(", "-", "1", ")", ")", ")", ".", "pow", "(", "1.", "/", "p", ")", "\n", "\n"]]}