{"home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.None.test_convetional_models.main": [[22, 56], ["parser.parse_args", "build_model", "build_model.fit", "AveragePrecisionMeter", "AveragePrecisionMeter.add", "print", "print", "AveragePrecisionMeter.overall", "print", "print", "MultiSceneClean_sklearn", "MultiSceneClean_sklearn", "MultiScene_sklearn", "MultiScene_sklearn", "build_model.predict", "AveragePrecisionMeter.value", "AveragePrecisionMeter.value().mean", "AveragePrecisionMeter.value"], "function", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.model_bank.build_model", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.overall", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean_sklearn", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean_sklearn", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene_sklearn", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene_sklearn", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# define dataset", "\n", "if", "args", ".", "dataset", "==", "'multiscene-clean'", ":", "\n", "        ", "x_tra", ",", "y_tra", "=", "MultiSceneClean_sklearn", "(", "'Tra'", ")", "\n", "x_test", ",", "y_test", "=", "MultiSceneClean_sklearn", "(", "'Test'", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'multiscene'", ":", "\n", "        ", "x_tra", ",", "y_tra", "=", "MultiScene_sklearn", "(", "'Tra'", ")", "\n", "x_test", ",", "y_test", "=", "MultiScene_sklearn", "(", "'Test'", ")", "\n", "\n", "# load model, loss is defined inside", "\n", "", "model", "=", "build_model", "(", "args", ")", "\n", "model", ".", "fit", "(", "x_tra", ",", "y_tra", ")", "\n", "\n", "y_pred", "=", "model", ".", "predict", "(", "x_test", ")", "*", "2", "-", "1", "\n", "meter", "=", "AveragePrecisionMeter", "(", "False", ")", "\n", "meter", ".", "add", "(", "y_pred", ",", "y_test", ")", "\n", "print", "(", "'per-class AP:'", ",", "meter", ".", "value", "(", ")", "*", "100", ")", "\n", "print", "(", "'mAP:'", ",", "meter", ".", "value", "(", ")", ".", "mean", "(", ")", "*", "100", ")", "\n", "OP", ",", "OR", ",", "OF1", ",", "CP", ",", "CR", ",", "CF1", ",", "EP", ",", "ER", ",", "EF1", "=", "meter", ".", "overall", "(", ")", "\n", "print", "(", "'CP | CR | CF1 | EP | ER | EF1 | OP | OR | OF1\\n'", "\n", "'---------------------------------------------\\n'", "\n", "'{CP:.1f}\\t'", "\n", "'{CR:.1f}\\t'", "\n", "'{CF1:.1f}\\t'", "\n", "'{EP:.1f}\\t'", "\n", "'{ER:.1f}\\t'", "\n", "'{EF1:.1f}\\t'", "\n", "'{OP:.1f}\\t'", "\n", "'{OR:.1f}\\t'", "\n", "'{OF1:.1f}'", ".", "format", "(", "CP", "=", "CP", "*", "100", ",", "CR", "=", "CR", "*", "100", ",", "CF1", "=", "CF1", "*", "100", ",", "EP", "=", "EP", "*", "100", ",", "ER", "=", "ER", "*", "100", ",", "EF1", "=", "EF1", "*", "100", ",", "OP", "=", "OP", "*", "100", ",", "OR", "=", "OR", "*", "100", ",", "OF1", "=", "OF1", "*", "100", ")", ")", "\n", "print", "(", "'==========================================================\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.None.main.main": [[31, 70], ["parser.parse_args", "build_model", "nn.MultiLabelSoftMarginLoss", "torch.optim.SGD", "MultiLabelMAPEngine", "MultiLabelMAPEngine.learning", "MultiSceneClean", "MultiSceneClean", "build_model.get_config_optim", "os.path.join", "torch.cuda.is_available", "MultiScene", "MultiScene"], "function", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.model_bank.build_model", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.learning", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.get_config_optim"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# define dataset", "\n", "if", "args", ".", "dataset", "==", "'multiscene-clean'", ":", "\n", "        ", "train_dataset", "=", "MultiSceneClean", "(", "'Tra'", ")", "\n", "#val_dataset = MultiSceneClean('Val') # split from Tra.csv", "\n", "test_dataset", "=", "MultiSceneClean", "(", "'Test'", ")", "\n", "", "elif", "args", ".", "dataset", "==", "'multiscene'", ":", "\n", "        ", "train_dataset", "=", "MultiScene", "(", "'Tra'", ")", "\n", "#val_dataset = MultiScene('Val') # split from Tra.csv", "\n", "test_dataset", "=", "MultiScene", "(", "'Test'", ")", "\n", "\n", "# load model", "\n", "", "model", "=", "build_model", "(", "args", ")", "\n", "\n", "# define loss function (criterion)", "\n", "criterion", "=", "nn", ".", "MultiLabelSoftMarginLoss", "(", ")", "\n", "\n", "# define optimizer", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "get_config_optim", "(", "args", ".", "lr", ",", "args", ".", "lrp", ")", ",", "lr", "=", "args", ".", "lr", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-4", ")", "\n", "\n", "state", "=", "{", "'save_model_path'", ":", "os", ".", "path", ".", "join", "(", "'weights'", ",", "args", ".", "dataset", ",", "args", ".", "model_name", ")", ",", "\n", "'batch_size'", ":", "args", ".", "batch_size", ",", "\n", "'image_size'", ":", "args", ".", "image_size", ",", "\n", "'max_epochs'", ":", "args", ".", "epochs", ",", "\n", "'evaluate'", ":", "args", ".", "evaluate", ",", "\n", "'resume'", ":", "args", ".", "weight_path", ",", "\n", "'num_classes'", ":", "args", ".", "nb_classes", ",", "\n", "'workers'", ":", "args", ".", "workers", ",", "\n", "'epoch_step'", ":", "100", ",", "\n", "'lr'", ":", "args", ".", "lr", ",", "\n", "'use_gpu'", ":", "torch", ".", "cuda", ".", "is_available", "(", ")", "}", "\n", "\n", "state", "[", "'print_freq'", "]", "=", "0", "\n", "state", "[", "'print_epoch'", "]", "=", "30", "\n", "engine", "=", "MultiLabelMAPEngine", "(", "state", ")", "\n", "engine", ".", "learning", "(", "model", ",", "criterion", ",", "train_dataset", ",", "test_dataset", ",", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene.__init__": [[33, 45], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "multiscene.read_object_labels_csv", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv"], ["    ", "def", "__init__", "(", "self", ",", "set", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "path_dataset", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'MultiScene'", ")", "\n", "self", ".", "set", "=", "set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "# define filename of csv file", "\n", "file_csv", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_dataset", ",", "set", "+", "'.csv'", ")", "\n", "self", ".", "labels", "=", "read_object_labels_csv", "(", "file_csv", ")", "\n", "\n", "print", "(", "'[dataset] MultiScene classification set=%s number of classes=%d  number of images=%d'", "%", "(", "\n", "set", ",", "len", "(", "SCENE_CATEGORY", ")", ",", "len", "(", "self", ".", "labels", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene.__getitem__": [[46, 55], ["PIL.Image.open().convert", "multiscene.MultiScene.transform", "multiscene.MultiScene.target_transform", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "labels", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_dataset", ",", "'images'", ",", "path", "+", "'.jpg'", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "(", "img", ",", "path", ")", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene.__len__": [[56, 58], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene.get_number_classes": [[59, 61], ["len"], "methods", ["None"], ["", "def", "get_number_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "SCENE_CATEGORY", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.read_object_labels_csv": [[13, 31], ["len", "print", "open", "csv.reader", "numpy.asarray().astype", "torch.from_numpy", "torch.from_numpy", "labels.append", "numpy.asarray"], "function", ["None"], ["def", "read_object_labels_csv", "(", "filename", ",", "only_gt", "=", "False", ",", "header", "=", "True", ")", ":", "\n", "    ", "labels", "=", "[", "]", "\n", "num_categories", "=", "len", "(", "SCENE_CATEGORY", ")", "\n", "print", "(", "'[dataset] read'", ",", "filename", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "rownum", "=", "0", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "header", "and", "rownum", "==", "0", ":", "\n", "                ", "header", "=", "row", "\n", "", "else", ":", "\n", "                ", "name", "=", "row", "[", "0", "]", "\n", "gt", "=", "(", "np", ".", "asarray", "(", "row", "[", "1", ":", "num_categories", "+", "1", "]", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "gt", "=", "torch", ".", "from_numpy", "(", "gt", ")", "\n", "item", "=", "(", "name", ",", "gt", ")", "if", "not", "only_gt", "else", "gt", "\n", "labels", ".", "append", "(", "item", ")", "\n", "", "rownum", "+=", "1", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene.MultiScene_sklearn": [[67, 94], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.stack().numpy", "torch.stack().numpy", "os.path.isfile", "os.path.isfile", "multiscene.read_object_labels_csv", "numpy.zeros", "range", "numpy.array", "numpy.save", "print", "print", "numpy.load", "print", "len", "print", "numpy.uint8", "skimage.feature.hog", "numpy.uint8", "numpy.histogram", "numpy.concatenate", "torch.stack", "torch.stack", "len", "PIL.Image.open().convert", "PIL.Image.open().convert", "skimage.feature.local_binary_pattern", "multiscene.read_object_labels_csv", "len", "len", "len", "len", "PIL.Image.open", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv"], ["def", "MultiScene_sklearn", "(", "set", ")", ":", "\n", "    ", "path_dataset", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'MultiScene'", ")", "\n", "path_feat", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'MultiScene'", ",", "'feat'", "+", "set", "+", "'.npy'", ")", "\n", "file_csv", "=", "os", ".", "path", ".", "join", "(", "path_dataset", ",", "set", "+", "'.csv'", ")", "\n", "y", "=", "torch", ".", "stack", "(", "read_object_labels_csv", "(", "file_csv", ",", "True", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path_feat", ")", ":", "\n", "        ", "print", "(", "'.npy files already exist.'", ")", "\n", "x", "=", "np", ".", "load", "(", "path_feat", ")", "\n", "print", "(", "'[dataset] MultiScene classification set=%s number of classes=%d  number of images=%d'", "%", "(", "set", ",", "len", "(", "SCENE_CATEGORY", ")", ",", "len", "(", "y", ")", ")", ")", "\n", "return", "x", ",", "y", "\n", "\n", "", "labels", "=", "read_object_labels_csv", "(", "file_csv", ")", "\n", "feat", "=", "np", ".", "zeros", "(", "(", "len", "(", "labels", ")", ",", "2048", "+", "128", ")", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "print", "(", "index", ")", "\n", "path", ",", "target", "=", "labels", "[", "index", "]", "\n", "img", "=", "np", ".", "uint8", "(", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "path_dataset", ",", "'images'", ",", "path", "+", "'.jpg'", ")", ")", ".", "convert", "(", "'RGB'", ")", ")", "\n", "feat_hog32", "=", "hog", "(", "img", ",", "orientations", "=", "8", ",", "pixels_per_cell", "=", "(", "32", ",", "32", ")", ",", "cells_per_block", "=", "(", "1", ",", "1", ")", ",", "block_norm", "=", "'L2'", ")", "\n", "img_gray", "=", "np", ".", "uint8", "(", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "path_dataset", ",", "'images'", ",", "path", "+", "'.jpg'", ")", ")", ".", "convert", "(", "'L'", ")", ")", "\n", "feat_lbp16", ",", "_", "=", "np", ".", "histogram", "(", "local_binary_pattern", "(", "img_gray", ",", "16", "*", "8", ",", "16", ",", "'uniform'", ")", ",", "density", "=", "True", ",", "bins", "=", "128", ",", "range", "=", "(", "0", ",", "128", ")", ")", "\n", "feat", "[", "index", ",", ":", "]", "=", "np", ".", "concatenate", "(", "[", "feat_hog32", ",", "feat_lbp16", "]", ")", "\n", "\n", "", "feat", "=", "np", ".", "array", "(", "feat", ")", "\n", "np", ".", "save", "(", "path_feat", ",", "feat", ")", "\n", "print", "(", "'[dataset] MultiScene classification set=%s number of classes=%d  number of images=%d'", "%", "(", "set", ",", "len", "(", "SCENE_CATEGORY", ")", ",", "len", "(", "y", ")", ")", ")", "\n", "return", "feat", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.__init__": [[25, 67], ["torchnet.meter.AverageValueMeter", "torchnet.meter.AverageValueMeter", "torchnet.meter.AverageValueMeter", "engine.Engine._state", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state", "engine.Engine._state"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state"], ["    ", "def", "__init__", "(", "self", ",", "state", "=", "{", "}", ")", ":", "\n", "        ", "self", ".", "state", "=", "state", "\n", "if", "self", ".", "_state", "(", "'use_gpu'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'use_gpu'", "]", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "", "if", "self", ".", "_state", "(", "'image_size'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'image_size'", "]", "=", "224", "\n", "\n", "", "if", "self", ".", "_state", "(", "'batch_size'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'batch_size'", "]", "=", "32", "\n", "\n", "", "if", "self", ".", "_state", "(", "'workers'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'workers'", "]", "=", "25", "\n", "\n", "", "if", "self", ".", "_state", "(", "'device_ids'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'device_ids'", "]", "=", "None", "\n", "\n", "", "if", "self", ".", "_state", "(", "'evaluate'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'evaluate'", "]", "=", "False", "\n", "\n", "", "if", "self", ".", "_state", "(", "'start_epoch'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'start_epoch'", "]", "=", "0", "\n", "\n", "", "if", "self", ".", "_state", "(", "'max_epochs'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'max_epochs'", "]", "=", "90", "\n", "\n", "", "if", "self", ".", "_state", "(", "'epoch_step'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'epoch_step'", "]", "=", "[", "]", "\n", "\n", "", "if", "self", ".", "_state", "(", "'print_epoch'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'print_epoch'", "]", "=", "20", "\n", "\n", "# meters", "\n", "", "self", ".", "state", "[", "'meter_loss'", "]", "=", "tnt", ".", "meter", ".", "AverageValueMeter", "(", ")", "\n", "# time measure", "\n", "self", ".", "state", "[", "'batch_time'", "]", "=", "tnt", ".", "meter", ".", "AverageValueMeter", "(", ")", "\n", "self", ".", "state", "[", "'data_time'", "]", "=", "tnt", ".", "meter", ".", "AverageValueMeter", "(", ")", "\n", "# display parameters", "\n", "if", "self", ".", "_state", "(", "'use_pb'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'use_pb'", "]", "=", "True", "\n", "", "if", "self", ".", "_state", "(", "'print_freq'", ")", "is", "None", ":", "\n", "            ", "self", ".", "state", "[", "'print_freq'", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state": [[68, 71], ["None"], "methods", ["None"], ["", "", "def", "_state", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "in", "self", ".", "state", ":", "\n", "            ", "return", "self", ".", "state", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_start_epoch": [[72, 76], ["engine.Engine.state[].reset", "engine.Engine.state[].reset", "engine.Engine.state[].reset"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.reset", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.reset", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.reset"], ["", "", "def", "on_start_epoch", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "        ", "self", ".", "state", "[", "'meter_loss'", "]", ".", "reset", "(", ")", "\n", "self", ".", "state", "[", "'batch_time'", "]", ".", "reset", "(", ")", "\n", "self", ".", "state", "[", "'data_time'", "]", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_end_epoch": [[77, 86], ["engine.Engine.state[].value", "print", "print"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value"], ["", "def", "on_end_epoch", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "        ", "loss", "=", "self", ".", "state", "[", "'meter_loss'", "]", ".", "value", "(", ")", "[", "0", "]", "\n", "if", "display", ":", "\n", "            ", "if", "training", ":", "\n", "                ", "print", "(", "'Epoch: [{0}]\\t'", "\n", "'Loss {loss:.4f}'", ".", "format", "(", "self", ".", "state", "[", "'epoch'", "]", ",", "loss", "=", "loss", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Test: \\t Loss {loss:.4f}'", ".", "format", "(", "loss", "=", "loss", ")", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_start_batch": [[87, 89], ["None"], "methods", ["None"], ["", "def", "on_start_batch", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_end_batch": [[90, 117], ["engine.Engine.state[].item", "engine.Engine.state[].add", "engine.Engine.state[].value", "engine.Engine.state[].value", "engine.Engine.state[].value", "print", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value"], ["", "def", "on_end_batch", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "\n", "# record loss", "\n", "        ", "self", ".", "state", "[", "'loss_batch'", "]", "=", "self", ".", "state", "[", "'loss'", "]", ".", "item", "(", ")", "\n", "self", ".", "state", "[", "'meter_loss'", "]", ".", "add", "(", "self", ".", "state", "[", "'loss_batch'", "]", ")", "\n", "\n", "if", "display", "and", "self", ".", "state", "[", "'print_freq'", "]", "!=", "0", "and", "self", ".", "state", "[", "'iteration'", "]", "%", "self", ".", "state", "[", "'print_freq'", "]", "==", "0", ":", "\n", "            ", "loss", "=", "self", ".", "state", "[", "'meter_loss'", "]", ".", "value", "(", ")", "[", "0", "]", "\n", "batch_time", "=", "self", ".", "state", "[", "'batch_time'", "]", ".", "value", "(", ")", "[", "0", "]", "\n", "data_time", "=", "self", ".", "state", "[", "'data_time'", "]", ".", "value", "(", ")", "[", "0", "]", "\n", "if", "training", ":", "\n", "                ", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'Time {batch_time_current:.3f} ({batch_time:.3f})\\t'", "\n", "'Data {data_time_current:.3f} ({data_time:.3f})\\t'", "\n", "'Loss {loss_current:.4f} ({loss:.4f})'", ".", "format", "(", "\n", "self", ".", "state", "[", "'epoch'", "]", ",", "self", ".", "state", "[", "'iteration'", "]", ",", "len", "(", "data_loader", ")", ",", "\n", "batch_time_current", "=", "self", ".", "state", "[", "'batch_time_current'", "]", ",", "\n", "batch_time", "=", "batch_time", ",", "data_time_current", "=", "self", ".", "state", "[", "'data_time_batch'", "]", ",", "\n", "data_time", "=", "data_time", ",", "loss_current", "=", "self", ".", "state", "[", "'loss_batch'", "]", ",", "loss", "=", "loss", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Test: [{0}/{1}]\\t'", "\n", "'Time {batch_time_current:.3f} ({batch_time:.3f})\\t'", "\n", "'Data {data_time_current:.3f} ({data_time:.3f})\\t'", "\n", "'Loss {loss_current:.4f} ({loss:.4f})'", ".", "format", "(", "\n", "self", ".", "state", "[", "'iteration'", "]", ",", "len", "(", "data_loader", ")", ",", "batch_time_current", "=", "self", ".", "state", "[", "'batch_time_current'", "]", ",", "\n", "batch_time", "=", "batch_time", ",", "data_time_current", "=", "self", ".", "state", "[", "'data_time_batch'", "]", ",", "\n", "data_time", "=", "data_time", ",", "loss_current", "=", "self", ".", "state", "[", "'loss_batch'", "]", ",", "loss", "=", "loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_forward": [[118, 135], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "model", "criterion", "optimizer.zero_grad", "engine.Engine.state[].backward", "optimizer.step"], "methods", ["None"], ["", "", "", "def", "on_forward", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "\n", "        ", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "self", ".", "state", "[", "'input'", "]", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "self", ".", "state", "[", "'target'", "]", ")", "\n", "\n", "if", "not", "training", ":", "\n", "            ", "input_var", ".", "volatile", "=", "True", "\n", "target_var", ".", "volatile", "=", "True", "\n", "\n", "# compute output", "\n", "", "self", ".", "state", "[", "'output'", "]", "=", "model", "(", "input_var", ")", "\n", "self", ".", "state", "[", "'loss'", "]", "=", "criterion", "(", "self", ".", "state", "[", "'output'", "]", ",", "target_var", ")", "\n", "\n", "if", "training", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "state", "[", "'loss'", "]", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.init_learning": [[136, 158], ["engine.Engine._state", "torchvision.Normalize", "torchvision.Compose", "engine.Engine._state", "torchvision.Normalize", "torchvision.Compose", "torchvision.Resize", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.Resize", "torchvision.ToTensor"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state"], ["", "", "def", "init_learning", "(", "self", ",", "model", ",", "criterion", ")", ":", "\n", "\n", "        ", "if", "self", ".", "_state", "(", "'train_transform'", ")", "is", "None", ":", "\n", "            ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "model", ".", "image_normalization_mean", ",", "\n", "std", "=", "model", ".", "image_normalization_std", ")", "\n", "self", ".", "state", "[", "'train_transform'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "state", "[", "'image_size'", "]", ",", "self", ".", "state", "[", "'image_size'", "]", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "\n", "", "if", "self", ".", "_state", "(", "'val_transform'", ")", "is", "None", ":", "\n", "            ", "normalize", "=", "transforms", ".", "Normalize", "(", "mean", "=", "model", ".", "image_normalization_mean", ",", "\n", "std", "=", "model", ".", "image_normalization_std", ")", "\n", "self", ".", "state", "[", "'val_transform'", "]", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "state", "[", "'image_size'", "]", ",", "self", ".", "state", "[", "'image_size'", "]", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "\n", "", "self", ".", "state", "[", "'best_score'", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.learning": [[159, 223], ["engine.Engine.init_learning", "engine.Engine._state", "engine.Engine._state", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "range", "engine.Engine._state", "os.path.isfile", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "criterion.cuda.cuda.cuda", "engine.Engine.validate", "engine.Engine.adjust_learning_rate", "print", "engine.Engine.train", "max", "engine.Engine.save_checkpoint", "print", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.nn.DataParallel().cuda.load_state_dict", "torch.nn.DataParallel().cuda.load_state_dict", "torch.nn.DataParallel().cuda.load_state_dict", "torch.nn.DataParallel().cuda.load_state_dict", "torch.nn.DataParallel().cuda.load_state_dict", "print", "print", "engine.Engine.validate", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "engine.Engine._state", "torch.nn.DataParallel().cuda.module.state_dict", "torch.nn.DataParallel().cuda.module.state_dict", "torch.nn.DataParallel().cuda.module.state_dict", "torch.nn.DataParallel().cuda.module.state_dict", "torch.nn.DataParallel().cuda.module.state_dict", "torch.nn.DataParallel().cuda.state_dict", "torch.nn.DataParallel().cuda.state_dict", "torch.nn.DataParallel().cuda.state_dict", "torch.nn.DataParallel().cuda.state_dict", "torch.nn.DataParallel().cuda.state_dict"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.init_learning", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.validate", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.adjust_learning_rate", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.train", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.save_checkpoint", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.validate", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state"], ["", "def", "learning", "(", "self", ",", "model", ",", "criterion", ",", "train_dataset", ",", "val_dataset", ",", "optimizer", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "init_learning", "(", "model", ",", "criterion", ")", "\n", "\n", "# define train and val transform", "\n", "train_dataset", ".", "transform", "=", "self", ".", "state", "[", "'train_transform'", "]", "\n", "train_dataset", ".", "target_transform", "=", "self", ".", "_state", "(", "'train_target_transform'", ")", "\n", "val_dataset", ".", "transform", "=", "self", ".", "state", "[", "'val_transform'", "]", "\n", "val_dataset", ".", "target_transform", "=", "self", ".", "_state", "(", "'val_target_transform'", ")", "\n", "# data loading code", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "\n", "batch_size", "=", "self", ".", "state", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "state", "[", "'workers'", "]", ")", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "\n", "batch_size", "=", "self", ".", "state", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "state", "[", "'workers'", "]", ")", "\n", "# optionally resume from a checkpoint", "\n", "if", "self", ".", "_state", "(", "'resume'", ")", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "self", ".", "state", "[", "'resume'", "]", ")", ":", "\n", "                ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "self", ".", "state", "[", "'resume'", "]", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "self", ".", "state", "[", "'resume'", "]", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "print", "(", "\"=> loaded checkpoint '{}' \"", "\n", ".", "format", "(", "self", ".", "state", "[", "'evaluate'", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "self", ".", "state", "[", "'resume'", "]", ")", ")", "\n", "\n", "\n", "", "", "if", "self", ".", "state", "[", "'use_gpu'", "]", ":", "\n", "            ", "train_loader", ".", "pin_memory", "=", "True", "\n", "val_loader", ".", "pin_memory", "=", "True", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "self", ".", "state", "[", "'device_ids'", "]", ")", ".", "cuda", "(", ")", "\n", "criterion", "=", "criterion", ".", "cuda", "(", ")", "\n", "\n", "", "if", "self", ".", "state", "[", "'evaluate'", "]", ":", "\n", "            ", "self", ".", "validate", "(", "val_loader", ",", "model", ",", "criterion", ")", "\n", "return", "\n", "\n", "", "print", "(", "'start training'", ")", "\n", "# TODO define optimizer", "\n", "prec1", "=", "0", "\n", "for", "epoch", "in", "range", "(", "self", ".", "state", "[", "'start_epoch'", "]", ",", "self", ".", "state", "[", "'max_epochs'", "]", ")", ":", "\n", "            ", "self", ".", "state", "[", "'epoch'", "]", "=", "epoch", "\n", "lr", "=", "self", ".", "adjust_learning_rate", "(", "optimizer", ")", "\n", "print", "(", "'lr:'", ",", "lr", ")", "\n", "\n", "# train for one epoch", "\n", "self", ".", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ")", "\n", "# evaluate on validation set", "\n", "if", "epoch", "%", "self", ".", "state", "[", "'print_epoch'", "]", "==", "0", ":", "\n", "                ", "prec1", "=", "self", ".", "validate", "(", "val_loader", ",", "model", ",", "criterion", ")", "\n", "\n", "# remember best prec@1 and save checkpoint", "\n", "", "is_best", "=", "prec1", ">", "self", ".", "state", "[", "'best_score'", "]", "\n", "self", ".", "state", "[", "'best_score'", "]", "=", "max", "(", "prec1", ",", "self", ".", "state", "[", "'best_score'", "]", ")", "\n", "self", ".", "save_checkpoint", "(", "{", "\n", "'arch'", ":", "self", ".", "_state", "(", "'arch'", ")", ",", "\n", "'state_dict'", ":", "model", ".", "module", ".", "state_dict", "(", ")", "if", "self", ".", "state", "[", "'use_gpu'", "]", "else", "model", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "is_best", ")", "\n", "\n", "print", "(", "' *** best={best:.3f}'", ".", "format", "(", "best", "=", "self", ".", "state", "[", "'best_score'", "]", ")", ")", "\n", "", "return", "self", ".", "state", "[", "'best_score'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.train": [[224, 258], ["model.train", "engine.Engine.on_start_epoch", "time.time", "time.time", "time.time", "time.time", "enumerate", "engine.Engine.on_end_epoch", "tqdm", "engine.Engine.state[].add", "engine.Engine.on_start_batch", "engine.Engine.on_forward", "engine.Engine.state[].add", "time.time", "time.time", "time.time", "time.time", "engine.Engine.on_end_batch", "time.time", "time.time", "time.time", "time.time", "engine.Engine.state[].cuda", "time.time", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.train", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_start_epoch", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_end_epoch", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.MultiLabelMAPEngine.on_start_batch", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.MultiLabelMAPEngine.on_forward", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_end_batch"], ["", "def", "train", "(", "self", ",", "data_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ")", ":", "\n", "\n", "# switch to train mode", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "on_start_epoch", "(", "True", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", ")", "\n", "\n", "if", "self", ".", "state", "[", "'use_pb'", "]", ":", "\n", "            ", "data_loader", "=", "tqdm", "(", "data_loader", ",", "desc", "=", "'Training'", ")", "\n", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "# measure data loading time", "\n", "            ", "self", ".", "state", "[", "'iteration'", "]", "=", "i", "\n", "self", ".", "state", "[", "'data_time_batch'", "]", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "self", ".", "state", "[", "'data_time'", "]", ".", "add", "(", "self", ".", "state", "[", "'data_time_batch'", "]", ")", "\n", "self", ".", "state", "[", "'input'", "]", "=", "input", "\n", "self", ".", "state", "[", "'target'", "]", "=", "target", "\n", "\n", "self", ".", "on_start_batch", "(", "True", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", ")", "\n", "\n", "if", "self", ".", "state", "[", "'use_gpu'", "]", ":", "\n", "                ", "self", ".", "state", "[", "'target'", "]", "=", "self", ".", "state", "[", "'target'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "", "self", ".", "on_forward", "(", "True", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", ")", "\n", "\n", "# measure elapsed time", "\n", "self", ".", "state", "[", "'batch_time_current'", "]", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "self", ".", "state", "[", "'batch_time'", "]", ".", "add", "(", "self", ".", "state", "[", "'batch_time_current'", "]", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "# measure accuracy", "\n", "self", ".", "on_end_batch", "(", "True", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", ")", "\n", "\n", "", "self", ".", "on_end_epoch", "(", "True", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.validate": [[259, 296], ["model.eval", "print", "engine.Engine.on_start_epoch", "time.time", "time.time", "time.time", "time.time", "enumerate", "engine.Engine.on_end_epoch", "tqdm", "engine.Engine.state[].add", "engine.Engine.on_start_batch", "engine.Engine.on_forward", "engine.Engine.state[].add", "time.time", "time.time", "time.time", "time.time", "engine.Engine.on_end_batch", "time.time", "time.time", "time.time", "time.time", "engine.Engine.state[].cuda", "time.time", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_start_epoch", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_end_epoch", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.MultiLabelMAPEngine.on_start_batch", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.MultiLabelMAPEngine.on_forward", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.on_end_batch"], ["", "def", "validate", "(", "self", ",", "data_loader", ",", "model", ",", "criterion", ")", ":", "\n", "\n", "# switch to evaluate mode", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "print", "(", "'model is evaluate mode!'", ")", "\n", "self", ".", "on_start_epoch", "(", "False", ",", "model", ",", "criterion", ",", "data_loader", ")", "\n", "\n", "if", "self", ".", "state", "[", "'use_pb'", "]", ":", "\n", "            ", "data_loader", "=", "tqdm", "(", "data_loader", ",", "desc", "=", "'Test'", ")", "\n", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "# measure data loading time", "\n", "            ", "self", ".", "state", "[", "'iteration'", "]", "=", "i", "\n", "self", ".", "state", "[", "'data_time_batch'", "]", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "self", ".", "state", "[", "'data_time'", "]", ".", "add", "(", "self", ".", "state", "[", "'data_time_batch'", "]", ")", "\n", "\n", "self", ".", "state", "[", "'input'", "]", "=", "input", "\n", "self", ".", "state", "[", "'target'", "]", "=", "target", "\n", "\n", "self", ".", "on_start_batch", "(", "False", ",", "model", ",", "criterion", ",", "data_loader", ")", "\n", "\n", "if", "self", ".", "state", "[", "'use_gpu'", "]", ":", "\n", "                ", "self", ".", "state", "[", "'target'", "]", "=", "self", ".", "state", "[", "'target'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "", "self", ".", "on_forward", "(", "False", ",", "model", ",", "criterion", ",", "data_loader", ")", "\n", "\n", "# measure elapsed time", "\n", "self", ".", "state", "[", "'batch_time_current'", "]", "=", "time", ".", "time", "(", ")", "-", "end", "\n", "self", ".", "state", "[", "'batch_time'", "]", ".", "add", "(", "self", ".", "state", "[", "'batch_time_current'", "]", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "# measure accuracy", "\n", "self", ".", "on_end_batch", "(", "False", ",", "model", ",", "criterion", ",", "data_loader", ")", "\n", "\n", "", "score", "=", "self", ".", "on_end_epoch", "(", "False", ",", "model", ",", "criterion", ",", "data_loader", ")", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.save_checkpoint": [[297, 316], ["print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "engine.Engine._state", "os.path.join", "shutil.copyfile", "os.path.exists", "os.makedirs", "engine.Engine._state", "os.path.join", "engine.Engine._state", "os.path.join", "shutil.copyfile", "engine.Engine._state", "os.remove", "engine.Engine._state"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine._state"], ["", "def", "save_checkpoint", "(", "self", ",", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "        ", "if", "self", ".", "_state", "(", "'save_model_path'", ")", "is", "not", "None", ":", "\n", "            ", "filename_", "=", "filename", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "state", "[", "'save_model_path'", "]", ",", "filename_", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "state", "[", "'save_model_path'", "]", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "state", "[", "'save_model_path'", "]", ")", "\n", "", "", "print", "(", "'save model {filename}'", ".", "format", "(", "filename", "=", "filename", ")", ")", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "            ", "filename_best", "=", "'model_best.pth.tar'", "\n", "if", "self", ".", "_state", "(", "'save_model_path'", ")", "is", "not", "None", ":", "\n", "                ", "filename_best", "=", "os", ".", "path", ".", "join", "(", "self", ".", "state", "[", "'save_model_path'", "]", ",", "filename_best", ")", "\n", "", "shutil", ".", "copyfile", "(", "filename", ",", "filename_best", ")", "\n", "if", "self", ".", "_state", "(", "'save_model_path'", ")", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "_state", "(", "'filename_previous_best'", ")", "is", "not", "None", ":", "\n", "                    ", "os", ".", "remove", "(", "self", ".", "_state", "(", "'filename_previous_best'", ")", ")", "\n", "", "filename_best", "=", "os", ".", "path", ".", "join", "(", "self", ".", "state", "[", "'save_model_path'", "]", ",", "'model_best_{score:.4f}.pth.tar'", ".", "format", "(", "score", "=", "self", ".", "state", "[", "'best_score'", "]", ")", ")", "\n", "shutil", ".", "copyfile", "(", "filename", ",", "filename_best", ")", "\n", "self", ".", "state", "[", "'filename_previous_best'", "]", "=", "filename_best", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.Engine.adjust_learning_rate": [[317, 325], ["np.unique", "lr_list.append", "np.mod", "np.array"], "methods", ["None"], ["", "", "", "def", "adjust_learning_rate", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "lr_list", "=", "[", "]", "\n", "decay", "=", "0.1", "if", "np", ".", "mod", "(", "(", "self", ".", "state", "[", "'epoch'", "]", "+", "1", ")", ",", "np", ".", "array", "(", "self", ".", "state", "[", "'epoch_step'", "]", ")", ")", "==", "0", "else", "1.0", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "*", "decay", "\n", "lr_list", ".", "append", "(", "param_group", "[", "'lr'", "]", ")", "\n", "", "return", "np", ".", "unique", "(", "lr_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.MultiLabelMAPEngine.on_forward": [[407, 422], ["torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "torch.autograd.Variable().float", "model", "criterion", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "optimizer.zero_grad", "engine.MultiLabelMAPEngine.state[].backward", "optimizer.step", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["None"], ["    ", "def", "on_forward", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "        ", "feature_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "self", ".", "state", "[", "'feature'", "]", ")", ".", "float", "(", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "self", ".", "state", "[", "'target'", "]", ")", ".", "float", "(", ")", "\n", "\n", "if", "not", "training", ":", "\n", "            ", "torch", ".", "no_grad", "(", ")", "\n", "\n", "# compute output", "\n", "", "self", ".", "state", "[", "'output'", "]", "=", "model", "(", "feature_var", ")", "\n", "self", ".", "state", "[", "'loss'", "]", "=", "criterion", "(", "self", ".", "state", "[", "'output'", "]", ",", "target_var", ")", "\n", "\n", "if", "training", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "state", "[", "'loss'", "]", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.engine.MultiLabelMAPEngine.on_start_batch": [[424, 431], ["engine.MultiLabelMAPEngine.state[].clone"], "methods", ["None"], ["", "", "def", "on_start_batch", "(", "self", ",", "training", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", "=", "None", ",", "display", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "state", "[", "'target_gt'", "]", "=", "self", ".", "state", "[", "'target'", "]", ".", "clone", "(", ")", "\n", "\n", "input", "=", "self", ".", "state", "[", "'input'", "]", "\n", "self", ".", "state", "[", "'feature'", "]", "=", "input", "[", "0", "]", "\n", "self", ".", "state", "[", "'out'", "]", "=", "input", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.__init__": [[17, 20], ["object.__init__", "metrics.AveragePrecisionMeter.reset"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "AveragePrecisionMeter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.reset": [[21, 25], ["torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatStorage", "torch.FloatStorage", "torch.FloatStorage", "torch.FloatStorage", "torch.LongStorage", "torch.LongStorage", "torch.LongStorage", "torch.LongStorage"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the meter with empty member variables\"\"\"", "\n", "self", ".", "scores", "=", "torch", ".", "FloatTensor", "(", "torch", ".", "FloatStorage", "(", ")", ")", "\n", "self", ".", "targets", "=", "torch", ".", "LongTensor", "(", "torch", ".", "LongStorage", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.add": [[26, 69], ["metrics.AveragePrecisionMeter.scores.resize_", "metrics.AveragePrecisionMeter.targets.resize_", "metrics.AveragePrecisionMeter.scores.narrow().copy_", "metrics.AveragePrecisionMeter.targets.narrow().copy_", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "output.view.view.dim", "output.view.view.view", "target.view.view.dim", "target.view.view.view", "metrics.AveragePrecisionMeter.scores.numel", "metrics.AveragePrecisionMeter.scores.storage().size", "math.ceil", "metrics.AveragePrecisionMeter.scores.storage().resize_", "metrics.AveragePrecisionMeter.targets.storage().resize_", "metrics.AveragePrecisionMeter.scores.size", "output.view.view.size", "target.view.view.size", "output.view.view.dim", "target.view.view.dim", "target.view.view.size", "metrics.AveragePrecisionMeter.targets.size", "metrics.AveragePrecisionMeter.scores.numel", "output.view.view.numel", "int", "int", "metrics.AveragePrecisionMeter.scores.dim", "output.view.view.size", "target.view.view.size", "metrics.AveragePrecisionMeter.scores.narrow", "metrics.AveragePrecisionMeter.targets.narrow", "metrics.AveragePrecisionMeter.scores.storage", "metrics.AveragePrecisionMeter.scores.storage().size", "metrics.AveragePrecisionMeter.scores.storage", "metrics.AveragePrecisionMeter.targets.storage", "output.view.view.size", "target.view.view.size", "output.view.view.numel", "output.view.view.numel", "metrics.AveragePrecisionMeter.scores.storage"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        concatenate samples of the new batch and previous batches\n        Args:\n            output: predicted multiple labels, should be an NxK tensor, postive/negative means presence/absence\n            target: ground truth multiple labels, should be an NxK binary tensors, each is multi-hot\n        Notes:\n            N: the number of samples\n            K: the number of classes\n        \"\"\"", "\n", "if", "not", "torch", ".", "is_tensor", "(", "output", ")", ":", "\n", "            ", "output", "=", "torch", ".", "from_numpy", "(", "output", ")", "\n", "", "if", "not", "torch", ".", "is_tensor", "(", "target", ")", ":", "\n", "            ", "target", "=", "torch", ".", "from_numpy", "(", "target", ")", "\n", "\n", "", "if", "output", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "output", "=", "output", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "assert", "output", ".", "dim", "(", ")", "==", "2", ",", "'wrong output size (should be 1D or 2D with one column \\\n                per class)'", "\n", "", "if", "target", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "target", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "assert", "target", ".", "dim", "(", ")", "==", "2", ",", "'wrong target size (should be 1D or 2D with one column \\\n                per class)'", "\n", "", "if", "self", ".", "scores", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "assert", "target", ".", "size", "(", "1", ")", "==", "self", ".", "targets", ".", "size", "(", "1", ")", ",", "'dimensions for output should match previously added examples.'", "\n", "\n", "# make sure storage is of sufficient size", "\n", "", "if", "self", ".", "scores", ".", "storage", "(", ")", ".", "size", "(", ")", "<", "self", ".", "scores", ".", "numel", "(", ")", "+", "output", ".", "numel", "(", ")", ":", "\n", "            ", "new_size", "=", "math", ".", "ceil", "(", "self", ".", "scores", ".", "storage", "(", ")", ".", "size", "(", ")", "*", "1.5", ")", "\n", "self", ".", "scores", ".", "storage", "(", ")", ".", "resize_", "(", "int", "(", "new_size", "+", "output", ".", "numel", "(", ")", ")", ")", "\n", "self", ".", "targets", ".", "storage", "(", ")", ".", "resize_", "(", "int", "(", "new_size", "+", "output", ".", "numel", "(", ")", ")", ")", "\n", "\n", "# store scores and targets", "\n", "", "offset", "=", "self", ".", "scores", ".", "size", "(", "0", ")", "if", "self", ".", "scores", ".", "dim", "(", ")", ">", "0", "else", "0", "\n", "self", ".", "scores", ".", "resize_", "(", "offset", "+", "output", ".", "size", "(", "0", ")", ",", "output", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "targets", ".", "resize_", "(", "offset", "+", "target", ".", "size", "(", "0", ")", ",", "target", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "scores", ".", "narrow", "(", "0", ",", "offset", ",", "output", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "output", ")", "\n", "self", ".", "targets", ".", "narrow", "(", "0", ",", "offset", ",", "target", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.value": [[70, 90], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "range", "metrics.AveragePrecisionMeter.scores.numel", "metrics.AveragePrecisionMeter.scores_nonzero.size", "metrics.AveragePrecisionMeter.scores_nonzero.size", "metrics.AveragePrecisionMeter.average_precision", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "metrics.AveragePrecisionMeter.scores_nonzero.size", "metrics.AveragePrecisionMeter.targets.sum", "metrics.AveragePrecisionMeter.targets.sum"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.average_precision"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the model's average precision for each class\n        Return:\n            ap (FloatTensor): 1xK tensor, with avg precision for each class k\n        \"\"\"", "\n", "\n", "if", "self", ".", "scores", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "self", ".", "scores_nonzero", "=", "self", ".", "scores", "[", ":", ",", "self", ".", "targets", ".", "sum", "(", "axis", "=", "0", ")", ">", "0", "]", "\n", "self", ".", "targets_nonzero", "=", "self", ".", "targets", "[", ":", ",", "self", ".", "targets", ".", "sum", "(", "axis", "=", "0", ")", ">", "0", "]", "\n", "ap", "=", "torch", ".", "zeros", "(", "self", ".", "scores_nonzero", ".", "size", "(", "1", ")", ")", "\n", "rg", "=", "torch", ".", "arange", "(", "1", ",", "self", ".", "scores_nonzero", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "# compute average precision for each class", "\n", "for", "k", "in", "range", "(", "self", ".", "scores_nonzero", ".", "size", "(", "1", ")", ")", ":", "\n", "# sort scores", "\n", "            ", "scores", "=", "self", ".", "scores_nonzero", "[", ":", ",", "k", "]", "\n", "targets", "=", "self", ".", "targets_nonzero", "[", ":", ",", "k", "]", "\n", "# compute average precision", "\n", "ap", "[", "k", "]", "=", "AveragePrecisionMeter", ".", "average_precision", "(", "scores", ",", "targets", ")", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.average_precision": [[91, 112], ["torch.sort", "torch.sort", "torch.sort", "torch.sort"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "average_precision", "(", "output", ",", "target", ")", ":", "\n", "# sort examples", "\n", "        ", "sorted", ",", "indices", "=", "torch", ".", "sort", "(", "output", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "\n", "# Computes prec@i", "\n", "pos_count", "=", "0.", "\n", "total_count", "=", "0.", "\n", "precision_at_i", "=", "0.", "\n", "for", "i", "in", "indices", ":", "\n", "            ", "label", "=", "target", "[", "i", "]", "\n", "if", "label", "==", "1", ":", "\n", "                ", "pos_count", "+=", "1", "\n", "", "total_count", "+=", "1", "\n", "if", "label", "==", "1", ":", "\n", "                ", "precision_at_i", "+=", "pos_count", "/", "total_count", "\n", "", "", "if", "pos_count", "==", "0", ":", "\n", "            ", "precision_at_i", "=", "0", "\n", "", "else", ":", "\n", "            ", "precision_at_i", "/=", "pos_count", "\n", "", "return", "precision_at_i", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.overall": [[113, 120], ["metrics.AveragePrecisionMeter.scores.cpu().numpy", "metrics.AveragePrecisionMeter.targets.cpu().numpy", "metrics.AveragePrecisionMeter.evaluation", "metrics.AveragePrecisionMeter.scores.numel", "metrics.AveragePrecisionMeter.scores.cpu", "metrics.AveragePrecisionMeter.targets.cpu"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.evaluation"], ["", "def", "overall", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "scores", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "scores", "=", "self", ".", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "targets", "=", "self", ".", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "targets", "[", "targets", "==", "-", "1", "]", "=", "0", "\n", "return", "self", ".", "evaluation", "(", "scores", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.overall_topk": [[121, 132], ["metrics.AveragePrecisionMeter.targets.cpu().numpy", "metrics.AveragePrecisionMeter.scores.size", "[].cpu().numpy", "metrics.AveragePrecisionMeter.scores.cpu().numpy", "range", "metrics.AveragePrecisionMeter.evaluation", "numpy.zeros", "metrics.AveragePrecisionMeter.targets.cpu", "[].cpu", "metrics.AveragePrecisionMeter.scores.cpu", "metrics.AveragePrecisionMeter.scores.topk"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.evaluation"], ["", "def", "overall_topk", "(", "self", ",", "k", ")", ":", "\n", "        ", "targets", "=", "self", ".", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "targets", "[", "targets", "==", "-", "1", "]", "=", "0", "\n", "n", ",", "c", "=", "self", ".", "scores", ".", "size", "(", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "(", "n", ",", "c", ")", ")", "-", "1", "\n", "index", "=", "self", ".", "scores", ".", "topk", "(", "k", ",", "1", ",", "True", ",", "True", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tmp", "=", "self", ".", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "for", "ind", "in", "index", "[", "i", "]", ":", "\n", "                ", "scores", "[", "i", ",", "ind", "]", "=", "1", "if", "tmp", "[", "i", ",", "ind", "]", ">=", "0", "else", "-", "1", "\n", "", "", "return", "self", ".", "evaluation", "(", "scores", ",", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.metrics.AveragePrecisionMeter.evaluation": [[133, 183], ["range", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.int8", "numpy.int8", "numpy.float32", "numpy.float32", "numpy.float32", "numpy.float32", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.round", "numpy.round", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.exp"], "methods", ["None"], ["", "def", "evaluation", "(", "self", ",", "scores_", ",", "targets_", ")", ":", "\n", "        ", "\"\"\"Returns the model's OP, OR, OF1, CP, CR, CF1, EP, ER, EF1\n            Return:\n            OP, OR, OF1, CP, CR, CF1, EP, ER, EF1: 9 Float tensors\n        \"\"\"", "\n", "eps", "=", "1e-10", "\n", "n", ",", "n_class", "=", "scores_", ".", "shape", "\n", "Nc", ",", "Np", ",", "Ng", "=", "np", ".", "zeros", "(", "n_class", ")", ",", "np", ".", "zeros", "(", "n_class", ")", ",", "np", ".", "zeros", "(", "n_class", ")", "\n", "for", "k", "in", "range", "(", "n_class", ")", ":", "\n", "            ", "scores", "=", "scores_", "[", ":", ",", "k", "]", "\n", "targets", "=", "targets_", "[", ":", ",", "k", "]", "\n", "targets", "[", "targets", "==", "-", "1", "]", "=", "0", "\n", "Ng", "[", "k", "]", "=", "np", ".", "sum", "(", "targets", "==", "1", ")", "\n", "Np", "[", "k", "]", "=", "np", ".", "sum", "(", "scores", ">=", "0", ")", "\n", "Nc", "[", "k", "]", "=", "np", ".", "sum", "(", "targets", "*", "(", "scores", ">=", "0", ")", ")", "\n", "\n", "", "OP", "=", "np", ".", "sum", "(", "Nc", ")", "/", "(", "np", ".", "sum", "(", "Np", ")", "+", "eps", ")", "\n", "OR", "=", "np", ".", "sum", "(", "Nc", ")", "/", "(", "np", ".", "sum", "(", "Ng", ")", "+", "eps", ")", "\n", "OF1", "=", "(", "2", "*", "OP", "*", "OR", ")", "/", "(", "OP", "+", "OR", "+", "eps", ")", "\n", "\n", "CP", "=", "Nc", "/", "(", "Np", "+", "eps", ")", "\n", "CR", "=", "Nc", "/", "(", "Ng", "+", "eps", ")", "\n", "CF1", "=", "(", "2", "*", "CP", "*", "CR", ")", "/", "(", "CP", "+", "CR", "+", "eps", ")", "\n", "\n", "CP", "=", "np", ".", "mean", "(", "CP", ")", "\n", "CR", "=", "np", ".", "mean", "(", "CR", ")", "\n", "CF1", "=", "np", ".", "mean", "(", "CF1", ")", "\n", "\n", "# calculate example-based", "\n", "pred", "=", "np", ".", "int8", "(", "np", ".", "round", "(", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "scores_", ")", ")", ")", ")", "\n", "gt", "=", "np", ".", "int8", "(", "np", ".", "round", "(", "targets_", ")", ")", "\n", "TP_e", "=", "np", ".", "float32", "(", "np", ".", "sum", "(", "(", "(", "pred", "+", "gt", ")", "==", "2", ")", ",", "1", ")", ")", "\n", "FP_e", "=", "np", ".", "float32", "(", "np", ".", "sum", "(", "(", "(", "pred", "-", "gt", ")", "==", "1", ")", ",", "1", ")", ")", "\n", "FN_e", "=", "np", ".", "float32", "(", "np", ".", "sum", "(", "(", "(", "pred", "-", "gt", ")", "==", "-", "1", ")", ",", "1", ")", ")", "\n", "TN_e", "=", "np", ".", "float32", "(", "np", ".", "sum", "(", "(", "(", "pred", "+", "gt", ")", "==", "0", ")", ",", "1", ")", ")", "\n", "\n", "# clear TP_e is 0, assign it some value and latter assign zero", "\n", "Nc", "=", "TP_e", "\n", "Np", "=", "TP_e", "+", "FP_e", "\n", "Ng", "=", "TP_e", "+", "FN_e", "\n", "\n", "EP", "=", "Nc", "/", "(", "Np", "+", "eps", ")", "\n", "ER", "=", "Nc", "/", "(", "Ng", "+", "eps", ")", "\n", "EF1", "=", "(", "2", "*", "EP", "*", "ER", ")", "/", "(", "EP", "+", "ER", "+", "eps", ")", "\n", "\n", "EP", "=", "np", ".", "mean", "(", "EP", ")", "\n", "ER", "=", "np", ".", "mean", "(", "ER", ")", "\n", "EF1", "=", "np", ".", "mean", "(", "EF1", ")", "\n", "\n", "return", "OP", ",", "OR", ",", "OF1", ",", "CP", ",", "CR", ",", "CF1", ",", "EP", ",", "ER", ",", "EF1", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.svm.svm": [[4, 8], ["len", "numpy.shape"], "function", ["None"], ["def", "svm", "(", "images", ",", "orientations", "=", "9", ",", "pixels_per_cell", "=", "(", "8", ",", "8", ")", ",", "cells_per_block", "=", "(", "3", ",", "3", ")", ",", "block_norm", "=", "'L2-Hys'", ")", ":", "\n", "# images should be numpy array (B x H x W x C) or (1 x H x W x C)", "\n", "    ", "if", "len", "(", "np", ".", "shape", "(", "images", ")", "==", "3", ")", ":", "\n", "        ", "images", "=", "images", "[", "np", ".", "newaxis", ",", ":", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean.__init__": [[34, 46], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "multiscene_clean.read_object_labels_csv", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv"], ["    ", "def", "__init__", "(", "self", ",", "set", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "path_dataset", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'MultiScene-Clean'", ")", "\n", "self", ".", "set", "=", "set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "# define filename of csv file", "\n", "file_csv", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_dataset", ",", "set", "+", "'.csv'", ")", "\n", "self", ".", "labels", "=", "read_object_labels_csv", "(", "file_csv", ")", "\n", "\n", "print", "(", "'[dataset] MultiScene-Clean classification set=%s number of classes=%d  number of images=%d'", "%", "(", "\n", "set", ",", "len", "(", "SCENE_CATEGORY", ")", ",", "len", "(", "self", ".", "labels", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean.__getitem__": [[47, 56], ["PIL.Image.open().convert", "multiscene_clean.MultiSceneClean.transform", "multiscene_clean.MultiSceneClean.target_transform", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "labels", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_dataset", ",", "'images'", ",", "path", "+", "'.jpg'", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "(", "img", ",", "path", ")", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean.__len__": [[57, 59], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean.get_number_classes": [[60, 62], ["len"], "methods", ["None"], ["", "def", "get_number_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "SCENE_CATEGORY", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv": [[14, 32], ["len", "open", "csv.reader", "numpy.asarray().astype", "torch.from_numpy", "torch.from_numpy", "labels.append", "numpy.asarray"], "function", ["None"], ["def", "read_object_labels_csv", "(", "filename", ",", "only_gt", "=", "False", ",", "header", "=", "True", ")", ":", "\n", "    ", "labels", "=", "[", "]", "\n", "num_categories", "=", "len", "(", "SCENE_CATEGORY", ")", "\n", "#print('[dataset] read', filename)", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "rownum", "=", "0", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "header", "and", "rownum", "==", "0", ":", "\n", "                ", "header", "=", "row", "\n", "", "else", ":", "\n", "                ", "name", "=", "row", "[", "0", "]", "\n", "gt", "=", "(", "np", ".", "asarray", "(", "row", "[", "1", ":", "num_categories", "+", "1", "]", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "gt", "=", "torch", ".", "from_numpy", "(", "gt", ")", "\n", "item", "=", "(", "name", ",", "gt", ")", "if", "not", "only_gt", "else", "gt", "\n", "labels", ".", "append", "(", "item", ")", "\n", "", "rownum", "+=", "1", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.MultiSceneClean_sklearn": [[68, 95], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.stack().numpy", "torch.stack().numpy", "os.path.isfile", "os.path.isfile", "multiscene_clean.read_object_labels_csv", "numpy.zeros", "range", "numpy.array", "numpy.save", "print", "print", "numpy.load", "print", "len", "print", "numpy.uint8", "skimage.feature.hog", "numpy.uint8", "numpy.histogram", "numpy.concatenate", "torch.stack", "torch.stack", "len", "PIL.Image.open().convert", "PIL.Image.open().convert", "skimage.feature.local_binary_pattern", "multiscene_clean.read_object_labels_csv", "len", "len", "len", "len", "PIL.Image.open", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv", "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.multiscene_clean.read_object_labels_csv"], ["def", "MultiSceneClean_sklearn", "(", "set", ")", ":", "\n", "    ", "path_dataset", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'MultiScene-Clean'", ")", "\n", "path_feat", "=", "os", ".", "path", ".", "join", "(", "ROOT", ",", "'MultiScene-Clean'", ",", "'feat'", "+", "set", "+", "'.npy'", ")", "\n", "file_csv", "=", "os", ".", "path", ".", "join", "(", "path_dataset", ",", "set", "+", "'.csv'", ")", "\n", "y", "=", "torch", ".", "stack", "(", "read_object_labels_csv", "(", "file_csv", ",", "True", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path_feat", ")", ":", "\n", "        ", "print", "(", "'.npy files already exist.'", ")", "\n", "x", "=", "np", ".", "load", "(", "path_feat", ")", "\n", "print", "(", "'[dataset] MultiScene classification set=%s number of classes=%d  number of images=%d'", "%", "(", "set", ",", "len", "(", "SCENE_CATEGORY", ")", ",", "len", "(", "y", ")", ")", ")", "\n", "return", "x", ",", "y", "\n", "\n", "", "labels", "=", "read_object_labels_csv", "(", "file_csv", ")", "\n", "feat", "=", "np", ".", "zeros", "(", "(", "len", "(", "labels", ")", ",", "2048", "+", "128", ")", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "print", "(", "index", ")", "\n", "path", ",", "target", "=", "labels", "[", "index", "]", "\n", "img", "=", "np", ".", "uint8", "(", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "path_dataset", ",", "'images'", ",", "path", "+", "'.jpg'", ")", ")", ".", "convert", "(", "'RGB'", ")", ")", "\n", "feat_hog32", "=", "hog", "(", "img", ",", "orientations", "=", "8", ",", "pixels_per_cell", "=", "(", "32", ",", "32", ")", ",", "cells_per_block", "=", "(", "1", ",", "1", ")", ",", "block_norm", "=", "'L2'", ")", "\n", "img_gray", "=", "np", ".", "uint8", "(", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "path_dataset", ",", "'images'", ",", "path", "+", "'.jpg'", ")", ")", ".", "convert", "(", "'L'", ")", ")", "\n", "feat_lbp16", ",", "_", "=", "np", ".", "histogram", "(", "local_binary_pattern", "(", "img_gray", ",", "16", "*", "8", ",", "16", ",", "'uniform'", ")", ",", "density", "=", "True", ",", "bins", "=", "128", ",", "range", "=", "(", "0", ",", "128", ")", ")", "\n", "feat", "[", "index", ",", ":", "]", "=", "np", ".", "concatenate", "(", "[", "feat_hog32", ",", "feat_lbp16", "]", ")", "\n", "\n", "", "feat", "=", "np", ".", "array", "(", "feat", ")", "\n", "np", ".", "save", "(", "path_feat", ",", "feat", ")", "\n", "print", "(", "'[dataset] MultiScene classification set=%s number of classes=%d  number of images=%d'", "%", "(", "set", ",", "len", "(", "SCENE_CATEGORY", ")", ",", "len", "(", "y", ")", ")", ")", "\n", "return", "feat", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.facnn.FACNN.__init__": [[9, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "backbone.VGGNet", "backbone.VGGNet"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ",", "dim", "=", "2048", ")", ":", "\n", "        ", "super", "(", "FACNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "backbone", "=", "VGGNet", "(", "model", ",", "True", ")", ".", "vggnet", "\n", "self", ".", "classifier", "=", "VGGNet", "(", "model", ",", "True", ")", ".", "classifier", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "4096", "+", "dim", ",", "num_classes", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "1280", ",", "dim", ",", "1", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "AvgPool2d", "(", "4", ",", "4", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "AvgPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.facnn.FACNN.forward": [[25, 44], ["facnn.FACNN.pool1", "facnn.FACNN.pool2", "facnn.FACNN.backbone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "facnn.FACNN.pool().view", "facnn.FACNN.classifier", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "facnn.FACNN.fc", "facnn.FACNN.backbone().view", "facnn.FACNN.pool", "facnn.FACNN.relu", "facnn.FACNN.backbone", "facnn.FACNN.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# vggnet", "\n", "# feature aggregation", "\n", "        ", "eps", "=", "1e-8", "\n", "c3", "=", "self", ".", "pool1", "(", "self", ".", "backbone", "[", ":", "17", "]", "(", "x", ")", ")", "\n", "c3", "=", "c3", "/", "(", "(", "c3", "*", "c3", "+", "eps", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "eps", ")", "\n", "c4", "=", "self", ".", "pool2", "(", "self", ".", "backbone", "[", ":", "24", "]", "(", "x", ")", ")", "\n", "c4", "=", "c4", "/", "(", "(", "c4", "*", "c4", "+", "eps", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "eps", ")", "\n", "c5", "=", "self", ".", "backbone", "(", "x", ")", "\n", "c5", "=", "c5", "/", "(", "(", "c5", "*", "c5", "+", "eps", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "eps", ")", "\n", "x_fa", "=", "torch", ".", "cat", "(", "[", "c3", ",", "c4", ",", "c5", "]", ",", "dim", "=", "1", ")", "\n", "x_fa", "=", "self", ".", "pool", "(", "self", ".", "relu", "(", "self", ".", "conv", "(", "x_fa", ")", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "dim", ")", "\n", "\n", "# vgg16 fc2 output:", "\n", "x_fc2", "=", "self", ".", "classifier", "(", "self", ".", "backbone", "(", "x", ")", ".", "view", "(", "-", "1", ",", "25088", ")", ")", "\n", "\n", "# fusion", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x_fa", ",", "x_fc2", "]", ",", "dim", "=", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.facnn.FACNN.get_config_optim": [[45, 50], ["facnn.FACNN.backbone.parameters", "facnn.FACNN.classifier.parameters", "facnn.FACNN.fc.parameters", "facnn.FACNN.conv.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "classifier", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ",", "\n", "{", "'params'", ":", "self", ".", "conv", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.relationnet.RelationNet.__init__": [[8, 46], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.AtrousResNet", "conv_parcels.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "stn_params.append", "range", "torchvision.resnet50", "backbone.AtrousVGGNet", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "int", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "g_theta.append", "torchvision.vgg16", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "backbone", ",", "num_classes", ",", "num_moda", ",", "num_units", ")", ":", "\n", "        ", "super", "(", "RelationNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_moda", "=", "num_moda", "\n", "self", ".", "num_units", "=", "num_units", "\n", "if", "backbone", "==", "'resnet50'", ":", "\n", "            ", "self", ".", "backbone", "=", "AtrousResNet", "(", "models", ".", "resnet50", "(", "pretrained", "=", "True", ")", ")", "\n", "self", ".", "backbone_feat", "=", "2048", "\n", "", "elif", "backbone", "==", "'vggnet16'", ":", "\n", "            ", "self", ".", "backbone", "=", "AtrousVGGNet", "(", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", ")", "\n", "self", ".", "backbone_feat", "=", "512", "\n", "\n", "", "self", ".", "feature_size", "=", "14", "\n", "self", ".", "avg", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "# relation module", "\n", "conv_parcels", "=", "[", "]", "\n", "stn_params", "=", "[", "]", "\n", "g_theta", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_classes", ")", ":", "\n", "            ", "conv_parcels", ".", "append", "(", "nn", ".", "Conv2d", "(", "self", ".", "backbone_feat", ",", "num_moda", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ")", "\n", "tmp", "=", "nn", ".", "Linear", "(", "int", "(", "num_moda", "*", "self", ".", "feature_size", "*", "self", ".", "feature_size", "/", "4", ")", ",", "6", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "tmp", ".", "weight", ")", "\n", "tmp", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", ")", "\n", "tmp", ".", "bias", "[", "1", "]", ".", "require_grad", "=", "False", "\n", "tmp", ".", "bias", "[", "3", "]", ".", "require_grad", "=", "False", "\n", "stn_params", ".", "append", "(", "tmp", ")", "\n", "for", "j", "in", "range", "(", "num_classes", "-", "1", ")", ":", "\n", "                ", "g_theta", ".", "append", "(", "nn", ".", "Conv2d", "(", "num_moda", "*", "2", ",", "num_units", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ")", "\n", "\n", "", "", "self", ".", "conv_parcels", "=", "nn", ".", "ModuleList", "(", "conv_parcels", ")", "\n", "self", ".", "stn_params", "=", "nn", ".", "ModuleList", "(", "stn_params", ")", "\n", "self", ".", "g_theta", "=", "nn", ".", "ModuleList", "(", "g_theta", ")", "\n", "self", ".", "f_phi", "=", "nn", ".", "Linear", "(", "num_units", ",", "1", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.relationnet.RelationNet.forward": [[47, 76], ["relationnet.RelationNet.backbone", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.max_pool2d().view", "torch.affine_grid", "torch.affine_grid", "torch.affine_grid", "x_obj.append", "range", "relationnet.RelationNet.avg().view", "torch.cat.append", "torch.cat.append", "torch.cat.append", "int", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "relationnet.RelationNet.f_phi", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "relationnet.RelationNet.avg", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "\n", "# extract attentional regions of each parcel", "\n", "x_obj", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_classes", ")", ":", "\n", "            ", "x_tmp", "=", "self", ".", "conv_parcels", "[", "i", "]", "(", "x", ")", "\n", "tmp", "=", "F", ".", "max_pool2d", "(", "F", ".", "relu", "(", "x_tmp", ")", ",", "2", ")", ".", "view", "(", "-", "1", ",", "int", "(", "self", ".", "num_moda", "*", "self", ".", "feature_size", "**", "2", "/", "4", ")", ")", "\n", "tmp", "=", "self", ".", "stn_params", "[", "i", "]", "(", "tmp", ")", ".", "view", "(", "-", "1", ",", "2", ",", "3", ")", "\n", "affine_grid_points", "=", "F", ".", "affine_grid", "(", "tmp", ",", "torch", ".", "Size", "(", "(", "tmp", ".", "size", "(", "0", ")", ",", "self", ".", "num_moda", ",", "self", ".", "feature_size", ",", "self", ".", "feature_size", ")", ")", ",", "align_corners", "=", "True", ")", "\n", "x_obj", ".", "append", "(", "F", ".", "grid_sample", "(", "x_tmp", ",", "affine_grid_points", ",", "align_corners", "=", "True", ")", ")", "\n", "\n", "# build relations between each label pair", "\n", "", "idx_g", "=", "0", "\n", "outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_classes", ")", ":", "\n", "            ", "relation_inter", "=", "0", "\n", "# g_theta", "\n", "for", "j", "in", "range", "(", "self", ".", "num_classes", ")", ":", "\n", "                ", "if", "not", "i", "==", "j", ":", "\n", "                    ", "relation_inter", "+=", "F", ".", "relu", "(", "self", ".", "g_theta", "[", "idx_g", "]", "(", "torch", ".", "cat", "(", "[", "x_obj", "[", "i", "]", ",", "x_obj", "[", "j", "]", "]", ",", "axis", "=", "1", ")", ")", ")", "\n", "idx_g", "+=", "1", "\n", "", "", "relation_accum", "=", "self", ".", "avg", "(", "relation_inter", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_units", ")", "\n", "# f_phi", "\n", "outputs", ".", "append", "(", "self", ".", "f_phi", "(", "relation_accum", ")", ")", "\n", "\n", "", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.relationnet.RelationNet.get_config_optim": [[77, 90], ["range", "range", "params.append", "params.append", "params.append", "params.append", "params.append", "relationnet.RelationNet.f_phi.parameters", "relationnet.RelationNet.backbone.parameters", "relationnet.RelationNet.conv_parcels[].parameters", "relationnet.RelationNet.stn_params[].parameters", "relationnet.RelationNet.g_theta[].parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "params", "=", "[", "]", "\n", "idx_g", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "num_classes", ")", ":", "\n", "            ", "params", ".", "append", "(", "{", "'params'", ":", "self", ".", "conv_parcels", "[", "i", "]", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ")", "\n", "params", ".", "append", "(", "{", "'params'", ":", "self", ".", "stn_params", "[", "i", "]", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ")", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_classes", "*", "(", "self", ".", "num_classes", "-", "1", ")", ")", ":", "\n", "            ", "params", ".", "append", "(", "{", "'params'", ":", "self", ".", "g_theta", "[", "i", "]", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ")", "\n", "\n", "", "params", ".", "append", "(", "{", "'params'", ":", "self", ".", "f_phi", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ")", "\n", "params", ".", "append", "(", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ")", "\n", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.model_bank.build_model": [[14, 65], ["cnn.VGGNetBaseline", "torchvision.vgg16", "cnn.VGGNetBaseline", "torchvision.vgg19", "cnn.InceptionBaseline", "torchvision.inception_v3", "cnn.ResNetBaseline", "torchvision.resnet50", "cnn.ResNetBaseline", "torchvision.resnet101", "cnn.ResNetBaseline", "torchvision.resnet152", "cnn.SqueezeNetBaseline", "torchvision.squeezenet1_0", "cnn.DenseNetBaseline", "torchvision.densenet121", "cnn.DenseNetBaseline", "torchvision.densenet169", "cnn.ShuffleNetBaseline", "torchvision.shufflenet_v2_x1_0", "cnn.MobileNetBaseline", "torchvision.mobilenet_v2", "cnn.ResNeXtBaseline", "torchvision.resnext50_32x4d", "cnn.ResNeXtBaseline", "torchvision.resnext101_32x8d", "cnn.MNASNetBaseline", "torchvision.mnasnet1_0", "relationnet.RelationNet", "relationnet.RelationNet", "sklearn.multioutput.MultiOutputClassifier", "sklearn.svm.SVC", "sklearn.multioutput.MultiOutputClassifier", "xgboost.XGBClassifier", "sklearn.multioutput.MultiOutputClassifier", "sklearn.ensemble.RandomForestClassifier", "saff.SAFF", "torchvision.vgg16", "facnn.FACNN", "torchvision.vgg16", "kfb.KFB", "print", "cnn.ResNeXtBaseline", "torchvision.vgg16", "torchvision.resnext101_32x8d"], "function", ["None"], ["def", "build_model", "(", "args", ")", ":", "\n", "    ", "model_name", "=", "args", ".", "model_name", "\n", "nb_classes", "=", "args", ".", "nb_classes", "\n", "pretrained", "=", "args", ".", "pretrain", "\n", "if", "model_name", "==", "'vggnet16'", ":", "\n", "        ", "return", "VGGNetBaseline", "(", "models", ".", "vgg16", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'vggnet19'", ":", "\n", "        ", "return", "VGGNetBaseline", "(", "models", ".", "vgg19", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'inceptionv3'", ":", "\n", "        ", "return", "InceptionBaseline", "(", "models", ".", "inception_v3", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'resnet50'", ":", "\n", "        ", "return", "ResNetBaseline", "(", "models", ".", "resnet50", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'resnet101'", ":", "\n", "        ", "return", "ResNetBaseline", "(", "models", ".", "resnet101", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'resnet152'", ":", "\n", "        ", "return", "ResNetBaseline", "(", "models", ".", "resnet152", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'squeezenet'", ":", "\n", "        ", "return", "SqueezeNetBaseline", "(", "models", ".", "squeezenet1_0", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'densenet121'", ":", "\n", "        ", "return", "DenseNetBaseline", "(", "models", ".", "densenet121", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'densenet169'", ":", "\n", "        ", "return", "DenseNetBaseline", "(", "models", ".", "densenet169", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'shufflenetv2'", ":", "\n", "        ", "return", "ShuffleNetBaseline", "(", "models", ".", "shufflenet_v2_x1_0", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'mobilenetv2'", ":", "\n", "        ", "return", "MobileNetBaseline", "(", "models", ".", "mobilenet_v2", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'resnext50'", ":", "\n", "        ", "return", "ResNeXtBaseline", "(", "models", ".", "resnext50_32x4d", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'resnext101'", ":", "\n", "        ", "return", "ResNeXtBaseline", "(", "models", ".", "resnext101_32x8d", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'mnasnet'", ":", "\n", "        ", "return", "MNASNetBaseline", "(", "models", ".", "mnasnet1_0", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'lr-vggnet16'", ":", "\n", "        ", "return", "RelationNet", "(", "'vggnet16'", ",", "nb_classes", ",", "num_moda", "=", "args", ".", "nb_moda", ",", "num_units", "=", "args", ".", "nb_units", ")", "\n", "", "elif", "model_name", "==", "'lr-resnet50'", ":", "\n", "        ", "return", "RelationNet", "(", "'resnet50'", ",", "nb_classes", ",", "num_moda", "=", "args", ".", "nb_moda", ",", "num_units", "=", "args", ".", "nb_units", ")", "\n", "", "elif", "model_name", "==", "'svm'", ":", "\n", "        ", "return", "MultiOutputClassifier", "(", "SVC", "(", "random_state", "=", "0", ",", "tol", "=", "1e-5", ",", "max_iter", "=", "100000", ",", "verbose", "=", "1", ")", ",", "-", "1", ")", "\n", "", "elif", "model_name", "==", "'xgboost'", ":", "\n", "        ", "return", "MultiOutputClassifier", "(", "XGBClassifier", "(", "booster", "=", "'gbtree'", ",", "n_jobs", "=", "100", ",", "n_estimators", "=", "200", ",", "verbosity", "=", "1", ",", "use_label_encoder", "=", "False", ",", "gpu_id", "=", "0", ")", ",", "-", "1", ")", "\n", "", "elif", "model_name", "==", "'rf'", ":", "\n", "        ", "return", "MultiOutputClassifier", "(", "RandomForestClassifier", "(", "random_state", "=", "0", ",", "n_estimators", "=", "200", ",", "verbose", "=", "1", ")", ",", "-", "1", ")", "\n", "", "elif", "model_name", "==", "'saff'", ":", "\n", "        ", "return", "SAFF", "(", "models", ".", "vgg16", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ",", "256", ")", "\n", "", "elif", "model_name", "==", "'facnn'", ":", "\n", "        ", "return", "FACNN", "(", "models", ".", "vgg16", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "elif", "model_name", "==", "'kfb'", ":", "\n", "        ", "return", "KFB", "(", "models", ".", "vgg16", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'The selected model is not pre-defined! Now got to default model (ResNeXt101)!'", ")", "\n", "return", "ResNeXtBaseline", "(", "models", ".", "resnext101_32x8d", "(", "pretrained", "=", "pretrained", ")", ",", "nb_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.VGGNetBaseline.__init__": [[9, 17], ["torch.Module.__init__", "backbone.VGGNet", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "VGGNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "VGGNet", "(", "model", ",", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "4096", ",", "num_classes", ",", "bias", "=", "True", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.VGGNetBaseline.forward": [[18, 22], ["cnn.VGGNetBaseline.backbone", "cnn.VGGNetBaseline.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# vggnet", "\n", "        ", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.VGGNetBaseline.get_config_optim": [[23, 26], ["cnn.VGGNetBaseline.backbone.parameters", "cnn.VGGNetBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.InceptionBaseline.__init__": [[29, 40], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.InceptionV3", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "InceptionBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "InceptionV3", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.InceptionBaseline.forward": [[41, 45], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.InceptionBaseline.fc", "cnn.InceptionBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# inceptionv3", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.InceptionBaseline.get_config_optim": [[46, 49], ["cnn.InceptionBaseline.backbone.parameters", "cnn.InceptionBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ResNetBaseline.__init__": [[52, 63], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.ResNet", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "ResNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "ResNet", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ResNetBaseline.forward": [[64, 68], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.ResNetBaseline.fc", "cnn.ResNetBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# resnet", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ResNetBaseline.get_config_optim": [[69, 72], ["cnn.ResNetBaseline.backbone.parameters", "cnn.ResNetBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.SqueezeNetBaseline.__init__": [[75, 87], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "backbone.SqueezeNet", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "SqueezeNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "SqueezeNet", "(", "model", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.5", ",", "inplace", "=", "False", ")", "\n", ")", "\n", "self", ".", "fc_conv", "=", "nn", ".", "Conv2d", "(", "model", ".", "classifier", "[", "1", "]", ".", "in_channels", ",", "num_classes", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "avg", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.SqueezeNetBaseline.forward": [[88, 92], ["cnn.SqueezeNetBaseline.backbone", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.SqueezeNetBaseline.avg", "cnn.SqueezeNetBaseline.fc_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# squeezenet", "\n", "        ", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "return", "torch", ".", "flatten", "(", "self", ".", "avg", "(", "self", ".", "fc_conv", "(", "x", ")", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.SqueezeNetBaseline.get_config_optim": [[93, 96], ["cnn.SqueezeNetBaseline.backbone.parameters", "cnn.SqueezeNetBaseline.fc_conv.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc_conv", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.DenseNetBaseline.__init__": [[99, 110], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.DenseNet", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "DenseNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "DenseNet", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "classifier", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization        ", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.DenseNetBaseline.forward": [[111, 115], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.DenseNetBaseline.fc", "cnn.DenseNetBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# densenet", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.DenseNetBaseline.get_config_optim": [[116, 119], ["cnn.DenseNetBaseline.backbone.parameters", "cnn.DenseNetBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ShuffleNetBaseline.__init__": [[123, 134], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.ShuffleNetV2", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "ShuffleNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "ShuffleNetV2", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ShuffleNetBaseline.forward": [[135, 139], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.ShuffleNetBaseline.fc", "cnn.ShuffleNetBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# shufflenet", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ShuffleNetBaseline.get_config_optim": [[140, 143], ["cnn.ShuffleNetBaseline.backbone.parameters", "cnn.ShuffleNetBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.MobileNetBaseline.__init__": [[146, 157], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.MobileNetV2", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "MobileNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "MobileNetV2", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "classifier", "[", "1", "]", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.MobileNetBaseline.forward": [[158, 162], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.MobileNetBaseline.fc", "cnn.MobileNetBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# mobilenet", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.MobileNetBaseline.get_config_optim": [[163, 166], ["cnn.MobileNetBaseline.backbone.parameters", "cnn.MobileNetBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ResNeXtBaseline.__init__": [[170, 181], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.ResNeXt", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "ResNeXtBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "ResNeXt", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ResNeXtBaseline.forward": [[182, 186], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.ResNeXtBaseline.fc", "cnn.ResNeXtBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# resnext", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.ResNeXtBaseline.get_config_optim": [[187, 190], ["cnn.ResNeXtBaseline.backbone.parameters", "cnn.ResNeXtBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.MNASNetBaseline.__init__": [[192, 203], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.MNASNet", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "MNASNetBaseline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "nn", ".", "Sequential", "(", "\n", "MNASNet", "(", "model", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "classifier", "[", "1", "]", ".", "in_features", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.MNASNetBaseline.forward": [[204, 208], ["torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "cnn.MNASNetBaseline.fc", "cnn.MNASNetBaseline.backbone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# mnasnet", "\n", "        ", "x", "=", "torch", ".", "flatten", "(", "self", ".", "backbone", "(", "x", ")", ",", "1", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.cnn.MNASNetBaseline.get_config_optim": [[209, 212], ["cnn.MNASNetBaseline.backbone.parameters", "cnn.MNASNetBaseline.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.VGGNet.__init__": [[5, 12], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "is_baseline", "=", "False", ")", ":", "\n", "        ", "super", "(", "VGGNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_baseline", "=", "is_baseline", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "vggnet", "=", "model", ".", "features", "\n", "self", ".", "avg", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "7", ",", "7", ")", ")", "\n", "self", ".", "classifier", "=", "model", ".", "classifier", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.VGGNet.forward": [[13, 19], ["backbone.VGGNet.classifier", "backbone.VGGNet.vggnet", "backbone.VGGNet.avg().view", "backbone.VGGNet.avg", "backbone.VGGNet.vggnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "is_baseline", ":", "\n", "# using fc1, fc2", "\n", "            ", "return", "self", ".", "classifier", "(", "self", ".", "avg", "(", "self", ".", "vggnet", "(", "x", ")", ")", ".", "view", "(", "-", "1", ",", "25088", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "vggnet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.InceptionV3.__init__": [[22, 44], ["torch.Module.__init__", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "inceptionv3", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "model", ".", "Conv2d_1a_3x3", ",", "\n", "self", ".", "model", ".", "Conv2d_2a_3x3", ",", "\n", "self", ".", "model", ".", "Conv2d_2b_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "self", ".", "model", ".", "Conv2d_3b_1x1", ",", "\n", "self", ".", "model", ".", "Conv2d_4a_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "self", ".", "model", ".", "Mixed_5b", ",", "\n", "self", ".", "model", ".", "Mixed_5c", ",", "\n", "self", ".", "model", ".", "Mixed_5d", ",", "\n", "self", ".", "model", ".", "Mixed_6a", ",", "\n", "self", ".", "model", ".", "Mixed_6b", ",", "\n", "self", ".", "model", ".", "Mixed_6c", ",", "\n", "self", ".", "model", ".", "Mixed_6d", ",", "\n", "self", ".", "model", ".", "Mixed_6e", ",", "\n", "self", ".", "model", ".", "Mixed_7a", ",", "\n", "self", ".", "model", ".", "Mixed_7b", ",", "\n", "self", ".", "model", ".", "Mixed_7c", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.InceptionV3.forward": [[46, 48], ["backbone.InceptionV3.inceptionv3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "inceptionv3", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.ResNet.__init__": [[51, 63], ["torch.Module.__init__", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "resnet", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "model", ".", "conv1", ",", "\n", "self", ".", "model", ".", "bn1", ",", "\n", "self", ".", "model", ".", "relu", ",", "\n", "self", ".", "model", ".", "maxpool", ",", "\n", "self", ".", "model", ".", "layer1", ",", "\n", "self", ".", "model", ".", "layer2", ",", "\n", "self", ".", "model", ".", "layer3", ",", "\n", "self", ".", "model", ".", "layer4", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.ResNet.forward": [[65, 67], ["backbone.ResNet.resnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "resnet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.SqueezeNet.__init__": [[69, 72], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "SqueezeNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "squeezenet", "=", "model", ".", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.SqueezeNet.forward": [[73, 75], ["backbone.SqueezeNet.squeezenet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "squeezenet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.DenseNet.__init__": [[77, 81], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "DenseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "densenet", "=", "model", ".", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.DenseNet.forward": [[82, 84], ["backbone.DenseNet.densenet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "densenet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.ShuffleNetV2.__init__": [[87, 97], ["torch.Module.__init__", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "ShuffleNetV2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "shufflenetv2", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "model", ".", "conv1", ",", "\n", "self", ".", "model", ".", "maxpool", ",", "\n", "self", ".", "model", ".", "stage2", ",", "\n", "self", ".", "model", ".", "stage3", ",", "\n", "self", ".", "model", ".", "stage4", ",", "\n", "self", ".", "model", ".", "conv5", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.ShuffleNetV2.forward": [[99, 101], ["backbone.ShuffleNetV2.shufflenetv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "shufflenetv2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.MobileNetV2.__init__": [[103, 107], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "MobileNetV2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "mobilenetv2", "=", "model", ".", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.MobileNetV2.forward": [[108, 110], ["backbone.MobileNetV2.mobilenetv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mobilenetv2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.ResNeXt.__init__": [[112, 124], ["torch.Module.__init__", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "ResNeXt", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "resnext", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "model", ".", "conv1", ",", "\n", "self", ".", "model", ".", "bn1", ",", "\n", "self", ".", "model", ".", "relu", ",", "\n", "self", ".", "model", ".", "maxpool", ",", "\n", "self", ".", "model", ".", "layer1", ",", "\n", "self", ".", "model", ".", "layer2", ",", "\n", "self", ".", "model", ".", "layer3", ",", "\n", "self", ".", "model", ".", "layer4", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.ResNeXt.forward": [[126, 128], ["backbone.ResNeXt.resnext"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "resnext", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.WideResNet.__init__": [[131, 143], ["torch.Module.__init__", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "wideresnet", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "model", ".", "conv1", ",", "\n", "self", ".", "model", ".", "bn1", ",", "\n", "self", ".", "model", ".", "relu", ",", "\n", "self", ".", "model", ".", "maxpool", ",", "\n", "self", ".", "model", ".", "layer1", ",", "\n", "self", ".", "model", ".", "layer2", ",", "\n", "self", ".", "model", ".", "layer3", ",", "\n", "self", ".", "model", ".", "layer4", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.WideResNet.forward": [[145, 147], ["backbone.WideResNet.wideresnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "wideresnet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.MNASNet.__init__": [[150, 154], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "MNASNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "mnasnet", "=", "model", ".", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.MNASNet.forward": [[155, 157], ["backbone.MNASNet.mnasnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mnasnet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.AtrousResNet.__init__": [[160, 184], ["torch.Module.__init__", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "AtrousResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "# modified to dilation version", "\n", "self", ".", "model", ".", "layer4", "[", "0", "]", ".", "conv2", ".", "stride", "=", "(", "1", ",", "1", ")", "\n", "self", ".", "model", ".", "layer4", "[", "0", "]", ".", "downsample", "[", "0", "]", ".", "stride", "=", "(", "1", ",", "1", ")", "\n", "self", ".", "model", ".", "layer4", "[", "1", "]", ".", "conv1", ".", "dilation", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "1", "]", ".", "conv2", ".", "padding", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "1", "]", ".", "conv2", ".", "dilation", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "1", "]", ".", "conv3", ".", "dilation", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "2", "]", ".", "conv1", ".", "dilation", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "2", "]", ".", "conv2", ".", "padding", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "2", "]", ".", "conv2", ".", "dilation", "=", "(", "2", ",", "2", ")", "\n", "self", ".", "model", ".", "layer4", "[", "2", "]", ".", "conv3", ".", "dilation", "=", "(", "2", ",", "2", ")", "\n", "# *****************************", "\n", "self", ".", "atrous_resnet", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "model", ".", "conv1", ",", "\n", "self", ".", "model", ".", "bn1", ",", "\n", "self", ".", "model", ".", "relu", ",", "\n", "self", ".", "model", ".", "maxpool", ",", "\n", "self", ".", "model", ".", "layer1", ",", "\n", "self", ".", "model", ".", "layer2", ",", "\n", "self", ".", "model", ".", "layer3", ",", "\n", "self", ".", "model", ".", "layer4", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.AtrousResNet.forward": [[186, 188], ["backbone.AtrousResNet.atrous_resnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "atrous_resnet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.AtrousVGGNet.__init__": [[190, 194], ["torch.Module.__init__", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "AtrousVGGNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "atrous_vggnet", "=", "nn", ".", "Sequential", "(", "\n", "model", ".", "features", "[", ":", "-", "1", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.backbone.AtrousVGGNet.forward": [[196, 198], ["backbone.AtrousVGGNet.atrous_vggnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "atrous_vggnet", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.kfb.KFB.__init__": [[9, 30], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.AvgPool1d", "torch.AvgPool1d", "torch.AvgPool1d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "backbone.VGGNet"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ",", "k", "=", "20", ")", ":", "\n", "        ", "super", "(", "KFB", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "backbone", "=", "VGGNet", "(", "model", ",", "False", ")", ".", "vggnet", "\n", "self", ".", "conv6", "=", "nn", ".", "Conv2d", "(", "512", ",", "k", "*", "num_classes", ",", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv7", "=", "nn", ".", "Conv2d", "(", "k", "*", "num_classes", ",", "num_classes", ",", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv8", "=", "nn", ".", "Conv2d", "(", "k", "*", "num_classes", ",", "k", "*", "num_classes", ",", "2", ")", "\n", "# pooling operations", "\n", "self", ".", "gmp", "=", "nn", ".", "MaxPool2d", "(", "14", ",", "14", ")", "# global max pooling", "\n", "self", ".", "aap", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "# adaptive average pooling", "\n", "self", ".", "mp", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "1", ")", "# 2d max pooling", "\n", "self", ".", "ccp", "=", "nn", ".", "AvgPool1d", "(", "k", ",", "k", ")", "# cross-channel pooling", "\n", "# norm, relu, fc", "\n", "self", ".", "norm", "=", "nn", ".", "BatchNorm2d", "(", "k", "*", "num_classes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", ",", "num_classes", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.kfb.KFB.forward": [[31, 48], ["kfb.KFB.fc", "kfb.KFB.gmp", "kfb.KFB.aap().view", "kfb.KFB.relu", "kfb.KFB.ccp().squeeze", "kfb.KFB.gmp().view", "kfb.KFB.conv6", "kfb.KFB.norm", "kfb.KFB.aap", "kfb.KFB.conv8", "kfb.KFB.ccp", "kfb.KFB.gmp", "kfb.KFB.conv7", "kfb.KFB.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# vggnet", "\n", "        ", "c4", "=", "self", ".", "backbone", "[", ":", "23", "]", "(", "x", ")", "\n", "c5", "=", "self", ".", "backbone", "[", ":", "30", "]", "(", "x", ")", "\n", "\n", "# pred 1", "\n", "pred1", "=", "self", ".", "fc", "(", "self", ".", "gmp", "(", "c5", ")", ".", "view", "(", "-", "1", ",", "512", ")", ")", "\n", "\n", "# pred 2", "\n", "heatmap", "=", "self", ".", "gmp", "(", "self", ".", "conv6", "(", "c4", ")", ")", "\n", "pred2", "=", "self", ".", "aap", "(", "self", ".", "conv7", "(", "heatmap", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_classes", ")", "\n", "\n", "# pred 3", "\n", "x", "=", "self", ".", "relu", "(", "self", ".", "norm", "(", "self", ".", "conv8", "(", "heatmap", ")", ")", ")", "\n", "pred3", "=", "self", ".", "ccp", "(", "x", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "k", "*", "self", ".", "num_classes", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "pred1", "+", "pred2", "+", "pred3", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.kfb.KFB.get_config_optim": [[49, 55], ["kfb.KFB.backbone.parameters", "kfb.KFB.conv6.parameters", "kfb.KFB.conv7.parameters", "kfb.KFB.conv8.parameters", "kfb.KFB.fc.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "conv6", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ",", "\n", "{", "'params'", ":", "self", ".", "conv7", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ",", "\n", "{", "'params'", ":", "self", ".", "conv8", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__": [[9, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "backbone.VGGNet"], "methods", ["home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "num_classes", ",", "dim", "=", "512", ")", ":", "\n", "        ", "super", "(", "SAFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "backbone", "=", "VGGNet", "(", "model", ",", "False", ")", ".", "vggnet", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "1280", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "dim", ",", "num_classes", ",", "bias", "=", "True", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool2d", "(", "4", ",", "4", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "norm", "=", "nn", ".", "BatchNorm1d", "(", "1280", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "# image normalization", "\n", "self", ".", "image_normalization_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "image_normalization_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.forward": [[25, 56], ["saff.SAFF.pool1", "saff.SAFF.pool2", "saff.SAFF.backbone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sqrt().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "saff.SAFF.relu", "saff.SAFF.fc2", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "saff.SAFF.fc1", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "saff.SAFF.norm", "omega.sum", "torch.sqrt().unsqueeze.sqrt().sum", "torch.sqrt().unsqueeze.sqrt().sum", "torch.sqrt().unsqueeze.sqrt().sum", "torch.sqrt().unsqueeze.sqrt", "torch.sqrt().unsqueeze.sqrt", "torch.sqrt().unsqueeze.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# vggnet", "\n", "        ", "eps", "=", "1e-20", "\n", "c3", "=", "self", ".", "pool1", "(", "self", ".", "backbone", "[", ":", "17", "]", "(", "x", ")", ")", "\n", "c4", "=", "self", ".", "pool2", "(", "self", ".", "backbone", "[", ":", "24", "]", "(", "x", ")", ")", "\n", "c5", "=", "self", ".", "backbone", "(", "x", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "c3", ",", "c4", ",", "c5", "]", ",", "dim", "=", "1", ")", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "\n", "\n", "# spatial weighted sum pooling", "\n", "s", "=", "torch", ".", "sum", "(", "x", ",", "1", ")", "\n", "s", "=", "torch", ".", "sqrt", "(", "s", "/", "(", "s", ".", "sqrt", "(", ")", ".", "sum", "(", "(", "1", ",", "2", ")", ",", "keepdim", "=", "True", ")", "+", "eps", ")", ")", ".", "unsqueeze", "(", "1", ")", "# a: 0.5, b: 2", "\n", "x_s", "=", "torch", ".", "sum", "(", "s", "*", "x", ",", "(", "2", ",", "3", ")", ")", "\n", "\n", "# cross-dimensional weighting", "\n", "omega", "=", "torch", ".", "sum", "(", "x", ">", "0", ",", "(", "2", ",", "3", ")", ")", "/", "(", "w", "*", "h", ")", "\n", "wk", "=", "torch", ".", "log", "(", "(", "c", "*", "eps", "+", "omega", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", "/", "(", "eps", "+", "omega", ")", "+", "eps", ")", "\n", "x", "=", "x_s", "*", "wk", "\n", "\n", "''' \n        # pca whitening (fail training) \n        x = x.t()\n        x = x-torch.mean(x, dim=0, keepdim=True)\n        cov = torch.mm(x, x.t())/c\n        u, s, v = torch.svd(cov)\n        x = torch.diag(2./(torch.sqrt(s[:self.dim])+eps)).mm(u[:, :self.dim].t()).mm(x).t()\n        '''", "\n", "\n", "x", "=", "self", ".", "relu", "(", "self", ".", "fc1", "(", "self", ".", "norm", "(", "x", ")", ")", ")", "\n", "return", "self", ".", "fc2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hua-YS_Multi-Scene-Recognition.utils.saff.SAFF.get_config_optim": [[57, 61], ["saff.SAFF.backbone.parameters", "saff.SAFF.fc1.parameters", "saff.SAFF.fc2.parameters"], "methods", ["None"], ["", "def", "get_config_optim", "(", "self", ",", "lr", ",", "lrp", ")", ":", "\n", "        ", "return", "[", "{", "'params'", ":", "self", ".", "backbone", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "*", "lrp", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", ",", "\n", "{", "'params'", ":", "self", ".", "fc2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr", "}", "]", "\n", "\n"]]}