{"home.repos.pwc.inspect_result.jiayuzou2020_hft.mmseg.__init__.digit_version": [[13, 51], ["packaging.version.parse", "list", "tuple", "len", "list.extend", "list.extend", "list.extend", "list.extend", "warnings.warn", "len", "mmcv.__version__"], "function", ["None"], ["def", "digit_version", "(", "version_str", ":", "str", ",", "length", ":", "int", "=", "4", ")", ":", "\n", "    ", "\"\"\"Convert a version string into a tuple of integers.\n\n    This method is usually used for comparing two versions. For pre-release\n    versions: alpha < beta < rc.\n\n    Args:\n        version_str (str): The version string.\n        length (int): The maximum number of version levels. Default: 4.\n\n    Returns:\n        tuple[int]: The version info in digits (integers).\n    \"\"\"", "\n", "version", "=", "parse", "(", "version_str", ")", "\n", "assert", "version", ".", "release", ",", "f'failed to parse version {version_str}'", "\n", "release", "=", "list", "(", "version", ".", "release", ")", "\n", "release", "=", "release", "[", ":", "length", "]", "\n", "if", "len", "(", "release", ")", "<", "length", ":", "\n", "        ", "release", "=", "release", "+", "[", "0", "]", "*", "(", "length", "-", "len", "(", "release", ")", ")", "\n", "", "if", "version", ".", "is_prerelease", ":", "\n", "        ", "mapping", "=", "{", "'a'", ":", "-", "3", ",", "'b'", ":", "-", "2", ",", "'rc'", ":", "-", "1", "}", "\n", "val", "=", "-", "4", "\n", "# version.pre can be None", "\n", "if", "version", ".", "pre", ":", "\n", "            ", "if", "version", ".", "pre", "[", "0", "]", "not", "in", "mapping", ":", "\n", "                ", "warnings", ".", "warn", "(", "f'unknown prerelease version {version.pre[0]}, '", "\n", "'version checking may go wrong'", ")", "\n", "", "else", ":", "\n", "                ", "val", "=", "mapping", "[", "version", ".", "pre", "[", "0", "]", "]", "\n", "", "release", ".", "extend", "(", "[", "val", ",", "version", ".", "pre", "[", "-", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "release", ".", "extend", "(", "[", "val", ",", "0", "]", ")", "\n", "\n", "", "", "elif", "version", ".", "is_postrelease", ":", "\n", "        ", "release", ".", "extend", "(", "[", "1", ",", "version", ".", "post", "]", ")", "\n", "", "else", ":", "\n", "        ", "release", ".", "extend", "(", "[", "0", ",", "0", "]", ")", "\n", "", "return", "tuple", "(", "release", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.mmseg.version.parse_version_info": [[6, 16], ["version_str.split", "tuple", "x.isdigit", "version_info.append", "int", "x.find", "x.split", "version_info.append", "version_info.append", "int"], "function", ["None"], ["def", "parse_version_info", "(", "version_str", ")", ":", "\n", "    ", "version_info", "=", "[", "]", "\n", "for", "x", "in", "version_str", ".", "split", "(", "'.'", ")", ":", "\n", "        ", "if", "x", ".", "isdigit", "(", ")", ":", "\n", "            ", "version_info", ".", "append", "(", "int", "(", "x", ")", ")", "\n", "", "elif", "x", ".", "find", "(", "'rc'", ")", "!=", "-", "1", ":", "\n", "            ", "patch_version", "=", "x", ".", "split", "(", "'rc'", ")", "\n", "version_info", ".", "append", "(", "int", "(", "patch_version", "[", "0", "]", ")", ")", "\n", "version_info", ".", "append", "(", "f'rc{patch_version[1]}'", ")", "\n", "", "", "return", "tuple", "(", "version_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.logger.get_root_logger": [[7, 29], ["mmcv.utils.get_logger"], "function", ["None"], ["def", "get_root_logger", "(", "log_file", "=", "None", ",", "log_level", "=", "logging", ".", "INFO", ")", ":", "\n", "    ", "\"\"\"Get the root logger.\n\n    The logger will be initialized if it has not been initialized. By default a\n    StreamHandler will be added. If `log_file` is specified, a FileHandler will\n    also be added. The name of the root logger is the top-level package name,\n    e.g., \"mmseg\".\n\n    Args:\n        log_file (str | None): The log filename. If specified, a FileHandler\n            will be added to the root logger.\n        log_level (int): The root logger level. Note that only the process of\n            rank 0 is affected, while other processes will set the level to\n            \"Error\" and be silent most of the time.\n\n    Returns:\n        logging.Logger: The root logger.\n    \"\"\"", "\n", "\n", "logger", "=", "get_logger", "(", "name", "=", "'mmseg'", ",", "log_file", "=", "log_file", ",", "log_level", "=", "log_level", ")", "\n", "\n", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.collect_env.collect_env": [[8, 14], ["mmcv.utils.collect_env", "mmcv.utils.get_git_hash"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.collect_env.collect_env"], ["def", "collect_env", "(", ")", ":", "\n", "    ", "\"\"\"Collect the information of the running environments.\"\"\"", "\n", "env_info", "=", "collect_base_env", "(", ")", "\n", "env_info", "[", "'MMSegmentation'", "]", "=", "f'{mmseg.__version__}+{get_git_hash()[:7]}'", "\n", "\n", "return", "env_info", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.inverted_residual.InvertedResidual.__init__": [[32, 85], ["dict", "dict", "torch.nn.Module.__init__", "int", "layers.extend", "torch.nn.Sequential", "round", "layers.append", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "stride", ",", "\n", "expand_ratio", ",", "\n", "dilation", "=", "1", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU6'", ")", ",", "\n", "with_cp", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "InvertedResidual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", ",", "f'stride must in [1, 2]. '", "f'But received {stride}.'", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "use_res_connect", "=", "self", ".", "stride", "==", "1", "and", "in_channels", "==", "out_channels", "\n", "hidden_dim", "=", "int", "(", "round", "(", "in_channels", "*", "expand_ratio", ")", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "if", "expand_ratio", "!=", "1", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "ConvModule", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "", "layers", ".", "extend", "(", "[", "\n", "ConvModule", "(", "\n", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "groups", "=", "hidden_dim", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "**", "kwargs", ")", ",", "\n", "ConvModule", "(", "\n", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ",", "\n", "**", "kwargs", ")", "\n", "]", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.inverted_residual.InvertedResidual.forward": [[86, 100], ["torch.utils.checkpoint.checkpoint", "inverted_residual.InvertedResidual.forward._inner_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "if", "self", ".", "use_res_connect", ":", "\n", "                ", "return", "x", "+", "self", ".", "conv", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n", "", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.inverted_residual.InvertedResidualV3.__init__": [[129, 187], ["dict", "dict", "torch.nn.Module.__init__", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "isinstance", "mmcv.cnn.ConvModule", "se_layer.SELayer", "dict"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "mid_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "se_cfg", "=", "None", ",", "\n", "with_expand_conv", "=", "True", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "with_cp", "=", "False", ")", ":", "\n", "        ", "super", "(", "InvertedResidualV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "with_res_shortcut", "=", "(", "stride", "==", "1", "and", "in_channels", "==", "out_channels", ")", "\n", "assert", "stride", "in", "[", "1", ",", "2", "]", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "with_se", "=", "se_cfg", "is", "not", "None", "\n", "self", ".", "with_expand_conv", "=", "with_expand_conv", "\n", "\n", "if", "self", ".", "with_se", ":", "\n", "            ", "assert", "isinstance", "(", "se_cfg", ",", "dict", ")", "\n", "", "if", "not", "self", ".", "with_expand_conv", ":", "\n", "            ", "assert", "mid_channels", "==", "in_channels", "\n", "\n", "", "if", "self", ".", "with_expand_conv", ":", "\n", "            ", "self", ".", "expand_conv", "=", "ConvModule", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "mid_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "", "self", ".", "depthwise_conv", "=", "ConvModule", "(", "\n", "in_channels", "=", "mid_channels", ",", "\n", "out_channels", "=", "mid_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "kernel_size", "//", "2", ",", "\n", "groups", "=", "mid_channels", ",", "\n", "conv_cfg", "=", "dict", "(", "\n", "type", "=", "'Conv2dAdaptivePadding'", ")", "if", "stride", "==", "2", "else", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "\n", "if", "self", ".", "with_se", ":", "\n", "            ", "self", ".", "se", "=", "SELayer", "(", "**", "se_cfg", ")", "\n", "\n", "", "self", ".", "linear_conv", "=", "ConvModule", "(", "\n", "in_channels", "=", "mid_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.inverted_residual.InvertedResidualV3.forward": [[188, 214], ["inverted_residual.InvertedResidualV3.depthwise_conv", "inverted_residual.InvertedResidualV3.linear_conv", "torch.utils.checkpoint.checkpoint", "inverted_residual.InvertedResidualV3.forward._inner_forward"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "out", "=", "x", "\n", "\n", "if", "self", ".", "with_expand_conv", ":", "\n", "                ", "out", "=", "self", ".", "expand_conv", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "depthwise_conv", "(", "out", ")", "\n", "\n", "if", "self", ".", "with_se", ":", "\n", "                ", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "", "out", "=", "self", ".", "linear_conv", "(", "out", ")", "\n", "\n", "if", "self", ".", "with_res_shortcut", ":", "\n", "                ", "return", "x", "+", "out", "\n", "", "else", ":", "\n", "                ", "return", "out", "\n", "\n", "", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.ckpt_convert.swin_convert": [[5, 57], ["collections.OrderedDict", "ckpt.items", "x[].transpose().reshape.reshape", "x[].transpose().reshape", "x[].transpose().reshape.reshape", "x[].transpose().reshape", "k.startswith", "k.startswith", "x[].transpose", "x[].transpose", "k.replace.replace", "k.startswith", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "ckpt_convert.swin_convert.correct_unfold_reduction_order"], "function", ["None"], ["def", "swin_convert", "(", "ckpt", ")", ":", "\n", "    ", "new_ckpt", "=", "OrderedDict", "(", ")", "\n", "\n", "def", "correct_unfold_reduction_order", "(", "x", ")", ":", "\n", "        ", "out_channel", ",", "in_channel", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "out_channel", ",", "4", ",", "in_channel", "//", "4", ")", "\n", "x", "=", "x", "[", ":", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ",", ":", "]", ".", "transpose", "(", "1", ",", "\n", "2", ")", ".", "reshape", "(", "out_channel", ",", "in_channel", ")", "\n", "return", "x", "\n", "\n", "", "def", "correct_unfold_norm_order", "(", "x", ")", ":", "\n", "        ", "in_channel", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "x", ".", "reshape", "(", "4", ",", "in_channel", "//", "4", ")", "\n", "x", "=", "x", "[", "[", "0", ",", "2", ",", "1", ",", "3", "]", ",", ":", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "in_channel", ")", "\n", "return", "x", "\n", "\n", "", "for", "k", ",", "v", "in", "ckpt", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "continue", "\n", "", "elif", "k", ".", "startswith", "(", "'layers'", ")", ":", "\n", "            ", "new_v", "=", "v", "\n", "if", "'attn.'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'attn.'", ",", "'attn.w_msa.'", ")", "\n", "", "elif", "'mlp.'", "in", "k", ":", "\n", "                ", "if", "'mlp.fc1.'", "in", "k", ":", "\n", "                    ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc1.'", ",", "'ffn.layers.0.0.'", ")", "\n", "", "elif", "'mlp.fc2.'", "in", "k", ":", "\n", "                    ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc2.'", ",", "'ffn.layers.1.'", ")", "\n", "", "else", ":", "\n", "                    ", "new_k", "=", "k", ".", "replace", "(", "'mlp.'", ",", "'ffn.'", ")", "\n", "", "", "elif", "'downsample'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", "\n", "if", "'reduction.'", "in", "k", ":", "\n", "                    ", "new_v", "=", "correct_unfold_reduction_order", "(", "v", ")", "\n", "", "elif", "'norm.'", "in", "k", ":", "\n", "                    ", "new_v", "=", "correct_unfold_norm_order", "(", "v", ")", "\n", "", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "new_k", "=", "new_k", ".", "replace", "(", "'layers'", ",", "'stages'", ",", "1", ")", "\n", "", "elif", "k", ".", "startswith", "(", "'patch_embed'", ")", ":", "\n", "            ", "new_v", "=", "v", "\n", "if", "'proj'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'proj'", ",", "'projection'", ")", "\n", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "", "else", ":", "\n", "            ", "new_v", "=", "v", "\n", "new_k", "=", "k", "\n", "\n", "", "new_ckpt", "[", "new_k", "]", "=", "new_v", "\n", "\n", "", "return", "new_ckpt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.ckpt_convert.vit_convert": [[59, 92], ["collections.OrderedDict", "ckpt.items", "k.startswith", "k.startswith", "k.replace", "k.startswith", "k.startswith", "k.replace", "k.replace.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace"], "function", ["None"], ["", "def", "vit_convert", "(", "ckpt", ")", ":", "\n", "\n", "    ", "new_ckpt", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "ckpt", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "continue", "\n", "", "if", "k", ".", "startswith", "(", "'norm'", ")", ":", "\n", "            ", "new_k", "=", "k", ".", "replace", "(", "'norm.'", ",", "'ln1.'", ")", "\n", "", "elif", "k", ".", "startswith", "(", "'patch_embed'", ")", ":", "\n", "            ", "if", "'proj'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'proj'", ",", "'projection'", ")", "\n", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "", "elif", "k", ".", "startswith", "(", "'blocks'", ")", ":", "\n", "            ", "if", "'norm'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'norm'", ",", "'ln'", ")", "\n", "", "elif", "'mlp.fc1'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc1'", ",", "'ffn.layers.0.0'", ")", "\n", "", "elif", "'mlp.fc2'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc2'", ",", "'ffn.layers.1'", ")", "\n", "", "elif", "'attn.qkv'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'attn.qkv.'", ",", "'attn.attn.in_proj_'", ")", "\n", "", "elif", "'attn.proj'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'attn.proj'", ",", "'attn.attn.out_proj'", ")", "\n", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "new_k", "=", "new_k", ".", "replace", "(", "'blocks.'", ",", "'layers.'", ")", "\n", "", "else", ":", "\n", "            ", "new_k", "=", "k", "\n", "", "new_ckpt", "[", "new_k", "]", "=", "v", "\n", "\n", "", "return", "new_ckpt", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.AdaptivePadding.__init__": [[43, 57], ["torch.Module.__init__", "mmcv.utils.to_2tuple", "mmcv.utils.to_2tuple", "mmcv.utils.to_2tuple"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "padding", "=", "'corner'", ")", ":", "\n", "\n", "        ", "super", "(", "AdaptivePadding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "padding", "in", "(", "'same'", ",", "'corner'", ")", "\n", "\n", "kernel_size", "=", "to_2tuple", "(", "kernel_size", ")", "\n", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "dilation", "=", "to_2tuple", "(", "dilation", ")", "\n", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.AdaptivePadding.get_pad_shape": [[58, 69], ["math.ceil", "math.ceil", "max", "max"], "methods", ["None"], ["", "def", "get_pad_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "input_h", ",", "input_w", "=", "input_shape", "\n", "kernel_h", ",", "kernel_w", "=", "self", ".", "kernel_size", "\n", "stride_h", ",", "stride_w", "=", "self", ".", "stride", "\n", "output_h", "=", "math", ".", "ceil", "(", "input_h", "/", "stride_h", ")", "\n", "output_w", "=", "math", ".", "ceil", "(", "input_w", "/", "stride_w", ")", "\n", "pad_h", "=", "max", "(", "(", "output_h", "-", "1", ")", "*", "stride_h", "+", "\n", "(", "kernel_h", "-", "1", ")", "*", "self", ".", "dilation", "[", "0", "]", "+", "1", "-", "input_h", ",", "0", ")", "\n", "pad_w", "=", "max", "(", "(", "output_w", "-", "1", ")", "*", "stride_w", "+", "\n", "(", "kernel_w", "-", "1", ")", "*", "self", ".", "dilation", "[", "1", "]", "+", "1", "-", "input_w", ",", "0", ")", "\n", "return", "pad_h", ",", "pad_w", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.AdaptivePadding.forward": [[70, 81], ["embed.AdaptivePadding.get_pad_shape", "torch.pad.size", "torch.pad", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.AdaptivePadding.get_pad_shape"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pad_h", ",", "pad_w", "=", "self", ".", "get_pad_shape", "(", "x", ".", "size", "(", ")", "[", "-", "2", ":", "]", ")", "\n", "if", "pad_h", ">", "0", "or", "pad_w", ">", "0", ":", "\n", "            ", "if", "self", ".", "padding", "==", "'corner'", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "x", ",", "[", "0", ",", "pad_w", ",", "0", ",", "pad_h", "]", ")", "\n", "", "elif", "self", ".", "padding", "==", "'same'", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "x", ",", "[", "\n", "pad_w", "//", "2", ",", "pad_w", "-", "pad_w", "//", "2", ",", "pad_h", "//", "2", ",", "\n", "pad_h", "-", "pad_h", "//", "2", "\n", "]", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.PatchEmbed.__init__": [[228, 277], ["mmcv.runner.base_module.BaseModule.__init__", "isinstance", "mmcv.cnn.build_conv_layer", "mmcv.utils.to_2tuple", "isinstance", "dict", "mmcv.cnn.build_norm_layer", "len", "mmcv.utils.to_2tuple", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", "=", "3", ",", "\n", "embed_dims", "=", "768", ",", "\n", "conv_type", "=", "None", ",", "\n", "kernel_size", "=", "16", ",", "\n", "stride", "=", "16", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "\n", "pad_to_patch_size", "=", "True", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "PatchEmbed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embed_dims", "=", "embed_dims", "\n", "self", ".", "init_cfg", "=", "init_cfg", "\n", "\n", "if", "stride", "is", "None", ":", "\n", "            ", "stride", "=", "kernel_size", "\n", "\n", "", "self", ".", "pad_to_patch_size", "=", "pad_to_patch_size", "\n", "\n", "# The default setting of patch size is equal to kernel size.", "\n", "patch_size", "=", "kernel_size", "\n", "if", "isinstance", "(", "patch_size", ",", "int", ")", ":", "\n", "            ", "patch_size", "=", "to_2tuple", "(", "patch_size", ")", "\n", "", "elif", "isinstance", "(", "patch_size", ",", "tuple", ")", ":", "\n", "            ", "if", "len", "(", "patch_size", ")", "==", "1", ":", "\n", "                ", "patch_size", "=", "to_2tuple", "(", "patch_size", "[", "0", "]", ")", "\n", "", "assert", "len", "(", "patch_size", ")", "==", "2", ",", "f'The size of patch should have length 1 or 2, '", "f'but got {len(patch_size)}'", "\n", "\n", "", "self", ".", "patch_size", "=", "patch_size", "\n", "\n", "# Use conv layer to embed", "\n", "conv_type", "=", "conv_type", "or", "'Conv2d'", "\n", "self", ".", "projection", "=", "build_conv_layer", "(", "\n", "dict", "(", "type", "=", "conv_type", ")", ",", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "embed_dims", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ")", "\n", "\n", "if", "norm_cfg", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "build_norm_layer", "(", "norm_cfg", ",", "embed_dims", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.PatchEmbed.forward": [[278, 299], ["embed.PatchEmbed.projection", "torch.pad.flatten().transpose", "embed.PatchEmbed.norm", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad.flatten"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "H", ",", "W", "=", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", "\n", "\n", "# TODO: Process overlapping op", "\n", "if", "self", ".", "pad_to_patch_size", ":", "\n", "# Modify H, W to multiple of patch size.", "\n", "            ", "if", "H", "%", "self", ".", "patch_size", "[", "0", "]", "!=", "0", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "\n", "x", ",", "(", "0", ",", "0", ",", "0", ",", "self", ".", "patch_size", "[", "0", "]", "-", "H", "%", "self", ".", "patch_size", "[", "0", "]", ")", ")", "\n", "", "if", "W", "%", "self", ".", "patch_size", "[", "1", "]", "!=", "0", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "\n", "x", ",", "(", "0", ",", "self", ".", "patch_size", "[", "1", "]", "-", "W", "%", "self", ".", "patch_size", "[", "1", "]", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "", "x", "=", "self", ".", "projection", "(", "x", ")", "\n", "self", ".", "DH", ",", "self", ".", "DW", "=", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", "\n", "x", "=", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.PatchMerging.__init__": [[329, 377], ["dict", "mmcv.runner.base_module.BaseModule.__init__", "mmcv.utils.to_2tuple", "mmcv.utils.to_2tuple", "mmcv.utils.to_2tuple", "isinstance", "mmcv.utils.to_2tuple", "torch.Unfold", "torch.Unfold", "torch.Linear", "torch.Linear", "embed.AdaptivePadding", "mmcv.cnn.build_norm_layer"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "2", ",", "\n", "stride", "=", "None", ",", "\n", "padding", "=", "'corner'", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'LN'", ")", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "init_cfg", "=", "init_cfg", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "if", "stride", ":", "\n", "            ", "stride", "=", "stride", "\n", "", "else", ":", "\n", "            ", "stride", "=", "kernel_size", "\n", "\n", "", "kernel_size", "=", "to_2tuple", "(", "kernel_size", ")", "\n", "stride", "=", "to_2tuple", "(", "stride", ")", "\n", "dilation", "=", "to_2tuple", "(", "dilation", ")", "\n", "\n", "if", "isinstance", "(", "padding", ",", "str", ")", ":", "\n", "            ", "self", ".", "adap_padding", "=", "AdaptivePadding", "(", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "padding", "=", "padding", ")", "\n", "# disable the padding of unfold", "\n", "padding", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "adap_padding", "=", "None", "\n", "\n", "", "padding", "=", "to_2tuple", "(", "padding", ")", "\n", "self", ".", "sampler", "=", "nn", ".", "Unfold", "(", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "dilation", "=", "dilation", ",", "\n", "padding", "=", "padding", ",", "\n", "stride", "=", "stride", ")", "\n", "\n", "sample_dim", "=", "kernel_size", "[", "0", "]", "*", "kernel_size", "[", "1", "]", "*", "in_channels", "\n", "\n", "if", "norm_cfg", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "build_norm_layer", "(", "norm_cfg", ",", "sample_dim", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "\n", "", "self", ".", "reduction", "=", "nn", ".", "Linear", "(", "sample_dim", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.embed.PatchMerging.forward": [[378, 424], ["isinstance", "embed.PatchMerging.view().permute", "embed.PatchMerging.sampler", "embed.PatchMerging.transpose", "embed.PatchMerging.reduction", "embed.PatchMerging.adap_padding", "embed.PatchMerging.norm", "embed.PatchMerging.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): Has shape (B, H*W, C_in).\n            input_size (tuple[int]): The spatial shape of x, arrange as (H, W).\n                Default: None.\n\n        Returns:\n            tuple: Contains merged results and its spatial shape.\n\n                - x (Tensor): Has shape (B, Merged_H * Merged_W, C_out)\n                - out_size (tuple[int]): Spatial shape of x, arrange as\n                    (Merged_H, Merged_W).\n        \"\"\"", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "assert", "isinstance", "(", "input_size", ",", "Sequence", ")", ",", "f'Expect '", "f'input_size is '", "f'`Sequence` '", "f'but get {input_size}'", "\n", "\n", "H", ",", "W", "=", "input_size", "\n", "assert", "L", "==", "H", "*", "W", ",", "'input feature has wrong size'", "\n", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", ".", "permute", "(", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "# B, C, H, W", "\n", "# Use nn.Unfold to merge patch. About 25% faster than original method,", "\n", "# but need to modify pretrained model for compatibility", "\n", "\n", "if", "self", ".", "adap_padding", ":", "\n", "            ", "x", "=", "self", ".", "adap_padding", "(", "x", ")", "\n", "H", ",", "W", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "", "x", "=", "self", ".", "sampler", "(", "x", ")", "\n", "# if kernel_size=2 and stride=2, x should has shape (B, 4*C, H/2*W/2)", "\n", "\n", "out_h", "=", "(", "H", "+", "2", "*", "self", ".", "sampler", ".", "padding", "[", "0", "]", "-", "self", ".", "sampler", ".", "dilation", "[", "0", "]", "*", "\n", "(", "self", ".", "sampler", ".", "kernel_size", "[", "0", "]", "-", "1", ")", "-", "\n", "1", ")", "//", "self", ".", "sampler", ".", "stride", "[", "0", "]", "+", "1", "\n", "out_w", "=", "(", "W", "+", "2", "*", "self", ".", "sampler", ".", "padding", "[", "1", "]", "-", "self", ".", "sampler", ".", "dilation", "[", "1", "]", "*", "\n", "(", "self", ".", "sampler", ".", "kernel_size", "[", "1", "]", "-", "1", ")", "-", "\n", "1", ")", "//", "self", ".", "sampler", ".", "stride", "[", "1", "]", "+", "1", "\n", "\n", "output_size", "=", "(", "out_h", ",", "out_w", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# B, H/2*W/2, 4*C", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "if", "self", ".", "norm", "else", "x", "\n", "x", "=", "self", ".", "reduction", "(", "x", ")", "\n", "return", "x", ",", "output_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.make_divisible.make_divisible": [[2, 29], ["max", "int"], "function", ["None"], ["def", "make_divisible", "(", "value", ",", "divisor", ",", "min_value", "=", "None", ",", "min_ratio", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"Make divisible function.\n\n    This function rounds the channel number to the nearest value that can be\n    divisible by the divisor. It is taken from the original tf repo. It ensures\n    that all layers have a channel number that is divisible by divisor. It can\n    be seen here: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py  # noqa\n\n    Args:\n        value (int): The original channel number.\n        divisor (int): The divisor to fully divide the channel number.\n        min_value (int): The minimum value of the output channel.\n            Default: None, means that the minimum value equal to the divisor.\n        min_ratio (float): The minimum ratio of the rounded channel number to\n            the original channel number. Default: 0.9.\n\n    Returns:\n        int: The modified output channel number.\n    \"\"\"", "\n", "\n", "if", "min_value", "is", "None", ":", "\n", "        ", "min_value", "=", "divisor", "\n", "", "new_value", "=", "max", "(", "min_value", ",", "int", "(", "value", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than (1-min_ratio).", "\n", "if", "new_value", "<", "min_ratio", "*", "value", ":", "\n", "        ", "new_value", "+=", "divisor", "\n", "", "return", "new_value", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.se_layer.SELayer.__init__": [[27, 53], ["torch.Module.__init__", "isinstance", "mmcv.is_tuple_of", "torch.AdaptiveAvgPool2d", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "dict", "dict", "len", "make_divisible.make_divisible.make_divisible", "make_divisible.make_divisible.make_divisible"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.make_divisible.make_divisible", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.make_divisible.make_divisible"], ["def", "__init__", "(", "self", ",", "\n", "channels", ",", "\n", "ratio", "=", "16", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "act_cfg", "=", "(", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "dict", "(", "type", "=", "'HSigmoid'", ",", "bias", "=", "3.0", ",", "divisor", "=", "6.0", ")", ")", ")", ":", "\n", "        ", "super", "(", "SELayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "act_cfg", ",", "dict", ")", ":", "\n", "            ", "act_cfg", "=", "(", "act_cfg", ",", "act_cfg", ")", "\n", "", "assert", "len", "(", "act_cfg", ")", "==", "2", "\n", "assert", "mmcv", ".", "is_tuple_of", "(", "act_cfg", ",", "dict", ")", "\n", "self", ".", "global_avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "conv1", "=", "ConvModule", "(", "\n", "in_channels", "=", "channels", ",", "\n", "out_channels", "=", "make_divisible", "(", "channels", "//", "ratio", ",", "8", ")", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "act_cfg", "=", "act_cfg", "[", "0", "]", ")", "\n", "self", ".", "conv2", "=", "ConvModule", "(", "\n", "in_channels", "=", "make_divisible", "(", "channels", "//", "ratio", ",", "8", ")", ",", "\n", "out_channels", "=", "channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "act_cfg", "=", "act_cfg", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.se_layer.SELayer.forward": [[54, 59], ["se_layer.SELayer.global_avgpool", "se_layer.SELayer.conv1", "se_layer.SELayer.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "global_avgpool", "(", "x", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "return", "x", "*", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.shape_convert.nlc_to_nchw": [[2, 17], ["x.transpose().reshape", "len", "x.transpose"], "function", ["None"], ["def", "nlc_to_nchw", "(", "x", ",", "hw_shape", ")", ":", "\n", "    ", "\"\"\"Convert [N, L, C] shape tensor to [N, C, H, W] shape tensor.\n\n    Args:\n        x (Tensor): The input tensor of shape [N, L, C] before conversion.\n        hw_shape (Sequence[int]): The height and width of output feature map.\n\n    Returns:\n        Tensor: The output tensor of shape [N, C, H, W] after conversion.\n    \"\"\"", "\n", "H", ",", "W", "=", "hw_shape", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "3", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "assert", "L", "==", "H", "*", "W", ",", "'The seq_len doesn\\'t match H, W'", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.shape_convert.nchw_to_nlc": [[19, 30], ["x.flatten().transpose().contiguous", "len", "x.flatten().transpose", "x.flatten"], "function", ["None"], ["", "def", "nchw_to_nlc", "(", "x", ")", ":", "\n", "    ", "\"\"\"Flatten [N, C, H, W] shape tensor to [N, L, C] shape tensor.\n\n    Args:\n        x (Tensor): The input tensor of shape [N, C, H, W] before conversion.\n\n    Returns:\n        Tensor: The output tensor of shape [N, L, C] after conversion.\n    \"\"\"", "\n", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "\n", "return", "x", ".", "flatten", "(", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.up_conv_block.UpConvBlock.__init__": [[45, 94], ["dict", "dict", "dict", "torch.Module.__init__", "conv_block", "mmcv.cnn.build_upsample_layer", "mmcv.cnn.ConvModule"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "conv_block", ",", "\n", "in_channels", ",", "\n", "skip_channels", ",", "\n", "out_channels", ",", "\n", "num_convs", "=", "2", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "with_cp", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "upsample_cfg", "=", "dict", "(", "type", "=", "'InterpConv'", ")", ",", "\n", "dcn", "=", "None", ",", "\n", "plugins", "=", "None", ")", ":", "\n", "        ", "super", "(", "UpConvBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "dcn", "is", "None", ",", "'Not implemented yet.'", "\n", "assert", "plugins", "is", "None", ",", "'Not implemented yet.'", "\n", "\n", "self", ".", "conv_block", "=", "conv_block", "(", "\n", "in_channels", "=", "2", "*", "skip_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "num_convs", "=", "num_convs", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "dcn", "=", "None", ",", "\n", "plugins", "=", "None", ")", "\n", "if", "upsample_cfg", "is", "not", "None", ":", "\n", "            ", "self", ".", "upsample", "=", "build_upsample_layer", "(", "\n", "cfg", "=", "upsample_cfg", ",", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "skip_channels", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "upsample", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "skip_channels", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.up_conv_block.UpConvBlock.forward": [[95, 103], ["up_conv_block.UpConvBlock.upsample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "up_conv_block.UpConvBlock.conv_block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "skip", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "\n", "x", "=", "self", ".", "upsample", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "skip", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "conv_block", "(", "out", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.res_layer.ResLayer.__init__": [[28, 97], ["dict", "layers.append", "range", "mmcv.runner.Sequential.__init__", "torch.nn.Sequential.extend", "torch.nn.Sequential", "block", "layers.append", "torch.nn.Sequential.append", "block", "torch.nn.AvgPool2d", "mmcv.cnn.build_conv_layer", "mmcv.cnn.build_norm_layer"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "num_blocks", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "avg_down", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "multi_grid", "=", "None", ",", "\n", "contract_dilation", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "block", "=", "block", "\n", "\n", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "[", "]", "\n", "conv_stride", "=", "stride", "\n", "if", "avg_down", ":", "\n", "                ", "conv_stride", "=", "1", "\n", "downsample", ".", "append", "(", "\n", "nn", ".", "AvgPool2d", "(", "\n", "kernel_size", "=", "stride", ",", "\n", "stride", "=", "stride", ",", "\n", "ceil_mode", "=", "True", ",", "\n", "count_include_pad", "=", "False", ")", ")", "\n", "", "downsample", ".", "extend", "(", "[", "\n", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "conv_stride", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "norm_cfg", ",", "planes", "*", "block", ".", "expansion", ")", "[", "1", "]", "\n", "]", ")", "\n", "downsample", "=", "nn", ".", "Sequential", "(", "*", "downsample", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "if", "multi_grid", "is", "None", ":", "\n", "            ", "if", "dilation", ">", "1", "and", "contract_dilation", ":", "\n", "                ", "first_dilation", "=", "dilation", "//", "2", "\n", "", "else", ":", "\n", "                ", "first_dilation", "=", "dilation", "\n", "", "", "else", ":", "\n", "            ", "first_dilation", "=", "multi_grid", "[", "0", "]", "\n", "", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "first_dilation", ",", "\n", "downsample", "=", "downsample", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "num_blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "inplanes", "=", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "dilation", "if", "multi_grid", "is", "None", "else", "multi_grid", "[", "i", "]", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "**", "kwargs", ")", ")", "\n", "", "super", "(", "ResLayer", ",", "self", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.__init__": [[33, 93], ["torch.nn.Module.__init__", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.build_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.build_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.init_weights", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.build_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.build_project"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.build_project", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.build_project", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinTransformer.init_weights", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.build_project", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.build_project"], ["def", "__init__", "(", "self", ",", "key_in_channels", ",", "query_in_channels", ",", "channels", ",", "\n", "out_channels", ",", "share_key_query", ",", "query_downsample", ",", "\n", "key_downsample", ",", "key_query_num_convs", ",", "value_out_num_convs", ",", "\n", "key_query_norm", ",", "value_out_norm", ",", "matmul_norm", ",", "with_out", ",", "\n", "conv_cfg", ",", "norm_cfg", ",", "act_cfg", ")", ":", "\n", "        ", "super", "(", "SelfAttentionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "share_key_query", ":", "\n", "            ", "assert", "key_in_channels", "==", "query_in_channels", "\n", "", "self", ".", "key_in_channels", "=", "key_in_channels", "\n", "self", ".", "query_in_channels", "=", "query_in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "share_key_query", "=", "share_key_query", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "key_project", "=", "self", ".", "build_project", "(", "\n", "key_in_channels", ",", "\n", "channels", ",", "\n", "num_convs", "=", "key_query_num_convs", ",", "\n", "use_conv_module", "=", "key_query_norm", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "if", "share_key_query", ":", "\n", "            ", "self", ".", "query_project", "=", "self", ".", "key_project", "\n", "", "else", ":", "\n", "            ", "self", ".", "query_project", "=", "self", ".", "build_project", "(", "\n", "query_in_channels", ",", "\n", "channels", ",", "\n", "num_convs", "=", "key_query_num_convs", ",", "\n", "use_conv_module", "=", "key_query_norm", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "", "self", ".", "value_project", "=", "self", ".", "build_project", "(", "\n", "key_in_channels", ",", "\n", "channels", "if", "with_out", "else", "out_channels", ",", "\n", "num_convs", "=", "value_out_num_convs", ",", "\n", "use_conv_module", "=", "value_out_norm", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "if", "with_out", ":", "\n", "            ", "self", ".", "out_project", "=", "self", ".", "build_project", "(", "\n", "channels", ",", "\n", "out_channels", ",", "\n", "num_convs", "=", "value_out_num_convs", ",", "\n", "use_conv_module", "=", "value_out_norm", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_project", "=", "None", "\n", "\n", "", "self", ".", "query_downsample", "=", "query_downsample", "\n", "self", ".", "key_downsample", "=", "key_downsample", "\n", "self", ".", "matmul_norm", "=", "matmul_norm", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.init_weights": [[94, 99], ["isinstance", "mmcv.cnn.constant_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize weight of later layer.\"\"\"", "\n", "if", "self", ".", "out_project", "is", "not", "None", ":", "\n", "            ", "if", "not", "isinstance", "(", "self", ".", "out_project", ",", "ConvModule", ")", ":", "\n", "                ", "constant_init", "(", "self", ".", "out_project", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.build_project": [[100, 131], ["range", "range", "len", "torch.nn.Sequential", "mmcv.cnn.ConvModule", "torch.nn.Sequential.append", "torch.nn.Conv2d", "torch.nn.Sequential.append", "mmcv.cnn.ConvModule", "torch.nn.Conv2d"], "methods", ["None"], ["", "", "", "def", "build_project", "(", "self", ",", "in_channels", ",", "channels", ",", "num_convs", ",", "use_conv_module", ",", "\n", "conv_cfg", ",", "norm_cfg", ",", "act_cfg", ")", ":", "\n", "        ", "\"\"\"Build projection layer for key/query/value/out.\"\"\"", "\n", "if", "use_conv_module", ":", "\n", "            ", "convs", "=", "[", "\n", "ConvModule", "(", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", "\n", "]", "\n", "for", "_", "in", "range", "(", "num_convs", "-", "1", ")", ":", "\n", "                ", "convs", ".", "append", "(", "\n", "ConvModule", "(", "\n", "channels", ",", "\n", "channels", ",", "\n", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "convs", "=", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", ",", "1", ")", "]", "\n", "for", "_", "in", "range", "(", "num_convs", "-", "1", ")", ":", "\n", "                ", "convs", ".", "append", "(", "nn", ".", "Conv2d", "(", "channels", ",", "channels", ",", "1", ")", ")", "\n", "", "", "if", "len", "(", "convs", ")", ">", "1", ":", "\n", "            ", "convs", "=", "nn", ".", "Sequential", "(", "*", "convs", ")", "\n", "", "else", ":", "\n", "            ", "convs", "=", "convs", "[", "0", "]", "\n", "", "return", "convs", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.self_attention_block.SelfAttentionBlock.forward": [[132, 161], ["query_feats.size", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.query_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.reshape", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.permute().contiguous", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.key_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.value_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.reshape", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.reshape", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.permute().contiguous", "torch.matmul", "torch.nn.functional.softmax", "torch.matmul", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.permute().contiguous", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.reshape", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.query_downsample", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.key_downsample", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.key_downsample", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.out_project", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.permute", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.permute", "self_attention_block.SelfAttentionBlock.SelfAttentionBlock.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query_feats", ",", "key_feats", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "batch_size", "=", "query_feats", ".", "size", "(", "0", ")", "\n", "query", "=", "self", ".", "query_project", "(", "query_feats", ")", "\n", "if", "self", ".", "query_downsample", "is", "not", "None", ":", "\n", "            ", "query", "=", "self", ".", "query_downsample", "(", "query", ")", "\n", "", "query", "=", "query", ".", "reshape", "(", "*", "query", ".", "shape", "[", ":", "2", "]", ",", "-", "1", ")", "\n", "query", "=", "query", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "key", "=", "self", ".", "key_project", "(", "key_feats", ")", "\n", "value", "=", "self", ".", "value_project", "(", "key_feats", ")", "\n", "if", "self", ".", "key_downsample", "is", "not", "None", ":", "\n", "            ", "key", "=", "self", ".", "key_downsample", "(", "key", ")", "\n", "value", "=", "self", ".", "key_downsample", "(", "value", ")", "\n", "", "key", "=", "key", ".", "reshape", "(", "*", "key", ".", "shape", "[", ":", "2", "]", ",", "-", "1", ")", "\n", "value", "=", "value", ".", "reshape", "(", "*", "value", ".", "shape", "[", ":", "2", "]", ",", "-", "1", ")", "\n", "value", "=", "value", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "sim_map", "=", "torch", ".", "matmul", "(", "query", ",", "key", ")", "\n", "if", "self", ".", "matmul_norm", ":", "\n", "            ", "sim_map", "=", "(", "self", ".", "channels", "**", "-", ".5", ")", "*", "sim_map", "\n", "", "sim_map", "=", "F", ".", "softmax", "(", "sim_map", ",", "dim", "=", "-", "1", ")", "\n", "\n", "context", "=", "torch", ".", "matmul", "(", "sim_map", ",", "value", ")", "\n", "context", "=", "context", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "context", "=", "context", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "*", "query_feats", ".", "shape", "[", "2", ":", "]", ")", "\n", "if", "self", ".", "out_project", "is", "not", "None", ":", "\n", "            ", "context", "=", "self", ".", "out_project", "(", "context", ")", "\n", "", "return", "context", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix": [[2, 19], ["dict", "inputs.items"], "function", ["None"], ["def", "add_prefix", "(", "inputs", ",", "prefix", ")", ":", "\n", "    ", "\"\"\"Add prefix for dict.\n\n    Args:\n        inputs (dict): The input dict with str keys.\n        prefix (str): The prefix to add.\n\n    Returns:\n\n        dict: The dict with keys updated with ``prefix``.\n    \"\"\"", "\n", "\n", "outputs", "=", "dict", "(", ")", "\n", "for", "name", ",", "value", "in", "inputs", ".", "items", "(", ")", ":", "\n", "        ", "outputs", "[", "f'{prefix}.{name}'", "]", "=", "value", "\n", "\n", "", "return", "outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.KittiRawDataset.__init__": [[50, 56], ["custom.CustomDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "KittiRawDataset", ",", "self", ")", ".", "__init__", "(", "\n", "img_suffix", "=", "'.png'", ",", "\n", "seg_map_suffix", "=", "'.png'", ",", "\n", "reduce_zero_label", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.KittiRawDataset.results2img": [[57, 93], ["mmcv.mkdir_or_exist", "mmcv.ProgressBar", "range", "len", "len", "os.join", "os.join", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "result_files.append", "mmcv.ProgressBar.update", "os.splitext", "os.splitext", "result.astype", "os.basename", "os.basename"], "methods", ["None"], ["", "def", "results2img", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "to_label_id", ")", ":", "\n", "        ", "\"\"\"Write the segmentation results to images.\n\n        Args:\n            results (list[list | tuple | ndarray]): Testing results of the\n                dataset.\n            imgfile_prefix (str): The filename prefix of the png files.\n                If the prefix is \"somepath/xxx\",\n                the png files will be named \"somepath/xxx.png\".\n            to_label_id (bool): whether convert output to label_id for\n                submission\n\n        Returns:\n            list[str: str]: result txt files which contains corresponding\n            semantic segmentation images.\n        \"\"\"", "\n", "mmcv", ".", "mkdir_or_exist", "(", "imgfile_prefix", ")", "\n", "result_files", "=", "[", "]", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "self", ")", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "result", "=", "results", "[", "idx", "]", "\n", "\n", "filename", "=", "self", ".", "img_infos", "[", "idx", "]", "[", "'filename'", "]", "\n", "basename", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "filename", ")", ")", "[", "0", "]", "\n", "\n", "png_filename", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "f'{basename}.png'", ")", "\n", "\n", "result", "=", "result", "+", "1", "\n", "\n", "output", "=", "Image", ".", "fromarray", "(", "result", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "output", ".", "save", "(", "png_filename", ")", "\n", "result_files", ".", "append", "(", "png_filename", ")", "\n", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n", "", "return", "result_files", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.KittiRawDataset.prepare_test_img": [[94, 110], ["kittiraw.KittiRawDataset.get_ann_info", "dict", "kittiraw.KittiRawDataset.pre_pipeline", "kittiraw.KittiRawDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n                introduced by pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.KittiRawDataset.format_results": [[111, 151], ["isinstance", "os.join", "os.join", "mmcv.utils.print_log", "tqdm.trange", "os.exists", "os.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "numpy.invert", "numpy.concatenate", "kittiraw.visualize_map_mask", "kittiraw.visualize_map_mask", "mmcv.imread", "mmcv.imresize", "numpy.concatenate", "os.join", "os.join", "mmcv.imwrite", "os.path.basename", "os.path.basename", "os.path.basename", "os.path.basename", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", "=", "None", ",", "to_label_id", "=", "True", ")", ":", "\n", "        ", "\"\"\"Format the results into dir for visualization.\n\n        Args:\n            results (list): Testing results of the dataset.\n            imgfile_prefix (str | None): The prefix of images files. It\n                includes the file path and the prefix of filename, e.g.,\n                \"a/b/prefix\". If not specified, a temp file will be created.\n                Default: None.\n            to_label_id (bool): whether convert output to label_id for\n                submission. Default: False\n\n        Returns:\n            tuple: (result_files, tmp_dir), result_files is a list containing\n               the image paths, tmp_dir is the temporal directory created\n                for saving json/png files when img_prefix is not specified.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", ",", "'results must be a list'", "\n", "\n", "imgfile_prefix", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "'vis'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "imgfile_prefix", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "imgfile_prefix", ")", "\n", "", "print_log", "(", "'\\n Start formatting the result'", ")", "\n", "\n", "for", "id", "in", "trange", "(", "len", "(", "results", ")", ")", ":", "\n", "            ", "pred", ",", "gt", ",", "img_path", "=", "results", "[", "id", "]", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "pred", ".", "shape", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "1", "and", "gt", ".", "shape", "[", "0", "]", "==", "1", "\n", "pred", "=", "pred", "[", "0", "]", "\n", "gt", "=", "gt", "[", "0", "]", "\n", "gt", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt", "[", "-", "1", ",", "...", "]", ")", "\n", "pred", "=", "np", ".", "concatenate", "(", "[", "pred", ",", "gt", "[", "-", "1", ",", "...", "]", "[", "None", ",", "...", "]", "]", ",", "axis", "=", "0", ")", "\n", "pred_vis", "=", "visualize_map_mask", "(", "pred", ")", "\n", "gt_vis", "=", "visualize_map_mask", "(", "gt", ")", "\n", "img", "=", "mmcv", ".", "imread", "(", "img_path", ",", "backend", "=", "'cv2'", ")", "\n", "img", "=", "mmcv", ".", "imresize", "(", "img", ",", "(", "int", "(", "float", "(", "img", ".", "shape", "[", "1", "]", ")", "*", "h", "/", "float", "(", "img", ".", "shape", "[", "0", "]", ")", ")", ",", "h", ")", ")", "\n", "vis", "=", "np", ".", "concatenate", "(", "[", "img", ",", "pred_vis", "[", ":", ":", "-", "1", ",", "...", "]", ",", "gt_vis", "[", ":", ":", "-", "1", ",", "]", "]", ",", "axis", "=", "1", ")", "\n", "save_path", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "os", ".", "path", ".", "basename", "(", "img_path", ")", ")", "\n", "mmcv", ".", "imwrite", "(", "vis", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.KittiRawDataset.evaluate": [[152, 219], ["isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "set().issubset", "KeyError", "set", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "set", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "torch.cat.sum", "ious.mean", "iou_c.mean.mean.mean", "torch.cat.sum().float", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.sum", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'mIoU'", ",", "\n", "logger", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the evaluate result according to the metric type.\n\n            Args:\n                results (list): Testing results of the dataset.\n                metric (str | list[str]): Type of evalutate metric, mIoU is in consistent\n                    with \"Predicting Semantic Map Representations from Images with\n                    Pyramid Occupancy Networks. CVPR2020\", where per class fp,fn,tp are\n                    calculated on the hold dataset first. mIOUv1 calculates the per\n                    class iou in each image first and average the result between the\n                    valid images (i.e. for class c, there is positive sample point in\n                    this image). mIOUv2 calculates the per image iou first and average\n                    the result between all images.\n                logger (logging.Logger | None | str): Logger used for printing\n                    related information during evaluation. Default: None.\n\n            Returns:\n                tuple: (result_files, tmp_dir), result_files is a list containing\n                   the image paths, tmp_dir is the temporal directory created\n                    for saving json/png files when img_prefix is not specified.\n            \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metric", "=", "[", "metric", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mIoUv1'", ",", "'mIoUv2'", ",", "'mAP'", "]", "\n", "if", "not", "set", "(", "metric", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "            ", "raise", "KeyError", "(", "'metric {} is not supported'", ".", "format", "(", "metric", ")", ")", "\n", "", "tp", "=", "torch", ".", "cat", "(", "[", "res", "[", "0", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fp", "=", "torch", ".", "cat", "(", "[", "res", "[", "1", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fn", "=", "torch", ".", "cat", "(", "[", "res", "[", "2", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "valids", "=", "torch", ".", "cat", "(", "[", "res", "[", "3", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "for", "met", "in", "metric", ":", "\n", "            ", "if", "met", "==", "'mIoU'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", "+", "fn", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "print_log", "(", "'%.04f:%s tp:%d fp:%d fn:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fn", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv1'", ":", "\n", "                ", "ious", "=", "tp", ".", "float", "(", ")", "/", "(", "tp", "+", "fp", "+", "fn", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "miou", ",", "valid_class", "=", "0", ",", "0", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "iou_c", "=", "ious", "[", ":", ",", "cid", "]", "[", "valids", "[", ":", ",", "cid", "]", "]", "\n", "if", "iou_c", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                        ", "iou_c", "=", "iou_c", ".", "mean", "(", ")", "\n", "miou", "+=", "iou_c", "\n", "valid_class", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "iou_c", "=", "-", "1", "\n", "", "print_log", "(", "'%.04f:%s'", "%", "(", "iou_c", ",", "self", ".", "CLASSES", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "miou", "/", "valid_class", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv2'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "-", "1", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "-", "1", ")", "+", "fp", ".", "sum", "(", "-", "1", ")", "+", "fn", ".", "sum", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\n%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mAP'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "print_log", "(", "'%.04f:%s tp:%d fp:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "'nuknown metric type %s'", "%", "metric", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.covert_color": [[17, 25], ["int", "int", "int"], "function", ["None"], ["def", "covert_color", "(", "input", ")", ":", "\n", "    ", "str1", "=", "input", "[", "1", ":", "3", "]", "\n", "str2", "=", "input", "[", "3", ":", "5", "]", "\n", "str3", "=", "input", "[", "5", ":", "7", "]", "\n", "r", "=", "int", "(", "'0x'", "+", "str1", ",", "16", ")", "\n", "g", "=", "int", "(", "'0x'", "+", "str2", ",", "16", ")", "\n", "b", "=", "int", "(", "'0x'", "+", "str3", ",", "16", ")", "\n", "return", "(", "r", ",", "g", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiraw.visualize_map_mask": [[26, 37], ["numpy.zeros", "vis.reshape.reshape", "map_mask.reshape.reshape", "range", "vis.reshape.reshape", "range", "numpy.where", "kittiraw.covert_color"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.covert_color"], ["", "def", "visualize_map_mask", "(", "map_mask", ")", ":", "\n", "    ", "color_map", "=", "[", "'#a6cee3'", ",", "'#303030'", "]", "\n", "ori_shape", "=", "map_mask", ".", "shape", "\n", "vis", "=", "np", ".", "zeros", "(", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "vis", "=", "vis", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "map_mask", "=", "map_mask", ".", "reshape", "(", "ori_shape", "[", "0", "]", ",", "-", "1", ")", "\n", "for", "layer_id", "in", "range", "(", "map_mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "keep", "=", "np", ".", "where", "(", "map_mask", "[", "layer_id", ",", ":", "]", ")", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "vis", "[", "keep", ",", "2", "-", "i", "]", "=", "covert_color", "(", "color_map", "[", "layer_id", "]", ")", "[", "i", "]", "\n", "", "", "return", "vis", ".", "reshape", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.__init__": [[77, 125], ["pipelines.Compose", "custom.CustomDataset.get_classes_and_palette", "custom.CustomDataset.load_annotations", "pipelines.LoadAnnotations", "pipelines.LoadAnnotations", "os.isabs", "os.join", "os.join", "os.join", "os.isabs", "os.isabs"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_classes_and_palette", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.load_annotations"], ["def", "__init__", "(", "self", ",", "\n", "pipeline", ",", "\n", "img_dir", ",", "\n", "img_suffix", "=", "'.jpg'", ",", "\n", "ann_dir", "=", "None", ",", "\n", "seg_map_suffix", "=", "'.png'", ",", "\n", "split", "=", "None", ",", "\n", "data_root", "=", "None", ",", "\n", "test_mode", "=", "False", ",", "\n", "ignore_index", "=", "255", ",", "\n", "reduce_zero_label", "=", "False", ",", "\n", "classes", "=", "None", ",", "\n", "palette", "=", "None", ",", "\n", "gt_seg_map_loader_cfg", "=", "None", ")", ":", "\n", "        ", "self", ".", "pipeline", "=", "Compose", "(", "pipeline", ")", "\n", "self", ".", "img_dir", "=", "img_dir", "\n", "self", ".", "img_suffix", "=", "img_suffix", "\n", "self", ".", "ann_dir", "=", "ann_dir", "\n", "self", ".", "seg_map_suffix", "=", "seg_map_suffix", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "data_root", "=", "data_root", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "self", ".", "reduce_zero_label", "=", "reduce_zero_label", "\n", "self", ".", "label_map", "=", "None", "\n", "self", ".", "CLASSES", ",", "self", ".", "PALETTE", "=", "self", ".", "get_classes_and_palette", "(", "\n", "classes", ",", "palette", ")", "\n", "self", ".", "gt_seg_map_loader", "=", "LoadAnnotations", "(", "\n", ")", "if", "gt_seg_map_loader_cfg", "is", "None", "else", "LoadAnnotations", "(", "\n", "**", "gt_seg_map_loader_cfg", ")", "\n", "\n", "if", "test_mode", ":", "\n", "            ", "assert", "self", ".", "CLASSES", "is", "not", "None", ",", "'`cls.CLASSES` or `classes` should be specified when testing'", "\n", "\n", "# join paths if data_root is specified", "\n", "", "if", "self", ".", "data_root", "is", "not", "None", ":", "\n", "            ", "if", "not", "osp", ".", "isabs", "(", "self", ".", "img_dir", ")", ":", "\n", "                ", "self", ".", "img_dir", "=", "osp", ".", "join", "(", "self", ".", "data_root", ",", "self", ".", "img_dir", ")", "\n", "", "if", "not", "(", "self", ".", "ann_dir", "is", "None", "or", "osp", ".", "isabs", "(", "self", ".", "ann_dir", ")", ")", ":", "\n", "                ", "self", ".", "ann_dir", "=", "osp", ".", "join", "(", "self", ".", "data_root", ",", "self", ".", "ann_dir", ")", "\n", "", "if", "not", "(", "self", ".", "split", "is", "None", "or", "osp", ".", "isabs", "(", "self", ".", "split", ")", ")", ":", "\n", "                ", "self", ".", "split", "=", "osp", ".", "join", "(", "self", ".", "data_root", ",", "self", ".", "split", ")", "\n", "\n", "# load annotations", "\n", "", "", "self", ".", "img_infos", "=", "self", ".", "load_annotations", "(", "self", ".", "img_dir", ",", "self", ".", "img_suffix", ",", "\n", "self", ".", "ann_dir", ",", "\n", "self", ".", "seg_map_suffix", ",", "self", ".", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.__len__": [[126, 129], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Total number of samples of data.\"\"\"", "\n", "return", "len", "(", "self", ".", "img_infos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.load_annotations": [[130, 168], ["mmcv.utils.print_log", "mmcv.scandir", "sorted", "open", "dict", "sorted.append", "mmseg.utils.get_root_logger", "line.strip", "dict", "sorted.append", "img.replace", "dict", "len", "dict"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.logger.get_root_logger"], ["", "def", "load_annotations", "(", "self", ",", "img_dir", ",", "img_suffix", ",", "ann_dir", ",", "seg_map_suffix", ",", "\n", "split", ")", ":", "\n", "        ", "\"\"\"Load annotation from directory.\n\n        Args:\n            img_dir (str): Path to image directory\n            img_suffix (str): Suffix of images.\n            ann_dir (str|None): Path to annotation directory.\n            seg_map_suffix (str|None): Suffix of segmentation maps.\n            split (str|None): Split txt file. If split is specified, only file\n                with suffix in the splits will be loaded. Otherwise, all images\n                in img_dir/ann_dir will be loaded. Default: None\n\n        Returns:\n            list[dict]: All image info of dataset.\n        \"\"\"", "\n", "\n", "img_infos", "=", "[", "]", "\n", "if", "split", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "split", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "img_name", "=", "line", ".", "strip", "(", ")", "\n", "img_info", "=", "dict", "(", "filename", "=", "img_name", "+", "img_suffix", ")", "\n", "if", "ann_dir", "is", "not", "None", ":", "\n", "                        ", "seg_map", "=", "img_name", "+", "seg_map_suffix", "\n", "img_info", "[", "'ann'", "]", "=", "dict", "(", "seg_map", "=", "seg_map", ")", "\n", "", "img_infos", ".", "append", "(", "img_info", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "img", "in", "mmcv", ".", "scandir", "(", "img_dir", ",", "img_suffix", ",", "recursive", "=", "True", ")", ":", "\n", "                ", "img_info", "=", "dict", "(", "filename", "=", "img", ")", "\n", "if", "ann_dir", "is", "not", "None", ":", "\n", "                    ", "seg_map", "=", "img", ".", "replace", "(", "img_suffix", ",", "seg_map_suffix", ")", "\n", "img_info", "[", "'ann'", "]", "=", "dict", "(", "seg_map", "=", "seg_map", ")", "\n", "", "img_infos", ".", "append", "(", "img_info", ")", "\n", "", "img_infos", "=", "sorted", "(", "img_infos", ",", "key", "=", "lambda", "x", ":", "x", "[", "'filename'", "]", ")", "\n", "\n", "", "print_log", "(", "f'Loaded {len(img_infos)} images'", ",", "logger", "=", "get_root_logger", "(", ")", ")", "\n", "return", "img_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info": [[169, 180], ["None"], "methods", ["None"], ["", "def", "get_ann_info", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get annotation by index.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Annotation info of specified index.\n        \"\"\"", "\n", "\n", "return", "self", ".", "img_infos", "[", "idx", "]", "[", "'ann'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline": [[181, 188], ["None"], "methods", ["None"], ["", "def", "pre_pipeline", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Prepare results dict for pipeline.\"\"\"", "\n", "results", "[", "'seg_fields'", "]", "=", "[", "]", "\n", "results", "[", "'img_prefix'", "]", "=", "self", ".", "img_dir", "\n", "results", "[", "'seg_prefix'", "]", "=", "self", ".", "ann_dir", "\n", "if", "self", ".", "custom_classes", ":", "\n", "            ", "results", "[", "'label_map'", "]", "=", "self", ".", "label_map", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.__getitem__": [[189, 204], ["custom.CustomDataset.prepare_test_img", "custom.CustomDataset.prepare_train_img"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.prepare_test_img", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.prepare_train_img"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training/test data after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training/test data (with annotation if `test_mode` is set\n                False).\n        \"\"\"", "\n", "\n", "if", "self", ".", "test_mode", ":", "\n", "            ", "return", "self", ".", "prepare_test_img", "(", "idx", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "prepare_train_img", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.prepare_train_img": [[205, 221], ["custom.CustomDataset.get_ann_info", "dict", "custom.CustomDataset.pre_pipeline", "custom.CustomDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "", "def", "prepare_train_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n                introduced by pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.prepare_test_img": [[222, 237], ["dict", "custom.CustomDataset.pre_pipeline", "custom.CustomDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get testing data after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Testing data after pipeline with new keys introduced by\n                pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.format_results": [[238, 241], ["None"], "methods", ["None"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "indices", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Place holder to format result to dataset specific output.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_gt_seg_map_by_idx": [[242, 249], ["custom.CustomDataset.get_ann_info", "dict", "custom.CustomDataset.pre_pipeline", "custom.CustomDataset.gt_seg_map_loader"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "get_gt_seg_map_by_idx", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Get one ground truth segmentation map for evaluation.\"\"\"", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "index", ")", "\n", "results", "=", "dict", "(", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "self", ".", "gt_seg_map_loader", "(", "results", ")", "\n", "return", "results", "[", "'gt_semantic_seg'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_gt_seg_maps": [[250, 264], ["range", "warnings.warn", "len", "custom.CustomDataset.get_ann_info", "dict", "custom.CustomDataset.pre_pipeline", "custom.CustomDataset.gt_seg_map_loader"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "get_gt_seg_maps", "(", "self", ",", "efficient_test", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get ground truth segmentation maps for evaluation.\"\"\"", "\n", "if", "efficient_test", "is", "not", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'DeprecationWarning: ``efficient_test`` has been deprecated '", "\n", "'since MMSeg v0.16, the ``get_gt_seg_maps()`` is CPU memory '", "\n", "'friendly by default. '", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "self", ".", "gt_seg_map_loader", "(", "results", ")", "\n", "yield", "results", "[", "'gt_semantic_seg'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_eval": [[265, 294], ["zip", "isinstance", "isinstance", "custom.CustomDataset.get_gt_seg_map_by_idx", "pre_eval_results.append", "mmseg.core.intersect_and_union", "len"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_gt_seg_map_by_idx", "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.intersect_and_union"], ["", "", "def", "pre_eval", "(", "self", ",", "preds", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Collect eval result from each iteration.\n\n        Args:\n            preds (list[torch.Tensor] | torch.Tensor): the segmentation logit\n                after argmax, shape (N, H, W).\n            indices (list[int] | int): the prediction related ground truth\n                indices.\n\n        Returns:\n            list[torch.Tensor]: (area_intersect, area_union, area_prediction,\n                area_ground_truth).\n        \"\"\"", "\n", "# In order to compat with batch inference", "\n", "if", "not", "isinstance", "(", "indices", ",", "list", ")", ":", "\n", "            ", "indices", "=", "[", "indices", "]", "\n", "", "if", "not", "isinstance", "(", "preds", ",", "list", ")", ":", "\n", "            ", "preds", "=", "[", "preds", "]", "\n", "\n", "", "pre_eval_results", "=", "[", "]", "\n", "\n", "for", "pred", ",", "index", "in", "zip", "(", "preds", ",", "indices", ")", ":", "\n", "            ", "seg_map", "=", "self", ".", "get_gt_seg_map_by_idx", "(", "index", ")", "\n", "pre_eval_results", ".", "append", "(", "\n", "intersect_and_union", "(", "pred", ",", "seg_map", ",", "len", "(", "self", ".", "CLASSES", ")", ",", "\n", "self", ".", "ignore_index", ",", "self", ".", "label_map", ",", "\n", "self", ".", "reduce_zero_label", ")", ")", "\n", "\n", "", "return", "pre_eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_classes_and_palette": [[295, 338], ["isinstance", "custom.CustomDataset.get_palette_for_custom_classes", "mmcv.list_from_file", "isinstance", "enumerate", "ValueError", "set().issubset", "ValueError", "mmcv.list_from_file.index", "set", "type"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_palette_for_custom_classes"], ["", "def", "get_classes_and_palette", "(", "self", ",", "classes", "=", "None", ",", "palette", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get class names of current dataset.\n\n        Args:\n            classes (Sequence[str] | str | None): If classes is None, use\n                default CLASSES defined by builtin dataset. If classes is a\n                string, take it as a file name. The file contains the name of\n                classes where each line contains one class name. If classes is\n                a tuple or list, override the CLASSES defined by the dataset.\n            palette (Sequence[Sequence[int]]] | np.ndarray | None):\n                The palette of segmentation map. If None is given, random\n                palette will be generated. Default: None\n        \"\"\"", "\n", "if", "classes", "is", "None", ":", "\n", "            ", "self", ".", "custom_classes", "=", "False", "\n", "return", "self", ".", "CLASSES", ",", "self", ".", "PALETTE", "\n", "\n", "", "self", ".", "custom_classes", "=", "True", "\n", "if", "isinstance", "(", "classes", ",", "str", ")", ":", "\n", "# take it as a file path", "\n", "            ", "class_names", "=", "mmcv", ".", "list_from_file", "(", "classes", ")", "\n", "", "elif", "isinstance", "(", "classes", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "class_names", "=", "classes", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unsupported type {type(classes)} of classes.'", ")", "\n", "\n", "", "if", "self", ".", "CLASSES", ":", "\n", "            ", "if", "not", "set", "(", "class_names", ")", ".", "issubset", "(", "self", ".", "CLASSES", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'classes is not a subset of CLASSES.'", ")", "\n", "\n", "# dictionary, its keys are the old label ids and its values", "\n", "# are the new label ids.", "\n", "# used for changing pixel labels in load_annotations.", "\n", "", "self", ".", "label_map", "=", "{", "}", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "self", ".", "CLASSES", ")", ":", "\n", "                ", "if", "c", "not", "in", "class_names", ":", "\n", "                    ", "self", ".", "label_map", "[", "i", "]", "=", "-", "1", "\n", "", "else", ":", "\n", "                    ", "self", ".", "label_map", "[", "i", "]", "=", "class_names", ".", "index", "(", "c", ")", "\n", "\n", "", "", "", "palette", "=", "self", ".", "get_palette_for_custom_classes", "(", "class_names", ",", "palette", ")", "\n", "\n", "return", "class_names", ",", "palette", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_palette_for_custom_classes": [[339, 357], ["sorted", "custom.CustomDataset.label_map.items", "type", "numpy.random.randint.append", "numpy.random.randint", "len"], "methods", ["None"], ["", "def", "get_palette_for_custom_classes", "(", "self", ",", "class_names", ",", "palette", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "label_map", "is", "not", "None", ":", "\n", "# return subset of palette", "\n", "            ", "palette", "=", "[", "]", "\n", "for", "old_id", ",", "new_id", "in", "sorted", "(", "\n", "self", ".", "label_map", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "                ", "if", "new_id", "!=", "-", "1", ":", "\n", "                    ", "palette", ".", "append", "(", "self", ".", "PALETTE", "[", "old_id", "]", ")", "\n", "", "", "palette", "=", "type", "(", "self", ".", "PALETTE", ")", "(", "palette", ")", "\n", "\n", "", "elif", "palette", "is", "None", ":", "\n", "            ", "if", "self", ".", "PALETTE", "is", "None", ":", "\n", "                ", "palette", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "255", ",", "size", "=", "(", "len", "(", "class_names", ")", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "                ", "palette", "=", "self", ".", "PALETTE", "\n", "\n", "", "", "return", "palette", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.evaluate": [[358, 458], ["isinstance", "collections.OrderedDict", "mmseg.core.pre_eval_to_metrics.pop", "collections.OrderedDict", "collections.OrderedDict.update", "collections.OrderedDict.move_to_end", "prettytable.PrettyTable", "collections.OrderedDict.items", "prettytable.PrettyTable", "collections.OrderedDict.items", "mmcv.utils.print_log", "mmcv.utils.print_log", "mmcv.utils.print_log", "mmcv.utils.print_log", "collections.OrderedDict.items", "collections.OrderedDict.pop", "collections.OrderedDict.items", "set().issubset", "KeyError", "mmcv.is_list_of", "mmcv.is_list_of", "len", "mmseg.core.eval_metrics", "mmseg.core.pre_eval_to_metrics", "tuple", "prettytable.PrettyTable.add_column", "eval_results.update", "set", "custom.CustomDataset.get_gt_seg_maps", "range", "numpy.round", "numpy.round", "prettytable.PrettyTable.add_column", "prettytable.PrettyTable.add_column", "prettytable.PrettyTable.get_string", "prettytable.PrettyTable.get_string", "set", "mmseg.core.pre_eval_to_metrics.items", "mmseg.core.pre_eval_to_metrics.items", "numpy.nanmean", "str", "enumerate"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.eval_metrics", "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.pre_eval_to_metrics", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_gt_seg_maps"], ["", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'mIoU'", ",", "\n", "logger", "=", "None", ",", "\n", "gt_seg_maps", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Evaluate the dataset.\n\n        Args:\n            results (list[tuple[torch.Tensor]] | list[str]): per image pre_eval\n                 results or predict segmentation map for computing evaluation\n                 metric.\n            metric (str | list[str]): Metrics to be evaluated. 'mIoU',\n                'mDice' and 'mFscore' are supported.\n            logger (logging.Logger | None | str): Logger used for printing\n                related information during evaluation. Default: None.\n            gt_seg_maps (generator[ndarray]): Custom gt seg maps as input,\n                used in ConcatDataset\n\n        Returns:\n            dict[str, float]: Default metrics.\n        \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metric", "=", "[", "metric", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mDice'", ",", "'mFscore'", "]", "\n", "if", "not", "set", "(", "metric", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "            ", "raise", "KeyError", "(", "'metric {} is not supported'", ".", "format", "(", "metric", ")", ")", "\n", "\n", "", "eval_results", "=", "{", "}", "\n", "# test a list of files", "\n", "if", "mmcv", ".", "is_list_of", "(", "results", ",", "np", ".", "ndarray", ")", "or", "mmcv", ".", "is_list_of", "(", "\n", "results", ",", "str", ")", ":", "\n", "            ", "if", "gt_seg_maps", "is", "None", ":", "\n", "                ", "gt_seg_maps", "=", "self", ".", "get_gt_seg_maps", "(", ")", "\n", "", "num_classes", "=", "len", "(", "self", ".", "CLASSES", ")", "\n", "ret_metrics", "=", "eval_metrics", "(", "\n", "results", ",", "\n", "gt_seg_maps", ",", "\n", "num_classes", ",", "\n", "self", ".", "ignore_index", ",", "\n", "metric", ",", "\n", "label_map", "=", "self", ".", "label_map", ",", "\n", "reduce_zero_label", "=", "self", ".", "reduce_zero_label", ")", "\n", "# test a list of pre_eval_results", "\n", "", "else", ":", "\n", "            ", "ret_metrics", "=", "pre_eval_to_metrics", "(", "results", ",", "metric", ")", "\n", "\n", "# Because dataset.CLASSES is required for per-eval.", "\n", "", "if", "self", ".", "CLASSES", "is", "None", ":", "\n", "            ", "class_names", "=", "tuple", "(", "range", "(", "num_classes", ")", ")", "\n", "", "else", ":", "\n", "            ", "class_names", "=", "self", ".", "CLASSES", "\n", "\n", "# summary table", "\n", "", "ret_metrics_summary", "=", "OrderedDict", "(", "{", "\n", "ret_metric", ":", "np", ".", "round", "(", "np", ".", "nanmean", "(", "ret_metric_value", ")", "*", "100", ",", "2", ")", "\n", "for", "ret_metric", ",", "ret_metric_value", "in", "ret_metrics", ".", "items", "(", ")", "\n", "}", ")", "\n", "\n", "# each class table", "\n", "ret_metrics", ".", "pop", "(", "'aAcc'", ",", "None", ")", "\n", "ret_metrics_class", "=", "OrderedDict", "(", "{", "\n", "ret_metric", ":", "np", ".", "round", "(", "ret_metric_value", "*", "100", ",", "2", ")", "\n", "for", "ret_metric", ",", "ret_metric_value", "in", "ret_metrics", ".", "items", "(", ")", "\n", "}", ")", "\n", "ret_metrics_class", ".", "update", "(", "{", "'Class'", ":", "class_names", "}", ")", "\n", "ret_metrics_class", ".", "move_to_end", "(", "'Class'", ",", "last", "=", "False", ")", "\n", "\n", "# for logger", "\n", "class_table_data", "=", "PrettyTable", "(", ")", "\n", "for", "key", ",", "val", "in", "ret_metrics_class", ".", "items", "(", ")", ":", "\n", "            ", "class_table_data", ".", "add_column", "(", "key", ",", "val", ")", "\n", "\n", "", "summary_table_data", "=", "PrettyTable", "(", ")", "\n", "for", "key", ",", "val", "in", "ret_metrics_summary", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "'aAcc'", ":", "\n", "                ", "summary_table_data", ".", "add_column", "(", "key", ",", "[", "val", "]", ")", "\n", "", "else", ":", "\n", "                ", "summary_table_data", ".", "add_column", "(", "'m'", "+", "key", ",", "[", "val", "]", ")", "\n", "\n", "", "", "print_log", "(", "'per class results:'", ",", "logger", ")", "\n", "print_log", "(", "'\\n'", "+", "class_table_data", ".", "get_string", "(", ")", ",", "logger", "=", "logger", ")", "\n", "print_log", "(", "'Summary:'", ",", "logger", ")", "\n", "print_log", "(", "'\\n'", "+", "summary_table_data", ".", "get_string", "(", ")", ",", "logger", "=", "logger", ")", "\n", "\n", "# each metric dict", "\n", "for", "key", ",", "value", "in", "ret_metrics_summary", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "'aAcc'", ":", "\n", "                ", "eval_results", "[", "key", "]", "=", "value", "/", "100.0", "\n", "", "else", ":", "\n", "                ", "eval_results", "[", "'m'", "+", "key", "]", "=", "value", "/", "100.0", "\n", "\n", "", "", "ret_metrics_class", ".", "pop", "(", "'Class'", ",", "None", ")", "\n", "for", "key", ",", "value", "in", "ret_metrics_class", ".", "items", "(", ")", ":", "\n", "            ", "eval_results", ".", "update", "(", "{", "\n", "key", "+", "'.'", "+", "str", "(", "name", ")", ":", "value", "[", "idx", "]", "/", "100.0", "\n", "for", "idx", ",", "name", "in", "enumerate", "(", "class_names", ")", "\n", "}", ")", "\n", "\n", "", "return", "eval_results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.KittiOdometryDataset.__init__": [[49, 55], ["custom.CustomDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "KittiOdometryDataset", ",", "self", ")", ".", "__init__", "(", "\n", "img_suffix", "=", "'.png'", ",", "\n", "seg_map_suffix", "=", "'.png'", ",", "\n", "reduce_zero_label", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.KittiOdometryDataset.results2img": [[56, 92], ["mmcv.mkdir_or_exist", "mmcv.ProgressBar", "range", "len", "len", "os.join", "os.join", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "result_files.append", "mmcv.ProgressBar.update", "os.splitext", "os.splitext", "result.astype", "os.basename", "os.basename"], "methods", ["None"], ["", "def", "results2img", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "to_label_id", ")", ":", "\n", "        ", "\"\"\"Write the segmentation results to images.\n\n        Args:\n            results (list[list | tuple | ndarray]): Testing results of the\n                dataset.\n            imgfile_prefix (str): The filename prefix of the png files.\n                If the prefix is \"somepath/xxx\",\n                the png files will be named \"somepath/xxx.png\".\n            to_label_id (bool): whether convert output to label_id for\n                submission\n\n        Returns:\n            list[str: str]: result txt files which contains corresponding\n            semantic segmentation images.\n        \"\"\"", "\n", "mmcv", ".", "mkdir_or_exist", "(", "imgfile_prefix", ")", "\n", "result_files", "=", "[", "]", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "self", ")", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "result", "=", "results", "[", "idx", "]", "\n", "\n", "filename", "=", "self", ".", "img_infos", "[", "idx", "]", "[", "'filename'", "]", "\n", "basename", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "filename", ")", ")", "[", "0", "]", "\n", "\n", "png_filename", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "f'{basename}.png'", ")", "\n", "\n", "result", "=", "result", "+", "1", "\n", "\n", "output", "=", "Image", ".", "fromarray", "(", "result", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "output", ".", "save", "(", "png_filename", ")", "\n", "result_files", ".", "append", "(", "png_filename", ")", "\n", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n", "", "return", "result_files", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.KittiOdometryDataset.prepare_test_img": [[93, 109], ["kittiodometry.KittiOdometryDataset.get_ann_info", "dict", "kittiodometry.KittiOdometryDataset.pre_pipeline", "kittiodometry.KittiOdometryDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n                introduced by pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.KittiOdometryDataset.format_results": [[110, 150], ["isinstance", "os.join", "os.join", "mmcv.utils.print_log", "tqdm.trange", "os.exists", "os.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "numpy.invert", "numpy.concatenate", "kittiodometry.visualize_map_mask", "kittiodometry.visualize_map_mask", "mmcv.imread", "mmcv.imresize", "numpy.concatenate", "os.join", "os.join", "mmcv.imwrite", "os.path.basename", "os.path.basename", "os.path.basename", "os.path.basename", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", "=", "None", ",", "to_label_id", "=", "True", ")", ":", "\n", "        ", "\"\"\"Format the results into dir for visualization.\n\n        Args:\n            results (list): Testing results of the dataset.\n            imgfile_prefix (str | None): The prefix of images files. It\n                includes the file path and the prefix of filename, e.g.,\n                \"a/b/prefix\". If not specified, a temp file will be created.\n                Default: None.\n            to_label_id (bool): whether convert output to label_id for\n                submission. Default: False\n\n        Returns:\n            tuple: (result_files, tmp_dir), result_files is a list containing\n               the image paths, tmp_dir is the temporal directory created\n                for saving json/png files when img_prefix is not specified.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", ",", "'results must be a list'", "\n", "\n", "imgfile_prefix", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "'vis'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "imgfile_prefix", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "imgfile_prefix", ")", "\n", "", "print_log", "(", "'\\n Start formatting the result'", ")", "\n", "\n", "for", "id", "in", "trange", "(", "len", "(", "results", ")", ")", ":", "\n", "            ", "pred", ",", "gt", ",", "img_path", "=", "results", "[", "id", "]", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "pred", ".", "shape", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "1", "and", "gt", ".", "shape", "[", "0", "]", "==", "1", "\n", "pred", "=", "pred", "[", "0", "]", "\n", "gt", "=", "gt", "[", "0", "]", "\n", "gt", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt", "[", "-", "1", ",", "...", "]", ")", "\n", "pred", "=", "np", ".", "concatenate", "(", "[", "pred", ",", "gt", "[", "-", "1", ",", "...", "]", "[", "None", ",", "...", "]", "]", ",", "axis", "=", "0", ")", "\n", "pred_vis", "=", "visualize_map_mask", "(", "pred", ")", "\n", "gt_vis", "=", "visualize_map_mask", "(", "gt", ")", "\n", "img", "=", "mmcv", ".", "imread", "(", "img_path", ",", "backend", "=", "'cv2'", ")", "\n", "img", "=", "mmcv", ".", "imresize", "(", "img", ",", "(", "int", "(", "float", "(", "img", ".", "shape", "[", "1", "]", ")", "*", "h", "/", "float", "(", "img", ".", "shape", "[", "0", "]", ")", ")", ",", "h", ")", ")", "\n", "vis", "=", "np", ".", "concatenate", "(", "[", "img", ",", "pred_vis", "[", ":", ":", "-", "1", ",", "...", "]", ",", "gt_vis", "[", ":", ":", "-", "1", ",", "]", "]", ",", "axis", "=", "1", ")", "\n", "save_path", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "os", ".", "path", ".", "basename", "(", "img_path", ")", ")", "\n", "mmcv", ".", "imwrite", "(", "vis", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.KittiOdometryDataset.evaluate": [[151, 218], ["isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "set().issubset", "KeyError", "set", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "set", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "torch.cat.sum", "ious.mean", "iou_c.mean.mean.mean", "torch.cat.sum().float", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.sum", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'mIoU'", ",", "\n", "logger", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the evaluate result according to the metric type.\n\n            Args:\n                results (list): Testing results of the dataset.\n                metric (str | list[str]): Type of evalutate metric, mIoU is in consistent\n                    with \"Predicting Semantic Map Representations from Images with\n                    Pyramid Occupancy Networks. CVPR2020\", where per class fp,fn,tp are\n                    calculated on the hold dataset first. mIOUv1 calculates the per\n                    class iou in each image first and average the result between the\n                    valid images (i.e. for class c, there is positive sample point in\n                    this image). mIOUv2 calculates the per image iou first and average\n                    the result between all images.\n                logger (logging.Logger | None | str): Logger used for printing\n                    related information during evaluation. Default: None.\n\n            Returns:\n                tuple: (result_files, tmp_dir), result_files is a list containing\n                   the image paths, tmp_dir is the temporal directory created\n                    for saving json/png files when img_prefix is not specified.\n            \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metric", "=", "[", "metric", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mIoUv1'", ",", "'mIoUv2'", ",", "'mAP'", "]", "\n", "if", "not", "set", "(", "metric", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "            ", "raise", "KeyError", "(", "'metric {} is not supported'", ".", "format", "(", "metric", ")", ")", "\n", "", "tp", "=", "torch", ".", "cat", "(", "[", "res", "[", "0", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fp", "=", "torch", ".", "cat", "(", "[", "res", "[", "1", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fn", "=", "torch", ".", "cat", "(", "[", "res", "[", "2", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "valids", "=", "torch", ".", "cat", "(", "[", "res", "[", "3", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "for", "met", "in", "metric", ":", "\n", "            ", "if", "met", "==", "'mIoU'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", "+", "fn", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "print_log", "(", "'%.04f:%s tp:%d fp:%d fn:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fn", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv1'", ":", "\n", "                ", "ious", "=", "tp", ".", "float", "(", ")", "/", "(", "tp", "+", "fp", "+", "fn", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "miou", ",", "valid_class", "=", "0", ",", "0", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "iou_c", "=", "ious", "[", ":", ",", "cid", "]", "[", "valids", "[", ":", ",", "cid", "]", "]", "\n", "if", "iou_c", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                        ", "iou_c", "=", "iou_c", ".", "mean", "(", ")", "\n", "miou", "+=", "iou_c", "\n", "valid_class", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "iou_c", "=", "-", "1", "\n", "", "print_log", "(", "'%.04f:%s'", "%", "(", "iou_c", ",", "self", ".", "CLASSES", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "miou", "/", "valid_class", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv2'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "-", "1", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "-", "1", ")", "+", "fp", ".", "sum", "(", "-", "1", ")", "+", "fn", ".", "sum", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\n%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mAP'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "print_log", "(", "'%.04f:%s tp:%d fp:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "'nuknown metric type %s'", "%", "metric", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.covert_color": [[17, 25], ["int", "int", "int"], "function", ["None"], ["def", "covert_color", "(", "input", ")", ":", "\n", "    ", "str1", "=", "input", "[", "1", ":", "3", "]", "\n", "str2", "=", "input", "[", "3", ":", "5", "]", "\n", "str3", "=", "input", "[", "5", ":", "7", "]", "\n", "r", "=", "int", "(", "'0x'", "+", "str1", ",", "16", ")", "\n", "g", "=", "int", "(", "'0x'", "+", "str2", ",", "16", ")", "\n", "b", "=", "int", "(", "'0x'", "+", "str3", ",", "16", ")", "\n", "return", "(", "r", ",", "g", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiodometry.visualize_map_mask": [[26, 37], ["numpy.zeros", "vis.reshape.reshape", "map_mask.reshape.reshape", "range", "vis.reshape.reshape", "range", "numpy.where", "kittiodometry.covert_color"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.covert_color"], ["", "def", "visualize_map_mask", "(", "map_mask", ")", ":", "\n", "    ", "color_map", "=", "[", "'#a6cee3'", ",", "'#303030'", "]", "\n", "ori_shape", "=", "map_mask", ".", "shape", "\n", "vis", "=", "np", ".", "zeros", "(", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "vis", "=", "vis", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "map_mask", "=", "map_mask", ".", "reshape", "(", "ori_shape", "[", "0", "]", ",", "-", "1", ")", "\n", "for", "layer_id", "in", "range", "(", "map_mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "keep", "=", "np", ".", "where", "(", "map_mask", "[", "layer_id", ",", ":", "]", ")", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "vis", "[", "keep", ",", "2", "-", "i", "]", "=", "covert_color", "(", "color_map", "[", "layer_id", "]", ")", "[", "i", "]", "\n", "", "", "return", "vis", ".", "reshape", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.NuscenesDataset.__init__": [[59, 65], ["custom.CustomDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "NuscenesDataset", ",", "self", ")", ".", "__init__", "(", "\n", "img_suffix", "=", "'.png'", ",", "\n", "seg_map_suffix", "=", "'.png'", ",", "\n", "reduce_zero_label", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.NuscenesDataset.results2img": [[66, 102], ["mmcv.mkdir_or_exist", "mmcv.ProgressBar", "range", "len", "len", "os.join", "os.join", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "result_files.append", "mmcv.ProgressBar.update", "os.splitext", "os.splitext", "result.astype", "os.basename", "os.basename"], "methods", ["None"], ["", "def", "results2img", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "to_label_id", ")", ":", "\n", "        ", "\"\"\"Write the segmentation results to images.\n\n        Args:\n            results (list[list | tuple | ndarray]): Testing results of the\n                dataset.\n            imgfile_prefix (str): The filename prefix of the png files.\n                If the prefix is \"somepath/xxx\",\n                the png files will be named \"somepath/xxx.png\".\n            to_label_id (bool): whether convert output to label_id for\n                submission\n\n        Returns:\n            list[str: str]: result txt files which contains corresponding\n            semantic segmentation images.\n        \"\"\"", "\n", "mmcv", ".", "mkdir_or_exist", "(", "imgfile_prefix", ")", "\n", "result_files", "=", "[", "]", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "self", ")", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "result", "=", "results", "[", "idx", "]", "\n", "\n", "filename", "=", "self", ".", "img_infos", "[", "idx", "]", "[", "'filename'", "]", "\n", "basename", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "filename", ")", ")", "[", "0", "]", "\n", "\n", "png_filename", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "f'{basename}.png'", ")", "\n", "\n", "result", "=", "result", "+", "1", "\n", "\n", "output", "=", "Image", ".", "fromarray", "(", "result", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "output", ".", "save", "(", "png_filename", ")", "\n", "result_files", ".", "append", "(", "png_filename", ")", "\n", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n", "", "return", "result_files", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.NuscenesDataset.prepare_test_img": [[103, 119], ["nuscenes.NuscenesDataset.get_ann_info", "dict", "nuscenes.NuscenesDataset.pre_pipeline", "nuscenes.NuscenesDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n                introduced by pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.NuscenesDataset.format_results": [[120, 160], ["isinstance", "os.join", "os.join", "mmcv.utils.print_log", "tqdm.trange", "os.exists", "os.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "numpy.invert", "numpy.concatenate", "nuscenes.visualize_map_mask", "nuscenes.visualize_map_mask", "mmcv.imread", "mmcv.imresize", "numpy.concatenate", "os.join", "os.join", "mmcv.imwrite", "os.path.basename", "os.path.basename", "os.path.basename", "os.path.basename", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", "=", "None", ",", "to_label_id", "=", "True", ")", ":", "\n", "        ", "\"\"\"Format the results into dir for visualization.\n\n        Args:\n            results (list): Testing results of the dataset.\n            imgfile_prefix (str | None): The prefix of images files. It\n                includes the file path and the prefix of filename, e.g.,\n                \"a/b/prefix\". If not specified, a temp file will be created.\n                Default: None.\n            to_label_id (bool): whether convert output to label_id for\n                submission. Default: False\n\n        Returns:\n            tuple: (result_files, tmp_dir), result_files is a list containing\n               the image paths, tmp_dir is the temporal directory created\n                for saving json/png files when img_prefix is not specified.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", ",", "'results must be a list'", "\n", "\n", "imgfile_prefix", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "'vis'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "imgfile_prefix", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "imgfile_prefix", ")", "\n", "", "print_log", "(", "'\\n Start formatting the result'", ")", "\n", "\n", "for", "id", "in", "trange", "(", "len", "(", "results", ")", ")", ":", "\n", "            ", "pred", ",", "gt", ",", "img_path", "=", "results", "[", "id", "]", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "pred", ".", "shape", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "1", "and", "gt", ".", "shape", "[", "0", "]", "==", "1", "\n", "pred", "=", "pred", "[", "0", "]", "\n", "gt", "=", "gt", "[", "0", "]", "\n", "gt", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt", "[", "-", "1", ",", "...", "]", ")", "\n", "pred", "=", "np", ".", "concatenate", "(", "[", "pred", ",", "gt", "[", "-", "1", ",", "...", "]", "[", "None", ",", "...", "]", "]", ",", "axis", "=", "0", ")", "\n", "pred_vis", "=", "visualize_map_mask", "(", "pred", ")", "\n", "gt_vis", "=", "visualize_map_mask", "(", "gt", ")", "\n", "img", "=", "mmcv", ".", "imread", "(", "img_path", ",", "backend", "=", "'cv2'", ")", "\n", "img", "=", "mmcv", ".", "imresize", "(", "img", ",", "(", "int", "(", "float", "(", "img", ".", "shape", "[", "1", "]", ")", "*", "h", "/", "float", "(", "img", ".", "shape", "[", "0", "]", ")", ")", ",", "h", ")", ")", "\n", "vis", "=", "np", ".", "concatenate", "(", "[", "img", ",", "pred_vis", "[", ":", ":", "-", "1", ",", "...", "]", ",", "gt_vis", "[", ":", ":", "-", "1", ",", "]", "]", ",", "axis", "=", "1", ")", "\n", "save_path", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "os", ".", "path", ".", "basename", "(", "img_path", ")", ")", "\n", "mmcv", ".", "imwrite", "(", "vis", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.NuscenesDataset.evaluate": [[161, 222], ["isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "set().issubset", "KeyError", "set", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "set", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "torch.cat.sum", "ious.mean", "iou_c.mean.mean.mean", "torch.cat.sum().float", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'mIoU'", ",", "\n", "logger", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the evaluate result according to the metric type.\n\n            Args:\n                results (list): Testing results of the dataset.\n                metric (str | list[str]): Type of evalutate metric, mIoU is in consistent\n                    with \"Predicting Semantic Map Representations from Images with\n                    Pyramid Occupancy Networks. CVPR2020\", where per class fp,fn,tp are\n                    calculated on the hold dataset first. mIOUv1 calculates the per\n                    class iou in each image first and average the result between the\n                    valid images (i.e. for class c, there is positive sample point in\n                    this image). mIOUv2 calculates the per image iou first and average\n                    the result between all images.\n                logger (logging.Logger | None | str): Logger used for printing\n                    related information during evaluation. Default: None.\n\n            Returns:\n                tuple: (result_files, tmp_dir), result_files is a list containing\n                   the image paths, tmp_dir is the temporal directory created\n                    for saving json/png files when img_prefix is not specified.\n            \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metric", "=", "[", "metric", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mIoUv1'", ",", "'mIoUv2'", "]", "\n", "if", "not", "set", "(", "metric", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "            ", "raise", "KeyError", "(", "'metric {} is not supported'", ".", "format", "(", "metric", ")", ")", "\n", "", "tp", "=", "torch", ".", "cat", "(", "[", "res", "[", "0", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fp", "=", "torch", ".", "cat", "(", "[", "res", "[", "1", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fn", "=", "torch", ".", "cat", "(", "[", "res", "[", "2", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "valids", "=", "torch", ".", "cat", "(", "[", "res", "[", "3", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "for", "met", "in", "metric", ":", "\n", "            ", "if", "met", "==", "'mIoU'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", "+", "fn", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "print_log", "(", "'%.04f:%s tp:%d fp:%d fn:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fn", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv1'", ":", "\n", "                ", "ious", "=", "tp", ".", "float", "(", ")", "/", "(", "tp", "+", "fp", "+", "fn", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "miou", ",", "valid_class", "=", "0", ",", "0", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "iou_c", "=", "ious", "[", ":", ",", "cid", "]", "[", "valids", "[", ":", ",", "cid", "]", "]", "\n", "if", "iou_c", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                        ", "iou_c", "=", "iou_c", ".", "mean", "(", ")", "\n", "miou", "+=", "iou_c", "\n", "valid_class", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "iou_c", "=", "-", "1", "\n", "", "print_log", "(", "'%.04f:%s'", "%", "(", "iou_c", ",", "self", ".", "CLASSES", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "miou", "/", "valid_class", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv2'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "-", "1", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "-", "1", ")", "+", "fp", ".", "sum", "(", "-", "1", ")", "+", "fn", ".", "sum", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\n%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "'nuknown metric type %s'", "%", "metric", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.covert_color": [[17, 25], ["int", "int", "int"], "function", ["None"], ["def", "covert_color", "(", "input", ")", ":", "\n", "    ", "str1", "=", "input", "[", "1", ":", "3", "]", "\n", "str2", "=", "input", "[", "3", ":", "5", "]", "\n", "str3", "=", "input", "[", "5", ":", "7", "]", "\n", "r", "=", "int", "(", "'0x'", "+", "str1", ",", "16", ")", "\n", "g", "=", "int", "(", "'0x'", "+", "str2", ",", "16", ")", "\n", "b", "=", "int", "(", "'0x'", "+", "str3", ",", "16", ")", "\n", "return", "(", "r", ",", "g", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.nuscenes.visualize_map_mask": [[27, 40], ["numpy.zeros", "vis.reshape.reshape", "map_mask.reshape.reshape", "range", "vis.reshape.reshape", "range", "numpy.where", "nuscenes.covert_color"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.covert_color"], ["", "def", "visualize_map_mask", "(", "map_mask", ")", ":", "\n", "    ", "color_map", "=", "[", "'#a6cee3'", ",", "'#1f78b4'", ",", "'#b2df8a'", ",", "'#33a02c'", ",", "'#fb9a99'", ",", "\n", "'#e31a1c'", ",", "'#fdbf6f'", ",", "'#ff7f00'", ",", "'#cab2d6'", ",", "'#6a3d9a'", ",", "\n", "'#7e772e'", ",", "'#00ff00'", ",", "'#0000ff'", ",", "'#00ffff'", ",", "'#303030'", "]", "\n", "ori_shape", "=", "map_mask", ".", "shape", "\n", "vis", "=", "np", ".", "zeros", "(", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "vis", "=", "vis", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "map_mask", "=", "map_mask", ".", "reshape", "(", "ori_shape", "[", "0", "]", ",", "-", "1", ")", "\n", "for", "layer_id", "in", "range", "(", "map_mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "keep", "=", "np", ".", "where", "(", "map_mask", "[", "layer_id", ",", ":", "]", ")", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "vis", "[", "keep", ",", "2", "-", "i", "]", "=", "covert_color", "(", "color_map", "[", "layer_id", "]", ")", "[", "i", "]", "\n", "", "", "return", "vis", ".", "reshape", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder._concat_dataset": [[27, 63], ["cfg.get", "cfg.get", "cfg.pop", "max", "range", "ConcatDataset", "isinstance", "len", "copy.deepcopy", "isinstance", "isinstance", "isinstance", "datasets.append", "isinstance", "len", "isinstance", "len", "builder.build_dataset"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset"], ["def", "_concat_dataset", "(", "cfg", ",", "default_args", "=", "None", ")", ":", "\n", "    ", "\"\"\"Build :obj:`ConcatDataset by.\"\"\"", "\n", "from", ".", "dataset_wrappers", "import", "ConcatDataset", "\n", "img_dir", "=", "cfg", "[", "'img_dir'", "]", "\n", "ann_dir", "=", "cfg", ".", "get", "(", "'ann_dir'", ",", "None", ")", "\n", "split", "=", "cfg", ".", "get", "(", "'split'", ",", "None", ")", "\n", "# pop 'separate_eval' since it is not a valid key for common datasets.", "\n", "separate_eval", "=", "cfg", ".", "pop", "(", "'separate_eval'", ",", "True", ")", "\n", "num_img_dir", "=", "len", "(", "img_dir", ")", "if", "isinstance", "(", "img_dir", ",", "(", "list", ",", "tuple", ")", ")", "else", "1", "\n", "if", "ann_dir", "is", "not", "None", ":", "\n", "        ", "num_ann_dir", "=", "len", "(", "ann_dir", ")", "if", "isinstance", "(", "ann_dir", ",", "(", "list", ",", "tuple", ")", ")", "else", "1", "\n", "", "else", ":", "\n", "        ", "num_ann_dir", "=", "0", "\n", "", "if", "split", "is", "not", "None", ":", "\n", "        ", "num_split", "=", "len", "(", "split", ")", "if", "isinstance", "(", "split", ",", "(", "list", ",", "tuple", ")", ")", "else", "1", "\n", "", "else", ":", "\n", "        ", "num_split", "=", "0", "\n", "", "if", "num_img_dir", ">", "1", ":", "\n", "        ", "assert", "num_img_dir", "==", "num_ann_dir", "or", "num_ann_dir", "==", "0", "\n", "assert", "num_img_dir", "==", "num_split", "or", "num_split", "==", "0", "\n", "", "else", ":", "\n", "        ", "assert", "num_split", "==", "num_ann_dir", "or", "num_ann_dir", "<=", "1", "\n", "", "num_dset", "=", "max", "(", "num_split", ",", "num_img_dir", ")", "\n", "\n", "datasets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_dset", ")", ":", "\n", "        ", "data_cfg", "=", "copy", ".", "deepcopy", "(", "cfg", ")", "\n", "if", "isinstance", "(", "img_dir", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "data_cfg", "[", "'img_dir'", "]", "=", "img_dir", "[", "i", "]", "\n", "", "if", "isinstance", "(", "ann_dir", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "data_cfg", "[", "'ann_dir'", "]", "=", "ann_dir", "[", "i", "]", "\n", "", "if", "isinstance", "(", "split", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "data_cfg", "[", "'split'", "]", "=", "split", "[", "i", "]", "\n", "", "datasets", ".", "append", "(", "build_dataset", "(", "data_cfg", ",", "default_args", ")", ")", "\n", "\n", "", "return", "ConcatDataset", "(", "datasets", ",", "separate_eval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset": [[65, 79], ["isinstance", "ConcatDataset", "RepeatDataset", "builder.build_dataset", "builder.build_dataset", "isinstance", "isinstance", "builder._concat_dataset", "mmcv.utils.build_from_cfg", "cfg.get", "cfg.get"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder._concat_dataset"], ["", "def", "build_dataset", "(", "cfg", ",", "default_args", "=", "None", ")", ":", "\n", "    ", "\"\"\"Build datasets.\"\"\"", "\n", "from", ".", "dataset_wrappers", "import", "ConcatDataset", ",", "RepeatDataset", "\n", "if", "isinstance", "(", "cfg", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "dataset", "=", "ConcatDataset", "(", "[", "build_dataset", "(", "c", ",", "default_args", ")", "for", "c", "in", "cfg", "]", ")", "\n", "", "elif", "cfg", "[", "'type'", "]", "==", "'RepeatDataset'", ":", "\n", "        ", "dataset", "=", "RepeatDataset", "(", "\n", "build_dataset", "(", "cfg", "[", "'dataset'", "]", ",", "default_args", ")", ",", "cfg", "[", "'times'", "]", ")", "\n", "", "elif", "isinstance", "(", "cfg", ".", "get", "(", "'img_dir'", ")", ",", "(", "list", ",", "tuple", ")", ")", "or", "isinstance", "(", "\n", "cfg", ".", "get", "(", "'split'", ",", "None", ")", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "dataset", "=", "_concat_dataset", "(", "cfg", ",", "default_args", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "build_from_cfg", "(", "cfg", ",", "DATASETS", ",", "default_args", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataloader": [[81, 165], ["mmcv.runner.get_dist_info", "torch.utils.data.DistributedSampler", "functools.partial", "mmcv.utils.digit_version", "mmcv.utils.digit_version", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "functools.partial", "functools.partial"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.mmseg.__init__.digit_version", "home.repos.pwc.inspect_result.jiayuzou2020_hft.mmseg.__init__.digit_version"], ["", "def", "build_dataloader", "(", "dataset", ",", "\n", "samples_per_gpu", ",", "\n", "workers_per_gpu", ",", "\n", "num_gpus", "=", "1", ",", "\n", "dist", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "seed", "=", "None", ",", "\n", "drop_last", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "\n", "persistent_workers", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Build PyTorch DataLoader.\n\n    In distributed training, each GPU/process has a dataloader.\n    In non-distributed training, there is only one dataloader for all GPUs.\n\n    Args:\n        dataset (Dataset): A PyTorch dataset.\n        samples_per_gpu (int): Number of training samples on each GPU, i.e.,\n            batch size of each GPU.\n        workers_per_gpu (int): How many subprocesses to use for data loading\n            for each GPU.\n        num_gpus (int): Number of GPUs. Only used in non-distributed training.\n        dist (bool): Distributed training/test or not. Default: True.\n        shuffle (bool): Whether to shuffle the data at every epoch.\n            Default: True.\n        seed (int | None): Seed to be used. Default: None.\n        drop_last (bool): Whether to drop the last incomplete batch in epoch.\n            Default: False\n        pin_memory (bool): Whether to use pin_memory in DataLoader.\n            Default: True\n        persistent_workers (bool): If True, the data loader will not shutdown\n            the worker processes after a dataset has been consumed once.\n            This allows to maintain the workers Dataset instances alive.\n            The argument also has effect in PyTorch>=1.7.0.\n            Default: True\n        kwargs: any keyword argument to be used to initialize DataLoader\n\n    Returns:\n        DataLoader: A PyTorch dataloader.\n    \"\"\"", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "if", "dist", ":", "\n", "        ", "sampler", "=", "DistributedSampler", "(", "\n", "dataset", ",", "world_size", ",", "rank", ",", "shuffle", "=", "shuffle", ")", "\n", "shuffle", "=", "False", "\n", "batch_size", "=", "samples_per_gpu", "\n", "num_workers", "=", "workers_per_gpu", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "None", "\n", "batch_size", "=", "num_gpus", "*", "samples_per_gpu", "\n", "num_workers", "=", "num_gpus", "*", "workers_per_gpu", "\n", "\n", "", "init_fn", "=", "partial", "(", "\n", "worker_init_fn", ",", "num_workers", "=", "num_workers", ",", "rank", "=", "rank", ",", "\n", "seed", "=", "seed", ")", "if", "seed", "is", "not", "None", "else", "None", "\n", "\n", "if", "digit_version", "(", "torch", ".", "__version__", ")", ">=", "digit_version", "(", "'1.8.0'", ")", ":", "\n", "        ", "data_loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "partial", "(", "collate", ",", "samples_per_gpu", "=", "samples_per_gpu", ")", ",", "\n", "pin_memory", "=", "pin_memory", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "worker_init_fn", "=", "init_fn", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", "persistent_workers", "=", "persistent_workers", ",", "\n", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "data_loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "partial", "(", "collate", ",", "samples_per_gpu", "=", "samples_per_gpu", ")", ",", "\n", "pin_memory", "=", "pin_memory", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "worker_init_fn", "=", "init_fn", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", "**", "kwargs", ")", "\n", "\n", "", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.worker_init_fn": [[167, 182], ["numpy.random.seed", "random.seed"], "function", ["None"], ["", "def", "worker_init_fn", "(", "worker_id", ",", "num_workers", ",", "rank", ",", "seed", ")", ":", "\n", "    ", "\"\"\"Worker init func for dataloader.\n\n    The seed of each worker equals to num_worker * rank + worker_id + user_seed\n\n    Args:\n        worker_id (int): Worker id.\n        num_workers (int): Number of workers.\n        rank (int): The rank of current process.\n        seed (int): The random seed to use.\n    \"\"\"", "\n", "\n", "worker_seed", "=", "num_workers", "*", "rank", "+", "worker_id", "+", "seed", "\n", "np", ".", "random", ".", "seed", "(", "worker_seed", ")", "\n", "random", ".", "seed", "(", "worker_seed", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.KittiObjectDataset.__init__": [[48, 54], ["custom.CustomDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "KittiObjectDataset", ",", "self", ")", ".", "__init__", "(", "\n", "img_suffix", "=", "'.png'", ",", "\n", "seg_map_suffix", "=", "'.png'", ",", "\n", "reduce_zero_label", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.KittiObjectDataset.results2img": [[55, 91], ["mmcv.mkdir_or_exist", "mmcv.ProgressBar", "range", "len", "len", "os.join", "os.join", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "result_files.append", "mmcv.ProgressBar.update", "os.splitext", "os.splitext", "result.astype", "os.basename", "os.basename"], "methods", ["None"], ["", "def", "results2img", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "to_label_id", ")", ":", "\n", "        ", "\"\"\"Write the segmentation results to images.\n\n        Args:\n            results (list[list | tuple | ndarray]): Testing results of the\n                dataset.\n            imgfile_prefix (str): The filename prefix of the png files.\n                If the prefix is \"somepath/xxx\",\n                the png files will be named \"somepath/xxx.png\".\n            to_label_id (bool): whether convert output to label_id for\n                submission\n\n        Returns:\n            list[str: str]: result txt files which contains corresponding\n            semantic segmentation images.\n        \"\"\"", "\n", "mmcv", ".", "mkdir_or_exist", "(", "imgfile_prefix", ")", "\n", "result_files", "=", "[", "]", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "self", ")", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "result", "=", "results", "[", "idx", "]", "\n", "\n", "filename", "=", "self", ".", "img_infos", "[", "idx", "]", "[", "'filename'", "]", "\n", "basename", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "filename", ")", ")", "[", "0", "]", "\n", "\n", "png_filename", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "f'{basename}.png'", ")", "\n", "\n", "result", "=", "result", "+", "1", "\n", "\n", "output", "=", "Image", ".", "fromarray", "(", "result", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "output", ".", "save", "(", "png_filename", ")", "\n", "result_files", ".", "append", "(", "png_filename", ")", "\n", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n", "", "return", "result_files", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.KittiObjectDataset.prepare_test_img": [[92, 108], ["kittiobject.KittiObjectDataset.get_ann_info", "dict", "kittiobject.KittiObjectDataset.pre_pipeline", "kittiobject.KittiObjectDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n                introduced by pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.KittiObjectDataset.format_results": [[109, 149], ["isinstance", "os.join", "os.join", "mmcv.utils.print_log", "tqdm.trange", "os.exists", "os.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "numpy.invert", "numpy.concatenate", "kittiobject.visualize_map_mask", "kittiobject.visualize_map_mask", "mmcv.imread", "mmcv.imresize", "numpy.concatenate", "os.join", "os.join", "mmcv.imwrite", "os.path.basename", "os.path.basename", "os.path.basename", "os.path.basename", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", "=", "None", ",", "to_label_id", "=", "True", ")", ":", "\n", "        ", "\"\"\"Format the results into dir for visualization.\n\n        Args:\n            results (list): Testing results of the dataset.\n            imgfile_prefix (str | None): The prefix of images files. It\n                includes the file path and the prefix of filename, e.g.,\n                \"a/b/prefix\". If not specified, a temp file will be created.\n                Default: None.\n            to_label_id (bool): whether convert output to label_id for\n                submission. Default: False\n\n        Returns:\n            tuple: (result_files, tmp_dir), result_files is a list containing\n               the image paths, tmp_dir is the temporal directory created\n                for saving json/png files when img_prefix is not specified.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", ",", "'results must be a list'", "\n", "\n", "imgfile_prefix", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "'vis'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "imgfile_prefix", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "imgfile_prefix", ")", "\n", "", "print_log", "(", "'\\n Start formatting the result'", ")", "\n", "\n", "for", "id", "in", "trange", "(", "len", "(", "results", ")", ")", ":", "\n", "            ", "pred", ",", "gt", ",", "img_path", "=", "results", "[", "id", "]", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "pred", ".", "shape", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "1", "and", "gt", ".", "shape", "[", "0", "]", "==", "1", "\n", "pred", "=", "pred", "[", "0", "]", "\n", "gt", "=", "gt", "[", "0", "]", "\n", "gt", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt", "[", "-", "1", ",", "...", "]", ")", "\n", "pred", "=", "np", ".", "concatenate", "(", "[", "pred", ",", "gt", "[", "-", "1", ",", "...", "]", "[", "None", ",", "...", "]", "]", ",", "axis", "=", "0", ")", "\n", "pred_vis", "=", "visualize_map_mask", "(", "pred", ")", "\n", "gt_vis", "=", "visualize_map_mask", "(", "gt", ")", "\n", "img", "=", "mmcv", ".", "imread", "(", "img_path", ",", "backend", "=", "'cv2'", ")", "\n", "img", "=", "mmcv", ".", "imresize", "(", "img", ",", "(", "int", "(", "float", "(", "img", ".", "shape", "[", "1", "]", ")", "*", "h", "/", "float", "(", "img", ".", "shape", "[", "0", "]", ")", ")", ",", "h", ")", ")", "\n", "vis", "=", "np", ".", "concatenate", "(", "[", "img", ",", "pred_vis", "[", ":", ":", "-", "1", ",", "...", "]", ",", "gt_vis", "[", ":", ":", "-", "1", ",", "]", "]", ",", "axis", "=", "1", ")", "\n", "save_path", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "os", ".", "path", ".", "basename", "(", "img_path", ")", ")", "\n", "mmcv", ".", "imwrite", "(", "vis", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.KittiObjectDataset.evaluate": [[150, 230], ["isinstance", "torch.is_tensor", "set().issubset", "KeyError", "torch.cat", "mmcv.utils.print_log", "mmcv.utils.print_log", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "set", "set", "torch.tensor", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "torch.cat.sum", "ious.mean", "iou_c.mean.mean.mean", "torch.cat.sum().float", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.sum", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'mIoU'", ",", "\n", "logger", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the evaluate result according to the metric type.\n\n            Args:\n                results (list): Testing results of the dataset.\n                metric (str | list[str]): Type of evalutate metric, mIoU is in consistent\n                    with \"Predicting Semantic Map Representations from Images with\n                    Pyramid Occupancy Networks. CVPR2020\", where per class fp,fn,tp are\n                    calculated on the hold dataset first. mIOUv1 calculates the per\n                    class iou in each image first and average the result between the\n                    valid images (i.e. for class c, there is positive sample point in\n                    this image). mIOUv2 calculates the per image iou first and average\n                    the result between all images.\n                logger (logging.Logger | None | str): Logger used for printing\n                    related information during evaluation. Default: None.\n\n            Returns:\n                tuple: (result_files, tmp_dir), result_files is a list containing\n                   the image paths, tmp_dir is the temporal directory created\n                    for saving json/png files when img_prefix is not specified.\n            \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metric", "=", "[", "metric", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mIoUv1'", ",", "'mIoUv2'", ",", "'mAP'", "]", "\n", "if", "not", "set", "(", "metric", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "            ", "raise", "KeyError", "(", "'metric {} is not supported'", ".", "format", "(", "metric", ")", ")", "\n", "# =================================== #", "\n", "# this is for acc_seg in testing set", "\n", "", "if", "torch", ".", "is_tensor", "(", "results", "[", "0", "]", ")", ":", "\n", "            ", "acc_seg", "=", "torch", ".", "cat", "(", "[", "res", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "print_log", "(", "'\\nper class results (acc_seg or loss_seg):'", ",", "logger", ")", "\n", "valid_seg", ",", "valid_count", "=", "0", ",", "0", "\n", "for", "acc_seg_value", "in", "acc_seg", ":", "\n", "                ", "if", "acc_seg_value", "<", "torch", ".", "tensor", "(", "100.0", ")", ":", "\n", "                    ", "valid_seg", "+=", "acc_seg_value", "\n", "valid_count", "+=", "1", "\n", "", "", "print_log", "(", "'acc_seg: %.04f'", "%", "(", "valid_seg", "/", "valid_count", ")", ",", "logger", ")", "\n", "# =================================== #", "\n", "", "else", ":", "\n", "            ", "tp", "=", "torch", ".", "cat", "(", "[", "res", "[", "0", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fp", "=", "torch", ".", "cat", "(", "[", "res", "[", "1", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fn", "=", "torch", ".", "cat", "(", "[", "res", "[", "2", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "valids", "=", "torch", ".", "cat", "(", "[", "res", "[", "3", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "for", "met", "in", "metric", ":", "\n", "                ", "if", "met", "==", "'mIoU'", ":", "\n", "                    ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", "+", "fn", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                        ", "print_log", "(", "'%.04f:%s tp:%d fp:%d fn:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fn", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv1'", ":", "\n", "                    ", "ious", "=", "tp", ".", "float", "(", ")", "/", "(", "tp", "+", "fp", "+", "fn", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "miou", ",", "valid_class", "=", "0", ",", "0", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                        ", "iou_c", "=", "ious", "[", ":", ",", "cid", "]", "[", "valids", "[", ":", ",", "cid", "]", "]", "\n", "if", "iou_c", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                            ", "iou_c", "=", "iou_c", ".", "mean", "(", ")", "\n", "miou", "+=", "iou_c", "\n", "valid_class", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "iou_c", "=", "-", "1", "\n", "", "print_log", "(", "'%.04f:%s'", "%", "(", "iou_c", ",", "self", ".", "CLASSES", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "miou", "/", "valid_class", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv2'", ":", "\n", "                    ", "ious", "=", "tp", ".", "sum", "(", "-", "1", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "-", "1", ")", "+", "fp", ".", "sum", "(", "-", "1", ")", "+", "fn", ".", "sum", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\n%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mAP'", ":", "\n", "                    ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                        ", "print_log", "(", "'%.04f:%s tp:%d fp:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "False", ",", "'unknown metric type %s'", "%", "metric", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.covert_color": [[15, 23], ["int", "int", "int"], "function", ["None"], ["def", "covert_color", "(", "input", ")", ":", "\n", "    ", "str1", "=", "input", "[", "1", ":", "3", "]", "\n", "str2", "=", "input", "[", "3", ":", "5", "]", "\n", "str3", "=", "input", "[", "5", ":", "7", "]", "\n", "r", "=", "int", "(", "'0x'", "+", "str1", ",", "16", ")", "\n", "g", "=", "int", "(", "'0x'", "+", "str2", ",", "16", ")", "\n", "b", "=", "int", "(", "'0x'", "+", "str3", ",", "16", ")", "\n", "return", "(", "r", ",", "g", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.kittiobject.visualize_map_mask": [[24, 35], ["numpy.zeros", "vis.reshape.reshape", "map_mask.reshape.reshape", "range", "vis.reshape.reshape", "range", "numpy.where", "kittiobject.covert_color"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.covert_color"], ["", "def", "visualize_map_mask", "(", "map_mask", ")", ":", "\n", "    ", "color_map", "=", "[", "'#a6cee3'", ",", "'#303030'", "]", "\n", "ori_shape", "=", "map_mask", ".", "shape", "\n", "vis", "=", "np", ".", "zeros", "(", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "vis", "=", "vis", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "map_mask", "=", "map_mask", ".", "reshape", "(", "ori_shape", "[", "0", "]", ",", "-", "1", ")", "\n", "for", "layer_id", "in", "range", "(", "map_mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "keep", "=", "np", ".", "where", "(", "map_mask", "[", "layer_id", ",", ":", "]", ")", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "vis", "[", "keep", ",", "2", "-", "i", "]", "=", "covert_color", "(", "color_map", "[", "layer_id", "]", ")", "[", "i", "]", "\n", "", "", "return", "vis", ".", "reshape", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.__init__": [[27, 38], ["torch.utils.data.dataset.ConcatDataset.__init__", "any", "NotImplementedError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "datasets", ",", "separate_eval", "=", "True", ")", ":", "\n", "        ", "super", "(", "ConcatDataset", ",", "self", ")", ".", "__init__", "(", "datasets", ")", "\n", "self", ".", "CLASSES", "=", "datasets", "[", "0", "]", ".", "CLASSES", "\n", "self", ".", "PALETTE", "=", "datasets", "[", "0", "]", ".", "PALETTE", "\n", "self", ".", "separate_eval", "=", "separate_eval", "\n", "assert", "separate_eval", "in", "[", "True", ",", "False", "]", ",", "f'separate_eval can only be True or False,'", "f'but get {separate_eval}'", "\n", "if", "any", "(", "[", "isinstance", "(", "ds", ",", "CityscapesDataset", ")", "for", "ds", "in", "datasets", "]", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "'Evaluating ConcatDataset containing CityscapesDataset'", "\n", "'is not supported!'", ")", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.evaluate": [[40, 103], ["len", "hasattr", "dict", "zip", "len", "NotImplementedError", "dataset_wrappers.ConcatDataset.datasets[].evaluate", "len", "mmcv.utils.print_log", "dataset.evaluate", "dataset.evaluate.items", "set", "mmcv.is_list_of", "mmcv.is_list_of", "itertools.chain", "type", "dict.update", "type", "len", "dataset.get_gt_seg_maps"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.evaluate", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.evaluate", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_gt_seg_maps"], ["", "", "def", "evaluate", "(", "self", ",", "results", ",", "logger", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Evaluate the results.\n\n        Args:\n            results (list[tuple[torch.Tensor]] | list[str]]): per image\n                pre_eval results or predict segmentation map for\n                computing evaluation metric.\n            logger (logging.Logger | str | None): Logger used for printing\n                related information during evaluation. Default: None.\n\n        Returns:\n            dict[str: float]: evaluate results of the total dataset\n                or each separate\n            dataset if `self.separate_eval=True`.\n        \"\"\"", "\n", "assert", "len", "(", "results", ")", "==", "self", ".", "cumulative_sizes", "[", "-", "1", "]", ",", "(", "'Dataset and results have different sizes: '", "\n", "f'{self.cumulative_sizes[-1]} v.s. {len(results)}'", ")", "\n", "\n", "# Check whether all the datasets support evaluation", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "assert", "hasattr", "(", "dataset", ",", "'evaluate'", ")", ",", "f'{type(dataset)} does not implement evaluate function'", "\n", "\n", "", "if", "self", ".", "separate_eval", ":", "\n", "            ", "dataset_idx", "=", "-", "1", "\n", "total_eval_results", "=", "dict", "(", ")", "\n", "for", "size", ",", "dataset", "in", "zip", "(", "self", ".", "cumulative_sizes", ",", "self", ".", "datasets", ")", ":", "\n", "                ", "start_idx", "=", "0", "if", "dataset_idx", "==", "-", "1", "else", "self", ".", "cumulative_sizes", "[", "dataset_idx", "]", "\n", "end_idx", "=", "self", ".", "cumulative_sizes", "[", "dataset_idx", "+", "1", "]", "\n", "\n", "results_per_dataset", "=", "results", "[", "start_idx", ":", "end_idx", "]", "\n", "print_log", "(", "\n", "f'\\nEvaluateing {dataset.img_dir} with '", "\n", "f'{len(results_per_dataset)} images now'", ",", "\n", "logger", "=", "logger", ")", "\n", "\n", "eval_results_per_dataset", "=", "dataset", ".", "evaluate", "(", "\n", "results_per_dataset", ",", "logger", "=", "logger", ",", "**", "kwargs", ")", "\n", "dataset_idx", "+=", "1", "\n", "for", "k", ",", "v", "in", "eval_results_per_dataset", ".", "items", "(", ")", ":", "\n", "                    ", "total_eval_results", ".", "update", "(", "{", "f'{dataset_idx}_{k}'", ":", "v", "}", ")", "\n", "\n", "", "", "return", "total_eval_results", "\n", "\n", "", "if", "len", "(", "set", "(", "[", "type", "(", "ds", ")", "for", "ds", "in", "self", ".", "datasets", "]", ")", ")", "!=", "1", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "'All the datasets should have same types when '", "\n", "'self.separate_eval=False'", ")", "\n", "", "else", ":", "\n", "            ", "if", "mmcv", ".", "is_list_of", "(", "results", ",", "np", ".", "ndarray", ")", "or", "mmcv", ".", "is_list_of", "(", "\n", "results", ",", "str", ")", ":", "\n", "# merge the generators of gt_seg_maps", "\n", "                ", "gt_seg_maps", "=", "chain", "(", "\n", "*", "[", "dataset", ".", "get_gt_seg_maps", "(", ")", "for", "dataset", "in", "self", ".", "datasets", "]", ")", "\n", "", "else", ":", "\n", "# if the results are `pre_eval` results,", "\n", "# we do not need gt_seg_maps to evaluate", "\n", "                ", "gt_seg_maps", "=", "None", "\n", "", "eval_results", "=", "self", ".", "datasets", "[", "0", "]", ".", "evaluate", "(", "\n", "results", ",", "gt_seg_maps", "=", "gt_seg_maps", ",", "logger", "=", "logger", ",", "**", "kwargs", ")", "\n", "return", "eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.get_dataset_idx_and_sample_idx": [[104, 126], ["bisect.bisect_right", "len", "ValueError", "len"], "methods", ["None"], ["", "", "def", "get_dataset_idx_and_sample_idx", "(", "self", ",", "indice", ")", ":", "\n", "        ", "\"\"\"Return dataset and sample index when given an indice of\n        ConcatDataset.\n\n        Args:\n            indice (int): indice of sample in ConcatDataset\n\n        Returns:\n            int: the index of sub dataset the sample belong to\n            int: the index of sample in its corresponding subset\n        \"\"\"", "\n", "if", "indice", "<", "0", ":", "\n", "            ", "if", "-", "indice", ">", "len", "(", "self", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'absolute value of index should not exceed dataset length'", ")", "\n", "", "indice", "=", "len", "(", "self", ")", "+", "indice", "\n", "", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "indice", ")", "\n", "if", "dataset_idx", "==", "0", ":", "\n", "            ", "sample_idx", "=", "indice", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "indice", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "", "return", "dataset_idx", ",", "sample_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.format_results": [[127, 146], ["isinstance", "isinstance", "enumerate", "sum", "list", "dataset_wrappers.ConcatDataset.get_dataset_idx_and_sample_idx", "dataset_wrappers.ConcatDataset.datasets[].format_results", "ret_res.append", "range", "len"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.get_dataset_idx_and_sample_idx", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.format_results"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "indices", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"format result for every sample of ConcatDataset.\"\"\"", "\n", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "list", "(", "range", "(", "len", "(", "self", ")", ")", ")", "\n", "\n", "", "assert", "isinstance", "(", "results", ",", "list", ")", ",", "'results must be a list.'", "\n", "assert", "isinstance", "(", "indices", ",", "list", ")", ",", "'indices must be a list.'", "\n", "\n", "ret_res", "=", "[", "]", "\n", "for", "i", ",", "indice", "in", "enumerate", "(", "indices", ")", ":", "\n", "            ", "dataset_idx", ",", "sample_idx", "=", "self", ".", "get_dataset_idx_and_sample_idx", "(", "\n", "indice", ")", "\n", "res", "=", "self", ".", "datasets", "[", "dataset_idx", "]", ".", "format_results", "(", "\n", "[", "results", "[", "i", "]", "]", ",", "\n", "imgfile_prefix", "+", "f'/{dataset_idx}'", ",", "\n", "indices", "=", "[", "sample_idx", "]", ",", "\n", "**", "kwargs", ")", "\n", "ret_res", ".", "append", "(", "res", ")", "\n", "", "return", "sum", "(", "ret_res", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.pre_eval": [[147, 161], ["enumerate", "sum", "isinstance", "isinstance", "dataset_wrappers.ConcatDataset.get_dataset_idx_and_sample_idx", "dataset_wrappers.ConcatDataset.datasets[].pre_eval", "ret_res.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.get_dataset_idx_and_sample_idx", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.ConcatDataset.pre_eval"], ["", "def", "pre_eval", "(", "self", ",", "preds", ",", "indices", ")", ":", "\n", "        ", "\"\"\"do pre eval for every sample of ConcatDataset.\"\"\"", "\n", "# In order to compat with batch inference", "\n", "if", "not", "isinstance", "(", "indices", ",", "list", ")", ":", "\n", "            ", "indices", "=", "[", "indices", "]", "\n", "", "if", "not", "isinstance", "(", "preds", ",", "list", ")", ":", "\n", "            ", "preds", "=", "[", "preds", "]", "\n", "", "ret_res", "=", "[", "]", "\n", "for", "i", ",", "indice", "in", "enumerate", "(", "indices", ")", ":", "\n", "            ", "dataset_idx", ",", "sample_idx", "=", "self", ".", "get_dataset_idx_and_sample_idx", "(", "\n", "indice", ")", "\n", "res", "=", "self", ".", "datasets", "[", "dataset_idx", "]", ".", "pre_eval", "(", "preds", "[", "i", "]", ",", "sample_idx", ")", "\n", "ret_res", ".", "append", "(", "res", ")", "\n", "", "return", "sum", "(", "ret_res", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.RepeatDataset.__init__": [[177, 183], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "times", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "times", "=", "times", "\n", "self", ".", "CLASSES", "=", "dataset", ".", "CLASSES", "\n", "self", ".", "PALETTE", "=", "dataset", ".", "PALETTE", "\n", "self", ".", "_ori_len", "=", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.RepeatDataset.__getitem__": [[184, 187], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get item from original dataset.\"\"\"", "\n", "return", "self", ".", "dataset", "[", "idx", "%", "self", ".", "_ori_len", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.dataset_wrappers.RepeatDataset.__len__": [[188, 191], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"The length is multiplied by ``times``\"\"\"", "\n", "return", "self", ".", "times", "*", "self", ".", "_ori_len", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.__init__": [[56, 62], ["custom.CustomDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ArgoverseDataset", ",", "self", ")", ".", "__init__", "(", "\n", "img_suffix", "=", "'.jpg'", ",", "\n", "seg_map_suffix", "=", "'.png'", ",", "\n", "reduce_zero_label", "=", "True", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.results2img": [[63, 99], ["mmcv.mkdir_or_exist", "mmcv.ProgressBar", "range", "len", "len", "os.join", "os.join", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "result_files.append", "mmcv.ProgressBar.update", "os.splitext", "os.splitext", "result.astype", "os.basename", "os.basename"], "methods", ["None"], ["", "def", "results2img", "(", "self", ",", "results", ",", "imgfile_prefix", ",", "to_label_id", ")", ":", "\n", "        ", "\"\"\"Write the segmentation results to images.\n\n        Args:\n            results (list[list | tuple | ndarray]): Testing results of the\n                dataset.\n            imgfile_prefix (str): The filename prefix of the png files.\n                If the prefix is \"somepath/xxx\",\n                the png files will be named \"somepath/xxx.png\".\n            to_label_id (bool): whether convert output to label_id for\n                submission\n\n        Returns:\n            list[str: str]: result txt files which contains corresponding\n            semantic segmentation images.\n        \"\"\"", "\n", "mmcv", ".", "mkdir_or_exist", "(", "imgfile_prefix", ")", "\n", "result_files", "=", "[", "]", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "self", ")", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "result", "=", "results", "[", "idx", "]", "\n", "\n", "filename", "=", "self", ".", "img_infos", "[", "idx", "]", "[", "'filename'", "]", "\n", "basename", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "filename", ")", ")", "[", "0", "]", "\n", "\n", "png_filename", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "f'{basename}.png'", ")", "\n", "\n", "result", "=", "result", "+", "1", "\n", "\n", "output", "=", "Image", ".", "fromarray", "(", "result", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "output", ".", "save", "(", "png_filename", ")", "\n", "result_files", ".", "append", "(", "png_filename", ")", "\n", "\n", "prog_bar", ".", "update", "(", ")", "\n", "\n", "", "return", "result_files", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.prepare_test_img": [[100, 116], ["argoverse.ArgoverseDataset.get_ann_info", "dict", "argoverse.ArgoverseDataset.pre_pipeline", "argoverse.ArgoverseDataset.pipeline"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.get_ann_info", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.custom.CustomDataset.pre_pipeline"], ["", "def", "prepare_test_img", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get training data and annotations after pipeline.\n\n        Args:\n            idx (int): Index of data.\n\n        Returns:\n            dict: Training data and annotation after pipeline with new keys\n                introduced by pipeline.\n        \"\"\"", "\n", "\n", "img_info", "=", "self", ".", "img_infos", "[", "idx", "]", "\n", "ann_info", "=", "self", ".", "get_ann_info", "(", "idx", ")", "\n", "results", "=", "dict", "(", "img_info", "=", "img_info", ",", "ann_info", "=", "ann_info", ")", "\n", "self", ".", "pre_pipeline", "(", "results", ")", "\n", "return", "self", ".", "pipeline", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.format_results": [[117, 157], ["isinstance", "os.join", "os.join", "mmcv.utils.print_log", "tqdm.trange", "os.exists", "os.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "numpy.invert", "numpy.concatenate", "argoverse.visualize_map_mask", "argoverse.visualize_map_mask", "mmcv.imread", "mmcv.imresize", "numpy.concatenate", "os.join", "os.join", "mmcv.imwrite", "os.path.basename", "os.path.basename", "os.path.basename", "os.path.basename", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask"], ["", "def", "format_results", "(", "self", ",", "results", ",", "imgfile_prefix", "=", "None", ",", "to_label_id", "=", "True", ")", ":", "\n", "        ", "\"\"\"Format the results into dir for visualization.\n\n        Args:\n            results (list): Testing results of the dataset.\n            imgfile_prefix (str | None): The prefix of images files. It\n                includes the file path and the prefix of filename, e.g.,\n                \"a/b/prefix\". If not specified, a temp file will be created.\n                Default: None.\n            to_label_id (bool): whether convert output to label_id for\n                submission. Default: False\n\n        Returns:\n            tuple: (result_files, tmp_dir), result_files is a list containing\n               the image paths, tmp_dir is the temporal directory created\n                for saving json/png files when img_prefix is not specified.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "results", ",", "list", ")", ",", "'results must be a list'", "\n", "\n", "imgfile_prefix", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "'vis'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "imgfile_prefix", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "imgfile_prefix", ")", "\n", "", "print_log", "(", "'\\n Start formatting the result'", ")", "\n", "\n", "for", "id", "in", "trange", "(", "len", "(", "results", ")", ")", ":", "\n", "            ", "pred", ",", "gt", ",", "img_path", "=", "results", "[", "id", "]", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "pred", ".", "shape", "\n", "assert", "pred", ".", "shape", "[", "0", "]", "==", "1", "and", "gt", ".", "shape", "[", "0", "]", "==", "1", "\n", "pred", "=", "pred", "[", "0", "]", "\n", "gt", "=", "gt", "[", "0", "]", "\n", "gt", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt", "[", "-", "1", ",", "...", "]", ")", "\n", "pred", "=", "np", ".", "concatenate", "(", "[", "pred", ",", "gt", "[", "-", "1", ",", "...", "]", "[", "None", ",", "...", "]", "]", ",", "axis", "=", "0", ")", "\n", "pred_vis", "=", "visualize_map_mask", "(", "pred", ")", "\n", "gt_vis", "=", "visualize_map_mask", "(", "gt", ")", "\n", "img", "=", "mmcv", ".", "imread", "(", "img_path", ",", "backend", "=", "'cv2'", ")", "\n", "img", "=", "mmcv", ".", "imresize", "(", "img", ",", "(", "int", "(", "float", "(", "img", ".", "shape", "[", "1", "]", ")", "*", "h", "/", "float", "(", "img", ".", "shape", "[", "0", "]", ")", ")", ",", "h", ")", ")", "\n", "vis", "=", "np", ".", "concatenate", "(", "[", "img", ",", "pred_vis", "[", ":", ":", "-", "1", ",", "...", "]", ",", "gt_vis", "[", ":", ":", "-", "1", ",", "]", "]", ",", "axis", "=", "1", ")", "\n", "save_path", "=", "osp", ".", "join", "(", "imgfile_prefix", ",", "os", ".", "path", ".", "basename", "(", "img_path", ")", ")", "\n", "mmcv", ".", "imwrite", "(", "vis", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.evaluate": [[158, 219], ["isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "set().issubset", "KeyError", "set", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "set", "torch.cat.sum().float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "range", "mmcv.utils.print_log", "torch.cat.float", "len", "mmcv.utils.print_log", "mmcv.utils.print_log", "torch.cat.sum", "ious.mean", "iou_c.mean.mean.mean", "torch.cat.sum().float", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "ious.mean", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum"], "methods", ["None"], ["", "", "def", "evaluate", "(", "self", ",", "\n", "results", ",", "\n", "metric", "=", "'mIoU'", ",", "\n", "logger", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calculate the evaluate result according to the metric type.\n\n            Args:\n                results (list): Testing results of the dataset.\n                metric (str | list[str]): Type of evalutate metric, mIoU is in consistent\n                    with \"Predicting Semantic Map Representations from Images with\n                    Pyramid Occupancy Networks. CVPR2020\", where per class fp,fn,tp are\n                    calculated on the hold dataset first. mIOUv1 calculates the per\n                    class iou in each image first and average the result between the\n                    valid images (i.e. for class c, there is positive sample point in\n                    this image). mIOUv2 calculates the per image iou first and average\n                    the result between all images.\n                logger (logging.Logger | None | str): Logger used for printing\n                    related information during evaluation. Default: None.\n\n            Returns:\n                tuple: (result_files, tmp_dir), result_files is a list containing\n                   the image paths, tmp_dir is the temporal directory created\n                    for saving json/png files when img_prefix is not specified.\n            \"\"\"", "\n", "if", "isinstance", "(", "metric", ",", "str", ")", ":", "\n", "            ", "metric", "=", "[", "metric", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mIoUv1'", ",", "'mIoUv2'", "]", "\n", "if", "not", "set", "(", "metric", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "            ", "raise", "KeyError", "(", "'metric {} is not supported'", ".", "format", "(", "metric", ")", ")", "\n", "", "tp", "=", "torch", ".", "cat", "(", "[", "res", "[", "0", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fp", "=", "torch", ".", "cat", "(", "[", "res", "[", "1", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "fn", "=", "torch", ".", "cat", "(", "[", "res", "[", "2", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "valids", "=", "torch", ".", "cat", "(", "[", "res", "[", "3", "]", "[", "None", ",", "...", "]", "for", "res", "in", "results", "]", ",", "dim", "=", "0", ")", "#N*C", "\n", "for", "met", "in", "metric", ":", "\n", "            ", "if", "met", "==", "'mIoU'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "0", ")", "+", "fp", ".", "sum", "(", "0", ")", "+", "fn", ".", "sum", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "print_log", "(", "'%.04f:%s tp:%d fp:%d fn:%d'", "%", "(", "ious", "[", "cid", "]", ",", "self", ".", "CLASSES", "[", "cid", "]", ",", "tp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fp", ".", "sum", "(", "0", ")", "[", "cid", "]", ",", "fn", ".", "sum", "(", "0", ")", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv1'", ":", "\n", "                ", "ious", "=", "tp", ".", "float", "(", ")", "/", "(", "tp", "+", "fp", "+", "fn", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\nper class results (iou):'", ",", "logger", ")", "\n", "miou", ",", "valid_class", "=", "0", ",", "0", "\n", "for", "cid", "in", "range", "(", "len", "(", "self", ".", "CLASSES", ")", ")", ":", "\n", "                    ", "iou_c", "=", "ious", "[", ":", ",", "cid", "]", "[", "valids", "[", ":", ",", "cid", "]", "]", "\n", "if", "iou_c", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                        ", "iou_c", "=", "iou_c", ".", "mean", "(", ")", "\n", "miou", "+=", "iou_c", "\n", "valid_class", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "iou_c", "=", "-", "1", "\n", "", "print_log", "(", "'%.04f:%s'", "%", "(", "iou_c", ",", "self", ".", "CLASSES", "[", "cid", "]", ")", ",", "logger", ")", "\n", "", "print_log", "(", "'%s: %.04f'", "%", "(", "met", ",", "miou", "/", "valid_class", ")", ",", "logger", ")", "\n", "", "elif", "met", "==", "'mIoUv2'", ":", "\n", "                ", "ious", "=", "tp", ".", "sum", "(", "-", "1", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", "-", "1", ")", "+", "fp", ".", "sum", "(", "-", "1", ")", "+", "fn", ".", "sum", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "print_log", "(", "'\\n%s: %.04f'", "%", "(", "met", ",", "ious", ".", "mean", "(", ")", ")", ",", "logger", ")", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "'nuknown metric type %s'", "%", "metric", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.covert_color": [[17, 25], ["int", "int", "int"], "function", ["None"], ["def", "covert_color", "(", "input", ")", ":", "\n", "    ", "str1", "=", "input", "[", "1", ":", "3", "]", "\n", "str2", "=", "input", "[", "3", ":", "5", "]", "\n", "str3", "=", "input", "[", "5", ":", "7", "]", "\n", "r", "=", "int", "(", "'0x'", "+", "str1", ",", "16", ")", "\n", "g", "=", "int", "(", "'0x'", "+", "str2", ",", "16", ")", "\n", "b", "=", "int", "(", "'0x'", "+", "str3", ",", "16", ")", "\n", "return", "(", "r", ",", "g", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.visualize_map_mask": [[27, 39], ["numpy.zeros", "vis.reshape.reshape", "map_mask.reshape.reshape", "range", "vis.reshape.reshape", "range", "numpy.where", "argoverse.covert_color"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.covert_color"], ["", "def", "visualize_map_mask", "(", "map_mask", ")", ":", "\n", "    ", "color_map", "=", "[", "'#a6cee3'", ",", "'#1f78b4'", ",", "'#b2df8a'", ",", "'#33a02c'", ",", "'#fb9a99'", ",", "\n", "'#e31a1c'", ",", "'#fdbf6f'", ",", "'#ff7f00'", ",", "'#303030'", "]", "\n", "ori_shape", "=", "map_mask", ".", "shape", "\n", "vis", "=", "np", ".", "zeros", "(", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "vis", "=", "vis", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "map_mask", "=", "map_mask", ".", "reshape", "(", "ori_shape", "[", "0", "]", ",", "-", "1", ")", "\n", "for", "layer_id", "in", "range", "(", "map_mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "keep", "=", "np", ".", "where", "(", "map_mask", "[", "layer_id", ",", ":", "]", ")", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "vis", "[", "keep", ",", "2", "-", "i", "]", "=", "covert_color", "(", "color_map", "[", "layer_id", "]", ")", "[", "i", "]", "\n", "", "", "return", "vis", ".", "reshape", "(", "ori_shape", "[", "1", "]", ",", "ori_shape", "[", "2", "]", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.ResizeToMultiple.__init__": [[27, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size_divisor", "=", "32", ",", "interpolation", "=", "None", ")", ":", "\n", "        ", "self", ".", "size_divisor", "=", "size_divisor", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.ResizeToMultiple.__call__": [[31, 65], ["mmcv.imresize_to_multiple", "results.get", "mmcv.imresize_to_multiple"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to resize images, semantic segmentation map to\n        multiple of size divisor.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Resized results, 'img_shape', 'pad_shape' keys are updated.\n        \"\"\"", "\n", "# Align image to multiple of size divisor.", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "img", "=", "mmcv", ".", "imresize_to_multiple", "(", "\n", "img", ",", "\n", "self", ".", "size_divisor", ",", "\n", "scale_factor", "=", "1", ",", "\n", "interpolation", "=", "self", ".", "interpolation", "\n", "if", "self", ".", "interpolation", "else", "'bilinear'", ")", "\n", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img", ".", "shape", "\n", "results", "[", "'pad_shape'", "]", "=", "img", ".", "shape", "\n", "\n", "# Align segmentation map to multiple of size divisor.", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "            ", "gt_seg", "=", "results", "[", "key", "]", "\n", "gt_seg", "=", "mmcv", ".", "imresize_to_multiple", "(", "\n", "gt_seg", ",", "\n", "self", ".", "size_divisor", ",", "\n", "scale_factor", "=", "1", ",", "\n", "interpolation", "=", "'nearest'", ")", "\n", "results", "[", "key", "]", "=", "gt_seg", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.ResizeToMultiple.__repr__": [[66, 71], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "(", "f'(size_divisor={self.size_divisor}, '", "\n", "f'interpolation={self.interpolation})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.__init__": [[108, 135], ["isinstance", "mmcv.is_list_of", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "img_scale", "=", "None", ",", "\n", "multiscale_mode", "=", "'range'", ",", "\n", "ratio_range", "=", "None", ",", "\n", "keep_ratio", "=", "True", ",", "\n", "resize_gt", "=", "True", ")", ":", "\n", "        ", "if", "img_scale", "is", "None", ":", "\n", "            ", "self", ".", "img_scale", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "img_scale", ",", "list", ")", ":", "\n", "                ", "self", ".", "img_scale", "=", "img_scale", "\n", "", "else", ":", "\n", "                ", "self", ".", "img_scale", "=", "[", "img_scale", "]", "\n", "", "assert", "mmcv", ".", "is_list_of", "(", "self", ".", "img_scale", ",", "tuple", ")", "\n", "\n", "", "if", "ratio_range", "is", "not", "None", ":", "\n", "# mode 1: given img_scale=None and a range of image ratio", "\n", "# mode 2: given a scale and a range of image ratio", "\n", "            ", "assert", "self", ".", "img_scale", "is", "None", "or", "len", "(", "self", ".", "img_scale", ")", "==", "1", "\n", "", "else", ":", "\n", "# mode 3 and 4: given multiple scales or a range of scales", "\n", "            ", "assert", "multiscale_mode", "in", "[", "'value'", ",", "'range'", "]", "\n", "\n", "", "self", ".", "multiscale_mode", "=", "multiscale_mode", "\n", "self", ".", "ratio_range", "=", "ratio_range", "\n", "self", ".", "keep_ratio", "=", "keep_ratio", "\n", "self", ".", "resize_gt", "=", "resize_gt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_select": [[136, 153], ["mmcv.is_list_of", "numpy.random.randint", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_select", "(", "img_scales", ")", ":", "\n", "        ", "\"\"\"Randomly select an img_scale from given candidates.\n\n        Args:\n            img_scales (list[tuple]): Images scales for selection.\n\n        Returns:\n            (tuple, int): Returns a tuple ``(img_scale, scale_dix)``,\n                where ``img_scale`` is the selected image scale and\n                ``scale_idx`` is the selected index in the given candidates.\n        \"\"\"", "\n", "\n", "assert", "mmcv", ".", "is_list_of", "(", "img_scales", ",", "tuple", ")", "\n", "scale_idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "img_scales", ")", ")", "\n", "img_scale", "=", "img_scales", "[", "scale_idx", "]", "\n", "return", "img_scale", ",", "scale_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_sample": [[154, 180], ["numpy.random.randint", "numpy.random.randint", "mmcv.is_list_of", "max", "min", "min", "min", "len", "max", "max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "random_sample", "(", "img_scales", ")", ":", "\n", "        ", "\"\"\"Randomly sample an img_scale when ``multiscale_mode=='range'``.\n\n        Args:\n            img_scales (list[tuple]): Images scale range for sampling.\n                There must be two tuples in img_scales, which specify the lower\n                and upper bound of image scales.\n\n        Returns:\n            (tuple, None): Returns a tuple ``(img_scale, None)``, where\n                ``img_scale`` is sampled scale and None is just a placeholder\n                to be consistent with :func:`random_select`.\n        \"\"\"", "\n", "\n", "assert", "mmcv", ".", "is_list_of", "(", "img_scales", ",", "tuple", ")", "and", "len", "(", "img_scales", ")", "==", "2", "\n", "img_scale_long", "=", "[", "max", "(", "s", ")", "for", "s", "in", "img_scales", "]", "\n", "img_scale_short", "=", "[", "min", "(", "s", ")", "for", "s", "in", "img_scales", "]", "\n", "long_edge", "=", "np", ".", "random", ".", "randint", "(", "\n", "min", "(", "img_scale_long", ")", ",", "\n", "max", "(", "img_scale_long", ")", "+", "1", ")", "\n", "short_edge", "=", "np", ".", "random", ".", "randint", "(", "\n", "min", "(", "img_scale_short", ")", ",", "\n", "max", "(", "img_scale_short", ")", "+", "1", ")", "\n", "img_scale", "=", "(", "long_edge", ",", "short_edge", ")", "\n", "return", "img_scale", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_sample_ratio": [[181, 207], ["isinstance", "int", "int", "len", "numpy.random.random_sample"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_sample"], ["", "@", "staticmethod", "\n", "def", "random_sample_ratio", "(", "img_scale", ",", "ratio_range", ")", ":", "\n", "        ", "\"\"\"Randomly sample an img_scale when ``ratio_range`` is specified.\n\n        A ratio will be randomly sampled from the range specified by\n        ``ratio_range``. Then it would be multiplied with ``img_scale`` to\n        generate sampled scale.\n\n        Args:\n            img_scale (tuple): Images scale base to multiply with ratio.\n            ratio_range (tuple[float]): The minimum and maximum ratio to scale\n                the ``img_scale``.\n\n        Returns:\n            (tuple, None): Returns a tuple ``(scale, None)``, where\n                ``scale`` is sampled ratio multiplied with ``img_scale`` and\n                None is just a placeholder to be consistent with\n                :func:`random_select`.\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "img_scale", ",", "tuple", ")", "and", "len", "(", "img_scale", ")", "==", "2", "\n", "min_ratio", ",", "max_ratio", "=", "ratio_range", "\n", "assert", "min_ratio", "<=", "max_ratio", "\n", "ratio", "=", "np", ".", "random", ".", "random_sample", "(", ")", "*", "(", "max_ratio", "-", "min_ratio", ")", "+", "min_ratio", "\n", "scale", "=", "int", "(", "img_scale", "[", "0", "]", "*", "ratio", ")", ",", "int", "(", "img_scale", "[", "1", "]", "*", "ratio", ")", "\n", "return", "scale", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize._random_scale": [[208, 245], ["transforms.Resize.random_sample_ratio", "transforms.Resize.random_sample_ratio", "len", "transforms.Resize.random_sample", "transforms.Resize.random_select"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_sample_ratio", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_sample_ratio", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_sample", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.random_select"], ["", "def", "_random_scale", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Randomly sample an img_scale according to ``ratio_range`` and\n        ``multiscale_mode``.\n\n        If ``ratio_range`` is specified, a ratio will be sampled and be\n        multiplied with ``img_scale``.\n        If multiple scales are specified by ``img_scale``, a scale will be\n        sampled according to ``multiscale_mode``.\n        Otherwise, single scale will be used.\n\n        Args:\n            results (dict): Result dict from :obj:`dataset`.\n\n        Returns:\n            dict: Two new keys 'scale` and 'scale_idx` are added into\n                ``results``, which would be used by subsequent pipelines.\n        \"\"\"", "\n", "\n", "if", "self", ".", "ratio_range", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "img_scale", "is", "None", ":", "\n", "                ", "h", ",", "w", "=", "results", "[", "'img'", "]", ".", "shape", "[", ":", "2", "]", "\n", "scale", ",", "scale_idx", "=", "self", ".", "random_sample_ratio", "(", "(", "w", ",", "h", ")", ",", "\n", "self", ".", "ratio_range", ")", "\n", "", "else", ":", "\n", "                ", "scale", ",", "scale_idx", "=", "self", ".", "random_sample_ratio", "(", "\n", "self", ".", "img_scale", "[", "0", "]", ",", "self", ".", "ratio_range", ")", "\n", "", "", "elif", "len", "(", "self", ".", "img_scale", ")", "==", "1", ":", "\n", "            ", "scale", ",", "scale_idx", "=", "self", ".", "img_scale", "[", "0", "]", ",", "0", "\n", "", "elif", "self", ".", "multiscale_mode", "==", "'range'", ":", "\n", "            ", "scale", ",", "scale_idx", "=", "self", ".", "random_sample", "(", "self", ".", "img_scale", ")", "\n", "", "elif", "self", ".", "multiscale_mode", "==", "'value'", ":", "\n", "            ", "scale", ",", "scale_idx", "=", "self", ".", "random_select", "(", "self", ".", "img_scale", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "results", "[", "'scale'", "]", "=", "scale", "\n", "results", "[", "'scale_idx'", "]", "=", "scale_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize._resize_img": [[246, 267], ["numpy.array", "mmcv.imrescale", "mmcv.imresize"], "methods", ["None"], ["", "def", "_resize_img", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Resize images with ``results['scale']``.\"\"\"", "\n", "if", "self", ".", "keep_ratio", ":", "\n", "            ", "img", ",", "scale_factor", "=", "mmcv", ".", "imrescale", "(", "\n", "results", "[", "'img'", "]", ",", "results", "[", "'scale'", "]", ",", "return_scale", "=", "True", ")", "\n", "# the w_scale and h_scale has minor difference", "\n", "# a real fix should be done in the mmcv.imrescale in the future", "\n", "new_h", ",", "new_w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "h", ",", "w", "=", "results", "[", "'img'", "]", ".", "shape", "[", ":", "2", "]", "\n", "w_scale", "=", "new_w", "/", "w", "\n", "h_scale", "=", "new_h", "/", "h", "\n", "", "else", ":", "\n", "            ", "img", ",", "w_scale", ",", "h_scale", "=", "mmcv", ".", "imresize", "(", "\n", "results", "[", "'img'", "]", ",", "results", "[", "'scale'", "]", ",", "return_scale", "=", "True", ")", "\n", "", "scale_factor", "=", "np", ".", "array", "(", "[", "w_scale", ",", "h_scale", ",", "w_scale", ",", "h_scale", "]", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img", ".", "shape", "\n", "results", "[", "'pad_shape'", "]", "=", "img", ".", "shape", "# in case that there is no padding", "\n", "results", "[", "'scale_factor'", "]", "=", "scale_factor", "\n", "results", "[", "'keep_ratio'", "]", "=", "self", ".", "keep_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize._resize_seg": [[268, 278], ["results.get", "mmcv.imrescale", "mmcv.imresize"], "methods", ["None"], ["", "def", "_resize_seg", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Resize semantic segmentation map with ``results['scale']``.\"\"\"", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "            ", "if", "self", ".", "keep_ratio", ":", "\n", "                ", "gt_seg", "=", "mmcv", ".", "imrescale", "(", "\n", "results", "[", "key", "]", ",", "results", "[", "'scale'", "]", ",", "interpolation", "=", "'nearest'", ")", "\n", "", "else", ":", "\n", "                ", "gt_seg", "=", "mmcv", ".", "imresize", "(", "\n", "results", "[", "key", "]", ",", "results", "[", "'scale'", "]", ",", "interpolation", "=", "'nearest'", ")", "\n", "", "results", "[", "key", "]", "=", "gt_seg", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.__call__": [[279, 297], ["transforms.Resize._resize_img", "transforms.Resize._random_scale", "transforms.Resize._resize_seg"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize._resize_img", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize._random_scale", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize._resize_seg"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to resize images, bounding boxes, masks, semantic\n        segmentation map.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Resized results, 'img_shape', 'pad_shape', 'scale_factor',\n                'keep_ratio' keys are added into result dict.\n        \"\"\"", "\n", "\n", "if", "'scale'", "not", "in", "results", ":", "\n", "            ", "self", ".", "_random_scale", "(", "results", ")", "\n", "", "self", ".", "_resize_img", "(", "results", ")", "\n", "if", "self", ".", "resize_gt", ":", "\n", "            ", "self", ".", "_resize_seg", "(", "results", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Resize.__repr__": [[298, 305], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "(", "f'(img_scale={self.img_scale}, '", "\n", "f'multiscale_mode={self.multiscale_mode}, '", "\n", "f'ratio_range={self.ratio_range}, '", "\n", "f'keep_ratio={self.keep_ratio})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlip.__init__": [[321, 328], ["mmcv.utils.deprecated_api_warning"], "methods", ["None"], ["@", "deprecated_api_warning", "(", "{", "'flip_ratio'", ":", "'prob'", "}", ",", "cls_name", "=", "'RandomFlip'", ")", "\n", "def", "__init__", "(", "self", ",", "prob", "=", "None", ",", "direction", "=", "'horizontal'", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "self", ".", "direction", "=", "direction", "\n", "if", "prob", "is", "not", "None", ":", "\n", "            ", "assert", "prob", ">=", "0", "and", "prob", "<=", "1", "\n", "", "assert", "direction", "in", "[", "'horizontal'", ",", "'vertical'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlip.__call__": [[329, 357], ["mmcv.imflip", "results.get", "mmcv.imflip().copy", "numpy.random.rand", "mmcv.imflip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to flip bounding boxes, masks, semantic segmentation\n        maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Flipped results, 'flip', 'flip_direction' keys are added into\n                result dict.\n        \"\"\"", "\n", "# np.random.rand() return a random value ranged [0,1)", "\n", "if", "'flip'", "not", "in", "results", ":", "\n", "            ", "flip", "=", "True", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", "else", "False", "\n", "results", "[", "'flip'", "]", "=", "flip", "\n", "", "if", "'flip_direction'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'flip_direction'", "]", "=", "self", ".", "direction", "\n", "", "if", "results", "[", "'flip'", "]", ":", "\n", "# flip image", "\n", "            ", "results", "[", "'img'", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "'img'", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", "\n", "# seg shape: 15x196x200,numpy array", "\n", "# flip segs", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "# use copy() to make numpy stride positive", "\n", "                ", "results", "[", "key", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "key", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", ".", "copy", "(", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlip.__repr__": [[358, 360], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(prob={self.prob})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipNuscenes.__init__": [[376, 383], ["mmcv.utils.deprecated_api_warning"], "methods", ["None"], ["@", "deprecated_api_warning", "(", "{", "'flip_ratio'", ":", "'prob'", "}", ",", "cls_name", "=", "'RandomFlip'", ")", "\n", "def", "__init__", "(", "self", ",", "prob", "=", "None", ",", "direction", "=", "'horizontal'", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "self", ".", "direction", "=", "direction", "\n", "if", "prob", "is", "not", "None", ":", "\n", "            ", "assert", "prob", ">=", "0", "and", "prob", "<=", "1", "\n", "", "assert", "direction", "in", "[", "'horizontal'", ",", "'vertical'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipNuscenes.__call__": [[384, 414], ["mmcv.imflip", "results.get", "results[].astype", "range", "results[].astype", "numpy.random.rand", "mmcv.imflip().copy", "mmcv.imflip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to flip bounding boxes, masks, semantic segmentation\n        maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Flipped results, 'flip', 'flip_direction' keys are added into\n                result dict.\n        \"\"\"", "\n", "if", "'flip'", "not", "in", "results", ":", "\n", "            ", "flip", "=", "True", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", "else", "False", "\n", "results", "[", "'flip'", "]", "=", "flip", "\n", "", "if", "'flip_direction'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'flip_direction'", "]", "=", "self", ".", "direction", "\n", "", "if", "results", "[", "'flip'", "]", ":", "\n", "# flip image", "\n", "            ", "results", "[", "'img'", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "'img'", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", "\n", "# seg shape: (14+1)x196x200,numpy array", "\n", "# flip segs", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "# use copy() to make numpy stride positive", "\n", "                ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "'uint8'", ")", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "                    ", "results", "[", "key", "]", "[", "i", ",", "...", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "key", "]", "[", "i", ",", "...", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", ".", "copy", "(", ")", "\n", "", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "bool", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipNuscenes.__repr__": [[415, 417], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(prob={self.prob})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipArgoverse.__init__": [[433, 440], ["mmcv.utils.deprecated_api_warning"], "methods", ["None"], ["@", "deprecated_api_warning", "(", "{", "'flip_ratio'", ":", "'prob'", "}", ",", "cls_name", "=", "'RandomFlip'", ")", "\n", "def", "__init__", "(", "self", ",", "prob", "=", "None", ",", "direction", "=", "'horizontal'", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "self", ".", "direction", "=", "direction", "\n", "if", "prob", "is", "not", "None", ":", "\n", "            ", "assert", "prob", ">=", "0", "and", "prob", "<=", "1", "\n", "", "assert", "direction", "in", "[", "'horizontal'", ",", "'vertical'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipArgoverse.__call__": [[441, 471], ["mmcv.imflip", "results.get", "results[].astype", "range", "results[].astype", "numpy.random.rand", "mmcv.imflip().copy", "mmcv.imflip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to flip bounding boxes, masks, semantic segmentation\n        maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Flipped results, 'flip', 'flip_direction' keys are added into\n                result dict.\n        \"\"\"", "\n", "if", "'flip'", "not", "in", "results", ":", "\n", "            ", "flip", "=", "True", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", "else", "False", "\n", "results", "[", "'flip'", "]", "=", "flip", "\n", "", "if", "'flip_direction'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'flip_direction'", "]", "=", "self", ".", "direction", "\n", "", "if", "results", "[", "'flip'", "]", ":", "\n", "# flip image", "\n", "            ", "results", "[", "'img'", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "'img'", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", "\n", "# seg shape: (8+1)x196x200,numpy array", "\n", "# flip segs", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "# use copy() to make numpy stride positive", "\n", "                ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "'uint8'", ")", "\n", "for", "i", "in", "range", "(", "9", ")", ":", "\n", "                    ", "results", "[", "key", "]", "[", "i", ",", "...", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "key", "]", "[", "i", ",", "...", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", ".", "copy", "(", ")", "\n", "", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "bool", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipArgoverse.__repr__": [[472, 474], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(prob={self.prob})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipKitti.__init__": [[492, 499], ["mmcv.utils.deprecated_api_warning"], "methods", ["None"], ["@", "deprecated_api_warning", "(", "{", "'flip_ratio'", ":", "'prob'", "}", ",", "cls_name", "=", "'RandomFlip'", ")", "\n", "def", "__init__", "(", "self", ",", "prob", "=", "None", ",", "direction", "=", "'horizontal'", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "self", ".", "direction", "=", "direction", "\n", "if", "prob", "is", "not", "None", ":", "\n", "            ", "assert", "prob", ">=", "0", "and", "prob", "<=", "1", "\n", "", "assert", "direction", "in", "[", "'horizontal'", ",", "'vertical'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipKitti.__call__": [[500, 530], ["mmcv.imflip", "results.get", "results[].astype", "range", "results[].astype", "numpy.random.rand", "mmcv.imflip().copy", "mmcv.imflip"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to flip bounding boxes, masks, semantic segmentation\n        maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Flipped results, 'flip', 'flip_direction' keys are added into\n                result dict.\n        \"\"\"", "\n", "if", "'flip'", "not", "in", "results", ":", "\n", "            ", "flip", "=", "True", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", "else", "False", "\n", "results", "[", "'flip'", "]", "=", "flip", "\n", "", "if", "'flip_direction'", "not", "in", "results", ":", "\n", "            ", "results", "[", "'flip_direction'", "]", "=", "self", ".", "direction", "\n", "", "if", "results", "[", "'flip'", "]", ":", "\n", "# flip image", "\n", "            ", "results", "[", "'img'", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "'img'", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", "\n", "# seg shape: (1+1)x196x200,numpy array", "\n", "# flip segs", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "# use copy() to make numpy stride positive", "\n", "                ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "'uint8'", ")", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                    ", "results", "[", "key", "]", "[", "i", ",", "...", "]", "=", "mmcv", ".", "imflip", "(", "\n", "results", "[", "key", "]", "[", "i", ",", "...", "]", ",", "direction", "=", "results", "[", "'flip_direction'", "]", ")", ".", "copy", "(", ")", "\n", "", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "bool", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomFlipKitti.__repr__": [[531, 533], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(prob={self.prob})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Pad.__init__": [[550, 562], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "size", "=", "None", ",", "\n", "size_divisor", "=", "None", ",", "\n", "pad_val", "=", "0", ",", "\n", "seg_pad_val", "=", "255", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "size_divisor", "=", "size_divisor", "\n", "self", ".", "pad_val", "=", "pad_val", "\n", "self", ".", "seg_pad_val", "=", "seg_pad_val", "\n", "# only one of size and size_divisor should be valid", "\n", "assert", "size", "is", "not", "None", "or", "size_divisor", "is", "not", "None", "\n", "assert", "size", "is", "None", "or", "size_divisor", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Pad._pad_img": [[563, 576], ["mmcv.impad", "mmcv.impad_to_multiple"], "methods", ["None"], ["", "def", "_pad_img", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Pad images according to ``self.size``.\"\"\"", "\n", "if", "self", ".", "size", "is", "not", "None", ":", "\n", "# results['img'] type:numpy array,results['img'].shape:[crop_size,3],for example,[512,1024,3]", "\n", "            ", "padded_img", "=", "mmcv", ".", "impad", "(", "\n", "results", "[", "'img'", "]", ",", "shape", "=", "self", ".", "size", ",", "pad_val", "=", "self", ".", "pad_val", ")", "\n", "", "elif", "self", ".", "size_divisor", "is", "not", "None", ":", "\n", "            ", "padded_img", "=", "mmcv", ".", "impad_to_multiple", "(", "\n", "results", "[", "'img'", "]", ",", "self", ".", "size_divisor", ",", "pad_val", "=", "self", ".", "pad_val", ")", "\n", "", "results", "[", "'img'", "]", "=", "padded_img", "\n", "results", "[", "'pad_shape'", "]", "=", "padded_img", ".", "shape", "\n", "results", "[", "'pad_fixed_size'", "]", "=", "self", ".", "size", "\n", "results", "[", "'pad_size_divisor'", "]", "=", "self", ".", "size_divisor", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Pad._pad_seg": [[577, 585], ["results.get", "mmcv.impad"], "methods", ["None"], ["", "def", "_pad_seg", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Pad masks according to ``results['pad_shape']``.\"\"\"", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "# results[key] is numpy array,results[key].shape:[0,196,200]", "\n", "            ", "results", "[", "key", "]", "=", "mmcv", ".", "impad", "(", "\n", "results", "[", "key", "]", ",", "\n", "shape", "=", "results", "[", "'pad_shape'", "]", "[", ":", "2", "]", ",", "\n", "pad_val", "=", "self", ".", "seg_pad_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Pad.__call__": [[586, 599], ["transforms.Pad._pad_img", "transforms.Pad._pad_seg"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes._pad_img", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes._pad_seg"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to pad images, masks, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Updated result dict.\n        \"\"\"", "\n", "\n", "self", ".", "_pad_img", "(", "results", ")", "\n", "self", ".", "_pad_seg", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Pad.__repr__": [[600, 605], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(size={self.size}, size_divisor={self.size_divisor}, '", "f'pad_val={self.pad_val})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes.__init__": [[622, 634], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "size", "=", "None", ",", "\n", "size_divisor", "=", "None", ",", "\n", "pad_val", "=", "0", ",", "\n", "seg_pad_val", "=", "0", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "size_divisor", "=", "size_divisor", "\n", "self", ".", "pad_val", "=", "pad_val", "\n", "self", ".", "seg_pad_val", "=", "seg_pad_val", "\n", "# only one of size and size_divisor should be valid", "\n", "assert", "size", "is", "not", "None", "or", "size_divisor", "is", "not", "None", "\n", "assert", "size", "is", "None", "or", "size_divisor", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes._pad_img": [[635, 648], ["mmcv.impad", "mmcv.impad_to_multiple"], "methods", ["None"], ["", "def", "_pad_img", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Pad images according to ``self.size``.\"\"\"", "\n", "if", "self", ".", "size", "is", "not", "None", ":", "\n", "# results['img'] type:numpy array,results['img'].shape:[crop_size,3],for example,[512,1024,3]", "\n", "            ", "padded_img", "=", "mmcv", ".", "impad", "(", "\n", "results", "[", "'img'", "]", ",", "shape", "=", "self", ".", "size", ",", "pad_val", "=", "self", ".", "pad_val", ")", "\n", "", "elif", "self", ".", "size_divisor", "is", "not", "None", ":", "\n", "            ", "padded_img", "=", "mmcv", ".", "impad_to_multiple", "(", "\n", "results", "[", "'img'", "]", ",", "self", ".", "size_divisor", ",", "pad_val", "=", "self", ".", "pad_val", ")", "\n", "", "results", "[", "'img'", "]", "=", "padded_img", "\n", "results", "[", "'pad_shape'", "]", "=", "padded_img", ".", "shape", "\n", "results", "[", "'pad_fixed_size'", "]", "=", "self", ".", "size", "\n", "results", "[", "'pad_size_divisor'", "]", "=", "self", ".", "size_divisor", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes._pad_seg": [[649, 660], ["results.get", "results[].astype", "range", "results[].astype", "mmcv.impad"], "methods", ["None"], ["", "def", "_pad_seg", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Pad masks according to ``results['pad_shape']``.\"\"\"", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "# results[key] is numpy array,results[key].shape:[0,196,200]", "\n", "            ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "'uint8'", ")", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "                ", "results", "[", "key", "]", "[", "i", ",", "...", "]", "=", "mmcv", ".", "impad", "(", "\n", "results", "[", "key", "]", "[", "i", ",", "...", "]", ",", "\n", "shape", "=", "results", "[", "'pad_shape'", "]", "[", ":", "2", "]", ",", "\n", "pad_val", "=", "self", ".", "seg_pad_val", ")", "\n", "", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes.__call__": [[661, 674], ["transforms.PadNuscenes._pad_img", "transforms.PadNuscenes._pad_seg"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes._pad_img", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes._pad_seg"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to pad images, masks, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Updated result dict.\n        \"\"\"", "\n", "\n", "self", ".", "_pad_img", "(", "results", ")", "\n", "self", ".", "_pad_seg", "(", "results", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PadNuscenes.__repr__": [[675, 680], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(size={self.size}, size_divisor={self.size_divisor}, '", "f'pad_val={self.pad_val})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Normalize.__init__": [[695, 699], ["numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ",", "to_rgb", "=", "True", ")", ":", "\n", "        ", "self", ".", "mean", "=", "np", ".", "array", "(", "mean", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "std", "=", "np", ".", "array", "(", "std", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "to_rgb", "=", "to_rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Normalize.__call__": [[700, 715], ["mmcv.imnormalize", "dict"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to normalize images.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Normalized results, 'img_norm_cfg' key is added into\n                result dict.\n        \"\"\"", "\n", "results", "[", "'img'", "]", "=", "mmcv", ".", "imnormalize", "(", "results", "[", "'img'", "]", ",", "self", ".", "mean", ",", "self", ".", "std", ",", "\n", "self", ".", "to_rgb", ")", "\n", "results", "[", "'img_norm_cfg'", "]", "=", "dict", "(", "\n", "mean", "=", "self", ".", "mean", ",", "std", "=", "self", ".", "std", ",", "to_rgb", "=", "self", ".", "to_rgb", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Normalize.__repr__": [[716, 721], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(mean={self.mean}, std={self.std}, to_rgb='", "f'{self.to_rgb})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Rerange.__init__": [[734, 740], ["isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "min_value", "=", "0", ",", "max_value", "=", "255", ")", ":", "\n", "        ", "assert", "isinstance", "(", "min_value", ",", "float", ")", "or", "isinstance", "(", "min_value", ",", "int", ")", "\n", "assert", "isinstance", "(", "max_value", ",", "float", ")", "or", "isinstance", "(", "max_value", ",", "int", ")", "\n", "assert", "min_value", "<", "max_value", "\n", "self", ".", "min_value", "=", "min_value", "\n", "self", ".", "max_value", "=", "max_value", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Rerange.__call__": [[741, 762], ["numpy.min", "numpy.max"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to rerange images.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n        Returns:\n            dict: Reranged results.\n        \"\"\"", "\n", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "img_min_value", "=", "np", ".", "min", "(", "img", ")", "\n", "img_max_value", "=", "np", ".", "max", "(", "img", ")", "\n", "\n", "assert", "img_min_value", "<", "img_max_value", "\n", "# rerange to [0, 1]", "\n", "img", "=", "(", "img", "-", "img_min_value", ")", "/", "(", "img_max_value", "-", "img_min_value", ")", "\n", "# rerange to [min_value, max_value]", "\n", "img", "=", "img", "*", "(", "self", ".", "max_value", "-", "self", ".", "min_value", ")", "+", "self", ".", "min_value", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.Rerange.__repr__": [[763, 767], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(min_value={self.min_value}, max_value={self.max_value})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.CLAHE.__init__": [[783, 789], ["isinstance", "mmcv.utils.is_tuple_of", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "clip_limit", "=", "40.0", ",", "tile_grid_size", "=", "(", "8", ",", "8", ")", ")", ":", "\n", "        ", "assert", "isinstance", "(", "clip_limit", ",", "(", "float", ",", "int", ")", ")", "\n", "self", ".", "clip_limit", "=", "clip_limit", "\n", "assert", "is_tuple_of", "(", "tile_grid_size", ",", "int", ")", "\n", "assert", "len", "(", "tile_grid_size", ")", "==", "2", "\n", "self", ".", "tile_grid_size", "=", "tile_grid_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.CLAHE.__call__": [[790, 806], ["range", "mmcv.clahe", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to Use CLAHE method process images.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Processed results.\n        \"\"\"", "\n", "\n", "for", "i", "in", "range", "(", "results", "[", "'img'", "]", ".", "shape", "[", "2", "]", ")", ":", "\n", "            ", "results", "[", "'img'", "]", "[", ":", ",", ":", ",", "i", "]", "=", "mmcv", ".", "clahe", "(", "\n", "np", ".", "array", "(", "results", "[", "'img'", "]", "[", ":", ",", ":", ",", "i", "]", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "\n", "self", ".", "clip_limit", ",", "self", ".", "tile_grid_size", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.CLAHE.__repr__": [[807, 812], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(clip_limit={self.clip_limit}, '", "f'tile_grid_size={self.tile_grid_size})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCrop.__init__": [[824, 829], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "crop_size", ",", "cat_max_ratio", "=", "1.", ",", "ignore_index", "=", "255", ")", ":", "\n", "        ", "assert", "crop_size", "[", "0", "]", ">", "0", "and", "crop_size", "[", "1", "]", ">", "0", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "cat_max_ratio", "=", "cat_max_ratio", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCrop.get_crop_bbox": [[830, 840], ["max", "max", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["", "def", "get_crop_bbox", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Randomly get a crop bounding box.\"\"\"", "\n", "margin_h", "=", "max", "(", "img", ".", "shape", "[", "0", "]", "-", "self", ".", "crop_size", "[", "0", "]", ",", "0", ")", "\n", "margin_w", "=", "max", "(", "img", ".", "shape", "[", "1", "]", "-", "self", ".", "crop_size", "[", "1", "]", ",", "0", ")", "\n", "offset_h", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "margin_h", "+", "1", ")", "\n", "offset_w", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "margin_w", "+", "1", ")", "\n", "crop_y1", ",", "crop_y2", "=", "offset_h", ",", "offset_h", "+", "self", ".", "crop_size", "[", "0", "]", "\n", "crop_x1", ",", "crop_x2", "=", "offset_w", ",", "offset_w", "+", "self", ".", "crop_size", "[", "1", "]", "\n", "\n", "return", "crop_y1", ",", "crop_y2", ",", "crop_x1", ",", "crop_x2", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCrop.crop": [[841, 846], ["None"], "methods", ["None"], ["", "def", "crop", "(", "self", ",", "img", ",", "crop_bbox", ")", ":", "\n", "        ", "\"\"\"Crop from ``img``\"\"\"", "\n", "crop_y1", ",", "crop_y2", ",", "crop_x1", ",", "crop_x2", "=", "crop_bbox", "\n", "img", "=", "img", "[", "crop_y1", ":", "crop_y2", ",", "crop_x1", ":", "crop_x2", ",", "...", "]", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCrop.__call__": [[847, 882], ["transforms.RandomCrop.get_crop_bbox", "transforms.RandomCrop.crop", "results.get", "range", "transforms.RandomCrop.crop", "transforms.RandomCrop.crop", "numpy.unique", "transforms.RandomCrop.get_crop_bbox", "len", "numpy.max", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.get_crop_bbox", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.crop", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.crop", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.crop", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.get_crop_bbox"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to randomly crop images, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Randomly cropped results, 'img_shape' key in result dict is\n                updated according to crop size.\n        \"\"\"", "\n", "# results['gt_semantic_seg'] is numpy array, shape: 15 x 196 x 200", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "crop_bbox", "=", "self", ".", "get_crop_bbox", "(", "img", ")", "\n", "if", "self", ".", "cat_max_ratio", "<", "1.", ":", "\n", "# Repeat 10 times", "\n", "            ", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "seg_temp", "=", "self", ".", "crop", "(", "results", "[", "'gt_semantic_seg'", "]", ",", "crop_bbox", ")", "\n", "labels", ",", "cnt", "=", "np", ".", "unique", "(", "seg_temp", ",", "return_counts", "=", "True", ")", "\n", "cnt", "=", "cnt", "[", "labels", "!=", "self", ".", "ignore_index", "]", "\n", "if", "len", "(", "cnt", ")", ">", "1", "and", "np", ".", "max", "(", "cnt", ")", "/", "np", ".", "sum", "(", "\n", "cnt", ")", "<", "self", ".", "cat_max_ratio", ":", "\n", "                    ", "break", "\n", "", "crop_bbox", "=", "self", ".", "get_crop_bbox", "(", "img", ")", "\n", "\n", "# crop the image", "\n", "", "", "img", "=", "self", ".", "crop", "(", "img", ",", "crop_bbox", ")", "\n", "img_shape", "=", "img", ".", "shape", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img_shape", "\n", "\n", "# crop semantic seg", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "            ", "results", "[", "key", "]", "=", "self", ".", "crop", "(", "results", "[", "key", "]", ",", "crop_bbox", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCrop.__repr__": [[883, 885], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(crop_size={self.crop_size})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.__init__": [[896, 901], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "crop_size", ",", "cat_max_ratio", "=", "1.", ",", "ignore_index", "=", "0", ")", ":", "\n", "        ", "assert", "crop_size", "[", "0", "]", ">", "0", "and", "crop_size", "[", "1", "]", ">", "0", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "cat_max_ratio", "=", "cat_max_ratio", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.get_crop_bbox": [[902, 912], ["max", "max", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["", "def", "get_crop_bbox", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Randomly get a crop bounding box.\"\"\"", "\n", "margin_h", "=", "max", "(", "img", ".", "shape", "[", "0", "]", "-", "self", ".", "crop_size", "[", "0", "]", ",", "0", ")", "\n", "margin_w", "=", "max", "(", "img", ".", "shape", "[", "1", "]", "-", "self", ".", "crop_size", "[", "1", "]", ",", "0", ")", "\n", "offset_h", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "margin_h", "+", "1", ")", "\n", "offset_w", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "margin_w", "+", "1", ")", "\n", "crop_y1", ",", "crop_y2", "=", "offset_h", ",", "offset_h", "+", "self", ".", "crop_size", "[", "0", "]", "\n", "crop_x1", ",", "crop_x2", "=", "offset_w", ",", "offset_w", "+", "self", ".", "crop_size", "[", "1", "]", "\n", "\n", "return", "crop_y1", ",", "crop_y2", ",", "crop_x1", ",", "crop_x2", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.crop": [[913, 918], ["None"], "methods", ["None"], ["", "def", "crop", "(", "self", ",", "img", ",", "crop_bbox", ")", ":", "\n", "        ", "\"\"\"Crop from ``img``\"\"\"", "\n", "crop_y1", ",", "crop_y2", ",", "crop_x1", ",", "crop_x2", "=", "crop_bbox", "\n", "img", "=", "img", "[", "crop_y1", ":", "crop_y2", ",", "crop_x1", ":", "crop_x2", ",", "...", "]", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.__call__": [[919, 959], ["transforms.RandomCropNuscenes.get_crop_bbox", "numpy.random.rand", "transforms.RandomCropNuscenes.crop", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "img.permute().squeeze().numpy.permute().squeeze().numpy.permute().unsqueeze", "torch.interpolate", "torch.interpolate", "img.permute().squeeze().numpy.permute().squeeze().numpy.permute().squeeze().numpy", "results.get", "img.permute().squeeze().numpy.permute().squeeze().numpy.copy", "results[].astype", "range", "numpy.array().astype", "numpy.array().astype.astype", "img.permute().squeeze().numpy.permute().squeeze().numpy.permute", "img.permute().squeeze().numpy.permute().squeeze().numpy.permute().squeeze", "transforms.RandomCropNuscenes.crop", "torch.from_numpy().float().permute", "torch.from_numpy().float().permute", "torch.from_numpy().float().permute", "torch.from_numpy().float().permute", "torch.interpolate", "torch.interpolate", "seg_temp.squeeze().numpy.squeeze().numpy.squeeze().numpy", "numpy.array().astype.append", "numpy.array", "img.permute().squeeze().numpy.permute().squeeze().numpy.permute", "int", "int", "int", "int", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "seg_temp.squeeze().numpy.squeeze().numpy.squeeze", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.get_crop_bbox", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.crop", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.crop"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to randomly crop images, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Randomly cropped results, 'img_shape' key in result dict is\n                updated according to crop size.\n        \"\"\"", "\n", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "crop_bbox", "=", "self", ".", "get_crop_bbox", "(", "img", ")", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "cat_max_ratio", ":", "\n", "# crop image", "\n", "            ", "img", "=", "self", ".", "crop", "(", "img", ",", "crop_bbox", ")", "\n", "img_shape", "=", "img", ".", "shape", "\n", "img", "=", "torch", ".", "from_numpy", "(", "img", ".", "copy", "(", ")", ")", "\n", "img", "=", "img", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "img", "=", "F", ".", "interpolate", "(", "img", ",", "size", "=", "(", "600", ",", "800", ")", ",", "mode", "=", "'nearest'", ")", "\n", "img", "=", "img", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "squeeze", "(", "0", ")", ".", "numpy", "(", ")", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img_shape", "\n", "# crop semantic seg", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "                ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "'uint8'", ")", "\n", "seg_temp_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "# add a channel in the last dimension", "\n", "                    ", "seg_temp", "=", "results", "[", "key", "]", "[", "i", ",", "...", "]", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "seg_temp", "=", "self", ".", "crop", "(", "seg_temp", ",", "(", "int", "(", "crop_bbox", "[", "0", "]", "*", "196", "/", "600", ")", ",", "int", "(", "crop_bbox", "[", "1", "]", "*", "196", "/", "600", ")", ",", "int", "(", "crop_bbox", "[", "2", "]", "*", "200", "/", "800", ")", ",", "int", "(", "crop_bbox", "[", "3", "]", "*", "200", "/", "800", ")", ")", ")", "\n", "seg_temp", "=", "seg_temp", "[", "np", ".", "newaxis", ",", "...", "]", "\n", "seg_temp", "=", "torch", ".", "from_numpy", "(", "seg_temp", ")", ".", "float", "(", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "seg_temp", "=", "F", ".", "interpolate", "(", "seg_temp", ",", "size", "=", "(", "196", ",", "200", ")", ",", "mode", "=", "'nearest'", ")", "\n", "seg_temp", "=", "seg_temp", ".", "squeeze", "(", ")", ".", "numpy", "(", ")", "\n", "seg_temp_list", ".", "append", "(", "seg_temp", ")", "\n", "", "seg_temp_list", "=", "np", ".", "array", "(", "seg_temp_list", ")", ".", "astype", "(", "bool", ")", "\n", "results", "[", "key", "]", "=", "seg_temp_list", ".", "astype", "(", "bool", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomCropNuscenes.__repr__": [[960, 962], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(crop_size={self.crop_size})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomRotate.__init__": [[983, 1003], ["isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "prob", ",", "\n", "degree", ",", "\n", "pad_val", "=", "0", ",", "\n", "seg_pad_val", "=", "255", ",", "\n", "center", "=", "None", ",", "\n", "auto_bound", "=", "False", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "assert", "prob", ">=", "0", "and", "prob", "<=", "1", "\n", "if", "isinstance", "(", "degree", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "assert", "degree", ">", "0", ",", "f'degree {degree} should be positive'", "\n", "self", ".", "degree", "=", "(", "-", "degree", ",", "degree", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "degree", "=", "degree", "\n", "", "assert", "len", "(", "self", ".", "degree", ")", "==", "2", ",", "f'degree {self.degree} should be a '", "f'tuple of (min, max)'", "\n", "self", ".", "pal_val", "=", "pad_val", "\n", "self", ".", "seg_pad_val", "=", "seg_pad_val", "\n", "self", ".", "center", "=", "center", "\n", "self", ".", "auto_bound", "=", "auto_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomRotate.__call__": [[1004, 1033], ["numpy.random.uniform", "min", "max", "mmcv.imrotate", "results.get", "numpy.random.rand", "mmcv.imrotate"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to rotate image, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Rotated results.\n        \"\"\"", "\n", "\n", "rotate", "=", "True", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", "else", "False", "\n", "degree", "=", "np", ".", "random", ".", "uniform", "(", "min", "(", "*", "self", ".", "degree", ")", ",", "max", "(", "*", "self", ".", "degree", ")", ")", "\n", "if", "rotate", ":", "\n", "            ", "results", "[", "'img'", "]", "=", "mmcv", ".", "imrotate", "(", "\n", "results", "[", "'img'", "]", ",", "\n", "angle", "=", "degree", ",", "\n", "border_value", "=", "self", ".", "pal_val", ",", "\n", "center", "=", "self", ".", "center", ",", "\n", "auto_bound", "=", "self", ".", "auto_bound", ")", "\n", "# rotate segs", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "                ", "results", "[", "key", "]", "=", "mmcv", ".", "imrotate", "(", "\n", "results", "[", "key", "]", ",", "\n", "angle", "=", "degree", ",", "\n", "border_value", "=", "self", ".", "seg_pad_val", ",", "\n", "center", "=", "self", ".", "center", ",", "\n", "auto_bound", "=", "self", ".", "auto_bound", ",", "\n", "interpolation", "=", "'nearest'", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomRotate.__repr__": [[1034, 1043], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(prob={self.prob}, '", "f'degree={self.degree}, '", "f'pad_val={self.pal_val}, '", "f'seg_pad_val={self.seg_pad_val}, '", "f'center={self.center}, '", "f'auto_bound={self.auto_bound})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomRotateNuscenes.__init__": [[1063, 1083], ["isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "prob", ",", "\n", "degree", ",", "\n", "pad_val", "=", "0", ",", "\n", "seg_pad_val", "=", "0", ",", "\n", "center", "=", "None", ",", "\n", "auto_bound", "=", "False", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "assert", "prob", ">=", "0", "and", "prob", "<=", "1", "\n", "if", "isinstance", "(", "degree", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "assert", "degree", ">", "0", ",", "f'degree {degree} should be positive'", "\n", "self", ".", "degree", "=", "(", "-", "degree", ",", "degree", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "degree", "=", "degree", "\n", "", "assert", "len", "(", "self", ".", "degree", ")", "==", "2", ",", "f'degree {self.degree} should be a '", "f'tuple of (min, max)'", "\n", "self", ".", "pal_val", "=", "pad_val", "\n", "self", ".", "seg_pad_val", "=", "seg_pad_val", "\n", "self", ".", "center", "=", "center", "\n", "self", ".", "auto_bound", "=", "auto_bound", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomRotateNuscenes.__call__": [[1084, 1117], ["numpy.random.uniform", "min", "max", "mmcv.imrotate", "results.get", "numpy.random.rand", "results[].astype", "range", "results[].astype", "mmcv.imrotate"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to rotate image, semantic segmentation maps.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Rotated results.\n        \"\"\"", "\n", "\n", "rotate", "=", "True", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", "else", "False", "\n", "degree", "=", "np", ".", "random", ".", "uniform", "(", "min", "(", "*", "self", ".", "degree", ")", ",", "max", "(", "*", "self", ".", "degree", ")", ")", "\n", "if", "rotate", ":", "\n", "            ", "results", "[", "'img'", "]", "=", "mmcv", ".", "imrotate", "(", "\n", "results", "[", "'img'", "]", ",", "\n", "angle", "=", "degree", ",", "\n", "border_value", "=", "self", ".", "pal_val", ",", "\n", "center", "=", "self", ".", "center", ",", "\n", "auto_bound", "=", "self", ".", "auto_bound", ")", "\n", "# results[key].shape: 15 x 196 x 200,key is gt_semantic_seg", "\n", "# rotate segs", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "                ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "'uint8'", ")", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "                    ", "results", "[", "key", "]", "[", "i", ",", "...", "]", "=", "mmcv", ".", "imrotate", "(", "\n", "results", "[", "key", "]", "[", "i", ",", "...", "]", ",", "\n", "angle", "=", "degree", ",", "\n", "border_value", "=", "self", ".", "seg_pad_val", ",", "\n", "center", "=", "self", ".", "center", ",", "\n", "auto_bound", "=", "self", ".", "auto_bound", ",", "\n", "interpolation", "=", "'nearest'", ")", "\n", "", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "astype", "(", "bool", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomRotateNuscenes.__repr__": [[1118, 1127], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(prob={self.prob}, '", "f'degree={self.degree}, '", "f'pad_val={self.pal_val}, '", "f'seg_pad_val={self.seg_pad_val}, '", "f'center={self.center}, '", "f'auto_bound={self.auto_bound})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RGB2Gray.__init__": [[1145, 1152], ["isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "out_channels", "=", "None", ",", "weights", "=", "(", "0.299", ",", "0.587", ",", "0.114", ")", ")", ":", "\n", "        ", "assert", "out_channels", "is", "None", "or", "out_channels", ">", "0", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "assert", "isinstance", "(", "weights", ",", "tuple", ")", "\n", "for", "item", "in", "weights", ":", "\n", "            ", "assert", "isinstance", "(", "item", ",", "(", "float", ",", "int", ")", ")", "\n", "", "self", ".", "weights", "=", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RGB2Gray.__call__": [[1153, 1176], ["numpy.array().reshape", "len", "len", "img.repeat.repeat.repeat", "img.repeat.repeat.repeat", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to convert RGB image to grayscale image.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Result dict with grayscale image.\n        \"\"\"", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "assert", "len", "(", "img", ".", "shape", ")", "==", "3", "\n", "assert", "img", ".", "shape", "[", "2", "]", "==", "len", "(", "self", ".", "weights", ")", "\n", "weights", "=", "np", ".", "array", "(", "self", ".", "weights", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "-", "1", ")", ")", "\n", "img", "=", "(", "img", "*", "weights", ")", ".", "sum", "(", "2", ",", "keepdims", "=", "True", ")", "\n", "if", "self", ".", "out_channels", "is", "None", ":", "\n", "            ", "img", "=", "img", ".", "repeat", "(", "weights", ".", "shape", "[", "2", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "img", ".", "repeat", "(", "self", ".", "out_channels", ",", "axis", "=", "2", ")", "\n", "\n", "", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img", ".", "shape", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RGB2Gray.__repr__": [[1177, 1182], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(out_channels={self.out_channels}, '", "f'weights={self.weights})'", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.AdjustGamma.__init__": [[1193, 1200], ["numpy.array().astype", "isinstance", "isinstance", "numpy.array", "numpy.arange"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gamma", "=", "1.0", ")", ":", "\n", "        ", "assert", "isinstance", "(", "gamma", ",", "float", ")", "or", "isinstance", "(", "gamma", ",", "int", ")", "\n", "assert", "gamma", ">", "0", "\n", "self", ".", "gamma", "=", "gamma", "\n", "inv_gamma", "=", "1.0", "/", "gamma", "\n", "self", ".", "table", "=", "np", ".", "array", "(", "[", "(", "i", "/", "255.0", ")", "**", "inv_gamma", "*", "255", "\n", "for", "i", "in", "np", ".", "arange", "(", "256", ")", "]", ")", ".", "astype", "(", "'uint8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.AdjustGamma.__call__": [[1201, 1215], ["mmcv.lut_transform", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to process the image with gamma correction.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Processed results.\n        \"\"\"", "\n", "\n", "results", "[", "'img'", "]", "=", "mmcv", ".", "lut_transform", "(", "\n", "np", ".", "array", "(", "results", "[", "'img'", "]", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "self", ".", "table", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.AdjustGamma.__repr__": [[1216, 1218], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(gamma={self.gamma})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.SegRescale.__init__": [[1228, 1230], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "scale_factor", "=", "1", ")", ":", "\n", "        ", "self", ".", "scale_factor", "=", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.SegRescale.__call__": [[1231, 1245], ["results.get", "mmcv.imrescale"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to scale the semantic segmentation map.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Result dict with semantic segmentation map scaled.\n        \"\"\"", "\n", "for", "key", "in", "results", ".", "get", "(", "'seg_fields'", ",", "[", "]", ")", ":", "\n", "            ", "if", "self", ".", "scale_factor", "!=", "1", ":", "\n", "                ", "results", "[", "key", "]", "=", "mmcv", ".", "imrescale", "(", "\n", "results", "[", "key", "]", ",", "self", ".", "scale_factor", ",", "interpolation", "=", "'nearest'", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.SegRescale.__repr__": [[1246, 1248], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(scale_factor={self.scale_factor})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.__init__": [[1271, 1280], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "brightness_delta", "=", "32", ",", "\n", "contrast_range", "=", "(", "0.5", ",", "1.5", ")", ",", "\n", "saturation_range", "=", "(", "0.5", ",", "1.5", ")", ",", "\n", "hue_delta", "=", "18", ")", ":", "\n", "        ", "self", ".", "brightness_delta", "=", "brightness_delta", "\n", "self", ".", "contrast_lower", ",", "self", ".", "contrast_upper", "=", "contrast_range", "\n", "self", ".", "saturation_lower", ",", "self", ".", "saturation_upper", "=", "saturation_range", "\n", "self", ".", "hue_delta", "=", "hue_delta", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.convert": [[1281, 1286], ["numpy.clip", "numpy.clip.astype", "numpy.clip.astype"], "methods", ["None"], ["", "def", "convert", "(", "self", ",", "img", ",", "alpha", "=", "1", ",", "beta", "=", "0", ")", ":", "\n", "        ", "\"\"\"Multiple with alpha and add beat with clip.\"\"\"", "\n", "img", "=", "img", ".", "astype", "(", "np", ".", "float32", ")", "*", "alpha", "+", "beta", "\n", "img", "=", "np", ".", "clip", "(", "img", ",", "0", ",", "255", ")", "\n", "return", "img", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.brightness": [[1287, 1295], ["numpy.random.randint", "transforms.PhotoMetricDistortion.convert", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.convert"], ["", "def", "brightness", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Brightness distortion.\"\"\"", "\n", "if", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "return", "self", ".", "convert", "(", "\n", "img", ",", "\n", "beta", "=", "random", ".", "uniform", "(", "-", "self", ".", "brightness_delta", ",", "\n", "self", ".", "brightness_delta", ")", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.contrast": [[1296, 1303], ["numpy.random.randint", "transforms.PhotoMetricDistortion.convert", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.convert"], ["", "def", "contrast", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Contrast distortion.\"\"\"", "\n", "if", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "return", "self", ".", "convert", "(", "\n", "img", ",", "\n", "alpha", "=", "random", ".", "uniform", "(", "self", ".", "contrast_lower", ",", "self", ".", "contrast_upper", ")", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.saturation": [[1304, 1314], ["numpy.random.randint", "mmcv.bgr2hsv", "transforms.PhotoMetricDistortion.convert", "mmcv.hsv2bgr", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.convert"], ["", "def", "saturation", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Saturation distortion.\"\"\"", "\n", "if", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "img", "=", "mmcv", ".", "bgr2hsv", "(", "img", ")", "\n", "img", "[", ":", ",", ":", ",", "1", "]", "=", "self", ".", "convert", "(", "\n", "img", "[", ":", ",", ":", ",", "1", "]", ",", "\n", "alpha", "=", "random", ".", "uniform", "(", "self", ".", "saturation_lower", ",", "\n", "self", ".", "saturation_upper", ")", ")", "\n", "img", "=", "mmcv", ".", "hsv2bgr", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.hue": [[1315, 1324], ["numpy.random.randint", "mmcv.bgr2hsv", "mmcv.hsv2bgr", "img[].astype", "numpy.random.randint"], "methods", ["None"], ["", "def", "hue", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Hue distortion.\"\"\"", "\n", "if", "random", ".", "randint", "(", "2", ")", ":", "\n", "            ", "img", "=", "mmcv", ".", "bgr2hsv", "(", "img", ")", "\n", "img", "[", ":", ",", ":", ",", "\n", "0", "]", "=", "(", "img", "[", ":", ",", ":", ",", "0", "]", ".", "astype", "(", "int", ")", "+", "\n", "random", ".", "randint", "(", "-", "self", ".", "hue_delta", ",", "self", ".", "hue_delta", ")", ")", "%", "180", "\n", "img", "=", "mmcv", ".", "hsv2bgr", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.__call__": [[1325, 1355], ["transforms.PhotoMetricDistortion.brightness", "numpy.random.randint", "transforms.PhotoMetricDistortion.saturation", "transforms.PhotoMetricDistortion.hue", "transforms.PhotoMetricDistortion.contrast", "transforms.PhotoMetricDistortion.contrast"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.brightness", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.saturation", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.hue", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.contrast", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.contrast"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to perform photometric distortion on images.\n\n        Args:\n            results (dict): Result dict from loading pipeline.\n\n        Returns:\n            dict: Result dict with images distorted.\n        \"\"\"", "\n", "img", "=", "results", "[", "'img'", "]", "\n", "img", "=", "self", ".", "brightness", "(", "img", ")", "\n", "\n", "# mode == 0 --> do random contrast first", "\n", "# mode == 1 --> do random contrast last", "\n", "mode", "=", "random", ".", "randint", "(", "2", ")", "\n", "if", "mode", "==", "1", ":", "\n", "            ", "img", "=", "self", ".", "contrast", "(", "img", ")", "\n", "\n", "# random saturation", "\n", "", "img", "=", "self", ".", "saturation", "(", "img", ")", "\n", "\n", "# random hue", "\n", "img", "=", "self", ".", "hue", "(", "img", ")", "\n", "\n", "# random contrast", "\n", "if", "mode", "==", "0", ":", "\n", "            ", "img", "=", "self", ".", "contrast", "(", "img", ")", "\n", "\n", "", "results", "[", "'img'", "]", "=", "img", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.PhotoMetricDistortion.__repr__": [[1356, 1365], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "(", "f'(brightness_delta={self.brightness_delta}, '", "\n", "f'contrast_range=({self.contrast_lower}, '", "\n", "f'{self.contrast_upper}), '", "\n", "f'saturation_range=({self.saturation_lower}, '", "\n", "f'{self.saturation_upper}), '", "\n", "f'hue_delta={self.hue_delta})'", ")", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomGrayscale.__init__": [[1380, 1382], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gray_prob", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "gray_prob", "=", "gray_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomGrayscale.__call__": [[1383, 1401], ["results.get", "numpy.random.random", "numpy.dstack", "mmcv.rgb2gray", "range"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (ndarray): Image to be converted to grayscale.\n        Returns:\n            ndarray: Randomly grayscaled image.\n        \"\"\"", "\n", "for", "key", "in", "results", ".", "get", "(", "'img_fields'", ",", "[", "'img'", "]", ")", ":", "\n", "            ", "img", "=", "results", "[", "key", "]", "\n", "num_output_channels", "=", "img", ".", "shape", "[", "2", "]", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "gray_prob", ":", "\n", "                ", "if", "num_output_channels", ">", "1", ":", "\n", "                    ", "img", "=", "mmcv", ".", "rgb2gray", "(", "img", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "results", "[", "key", "]", "=", "np", ".", "dstack", "(", "\n", "[", "img", "for", "_", "in", "range", "(", "num_output_channels", ")", "]", ")", "\n", "return", "results", "\n", "", "", "results", "[", "key", "]", "=", "img", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.RandomGrayscale.__repr__": [[1402, 1404], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(gray_prob={self.gray_prob})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.HideAndSeek.__init__": [[1418, 1425], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "prob", "=", "1.0", ",", "\n", "prob_hiding_patches", "=", "0.10", ",", "\n", "grid_sizes", "=", "(", "32", ",", "44", ",", "56", ",", "64", ",", "72", ")", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "self", ".", "prob_hiding_patches", "=", "prob_hiding_patches", "\n", "self", ".", "grid_sizes", "=", "grid_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.HideAndSeek._hide_and_seek": [[1426, 1443], ["numpy.random.randint", "range", "len", "range", "min", "min", "numpy.random.rand"], "methods", ["None"], ["", "def", "_hide_and_seek", "(", "self", ",", "img", ")", ":", "\n", "# get width and height of the image", "\n", "        ", "height", ",", "width", ",", "_", "=", "img", ".", "shape", "\n", "\n", "# randomly choose one grid size", "\n", "index", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "grid_sizes", ")", "-", "1", ")", "\n", "grid_size", "=", "self", ".", "grid_sizes", "[", "index", "]", "\n", "\n", "# hide the patches", "\n", "if", "grid_size", "!=", "0", ":", "\n", "            ", "for", "x", "in", "range", "(", "0", ",", "width", ",", "grid_size", ")", ":", "\n", "                ", "for", "y", "in", "range", "(", "0", ",", "height", ",", "grid_size", ")", ":", "\n", "                    ", "x_end", "=", "min", "(", "width", ",", "x", "+", "grid_size", ")", "\n", "y_end", "=", "min", "(", "height", ",", "y", "+", "grid_size", ")", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", "<=", "self", ".", "prob_hiding_patches", ":", "\n", "                        ", "img", "[", "y", ":", "y_end", ",", "x", ":", "x_end", ",", ":", "]", "=", "0", "\n", "", "", "", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.HideAndSeek.__call__": [[1444, 1450], ["numpy.random.rand", "transforms.HideAndSeek._hide_and_seek"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.transforms.HideAndSeek._hide_and_seek"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "img", "=", "results", "[", "'img'", "]", "\n", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "prob", ":", "\n", "            ", "img", "=", "self", ".", "_hide_and_seek", "(", "img", ")", "\n", "", "results", "[", "'img'", "]", "=", "img", "\n", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ToTensor.__init__": [[45, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keys", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ToTensor.__call__": [[48, 62], ["formatting.to_tensor"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.to_tensor"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to convert data in results to :obj:`torch.Tensor`.\n\n        Args:\n            results (dict): Result dict contains the data to convert.\n\n        Returns:\n            dict: The result dict contains the data converted\n                to :obj:`torch.Tensor`.\n        \"\"\"", "\n", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "results", "[", "key", "]", "=", "to_tensor", "(", "results", "[", "key", "]", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ToTensor.__repr__": [[63, 65], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(keys={self.keys})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ImageToTensor.__init__": [[79, 81], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keys", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ImageToTensor.__call__": [[82, 100], ["formatting.to_tensor", "len", "numpy.expand_dims", "numpy.expand_dims.transpose"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.to_tensor"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to convert image in results to :obj:`torch.Tensor` and\n        transpose the channel order.\n\n        Args:\n            results (dict): Result dict contains the image data to convert.\n\n        Returns:\n            dict: The result dict contains the image converted\n                to :obj:`torch.Tensor` and transposed to (C, H, W) order.\n        \"\"\"", "\n", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "img", "=", "results", "[", "key", "]", "\n", "if", "len", "(", "img", ".", "shape", ")", "<", "3", ":", "\n", "                ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "-", "1", ")", "\n", "", "results", "[", "key", "]", "=", "to_tensor", "(", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ImageToTensor.__repr__": [[101, 103], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(keys={self.keys})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.Transpose.__init__": [[114, 117], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keys", ",", "order", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "order", "=", "order", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.Transpose.__call__": [[118, 133], ["results[].transpose"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to convert image in results to :obj:`torch.Tensor` and\n        transpose the channel order.\n\n        Args:\n            results (dict): Result dict contains the image data to convert.\n\n        Returns:\n            dict: The result dict contains the image converted\n                to :obj:`torch.Tensor` and transposed to (C, H, W) order.\n        \"\"\"", "\n", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "results", "[", "key", "]", "=", "results", "[", "key", "]", ".", "transpose", "(", "self", ".", "order", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.Transpose.__repr__": [[134, 137], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(keys={self.keys}, order={self.order})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ToDataContainer.__init__": [[151, 155], ["dict", "dict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "fields", "=", "(", "dict", "(", "key", "=", "'img'", ",", "\n", "stack", "=", "True", ")", ",", "dict", "(", "key", "=", "'gt_semantic_seg'", ")", ")", ")", ":", "\n", "        ", "self", ".", "fields", "=", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ToDataContainer.__call__": [[156, 173], ["field.copy.copy.copy", "field.copy.copy.pop", "mmcv.parallel.DataContainer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to convert data in results to\n        :obj:`mmcv.DataContainer`.\n\n        Args:\n            results (dict): Result dict contains the data to convert.\n\n        Returns:\n            dict: The result dict contains the data converted to\n                :obj:`mmcv.DataContainer`.\n        \"\"\"", "\n", "\n", "for", "field", "in", "self", ".", "fields", ":", "\n", "            ", "field", "=", "field", ".", "copy", "(", ")", "\n", "key", "=", "field", ".", "pop", "(", "'key'", ")", "\n", "results", "[", "key", "]", "=", "DC", "(", "results", "[", "key", "]", ",", "**", "field", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.ToDataContainer.__repr__": [[174, 176], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(fields={self.fields})'", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.DefaultFormatBundle.__call__": [[190, 214], ["numpy.ascontiguousarray", "mmcv.parallel.DataContainer", "mmcv.parallel.DataContainer", "len", "numpy.expand_dims", "numpy.expand_dims.transpose", "formatting.to_tensor", "formatting.to_tensor", "[].astype"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.to_tensor", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.to_tensor"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to transform and format common fields in results.\n\n        Args:\n            results (dict): Result dict contains the data to convert.\n\n        Returns:\n            dict: The result dict contains the data that is formatted with\n                default bundle.\n        \"\"\"", "\n", "\n", "if", "'img'", "in", "results", ":", "\n", "            ", "img", "=", "results", "[", "'img'", "]", "\n", "if", "len", "(", "img", ".", "shape", ")", "<", "3", ":", "\n", "                ", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "-", "1", ")", "\n", "", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "results", "[", "'img'", "]", "=", "DC", "(", "to_tensor", "(", "img", ")", ",", "stack", "=", "True", ")", "\n", "", "if", "'gt_semantic_seg'", "in", "results", ":", "\n", "# convert to long", "\n", "            ", "results", "[", "'gt_semantic_seg'", "]", "=", "DC", "(", "\n", "to_tensor", "(", "results", "[", "'gt_semantic_seg'", "]", "[", "None", ",", "\n", "...", "]", ".", "astype", "(", "np", ".", "int64", ")", ")", ",", "\n", "stack", "=", "True", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.DefaultFormatBundle.__repr__": [[215, 217], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.Collect.__init__": [[257, 264], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "keys", ",", "\n", "meta_keys", "=", "(", "'filename'", ",", "'ori_filename'", ",", "'ori_shape'", ",", "\n", "'img_shape'", ",", "'pad_shape'", ",", "'scale_factor'", ",", "'flip'", ",", "\n", "'flip_direction'", ",", "'img_norm_cfg'", ")", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "meta_keys", "=", "meta_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.Collect.__call__": [[265, 286], ["mmcv.parallel.DataContainer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to collect keys in results. The keys in ``meta_keys``\n        will be converted to :obj:mmcv.DataContainer.\n\n        Args:\n            results (dict): Result dict contains the data to collect.\n\n        Returns:\n            dict: The result dict contains the following keys\n                - keys in``self.keys``\n                - ``img_metas``\n        \"\"\"", "\n", "\n", "data", "=", "{", "}", "\n", "img_meta", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "meta_keys", ":", "\n", "            ", "img_meta", "[", "key", "]", "=", "results", "[", "key", "]", "\n", "", "data", "[", "'img_metas'", "]", "=", "DC", "(", "img_meta", ",", "cpu_only", "=", "True", ")", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "data", "[", "key", "]", "=", "results", "[", "key", "]", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.Collect.__repr__": [[287, 290], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f'(keys={self.keys}, meta_keys={self.meta_keys})'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.to_tensor": [[12, 35], ["isinstance", "isinstance", "torch.from_numpy", "isinstance", "torch.tensor", "isinstance", "mmcv.is_str", "torch.LongTensor", "isinstance", "torch.FloatTensor", "TypeError", "type"], "function", ["None"], ["def", "to_tensor", "(", "data", ")", ":", "\n", "    ", "\"\"\"Convert objects of various python types to :obj:`torch.Tensor`.\n\n    Supported types are: :class:`numpy.ndarray`, :class:`torch.Tensor`,\n    :class:`Sequence`, :class:`int` and :class:`float`.\n\n    Args:\n        data (torch.Tensor | numpy.ndarray | Sequence | int | float): Data to\n            be converted.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "data", "\n", "", "elif", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "torch", ".", "from_numpy", "(", "data", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "Sequence", ")", "and", "not", "mmcv", ".", "is_str", "(", "data", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "data", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "int", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "[", "data", "]", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "FloatTensor", "(", "[", "data", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "f'type {type(data)} cannot be converted to tensor.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.test_time_aug.MultiScaleFlipAug.__init__": [[54, 93], ["compose.Compose", "mmcv.is_list_of", "mmcv.is_list_of", "mmcv.is_list_of", "mmcv.is_list_of", "isinstance", "warnings.warn", "warnings.warn", "isinstance", "isinstance", "mmcv.is_list_of", "any", "len", "isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "transforms", ",", "\n", "img_scale", ",", "\n", "img_ratios", "=", "None", ",", "\n", "flip", "=", "False", ",", "\n", "flip_direction", "=", "'horizontal'", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "Compose", "(", "transforms", ")", "\n", "if", "img_ratios", "is", "not", "None", ":", "\n", "            ", "img_ratios", "=", "img_ratios", "if", "isinstance", "(", "img_ratios", ",", "\n", "list", ")", "else", "[", "img_ratios", "]", "\n", "assert", "mmcv", ".", "is_list_of", "(", "img_ratios", ",", "float", ")", "\n", "", "if", "img_scale", "is", "None", ":", "\n", "# mode 1: given img_scale=None and a range of image ratio", "\n", "            ", "self", ".", "img_scale", "=", "None", "\n", "assert", "mmcv", ".", "is_list_of", "(", "img_ratios", ",", "float", ")", "\n", "", "elif", "isinstance", "(", "img_scale", ",", "tuple", ")", "and", "mmcv", ".", "is_list_of", "(", "\n", "img_ratios", ",", "float", ")", ":", "\n", "            ", "assert", "len", "(", "img_scale", ")", "==", "2", "\n", "# mode 2: given a scale and a range of image ratio", "\n", "self", ".", "img_scale", "=", "[", "(", "int", "(", "img_scale", "[", "0", "]", "*", "ratio", ")", ",", "\n", "int", "(", "img_scale", "[", "1", "]", "*", "ratio", ")", ")", "\n", "for", "ratio", "in", "img_ratios", "]", "\n", "", "else", ":", "\n", "# mode 3: given multiple scales", "\n", "            ", "self", ".", "img_scale", "=", "img_scale", "if", "isinstance", "(", "img_scale", ",", "\n", "list", ")", "else", "[", "img_scale", "]", "\n", "", "assert", "mmcv", ".", "is_list_of", "(", "self", ".", "img_scale", ",", "tuple", ")", "or", "self", ".", "img_scale", "is", "None", "\n", "self", ".", "flip", "=", "flip", "\n", "self", ".", "img_ratios", "=", "img_ratios", "\n", "self", ".", "flip_direction", "=", "flip_direction", "if", "isinstance", "(", "\n", "flip_direction", ",", "list", ")", "else", "[", "flip_direction", "]", "\n", "assert", "mmcv", ".", "is_list_of", "(", "self", ".", "flip_direction", ",", "str", ")", "\n", "if", "not", "self", ".", "flip", "and", "self", ".", "flip_direction", "!=", "[", "'horizontal'", "]", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'flip_direction has no effect when flip is set to False'", ")", "\n", "", "if", "(", "self", ".", "flip", "\n", "and", "not", "any", "(", "[", "t", "[", "'type'", "]", "==", "'RandomFlip'", "for", "t", "in", "transforms", "]", ")", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'flip has no effect when RandomFlip is not in transforms'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.test_time_aug.MultiScaleFlipAug.__call__": [[94, 128], ["mmcv.is_list_of", "test_time_aug.MultiScaleFlipAug.items", "aug_data_dict[].append", "int", "int", "results.copy", "test_time_aug.MultiScaleFlipAug.transforms", "aug_data.append"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to apply test time augment transforms on results.\n\n        Args:\n            results (dict): Result dict contains the data to transform.\n\n        Returns:\n           dict[str: list]: The augmented data, where each value is wrapped\n               into a list.\n        \"\"\"", "\n", "\n", "aug_data", "=", "[", "]", "\n", "if", "self", ".", "img_scale", "is", "None", "and", "mmcv", ".", "is_list_of", "(", "self", ".", "img_ratios", ",", "float", ")", ":", "\n", "            ", "h", ",", "w", "=", "results", "[", "'img'", "]", ".", "shape", "[", ":", "2", "]", "\n", "img_scale", "=", "[", "(", "int", "(", "w", "*", "ratio", ")", ",", "int", "(", "h", "*", "ratio", ")", ")", "\n", "for", "ratio", "in", "self", ".", "img_ratios", "]", "\n", "", "else", ":", "\n", "            ", "img_scale", "=", "self", ".", "img_scale", "\n", "", "flip_aug", "=", "[", "False", ",", "True", "]", "if", "self", ".", "flip", "else", "[", "False", "]", "\n", "for", "scale", "in", "img_scale", ":", "\n", "            ", "for", "flip", "in", "flip_aug", ":", "\n", "                ", "for", "direction", "in", "self", ".", "flip_direction", ":", "\n", "                    ", "_results", "=", "results", ".", "copy", "(", ")", "\n", "_results", "[", "'scale'", "]", "=", "scale", "\n", "_results", "[", "'flip'", "]", "=", "flip", "\n", "_results", "[", "'flip_direction'", "]", "=", "direction", "\n", "data", "=", "self", ".", "transforms", "(", "_results", ")", "\n", "aug_data", ".", "append", "(", "data", ")", "\n", "# list of dict to dict of list", "\n", "", "", "", "aug_data_dict", "=", "{", "key", ":", "[", "]", "for", "key", "in", "aug_data", "[", "0", "]", "}", "\n", "for", "data", "in", "aug_data", ":", "\n", "            ", "for", "key", ",", "val", "in", "data", ".", "items", "(", ")", ":", "\n", "                ", "aug_data_dict", "[", "key", "]", ".", "append", "(", "val", ")", "\n", "", "", "return", "aug_data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.test_time_aug.MultiScaleFlipAug.__repr__": [[129, 135], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(transforms={self.transforms}, '", "\n", "repr_str", "+=", "f'img_scale={self.img_scale}, flip={self.flip})'", "\n", "repr_str", "+=", "f'flip_direction={self.flip_direction}'", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.LoadImageFromFile.__init__": [[38, 48], ["dict", "file_client_args.copy"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "to_float32", "=", "False", ",", "\n", "color_type", "=", "'color'", ",", "\n", "file_client_args", "=", "dict", "(", "backend", "=", "'disk'", ")", ",", "\n", "imdecode_backend", "=", "'cv2'", ")", ":", "\n", "        ", "self", ".", "to_float32", "=", "to_float32", "\n", "self", ".", "color_type", "=", "color_type", "\n", "self", ".", "file_client_args", "=", "file_client_args", ".", "copy", "(", ")", "\n", "self", ".", "file_client", "=", "None", "\n", "self", ".", "imdecode_backend", "=", "imdecode_backend", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.LoadImageFromFile.__call__": [[49, 88], ["loading.LoadImageFromFile.file_client.get", "mmcv.imfrombytes", "dict", "mmcv.FileClient", "results.get", "os.join", "os.join", "img.astype.astype.astype", "len", "numpy.zeros", "numpy.ones"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call functions to load image and get image meta information.\n\n        Args:\n            results (dict): Result dict from :obj:`mmseg.CustomDataset`.\n\n        Returns:\n            dict: The dict contains loaded image and meta information.\n        \"\"\"", "\n", "\n", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "mmcv", ".", "FileClient", "(", "**", "self", ".", "file_client_args", ")", "\n", "\n", "", "if", "results", ".", "get", "(", "'img_prefix'", ")", "is", "not", "None", ":", "\n", "            ", "filename", "=", "osp", ".", "join", "(", "results", "[", "'img_prefix'", "]", ",", "\n", "results", "[", "'img_info'", "]", "[", "'filename'", "]", ")", "\n", "", "else", ":", "\n", "            ", "filename", "=", "results", "[", "'img_info'", "]", "[", "'filename'", "]", "\n", "", "img_bytes", "=", "self", ".", "file_client", ".", "get", "(", "filename", ")", "\n", "# using cv2 to read image, so the image format is H,W,C", "\n", "img", "=", "mmcv", ".", "imfrombytes", "(", "\n", "img_bytes", ",", "flag", "=", "self", ".", "color_type", ",", "backend", "=", "self", ".", "imdecode_backend", ")", "\n", "if", "self", ".", "to_float32", ":", "\n", "            ", "img", "=", "img", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "results", "[", "'filename'", "]", "=", "filename", "\n", "results", "[", "'ori_filename'", "]", "=", "results", "[", "'img_info'", "]", "[", "'filename'", "]", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img", ".", "shape", "\n", "results", "[", "'ori_shape'", "]", "=", "img", ".", "shape", "\n", "# Set initial values for default meta_keys", "\n", "results", "[", "'pad_shape'", "]", "=", "img", ".", "shape", "\n", "results", "[", "'scale_factor'", "]", "=", "1.0", "\n", "num_channels", "=", "1", "if", "len", "(", "img", ".", "shape", ")", "<", "3", "else", "img", ".", "shape", "[", "2", "]", "\n", "results", "[", "'img_norm_cfg'", "]", "=", "dict", "(", "\n", "mean", "=", "np", ".", "zeros", "(", "num_channels", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "std", "=", "np", ".", "ones", "(", "num_channels", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "to_rgb", "=", "False", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.LoadImageFromFile.__repr__": [[89, 95], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(to_float32={self.to_float32},'", "\n", "repr_str", "+=", "f\"color_type='{self.color_type}',\"", "\n", "repr_str", "+=", "f\"imdecode_backend='{self.imdecode_backend}')\"", "\n", "return", "repr_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.LoadAnnotations.__init__": [[116, 149], ["dict", "file_client_args.copy", "json.load", "json.load", "json.load", "json.load", "json.load", "open", "open", "open", "open", "open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "reduce_zero_label", "=", "False", ",", "\n", "file_client_args", "=", "dict", "(", "backend", "=", "'disk'", ")", ",", "\n", "imdecode_backend", "=", "'pillow'", ",", "\n", "with_calib", "=", "False", ",", "\n", "with_calib_argoverse", "=", "False", ",", "\n", "with_calib_kittiraw", "=", "False", ",", "\n", "with_calib_kittiodometry", "=", "False", ",", "\n", "with_calib_kittiobject", "=", "False", ")", ":", "\n", "        ", "self", ".", "reduce_zero_label", "=", "reduce_zero_label", "\n", "self", ".", "file_client_args", "=", "file_client_args", ".", "copy", "(", ")", "\n", "self", ".", "file_client", "=", "None", "\n", "self", ".", "imdecode_backend", "=", "imdecode_backend", "\n", "self", ".", "with_calib", "=", "with_calib", "\n", "self", ".", "with_calib_argoverse", "=", "with_calib_argoverse", "\n", "self", ".", "with_calib_kittiraw", "=", "with_calib_kittiraw", "\n", "self", ".", "with_calib_kittiodometry", "=", "with_calib_kittiodometry", "\n", "self", ".", "with_calib_kittiobject", "=", "with_calib_kittiobject", "\n", "if", "self", ".", "with_calib", ":", "\n", "# modify the path of nuscenes dataset", "\n", "            ", "self", ".", "nuscenes", "=", "json", ".", "load", "(", "open", "(", "'/data/nuscenes/calib.json'", ",", "'r'", ")", ")", "\n", "", "if", "self", ".", "with_calib_argoverse", ":", "\n", "# modify the path of argoverse dataset", "\n", "            ", "self", ".", "argoverse", "=", "json", ".", "load", "(", "open", "(", "'/data/argoversev1.0/calib.json'", ",", "'r'", ")", ")", "\n", "", "if", "self", ".", "with_calib_kittiraw", ":", "\n", "# modify the path of kittiraw dataset", "\n", "            ", "self", ".", "kittiraw", "=", "json", ".", "load", "(", "open", "(", "'/data/kitti_processed/kitti_raw/calib.json'", ",", "'r'", ")", ")", "\n", "", "if", "self", ".", "with_calib_kittiodometry", ":", "\n", "# modify the path of kittiodometry dataset", "\n", "            ", "self", ".", "kittiodometry", "=", "json", ".", "load", "(", "open", "(", "'/data/kitti_processed/kitti_odometry/calib.json'", ",", "'r'", ")", ")", "\n", "", "if", "self", ".", "with_calib_kittiobject", ":", "\n", "# modify the path of kittiobject dataset", "\n", "            ", "self", ".", "kittiobject", "=", "json", ".", "load", "(", "open", "(", "'/data/kitti_processed/kitti_object/calib.json'", ",", "'r'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.LoadAnnotations.__call__": [[150, 238], ["results[].append", "mmcv.FileClient", "results.get", "os.join", "os.join", "torchvision.transforms.functional.to_tensor().long", "numpy.invert", "loading.LoadAnnotations.file_client.get", "mmcv.imfrombytes().squeeze().astype", "results.get", "results[].items", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "decode_binary_labels().numpy", "decode_binary_labels().numpy", "numpy.zeros().astype", "cv2.imread", "cv2.flip().astype", "cv2.imread().astype", "numpy.invert", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "os.basename().split", "torchvision.transforms.functional.to_tensor", "mmcv.imfrombytes().squeeze", "PIL.Image.open", "loading.decode_binary_labels", "loading.decode_binary_labels", "numpy.zeros", "cv2.flip", "cv2.imread", "os.basename", "os.basename", "os.basename", "os.basename", "os.basename", "os.basename", "os.basename", "os.basename", "os.basename", "os.basename", "gt_semantic_seg[].astype", "mmcv.imfrombytes"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.formatting.to_tensor", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.decode_binary_labels", "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.decode_binary_labels"], ["", "", "def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to load multiple types annotations.\n\n        Args:\n            results (dict): Result dict from :obj:`mmseg.CustomDataset`.\n\n        Returns:\n            dict: The dict contains loaded semantic segmentation annotations.\n        \"\"\"", "\n", "\n", "if", "self", ".", "file_client", "is", "None", ":", "\n", "            ", "self", ".", "file_client", "=", "mmcv", ".", "FileClient", "(", "**", "self", ".", "file_client_args", ")", "\n", "\n", "", "if", "results", ".", "get", "(", "'seg_prefix'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "filename", "=", "osp", ".", "join", "(", "results", "[", "'seg_prefix'", "]", ",", "\n", "results", "[", "'ann_info'", "]", "[", "'seg_map'", "]", ")", "\n", "", "else", ":", "\n", "            ", "filename", "=", "results", "[", "'ann_info'", "]", "[", "'seg_map'", "]", "\n", "", "if", "self", ".", "imdecode_backend", "==", "'pyramid'", ":", "\n", "            ", "encoded_labels", "=", "torchvision", ".", "transforms", ".", "functional", ".", "to_tensor", "(", "Image", ".", "open", "(", "filename", ")", ")", ".", "long", "(", ")", "\n", "# decode to binary labels,the data type of gt_semantic_seg is bool,i.e. 0 or 1, gt_semantic_seg is numpy array", "\n", "if", "self", ".", "with_calib", ":", "\n", "# encoded_labels shape: [1,196,200]", "\n", "                ", "gt_semantic_seg", "=", "decode_binary_labels", "(", "encoded_labels", ",", "15", ")", ".", "numpy", "(", ")", "\n", "", "if", "self", ".", "with_calib_argoverse", ":", "\n", "                ", "gt_semantic_seg", "=", "decode_binary_labels", "(", "encoded_labels", ",", "9", ")", ".", "numpy", "(", ")", "\n", "", "if", "self", ".", "with_calib_kittiraw", "or", "self", ".", "with_calib_kittiodometry", "or", "self", ".", "with_calib_kittiobject", ":", "\n", "                ", "gt_semantic_seg", "=", "np", ".", "zeros", "(", "(", "2", ",", "196", ",", "200", ")", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "gt_semantic_seg", "[", "0", ",", "...", "]", "=", "cv2", ".", "imread", "(", "filename", ",", "cv2", ".", "IMREAD_GRAYSCALE", ")", "\n", "gt_semantic_seg", "[", "0", ",", "...", "]", "=", "cv2", ".", "flip", "(", "gt_semantic_seg", "[", "0", ",", "...", "]", ".", "astype", "(", "np", ".", "uint8", ")", ",", "0", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "# mask_test.png is provided in mmseg/datasets/pipelines/", "\n", "gt_semantic_seg", "[", "-", "1", ",", "...", "]", "=", "cv2", ".", "imread", "(", "\"mask_test.png\"", ",", "cv2", ".", "IMREAD_GRAYSCALE", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "gt_semantic_seg", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt_semantic_seg", "[", "-", "1", ",", "...", "]", ")", "\n", "# np.invert() equals to bitwise-not, so gt_semantic_seg is bool value, i.e., True or False", "\n", "", "gt_semantic_seg", "[", "-", "1", ",", "...", "]", "=", "np", ".", "invert", "(", "gt_semantic_seg", "[", "-", "1", ",", "...", "]", ")", "\n", "", "else", ":", "\n", "            ", "img_bytes", "=", "self", ".", "file_client", ".", "get", "(", "filename", ")", "\n", "gt_semantic_seg", "=", "mmcv", ".", "imfrombytes", "(", "\n", "img_bytes", ",", "flag", "=", "'unchanged'", ",", "\n", "backend", "=", "self", ".", "imdecode_backend", ")", ".", "squeeze", "(", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "# modify if custom classes", "\n", "", "if", "results", ".", "get", "(", "'label_map'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "for", "old_id", ",", "new_id", "in", "results", "[", "'label_map'", "]", ".", "items", "(", ")", ":", "\n", "                ", "gt_semantic_seg", "[", "gt_semantic_seg", "==", "old_id", "]", "=", "new_id", "\n", "# reduce zero_label", "\n", "", "", "if", "self", ".", "reduce_zero_label", ":", "\n", "# avoid using underflow conversion", "\n", "            ", "gt_semantic_seg", "[", "gt_semantic_seg", "==", "0", "]", "=", "255", "\n", "gt_semantic_seg", "=", "gt_semantic_seg", "-", "1", "\n", "gt_semantic_seg", "[", "gt_semantic_seg", "==", "254", "]", "=", "255", "\n", "", "results", "[", "'gt_semantic_seg'", "]", "=", "gt_semantic_seg", "\n", "results", "[", "'seg_fields'", "]", ".", "append", "(", "'gt_semantic_seg'", ")", "\n", "if", "self", ".", "with_calib", ":", "\n", "            ", "token", "=", "osp", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "intrinsics", "=", "torch", ".", "tensor", "(", "self", ".", "nuscenes", "[", "token", "]", ")", "\n", "# scale calibration matrix to account for image downsampling", "\n", "intrinsics", "[", "0", "]", "*=", "800", "/", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "intrinsics", "[", "1", "]", "*=", "600", "/", "results", "[", "'img_shape'", "]", "[", "0", "]", "\n", "results", "[", "'calib'", "]", "=", "intrinsics", "\n", "", "if", "self", ".", "with_calib_argoverse", ":", "\n", "            ", "token", "=", "osp", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "intrinsics", "=", "torch", ".", "tensor", "(", "self", ".", "argoverse", "[", "token", "]", ")", "\n", "# scale calibration matrix to account for image downsampling", "\n", "intrinsics", "[", "0", "]", "*=", "960", "/", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "intrinsics", "[", "1", "]", "*=", "600", "/", "results", "[", "'img_shape'", "]", "[", "0", "]", "\n", "results", "[", "'calib'", "]", "=", "intrinsics", "\n", "", "if", "self", ".", "with_calib_kittiraw", ":", "\n", "            ", "token", "=", "osp", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "intrinsics", "=", "torch", ".", "tensor", "(", "self", ".", "kittiraw", "[", "token", "]", ")", "\n", "# scale calibration matrix to account for image downsampling", "\n", "intrinsics", "[", "0", "]", "*=", "1024", "/", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "intrinsics", "[", "1", "]", "*=", "1024", "/", "results", "[", "'img_shape'", "]", "[", "0", "]", "\n", "results", "[", "'calib'", "]", "=", "intrinsics", "\n", "", "if", "self", ".", "with_calib_kittiodometry", ":", "\n", "            ", "token", "=", "osp", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "intrinsics", "=", "torch", ".", "tensor", "(", "self", ".", "kittiodometry", "[", "token", "]", ")", "\n", "# scale calibration matrix to account for image downsampling", "\n", "intrinsics", "[", "0", "]", "*=", "1024", "/", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "intrinsics", "[", "1", "]", "*=", "1024", "/", "results", "[", "'img_shape'", "]", "[", "0", "]", "\n", "results", "[", "'calib'", "]", "=", "intrinsics", "\n", "", "if", "self", ".", "with_calib_kittiobject", ":", "\n", "            ", "token", "=", "osp", ".", "basename", "(", "filename", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "intrinsics", "=", "torch", ".", "tensor", "(", "self", ".", "kittiobject", "[", "token", "]", ")", "\n", "# scale calibration matrix to account for image downsampling", "\n", "intrinsics", "[", "0", "]", "*=", "1024", "/", "results", "[", "'img_shape'", "]", "[", "1", "]", "\n", "intrinsics", "[", "1", "]", "*=", "1024", "/", "results", "[", "'img_shape'", "]", "[", "0", "]", "\n", "results", "[", "'calib'", "]", "=", "intrinsics", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.LoadAnnotations.__repr__": [[239, 244], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(reduce_zero_label={self.reduce_zero_label},'", "\n", "repr_str", "+=", "f\"imdecode_backend='{self.imdecode_backend}')\"", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.loading.decode_binary_labels": [[97, 100], ["torch.pow", "torch.arange", "torch.pow.view"], "function", ["None"], ["", "", "def", "decode_binary_labels", "(", "labels", ",", "nclass", ")", ":", "\n", "    ", "bits", "=", "torch", ".", "pow", "(", "2", ",", "torch", ".", "arange", "(", "nclass", ")", ")", "\n", "return", "(", "labels", "&", "bits", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.compose.Compose.__init__": [[18, 29], ["isinstance", "isinstance", "mmcv.utils.build_from_cfg", "compose.Compose.transforms.append", "callable", "compose.Compose.transforms.append", "TypeError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "assert", "isinstance", "(", "transforms", ",", "collections", ".", "abc", ".", "Sequence", ")", "\n", "self", ".", "transforms", "=", "[", "]", "\n", "for", "transform", "in", "transforms", ":", "\n", "            ", "if", "isinstance", "(", "transform", ",", "dict", ")", ":", "\n", "                ", "transform", "=", "build_from_cfg", "(", "transform", ",", "PIPELINES", ")", "\n", "self", ".", "transforms", ".", "append", "(", "transform", ")", "\n", "", "elif", "callable", "(", "transform", ")", ":", "\n", "                ", "self", ".", "transforms", ".", "append", "(", "transform", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "'transform must be callable or a dict'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.compose.Compose.__call__": [[30, 45], ["t"], "methods", ["None"], ["", "", "", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"Call function to apply transforms sequentially.\n\n        Args:\n            data (dict): A result dict contains the data to transform.\n\n        Returns:\n           dict: Transformed data.\n        \"\"\"", "\n", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "data", "=", "t", "(", "data", ")", "\n", "if", "data", "is", "None", ":", "\n", "                ", "return", "None", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.pipelines.compose.Compose.__repr__": [[46, 53], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "f'    {t}'", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.inference.LoadImage.__call__": [[46, 68], ["isinstance", "mmcv.imread"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "results", ")", ":", "\n", "        ", "\"\"\"Call function to load images into results.\n\n        Args:\n            results (dict): A result dict contains the file name\n                of the image to be read.\n\n        Returns:\n            dict: ``results`` will be returned containing loaded image.\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "results", "[", "'img'", "]", ",", "str", ")", ":", "\n", "            ", "results", "[", "'filename'", "]", "=", "results", "[", "'img'", "]", "\n", "results", "[", "'ori_filename'", "]", "=", "results", "[", "'img'", "]", "\n", "", "else", ":", "\n", "            ", "results", "[", "'filename'", "]", "=", "None", "\n", "results", "[", "'ori_filename'", "]", "=", "None", "\n", "", "img", "=", "mmcv", ".", "imread", "(", "results", "[", "'img'", "]", ")", "\n", "results", "[", "'img'", "]", "=", "img", "\n", "results", "[", "'img_shape'", "]", "=", "img", ".", "shape", "\n", "results", "[", "'ori_shape'", "]", "=", "img", ".", "shape", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.inference.init_segmentor": [[12, 41], ["isinstance", "mmseg.models.build_segmentor", "mmseg.models.build_segmentor.to", "mmseg.models.build_segmentor.eval", "mmcv.Config.fromfile", "mmcv.runner.load_checkpoint", "isinstance", "TypeError", "mmcv.Config.fromfile.get", "type"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_segmentor"], ["def", "init_segmentor", "(", "config", ",", "checkpoint", "=", "None", ",", "device", "=", "'cuda:0'", ")", ":", "\n", "    ", "\"\"\"Initialize a segmentor from config file.\n\n    Args:\n        config (str or :obj:`mmcv.Config`): Config file path or the config\n            object.\n        checkpoint (str, optional): Checkpoint path. If left as None, the model\n            will not load any weights.\n        device (str, optional) CPU/CUDA device option. Default 'cuda:0'.\n            Use 'cpu' for loading model on CPU.\n    Returns:\n        nn.Module: The constructed segmentor.\n    \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "str", ")", ":", "\n", "        ", "config", "=", "mmcv", ".", "Config", ".", "fromfile", "(", "config", ")", "\n", "", "elif", "not", "isinstance", "(", "config", ",", "mmcv", ".", "Config", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'config must be a filename or Config object, '", "\n", "'but got {}'", ".", "format", "(", "type", "(", "config", ")", ")", ")", "\n", "", "config", ".", "model", ".", "pretrained", "=", "None", "\n", "config", ".", "model", ".", "train_cfg", "=", "None", "\n", "model", "=", "build_segmentor", "(", "config", ".", "model", ",", "test_cfg", "=", "config", ".", "get", "(", "'test_cfg'", ")", ")", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "checkpoint", "=", "load_checkpoint", "(", "model", ",", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "CLASSES", "=", "checkpoint", "[", "'meta'", "]", "[", "'CLASSES'", "]", "\n", "model", ".", "PALETTE", "=", "checkpoint", "[", "'meta'", "]", "[", "'PALETTE'", "]", "\n", "", "model", ".", "cfg", "=", "config", "# save the config in the model for convenience", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.inference.inference_segmentor": [[70, 100], ["mmseg.datasets.pipelines.Compose", "dict", "mmseg.datasets.pipelines.Compose.", "mmcv.parallel.collate", "next", "next", "torch.no_grad", "model", "model.parameters", "inference.LoadImage", "model.parameters", "mmcv.parallel.scatter"], "function", ["None"], ["", "", "def", "inference_segmentor", "(", "model", ",", "img", ")", ":", "\n", "    ", "\"\"\"Inference image(s) with the segmentor.\n\n    Args:\n        model (nn.Module): The loaded segmentor.\n        imgs (str/ndarray or list[str/ndarray]): Either image files or loaded\n            images.\n\n    Returns:\n        (list[Tensor]): The segmentation result.\n    \"\"\"", "\n", "cfg", "=", "model", ".", "cfg", "\n", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# model device", "\n", "# build the data pipeline", "\n", "test_pipeline", "=", "[", "LoadImage", "(", ")", "]", "+", "cfg", ".", "data", ".", "test", ".", "pipeline", "[", "1", ":", "]", "\n", "test_pipeline", "=", "Compose", "(", "test_pipeline", ")", "\n", "# prepare data", "\n", "data", "=", "dict", "(", "img", "=", "img", ")", "\n", "data", "=", "test_pipeline", "(", "data", ")", "\n", "data", "=", "collate", "(", "[", "data", "]", ",", "samples_per_gpu", "=", "1", ")", "\n", "if", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "# scatter to specified GPU", "\n", "        ", "data", "=", "scatter", "(", "data", ",", "[", "device", "]", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "data", "[", "'img_metas'", "]", "=", "[", "i", ".", "data", "[", "0", "]", "for", "i", "in", "data", "[", "'img_metas'", "]", "]", "\n", "# data['img_metas'] is a list", "\n", "# forward the model", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.inference.show_result_pyplot": [[102, 137], ["hasattr", "model.show_result", "matplotlib.figure", "matplotlib.imshow", "matplotlib.title", "matplotlib.tight_layout", "matplotlib.show", "mmcv.bgr2rgb"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.show_result"], ["", "def", "show_result_pyplot", "(", "model", ",", "\n", "img", ",", "\n", "result", ",", "\n", "palette", "=", "None", ",", "\n", "fig_size", "=", "(", "15", ",", "10", ")", ",", "\n", "opacity", "=", "0.5", ",", "\n", "title", "=", "''", ",", "\n", "block", "=", "True", ")", ":", "\n", "    ", "\"\"\"Visualize the segmentation results on the image.\n\n    Args:\n        model (nn.Module): The loaded segmentor.\n        img (str or np.ndarray): Image filename or loaded image.\n        result (list): The segmentation result.\n        palette (list[list[int]]] | None): The palette of segmentation\n            map. If None is given, random palette will be generated.\n            Default: None\n        fig_size (tuple): Figure size of the pyplot figure.\n        opacity(float): Opacity of painted segmentation map.\n            Default 0.5.\n            Must be in (0, 1] range.\n        title (str): The title of pyplot figure.\n            Default is ''.\n        block (bool): Whether to block the pyplot figure.\n            Default is True.\n    \"\"\"", "\n", "if", "hasattr", "(", "model", ",", "'module'", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "img", "=", "model", ".", "show_result", "(", "\n", "img", ",", "result", ",", "palette", "=", "palette", ",", "show", "=", "False", ",", "opacity", "=", "opacity", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "fig_size", ")", "\n", "plt", ".", "imshow", "(", "mmcv", ".", "bgr2rgb", "(", "img", ")", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", "block", "=", "block", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.train.set_random_seed": [[15, 32], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_random_seed", "(", "seed", ",", "deterministic", "=", "False", ")", ":", "\n", "    ", "\"\"\"Set random seed.\n\n    Args:\n        seed (int): Seed to be used.\n        deterministic (bool): Whether to set the deterministic option for\n            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`\n            to True and `torch.backends.cudnn.benchmark` to False.\n            Default: False.\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "if", "deterministic", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.train.train_segmentor": [[34, 121], ["mmseg.utils.get_root_logger", "mmcv.runner.build_optimizer", "mmcv.runner.build_runner", "mmcv.runner.build_runner.register_training_hooks", "mmcv.runner.build_runner.run", "isinstance", "mmseg.datasets.build_dataloader", "cfg.get", "mmcv.parallel.MMDistributedDataParallel", "mmcv.parallel.MMDataParallel", "cfg.get", "warnings.warn", "cfg.get", "mmseg.datasets.build_dataset", "mmseg.datasets.build_dataloader", "cfg.get", "mmcv.runner.build_runner.register_hook", "mmcv.runner.build_runner.resume", "len", "mmcv.parallel.MMDataParallel.cuda", "mmcv.parallel.MMDataParallel.cuda", "dict", "dict", "eval_hook", "mmcv.runner.build_runner.load_checkpoint", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataloader"], ["", "", "def", "train_segmentor", "(", "model", ",", "\n", "dataset", ",", "\n", "cfg", ",", "\n", "distributed", "=", "False", ",", "\n", "validate", "=", "False", ",", "\n", "timestamp", "=", "None", ",", "\n", "meta", "=", "None", ")", ":", "\n", "    ", "\"\"\"Launch segmentor training.\"\"\"", "\n", "logger", "=", "get_root_logger", "(", "cfg", ".", "log_level", ")", "\n", "\n", "# prepare data loaders", "\n", "dataset", "=", "dataset", "if", "isinstance", "(", "dataset", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "dataset", "]", "\n", "data_loaders", "=", "[", "\n", "build_dataloader", "(", "\n", "ds", ",", "\n", "cfg", ".", "data", ".", "samples_per_gpu", ",", "\n", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "# cfg.gpus will be ignored if distributed", "\n", "len", "(", "cfg", ".", "gpu_ids", ")", ",", "\n", "dist", "=", "distributed", ",", "\n", "seed", "=", "cfg", ".", "seed", ",", "\n", "drop_last", "=", "True", ")", "for", "ds", "in", "dataset", "\n", "]", "\n", "\n", "# put model on gpus", "\n", "if", "distributed", ":", "\n", "        ", "find_unused_parameters", "=", "cfg", ".", "get", "(", "'find_unused_parameters'", ",", "False", ")", "\n", "# Sets the `find_unused_parameters` parameter in", "\n", "# torch.nn.parallel.DistributedDataParallel", "\n", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n", "device_ids", "=", "[", "torch", ".", "cuda", ".", "current_device", "(", ")", "]", ",", "\n", "broadcast_buffers", "=", "False", ",", "\n", "find_unused_parameters", "=", "find_unused_parameters", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "\n", "model", ".", "cuda", "(", "cfg", ".", "gpu_ids", "[", "0", "]", ")", ",", "device_ids", "=", "cfg", ".", "gpu_ids", ")", "\n", "\n", "# build runner", "\n", "", "optimizer", "=", "build_optimizer", "(", "model", ",", "cfg", ".", "optimizer", ")", "\n", "\n", "if", "cfg", ".", "get", "(", "'runner'", ")", "is", "None", ":", "\n", "        ", "cfg", ".", "runner", "=", "{", "'type'", ":", "'IterBasedRunner'", ",", "'max_iters'", ":", "cfg", ".", "total_iters", "}", "\n", "warnings", ".", "warn", "(", "\n", "'config is now expected to have a `runner` section, '", "\n", "'please set `runner` in your config.'", ",", "UserWarning", ")", "\n", "\n", "", "runner", "=", "build_runner", "(", "\n", "cfg", ".", "runner", ",", "\n", "default_args", "=", "dict", "(", "\n", "model", "=", "model", ",", "\n", "batch_processor", "=", "None", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "work_dir", "=", "cfg", ".", "work_dir", ",", "\n", "logger", "=", "logger", ",", "\n", "meta", "=", "meta", ")", ")", "\n", "\n", "# register hooks", "\n", "runner", ".", "register_training_hooks", "(", "cfg", ".", "lr_config", ",", "cfg", ".", "optimizer_config", ",", "\n", "cfg", ".", "checkpoint_config", ",", "cfg", ".", "log_config", ",", "\n", "cfg", ".", "get", "(", "'momentum_config'", ",", "None", ")", ")", "\n", "\n", "# an ugly walkaround to make the .log and .log.json filenames the same", "\n", "runner", ".", "timestamp", "=", "timestamp", "\n", "\n", "# register eval hooks", "\n", "if", "validate", ":", "\n", "        ", "val_dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "val", ",", "dict", "(", "test_mode", "=", "True", ")", ")", "\n", "val_dataloader", "=", "build_dataloader", "(", "\n", "val_dataset", ",", "\n", "samples_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "eval_cfg", "=", "cfg", ".", "get", "(", "'evaluation'", ",", "{", "}", ")", "\n", "eval_cfg", "[", "'by_epoch'", "]", "=", "cfg", ".", "runner", "[", "'type'", "]", "!=", "'IterBasedRunner'", "\n", "eval_hook", "=", "DistEvalHook", "if", "distributed", "else", "EvalHook", "\n", "# In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the", "\n", "# priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.", "\n", "runner", ".", "register_hook", "(", "\n", "eval_hook", "(", "val_dataloader", ",", "**", "eval_cfg", ")", ",", "priority", "=", "'LOW'", ")", "\n", "\n", "", "if", "cfg", ".", "resume_from", ":", "\n", "        ", "runner", ".", "resume", "(", "cfg", ".", "resume_from", ")", "\n", "", "elif", "cfg", ".", "load_from", ":", "\n", "        ", "runner", ".", "load_checkpoint", "(", "cfg", ".", "load_from", ")", "\n", "", "runner", ".", "run", "(", "data_loaders", ",", "cfg", ".", "workflow", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.np2tmp": [[12, 18], ["numpy.save", "tempfile.NamedTemporaryFile"], "function", ["None"], ["def", "np2tmp", "(", "array", ",", "temp_file_name", "=", "None", ",", "tmpdir", "=", "None", ")", ":", "\n", "    ", "if", "temp_file_name", "is", "None", ":", "\n", "        ", "temp_file_name", "=", "tempfile", ".", "NamedTemporaryFile", "(", "\n", "suffix", "=", "'.npy'", ",", "delete", "=", "False", ",", "dir", "=", "tmpdir", ")", ".", "name", "\n", "", "np", ".", "save", "(", "temp_file_name", ",", "array", ")", "\n", "return", "temp_file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.single_gpu_test": [[20, 75], ["model.eval", "mmcv.ProgressBar", "enumerate", "len", "mmcv.mkdir_or_exist", "isinstance", "len", "range", "torch.no_grad", "model", "mmcv.image.tensor2imgs", "zip", "results.extend", "results.append", "mmcv.ProgressBar.update", "len", "len", "mmcv.imresize", "model.module.show_result", "test.np2tmp", "os.join", "test.np2tmp"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.show_result", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.np2tmp", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.np2tmp"], ["", "def", "single_gpu_test", "(", "model", ",", "\n", "data_loader", ",", "\n", "show", "=", "False", ",", "\n", "out_dir", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "opacity", "=", "0.5", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "results", "=", "[", "]", "\n", "dataset", "=", "data_loader", ".", "dataset", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "dataset", ")", ")", "\n", "if", "efficient_test", ":", "\n", "        ", "mmcv", ".", "mkdir_or_exist", "(", "'.efficient_test'", ")", "\n", "", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "**", "data", ")", "\n", "\n", "", "if", "show", "or", "out_dir", ":", "\n", "            ", "img_tensor", "=", "data", "[", "'img'", "]", "[", "0", "]", "\n", "img_metas", "=", "data", "[", "'img_metas'", "]", "[", "0", "]", ".", "data", "[", "0", "]", "\n", "imgs", "=", "tensor2imgs", "(", "img_tensor", ",", "**", "img_metas", "[", "0", "]", "[", "'img_norm_cfg'", "]", ")", "\n", "assert", "len", "(", "imgs", ")", "==", "len", "(", "img_metas", ")", "\n", "\n", "for", "img", ",", "img_meta", "in", "zip", "(", "imgs", ",", "img_metas", ")", ":", "\n", "                ", "h", ",", "w", ",", "_", "=", "img_meta", "[", "'img_shape'", "]", "\n", "img_show", "=", "img", "[", ":", "h", ",", ":", "w", ",", ":", "]", "\n", "\n", "ori_h", ",", "ori_w", "=", "img_meta", "[", "'ori_shape'", "]", "[", ":", "-", "1", "]", "\n", "img_show", "=", "mmcv", ".", "imresize", "(", "img_show", ",", "(", "ori_w", ",", "ori_h", ")", ")", "\n", "\n", "if", "out_dir", ":", "\n", "                    ", "out_file", "=", "osp", ".", "join", "(", "out_dir", ",", "img_meta", "[", "'ori_filename'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "out_file", "=", "None", "\n", "\n", "", "model", ".", "module", ".", "show_result", "(", "\n", "img_show", ",", "\n", "result", ",", "\n", "palette", "=", "dataset", ".", "PALETTE", ",", "\n", "show", "=", "show", ",", "\n", "out_file", "=", "out_file", ",", "\n", "opacity", "=", "opacity", ")", "\n", "\n", "", "", "if", "isinstance", "(", "result", ",", "list", ")", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "[", "np2tmp", "(", "_", ",", "tmpdir", "=", "'.efficient_test'", ")", "for", "_", "in", "result", "]", "\n", "", "results", ".", "extend", "(", "result", ")", "\n", "", "else", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "np2tmp", "(", "result", ",", "tmpdir", "=", "'.efficient_test'", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "batch_size", "=", "len", "(", "result", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "prog_bar", ".", "update", "(", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.multi_gpu_test": [[77, 114], ["model.eval", "mmcv.runner.get_dist_info", "enumerate", "mmcv.ProgressBar", "mmcv.mkdir_or_exist", "isinstance", "mmcv.engine.collect_results_gpu", "mmcv.engine.collect_results_cpu", "len", "torch.no_grad", "model", "mmcv.engine.collect_results_cpu.extend", "mmcv.engine.collect_results_cpu.append", "len", "range", "len", "len", "test.np2tmp", "mmcv.ProgressBar.update", "test.np2tmp"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.np2tmp", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.np2tmp"], ["", "def", "multi_gpu_test", "(", "model", ",", "\n", "data_loader", ",", "\n", "tmpdir", "=", "None", ",", "\n", "gpu_collect", "=", "False", ",", "\n", "efficient_test", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "results", "=", "[", "]", "\n", "dataset", "=", "data_loader", ".", "dataset", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "dataset", ")", ")", "\n", "", "if", "efficient_test", ":", "\n", "        ", "mmcv", ".", "mkdir_or_exist", "(", "'.efficient_test'", ")", "\n", "", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "\n", "", "if", "isinstance", "(", "result", ",", "list", ")", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "[", "np2tmp", "(", "_", ",", "tmpdir", "=", "'.efficient_test'", ")", "for", "_", "in", "result", "]", "\n", "", "results", ".", "extend", "(", "result", ")", "\n", "", "else", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "np2tmp", "(", "result", ",", "tmpdir", "=", "'.efficient_test'", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "if", "rank", "==", "0", ":", "\n", "            ", "batch_size", "=", "len", "(", "result", ")", "\n", "for", "_", "in", "range", "(", "batch_size", "*", "world_size", ")", ":", "\n", "                ", "prog_bar", ".", "update", "(", ")", "\n", "\n", "# collect results from all ranks", "\n", "", "", "", "if", "gpu_collect", ":", "\n", "        ", "results", "=", "collect_results_gpu", "(", "results", ",", "len", "(", "dataset", ")", ")", "\n", "", "else", ":", "\n", "        ", "results", "=", "collect_results_cpu", "(", "results", ",", "len", "(", "dataset", ")", ",", "tmpdir", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.Upsample.__init__": [[32, 45], ["torch.Module.__init__", "isinstance", "tuple", "float", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "size", "=", "None", ",", "\n", "scale_factor", "=", "None", ",", "\n", "mode", "=", "'nearest'", ",", "\n", "align_corners", "=", "None", ")", ":", "\n", "        ", "super", "(", "Upsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "if", "isinstance", "(", "scale_factor", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "scale_factor", "=", "tuple", "(", "float", "(", "factor", ")", "for", "factor", "in", "scale_factor", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "scale_factor", "=", "float", "(", "scale_factor", ")", "if", "scale_factor", "else", "None", "\n", "", "self", ".", "mode", "=", "mode", "\n", "self", ".", "align_corners", "=", "align_corners", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.Upsample.forward": [[46, 52], ["wrappers.resize", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "size", ":", "\n", "            ", "size", "=", "[", "int", "(", "t", "*", "self", ".", "scale_factor", ")", "for", "t", "in", "x", ".", "shape", "[", "-", "2", ":", "]", "]", "\n", "", "else", ":", "\n", "            ", "size", "=", "self", ".", "size", "\n", "", "return", "resize", "(", "x", ",", "size", ",", "None", ",", "self", ".", "mode", ",", "self", ".", "align_corners", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize": [[8, 28], ["torch.interpolate", "tuple", "tuple", "int", "int", "warnings.warn"], "function", ["None"], ["def", "resize", "(", "input", ",", "\n", "size", "=", "None", ",", "\n", "scale_factor", "=", "None", ",", "\n", "mode", "=", "'nearest'", ",", "\n", "align_corners", "=", "None", ",", "\n", "warning", "=", "True", ")", ":", "\n", "    ", "if", "warning", ":", "\n", "        ", "if", "size", "is", "not", "None", "and", "align_corners", ":", "\n", "            ", "input_h", ",", "input_w", "=", "tuple", "(", "int", "(", "x", ")", "for", "x", "in", "input", ".", "shape", "[", "2", ":", "]", ")", "\n", "output_h", ",", "output_w", "=", "tuple", "(", "int", "(", "x", ")", "for", "x", "in", "size", ")", "\n", "if", "output_h", ">", "input_h", "or", "output_w", ">", "output_h", ":", "\n", "                ", "if", "(", "(", "output_h", ">", "1", "and", "output_w", ">", "1", "and", "input_h", ">", "1", "\n", "and", "input_w", ">", "1", ")", "and", "(", "output_h", "-", "1", ")", "%", "(", "input_h", "-", "1", ")", "\n", "and", "(", "output_w", "-", "1", ")", "%", "(", "input_w", "-", "1", ")", ")", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "f'When align_corners={align_corners}, '", "\n", "'the output would more aligned if '", "\n", "f'input size {(input_h, input_w)} is `x+1` and '", "\n", "f'out size {(output_h, output_w)} is `nx+1`'", ")", "\n", "", "", "", "", "return", "F", ".", "interpolate", "(", "input", ",", "size", ",", "scale_factor", ",", "mode", ",", "align_corners", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.__init__": [[18, 32], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.empty().uniform_", "torch.empty().uniform_", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "channels", ",", "num_codes", ")", ":", "\n", "        ", "super", "(", "Encoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# init codewords and smoothing factor", "\n", "self", ".", "channels", ",", "self", ".", "num_codes", "=", "channels", ",", "num_codes", "\n", "std", "=", "1.", "/", "(", "(", "num_codes", "*", "channels", ")", "**", "0.5", ")", "\n", "# [num_codes, channels]", "\n", "self", ".", "codewords", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "empty", "(", "num_codes", ",", "channels", ",", "\n", "dtype", "=", "torch", ".", "float", ")", ".", "uniform_", "(", "-", "std", ",", "std", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "# [num_codes]", "\n", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "empty", "(", "num_codes", ",", "dtype", "=", "torch", ".", "float", ")", ".", "uniform_", "(", "-", "1", ",", "0", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.scaled_l2": [[33, 45], ["codewords.size", "x.size", "scale.view", "x.unsqueeze().expand", "codewords.view", "x.unsqueeze", "x.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "scaled_l2", "(", "x", ",", "codewords", ",", "scale", ")", ":", "\n", "        ", "num_codes", ",", "channels", "=", "codewords", ".", "size", "(", ")", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "reshaped_scale", "=", "scale", ".", "view", "(", "(", "1", ",", "1", ",", "num_codes", ")", ")", "\n", "expanded_x", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "(", "batch_size", ",", "x", ".", "size", "(", "1", ")", ",", "num_codes", ",", "channels", ")", ")", "\n", "reshaped_codewords", "=", "codewords", ".", "view", "(", "(", "1", ",", "1", ",", "num_codes", ",", "channels", ")", ")", "\n", "\n", "scaled_l2_norm", "=", "reshaped_scale", "*", "(", "\n", "expanded_x", "-", "reshaped_codewords", ")", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", "=", "3", ")", "\n", "return", "scaled_l2_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.aggregate": [[46, 57], ["codewords.size", "codewords.view", "x.size", "x.unsqueeze().expand", "x.unsqueeze", "x.size", "assignment_weights.unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "aggregate", "(", "assignment_weights", ",", "x", ",", "codewords", ")", ":", "\n", "        ", "num_codes", ",", "channels", "=", "codewords", ".", "size", "(", ")", "\n", "reshaped_codewords", "=", "codewords", ".", "view", "(", "(", "1", ",", "1", ",", "num_codes", ",", "channels", ")", ")", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "expanded_x", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "(", "batch_size", ",", "x", ".", "size", "(", "1", ")", ",", "num_codes", ",", "channels", ")", ")", "\n", "encoded_feat", "=", "(", "assignment_weights", ".", "unsqueeze", "(", "3", ")", "*", "\n", "(", "expanded_x", "-", "reshaped_codewords", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "encoded_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.forward": [[58, 70], ["x.view().transpose().contiguous.view().transpose().contiguous.size", "x.view().transpose().contiguous.view().transpose().contiguous.view().transpose().contiguous", "torch.nn.functional.softmax", "encoding.Encoding.aggregate", "encoding.Encoding.scaled_l2", "x.view().transpose().contiguous.view().transpose().contiguous.dim", "x.view().transpose().contiguous.view().transpose().contiguous.size", "x.view().transpose().contiguous.view().transpose().contiguous.view().transpose", "x.view().transpose().contiguous.view().transpose().contiguous.view"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.aggregate", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.scaled_l2"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "assert", "x", ".", "dim", "(", ")", "==", "4", "and", "x", ".", "size", "(", "1", ")", "==", "self", ".", "channels", "\n", "# [batch_size, channels, height, width]", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "# [batch_size, height x width, channels]", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "self", ".", "channels", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "# assignment_weights: [batch_size, channels, num_codes]", "\n", "assignment_weights", "=", "F", ".", "softmax", "(", "\n", "self", ".", "scaled_l2", "(", "x", ",", "self", ".", "codewords", ",", "self", ".", "scale", ")", ",", "dim", "=", "2", ")", "\n", "# aggregate", "\n", "encoded_feat", "=", "self", ".", "aggregate", "(", "assignment_weights", ",", "x", ",", "self", ".", "codewords", ")", "\n", "return", "encoded_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.encoding.Encoding.__repr__": [[71, 76], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "repr_str", "=", "self", ".", "__class__", ".", "__name__", "\n", "repr_str", "+=", "f'(Nx{self.channels}xHxW =>Nx{self.num_codes}'", "f'x{self.channels})'", "\n", "return", "repr_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_backbone": [[18, 21], ["BACKBONES.build"], "function", ["None"], ["base_soft_limit", "=", "rlimit", "[", "0", "]", "\n", "hard_limit", "=", "rlimit", "[", "1", "]", "\n", "soft_limit", "=", "min", "(", "max", "(", "4096", ",", "base_soft_limit", ")", ",", "hard_limit", ")", "\n", "resource", ".", "setrlimit", "(", "resource", ".", "RLIMIT_NOFILE", ",", "(", "soft_limit", ",", "hard_limit", ")", ")", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_neck": [[23, 26], ["NECKS.build"], "function", ["None"], ["", "DATASETS", "=", "Registry", "(", "'dataset'", ")", "\n", "PIPELINES", "=", "Registry", "(", "'pipeline'", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head": [[28, 31], ["HEADS.build"], "function", ["None"], ["    ", "\"\"\"Build :obj:`ConcatDataset by.\"\"\"", "\n", "from", ".", "dataset_wrappers", "import", "ConcatDataset", "\n", "img_dir", "=", "cfg", "[", "'img_dir'", "]", "\n", "ann_dir", "=", "cfg", ".", "get", "(", "'ann_dir'", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_loss": [[33, 36], ["LOSSES.build"], "function", ["None"], ["# pop 'separate_eval' since it is not a valid key for common datasets.", "\n", "separate_eval", "=", "cfg", ".", "pop", "(", "'separate_eval'", ",", "True", ")", "\n", "num_img_dir", "=", "len", "(", "img_dir", ")", "if", "isinstance", "(", "img_dir", ",", "(", "list", ",", "tuple", ")", ")", "else", "1", "\n", "if", "ann_dir", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_segmentor": [[38, 50], ["SEGMENTORS.build", "warnings.warn", "cfg.get", "cfg.get", "dict"], "function", ["None"], ["", "else", ":", "\n", "        ", "num_ann_dir", "=", "0", "\n", "", "if", "split", "is", "not", "None", ":", "\n", "        ", "num_split", "=", "len", "(", "split", ")", "if", "isinstance", "(", "split", ",", "(", "list", ",", "tuple", ")", ")", "else", "1", "\n", "", "else", ":", "\n", "        ", "num_split", "=", "0", "\n", "", "if", "num_img_dir", ">", "1", ":", "\n", "        ", "assert", "num_img_dir", "==", "num_ann_dir", "or", "num_ann_dir", "==", "0", "\n", "assert", "num_img_dir", "==", "num_split", "or", "num_split", "==", "0", "\n", "", "else", ":", "\n", "        ", "assert", "num_split", "==", "num_ann_dir", "or", "num_ann_dir", "<=", "1", "\n", "", "num_dset", "=", "max", "(", "num_split", ",", "num_img_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.Resampler.__init__": [[22, 32], ["torch.Module.__init__", "pyramid_transformer._make_grid"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck._make_grid"], ["    ", "def", "__init__", "(", "self", ",", "resolution", ",", "extents", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Store z positions of the near and far planes", "\n", "# extents[1]:zmin,extents[3]:zmax", "\n", "self", ".", "near", "=", "extents", "[", "1", "]", "\n", "self", ".", "far", "=", "extents", "[", "3", "]", "\n", "\n", "# Make a grid in the x-z plane", "\n", "self", ".", "grid", "=", "_make_grid", "(", "resolution", ",", "extents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.Resampler.forward": [[33, 55], ["pyramid_transformer.Resampler.grid.to", "[].view", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pyramid_transformer.Resampler.grid.unsqueeze", "features.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "calib", ")", ":", "\n", "# Copy grid to the correct device", "\n", "        ", "self", ".", "grid", "=", "self", ".", "grid", ".", "to", "(", "features", ")", "\n", "\n", "# We ignore the image v-coordinate, and assume the world Y-coordinate", "\n", "# is zero, so we only need a 2x2 submatrix of the original 3x3 matrix", "\n", "# calib shape:[bs,3,3]-->[bs,2,3]-->[bs,2,2]-->[bs,1,1,2,2]", "\n", "calib", "=", "calib", "[", ":", ",", "[", "0", ",", "2", "]", "]", "[", "...", ",", "[", "0", ",", "2", "]", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "2", ",", "2", ")", "\n", "\n", "# Transform grid center locations into image u-coordinates", "\n", "cam_coords", "=", "torch", ".", "matmul", "(", "calib", ",", "self", ".", "grid", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# Apply perspective projection and normalize", "\n", "ucoords", "=", "cam_coords", "[", "...", ",", "0", "]", "/", "cam_coords", "[", "...", ",", "1", "]", "\n", "ucoords", "=", "ucoords", "/", "features", ".", "size", "(", "-", "1", ")", "*", "2", "-", "1", "\n", "\n", "# Normalize z coordinates", "\n", "zcoords", "=", "(", "cam_coords", "[", "...", ",", "1", "]", "-", "self", ".", "near", ")", "/", "(", "self", ".", "far", "-", "self", ".", "near", ")", "*", "2", "-", "1", "\n", "\n", "# Resample 3D feature map", "\n", "grid_coords", "=", "torch", ".", "stack", "(", "[", "ucoords", ",", "zcoords", "]", ",", "-", "1", ")", ".", "clamp", "(", "-", "1.1", ",", "1.1", ")", "\n", "return", "F", ".", "grid_sample", "(", "features", ",", "grid_coords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.DenseTransformer.__init__": [[58, 84], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_transformer.Resampler", "math.ceil", "math.ceil", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "resolution", ",", "grid_extents", ",", "\n", "ymin", ",", "ymax", ",", "focal_length", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Initial convolution to reduce feature dimensions", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", ",", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "GroupNorm", "(", "16", ",", "channels", ")", "\n", "\n", "# Resampler transforms perspective features to BEV", "\n", "self", ".", "resampler", "=", "Resampler", "(", "resolution", ",", "grid_extents", ")", "\n", "\n", "# Compute input height based on region of image covered by grid", "\n", "self", ".", "zmin", ",", "zmax", "=", "grid_extents", "[", "1", "]", ",", "grid_extents", "[", "3", "]", "\n", "self", ".", "in_height", "=", "math", ".", "ceil", "(", "focal_length", "*", "(", "ymax", "-", "ymin", ")", "/", "self", ".", "zmin", ")", "\n", "# self.ymid = 1", "\n", "self", ".", "ymid", "=", "(", "ymin", "+", "ymax", ")", "/", "2", "\n", "\n", "# Compute number of output cells required", "\n", "self", ".", "out_depth", "=", "math", ".", "ceil", "(", "(", "zmax", "-", "self", ".", "zmin", ")", "/", "resolution", ")", "\n", "\n", "# Dense layer which maps UV features to UZ", "\n", "self", ".", "fc", "=", "nn", ".", "Conv1d", "(", "\n", "channels", "*", "self", ".", "in_height", ",", "channels", "*", "self", ".", "out_depth", ",", "1", ",", "groups", "=", "groups", "\n", ")", "\n", "\n", "self", ".", "out_channels", "=", "channels", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.DenseTransformer.forward": [[85, 100], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu", "torch.relu", "torch.relu", "torch.relu.flatten", "pyramid_transformer.DenseTransformer.fc().view", "pyramid_transformer.DenseTransformer.resampler", "pyramid_transformer.DenseTransformer.bn", "pyramid_transformer.DenseTransformer._crop_feature_map", "pyramid_transformer.DenseTransformer.conv", "pyramid_transformer.DenseTransformer.fc", "zip"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.DenseTransformer._crop_feature_map"], ["", "def", "forward", "(", "self", ",", "features", ",", "calib", ",", "*", "args", ")", ":", "\n", "# Crop feature maps to a fixed input height", "\n", "        ", "features", "=", "torch", ".", "stack", "(", "[", "self", ".", "_crop_feature_map", "(", "fmap", ",", "cal", ")", "\n", "for", "fmap", ",", "cal", "in", "zip", "(", "features", ",", "calib", ")", "]", ")", "\n", "\n", "# Reduce feature dimension to minimize memory usage", "\n", "features", "=", "F", ".", "relu", "(", "self", ".", "bn", "(", "self", ".", "conv", "(", "features", ")", ")", ")", "\n", "\n", "# Flatten height and channel dimensions", "\n", "B", ",", "C", ",", "_", ",", "W", "=", "features", ".", "shape", "\n", "flat_feats", "=", "features", ".", "flatten", "(", "1", ",", "2", ")", "\n", "# H is not fixed every time", "\n", "bev_feats", "=", "self", ".", "fc", "(", "flat_feats", ")", ".", "view", "(", "B", ",", "C", ",", "-", "1", ",", "W", ")", "\n", "# Resample to orthographic grid", "\n", "return", "self", ".", "resampler", "(", "bev_feats", ",", "calib", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.DenseTransformer._crop_feature_map": [[101, 110], ["math.floor", "math.floor", "torch.pad", "torch.pad", "torch.pad"], "methods", ["None"], ["", "def", "_crop_feature_map", "(", "self", ",", "fmap", ",", "calib", ")", ":", "\n", "# Compute upper and lower bounds of visible region", "\n", "        ", "focal_length", ",", "img_offset", "=", "calib", "[", "1", ",", "1", ":", "]", "\n", "vmid", "=", "self", ".", "ymid", "*", "focal_length", "/", "self", ".", "zmin", "+", "img_offset", "\n", "vmin", "=", "math", ".", "floor", "(", "vmid", "-", "self", ".", "in_height", "/", "2", ")", "\n", "vmax", "=", "math", ".", "floor", "(", "vmid", "+", "self", ".", "in_height", "/", "2", ")", "\n", "\n", "# Pad or crop input tensor to match dimensions", "\n", "return", "F", ".", "pad", "(", "fmap", ",", "[", "0", ",", "0", ",", "-", "vmin", ",", "vmax", "-", "fmap", ".", "shape", "[", "-", "2", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.TransformerPyramid.__init__": [[114, 130], ["mmcv.runner.BaseModule.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "functools.reduce", "min", "pyramid_transformer.DenseTransformer", "pyramid_transformer.TransformerPyramid.transformers.append", "pow", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", "=", "256", ",", "channels", "=", "64", ",", "resolution", "=", "0.25", "*", "reduce", "(", "mul", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "extents", "=", "[", "-", "25.0", ",", "1.0", ",", "25.0", ",", "50.0", "]", ",", "ymin", "=", "-", "2", ",", "ymax", "=", "4", ",", "focal_length", "=", "630.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transformers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# Scaled focal length for each transformer", "\n", "            ", "focal", "=", "focal_length", "/", "pow", "(", "2", ",", "i", "+", "3", ")", "\n", "\n", "# Compute grid bounds for each transformer", "\n", "zmax", "=", "min", "(", "math", ".", "floor", "(", "focal", "*", "2", ")", "*", "resolution", ",", "extents", "[", "3", "]", ")", "\n", "zmin", "=", "math", ".", "floor", "(", "focal", ")", "*", "resolution", "if", "i", "<", "4", "else", "extents", "[", "1", "]", "\n", "subset_extents", "=", "[", "extents", "[", "0", "]", ",", "zmin", ",", "extents", "[", "2", "]", ",", "zmax", "]", "\n", "# Build transformers", "\n", "tfm", "=", "DenseTransformer", "(", "in_channels", ",", "channels", ",", "resolution", ",", "\n", "subset_extents", ",", "ymin", ",", "ymax", ",", "focal", ")", "\n", "self", ".", "transformers", ".", "append", "(", "tfm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer.TransformerPyramid.forward": [[131, 144], ["list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "calib.clone", "list.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "feature_maps", ",", "calib", ")", ":", "\n", "        ", "bev_feats", "=", "list", "(", ")", "\n", "# scale = 8,16,32,64,128", "\n", "# calib.shape = [bs,3,3]", "\n", "for", "i", ",", "fmap", "in", "enumerate", "(", "feature_maps", ")", ":", "\n", "# Scale calibration matrix to account for downsampling", "\n", "            ", "scale", "=", "8", "*", "2", "**", "i", "\n", "calib_downsamp", "=", "calib", ".", "clone", "(", ")", "\n", "calib_downsamp", "[", ":", ",", ":", "2", "]", "=", "calib", "[", ":", ",", ":", "2", "]", "/", "scale", "\n", "\n", "# Apply orthographic transformation to each feature map separately", "\n", "bev_feats", ".", "append", "(", "self", ".", "transformers", "[", "i", "]", "(", "fmap", ",", "calib_downsamp", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyramid_transformer._make_grid": [[13, 19], ["torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.stack", "torch.stack", "torch.stack", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["def", "_make_grid", "(", "resolution", ",", "extents", ")", ":", "\n", "# Create a grid of cooridinates in the birds-eye-view", "\n", "    ", "x1", ",", "z1", ",", "x2", ",", "z2", "=", "extents", "\n", "zz", ",", "xx", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "z1", ",", "z2", ",", "resolution", ")", ",", "torch", ".", "arange", "(", "x1", ",", "x2", ",", "resolution", ")", ")", "\n", "\n", "return", "torch", ".", "stack", "(", "[", "xx", ",", "zz", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.fpn.FPN.__init__": [[67, 161], ["dict", "dict", "mmcv.runner.BaseModule.__init__", "isinstance", "len", "upsample_cfg.copy", "isinstance", "isinstance", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "mmcv.cnn.ConvModule", "mmcv.cnn.ConvModule", "fpn.FPN.lateral_convs.append", "fpn.FPN.fpn_convs.append", "range", "len", "mmcv.cnn.ConvModule", "fpn.FPN.fpn_convs.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "num_outs", ",", "\n", "start_level", "=", "0", ",", "\n", "end_level", "=", "-", "1", ",", "\n", "add_extra_convs", "=", "False", ",", "\n", "extra_convs_on_inputs", "=", "False", ",", "\n", "relu_before_extra_convs", "=", "False", ",", "\n", "no_norm_on_lateral", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "None", ",", "\n", "upsample_cfg", "=", "dict", "(", "mode", "=", "'nearest'", ")", ",", "\n", "init_cfg", "=", "dict", "(", "\n", "type", "=", "'Xavier'", ",", "layer", "=", "'Conv2d'", ",", "distribution", "=", "'uniform'", ")", ")", ":", "\n", "        ", "super", "(", "FPN", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "assert", "isinstance", "(", "in_channels", ",", "list", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_ins", "=", "len", "(", "in_channels", ")", "\n", "self", ".", "num_outs", "=", "num_outs", "\n", "self", ".", "relu_before_extra_convs", "=", "relu_before_extra_convs", "\n", "self", ".", "no_norm_on_lateral", "=", "no_norm_on_lateral", "\n", "self", ".", "fp16_enabled", "=", "False", "\n", "self", ".", "upsample_cfg", "=", "upsample_cfg", ".", "copy", "(", ")", "\n", "\n", "if", "end_level", "==", "-", "1", ":", "\n", "            ", "self", ".", "backbone_end_level", "=", "self", ".", "num_ins", "\n", "assert", "num_outs", ">=", "self", ".", "num_ins", "-", "start_level", "\n", "", "else", ":", "\n", "# if end_level < inputs, no extra level is allowed", "\n", "            ", "self", ".", "backbone_end_level", "=", "end_level", "\n", "assert", "end_level", "<=", "len", "(", "in_channels", ")", "\n", "assert", "num_outs", "==", "end_level", "-", "start_level", "\n", "", "self", ".", "start_level", "=", "start_level", "\n", "self", ".", "end_level", "=", "end_level", "\n", "self", ".", "add_extra_convs", "=", "add_extra_convs", "\n", "assert", "isinstance", "(", "add_extra_convs", ",", "(", "str", ",", "bool", ")", ")", "\n", "if", "isinstance", "(", "add_extra_convs", ",", "str", ")", ":", "\n", "# Extra_convs_source choices: 'on_input', 'on_lateral', 'on_output'", "\n", "            ", "assert", "add_extra_convs", "in", "(", "'on_input'", ",", "'on_lateral'", ",", "'on_output'", ")", "\n", "", "elif", "add_extra_convs", ":", "# True", "\n", "            ", "if", "extra_convs_on_inputs", ":", "\n", "# For compatibility with previous release", "\n", "# TODO: deprecate `extra_convs_on_inputs`", "\n", "                ", "self", ".", "add_extra_convs", "=", "'on_input'", "\n", "", "else", ":", "\n", "                ", "self", ".", "add_extra_convs", "=", "'on_output'", "\n", "\n", "", "", "self", ".", "lateral_convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fpn_convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "start_level", ",", "self", ".", "backbone_end_level", ")", ":", "\n", "            ", "l_conv", "=", "ConvModule", "(", "\n", "in_channels", "[", "i", "]", ",", "\n", "out_channels", ",", "\n", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", "if", "not", "self", ".", "no_norm_on_lateral", "else", "None", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "inplace", "=", "False", ")", "\n", "fpn_conv", "=", "ConvModule", "(", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "3", ",", "\n", "padding", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "inplace", "=", "False", ")", "\n", "\n", "self", ".", "lateral_convs", ".", "append", "(", "l_conv", ")", "\n", "self", ".", "fpn_convs", ".", "append", "(", "fpn_conv", ")", "\n", "\n", "# add extra conv layers (e.g., RetinaNet)", "\n", "", "extra_levels", "=", "num_outs", "-", "self", ".", "backbone_end_level", "+", "self", ".", "start_level", "\n", "if", "self", ".", "add_extra_convs", "and", "extra_levels", ">=", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "extra_levels", ")", ":", "\n", "                ", "if", "i", "==", "0", "and", "self", ".", "add_extra_convs", "==", "'on_input'", ":", "\n", "                    ", "in_channels", "=", "self", ".", "in_channels", "[", "self", ".", "backbone_end_level", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "in_channels", "=", "out_channels", "\n", "", "extra_fpn_conv", "=", "ConvModule", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "inplace", "=", "False", ")", "\n", "self", ".", "fpn_convs", ".", "append", "(", "extra_fpn_conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.fpn.FPN.forward": [[162, 212], ["mmcv.runner.auto_fp16", "len", "range", "tuple", "len", "len", "lateral_conv", "len", "enumerate", "mmseg.ops.resize", "mmseg.ops.resize", "range", "range", "outs.append", "range", "outs.append", "torch.max_pool2d", "torch.max_pool2d", "outs.append", "outs.append", "torch.relu", "torch.relu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "", "", "@", "auto_fp16", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "len", "(", "inputs", ")", "==", "len", "(", "self", ".", "in_channels", ")", "\n", "# build laterals", "\n", "laterals", "=", "[", "\n", "lateral_conv", "(", "inputs", "[", "i", "+", "self", ".", "start_level", "]", ")", "\n", "for", "i", ",", "lateral_conv", "in", "enumerate", "(", "self", ".", "lateral_convs", ")", "\n", "]", "\n", "\n", "# build top-down path", "\n", "used_backbone_levels", "=", "len", "(", "laterals", ")", "\n", "for", "i", "in", "range", "(", "used_backbone_levels", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "# In some cases, fixing `scale factor` (e.g. 2) is preferred, but", "\n", "#  it cannot co-exist with `size` in `F.interpolate`.", "\n", "            ", "if", "'scale_factor'", "in", "self", ".", "upsample_cfg", ":", "\n", "                ", "laterals", "[", "i", "-", "1", "]", "+=", "resize", "(", "laterals", "[", "i", "]", ",", "**", "self", ".", "upsample_cfg", ")", "\n", "", "else", ":", "\n", "                ", "prev_shape", "=", "laterals", "[", "i", "-", "1", "]", ".", "shape", "[", "2", ":", "]", "\n", "laterals", "[", "i", "-", "1", "]", "+=", "resize", "(", "\n", "laterals", "[", "i", "]", ",", "size", "=", "prev_shape", ",", "**", "self", ".", "upsample_cfg", ")", "\n", "\n", "# build outputs", "\n", "# part 1: from original levels", "\n", "", "", "outs", "=", "[", "\n", "self", ".", "fpn_convs", "[", "i", "]", "(", "laterals", "[", "i", "]", ")", "for", "i", "in", "range", "(", "used_backbone_levels", ")", "\n", "]", "\n", "# part 2: add extra levels", "\n", "if", "self", ".", "num_outs", ">", "len", "(", "outs", ")", ":", "\n", "# use max pool to get more levels on top of outputs", "\n", "# (e.g., Faster R-CNN, Mask R-CNN)", "\n", "            ", "if", "not", "self", ".", "add_extra_convs", ":", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "num_outs", "-", "used_backbone_levels", ")", ":", "\n", "                    ", "outs", ".", "append", "(", "F", ".", "max_pool2d", "(", "outs", "[", "-", "1", "]", ",", "1", ",", "stride", "=", "2", ")", ")", "\n", "# add conv layers on top of original feature maps (RetinaNet)", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "add_extra_convs", "==", "'on_input'", ":", "\n", "                    ", "extra_source", "=", "inputs", "[", "self", ".", "backbone_end_level", "-", "1", "]", "\n", "", "elif", "self", ".", "add_extra_convs", "==", "'on_lateral'", ":", "\n", "                    ", "extra_source", "=", "laterals", "[", "-", "1", "]", "\n", "", "elif", "self", ".", "add_extra_convs", "==", "'on_output'", ":", "\n", "                    ", "extra_source", "=", "outs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "", "outs", ".", "append", "(", "self", ".", "fpn_convs", "[", "used_backbone_levels", "]", "(", "extra_source", ")", ")", "\n", "for", "i", "in", "range", "(", "used_backbone_levels", "+", "1", ",", "self", ".", "num_outs", ")", ":", "\n", "                    ", "if", "self", ".", "relu_before_extra_convs", ":", "\n", "                        ", "outs", ".", "append", "(", "self", ".", "fpn_convs", "[", "i", "]", "(", "F", ".", "relu", "(", "outs", "[", "-", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                        ", "outs", ".", "append", "(", "self", ".", "fpn_convs", "[", "i", "]", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "", "", "", "", "return", "tuple", "(", "outs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.QuickCumsum.forward": [[23, 39], ["torch.cat.cumsum", "torch.cat.cumsum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ctx.save_for_backward", "ctx.mark_non_differentiable"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "geom_feats", ",", "ranks", ")", ":", "\n", "        ", "x", "=", "x", ".", "cumsum", "(", "0", ")", "\n", "kept", "=", "torch", ".", "ones", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "kept", "[", ":", "-", "1", "]", "=", "(", "ranks", "[", "1", ":", "]", "!=", "ranks", "[", ":", "-", "1", "]", ")", "\n", "\n", "x", ",", "geom_feats", "=", "x", "[", "kept", "]", ",", "geom_feats", "[", "kept", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", ":", "1", "]", ",", "x", "[", "1", ":", "]", "-", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# save kept for backward", "\n", "ctx", ".", "save_for_backward", "(", "kept", ")", "\n", "\n", "# no gradient for geom_feats", "\n", "ctx", ".", "mark_non_differentiable", "(", "geom_feats", ")", "\n", "\n", "return", "x", ",", "geom_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.QuickCumsum.backward": [[40, 47], ["torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "gradx", ",", "gradgeom", ")", ":", "\n", "        ", "kept", ",", "=", "ctx", ".", "saved_tensors", "\n", "back", "=", "torch", ".", "cumsum", "(", "kept", ",", "0", ")", "\n", "back", "[", "kept", "]", "-=", "1", "\n", "val", "=", "gradx", "[", "back", "]", "\n", "return", "val", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.TransformerLiftSplatShoot.__init__": [[51, 76], ["dict", "mmcv.runner.BaseModule.__init__", "lift_splat_shoot_transformer.gen_dx_bx", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lift_splat_shoot_transformer.TransformerLiftSplatShoot.create_frustum", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.gen_dx_bx", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.create_frustum"], ["    ", "def", "__init__", "(", "self", ",", "use_high_res", "=", "False", ",", "downsample", "=", "32", ",", "in_channels", "=", "768", ",", "bev_feature_channels", "=", "64", ",", "ogfH", "=", "600", ",", "ogfW", "=", "800", ",", "\n", "grid_conf", "=", "dict", "(", "dbound", "=", "[", "1", ",", "50", ",", "1", "]", ",", "xbound", "=", "[", "-", "25", ",", "25", ",", "0.5", "]", ",", "zbound", "=", "[", "1", ",", "50", ",", "0.5", "]", ",", "ybound", "=", "[", "-", "10", ",", "10", ",", "20", "]", ")", ")", ":", "\n", "        ", "super", "(", "TransformerLiftSplatShoot", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_high_res", "=", "use_high_res", "\n", "self", ".", "grid_conf", "=", "grid_conf", "\n", "dx", ",", "bx", ",", "nx", "=", "gen_dx_bx", "(", "self", ".", "grid_conf", "[", "'xbound'", "]", ",", "\n", "self", ".", "grid_conf", "[", "'ybound'", "]", ",", "\n", "self", ".", "grid_conf", "[", "'zbound'", "]", ",", "\n", ")", "\n", "self", ".", "dx", "=", "nn", ".", "Parameter", "(", "dx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "bx", "=", "nn", ".", "Parameter", "(", "bx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "nx", "=", "nn", ".", "Parameter", "(", "nx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "if", "not", "self", ".", "use_high_res", ":", "\n", "            ", "self", ".", "ogfH", "=", "ogfH", "\n", "self", ".", "ogfW", "=", "ogfW", "\n", "", "else", ":", "\n", "            ", "self", ".", "ogfH", "=", "1024", "\n", "self", ".", "ogfW", "=", "1024", "\n", "", "self", ".", "frustum", "=", "self", ".", "create_frustum", "(", ")", "\n", "self", ".", "D", ",", "_", ",", "_", ",", "_", "=", "self", ".", "frustum", ".", "shape", "\n", "self", ".", "C", "=", "bev_feature_channels", "\n", "# by default, self.C = 64, self.D = 49", "\n", "self", ".", "depthnet", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "self", ".", "D", "+", "self", ".", "C", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "use_quickcumsum", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.TransformerLiftSplatShoot.create_frustum": [[77, 87], ["torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.Parameter", "torch.Parameter", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace"], "methods", ["None"], ["", "def", "create_frustum", "(", "self", ")", ":", "\n", "        ", "fH", ",", "fW", "=", "self", ".", "ogfH", "//", "self", ".", "downsample", ",", "self", ".", "ogfW", "//", "self", ".", "downsample", "\n", "depth_samples", "=", "torch", ".", "arange", "(", "*", "self", ".", "grid_conf", "[", "'dbound'", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "fH", ",", "fW", ")", "\n", "num_depth", ",", "_", ",", "_", "=", "depth_samples", ".", "shape", "\n", "x_samples", "=", "torch", ".", "linspace", "(", "0", ",", "self", ".", "ogfW", "-", "1", ",", "fW", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "1", ",", "1", ",", "fW", ")", ".", "expand", "(", "num_depth", ",", "fH", ",", "fW", ")", "\n", "y_samples", "=", "torch", ".", "linspace", "(", "0", ",", "self", ".", "ogfH", "-", "1", ",", "fH", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "1", ",", "fH", ",", "1", ")", ".", "expand", "(", "num_depth", ",", "fH", ",", "fW", ")", "\n", "\n", "# D x H x W x 3", "\n", "frustum", "=", "torch", ".", "stack", "(", "(", "x_samples", ",", "y_samples", ",", "depth_samples", ")", ",", "-", "1", ")", "\n", "return", "nn", ".", "Parameter", "(", "frustum", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.TransformerLiftSplatShoot.get_geometry": [[88, 97], ["lift_splat_shoot_transformer.TransformerLiftSplatShoot.frustum.view().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse.view().matmul().squeeze().view", "torch.inverse.view().matmul().squeeze().view", "lift_splat_shoot_transformer.TransformerLiftSplatShoot.frustum.view", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul", "torch.inverse.view().matmul", "torch.inverse.view().matmul().squeeze().view.unsqueeze", "torch.inverse.view", "torch.inverse.view"], "methods", ["None"], ["", "def", "get_geometry", "(", "self", ",", "intrinstics", ")", ":", "\n", "        ", "B", "=", "intrinstics", ".", "shape", "[", "0", "]", "\n", "D", ",", "H", ",", "W", ",", "C", "=", "self", ".", "frustum", ".", "shape", "\n", "points", "=", "self", ".", "frustum", ".", "view", "(", "1", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", ".", "expand", "(", "B", ",", "D", ",", "H", ",", "W", ",", "C", ")", "\n", "points", "=", "torch", ".", "cat", "(", "[", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", ":", "2", "]", "*", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", "2", ":", "3", "]", ",", "\n", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", "2", ":", "3", "]", "]", ",", "4", ")", "\n", "combine", "=", "torch", ".", "inverse", "(", "intrinstics", ")", "\n", "points", "=", "combine", ".", "view", "(", "B", ",", "1", ",", "1", ",", "1", ",", "3", ",", "3", ")", ".", "matmul", "(", "points", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "B", ",", "1", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "points", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.TransformerLiftSplatShoot.voxel_pooling": [[98, 140], ["lift_splat_shoot_transformer.TransformerLiftSplatShoot.nx.to", "x.reshape.reshape.reshape", "torch.cat.view", "torch.cat.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ranks.argsort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lift_splat_shoot_transformer.cumsum_trick", "QuickCumsum.apply", "torch.cat.unbind", "torch.cat.unbind", "torch.full", "torch.full", "torch.full", "torch.full", "range"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.cumsum_trick"], ["", "def", "voxel_pooling", "(", "self", ",", "geom_feats", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "D", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "Nprime", "=", "B", "*", "N", "*", "D", "*", "H", "*", "W", "\n", "nx", "=", "self", ".", "nx", ".", "to", "(", "torch", ".", "long", ")", "\n", "# flatten x", "\n", "x", "=", "x", ".", "reshape", "(", "Nprime", ",", "C", ")", "\n", "# flatten indices", "\n", "geom_feats", "=", "(", "(", "geom_feats", "-", "(", "self", ".", "bx", "-", "self", ".", "dx", "/", "2.", ")", ")", "/", "self", ".", "dx", ")", ".", "long", "(", ")", "\n", "geom_feats", "=", "geom_feats", ".", "view", "(", "Nprime", ",", "3", ")", "\n", "batch_ix", "=", "torch", ".", "cat", "(", "[", "torch", ".", "full", "(", "[", "Nprime", "//", "B", ",", "1", "]", ",", "ix", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "for", "ix", "in", "range", "(", "B", ")", "]", ")", "\n", "geom_feats", "=", "torch", ".", "cat", "(", "(", "geom_feats", ",", "batch_ix", ")", ",", "1", ")", "\n", "\n", "# filter out points that are outside box", "\n", "kept", "=", "(", "geom_feats", "[", ":", ",", "0", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "0", "]", "<", "nx", "[", "0", "]", ")", "&", "(", "geom_feats", "[", ":", ",", "1", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "1", "]", "<", "nx", "[", "1", "]", ")", "&", "(", "geom_feats", "[", ":", ",", "2", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "2", "]", "<", "nx", "[", "2", "]", ")", "\n", "x", "=", "x", "[", "kept", "]", "\n", "geom_feats", "=", "geom_feats", "[", "kept", "]", "\n", "\n", "# get tensors from the same voxel next to each other", "\n", "ranks", "=", "geom_feats", "[", ":", ",", "0", "]", "*", "(", "nx", "[", "1", "]", "*", "nx", "[", "2", "]", "*", "B", ")", "+", "geom_feats", "[", ":", ",", "1", "]", "*", "(", "nx", "[", "2", "]", "*", "B", ")", "+", "geom_feats", "[", ":", ",", "2", "]", "*", "B", "+", "geom_feats", "[", ":", ",", "3", "]", "\n", "sorts", "=", "ranks", ".", "argsort", "(", ")", "\n", "x", ",", "geom_feats", ",", "ranks", "=", "x", "[", "sorts", "]", ",", "geom_feats", "[", "sorts", "]", ",", "ranks", "[", "sorts", "]", "\n", "\n", "# cumsum trick", "\n", "if", "not", "self", ".", "use_quickcumsum", ":", "\n", "            ", "x", ",", "geom_feats", "=", "cumsum_trick", "(", "x", ",", "geom_feats", ",", "ranks", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "geom_feats", "=", "QuickCumsum", ".", "apply", "(", "x", ",", "geom_feats", ",", "ranks", ")", "\n", "\n", "# griddify (B x C x Z x X x Y)", "\n", "", "final", "=", "torch", ".", "zeros", "(", "(", "B", ",", "C", ",", "nx", "[", "1", "]", ",", "nx", "[", "2", "]", ",", "nx", "[", "0", "]", ")", ",", "device", "=", "x", ".", "device", ")", "\n", "final", "[", "geom_feats", "[", ":", ",", "3", "]", ",", ":", ",", "geom_feats", "[", ":", ",", "1", "]", ",", "geom_feats", "[", ":", ",", "2", "]", ",", "geom_feats", "[", ":", ",", "0", "]", "]", "=", "x", "\n", "\n", "# collapse Z", "\n", "final", "=", "torch", ".", "cat", "(", "final", ".", "unbind", "(", "dim", "=", "2", ")", ",", "1", ")", "\n", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.TransformerLiftSplatShoot.get_depth_dist": [[141, 143], ["x.softmax"], "methods", ["None"], ["", "def", "get_depth_dist", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.TransformerLiftSplatShoot.forward": [[144, 161], ["lift_splat_shoot_transformer.TransformerLiftSplatShoot.get_geometry", "lift_splat_shoot_transformer.TransformerLiftSplatShoot.depthnet", "lift_splat_shoot_transformer.TransformerLiftSplatShoot.get_depth_dist", "new_feature.view", "feature.permute.permute.permute", "lift_splat_shoot_transformer.TransformerLiftSplatShoot.voxel_pooling", "lift_splat_shoot_transformer.TransformerLiftSplatShoot.unsqueeze", "feature[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_geometry", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_depth_dist", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.voxel_pooling"], ["", "def", "forward", "(", "self", ",", "feature_maps", ",", "intrinstics", ")", ":", "\n", "# feature_maps[3].shape: bs,768,19,25", "\n", "        ", "geom", "=", "self", ".", "get_geometry", "(", "intrinstics", ")", "#geom.shape: bs,1,49,18,25,3", "\n", "b", ",", "_", ",", "_", ",", "h", ",", "w", ",", "_", "=", "geom", ".", "shape", "\n", "if", "self", ".", "downsample", "==", "32", ":", "\n", "            ", "feature", "=", "feature_maps", "[", "3", "]", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "# feature.shape:bs,768,18,25", "\n", "", "elif", "self", ".", "downsample", "==", "16", ":", "\n", "            ", "feature", "=", "feature_maps", "[", "0", "]", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "", "feature", "=", "self", ".", "depthnet", "(", "feature", ")", "# feature.shape:bs,113,18,25", "\n", "depth", "=", "self", ".", "get_depth_dist", "(", "feature", "[", ":", ",", ":", "self", ".", "D", "]", ")", "# depth.shape: bs,49,18,25", "\n", "new_feature", "=", "depth", ".", "unsqueeze", "(", "1", ")", "*", "feature", "[", ":", ",", "self", ".", "D", ":", "(", "self", ".", "D", "+", "self", ".", "C", ")", "]", ".", "unsqueeze", "(", "2", ")", "# new_feature.shape: bs,64,49,18,25", "\n", "feature", "=", "new_feature", ".", "view", "(", "b", ",", "1", ",", "self", ".", "C", ",", "self", ".", "D", ",", "h", ",", "w", ")", "# feature.shape: bs,1,64,49,18,25", "\n", "feature", "=", "feature", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "5", ",", "2", ")", "# feature.shape: bs,1,49,18,25,64", "\n", "# self.voxel_pooling(geom, feature).shape: bs,64,98,100", "\n", "return", "self", ".", "voxel_pooling", "(", "geom", ",", "feature", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.gen_dx_bx": [[7, 12], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["def", "gen_dx_bx", "(", "xbound", ",", "ybound", ",", "zbound", ")", ":", "\n", "    ", "dx", "=", "torch", ".", "Tensor", "(", "[", "row", "[", "2", "]", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "bx", "=", "torch", ".", "Tensor", "(", "[", "row", "[", "0", "]", "+", "row", "[", "2", "]", "/", "2.0", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "nx", "=", "torch", ".", "Tensor", "(", "[", "(", "row", "[", "1", "]", "-", "row", "[", "0", "]", ")", "/", "row", "[", "2", "]", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "return", "dx", ",", "bx", ",", "nx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lift_splat_shoot_transformer.cumsum_trick": [[13, 20], ["torch.cat.cumsum", "torch.ones", "torch.ones", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "cumsum_trick", "(", "x", ",", "geom_feats", ",", "ranks", ")", ":", "\n", "    ", "x", "=", "x", ".", "cumsum", "(", "0", ")", "\n", "kept", "=", "torch", ".", "ones", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "kept", "[", ":", "-", "1", "]", "=", "(", "ranks", "[", "1", ":", "]", "!=", "ranks", "[", ":", "-", "1", "]", ")", "\n", "x", ",", "geom_feats", "=", "x", "[", "kept", "]", ",", "geom_feats", "[", "kept", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", ":", "1", "]", ",", "x", "[", "1", ":", "]", "-", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "return", "x", ",", "geom_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Resampler.__init__": [[23, 33], ["torch.Module.__init__", "pyva_combine_transformer._make_grid"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck._make_grid"], ["    ", "def", "__init__", "(", "self", ",", "resolution", ",", "extents", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Store z positions of the near and far planes", "\n", "# extents[1]:zmin,extents[3]:zmax", "\n", "self", ".", "near", "=", "extents", "[", "1", "]", "\n", "self", ".", "far", "=", "extents", "[", "3", "]", "\n", "\n", "# Make a grid in the x-z plane", "\n", "self", ".", "grid", "=", "_make_grid", "(", "resolution", ",", "extents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Resampler.forward": [[34, 56], ["pyva_combine_transformer.Resampler.grid.to", "[].view", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pyva_combine_transformer.Resampler.grid.unsqueeze", "features.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "calib", ")", ":", "\n", "# Copy grid to the correct device", "\n", "        ", "self", ".", "grid", "=", "self", ".", "grid", ".", "to", "(", "features", ")", "\n", "\n", "# We ignore the image v-coordinate, and assume the world Y-coordinate", "\n", "# is zero, so we only need a 2x2 submatrix of the original 3x3 matrix", "\n", "# calib shape:[bs,3,3]-->[bs,2,3]-->[bs,2,2]-->[bs,1,1,2,2]", "\n", "calib", "=", "calib", "[", ":", ",", "[", "0", ",", "2", "]", "]", "[", "...", ",", "[", "0", ",", "2", "]", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "2", ",", "2", ")", "\n", "\n", "# Transform grid center locations into image u-coordinates", "\n", "cam_coords", "=", "torch", ".", "matmul", "(", "calib", ",", "self", ".", "grid", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# Apply perspective projection and normalize", "\n", "ucoords", "=", "cam_coords", "[", "...", ",", "0", "]", "/", "cam_coords", "[", "...", ",", "1", "]", "\n", "ucoords", "=", "ucoords", "/", "features", ".", "size", "(", "-", "1", ")", "*", "2", "-", "1", "\n", "\n", "# Normalize z coordinates", "\n", "zcoords", "=", "(", "cam_coords", "[", "...", ",", "1", "]", "-", "self", ".", "near", ")", "/", "(", "self", ".", "far", "-", "self", ".", "near", ")", "*", "2", "-", "1", "\n", "\n", "# Resample 3D feature map", "\n", "grid_coords", "=", "torch", ".", "stack", "(", "[", "ucoords", ",", "zcoords", "]", ",", "-", "1", ")", ".", "clamp", "(", "-", "1.1", ",", "1.1", ")", "\n", "return", "F", ".", "grid_sample", "(", "features", ",", "grid_coords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.DenseTransformer.__init__": [[60, 84], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyva_combine_transformer.Resampler", "math.ceil", "math.ceil", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "resolution", ",", "grid_extents", ",", "\n", "ymin", ",", "ymax", ",", "focal_length", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Initial convolution to reduce feature dimensions", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", ",", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "GroupNorm", "(", "16", ",", "channels", ")", "\n", "\n", "# Resampler transforms perspective features to BEV", "\n", "self", ".", "resampler", "=", "Resampler", "(", "resolution", ",", "grid_extents", ")", "\n", "\n", "# Compute input height based on region of image covered by grid", "\n", "self", ".", "zmin", ",", "zmax", "=", "grid_extents", "[", "1", "]", ",", "grid_extents", "[", "3", "]", "\n", "self", ".", "in_height", "=", "math", ".", "ceil", "(", "focal_length", "*", "(", "ymax", "-", "ymin", ")", "/", "self", ".", "zmin", ")", "\n", "self", ".", "ymid", "=", "(", "ymin", "+", "ymax", ")", "/", "2", "\n", "\n", "# Compute number of output cells required", "\n", "self", ".", "out_depth", "=", "math", ".", "ceil", "(", "(", "zmax", "-", "self", ".", "zmin", ")", "/", "resolution", ")", "\n", "\n", "# Dense layer which maps UV features to UZ", "\n", "self", ".", "fc", "=", "nn", ".", "Conv1d", "(", "\n", "channels", "*", "self", ".", "in_height", ",", "channels", "*", "self", ".", "out_depth", ",", "1", ",", "groups", "=", "groups", "\n", ")", "\n", "self", ".", "out_channels", "=", "channels", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.DenseTransformer.forward": [[85, 100], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu", "torch.relu", "torch.relu", "torch.relu.flatten", "pyva_combine_transformer.DenseTransformer.fc().view", "pyva_combine_transformer.DenseTransformer.resampler", "pyva_combine_transformer.DenseTransformer.bn", "pyva_combine_transformer.DenseTransformer._crop_feature_map", "pyva_combine_transformer.DenseTransformer.conv", "pyva_combine_transformer.DenseTransformer.fc", "zip"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.DenseTransformer._crop_feature_map"], ["", "def", "forward", "(", "self", ",", "features", ",", "calib", ",", "*", "args", ")", ":", "\n", "# Crop feature maps to a fixed input height", "\n", "        ", "features", "=", "torch", ".", "stack", "(", "[", "self", ".", "_crop_feature_map", "(", "fmap", ",", "cal", ")", "\n", "for", "fmap", ",", "cal", "in", "zip", "(", "features", ",", "calib", ")", "]", ")", "\n", "\n", "# Reduce feature dimension to minimize memory usage", "\n", "features", "=", "F", ".", "relu", "(", "self", ".", "bn", "(", "self", ".", "conv", "(", "features", ")", ")", ")", "\n", "\n", "# Flatten height and channel dimensions", "\n", "B", ",", "C", ",", "_", ",", "W", "=", "features", ".", "shape", "\n", "flat_feats", "=", "features", ".", "flatten", "(", "1", ",", "2", ")", "\n", "bev_feats", "=", "self", ".", "fc", "(", "flat_feats", ")", ".", "view", "(", "B", ",", "C", ",", "-", "1", ",", "W", ")", "\n", "\n", "# Resample to orthographic grid", "\n", "return", "self", ".", "resampler", "(", "bev_feats", ",", "calib", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.DenseTransformer._crop_feature_map": [[101, 110], ["math.floor", "math.floor", "torch.pad", "torch.pad", "torch.pad"], "methods", ["None"], ["", "def", "_crop_feature_map", "(", "self", ",", "fmap", ",", "calib", ")", ":", "\n", "# Compute upper and lower bounds of visible region", "\n", "        ", "focal_length", ",", "img_offset", "=", "calib", "[", "1", ",", "1", ":", "]", "\n", "vmid", "=", "self", ".", "ymid", "*", "focal_length", "/", "self", ".", "zmin", "+", "img_offset", "\n", "vmin", "=", "math", ".", "floor", "(", "vmid", "-", "self", ".", "in_height", "/", "2", ")", "\n", "vmax", "=", "math", ".", "floor", "(", "vmid", "+", "self", ".", "in_height", "/", "2", ")", "\n", "\n", "# Pad or crop input tensor to match dimensions", "\n", "return", "F", ".", "pad", "(", "fmap", ",", "[", "0", ",", "0", ",", "-", "vmin", ",", "vmax", "-", "fmap", ".", "shape", "[", "-", "2", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.CrossViewTransformer.__init__": [[120, 127], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "128", ")", ":", "\n", "        ", "super", "(", "CrossViewTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "query_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "f_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", "*", "2", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.CrossViewTransformer.forward": [[128, 149], ["front_x.size", "pyva_combine_transformer.CrossViewTransformer.query_conv().view", "pyva_combine_transformer.CrossViewTransformer.key_conv().view().permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pyva_combine_transformer.CrossViewTransformer.value_conv().view", "feature_selection().view", "front_star.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pyva_combine_transformer.CrossViewTransformer.f_conv", "front_star.size", "front_star.size", "pyva_combine_transformer.CrossViewTransformer.query_conv", "pyva_combine_transformer.CrossViewTransformer.key_conv().view", "pyva_combine_transformer.CrossViewTransformer.value_conv", "pyva_combine_transformer.feature_selection", "pyva_combine_transformer.CrossViewTransformer.key_conv"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.feature_selection"], ["", "def", "forward", "(", "self", ",", "front_x", ",", "cross_x", ",", "front_x_hat", ")", ":", "\n", "        ", "m_batchsize", ",", "C", ",", "width", ",", "height", "=", "front_x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "cross_x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B x C x (N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "front_x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B x C x (W*H)", "\n", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_key", ",", "proj_query", ")", "# transpose check", "\n", "front_star", ",", "front_star_arg", "=", "torch", ".", "max", "(", "energy", ",", "dim", "=", "1", ")", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "front_x_hat", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B x C x N", "\n", "\n", "T", "=", "feature_selection", "(", "proj_value", ",", "2", ",", "front_star_arg", ")", ".", "view", "(", "front_star", ".", "size", "(", "0", ")", ",", "-", "1", ",", "width", ",", "height", ")", "\n", "\n", "S", "=", "front_star", ".", "view", "(", "front_star", ".", "size", "(", "0", ")", ",", "1", ",", "width", ",", "height", ")", "\n", "# according to github issue,front_x should be cross_x, https://github.com/JonDoe-297/cross-view/issues/4", "\n", "front_res", "=", "torch", ".", "cat", "(", "(", "cross_x", ",", "T", ")", ",", "dim", "=", "1", ")", "\n", "front_res", "=", "self", ".", "f_conv", "(", "front_res", ")", "\n", "front_res", "=", "front_res", "*", "S", "\n", "# according to github issue,front_x should be cross_x, https://github.com/JonDoe-297/cross-view/issues/4", "\n", "# output = front_x + front_res", "\n", "output", "=", "cross_x", "+", "front_res", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Conv3x3.__init__": [[154, 162], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "use_refl", "=", "True", ")", ":", "\n", "        ", "super", "(", "Conv3x3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "use_refl", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ReflectionPad2d", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ZeroPad2d", "(", "1", ")", "\n", "", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "int", "(", "in_channels", ")", ",", "int", "(", "out_channels", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Conv3x3.forward": [[163, 167], ["pyva_combine_transformer.Conv3x3.pad", "pyva_combine_transformer.Conv3x3.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "pad", "(", "x", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.CycledViewProjection.__init__": [[169, 173], ["torch.Module.__init__", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.TransformModule"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "8", ")", ":", "\n", "        ", "super", "(", "CycledViewProjection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform_module", "=", "TransformModule", "(", "dim", "=", "in_dim", ")", "\n", "self", ".", "retransform_module", "=", "TransformModule", "(", "dim", "=", "in_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.CycledViewProjection.forward": [[174, 180], ["x.view().size", "pyva_combine_transformer.CycledViewProjection.transform_module", "pyva_combine_transformer.CycledViewProjection.view", "pyva_combine_transformer.CycledViewProjection.retransform_module", "x.view", "list", "int", "list", "x.size", "int", "x.size", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "view", "(", "[", "-", "1", ",", "int", "(", "x", ".", "size", "(", ")", "[", "1", "]", ")", "]", "+", "list", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", ".", "size", "(", ")", "\n", "transform_feature", "=", "self", ".", "transform_module", "(", "x", ")", "\n", "transform_features", "=", "transform_feature", ".", "view", "(", "[", "B", ",", "int", "(", "x", ".", "size", "(", ")", "[", "1", "]", ")", "]", "+", "list", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", "\n", "retransform_features", "=", "self", ".", "retransform_module", "(", "transform_features", ")", "\n", "return", "transform_feature", ",", "retransform_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.TransformModule.__init__": [[182, 191], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "8", ")", ":", "\n", "        ", "super", "(", "TransformModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "mat_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "fc_transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.TransformModule.forward": [[192, 199], ["x.view.view.view", "pyva_combine_transformer.TransformModule.fc_transform", "view_comb.view.view.view", "list", "list", "x.view.view.size", "view_comb.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# shape x: B, C, H, W", "\n", "# x = self.bn(x)", "\n", "        ", "x", "=", "x", ".", "view", "(", "list", "(", "x", ".", "size", "(", ")", "[", ":", "2", "]", ")", "+", "[", "self", ".", "dim", "*", "self", ".", "dim", "]", ")", "\n", "view_comb", "=", "self", ".", "fc_transform", "(", "x", ")", "\n", "view_comb", "=", "view_comb", ".", "view", "(", "list", "(", "view_comb", ".", "size", "(", ")", "[", ":", "2", "]", ")", "+", "[", "self", ".", "dim", ",", "self", ".", "dim", "]", ")", "\n", "return", "view_comb", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pyva_combine_transformer.__init__": [[202, 242], ["mmcv.runner.BaseModule.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "pyva_combine_transformer.Conv3x3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.CrossViewTransformer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyva_combine_transformer.Conv3x3", "functools.reduce", "min", "pyva_combine_transformer.DenseTransformer", "pyva_combine_transformer.Pyva_combine_transformer.transformers.append", "pyva_combine_transformer.Conv3x3", "pyva_combine_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "pow", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "back", "=", "'swin'", ",", "in_channels", "=", "256", ",", "channels", "=", "64", ",", "resolution", "=", "0.25", "*", "reduce", "(", "mul", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "extents", "=", "[", "-", "25.0", ",", "1.0", ",", "25.0", ",", "50.0", "]", ",", "ymin", "=", "-", "2", ",", "ymax", "=", "4", ",", "focal_length", "=", "630.0", ")", ":", "\n", "        ", "super", "(", "Pyva_combine_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "back", "=", "back", "\n", "# pyramid transformer", "\n", "self", ".", "transformers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# Scaled focal length for each transformer", "\n", "            ", "focal", "=", "focal_length", "/", "pow", "(", "2", ",", "i", "+", "3", ")", "\n", "\n", "# Compute grid bounds for each transformer", "\n", "zmax", "=", "min", "(", "math", ".", "floor", "(", "focal", "*", "2", ")", "*", "resolution", ",", "extents", "[", "3", "]", ")", "\n", "zmin", "=", "math", ".", "floor", "(", "focal", ")", "*", "resolution", "if", "i", "<", "4", "else", "extents", "[", "1", "]", "\n", "subset_extents", "=", "[", "extents", "[", "0", "]", ",", "zmin", ",", "extents", "[", "2", "]", ",", "zmax", "]", "\n", "# Build transformers", "\n", "tfm", "=", "DenseTransformer", "(", "in_channels", ",", "channels", ",", "resolution", ",", "\n", "subset_extents", ",", "ymin", ",", "ymax", ",", "focal", ")", "\n", "self", ".", "transformers", ".", "append", "(", "tfm", ")", "\n", "\n", "", "if", "self", ".", "back", "==", "'res50'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "2048", ",", "512", ")", "\n", "", "if", "self", ".", "back", "==", "'swin'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "256", ",", "512", ")", "\n", "", "self", ".", "conv2", "=", "Conv3x3", "(", "512", ",", "128", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "transform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "retransform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "crossview", "=", "CrossViewTransformer", "(", "in_dim", "=", "128", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv5", "=", "Conv3x3", "(", "64", ",", "64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pyva_combine_transformer.forward": [[243, 287], ["pyva_combine_transformer.Pyva_combine_transformer.conv1", "pyva_combine_transformer.Pyva_combine_transformer.pool", "pyva_combine_transformer.Pyva_combine_transformer.conv2", "pyva_combine_transformer.Pyva_combine_transformer.pool", "pyva_combine_transformer.Pyva_combine_transformer.transform_feature", "pyva_combine_transformer.Pyva_combine_transformer.retransform_feature", "pyva_combine_transformer.Pyva_combine_transformer.crossview", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_transformer.conv3", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_transformer.conv4", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_transformer.conv5", "pyva_combine_transformer.Pyva_combine_transformer.view", "pyva_combine_transformer.Pyva_combine_transformer.view", "pyva_combine_transformer.Pyva_combine_transformer.view", "calib.clone", "torch.cat.append", "torch.cat.append", "torch.cat.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n", "        ", "feature_maps", "=", "x", "\n", "x", "=", "x", "[", "2", "]", "# bs,256,32,32", "\n", "# if we use swin as backbone, x.shape = [bs,256,32,32]", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "# bs,512, 32, 32", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,512, 16, 16", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "# bs,128, 16, 16", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,128, 8, 8", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "transform_feature", "=", "self", ".", "transform_feature", "(", "x", ")", "# bs,128, 8, 8", "\n", "retransform_feature", "=", "self", ".", "retransform_feature", "(", "transform_feature", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "self", ".", "crossview", "(", "x", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "transform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "retransform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv3", "(", "feature_final", ")", "# bs,128, 16,16", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv4", "(", "feature_final", ")", "# bs,64, 32, 32", "\n", "\n", "bev_feats", "=", "list", "(", ")", "\n", "# scale = 8,16,32,64,128", "\n", "# calib.shape = [bs,3,3]", "\n", "for", "i", ",", "fmap", "in", "enumerate", "(", "feature_maps", ")", ":", "\n", "# Scale calibration matrix to account for downsampling", "\n", "            ", "scale", "=", "8", "*", "2", "**", "i", "\n", "calib_downsamp", "=", "calib", ".", "clone", "(", ")", "\n", "calib_downsamp", "[", ":", ",", ":", "2", "]", "=", "calib", "[", ":", ",", ":", "2", "]", "/", "scale", "\n", "\n", "# Apply orthographic transformation to each feature map separately", "\n", "bev_feats", ".", "append", "(", "self", ".", "transformers", "[", "i", "]", "(", "fmap", ",", "calib_downsamp", ")", ")", "\n", "\n", "", "bev_feats", "=", "torch", ".", "cat", "(", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "\n", "feature_final", ",", "\n", "size", "=", "(", "98", ",", "100", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "True", "\n", ")", "# bs,64, 98,100", "\n", "feature_final", "=", "self", ".", "conv5", "(", "feature_final", ")", "\n", "\n", "# combine learnable and unlearnable feature", "\n", "feature_final_out", "=", "feature_final", "+", "bev_feats", "\n", "return", "feature_final_out", ",", "x", ",", "retransform_feature", ",", "transform_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.__init__": [[290, 338], ["mmcv.runner.BaseModule.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "pyva_combine_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "functools.reduce", "min", "pyva_combine_transformer.DenseTransformer", "pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.transformers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "pow", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "math.floor", "math.floor", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "back", "=", "'swin'", ",", "use_light", "=", "False", ",", "in_channels", "=", "256", ",", "channels", "=", "64", ",", "resolution", "=", "0.25", "*", "reduce", "(", "mul", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "extents", "=", "[", "-", "25.0", ",", "1.0", ",", "25.0", ",", "50.0", "]", ",", "ymin", "=", "-", "2", ",", "ymax", "=", "4", ",", "focal_length", "=", "630.0", ",", "\n", "input_width", "=", "32", ",", "input_height", "=", "32", ",", "input_dim", "=", "256", ",", "output_width", "=", "100", ",", "output_height", "=", "98", ",", "output_dim", "=", "64", ")", ":", "\n", "        ", "super", "(", "Pon_combine_vpn_simple_fpn_force_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "back", "=", "back", "\n", "self", ".", "use_light", "=", "use_light", "\n", "self", ".", "depth_list", "=", "[", "7", ",", "10", ",", "20", ",", "39", ",", "22", "]", "\n", "# pyramid transformer", "\n", "self", ".", "transformers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# Scaled focal length for each transformer", "\n", "            ", "focal", "=", "focal_length", "/", "pow", "(", "2", ",", "i", "+", "3", ")", "\n", "# Compute grid bounds for each transformer", "\n", "zmax", "=", "min", "(", "math", ".", "floor", "(", "focal", "*", "2", ")", "*", "resolution", ",", "extents", "[", "3", "]", ")", "\n", "zmin", "=", "math", ".", "floor", "(", "focal", ")", "*", "resolution", "if", "i", "<", "4", "else", "extents", "[", "1", "]", "\n", "subset_extents", "=", "[", "extents", "[", "0", "]", ",", "zmin", ",", "extents", "[", "2", "]", ",", "zmax", "]", "\n", "# Build transformers", "\n", "tfm", "=", "DenseTransformer", "(", "in_channels", ",", "channels", ",", "resolution", ",", "\n", "subset_extents", ",", "ymin", ",", "ymax", ",", "focal", ")", "\n", "self", ".", "transformers", ".", "append", "(", "tfm", ")", "\n", "\n", "", "self", ".", "conv5", "=", "Conv3x3", "(", "64", ",", "64", ")", "\n", "self", ".", "conv_down_1", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv_down_2", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "\n", "# vpn init part", "\n", "self", ".", "input_width", "=", "input_width", "\n", "self", ".", "input_height", "=", "input_height", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_width", "=", "output_width", "\n", "self", ".", "output_height", "=", "output_height", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "if", "self", ".", "use_light", ":", "\n", "            ", "self", ".", "tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_width", "*", "self", ".", "input_height", ",", "int", "(", "0.05", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "int", "(", "0.05", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_width", "*", "self", ".", "input_height", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "output_width", "*", "self", ".", "output_height", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "self", ".", "input_dim", ",", "self", ".", "output_dim", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.forward": [[339, 382], ["x.view.view.view", "pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.tf", "x.view.view.view", "pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.conv", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.conv5", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.conv_down_1", "pyva_combine_transformer.Pon_combine_vpn_simple_fpn_force_transformer.conv_down_2", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "calib.clone", "list.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n", "        ", "feature_maps", "=", "x", "\n", "x_0", ",", "x_1", ",", "x_2", ",", "x_3", ",", "x_4", "=", "x", "\n", "x_1", "=", "x_1", "+", "self", ".", "conv_down_1", "(", "x_0", ")", "\n", "x_2", "=", "x_2", "+", "self", ".", "conv_down_2", "(", "x_1", ")", "\n", "x_3", "=", "x_3", "+", "F", ".", "interpolate", "(", "x_4", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "x_2", "=", "x_2", "+", "F", ".", "interpolate", "(", "x_3", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "x", "=", "x_2", "# bs,256,32,32", "\n", "\n", "# learnable part", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "n", ",", "c", ",", "h", "*", "w", ")", "\n", "x", "=", "self", ".", "tf", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "n", ",", "c", ",", "self", ".", "output_height", ",", "self", ".", "output_width", ")", "\n", "feature_final", "=", "self", ".", "conv", "(", "x", ")", "\n", "\n", "feature_final_1", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "0", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_2", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "1", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_3", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "2", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_4", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "3", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_5", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "4", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_list", "=", "[", "feature_final_1", ",", "feature_final_2", ",", "feature_final_3", ",", "feature_final_4", ",", "feature_final_5", "]", "\n", "feature_final", "=", "torch", ".", "cat", "(", "feature_final_list", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "feature_final", "=", "self", ".", "conv5", "(", "feature_final", ")", "\n", "\n", "# unlearnable part", "\n", "bev_feats", "=", "list", "(", ")", "\n", "# scale = 8,16,32,64,128", "\n", "# calib.shape = [bs,3,3]", "\n", "for", "i", ",", "fmap", "in", "enumerate", "(", "feature_maps", ")", ":", "\n", "# Scale calibration matrix to account for downsampling", "\n", "            ", "scale", "=", "8", "*", "2", "**", "i", "\n", "calib_downsamp", "=", "calib", ".", "clone", "(", ")", "\n", "calib_downsamp", "[", ":", ",", ":", "2", "]", "=", "calib", "[", ":", ",", ":", "2", "]", "/", "scale", "\n", "\n", "# Apply orthographic transformation to each feature map separately", "\n", "bev_feats", ".", "append", "(", "self", ".", "transformers", "[", "i", "]", "(", "fmap", ",", "calib_downsamp", ")", ")", "\n", "\n", "", "bev_feats_out", "=", "torch", ".", "cat", "(", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "\n", "# combine learnable and unlearnable feature", "\n", "feature_final_out", "=", "feature_final", "+", "bev_feats_out", "\n", "return", "feature_final_out", ",", "bev_feats_out", ",", "feature_final", ",", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "feature_final_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pyva_combine_simple_force_transformer.__init__": [[385, 428], ["mmcv.runner.BaseModule.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "pyva_combine_transformer.Conv3x3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.CrossViewTransformer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyva_combine_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "functools.reduce", "min", "pyva_combine_transformer.DenseTransformer", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.transformers.append", "pyva_combine_transformer.Conv3x3", "pyva_combine_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "pow", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "back", "=", "'swin'", ",", "in_channels", "=", "256", ",", "channels", "=", "64", ",", "resolution", "=", "0.25", "*", "reduce", "(", "mul", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "extents", "=", "[", "-", "25.0", ",", "1.0", ",", "25.0", ",", "50.0", "]", ",", "ymin", "=", "-", "2", ",", "ymax", "=", "4", ",", "focal_length", "=", "630.0", ")", ":", "\n", "        ", "super", "(", "Pyva_combine_simple_force_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "back", "=", "back", "\n", "# pyramid transformer", "\n", "self", ".", "transformers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# Scaled focal length for each transformer", "\n", "            ", "focal", "=", "focal_length", "/", "pow", "(", "2", ",", "i", "+", "3", ")", "\n", "\n", "# Compute grid bounds for each transformer", "\n", "zmax", "=", "min", "(", "math", ".", "floor", "(", "focal", "*", "2", ")", "*", "resolution", ",", "extents", "[", "3", "]", ")", "\n", "zmin", "=", "math", ".", "floor", "(", "focal", ")", "*", "resolution", "if", "i", "<", "4", "else", "extents", "[", "1", "]", "\n", "subset_extents", "=", "[", "extents", "[", "0", "]", ",", "zmin", ",", "extents", "[", "2", "]", ",", "zmax", "]", "\n", "# Build transformers", "\n", "tfm", "=", "DenseTransformer", "(", "in_channels", ",", "channels", ",", "resolution", ",", "\n", "subset_extents", ",", "ymin", ",", "ymax", ",", "focal", ")", "\n", "self", ".", "transformers", ".", "append", "(", "tfm", ")", "\n", "\n", "", "if", "self", ".", "back", "==", "'res50'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "2048", ",", "512", ")", "\n", "", "if", "self", ".", "back", "==", "'swin'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "256", ",", "512", ")", "\n", "", "self", ".", "conv2", "=", "Conv3x3", "(", "512", ",", "128", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "transform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "retransform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "crossview", "=", "CrossViewTransformer", "(", "in_dim", "=", "128", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv5", "=", "Conv3x3", "(", "64", ",", "64", ")", "\n", "self", ".", "conv_down_1", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv_down_2", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pyva_combine_simple_force_transformer.forward": [[428, 479], ["pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv1", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.pool", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv2", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.pool", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.transform_feature", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.retransform_feature", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.crossview", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv3", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv4", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv5", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv_down_1", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.conv_down_2", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.view", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.view", "pyva_combine_transformer.Pyva_combine_simple_force_transformer.view", "calib.clone", "list.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n", "        ", "feature_maps", "=", "x", "\n", "# x[0].shape: bs,256,128,128   x[1].shape: bs,256,64,64", "\n", "# x[2].shape: bs,256,32,32     x[3].shape: bs,256,16,16", "\n", "x_0", ",", "x_1", ",", "x_2", ",", "x_3", ",", "x_4", "=", "x", "\n", "x_1", "=", "x_1", "+", "self", ".", "conv_down_1", "(", "x_0", ")", "\n", "x_2", "=", "x_2", "+", "self", ".", "conv_down_2", "(", "x_1", ")", "\n", "x_3", "=", "x_3", "+", "F", ".", "interpolate", "(", "x_4", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "x_2", "=", "x_2", "+", "F", ".", "interpolate", "(", "x_3", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "x", "=", "x_2", "# bs,256,32,32", "\n", "# if we use swin as backbone, x.shape = [bs,256,32,32]", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "# bs,512, 32, 32", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,512, 16, 16", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "# bs,128, 16, 16", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,128, 8, 8", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "transform_feature", "=", "self", ".", "transform_feature", "(", "x", ")", "# bs,128, 8, 8", "\n", "retransform_feature", "=", "self", ".", "retransform_feature", "(", "transform_feature", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "self", ".", "crossview", "(", "x", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "transform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "retransform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv3", "(", "feature_final", ")", "# bs,128, 16,16", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv4", "(", "feature_final", ")", "# bs,64, 32, 32", "\n", "\n", "bev_feats", "=", "list", "(", ")", "\n", "# scale = 8,16,32,64,128", "\n", "# calib.shape = [bs,3,3]", "\n", "for", "i", ",", "fmap", "in", "enumerate", "(", "feature_maps", ")", ":", "\n", "# Scale calibration matrix to account for downsampling", "\n", "            ", "scale", "=", "8", "*", "2", "**", "i", "\n", "calib_downsamp", "=", "calib", ".", "clone", "(", ")", "\n", "calib_downsamp", "[", ":", ",", ":", "2", "]", "=", "calib", "[", ":", ",", ":", "2", "]", "/", "scale", "\n", "\n", "# Apply orthographic transformation to each feature map separately", "\n", "bev_feats", ".", "append", "(", "self", ".", "transformers", "[", "i", "]", "(", "fmap", ",", "calib_downsamp", ")", ")", "\n", "\n", "", "bev_feats_out", "=", "torch", ".", "cat", "(", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "\n", "feature_final", ",", "\n", "size", "=", "(", "98", ",", "100", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "True", "\n", ")", "# bs,64, 98,100", "\n", "feature_final", "=", "self", ".", "conv5", "(", "feature_final", ")", "\n", "feature_final_list", "=", "[", "feature_final", "[", ":", ",", ":", ",", ":", "7", ",", ":", "]", ",", "feature_final", "[", ":", ",", ":", ",", "7", ":", "17", ",", ":", "]", ",", "feature_final", "[", ":", ",", ":", ",", "17", ":", "37", ",", ":", "]", ",", "feature_final", "[", ":", ",", ":", ",", "37", ":", "76", ",", ":", "]", ",", "feature_final", "[", ":", ",", ":", ",", "76", ":", ",", ":", "]", "]", "\n", "# combine learnable and unlearnable feature", "\n", "feature_final_out", "=", "feature_final", "+", "bev_feats_out", "\n", "return", "feature_final_out", ",", "retransform_feature", ",", "transform_feature", ",", "bev_feats_out", ",", "feature_final", ",", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "feature_final_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.__init__": [[482, 524], ["mmcv.runner.BaseModule.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "pyva_combine_transformer.Conv3x3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.TransformModule", "pyva_combine_transformer.CrossViewTransformer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyva_combine_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "functools.reduce", "min", "pyva_combine_transformer.DenseTransformer", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.transformers.append", "pyva_combine_transformer.Conv3x3", "pyva_combine_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "pow", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "back", "=", "'swin'", ",", "in_channels", "=", "256", ",", "channels", "=", "64", ",", "resolution", "=", "0.25", "*", "reduce", "(", "mul", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "extents", "=", "[", "-", "25.0", ",", "1.0", ",", "25.0", ",", "50.0", "]", ",", "ymin", "=", "-", "2", ",", "ymax", "=", "4", ",", "focal_length", "=", "630.0", ")", ":", "\n", "        ", "super", "(", "Pyva_combine_simple_fpn_force_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "back", "=", "back", "\n", "self", ".", "depth_list", "=", "[", "7", ",", "10", ",", "20", ",", "39", ",", "22", "]", "\n", "# pyramid transformer", "\n", "self", ".", "transformers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# Scaled focal length for each transformer", "\n", "            ", "focal", "=", "focal_length", "/", "pow", "(", "2", ",", "i", "+", "3", ")", "\n", "# Compute grid bounds for each transformer", "\n", "zmax", "=", "min", "(", "math", ".", "floor", "(", "focal", "*", "2", ")", "*", "resolution", ",", "extents", "[", "3", "]", ")", "\n", "zmin", "=", "math", ".", "floor", "(", "focal", ")", "*", "resolution", "if", "i", "<", "4", "else", "extents", "[", "1", "]", "\n", "subset_extents", "=", "[", "extents", "[", "0", "]", ",", "zmin", ",", "extents", "[", "2", "]", ",", "zmax", "]", "\n", "# Build transformers", "\n", "tfm", "=", "DenseTransformer", "(", "in_channels", ",", "channels", ",", "resolution", ",", "\n", "subset_extents", ",", "ymin", ",", "ymax", ",", "focal", ")", "\n", "self", ".", "transformers", ".", "append", "(", "tfm", ")", "\n", "\n", "", "if", "self", ".", "back", "==", "'res50'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "2048", ",", "512", ")", "\n", "", "if", "self", ".", "back", "==", "'swin'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "256", ",", "512", ")", "\n", "", "self", ".", "conv2", "=", "Conv3x3", "(", "512", ",", "128", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "transform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "retransform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "crossview", "=", "CrossViewTransformer", "(", "in_dim", "=", "128", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv5", "=", "Conv3x3", "(", "64", ",", "64", ")", "\n", "self", ".", "conv_down_1", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv_down_2", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.forward": [[524, 576], ["pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv1", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.pool", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv2", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.pool", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.transform_feature", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.retransform_feature", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.crossview", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv3", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv4", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv5", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv_down_1", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.conv_down_2", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.view", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.view", "pyva_combine_transformer.Pyva_combine_simple_fpn_force_transformer.view", "calib.clone", "list.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n", "        ", "feature_maps", "=", "x", "\n", "x_0", ",", "x_1", ",", "x_2", ",", "x_3", ",", "x_4", "=", "x", "\n", "x_1", "=", "x_1", "+", "self", ".", "conv_down_1", "(", "x_0", ")", "\n", "x_2", "=", "x_2", "+", "self", ".", "conv_down_2", "(", "x_1", ")", "\n", "x_3", "=", "x_3", "+", "F", ".", "interpolate", "(", "x_4", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "x_2", "=", "x_2", "+", "F", ".", "interpolate", "(", "x_3", ",", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "x", "=", "x_2", "# bs,256,32,32", "\n", "# if we use swin as backbone, x.shape = [bs,256,32,32]", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "# bs,512, 32, 32", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,512, 16, 16", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "# bs,128, 16, 16", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,128, 8, 8", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "transform_feature", "=", "self", ".", "transform_feature", "(", "x", ")", "# bs,128, 8, 8", "\n", "retransform_feature", "=", "self", ".", "retransform_feature", "(", "transform_feature", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "self", ".", "crossview", "(", "x", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "transform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "retransform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv3", "(", "feature_final", ")", "# bs,128, 16,16", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv4", "(", "feature_final", ")", "# bs,64, 32, 32", "\n", "\n", "feature_final_1", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "0", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_2", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "1", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_3", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "2", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_4", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "3", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_5", "=", "F", ".", "interpolate", "(", "feature_final", ",", "size", "=", "(", "self", ".", "depth_list", "[", "4", "]", ",", "100", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "# bs,64, 22,100", "\n", "feature_final_list", "=", "[", "feature_final_1", ",", "feature_final_2", ",", "feature_final_3", ",", "feature_final_4", ",", "feature_final_5", "]", "\n", "feature_final", "=", "torch", ".", "cat", "(", "feature_final_list", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "feature_final", "=", "self", ".", "conv5", "(", "feature_final", ")", "\n", "\n", "bev_feats", "=", "list", "(", ")", "\n", "# scale = 8,16,32,64,128", "\n", "# calib.shape = [bs,3,3]", "\n", "for", "i", ",", "fmap", "in", "enumerate", "(", "feature_maps", ")", ":", "\n", "# Scale calibration matrix to account for downsampling", "\n", "            ", "scale", "=", "8", "*", "2", "**", "i", "\n", "calib_downsamp", "=", "calib", ".", "clone", "(", ")", "\n", "calib_downsamp", "[", ":", ",", ":", "2", "]", "=", "calib", "[", ":", ",", ":", "2", "]", "/", "scale", "\n", "\n", "# Apply orthographic transformation to each feature map separately", "\n", "bev_feats", ".", "append", "(", "self", ".", "transformers", "[", "i", "]", "(", "fmap", ",", "calib_downsamp", ")", ")", "\n", "\n", "# Combine birds-eye-view feature maps along the depth axis", "\n", "# bev_feats.shape:[bs,64,98,100]", "\n", "", "bev_feats_out", "=", "torch", ".", "cat", "(", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "\n", "# combine learnable and unlearnable feature", "\n", "feature_final_out", "=", "feature_final", "+", "bev_feats_out", "\n", "return", "feature_final_out", ",", "retransform_feature", ",", "transform_feature", ",", "bev_feats_out", ",", "feature_final", ",", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "feature_final_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer._make_grid": [[13, 19], ["torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.stack", "torch.stack", "torch.stack", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["def", "_make_grid", "(", "resolution", ",", "extents", ")", ":", "\n", "# Create a grid of cooridinates in the birds-eye-view", "\n", "    ", "x1", ",", "z1", ",", "x2", ",", "z2", "=", "extents", "\n", "zz", ",", "xx", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "z1", ",", "z2", ",", "resolution", ")", ",", "torch", ".", "arange", "(", "x1", ",", "x2", ",", "resolution", ")", ")", "\n", "\n", "return", "torch", ".", "stack", "(", "[", "xx", ",", "zz", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_combine_transformer.feature_selection": [[111, 118], ["list", "index.view().expand.view().expand", "torch.gather", "torch.gather", "torch.gather", "input.size", "input.size", "index.view().expand.view", "range", "len", "input.size"], "function", ["None"], ["", "", "def", "feature_selection", "(", "input", ",", "dim", ",", "index", ")", ":", "\n", "    ", "views", "=", "[", "input", ".", "size", "(", "0", ")", "]", "+", "[", "1", "if", "i", "!=", "dim", "else", "-", "1", "for", "i", "in", "range", "(", "1", ",", "len", "(", "input", ".", "size", "(", ")", ")", ")", "]", "\n", "expanse", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "expanse", "[", "0", "]", "=", "-", "1", "\n", "expanse", "[", "dim", "]", "=", "-", "1", "\n", "index", "=", "index", ".", "view", "(", "views", ")", ".", "expand", "(", "expanse", ")", "\n", "return", "torch", ".", "gather", "(", "input", ",", "dim", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.linear_transformer.TransformerLinear.__init__": [[9, 38], ["mmcv.runner.BaseModule.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_light", "=", "False", ",", "use_high_res", "=", "False", ",", "input_width", "=", "25", ",", "input_height", "=", "19", ",", "input_dim", "=", "768", ",", "output_width", "=", "100", ",", "output_height", "=", "98", ",", "output_dim", "=", "64", ")", ":", "\n", "        ", "super", "(", "TransformerLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_light", "=", "use_light", "\n", "self", ".", "use_hight_res", "=", "use_high_res", "\n", "if", "not", "use_high_res", ":", "\n", "            ", "self", ".", "input_width", "=", "input_width", "\n", "self", ".", "input_height", "=", "input_height", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_width", "=", "32", "\n", "self", ".", "input_height", "=", "32", "\n", "\n", "", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_width", "=", "output_width", "\n", "self", ".", "output_height", "=", "output_height", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "if", "not", "self", ".", "use_light", ":", "\n", "            ", "self", ".", "tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_width", "*", "self", ".", "input_height", ",", "int", "(", "0.2", "*", "(", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "int", "(", "0.2", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_width", "*", "self", ".", "input_height", ",", "int", "(", "0.05", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "int", "(", "0.05", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "self", ".", "input_dim", ",", "self", ".", "output_dim", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.linear_transformer.TransformerLinear.forward": [[39, 47], ["linear_transformer.TransformerLinear.view", "linear_transformer.TransformerLinear.tf", "linear_transformer.TransformerLinear.view", "linear_transformer.TransformerLinear.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "feature_maps", ",", "intrinstics", ")", ":", "\n", "        ", "feature", "=", "feature_maps", "[", "3", "]", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "feature", ".", "shape", "\n", "feature", "=", "feature", ".", "view", "(", "n", ",", "c", ",", "h", "*", "w", ")", "\n", "feature", "=", "self", ".", "tf", "(", "feature", ")", "\n", "feature", "=", "feature", ".", "view", "(", "n", ",", "c", ",", "self", ".", "output_height", ",", "self", ".", "output_width", ")", "\n", "feature", "=", "self", ".", "conv", "(", "feature", ")", "\n", "return", "feature", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.CrossViewTransformer.__init__": [[19, 26], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "128", ")", ":", "\n", "        ", "super", "(", "CrossViewTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "query_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "f_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", "*", "2", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.CrossViewTransformer.forward": [[27, 48], ["front_x.size", "pyva_transformer.CrossViewTransformer.query_conv().view", "pyva_transformer.CrossViewTransformer.key_conv().view().permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pyva_transformer.CrossViewTransformer.value_conv().view", "feature_selection().view", "front_star.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pyva_transformer.CrossViewTransformer.f_conv", "front_star.size", "front_star.size", "pyva_transformer.CrossViewTransformer.query_conv", "pyva_transformer.CrossViewTransformer.key_conv().view", "pyva_transformer.CrossViewTransformer.value_conv", "pyva_transformer.feature_selection", "pyva_transformer.CrossViewTransformer.key_conv"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.feature_selection"], ["", "def", "forward", "(", "self", ",", "front_x", ",", "cross_x", ",", "front_x_hat", ")", ":", "\n", "        ", "m_batchsize", ",", "C", ",", "width", ",", "height", "=", "front_x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "cross_x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B x C x (N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "front_x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B x C x (W*H)", "\n", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_key", ",", "proj_query", ")", "# transpose check", "\n", "front_star", ",", "front_star_arg", "=", "torch", ".", "max", "(", "energy", ",", "dim", "=", "1", ")", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "front_x_hat", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B x C x N", "\n", "\n", "T", "=", "feature_selection", "(", "proj_value", ",", "2", ",", "front_star_arg", ")", ".", "view", "(", "front_star", ".", "size", "(", "0", ")", ",", "-", "1", ",", "width", ",", "height", ")", "\n", "\n", "S", "=", "front_star", ".", "view", "(", "front_star", ".", "size", "(", "0", ")", ",", "1", ",", "width", ",", "height", ")", "\n", "# according to github issue,front_x should be cross_x, https://github.com/JonDoe-297/cross-view/issues/4", "\n", "front_res", "=", "torch", ".", "cat", "(", "(", "cross_x", ",", "T", ")", ",", "dim", "=", "1", ")", "\n", "front_res", "=", "self", ".", "f_conv", "(", "front_res", ")", "\n", "front_res", "=", "front_res", "*", "S", "\n", "# according to github issue,front_x should be cross_x, https://github.com/JonDoe-297/cross-view/issues/4", "\n", "# output = front_x + front_res", "\n", "output", "=", "cross_x", "+", "front_res", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.Conv3x3.__init__": [[53, 61], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "use_refl", "=", "True", ")", ":", "\n", "        ", "super", "(", "Conv3x3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "use_refl", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ReflectionPad2d", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ZeroPad2d", "(", "1", ")", "\n", "", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "int", "(", "in_channels", ")", ",", "int", "(", "out_channels", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.Conv3x3.forward": [[62, 66], ["pyva_transformer.Conv3x3.pad", "pyva_transformer.Conv3x3.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "pad", "(", "x", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.CycledViewProjection.__init__": [[68, 72], ["torch.Module.__init__", "pyva_transformer.TransformModule", "pyva_transformer.TransformModule"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "8", ")", ":", "\n", "        ", "super", "(", "CycledViewProjection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform_module", "=", "TransformModule", "(", "dim", "=", "in_dim", ")", "\n", "self", ".", "retransform_module", "=", "TransformModule", "(", "dim", "=", "in_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.CycledViewProjection.forward": [[73, 79], ["x.view().size", "pyva_transformer.CycledViewProjection.transform_module", "pyva_transformer.CycledViewProjection.view", "pyva_transformer.CycledViewProjection.retransform_module", "x.view", "list", "int", "list", "x.size", "int", "x.size", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "view", "(", "[", "-", "1", ",", "int", "(", "x", ".", "size", "(", ")", "[", "1", "]", ")", "]", "+", "list", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", ".", "size", "(", ")", "\n", "transform_feature", "=", "self", ".", "transform_module", "(", "x", ")", "\n", "transform_features", "=", "transform_feature", ".", "view", "(", "[", "B", ",", "int", "(", "x", ".", "size", "(", ")", "[", "1", "]", ")", "]", "+", "list", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", "\n", "retransform_features", "=", "self", ".", "retransform_module", "(", "transform_features", ")", "\n", "return", "transform_feature", ",", "retransform_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.TransformModule.__init__": [[82, 100], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "8", ",", "use_heavy", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "use_heavy", "=", "use_heavy", "\n", "self", ".", "mat_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "not", "self", ".", "use_heavy", ":", "\n", "            ", "self", ".", "fc_transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc_transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", "*", "784", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", "*", "784", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.TransformModule.forward": [[101, 107], ["x.view.view.view", "pyva_transformer.TransformModule.fc_transform", "view_comb.view.view.view", "list", "list", "x.view.view.size", "view_comb.view.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# shape x: B, C, H, W", "\n", "        ", "x", "=", "x", ".", "view", "(", "list", "(", "x", ".", "size", "(", ")", "[", ":", "2", "]", ")", "+", "[", "self", ".", "dim", "*", "self", ".", "dim", "]", ")", "\n", "view_comb", "=", "self", ".", "fc_transform", "(", "x", ")", "\n", "view_comb", "=", "view_comb", ".", "view", "(", "list", "(", "view_comb", ".", "size", "(", ")", "[", ":", "2", "]", ")", "+", "[", "self", ".", "dim", ",", "self", ".", "dim", "]", ")", "\n", "return", "view_comb", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.Interpo.__init__": [[109, 112], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "Interpo", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.Interpo.forward": [[113, 116], ["torch.interpolate", "torch.interpolate", "torch.interpolate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "size", "=", "self", ".", "size", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.Pyva_transformer.__init__": [[119, 150], ["torch.Module.__init__", "pyva_transformer.Conv3x3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "pyva_transformer.TransformModule", "pyva_transformer.TransformModule", "pyva_transformer.CrossViewTransformer", "pyva_transformer.Interpo", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyva_transformer.Conv3x3", "pyva_transformer.Conv3x3", "pyva_transformer.Conv3x3", "pyva_transformer.Conv3x3", "pyva_transformer.Conv3x3", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "back", "=", "'swin'", ",", "use_fpn", "=", "False", ",", "use_heavy", "=", "False", ")", ":", "\n", "        ", "super", "(", "Pyva_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "back", "=", "back", "\n", "self", ".", "use_fpn", "=", "use_fpn", "\n", "self", ".", "use_heavy", "=", "use_heavy", "\n", "if", "self", ".", "back", "==", "'res18'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "512", ",", "512", ")", "\n", "", "if", "self", ".", "back", "==", "'res18'", "and", "self", ".", "use_fpn", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "256", ",", "512", ")", "\n", "", "if", "self", ".", "back", "==", "'res50'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "2048", ",", "512", ")", "\n", "", "if", "self", ".", "back", "==", "'swin'", ":", "\n", "            ", "self", ".", "conv1", "=", "Conv3x3", "(", "768", ",", "512", ")", "\n", "", "self", ".", "conv2", "=", "Conv3x3", "(", "512", ",", "128", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "transform_feature", "=", "TransformModule", "(", "use_heavy", "=", "self", ".", "use_heavy", ",", "dim", "=", "8", ")", "\n", "self", ".", "retransform_feature", "=", "TransformModule", "(", "use_heavy", "=", "self", ".", "use_heavy", ",", "dim", "=", "8", ")", "\n", "self", ".", "crossview", "=", "CrossViewTransformer", "(", "in_dim", "=", "128", ")", "\n", "self", ".", "interpolate", "=", "Interpo", "(", "self", ".", "size", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "self", ".", "conv5", "=", "Conv3x3", "(", "64", ",", "64", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.Pyva_transformer.forward": [[151, 178], ["pyva_transformer.Pyva_transformer.interpolate", "pyva_transformer.Pyva_transformer.conv1", "pyva_transformer.Pyva_transformer.pool", "pyva_transformer.Pyva_transformer.conv2", "pyva_transformer.Pyva_transformer.pool", "pyva_transformer.Pyva_transformer.transform_feature", "pyva_transformer.Pyva_transformer.retransform_feature", "pyva_transformer.Pyva_transformer.crossview", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_transformer.Pyva_transformer.conv3", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_transformer.Pyva_transformer.conv4", "torch.interpolate", "torch.interpolate", "torch.interpolate", "pyva_transformer.Pyva_transformer.conv5", "pyva_transformer.Pyva_transformer.view", "pyva_transformer.Pyva_transformer.view", "pyva_transformer.Pyva_transformer.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n", "        ", "x", "=", "x", "[", "-", "1", "]", "# bs,2048, 38, 50", "\n", "# if we use swin as backbone, x.shape = [bs,768,32,32];if we use res18 as backbone, x.shape: [bs,512,32,32]", "\n", "x", "=", "self", ".", "interpolate", "(", "x", ")", "# bs,2048, 32, 32", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "# bs,512, 32, 32", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,512, 16, 16", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "# bs,128, 16, 16", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "# bs,128, 8, 8", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "transform_feature", "=", "self", ".", "transform_feature", "(", "x", ")", "# bs,128, 8, 8", "\n", "retransform_feature", "=", "self", ".", "retransform_feature", "(", "transform_feature", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "self", ".", "crossview", "(", "x", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "transform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "retransform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ")", "# bs,128, 8, 8", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv3", "(", "feature_final", ")", "# bs,128, 16,16", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "feature_final", ",", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", "\n", "feature_final", "=", "self", ".", "conv4", "(", "feature_final", ")", "# bs,64, 32, 32", "\n", "\n", "feature_final", "=", "F", ".", "interpolate", "(", "\n", "feature_final", ",", "\n", "size", "=", "(", "98", ",", "100", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "True", "\n", ")", "# bs,64, 98,100", "\n", "feature_final", "=", "self", ".", "conv5", "(", "feature_final", ")", "\n", "return", "feature_final", ",", "x", ",", "retransform_feature", ",", "transform_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.pyva_transformer.feature_selection": [[6, 17], ["list", "index.view().expand.view().expand", "torch.gather", "torch.gather", "torch.gather", "input.size", "input.size", "index.view().expand.view", "range", "len", "input.size"], "function", ["None"], ["def", "feature_selection", "(", "input", ",", "dim", ",", "index", ")", ":", "\n", "# feature selection", "\n", "# input: [N, ?, ?, ...]", "\n", "# dim: scalar > 0", "\n", "# index: [N, idx]", "\n", "    ", "views", "=", "[", "input", ".", "size", "(", "0", ")", "]", "+", "[", "1", "if", "i", "!=", "dim", "else", "-", "1", "for", "i", "in", "range", "(", "1", ",", "len", "(", "input", ".", "size", "(", ")", ")", ")", "]", "\n", "expanse", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "expanse", "[", "0", "]", "=", "-", "1", "\n", "expanse", "[", "dim", "]", "=", "-", "1", "\n", "index", "=", "index", ".", "view", "(", "views", ")", ".", "expand", "(", "expanse", ")", "\n", "return", "torch", ".", "gather", "(", "input", ",", "dim", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.CrossViewTransformer.__init__": [[19, 26], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "128", ")", ":", "\n", "        ", "super", "(", "CrossViewTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "query_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "key_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", "//", "8", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "value_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "f_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_dim", "*", "2", ",", "out_channels", "=", "in_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.CrossViewTransformer.forward": [[27, 48], ["front_x.size", "origin_pyva_transformer.CrossViewTransformer.query_conv().view", "origin_pyva_transformer.CrossViewTransformer.key_conv().view().permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "origin_pyva_transformer.CrossViewTransformer.value_conv().view", "feature_selection().view", "front_star.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "origin_pyva_transformer.CrossViewTransformer.f_conv", "front_star.size", "front_star.size", "origin_pyva_transformer.CrossViewTransformer.query_conv", "origin_pyva_transformer.CrossViewTransformer.key_conv().view", "origin_pyva_transformer.CrossViewTransformer.value_conv", "origin_pyva_transformer.feature_selection", "origin_pyva_transformer.CrossViewTransformer.key_conv"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.feature_selection"], ["", "def", "forward", "(", "self", ",", "front_x", ",", "cross_x", ",", "front_x_hat", ")", ":", "\n", "        ", "m_batchsize", ",", "C", ",", "width", ",", "height", "=", "front_x", ".", "size", "(", ")", "\n", "proj_query", "=", "self", ".", "query_conv", "(", "cross_x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B x C x (N)", "\n", "proj_key", "=", "self", ".", "key_conv", "(", "front_x", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# B x C x (W*H)", "\n", "\n", "energy", "=", "torch", ".", "bmm", "(", "proj_key", ",", "proj_query", ")", "# transpose check", "\n", "front_star", ",", "front_star_arg", "=", "torch", ".", "max", "(", "energy", ",", "dim", "=", "1", ")", "\n", "proj_value", "=", "self", ".", "value_conv", "(", "front_x_hat", ")", ".", "view", "(", "m_batchsize", ",", "-", "1", ",", "width", "*", "height", ")", "# B x C x N", "\n", "\n", "T", "=", "feature_selection", "(", "proj_value", ",", "2", ",", "front_star_arg", ")", ".", "view", "(", "front_star", ".", "size", "(", "0", ")", ",", "-", "1", ",", "width", ",", "height", ")", "\n", "\n", "S", "=", "front_star", ".", "view", "(", "front_star", ".", "size", "(", "0", ")", ",", "1", ",", "width", ",", "height", ")", "\n", "# according to github issue,front_x should be cross_x, https://github.com/JonDoe-297/cross-view/issues/4", "\n", "front_res", "=", "torch", ".", "cat", "(", "(", "cross_x", ",", "T", ")", ",", "dim", "=", "1", ")", "\n", "front_res", "=", "self", ".", "f_conv", "(", "front_res", ")", "\n", "front_res", "=", "front_res", "*", "S", "\n", "# according to github issue,front_x should be cross_x, https://github.com/JonDoe-297/cross-view/issues/4", "\n", "# output = front_x + front_res", "\n", "output", "=", "cross_x", "+", "front_res", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.Conv3x3.__init__": [[53, 61], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "torch.ZeroPad2d", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "use_refl", "=", "True", ")", ":", "\n", "        ", "super", "(", "Conv3x3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "use_refl", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ReflectionPad2d", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pad", "=", "nn", ".", "ZeroPad2d", "(", "1", ")", "\n", "", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "int", "(", "in_channels", ")", ",", "int", "(", "out_channels", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.Conv3x3.forward": [[62, 66], ["origin_pyva_transformer.Conv3x3.pad", "origin_pyva_transformer.Conv3x3.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "pad", "(", "x", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.CycledViewProjection.__init__": [[68, 72], ["torch.Module.__init__", "origin_pyva_transformer.TransformModule", "origin_pyva_transformer.TransformModule"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "8", ")", ":", "\n", "        ", "super", "(", "CycledViewProjection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform_module", "=", "TransformModule", "(", "dim", "=", "in_dim", ")", "\n", "self", ".", "retransform_module", "=", "TransformModule", "(", "dim", "=", "in_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.CycledViewProjection.forward": [[73, 79], ["x.view().size", "origin_pyva_transformer.CycledViewProjection.transform_module", "origin_pyva_transformer.CycledViewProjection.view", "origin_pyva_transformer.CycledViewProjection.retransform_module", "x.view", "list", "int", "list", "x.size", "int", "x.size", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "view", "(", "[", "-", "1", ",", "int", "(", "x", ".", "size", "(", ")", "[", "1", "]", ")", "]", "+", "list", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", ".", "size", "(", ")", "\n", "transform_feature", "=", "self", ".", "transform_module", "(", "x", ")", "\n", "transform_features", "=", "transform_feature", ".", "view", "(", "[", "B", ",", "int", "(", "x", ".", "size", "(", ")", "[", "1", "]", ")", "]", "+", "list", "(", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", "\n", "retransform_features", "=", "self", ".", "retransform_module", "(", "transform_features", ")", "\n", "return", "transform_feature", ",", "retransform_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.TransformModule.__init__": [[82, 92], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", "=", "8", ")", ":", "\n", "        ", "super", "(", "TransformModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "mat_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# self.bn = nn.BatchNorm2d(512)", "\n", "self", ".", "fc_transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim", "*", "dim", ",", "dim", "*", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.TransformModule.forward": [[93, 100], ["x.view.view.view", "origin_pyva_transformer.TransformModule.fc_transform", "view_comb.view.view.view", "list", "list", "x.view.view.size", "view_comb.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# shape x: B, C, H, W", "\n", "# x = self.bn(x)", "\n", "        ", "x", "=", "x", ".", "view", "(", "list", "(", "x", ".", "size", "(", ")", "[", ":", "2", "]", ")", "+", "[", "self", ".", "dim", "*", "self", ".", "dim", "]", ")", "\n", "view_comb", "=", "self", ".", "fc_transform", "(", "x", ")", "\n", "view_comb", "=", "view_comb", ".", "view", "(", "list", "(", "view_comb", ".", "size", "(", ")", "[", ":", "2", "]", ")", "+", "[", "self", ".", "dim", ",", "self", ".", "dim", "]", ")", "\n", "return", "view_comb", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.Interpo.__init__": [[102, 105], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "Interpo", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.Interpo.forward": [[106, 109], ["torch.interpolate", "torch.interpolate", "torch.interpolate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "size", "=", "self", ".", "size", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.origin_Pyva_transformer.__init__": [[112, 124], ["torch.Module.__init__", "origin_pyva_transformer.Conv3x3", "origin_pyva_transformer.Conv3x3", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "origin_pyva_transformer.TransformModule", "origin_pyva_transformer.TransformModule", "origin_pyva_transformer.CrossViewTransformer", "origin_pyva_transformer.Interpo"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "origin_Pyva_transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# the last output of ResNetV1c_50 has the shape of (batch_size, 2048, 38, 50)", "\n", "# so we interpolate it into (batch_size, 128, 32, 32)", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "conv1", "=", "Conv3x3", "(", "2048", ",", "128", ")", "\n", "self", ".", "conv2", "=", "Conv3x3", "(", "128", ",", "128", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", "self", ".", "transform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "retransform_feature", "=", "TransformModule", "(", "dim", "=", "8", ")", "\n", "self", ".", "crossview", "=", "CrossViewTransformer", "(", "in_dim", "=", "128", ")", "\n", "self", ".", "interpolate", "=", "Interpo", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.origin_Pyva_transformer.forward": [[125, 139], ["origin_pyva_transformer.origin_Pyva_transformer.interpolate", "origin_pyva_transformer.origin_Pyva_transformer.conv1", "origin_pyva_transformer.origin_Pyva_transformer.pool", "origin_pyva_transformer.origin_Pyva_transformer.conv2", "origin_pyva_transformer.origin_Pyva_transformer.pool", "origin_pyva_transformer.origin_Pyva_transformer.transform_feature", "origin_pyva_transformer.origin_Pyva_transformer.retransform_feature", "origin_pyva_transformer.origin_Pyva_transformer.crossview", "origin_pyva_transformer.origin_Pyva_transformer.view", "origin_pyva_transformer.origin_Pyva_transformer.view", "origin_pyva_transformer.origin_Pyva_transformer.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "calib", ")", ":", "\n", "        ", "x", "=", "x", "[", "-", "1", "]", "\n", "x", "=", "self", ".", "interpolate", "(", "x", ")", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "transform_feature", "=", "self", ".", "transform_feature", "(", "x", ")", "\n", "retransform_feature", "=", "self", ".", "retransform_feature", "(", "transform_feature", ")", "\n", "feature_final", "=", "self", ".", "crossview", "(", "x", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "transform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ",", "\n", "retransform_feature", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", ")", "\n", "return", "feature_final", ",", "x", ",", "retransform_feature", ",", "transform_feature", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.origin_pyva_transformer.feature_selection": [[6, 17], ["list", "index.view().expand.view().expand", "torch.gather", "torch.gather", "torch.gather", "input.size", "input.size", "index.view().expand.view", "range", "len", "input.size"], "function", ["None"], ["def", "feature_selection", "(", "input", ",", "dim", ",", "index", ")", ":", "\n", "# feature selection", "\n", "# input: [N, ?, ?, ...]", "\n", "# dim: scalar > 0", "\n", "# index: [N, idx]", "\n", "    ", "views", "=", "[", "input", ".", "size", "(", "0", ")", "]", "+", "[", "1", "if", "i", "!=", "dim", "else", "-", "1", "for", "i", "in", "range", "(", "1", ",", "len", "(", "input", ".", "size", "(", ")", ")", ")", "]", "\n", "expanse", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "expanse", "[", "0", "]", "=", "-", "1", "\n", "expanse", "[", "dim", "]", "=", "-", "1", "\n", "index", "=", "index", ".", "view", "(", "views", ")", ".", "expand", "(", "expanse", ")", "\n", "return", "torch", ".", "gather", "(", "input", ",", "dim", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.QuickCumsum.forward": [[27, 40], ["torch.cat.cumsum", "torch.cat.cumsum", "torch.cat.cumsum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ctx.save_for_backward", "ctx.mark_non_differentiable"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "geom_feats", ",", "ranks", ")", ":", "\n", "        ", "x", "=", "x", ".", "cumsum", "(", "0", ")", "\n", "kept", "=", "torch", ".", "ones", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "kept", "[", ":", "-", "1", "]", "=", "(", "ranks", "[", "1", ":", "]", "!=", "ranks", "[", ":", "-", "1", "]", ")", "\n", "x", ",", "geom_feats", "=", "x", "[", "kept", "]", ",", "geom_feats", "[", "kept", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", ":", "1", "]", ",", "x", "[", "1", ":", "]", "-", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# save kept for backward", "\n", "ctx", ".", "save_for_backward", "(", "kept", ")", "\n", "# no gradient for geom_feats", "\n", "ctx", ".", "mark_non_differentiable", "(", "geom_feats", ")", "\n", "return", "x", ",", "geom_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.QuickCumsum.backward": [[41, 48], ["torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "gradx", ",", "gradgeom", ")", ":", "\n", "        ", "kept", ",", "=", "ctx", ".", "saved_tensors", "\n", "back", "=", "torch", ".", "cumsum", "(", "kept", ",", "0", ")", "\n", "back", "[", "kept", "]", "-=", "1", "\n", "val", "=", "gradx", "[", "back", "]", "\n", "return", "val", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.Resampler.__init__": [[58, 68], ["torch.Module.__init__", "lss_pyva_neck._make_grid"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck._make_grid"], ["    ", "def", "__init__", "(", "self", ",", "resolution", ",", "extents", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Store z positions of the near and far planes", "\n", "# extents[1]:zmin,extents[3]:zmax", "\n", "self", ".", "near", "=", "extents", "[", "1", "]", "\n", "self", ".", "far", "=", "extents", "[", "3", "]", "\n", "\n", "# Make a grid in the x-z plane", "\n", "self", ".", "grid", "=", "_make_grid", "(", "resolution", ",", "extents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.Resampler.forward": [[69, 91], ["lss_pyva_neck.Resampler.grid.to", "[].view", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.stack().clamp", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "lss_pyva_neck.Resampler.grid.unsqueeze", "features.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "calib", ")", ":", "\n", "# Copy grid to the correct device", "\n", "        ", "self", ".", "grid", "=", "self", ".", "grid", ".", "to", "(", "features", ")", "\n", "\n", "# We ignore the image v-coordinate, and assume the world Y-coordinate", "\n", "# is zero, so we only need a 2x2 submatrix of the original 3x3 matrix", "\n", "# calib shape:[bs,3,3]-->[bs,2,3]-->[bs,2,2]-->[bs,1,1,2,2]", "\n", "calib", "=", "calib", "[", ":", ",", "[", "0", ",", "2", "]", "]", "[", "...", ",", "[", "0", ",", "2", "]", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "2", ",", "2", ")", "\n", "\n", "# Transform grid center locations into image u-coordinates", "\n", "cam_coords", "=", "torch", ".", "matmul", "(", "calib", ",", "self", ".", "grid", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# Apply perspective projection and normalize", "\n", "ucoords", "=", "cam_coords", "[", "...", ",", "0", "]", "/", "cam_coords", "[", "...", ",", "1", "]", "\n", "ucoords", "=", "ucoords", "/", "features", ".", "size", "(", "-", "1", ")", "*", "2", "-", "1", "\n", "\n", "# Normalize z coordinates", "\n", "zcoords", "=", "(", "cam_coords", "[", "...", ",", "1", "]", "-", "self", ".", "near", ")", "/", "(", "self", ".", "far", "-", "self", ".", "near", ")", "*", "2", "-", "1", "\n", "\n", "# Resample 3D feature map", "\n", "grid_coords", "=", "torch", ".", "stack", "(", "[", "ucoords", ",", "zcoords", "]", ",", "-", "1", ")", ".", "clamp", "(", "-", "1.1", ",", "1.1", ")", "\n", "return", "F", ".", "grid_sample", "(", "features", ",", "grid_coords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.DenseTransformer.__init__": [[94, 119], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "lss_pyva_neck.Resampler", "math.ceil", "math.ceil", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "resolution", ",", "grid_extents", ",", "\n", "ymin", ",", "ymax", ",", "focal_length", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Initial convolution to reduce feature dimensions", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "channels", ",", "1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "GroupNorm", "(", "16", ",", "channels", ")", "\n", "\n", "# Resampler transforms perspective features to BEV", "\n", "self", ".", "resampler", "=", "Resampler", "(", "resolution", ",", "grid_extents", ")", "\n", "\n", "# Compute input height based on region of image covered by grid", "\n", "self", ".", "zmin", ",", "zmax", "=", "grid_extents", "[", "1", "]", ",", "grid_extents", "[", "3", "]", "\n", "self", ".", "in_height", "=", "math", ".", "ceil", "(", "focal_length", "*", "(", "ymax", "-", "ymin", ")", "/", "self", ".", "zmin", ")", "\n", "# self.ymid = 1", "\n", "self", ".", "ymid", "=", "(", "ymin", "+", "ymax", ")", "/", "2", "\n", "\n", "# Compute number of output cells required", "\n", "self", ".", "out_depth", "=", "math", ".", "ceil", "(", "(", "zmax", "-", "self", ".", "zmin", ")", "/", "resolution", ")", "\n", "\n", "# Dense layer which maps UV features to UZ", "\n", "self", ".", "fc", "=", "nn", ".", "Conv1d", "(", "\n", "channels", "*", "self", ".", "in_height", ",", "channels", "*", "self", ".", "out_depth", ",", "1", ",", "groups", "=", "groups", "\n", ")", "\n", "self", ".", "out_channels", "=", "channels", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.DenseTransformer.forward": [[120, 135], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu", "torch.relu", "torch.relu", "torch.relu.flatten", "lss_pyva_neck.DenseTransformer.fc().view", "lss_pyva_neck.DenseTransformer.resampler", "lss_pyva_neck.DenseTransformer.bn", "lss_pyva_neck.DenseTransformer._crop_feature_map", "lss_pyva_neck.DenseTransformer.conv", "lss_pyva_neck.DenseTransformer.fc", "zip"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.DenseTransformer._crop_feature_map"], ["", "def", "forward", "(", "self", ",", "features", ",", "calib", ",", "*", "args", ")", ":", "\n", "# Crop feature maps to a fixed input height", "\n", "        ", "features", "=", "torch", ".", "stack", "(", "[", "self", ".", "_crop_feature_map", "(", "fmap", ",", "cal", ")", "\n", "for", "fmap", ",", "cal", "in", "zip", "(", "features", ",", "calib", ")", "]", ")", "\n", "\n", "# Reduce feature dimension to minimize memory usage", "\n", "features", "=", "F", ".", "relu", "(", "self", ".", "bn", "(", "self", ".", "conv", "(", "features", ")", ")", ")", "\n", "\n", "# Flatten height and channel dimensions", "\n", "B", ",", "C", ",", "_", ",", "W", "=", "features", ".", "shape", "\n", "flat_feats", "=", "features", ".", "flatten", "(", "1", ",", "2", ")", "\n", "# H is not fixed every time", "\n", "bev_feats", "=", "self", ".", "fc", "(", "flat_feats", ")", ".", "view", "(", "B", ",", "C", ",", "-", "1", ",", "W", ")", "\n", "# Resample to orthographic grid", "\n", "return", "self", ".", "resampler", "(", "bev_feats", ",", "calib", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.DenseTransformer._crop_feature_map": [[136, 145], ["math.floor", "math.floor", "torch.pad", "torch.pad", "torch.pad"], "methods", ["None"], ["", "def", "_crop_feature_map", "(", "self", ",", "fmap", ",", "calib", ")", ":", "\n", "# Compute upper and lower bounds of visible region", "\n", "        ", "focal_length", ",", "img_offset", "=", "calib", "[", "1", ",", "1", ":", "]", "\n", "vmid", "=", "self", ".", "ymid", "*", "focal_length", "/", "self", ".", "zmin", "+", "img_offset", "\n", "vmin", "=", "math", ".", "floor", "(", "vmid", "-", "self", ".", "in_height", "/", "2", ")", "\n", "vmax", "=", "math", ".", "floor", "(", "vmid", "+", "self", ".", "in_height", "/", "2", ")", "\n", "\n", "# Pad or crop input tensor to match dimensions", "\n", "return", "F", ".", "pad", "(", "fmap", ",", "[", "0", ",", "0", ",", "-", "vmin", ",", "vmax", "-", "fmap", ".", "shape", "[", "-", "2", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.LSS_PYVA_neck.__init__": [[149, 193], ["dict", "mmcv.runner.BaseModule.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "lss_pyva_neck.gen_dx_bx", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lss_pyva_neck.LSS_PYVA_neck.create_frustum", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "functools.reduce", "min", "lss_pyva_neck.DenseTransformer", "lss_pyva_neck.LSS_PYVA_neck.transformers.append", "pow", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.gen_dx_bx", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.create_frustum"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", "=", "256", ",", "channels", "=", "64", ",", "resolution", "=", "0.25", "*", "reduce", "(", "mul", ",", "[", "1", ",", "2", "]", ")", ",", "\n", "extents", "=", "[", "-", "25.0", ",", "1.0", ",", "25.0", ",", "50.0", "]", ",", "ymin", "=", "-", "2", ",", "ymax", "=", "4", ",", "focal_length", "=", "630.0", ",", "\n", "downsample", "=", "32", ",", "bev_feature_channels", "=", "64", ",", "ogfH", "=", "1024", ",", "ogfW", "=", "1024", ",", "\n", "grid_conf", "=", "dict", "(", "dbound", "=", "[", "1", ",", "50", ",", "1", "]", ",", "xbound", "=", "[", "-", "25", ",", "25", ",", "0.5", "]", ",", "zbound", "=", "[", "1", ",", "50", ",", "0.5", "]", ",", "ybound", "=", "[", "-", "10", ",", "10", ",", "20", "]", ")", ")", ":", "\n", "# resolution = 0.25*(1*2)=0.5", "\n", "# focal = 78.75,39.375,19.6875,9.84375,4.921875", "\n", "# subset_extents = [-25,39,25,50],[-25,19.5,25,39],\\", "\n", "# [-25,9.5,25,19.5],[-25,4.5,25,9.5],[-25,1,25,4.5]", "\n", "# ymin=-2,ymax=4", "\n", "        ", "super", "(", "LSS_PYVA_neck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# pyva part", "\n", "self", ".", "transformers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# Scaled focal length for each transformer", "\n", "            ", "focal", "=", "focal_length", "/", "pow", "(", "2", ",", "i", "+", "3", ")", "\n", "\n", "# Compute grid bounds for each transformer", "\n", "zmax", "=", "min", "(", "math", ".", "floor", "(", "focal", "*", "2", ")", "*", "resolution", ",", "extents", "[", "3", "]", ")", "\n", "zmin", "=", "math", ".", "floor", "(", "focal", ")", "*", "resolution", "if", "i", "<", "4", "else", "extents", "[", "1", "]", "\n", "subset_extents", "=", "[", "extents", "[", "0", "]", ",", "zmin", ",", "extents", "[", "2", "]", ",", "zmax", "]", "\n", "# Build transformers", "\n", "tfm", "=", "DenseTransformer", "(", "in_channels", ",", "channels", ",", "resolution", ",", "\n", "subset_extents", ",", "ymin", ",", "ymax", ",", "focal", ")", "\n", "self", ".", "transformers", ".", "append", "(", "tfm", ")", "\n", "\n", "# lss part", "\n", "", "self", ".", "grid_conf", "=", "grid_conf", "\n", "dx", ",", "bx", ",", "nx", "=", "gen_dx_bx", "(", "self", ".", "grid_conf", "[", "'xbound'", "]", ",", "\n", "self", ".", "grid_conf", "[", "'ybound'", "]", ",", "\n", "self", ".", "grid_conf", "[", "'zbound'", "]", ",", "\n", ")", "\n", "self", ".", "dx", "=", "nn", ".", "Parameter", "(", "dx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "bx", "=", "nn", ".", "Parameter", "(", "bx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "nx", "=", "nn", ".", "Parameter", "(", "nx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "ogfH", "=", "ogfH", "\n", "self", ".", "ogfW", "=", "ogfW", "\n", "self", ".", "frustum", "=", "self", ".", "create_frustum", "(", ")", "\n", "self", ".", "D", ",", "_", ",", "_", ",", "_", "=", "self", ".", "frustum", ".", "shape", "\n", "self", ".", "C", "=", "bev_feature_channels", "\n", "# by default, self.C = 64, self.D = 49", "\n", "self", ".", "depthnet", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "self", ".", "D", "+", "self", ".", "C", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "use_quickcumsum", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.LSS_PYVA_neck.create_frustum": [[194, 204], ["torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace"], "methods", ["None"], ["", "def", "create_frustum", "(", "self", ")", ":", "\n", "        ", "fH", ",", "fW", "=", "self", ".", "ogfH", "//", "self", ".", "downsample", ",", "self", ".", "ogfW", "//", "self", ".", "downsample", "\n", "depth_samples", "=", "torch", ".", "arange", "(", "*", "self", ".", "grid_conf", "[", "'dbound'", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "fH", ",", "fW", ")", "\n", "num_depth", ",", "_", ",", "_", "=", "depth_samples", ".", "shape", "\n", "x_samples", "=", "torch", ".", "linspace", "(", "0", ",", "self", ".", "ogfW", "-", "1", ",", "fW", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "1", ",", "1", ",", "fW", ")", ".", "expand", "(", "num_depth", ",", "fH", ",", "fW", ")", "\n", "y_samples", "=", "torch", ".", "linspace", "(", "0", ",", "self", ".", "ogfH", "-", "1", ",", "fH", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "1", ",", "fH", ",", "1", ")", ".", "expand", "(", "num_depth", ",", "fH", ",", "fW", ")", "\n", "\n", "# D x H x W x 3", "\n", "frustum", "=", "torch", ".", "stack", "(", "(", "x_samples", ",", "y_samples", ",", "depth_samples", ")", ",", "-", "1", ")", "\n", "return", "nn", ".", "Parameter", "(", "frustum", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.LSS_PYVA_neck.get_geometry": [[205, 214], ["lss_pyva_neck.LSS_PYVA_neck.frustum.view().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse.view().matmul().squeeze().view", "torch.inverse.view().matmul().squeeze().view", "torch.inverse.view().matmul().squeeze().view", "lss_pyva_neck.LSS_PYVA_neck.frustum.view", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul", "torch.inverse.view().matmul", "torch.inverse.view().matmul", "torch.inverse.view().matmul().squeeze().view.unsqueeze", "torch.inverse.view", "torch.inverse.view", "torch.inverse.view"], "methods", ["None"], ["", "def", "get_geometry", "(", "self", ",", "intrinstics", ")", ":", "\n", "        ", "B", "=", "intrinstics", ".", "shape", "[", "0", "]", "\n", "D", ",", "H", ",", "W", ",", "C", "=", "self", ".", "frustum", ".", "shape", "\n", "points", "=", "self", ".", "frustum", ".", "view", "(", "1", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", ".", "expand", "(", "B", ",", "D", ",", "H", ",", "W", ",", "C", ")", "\n", "points", "=", "torch", ".", "cat", "(", "[", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", ":", "2", "]", "*", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", "2", ":", "3", "]", ",", "\n", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", "2", ":", "3", "]", "]", ",", "4", ")", "\n", "combine", "=", "torch", ".", "inverse", "(", "intrinstics", ")", "\n", "points", "=", "combine", ".", "view", "(", "B", ",", "1", ",", "1", ",", "1", ",", "3", ",", "3", ")", ".", "matmul", "(", "points", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "B", ",", "1", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "points", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.LSS_PYVA_neck.voxel_pooling": [[215, 257], ["lss_pyva_neck.LSS_PYVA_neck.nx.to", "x.reshape.reshape.reshape", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ranks.argsort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lss_pyva_neck.cumsum_trick", "QuickCumsum.apply", "torch.cat.unbind", "torch.cat.unbind", "torch.cat.unbind", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "range"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.cumsum_trick"], ["", "def", "voxel_pooling", "(", "self", ",", "geom_feats", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "D", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "Nprime", "=", "B", "*", "N", "*", "D", "*", "H", "*", "W", "\n", "nx", "=", "self", ".", "nx", ".", "to", "(", "torch", ".", "long", ")", "\n", "# flatten x", "\n", "x", "=", "x", ".", "reshape", "(", "Nprime", ",", "C", ")", "\n", "# flatten indices", "\n", "geom_feats", "=", "(", "(", "geom_feats", "-", "(", "self", ".", "bx", "-", "self", ".", "dx", "/", "2.", ")", ")", "/", "self", ".", "dx", ")", ".", "long", "(", ")", "\n", "geom_feats", "=", "geom_feats", ".", "view", "(", "Nprime", ",", "3", ")", "\n", "batch_ix", "=", "torch", ".", "cat", "(", "[", "torch", ".", "full", "(", "[", "Nprime", "//", "B", ",", "1", "]", ",", "ix", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "for", "ix", "in", "range", "(", "B", ")", "]", ")", "\n", "geom_feats", "=", "torch", ".", "cat", "(", "(", "geom_feats", ",", "batch_ix", ")", ",", "1", ")", "\n", "\n", "# filter out points that are outside box", "\n", "kept", "=", "(", "geom_feats", "[", ":", ",", "0", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "0", "]", "<", "nx", "[", "0", "]", ")", "&", "(", "geom_feats", "[", ":", ",", "1", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "1", "]", "<", "nx", "[", "1", "]", ")", "&", "(", "geom_feats", "[", ":", ",", "2", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "2", "]", "<", "nx", "[", "2", "]", ")", "\n", "x", "=", "x", "[", "kept", "]", "\n", "geom_feats", "=", "geom_feats", "[", "kept", "]", "\n", "\n", "# get tensors from the same voxel next to each other", "\n", "ranks", "=", "geom_feats", "[", ":", ",", "0", "]", "*", "(", "nx", "[", "1", "]", "*", "nx", "[", "2", "]", "*", "B", ")", "+", "geom_feats", "[", ":", ",", "1", "]", "*", "(", "nx", "[", "2", "]", "*", "B", ")", "+", "geom_feats", "[", ":", ",", "2", "]", "*", "B", "+", "geom_feats", "[", ":", ",", "3", "]", "\n", "sorts", "=", "ranks", ".", "argsort", "(", ")", "\n", "x", ",", "geom_feats", ",", "ranks", "=", "x", "[", "sorts", "]", ",", "geom_feats", "[", "sorts", "]", ",", "ranks", "[", "sorts", "]", "\n", "\n", "# cumsum trick", "\n", "if", "not", "self", ".", "use_quickcumsum", ":", "\n", "            ", "x", ",", "geom_feats", "=", "cumsum_trick", "(", "x", ",", "geom_feats", ",", "ranks", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "geom_feats", "=", "QuickCumsum", ".", "apply", "(", "x", ",", "geom_feats", ",", "ranks", ")", "\n", "\n", "# griddify (B x C x Z x X x Y)", "\n", "", "final", "=", "torch", ".", "zeros", "(", "(", "B", ",", "C", ",", "nx", "[", "1", "]", ",", "nx", "[", "2", "]", ",", "nx", "[", "0", "]", ")", ",", "device", "=", "x", ".", "device", ")", "\n", "final", "[", "geom_feats", "[", ":", ",", "3", "]", ",", ":", ",", "geom_feats", "[", ":", ",", "1", "]", ",", "geom_feats", "[", ":", ",", "2", "]", ",", "geom_feats", "[", ":", ",", "0", "]", "]", "=", "x", "\n", "\n", "# collapse Z", "\n", "final", "=", "torch", ".", "cat", "(", "final", ".", "unbind", "(", "dim", "=", "2", ")", ",", "1", ")", "\n", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.LSS_PYVA_neck.get_depth_dist": [[258, 260], ["x.softmax"], "methods", ["None"], ["", "def", "get_depth_dist", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.LSS_PYVA_neck.forward": [[261, 293], ["lss_pyva_neck.LSS_PYVA_neck.get_geometry", "lss_pyva_neck.LSS_PYVA_neck.depthnet", "lss_pyva_neck.LSS_PYVA_neck.get_depth_dist", "new_feature.view", "feature.permute.permute.permute", "lss_pyva_neck.LSS_PYVA_neck.voxel_pooling", "list", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lss_pyva_neck.LSS_PYVA_neck.unsqueeze", "feature[].unsqueeze", "calib.clone", "list.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_geometry", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_depth_dist", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.voxel_pooling"], ["", "def", "forward", "(", "self", ",", "feature_maps", ",", "calib", ")", ":", "\n", "        ", "geom", "=", "self", ".", "get_geometry", "(", "calib", ")", "\n", "b", ",", "_", ",", "_", ",", "h", ",", "w", ",", "_", "=", "geom", ".", "shape", "\n", "if", "self", ".", "downsample", "==", "32", ":", "\n", "# feature = feature_maps[3][:,:,:h,:w]  ", "\n", "            ", "feature", "=", "feature_maps", "[", "2", "]", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "\n", "", "elif", "self", ".", "downsample", "==", "16", ":", "\n", "            ", "feature", "=", "feature_maps", "[", "0", "]", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "", "feature", "=", "self", ".", "depthnet", "(", "feature", ")", "\n", "depth", "=", "self", ".", "get_depth_dist", "(", "feature", "[", ":", ",", ":", "self", ".", "D", "]", ")", "\n", "new_feature", "=", "depth", ".", "unsqueeze", "(", "1", ")", "*", "feature", "[", ":", ",", "self", ".", "D", ":", "(", "self", ".", "D", "+", "self", ".", "C", ")", "]", ".", "unsqueeze", "(", "2", ")", "\n", "feature", "=", "new_feature", ".", "view", "(", "b", ",", "1", ",", "self", ".", "C", ",", "self", ".", "D", ",", "h", ",", "w", ")", "\n", "feature", "=", "feature", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "5", ",", "2", ")", "\n", "# feature_lss.shape: bs,64,98,100", "\n", "feature_lss", "=", "self", ".", "voxel_pooling", "(", "geom", ",", "feature", ")", "\n", "\n", "# pyva part", "\n", "bev_feats", "=", "list", "(", ")", "\n", "# scale = 8,16,32,64,128", "\n", "# calib.shape = [bs,3,3]", "\n", "for", "i", ",", "fmap", "in", "enumerate", "(", "feature_maps", ")", ":", "\n", "# Scale calibration matrix to account for downsampling", "\n", "            ", "scale", "=", "8", "*", "2", "**", "i", "\n", "calib_downsamp", "=", "calib", ".", "clone", "(", ")", "\n", "calib_downsamp", "[", ":", ",", ":", "2", "]", "=", "calib", "[", ":", ",", ":", "2", "]", "/", "scale", "\n", "# Apply orthographic transformation to each feature map separately", "\n", "bev_feats", ".", "append", "(", "self", ".", "transformers", "[", "i", "]", "(", "fmap", ",", "calib_downsamp", ")", ")", "\n", "", "feature_pyva", "=", "torch", ".", "cat", "(", "bev_feats", "[", ":", ":", "-", "1", "]", ",", "dim", "=", "-", "2", ")", "\n", "feature_final", "=", "feature_pyva", "+", "feature_lss", "\n", "return", "feature_final", ",", "feature_pyva", ",", "feature_lss", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.gen_dx_bx": [[12, 17], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["def", "gen_dx_bx", "(", "xbound", ",", "ybound", ",", "zbound", ")", ":", "\n", "    ", "dx", "=", "torch", ".", "Tensor", "(", "[", "row", "[", "2", "]", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "bx", "=", "torch", ".", "Tensor", "(", "[", "row", "[", "0", "]", "+", "row", "[", "2", "]", "/", "2.0", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "nx", "=", "torch", ".", "Tensor", "(", "[", "(", "row", "[", "1", "]", "-", "row", "[", "0", "]", ")", "/", "row", "[", "2", "]", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "return", "dx", ",", "bx", ",", "nx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck.cumsum_trick": [[18, 25], ["torch.cat.cumsum", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "cumsum_trick", "(", "x", ",", "geom_feats", ",", "ranks", ")", ":", "\n", "    ", "x", "=", "x", ".", "cumsum", "(", "0", ")", "\n", "kept", "=", "torch", ".", "ones", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "kept", "[", ":", "-", "1", "]", "=", "(", "ranks", "[", "1", ":", "]", "!=", "ranks", "[", ":", "-", "1", "]", ")", "\n", "x", ",", "geom_feats", "=", "x", "[", "kept", "]", ",", "geom_feats", "[", "kept", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", ":", "1", "]", ",", "x", "[", "1", ":", "]", "-", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "return", "x", ",", "geom_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_pyva_neck._make_grid": [[51, 56], ["torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.stack", "torch.stack", "torch.stack", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "", "def", "_make_grid", "(", "resolution", ",", "extents", ")", ":", "\n", "# Create a grid of cooridinates in the birds-eye-view", "\n", "    ", "x1", ",", "z1", ",", "x2", ",", "z2", "=", "extents", "\n", "zz", ",", "xx", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "z1", ",", "z2", ",", "resolution", ")", ",", "torch", ".", "arange", "(", "x1", ",", "x2", ",", "resolution", ")", ")", "\n", "return", "torch", ".", "stack", "(", "[", "xx", ",", "zz", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.QuickCumsum.forward": [[25, 41], ["torch.cat.cumsum", "torch.cat.cumsum", "torch.cat.cumsum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ctx.save_for_backward", "ctx.mark_non_differentiable"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "geom_feats", ",", "ranks", ")", ":", "\n", "        ", "x", "=", "x", ".", "cumsum", "(", "0", ")", "\n", "kept", "=", "torch", ".", "ones", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "kept", "[", ":", "-", "1", "]", "=", "(", "ranks", "[", "1", ":", "]", "!=", "ranks", "[", ":", "-", "1", "]", ")", "\n", "\n", "x", ",", "geom_feats", "=", "x", "[", "kept", "]", ",", "geom_feats", "[", "kept", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", ":", "1", "]", ",", "x", "[", "1", ":", "]", "-", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# save kept for backward", "\n", "ctx", ".", "save_for_backward", "(", "kept", ")", "\n", "\n", "# no gradient for geom_feats", "\n", "ctx", ".", "mark_non_differentiable", "(", "geom_feats", ")", "\n", "\n", "return", "x", ",", "geom_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.QuickCumsum.backward": [[42, 49], ["torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "gradx", ",", "gradgeom", ")", ":", "\n", "        ", "kept", ",", "=", "ctx", ".", "saved_tensors", "\n", "back", "=", "torch", ".", "cumsum", "(", "kept", ",", "0", ")", "\n", "back", "[", "kept", "]", "-=", "1", "\n", "val", "=", "gradx", "[", "back", "]", "\n", "return", "val", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.__init__": [[52, 97], ["dict", "mmcv.runner.BaseModule.__init__", "lss_vpn_neck.gen_dx_bx", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lss_vpn_neck.LSS_VPN_neck.create_frustum", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.gen_dx_bx", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.create_frustum"], ["    ", "def", "__init__", "(", "self", ",", "use_light", "=", "False", ",", "downsample", "=", "32", ",", "in_channels", "=", "768", ",", "bev_feature_channels", "=", "64", ",", "ogfH", "=", "1024", ",", "ogfW", "=", "1024", ",", "\n", "grid_conf", "=", "dict", "(", "dbound", "=", "[", "1", ",", "50", ",", "1", "]", ",", "xbound", "=", "[", "-", "25", ",", "25", ",", "0.5", "]", ",", "zbound", "=", "[", "1", ",", "50", ",", "0.5", "]", ",", "ybound", "=", "[", "-", "10", ",", "10", ",", "20", "]", ")", ",", "\n", "input_width", "=", "32", ",", "input_height", "=", "32", ",", "input_dim", "=", "768", ",", "output_width", "=", "100", ",", "output_height", "=", "98", ",", "output_dim", "=", "64", ")", ":", "\n", "        ", "super", "(", "LSS_VPN_high_neck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "grid_conf", "=", "grid_conf", "\n", "self", ".", "use_light", "=", "use_light", "\n", "dx", ",", "bx", ",", "nx", "=", "gen_dx_bx", "(", "self", ".", "grid_conf", "[", "'xbound'", "]", ",", "\n", "self", ".", "grid_conf", "[", "'ybound'", "]", ",", "\n", "self", ".", "grid_conf", "[", "'zbound'", "]", ",", "\n", ")", "\n", "self", ".", "dx", "=", "nn", ".", "Parameter", "(", "dx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "bx", "=", "nn", ".", "Parameter", "(", "bx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "nx", "=", "nn", ".", "Parameter", "(", "nx", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "ogfH", "=", "ogfH", "\n", "self", ".", "ogfW", "=", "ogfW", "\n", "self", ".", "frustum", "=", "self", ".", "create_frustum", "(", ")", "\n", "self", ".", "D", ",", "_", ",", "_", ",", "_", "=", "self", ".", "frustum", ".", "shape", "\n", "self", ".", "C", "=", "bev_feature_channels", "\n", "# by default, self.C = 64, self.D = 49", "\n", "self", ".", "depthnet", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "self", ".", "D", "+", "self", ".", "C", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "use_quickcumsum", "=", "True", "\n", "\n", "# vpn part", "\n", "self", ".", "input_width", "=", "input_width", "\n", "self", ".", "input_height", "=", "input_height", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_width", "=", "output_width", "\n", "self", ".", "output_height", "=", "output_height", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "if", "not", "self", ".", "use_light", ":", "\n", "            ", "self", ".", "tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_width", "*", "self", ".", "input_height", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "output_width", "*", "self", ".", "output_height", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_width", "*", "self", ".", "input_height", ",", "int", "(", "0.05", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "int", "(", "0.05", "*", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "self", ".", "output_width", "*", "self", ".", "output_height", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "self", ".", "input_dim", ",", "self", ".", "output_dim", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.create_frustum": [[98, 108], ["torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.linspace().view().expand", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.linspace().view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace"], "methods", ["None"], ["", "def", "create_frustum", "(", "self", ")", ":", "\n", "        ", "fH", ",", "fW", "=", "self", ".", "ogfH", "//", "self", ".", "downsample", ",", "self", ".", "ogfW", "//", "self", ".", "downsample", "\n", "depth_samples", "=", "torch", ".", "arange", "(", "*", "self", ".", "grid_conf", "[", "'dbound'", "]", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "fH", ",", "fW", ")", "\n", "num_depth", ",", "_", ",", "_", "=", "depth_samples", ".", "shape", "\n", "x_samples", "=", "torch", ".", "linspace", "(", "0", ",", "self", ".", "ogfW", "-", "1", ",", "fW", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "1", ",", "1", ",", "fW", ")", ".", "expand", "(", "num_depth", ",", "fH", ",", "fW", ")", "\n", "y_samples", "=", "torch", ".", "linspace", "(", "0", ",", "self", ".", "ogfH", "-", "1", ",", "fH", ",", "dtype", "=", "torch", ".", "float", ")", ".", "view", "(", "1", ",", "fH", ",", "1", ")", ".", "expand", "(", "num_depth", ",", "fH", ",", "fW", ")", "\n", "\n", "# D x H x W x 3", "\n", "frustum", "=", "torch", ".", "stack", "(", "(", "x_samples", ",", "y_samples", ",", "depth_samples", ")", ",", "-", "1", ")", "\n", "return", "nn", ".", "Parameter", "(", "frustum", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_geometry": [[109, 118], ["lss_vpn_neck.LSS_VPN_neck.frustum.view().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse.view().matmul().squeeze().view", "torch.inverse.view().matmul().squeeze().view", "torch.inverse.view().matmul().squeeze().view", "lss_vpn_neck.LSS_VPN_neck.frustum.view", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul().squeeze", "torch.inverse.view().matmul", "torch.inverse.view().matmul", "torch.inverse.view().matmul", "torch.inverse.view().matmul().squeeze().view.unsqueeze", "torch.inverse.view", "torch.inverse.view", "torch.inverse.view"], "methods", ["None"], ["", "def", "get_geometry", "(", "self", ",", "intrinstics", ")", ":", "\n", "        ", "B", "=", "intrinstics", ".", "shape", "[", "0", "]", "\n", "D", ",", "H", ",", "W", ",", "C", "=", "self", ".", "frustum", ".", "shape", "\n", "points", "=", "self", ".", "frustum", ".", "view", "(", "1", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", ".", "expand", "(", "B", ",", "D", ",", "H", ",", "W", ",", "C", ")", "\n", "points", "=", "torch", ".", "cat", "(", "[", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", ":", "2", "]", "*", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", "2", ":", "3", "]", ",", "\n", "points", "[", ":", ",", ":", ",", ":", ",", ":", ",", "2", ":", "3", "]", "]", ",", "4", ")", "\n", "combine", "=", "torch", ".", "inverse", "(", "intrinstics", ")", "\n", "points", "=", "combine", ".", "view", "(", "B", ",", "1", ",", "1", ",", "1", ",", "3", ",", "3", ")", ".", "matmul", "(", "points", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "B", ",", "1", ",", "D", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "points", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.voxel_pooling": [[119, 161], ["lss_vpn_neck.LSS_VPN_neck.nx.to", "x.reshape.reshape.reshape", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ranks.argsort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lss_vpn_neck.cumsum_trick", "QuickCumsum.apply", "torch.cat.unbind", "torch.cat.unbind", "torch.cat.unbind", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "range"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.cumsum_trick"], ["", "def", "voxel_pooling", "(", "self", ",", "geom_feats", ",", "x", ")", ":", "\n", "        ", "B", ",", "N", ",", "D", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "Nprime", "=", "B", "*", "N", "*", "D", "*", "H", "*", "W", "\n", "nx", "=", "self", ".", "nx", ".", "to", "(", "torch", ".", "long", ")", "\n", "# flatten x", "\n", "x", "=", "x", ".", "reshape", "(", "Nprime", ",", "C", ")", "\n", "# flatten indices", "\n", "geom_feats", "=", "(", "(", "geom_feats", "-", "(", "self", ".", "bx", "-", "self", ".", "dx", "/", "2.", ")", ")", "/", "self", ".", "dx", ")", ".", "long", "(", ")", "\n", "geom_feats", "=", "geom_feats", ".", "view", "(", "Nprime", ",", "3", ")", "\n", "batch_ix", "=", "torch", ".", "cat", "(", "[", "torch", ".", "full", "(", "[", "Nprime", "//", "B", ",", "1", "]", ",", "ix", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "for", "ix", "in", "range", "(", "B", ")", "]", ")", "\n", "geom_feats", "=", "torch", ".", "cat", "(", "(", "geom_feats", ",", "batch_ix", ")", ",", "1", ")", "\n", "\n", "# filter out points that are outside box", "\n", "kept", "=", "(", "geom_feats", "[", ":", ",", "0", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "0", "]", "<", "nx", "[", "0", "]", ")", "&", "(", "geom_feats", "[", ":", ",", "1", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "1", "]", "<", "nx", "[", "1", "]", ")", "&", "(", "geom_feats", "[", ":", ",", "2", "]", ">=", "0", ")", "&", "(", "geom_feats", "[", ":", ",", "2", "]", "<", "nx", "[", "2", "]", ")", "\n", "x", "=", "x", "[", "kept", "]", "\n", "geom_feats", "=", "geom_feats", "[", "kept", "]", "\n", "\n", "# get tensors from the same voxel next to each other", "\n", "ranks", "=", "geom_feats", "[", ":", ",", "0", "]", "*", "(", "nx", "[", "1", "]", "*", "nx", "[", "2", "]", "*", "B", ")", "+", "geom_feats", "[", ":", ",", "1", "]", "*", "(", "nx", "[", "2", "]", "*", "B", ")", "+", "geom_feats", "[", ":", ",", "2", "]", "*", "B", "+", "geom_feats", "[", ":", ",", "3", "]", "\n", "sorts", "=", "ranks", ".", "argsort", "(", ")", "\n", "x", ",", "geom_feats", ",", "ranks", "=", "x", "[", "sorts", "]", ",", "geom_feats", "[", "sorts", "]", ",", "ranks", "[", "sorts", "]", "\n", "\n", "# cumsum trick", "\n", "if", "not", "self", ".", "use_quickcumsum", ":", "\n", "            ", "x", ",", "geom_feats", "=", "cumsum_trick", "(", "x", ",", "geom_feats", ",", "ranks", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "geom_feats", "=", "QuickCumsum", ".", "apply", "(", "x", ",", "geom_feats", ",", "ranks", ")", "\n", "\n", "# griddify (B x C x Z x X x Y)", "\n", "", "final", "=", "torch", ".", "zeros", "(", "(", "B", ",", "C", ",", "nx", "[", "1", "]", ",", "nx", "[", "2", "]", ",", "nx", "[", "0", "]", ")", ",", "device", "=", "x", ".", "device", ")", "\n", "final", "[", "geom_feats", "[", ":", ",", "3", "]", ",", ":", ",", "geom_feats", "[", ":", ",", "1", "]", ",", "geom_feats", "[", ":", ",", "2", "]", ",", "geom_feats", "[", ":", ",", "0", "]", "]", "=", "x", "\n", "\n", "# collapse Z", "\n", "final", "=", "torch", ".", "cat", "(", "final", ".", "unbind", "(", "dim", "=", "2", ")", ",", "1", ")", "\n", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_depth_dist": [[162, 164], ["x.softmax"], "methods", ["None"], ["", "def", "get_depth_dist", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "softmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.forward": [[165, 193], ["lss_vpn_neck.LSS_VPN_neck.get_geometry", "lss_vpn_neck.LSS_VPN_neck.depthnet", "lss_vpn_neck.LSS_VPN_neck.get_depth_dist", "new_feature.view", "feature.permute.permute.permute", "lss_vpn_neck.LSS_VPN_neck.voxel_pooling", "lss_vpn_neck.LSS_VPN_neck.view", "lss_vpn_neck.LSS_VPN_neck.tf", "lss_vpn_neck.LSS_VPN_neck.view", "lss_vpn_neck.LSS_VPN_neck.conv", "lss_vpn_neck.LSS_VPN_neck.unsqueeze", "feature[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_geometry", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.get_depth_dist", "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.LSS_VPN_neck.voxel_pooling"], ["", "def", "forward", "(", "self", ",", "feature_maps", ",", "intrinstics", ")", ":", "\n", "# lss part", "\n", "# feature_maps[3].shape: bs,768,19,25", "\n", "        ", "geom", "=", "self", ".", "get_geometry", "(", "intrinstics", ")", "#geom.shape: bs,1,49,18,25,3", "\n", "b", ",", "_", ",", "_", ",", "h", ",", "w", ",", "_", "=", "geom", ".", "shape", "\n", "if", "self", ".", "downsample", "==", "32", ":", "\n", "            ", "feature", "=", "feature_maps", "[", "3", "]", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "# feature.shape:bs,768,18,25", "\n", "", "elif", "self", ".", "downsample", "==", "16", ":", "\n", "            ", "feature", "=", "feature_maps", "[", "0", "]", "[", ":", ",", ":", ",", ":", "h", ",", ":", "w", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "", "feature", "=", "self", ".", "depthnet", "(", "feature", ")", "# feature.shape:bs,113,18,25", "\n", "depth", "=", "self", ".", "get_depth_dist", "(", "feature", "[", ":", ",", ":", "self", ".", "D", "]", ")", "# depth.shape: bs,49,18,25", "\n", "new_feature", "=", "depth", ".", "unsqueeze", "(", "1", ")", "*", "feature", "[", ":", ",", "self", ".", "D", ":", "(", "self", ".", "D", "+", "self", ".", "C", ")", "]", ".", "unsqueeze", "(", "2", ")", "# new_feature.shape: bs,64,49,18,25", "\n", "feature", "=", "new_feature", ".", "view", "(", "b", ",", "1", ",", "self", ".", "C", ",", "self", ".", "D", ",", "h", ",", "w", ")", "# feature.shape: bs,1,64,49,18,25", "\n", "feature", "=", "feature", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "5", ",", "2", ")", "# feature.shape: bs,1,49,18,25,64", "\n", "# self.voxel_pooling(geom, feature).shape: bs,64,98,100", "\n", "feature_lss", "=", "self", ".", "voxel_pooling", "(", "geom", ",", "feature", ")", "\n", "\n", "# vpn part", "\n", "feature_vpn", "=", "feature_maps", "[", "3", "]", "\n", "n", ",", "c", ",", "h", ",", "w", "=", "feature_vpn", ".", "shape", "\n", "feature_vpn", "=", "feature_vpn", ".", "view", "(", "n", ",", "c", ",", "h", "*", "w", ")", "\n", "feature_vpn", "=", "self", ".", "tf", "(", "feature_vpn", ")", "\n", "feature_vpn", "=", "feature_vpn", ".", "view", "(", "n", ",", "c", ",", "self", ".", "output_height", ",", "self", ".", "output_width", ")", "\n", "feature_vpn", "=", "self", ".", "conv", "(", "feature_vpn", ")", "\n", "feature_final", "=", "feature_lss", "+", "feature_vpn", "\n", "return", "feature_final", ",", "feature_vpn", ",", "feature_lss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.gen_dx_bx": [[9, 14], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["def", "gen_dx_bx", "(", "xbound", ",", "ybound", ",", "zbound", ")", ":", "\n", "    ", "dx", "=", "torch", ".", "Tensor", "(", "[", "row", "[", "2", "]", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "bx", "=", "torch", ".", "Tensor", "(", "[", "row", "[", "0", "]", "+", "row", "[", "2", "]", "/", "2.0", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "nx", "=", "torch", ".", "Tensor", "(", "[", "(", "row", "[", "1", "]", "-", "row", "[", "0", "]", ")", "/", "row", "[", "2", "]", "for", "row", "in", "[", "xbound", ",", "ybound", ",", "zbound", "]", "]", ")", "\n", "return", "dx", ",", "bx", ",", "nx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.necks.lss_vpn_neck.cumsum_trick": [[15, 22], ["torch.cat.cumsum", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "cumsum_trick", "(", "x", ",", "geom_feats", ",", "ranks", ")", ":", "\n", "    ", "x", "=", "x", ".", "cumsum", "(", "0", ")", "\n", "kept", "=", "torch", ".", "ones", "(", "x", ".", "shape", "[", "0", "]", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "kept", "[", ":", "-", "1", "]", "=", "(", "ranks", "[", "1", ":", "]", "!=", "ranks", "[", ":", "-", "1", "]", ")", "\n", "x", ",", "geom_feats", "=", "x", "[", "kept", "]", ",", "geom_feats", "[", "kept", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", ":", "1", "]", ",", "x", "[", "1", ":", "]", "-", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "return", "x", ",", "geom_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.PatchMerging.__init__": [[42, 65], ["dict", "mmcv.runner.base_module.BaseModule.__init__", "torch.Unfold", "torch.Unfold", "torch.Unfold", "torch.Unfold", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "mmcv.cnn.build_norm_layer"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "stride", "=", "2", ",", "\n", "bias", "=", "False", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'LN'", ")", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "self", ".", "sampler", "=", "nn", ".", "Unfold", "(", "\n", "kernel_size", "=", "stride", ",", "dilation", "=", "1", ",", "padding", "=", "0", ",", "stride", "=", "stride", ")", "\n", "\n", "sample_dim", "=", "stride", "**", "2", "*", "in_channels", "\n", "\n", "if", "norm_cfg", "is", "not", "None", ":", "\n", "            ", "self", ".", "norm", "=", "build_norm_layer", "(", "norm_cfg", ",", "sample_dim", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "\n", "", "self", ".", "reduction", "=", "nn", ".", "Linear", "(", "sample_dim", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.PatchMerging.forward": [[66, 91], ["torch.pad.view().permute", "swin.PatchMerging.sampler", "torch.pad.transpose", "swin.PatchMerging.reduction", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "swin.PatchMerging.norm", "torch.pad.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "hw_shape", ")", ":", "\n", "        ", "\"\"\"\n        x: x.shape -> [B, H*W, C]\n        hw_shape: (H, W)\n        \"\"\"", "\n", "B", ",", "L", ",", "C", "=", "x", ".", "shape", "\n", "H", ",", "W", "=", "hw_shape", "\n", "assert", "L", "==", "H", "*", "W", ",", "'input feature has wrong size'", "\n", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", ".", "permute", "(", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "# B, C, H, W", "\n", "\n", "# stride is fixed to be equal to kernel_size.", "\n", "if", "(", "H", "%", "self", ".", "stride", "!=", "0", ")", "or", "(", "W", "%", "self", ".", "stride", "!=", "0", ")", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "W", "%", "self", ".", "stride", ",", "0", ",", "H", "%", "self", ".", "stride", ")", ")", "\n", "\n", "# Use nn.Unfold to merge patch. About 25% faster than original method,", "\n", "# but need to modify pretrained model for compatibility", "\n", "", "x", "=", "self", ".", "sampler", "(", "x", ")", "# B, 4*C, H/2*W/2", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# B, H/2*W/2, 4*C", "\n", "\n", "x", "=", "self", ".", "norm", "(", "x", ")", "if", "self", ".", "norm", "else", "x", "\n", "x", "=", "self", ".", "reduction", "(", "x", ")", "\n", "\n", "down_hw_shape", "=", "(", "H", "+", "1", ")", "//", "2", ",", "(", "W", "+", "1", ")", "//", "2", "\n", "return", "x", ",", "down_hw_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.WindowMSA.__init__": [[113, 149], ["mmcv.runner.base_module.BaseModule.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "swin.WindowMSA.double_step_seq", "rel_position_index.flip().contiguous.flip().contiguous.flip().contiguous", "swin.WindowMSA.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "rel_position_index.flip().contiguous.flip().contiguous.flip"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.WindowMSA.double_step_seq"], ["def", "__init__", "(", "self", ",", "\n", "embed_dims", ",", "\n", "num_heads", ",", "\n", "window_size", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "proj_drop_rate", "=", "0.", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dims", "=", "embed_dims", "\n", "self", ".", "window_size", "=", "window_size", "# Wh, Ww", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_embed_dims", "=", "embed_dims", "//", "num_heads", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_embed_dims", "**", "-", "0.5", "\n", "self", ".", "init_cfg", "=", "init_cfg", "\n", "\n", "# define a parameter table of relative position bias", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", ",", "\n", "num_heads", ")", ")", "# 2*Wh-1 * 2*Ww-1, nH", "\n", "\n", "# About 2x faster than original impl", "\n", "Wh", ",", "Ww", "=", "self", ".", "window_size", "\n", "rel_index_coords", "=", "self", ".", "double_step_seq", "(", "2", "*", "Ww", "-", "1", ",", "Wh", ",", "1", ",", "Ww", ")", "\n", "rel_position_index", "=", "rel_index_coords", "+", "rel_index_coords", ".", "T", "\n", "rel_position_index", "=", "rel_position_index", ".", "flip", "(", "1", ")", ".", "contiguous", "(", ")", "\n", "self", ".", "register_buffer", "(", "'relative_position_index'", ",", "rel_position_index", ")", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "embed_dims", ",", "embed_dims", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop_rate", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "embed_dims", ",", "embed_dims", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop_rate", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.WindowMSA.init_weights": [[150, 152], ["mmcv.cnn.trunc_normal_init"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "trunc_normal_init", "(", "self", ".", "relative_position_bias_table", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.WindowMSA.forward": [[153, 194], ["swin.WindowMSA.qkv().reshape().permute", "swin.WindowMSA.relative_position_bias_table[].view", "relative_position_bias.permute().contiguous.permute().contiguous.permute().contiguous", "swin.WindowMSA.attn_drop", "swin.WindowMSA.proj", "swin.WindowMSA.proj_drop", "k.transpose", "relative_position_bias.permute().contiguous.permute().contiguous.unsqueeze", "swin.WindowMSA.view", "swin.WindowMSA.softmax", "swin.WindowMSA.softmax", "swin.WindowMSA.qkv().reshape", "relative_position_bias.permute().contiguous.permute().contiguous.permute", "swin.WindowMSA.view", "mask.unsqueeze().unsqueeze", "swin.WindowMSA.qkv", "swin.WindowMSA.relative_position_index.view", "mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n\n            x (tensor): input features with shape of (num_windows*B, N, C)\n            mask (tensor | None, Optional): mask with shape of (num_windows,\n                Wh*Ww, Wh*Ww), value should be between (-inf, 0].\n        \"\"\"", "\n", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "\n", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "\n", "2", "]", "# make torchscript happy (cannot use tensor as tuple)", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "\n", "self", ".", "relative_position_index", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "\n", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "\n", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "\n", "-", "1", ")", "# Wh*Ww,Wh*Ww,nH", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "permute", "(", "\n", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "# nH, Wh*Ww, Wh*Ww", "\n", "attn", "=", "attn", "+", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "nW", "=", "mask", ".", "shape", "[", "0", "]", "\n", "attn", "=", "attn", ".", "view", "(", "B", "//", "nW", ",", "nW", ",", "self", ".", "num_heads", ",", "N", ",", "\n", "N", ")", "+", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "attn", "=", "attn", ".", "view", "(", "-", "1", ",", "self", ".", "num_heads", ",", "N", ",", "N", ")", "\n", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "\n", "", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.WindowMSA.double_step_seq": [[195, 200], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "double_step_seq", "(", "step1", ",", "len1", ",", "step2", ",", "len2", ")", ":", "\n", "        ", "seq1", "=", "torch", ".", "arange", "(", "0", ",", "step1", "*", "len1", ",", "step1", ")", "\n", "seq2", "=", "torch", ".", "arange", "(", "0", ",", "step2", "*", "len2", ",", "step2", ")", "\n", "return", "(", "seq1", "[", ":", ",", "None", "]", "+", "seq2", "[", "None", ",", ":", "]", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.__init__": [[226, 254], ["dict", "mmcv.runner.base_module.BaseModule.__init__", "swin.WindowMSA", "mmcv.cnn.bricks.transformer.build_dropout", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embed_dims", ",", "\n", "num_heads", ",", "\n", "window_size", ",", "\n", "shift_size", "=", "0", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "attn_drop_rate", "=", "0", ",", "\n", "proj_drop_rate", "=", "0", ",", "\n", "dropout_layer", "=", "dict", "(", "type", "=", "'DropPath'", ",", "drop_prob", "=", "0.", ")", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "shift_size", "=", "shift_size", "\n", "assert", "0", "<=", "self", ".", "shift_size", "<", "self", ".", "window_size", "\n", "\n", "self", ".", "w_msa", "=", "WindowMSA", "(", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "window_size", "=", "to_2tuple", "(", "window_size", ")", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "proj_drop_rate", "=", "proj_drop_rate", ",", "\n", "init_cfg", "=", "None", ")", "\n", "\n", "self", ".", "drop", "=", "build_dropout", "(", "dropout_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.forward": [[255, 331], ["torch.pad.view", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "swin.ShiftWindowMSA.window_partition", "query_windows.view.view.view", "swin.ShiftWindowMSA.w_msa", "attn_windows.view.view.view", "swin.ShiftWindowMSA.window_reverse", "x[].contiguous.view", "swin.ShiftWindowMSA.drop", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "swin.ShiftWindowMSA.window_partition", "mask_windows.view.view.view", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill().masked_fill", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "x[].contiguous", "slice", "slice", "slice", "slice", "slice", "slice", "mask_windows.view.view.unsqueeze", "mask_windows.view.view.unsqueeze", "float", "attn_mask.masked_fill().masked_fill.masked_fill().masked_fill.masked_fill", "float"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.window_partition", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.window_reverse", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.window_partition"], ["", "def", "forward", "(", "self", ",", "query", ",", "hw_shape", ")", ":", "\n", "        ", "B", ",", "L", ",", "C", "=", "query", ".", "shape", "\n", "H", ",", "W", "=", "hw_shape", "\n", "assert", "L", "==", "H", "*", "W", ",", "'input feature has wrong size'", "\n", "query", "=", "query", ".", "view", "(", "B", ",", "H", ",", "W", ",", "C", ")", "\n", "\n", "# pad feature maps to multiples of window size", "\n", "pad_r", "=", "(", "self", ".", "window_size", "-", "W", "%", "self", ".", "window_size", ")", "%", "self", ".", "window_size", "\n", "pad_b", "=", "(", "self", ".", "window_size", "-", "H", "%", "self", ".", "window_size", ")", "%", "self", ".", "window_size", "\n", "query", "=", "F", ".", "pad", "(", "query", ",", "(", "0", ",", "0", ",", "0", ",", "pad_r", ",", "0", ",", "pad_b", ")", ")", "\n", "H_pad", ",", "W_pad", "=", "query", ".", "shape", "[", "1", "]", ",", "query", ".", "shape", "[", "2", "]", "\n", "\n", "# cyclic shift", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "            ", "shifted_query", "=", "torch", ".", "roll", "(", "\n", "query", ",", "\n", "shifts", "=", "(", "-", "self", ".", "shift_size", ",", "-", "self", ".", "shift_size", ")", ",", "\n", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# calculate attention mask for SW-MSA", "\n", "img_mask", "=", "torch", ".", "zeros", "(", "(", "1", ",", "H_pad", ",", "W_pad", ",", "1", ")", ",", "\n", "device", "=", "query", ".", "device", ")", "# 1 H W 1", "\n", "h_slices", "=", "(", "slice", "(", "0", ",", "-", "self", ".", "window_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", ",", "\n", "-", "self", ".", "shift_size", ")", ",", "slice", "(", "-", "self", ".", "shift_size", ",", "None", ")", ")", "\n", "w_slices", "=", "(", "slice", "(", "0", ",", "-", "self", ".", "window_size", ")", ",", "\n", "slice", "(", "-", "self", ".", "window_size", ",", "\n", "-", "self", ".", "shift_size", ")", ",", "slice", "(", "-", "self", ".", "shift_size", ",", "None", ")", ")", "\n", "cnt", "=", "0", "\n", "for", "h", "in", "h_slices", ":", "\n", "                ", "for", "w", "in", "w_slices", ":", "\n", "                    ", "img_mask", "[", ":", ",", "h", ",", "w", ",", ":", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "# nW, window_size, window_size, 1", "\n", "", "", "mask_windows", "=", "self", ".", "window_partition", "(", "img_mask", ")", "\n", "mask_windows", "=", "mask_windows", ".", "view", "(", "\n", "-", "1", ",", "self", ".", "window_size", "*", "self", ".", "window_size", ")", "\n", "attn_mask", "=", "mask_windows", ".", "unsqueeze", "(", "1", ")", "-", "mask_windows", ".", "unsqueeze", "(", "2", ")", "\n", "attn_mask", "=", "attn_mask", ".", "masked_fill", "(", "attn_mask", "!=", "0", ",", "\n", "float", "(", "-", "100.0", ")", ")", ".", "masked_fill", "(", "\n", "attn_mask", "==", "0", ",", "float", "(", "0.0", ")", ")", "\n", "", "else", ":", "\n", "            ", "shifted_query", "=", "query", "\n", "attn_mask", "=", "None", "\n", "\n", "# nW*B, window_size, window_size, C", "\n", "", "query_windows", "=", "self", ".", "window_partition", "(", "shifted_query", ")", "\n", "# nW*B, window_size*window_size, C", "\n", "query_windows", "=", "query_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", "**", "2", ",", "C", ")", "\n", "\n", "# W-MSA/SW-MSA (nW*B, window_size*window_size, C)", "\n", "attn_windows", "=", "self", ".", "w_msa", "(", "query_windows", ",", "mask", "=", "attn_mask", ")", "\n", "\n", "# merge windows", "\n", "attn_windows", "=", "attn_windows", ".", "view", "(", "-", "1", ",", "self", ".", "window_size", ",", "\n", "self", ".", "window_size", ",", "C", ")", "\n", "\n", "# B H' W' C", "\n", "shifted_x", "=", "self", ".", "window_reverse", "(", "attn_windows", ",", "H_pad", ",", "W_pad", ")", "\n", "# reverse cyclic shift", "\n", "if", "self", ".", "shift_size", ">", "0", ":", "\n", "            ", "x", "=", "torch", ".", "roll", "(", "\n", "shifted_x", ",", "\n", "shifts", "=", "(", "self", ".", "shift_size", ",", "self", ".", "shift_size", ")", ",", "\n", "dims", "=", "(", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "shifted_x", "\n", "\n", "", "if", "pad_r", ">", "0", "or", "pad_b", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", "H", ",", ":", "W", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "B", ",", "H", "*", "W", ",", "C", ")", "\n", "\n", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.window_reverse": [[332, 348], ["int", "windows.view", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "x.permute().contiguous().view.permute().contiguous().view.permute"], "methods", ["None"], ["", "def", "window_reverse", "(", "self", ",", "windows", ",", "H", ",", "W", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            windows: (num_windows*B, window_size, window_size, C)\n            window_size (int): Window size\n            H (int): Height of image\n            W (int): Width of image\n        Returns:\n            x: (B, H, W, C)\n        \"\"\"", "\n", "window_size", "=", "self", ".", "window_size", "\n", "B", "=", "int", "(", "windows", ".", "shape", "[", "0", "]", "/", "(", "H", "*", "W", "/", "window_size", "/", "window_size", ")", ")", "\n", "x", "=", "windows", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "\n", "window_size", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.ShiftWindowMSA.window_partition": [[349, 364], ["x.view.view.view", "x.view.view.permute().contiguous", "windows.view.view.view", "x.view.view.permute"], "methods", ["None"], ["", "def", "window_partition", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: (B, H, W, C)\n            window_size (int): window size\n        Returns:\n            windows: (num_windows*B, window_size, window_size, C)\n        \"\"\"", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "window_size", "=", "self", ".", "window_size", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "window_size", ",", "W", "//", "window_size", ",", "\n", "window_size", ",", "C", ")", "\n", "windows", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", "\n", "windows", "=", "windows", ".", "view", "(", "-", "1", ",", "window_size", ",", "window_size", ",", "C", ")", "\n", "return", "windows", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinBlock.__init__": [[388, 430], ["dict", "dict", "mmcv.runner.base_module.BaseModule.__init__", "swin.ShiftWindowMSA", "mmcv.cnn.bricks.transformer.FFN", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embed_dims", ",", "\n", "num_heads", ",", "\n", "feedforward_channels", ",", "\n", "window_size", "=", "7", ",", "\n", "shift", "=", "False", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'GELU'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'LN'", ")", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "SwinBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "init_cfg", "=", "init_cfg", "\n", "\n", "self", ".", "norm1", "=", "build_norm_layer", "(", "norm_cfg", ",", "embed_dims", ")", "[", "1", "]", "\n", "self", ".", "attn", "=", "ShiftWindowMSA", "(", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "window_size", "=", "window_size", ",", "\n", "shift_size", "=", "window_size", "//", "2", "if", "shift", "else", "0", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "proj_drop_rate", "=", "drop_rate", ",", "\n", "dropout_layer", "=", "dict", "(", "type", "=", "'DropPath'", ",", "drop_prob", "=", "drop_path_rate", ")", ",", "\n", "init_cfg", "=", "None", ")", "\n", "\n", "self", ".", "norm2", "=", "build_norm_layer", "(", "norm_cfg", ",", "embed_dims", ")", "[", "1", "]", "\n", "self", ".", "ffn", "=", "FFN", "(", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "feedforward_channels", "=", "feedforward_channels", ",", "\n", "num_fcs", "=", "2", ",", "\n", "ffn_drop", "=", "drop_rate", ",", "\n", "dropout_layer", "=", "dict", "(", "type", "=", "'DropPath'", ",", "drop_prob", "=", "drop_path_rate", ")", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "add_identity", "=", "True", ",", "\n", "init_cfg", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinBlock.forward": [[431, 443], ["swin.SwinBlock.norm1", "swin.SwinBlock.attn", "swin.SwinBlock.norm2", "swin.SwinBlock.ffn"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.norm1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm2"], ["", "def", "forward", "(", "self", ",", "x", ",", "hw_shape", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x", "=", "self", ".", "attn", "(", "x", ",", "hw_shape", ")", "\n", "\n", "x", "=", "x", "+", "identity", "\n", "\n", "identity", "=", "x", "\n", "x", "=", "self", ".", "norm2", "(", "x", ")", "\n", "x", "=", "self", ".", "ffn", "(", "x", ",", "identity", "=", "identity", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinBlockSequence.__init__": [[470, 512], ["dict", "dict", "mmcv.runner.base_module.BaseModule.__init__", "mmcv.runner.base_module.ModuleList", "range", "isinstance", "swin.SwinBlock", "swin.SwinBlockSequence.blocks.append", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "embed_dims", ",", "\n", "num_heads", ",", "\n", "feedforward_channels", ",", "\n", "depth", ",", "\n", "window_size", "=", "7", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.", ",", "\n", "downsample", "=", "None", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'GELU'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'LN'", ")", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "init_cfg", "=", "init_cfg", "\n", "\n", "drop_path_rate", "=", "drop_path_rate", "if", "isinstance", "(", "\n", "drop_path_rate", ",", "\n", "list", ")", "else", "[", "deepcopy", "(", "drop_path_rate", ")", "for", "_", "in", "range", "(", "depth", ")", "]", "\n", "\n", "self", ".", "blocks", "=", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "depth", ")", ":", "\n", "            ", "block", "=", "SwinBlock", "(", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "feedforward_channels", "=", "feedforward_channels", ",", "\n", "window_size", "=", "window_size", ",", "\n", "shift", "=", "False", "if", "i", "%", "2", "==", "0", "else", "True", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "drop_path_rate", "[", "i", "]", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "init_cfg", "=", "None", ")", "\n", "self", ".", "blocks", ".", "append", "(", "block", ")", "\n", "\n", "", "self", ".", "downsample", "=", "downsample", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinBlockSequence.forward": [[513, 522], ["torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "torch.checkpoint", "swin.SwinBlockSequence.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "hw_shape", ")", ":", "\n", "        ", "for", "block", "in", "self", ".", "blocks", ":", "\n", "            ", "x", "=", "checkpoint", ".", "checkpoint", "(", "block", ",", "x", ",", "hw_shape", ")", "\n", "\n", "", "if", "self", ".", "downsample", ":", "\n", "            ", "x_down", ",", "down_hw_shape", "=", "self", ".", "downsample", "(", "x", ",", "hw_shape", ")", "\n", "return", "x_down", ",", "down_hw_shape", ",", "x", ",", "hw_shape", "\n", "", "else", ":", "\n", "            ", "return", "x", ",", "hw_shape", ",", "x", ",", "hw_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinTransformer.__init__": [[575, 694], ["dict", "dict", "mmcv.runner.base_module.BaseModule.__init__", "isinstance", "len", "utils.PatchEmbed", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "sum", "mmcv.runner.base_module.ModuleList", "range", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "isinstance", "isinstance", "warnings.warn", "TypeError", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "x.item", "swin.SwinBlockSequence", "swin.SwinTransformer.stages.append", "int", "swin.SwinTransformer.add_module", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "swin.PatchMerging", "range", "mmcv.cnn.build_norm_layer", "len", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "pretrain_img_size", "=", "224", ",", "\n", "in_channels", "=", "3", ",", "\n", "embed_dims", "=", "96", ",", "\n", "patch_size", "=", "4", ",", "\n", "window_size", "=", "7", ",", "\n", "mlp_ratio", "=", "4", ",", "\n", "depths", "=", "(", "2", ",", "2", ",", "6", ",", "2", ")", ",", "\n", "num_heads", "=", "(", "3", ",", "6", ",", "12", ",", "24", ")", ",", "\n", "strides", "=", "(", "4", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ")", ",", "\n", "qkv_bias", "=", "True", ",", "\n", "qk_scale", "=", "None", ",", "\n", "patch_norm", "=", "True", ",", "\n", "drop_rate", "=", "0.", ",", "\n", "attn_drop_rate", "=", "0.", ",", "\n", "drop_path_rate", "=", "0.1", ",", "\n", "use_abs_pos_embed", "=", "False", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'GELU'", ")", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'LN'", ")", ",", "\n", "pretrain_style", "=", "'official'", ",", "\n", "pretrained", "=", "None", ",", "\n", "init_cfg", "=", "None", ",", "\n", "output_missing_index_as_none", "=", "False", ")", ":", "\n", "        ", "super", "(", "SwinTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "isinstance", "(", "pretrain_img_size", ",", "int", ")", ":", "\n", "            ", "pretrain_img_size", "=", "to_2tuple", "(", "pretrain_img_size", ")", "\n", "", "elif", "isinstance", "(", "pretrain_img_size", ",", "tuple", ")", ":", "\n", "            ", "if", "len", "(", "pretrain_img_size", ")", "==", "1", ":", "\n", "                ", "pretrain_img_size", "=", "to_2tuple", "(", "pretrain_img_size", "[", "0", "]", ")", "\n", "", "assert", "len", "(", "pretrain_img_size", ")", "==", "2", ",", "f'The size of image should have length 1 or 2, '", "f'but got {len(pretrain_img_size)}'", "\n", "\n", "", "assert", "pretrain_style", "in", "[", "'official'", ",", "'mmcls'", "]", ",", "'We only support load '", "\n", "'official ckpt and mmcls ckpt.'", "\n", "\n", "if", "isinstance", "(", "pretrained", ",", "str", ")", "or", "pretrained", "is", "None", ":", "\n", "            ", "warnings", ".", "warn", "(", "'DeprecationWarning: pretrained is a deprecated, '", "\n", "'please use \"init_cfg\" instead'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n", "", "num_layers", "=", "len", "(", "depths", ")", "\n", "self", ".", "out_indices", "=", "out_indices", "\n", "self", ".", "use_abs_pos_embed", "=", "use_abs_pos_embed", "\n", "self", ".", "pretrain_style", "=", "pretrain_style", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "init_cfg", "=", "init_cfg", "\n", "\n", "assert", "strides", "[", "0", "]", "==", "patch_size", ",", "'Use non-overlapping patch embed.'", "\n", "\n", "self", ".", "patch_embed", "=", "PatchEmbed", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "embed_dims", "=", "embed_dims", ",", "\n", "conv_type", "=", "'Conv2d'", ",", "\n", "kernel_size", "=", "patch_size", ",", "\n", "stride", "=", "strides", "[", "0", "]", ",", "\n", "pad_to_patch_size", "=", "True", ",", "\n", "norm_cfg", "=", "norm_cfg", "if", "patch_norm", "else", "None", ",", "\n", "init_cfg", "=", "None", ")", "\n", "\n", "if", "self", ".", "use_abs_pos_embed", ":", "\n", "            ", "patch_row", "=", "pretrain_img_size", "[", "0", "]", "//", "patch_size", "\n", "patch_col", "=", "pretrain_img_size", "[", "1", "]", "//", "patch_size", "\n", "num_patches", "=", "patch_row", "*", "patch_col", "\n", "self", ".", "absolute_pos_embed", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "1", ",", "num_patches", ",", "embed_dims", ")", ")", ")", "\n", "\n", "", "self", ".", "drop_after_pos", "=", "nn", ".", "Dropout", "(", "p", "=", "drop_rate", ")", "\n", "\n", "# stochastic depth", "\n", "total_depth", "=", "sum", "(", "depths", ")", "\n", "dpr", "=", "[", "\n", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "total_depth", ")", "\n", "]", "# stochastic depth decay rule", "\n", "\n", "self", ".", "stages", "=", "ModuleList", "(", ")", "\n", "in_channels", "=", "embed_dims", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "if", "i", "<", "num_layers", "-", "1", ":", "\n", "                ", "downsample", "=", "PatchMerging", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "2", "*", "in_channels", ",", "\n", "stride", "=", "strides", "[", "i", "+", "1", "]", ",", "\n", "norm_cfg", "=", "norm_cfg", "if", "patch_norm", "else", "None", ",", "\n", "init_cfg", "=", "None", ")", "\n", "", "else", ":", "\n", "                ", "downsample", "=", "None", "\n", "\n", "", "stage", "=", "SwinBlockSequence", "(", "\n", "embed_dims", "=", "in_channels", ",", "\n", "num_heads", "=", "num_heads", "[", "i", "]", ",", "\n", "feedforward_channels", "=", "mlp_ratio", "*", "in_channels", ",", "\n", "depth", "=", "depths", "[", "i", "]", ",", "\n", "window_size", "=", "window_size", ",", "\n", "qkv_bias", "=", "qkv_bias", ",", "\n", "qk_scale", "=", "qk_scale", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "attn_drop_rate", "=", "attn_drop_rate", ",", "\n", "drop_path_rate", "=", "dpr", "[", ":", "depths", "[", "i", "]", "]", ",", "\n", "downsample", "=", "downsample", ",", "\n", "act_cfg", "=", "act_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "init_cfg", "=", "None", ")", "\n", "self", ".", "stages", ".", "append", "(", "stage", ")", "\n", "\n", "dpr", "=", "dpr", "[", "depths", "[", "i", "]", ":", "]", "\n", "if", "downsample", ":", "\n", "                ", "in_channels", "=", "downsample", ".", "out_channels", "\n", "\n", "", "", "self", ".", "num_features", "=", "[", "int", "(", "embed_dims", "*", "2", "**", "i", ")", "for", "i", "in", "range", "(", "num_layers", ")", "]", "\n", "# Add a norm layer for each output", "\n", "for", "i", "in", "out_indices", ":", "\n", "            ", "layer", "=", "build_norm_layer", "(", "norm_cfg", ",", "self", ".", "num_features", "[", "i", "]", ")", "[", "1", "]", "\n", "layer_name", "=", "f'norm{i}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "layer", ")", "\n", "", "self", ".", "output_missing_index_as_none", "=", "output_missing_index_as_none", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinTransformer.init_weights": [[695, 763], ["super().init_weights", "swin.SwinTransformer.modules", "isinstance", "mmcv.cnn.trunc_normal_init", "isinstance", "utils.get_root_logger", "mmcv.runner._load_checkpoint", "[].startswith", "swin.SwinTransformer.load_state_dict", "mmcv.cnn.trunc_normal_init", "isinstance", "utils.swin_convert", "utils.swin_convert.get", "absolute_pos_embed.size", "swin.SwinTransformer.absolute_pos_embed.size", "table_pretrained.size", "table_current.size", "mmcv.cnn.utils.weight_init.constant_init", "mmcv.cnn.utils.weight_init.constant_init", "mmcv.cnn.utils.weight_init.constant_init", "utils.get_root_logger.warning", "absolute_pos_embed.view().permute().contiguous", "utils.swin_convert.keys", "swin.SwinTransformer.state_dict", "utils.get_root_logger.warning", "list", "utils.swin_convert.items", "int", "int", "mmseg.ops.resize", "mmseg.ops.resize.view().permute().contiguous", "utils.swin_convert.keys", "absolute_pos_embed.view().permute", "table_pretrained.permute().reshape", "mmseg.ops.resize.view().permute", "absolute_pos_embed.view", "table_pretrained.permute", "mmseg.ops.resize.view"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinTransformer.init_weights", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.ckpt_convert.swin_convert", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "pretrained", "is", "None", ":", "\n", "            ", "super", "(", ")", ".", "init_weights", "(", ")", "\n", "if", "self", ".", "use_abs_pos_embed", ":", "\n", "                ", "trunc_normal_init", "(", "self", ".", "absolute_pos_embed", ",", "std", "=", "0.02", ")", "\n", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Linear", ")", ":", "\n", "                    ", "trunc_normal_init", "(", "m", ".", "weight", ",", "std", "=", ".02", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                        ", "constant_init", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "LayerNorm", ")", ":", "\n", "                    ", "constant_init", "(", "m", ".", "bias", ",", "0", ")", "\n", "constant_init", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "", "", "", "elif", "isinstance", "(", "self", ".", "pretrained", ",", "str", ")", ":", "\n", "            ", "logger", "=", "get_root_logger", "(", ")", "\n", "ckpt", "=", "_load_checkpoint", "(", "\n", "self", ".", "pretrained", ",", "logger", "=", "logger", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'state_dict'", "in", "ckpt", ":", "\n", "                ", "state_dict", "=", "ckpt", "[", "'state_dict'", "]", "\n", "", "elif", "'model'", "in", "ckpt", ":", "\n", "                ", "state_dict", "=", "ckpt", "[", "'model'", "]", "\n", "", "else", ":", "\n", "                ", "state_dict", "=", "ckpt", "\n", "\n", "", "if", "self", ".", "pretrain_style", "==", "'official'", ":", "\n", "                ", "state_dict", "=", "swin_convert", "(", "state_dict", ")", "\n", "\n", "# strip prefix of state_dict", "\n", "", "if", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "[", "0", "]", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                ", "state_dict", "=", "{", "k", "[", "7", ":", "]", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "\n", "# reshape absolute position embedding", "\n", "", "if", "state_dict", ".", "get", "(", "'absolute_pos_embed'", ")", "is", "not", "None", ":", "\n", "                ", "absolute_pos_embed", "=", "state_dict", "[", "'absolute_pos_embed'", "]", "\n", "N1", ",", "L", ",", "C1", "=", "absolute_pos_embed", ".", "size", "(", ")", "\n", "N2", ",", "C2", ",", "H", ",", "W", "=", "self", ".", "absolute_pos_embed", ".", "size", "(", ")", "\n", "if", "N1", "!=", "N2", "or", "C1", "!=", "C2", "or", "L", "!=", "H", "*", "W", ":", "\n", "                    ", "logger", ".", "warning", "(", "'Error in loading absolute_pos_embed, pass'", ")", "\n", "", "else", ":", "\n", "                    ", "state_dict", "[", "'absolute_pos_embed'", "]", "=", "absolute_pos_embed", ".", "view", "(", "\n", "N2", ",", "H", ",", "W", ",", "C2", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# interpolate position bias table if needed", "\n", "", "", "relative_position_bias_table_keys", "=", "[", "\n", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "\n", "if", "'relative_position_bias_table'", "in", "k", "\n", "]", "\n", "for", "table_key", "in", "relative_position_bias_table_keys", ":", "\n", "                ", "table_pretrained", "=", "state_dict", "[", "table_key", "]", "\n", "table_current", "=", "self", ".", "state_dict", "(", ")", "[", "table_key", "]", "\n", "L1", ",", "nH1", "=", "table_pretrained", ".", "size", "(", ")", "\n", "L2", ",", "nH2", "=", "table_current", ".", "size", "(", ")", "\n", "if", "nH1", "!=", "nH2", ":", "\n", "                    ", "logger", ".", "warning", "(", "f'Error in loading {table_key}, pass'", ")", "\n", "", "else", ":", "\n", "                    ", "if", "L1", "!=", "L2", ":", "\n", "                        ", "S1", "=", "int", "(", "L1", "**", "0.5", ")", "\n", "S2", "=", "int", "(", "L2", "**", "0.5", ")", "\n", "table_pretrained_resized", "=", "resize", "(", "\n", "table_pretrained", ".", "permute", "(", "1", ",", "0", ")", ".", "reshape", "(", "\n", "1", ",", "nH1", ",", "S1", ",", "S1", ")", ",", "\n", "size", "=", "(", "S2", ",", "S2", ")", ",", "\n", "mode", "=", "'bicubic'", ")", "\n", "state_dict", "[", "table_key", "]", "=", "table_pretrained_resized", ".", "view", "(", "\n", "nH2", ",", "L2", ")", ".", "permute", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "\n", "# load state_dict", "\n", "", "", "", "self", ".", "load_state_dict", "(", "state_dict", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinTransformer.forward": [[764, 785], ["swin.SwinTransformer.patch_embed", "swin.SwinTransformer.drop_after_pos", "enumerate", "stage", "getattr", "getattr.", "out.view().permute().contiguous.view().permute().contiguous.view().permute().contiguous", "outs.append", "outs.append", "out.view().permute().contiguous.view().permute().contiguous.view().permute", "out.view().permute().contiguous.view().permute().contiguous.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "patch_embed", "(", "x", ")", "\n", "\n", "hw_shape", "=", "(", "self", ".", "patch_embed", ".", "DH", ",", "self", ".", "patch_embed", ".", "DW", ")", "\n", "if", "self", ".", "use_abs_pos_embed", ":", "\n", "            ", "x", "=", "x", "+", "self", ".", "absolute_pos_embed", "\n", "", "x", "=", "self", ".", "drop_after_pos", "(", "x", ")", "\n", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "stage", "in", "enumerate", "(", "self", ".", "stages", ")", ":", "\n", "            ", "x", ",", "hw_shape", ",", "out", ",", "out_hw_shape", "=", "stage", "(", "x", ",", "hw_shape", ")", "\n", "if", "i", "in", "self", ".", "out_indices", ":", "\n", "                ", "norm_layer", "=", "getattr", "(", "self", ",", "f'norm{i}'", ")", "\n", "out", "=", "norm_layer", "(", "out", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "*", "out_hw_shape", ",", "\n", "self", ".", "num_features", "[", "i", "]", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "\n", "2", ")", ".", "contiguous", "(", ")", "\n", "outs", ".", "append", "(", "out", ")", "\n", "", "elif", "self", ".", "output_missing_index_as_none", ":", "\n", "                ", "outs", ".", "append", "(", "None", ")", "\n", "", "", "return", "outs", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.BasicBlock.__init__": [[19, 58], ["dict", "mmcv.runner.BaseModule.__init__", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_conv_layer", "resnet.BasicBlock.add_module", "mmcv.cnn.build_conv_layer", "resnet.BasicBlock.add_module", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "with_cp", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "dcn", "=", "None", ",", "\n", "plugins", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "assert", "dcn", "is", "None", ",", "'Not implemented yet.'", "\n", "assert", "plugins", "is", "None", ",", "'Not implemented yet.'", "\n", "\n", "self", ".", "norm1_name", ",", "norm1", "=", "build_norm_layer", "(", "norm_cfg", ",", "planes", ",", "postfix", "=", "1", ")", "\n", "self", ".", "norm2_name", ",", "norm2", "=", "build_norm_layer", "(", "norm_cfg", ",", "planes", ",", "postfix", "=", "2", ")", "\n", "\n", "self", ".", "conv1", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm1_name", ",", "norm1", ")", "\n", "self", ".", "conv2", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "planes", ",", "planes", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm2_name", ",", "norm2", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.BasicBlock.norm1": [[59, 63], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm1", "(", "self", ")", ":", "\n", "        ", "\"\"\"nn.Module: normalization layer after the first convolution layer\"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm1_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.BasicBlock.norm2": [[64, 68], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm2", "(", "self", ")", ":", "\n", "        ", "\"\"\"nn.Module: normalization layer after the second convolution layer\"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm2_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.BasicBlock.forward": [[69, 97], ["resnet.BasicBlock.relu", "resnet.BasicBlock.conv1", "resnet.BasicBlock.norm1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.norm2", "torch.checkpoint", "torch.checkpoint", "resnet.BasicBlock.forward._inner_forward"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.norm1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm2"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "\n", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "norm1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "norm2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.__init__": [[108, 221], ["dict", "mmcv.runner.BaseModule.__init__", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_conv_layer", "resnet.Bottleneck.add_module", "resnet.Bottleneck.add_module", "mmcv.cnn.build_conv_layer", "resnet.Bottleneck.add_module", "torch.ReLU", "torch.ReLU", "isinstance", "isinstance", "all", "dcn.pop", "mmcv.cnn.build_conv_layer", "mmcv.cnn.build_conv_layer", "resnet.Bottleneck.make_block_plugins", "resnet.Bottleneck.make_block_plugins", "resnet.Bottleneck.make_block_plugins"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.make_block_plugins", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.make_block_plugins", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.make_block_plugins"], ["def", "__init__", "(", "self", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "\n", "downsample", "=", "None", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "with_cp", "=", "False", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ")", ",", "\n", "dcn", "=", "None", ",", "\n", "plugins", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "assert", "style", "in", "[", "'pytorch'", ",", "'caffe'", "]", "\n", "assert", "dcn", "is", "None", "or", "isinstance", "(", "dcn", ",", "dict", ")", "\n", "assert", "plugins", "is", "None", "or", "isinstance", "(", "plugins", ",", "list", ")", "\n", "if", "plugins", "is", "not", "None", ":", "\n", "            ", "allowed_position", "=", "[", "'after_conv1'", ",", "'after_conv2'", ",", "'after_conv3'", "]", "\n", "assert", "all", "(", "p", "[", "'position'", "]", "in", "allowed_position", "for", "p", "in", "plugins", ")", "\n", "\n", "", "self", ".", "inplanes", "=", "inplanes", "\n", "self", ".", "planes", "=", "planes", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "dcn", "=", "dcn", "\n", "self", ".", "with_dcn", "=", "dcn", "is", "not", "None", "\n", "self", ".", "plugins", "=", "plugins", "\n", "self", ".", "with_plugins", "=", "plugins", "is", "not", "None", "\n", "\n", "if", "self", ".", "with_plugins", ":", "\n", "# collect plugins for conv1/conv2/conv3", "\n", "            ", "self", ".", "after_conv1_plugins", "=", "[", "\n", "plugin", "[", "'cfg'", "]", "for", "plugin", "in", "plugins", "\n", "if", "plugin", "[", "'position'", "]", "==", "'after_conv1'", "\n", "]", "\n", "self", ".", "after_conv2_plugins", "=", "[", "\n", "plugin", "[", "'cfg'", "]", "for", "plugin", "in", "plugins", "\n", "if", "plugin", "[", "'position'", "]", "==", "'after_conv2'", "\n", "]", "\n", "self", ".", "after_conv3_plugins", "=", "[", "\n", "plugin", "[", "'cfg'", "]", "for", "plugin", "in", "plugins", "\n", "if", "plugin", "[", "'position'", "]", "==", "'after_conv3'", "\n", "]", "\n", "\n", "", "if", "self", ".", "style", "==", "'pytorch'", ":", "\n", "            ", "self", ".", "conv1_stride", "=", "1", "\n", "self", ".", "conv2_stride", "=", "stride", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1_stride", "=", "stride", "\n", "self", ".", "conv2_stride", "=", "1", "\n", "\n", "", "self", ".", "norm1_name", ",", "norm1", "=", "build_norm_layer", "(", "norm_cfg", ",", "planes", ",", "postfix", "=", "1", ")", "\n", "self", ".", "norm2_name", ",", "norm2", "=", "build_norm_layer", "(", "norm_cfg", ",", "planes", ",", "postfix", "=", "2", ")", "\n", "self", ".", "norm3_name", ",", "norm3", "=", "build_norm_layer", "(", "\n", "norm_cfg", ",", "planes", "*", "self", ".", "expansion", ",", "postfix", "=", "3", ")", "\n", "\n", "self", ".", "conv1", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "inplanes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "self", ".", "conv1_stride", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm1_name", ",", "norm1", ")", "\n", "fallback_on_stride", "=", "False", "\n", "if", "self", ".", "with_dcn", ":", "\n", "            ", "fallback_on_stride", "=", "dcn", ".", "pop", "(", "'fallback_on_stride'", ",", "False", ")", "\n", "", "if", "not", "self", ".", "with_dcn", "or", "fallback_on_stride", ":", "\n", "            ", "self", ".", "conv2", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "planes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "self", ".", "conv2_stride", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "conv_cfg", "is", "None", ",", "'conv_cfg must be None for DCN'", "\n", "self", ".", "conv2", "=", "build_conv_layer", "(", "\n", "dcn", ",", "\n", "planes", ",", "\n", "planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "self", ".", "conv2_stride", ",", "\n", "padding", "=", "dilation", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "add_module", "(", "self", ".", "norm2_name", ",", "norm2", ")", "\n", "self", ".", "conv3", "=", "build_conv_layer", "(", "\n", "conv_cfg", ",", "\n", "planes", ",", "\n", "planes", "*", "self", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm3_name", ",", "norm3", ")", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n", "if", "self", ".", "with_plugins", ":", "\n", "            ", "self", ".", "after_conv1_plugin_names", "=", "self", ".", "make_block_plugins", "(", "\n", "planes", ",", "self", ".", "after_conv1_plugins", ")", "\n", "self", ".", "after_conv2_plugin_names", "=", "self", ".", "make_block_plugins", "(", "\n", "planes", ",", "self", ".", "after_conv2_plugins", ")", "\n", "self", ".", "after_conv3_plugin_names", "=", "self", ".", "make_block_plugins", "(", "\n", "planes", "*", "self", ".", "expansion", ",", "self", ".", "after_conv3_plugins", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.make_block_plugins": [[222, 244], ["isinstance", "plugin.copy.copy.copy", "mmcv.cnn.build_plugin_layer", "resnet.Bottleneck.add_module", "plugin_names.append", "hasattr", "plugin.copy.copy.pop"], "methods", ["None"], ["", "", "def", "make_block_plugins", "(", "self", ",", "in_channels", ",", "plugins", ")", ":", "\n", "        ", "\"\"\"make plugins for block.\n\n        Args:\n            in_channels (int): Input channels of plugin.\n            plugins (list[dict]): List of plugins cfg to build.\n\n        Returns:\n            list[str]: List of the names of plugin.\n        \"\"\"", "\n", "assert", "isinstance", "(", "plugins", ",", "list", ")", "\n", "plugin_names", "=", "[", "]", "\n", "for", "plugin", "in", "plugins", ":", "\n", "            ", "plugin", "=", "plugin", ".", "copy", "(", ")", "\n", "name", ",", "layer", "=", "build_plugin_layer", "(", "\n", "plugin", ",", "\n", "in_channels", "=", "in_channels", ",", "\n", "postfix", "=", "plugin", ".", "pop", "(", "'postfix'", ",", "''", ")", ")", "\n", "assert", "not", "hasattr", "(", "self", ",", "name", ")", ",", "f'duplicate plugin {name}'", "\n", "self", ".", "add_module", "(", "name", ",", "layer", ")", "\n", "plugin_names", ".", "append", "(", "name", ")", "\n", "", "return", "plugin_names", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.forward_plugin": [[245, 251], ["getattr"], "methods", ["None"], ["", "def", "forward_plugin", "(", "self", ",", "x", ",", "plugin_names", ")", ":", "\n", "        ", "\"\"\"Forward function for plugins.\"\"\"", "\n", "out", "=", "x", "\n", "for", "name", "in", "plugin_names", ":", "\n", "            ", "out", "=", "getattr", "(", "self", ",", "name", ")", "(", "x", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm1": [[252, 256], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm1", "(", "self", ")", ":", "\n", "        ", "\"\"\"nn.Module: normalization layer after the first convolution layer\"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm1_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm2": [[257, 261], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm2", "(", "self", ")", ":", "\n", "        ", "\"\"\"nn.Module: normalization layer after the second convolution layer\"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm2_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm3": [[262, 266], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm3", "(", "self", ")", ":", "\n", "        ", "\"\"\"nn.Module: normalization layer after the third convolution layer\"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm3_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.forward": [[267, 308], ["resnet.Bottleneck.relu", "resnet.Bottleneck.conv1", "resnet.Bottleneck.norm1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.norm2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.norm3", "torch.checkpoint", "torch.checkpoint", "resnet.Bottleneck.forward._inner_forward"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.norm1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm2", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.Bottleneck.norm3"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "\n", "def", "_inner_forward", "(", "x", ")", ":", "\n", "            ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "norm1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "if", "self", ".", "with_plugins", ":", "\n", "                ", "out", "=", "self", ".", "forward_plugin", "(", "out", ",", "self", ".", "after_conv1_plugin_names", ")", "\n", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "norm2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "if", "self", ".", "with_plugins", ":", "\n", "                ", "out", "=", "self", ".", "forward_plugin", "(", "out", ",", "self", ".", "after_conv2_plugin_names", ")", "\n", "\n", "", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "norm3", "(", "out", ")", "\n", "\n", "if", "self", ".", "with_plugins", ":", "\n", "                ", "out", "=", "self", ".", "forward_plugin", "(", "out", ",", "self", ".", "after_conv3_plugin_names", ")", "\n", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "                ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "\n", "return", "out", "\n", "\n", "", "if", "self", ".", "with_cp", "and", "x", ".", "requires_grad", ":", "\n", "            ", "out", "=", "cp", ".", "checkpoint", "(", "_inner_forward", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "_inner_forward", "(", "x", ")", "\n", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.__init__": [[396, 528], ["dict", "mmcv.runner.BaseModule.__init__", "isinstance", "resnet.ResNet._make_stem_layer", "enumerate", "resnet.ResNet._freeze_stages", "KeyError", "warnings.warn", "dict", "len", "len", "max", "resnet.ResNet.make_res_layer", "resnet.ResNet.add_module", "resnet.ResNet.res_layers.append", "TypeError", "len", "resnet.ResNet.make_stage_plugins", "len", "dict", "dict", "len", "dict", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet._make_stem_layer", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet._freeze_stages", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.make_res_layer", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.make_stage_plugins"], ["def", "__init__", "(", "self", ",", "\n", "depth", ",", "\n", "in_channels", "=", "3", ",", "\n", "stem_channels", "=", "64", ",", "\n", "base_channels", "=", "64", ",", "\n", "num_stages", "=", "4", ",", "\n", "strides", "=", "(", "1", ",", "2", ",", "2", ",", "2", ")", ",", "\n", "dilations", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "out_indices", "=", "(", "0", ",", "1", ",", "2", ",", "3", ")", ",", "\n", "style", "=", "'pytorch'", ",", "\n", "deep_stem", "=", "False", ",", "\n", "avg_down", "=", "False", ",", "\n", "frozen_stages", "=", "-", "1", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "dict", "(", "type", "=", "'BN'", ",", "requires_grad", "=", "True", ")", ",", "\n", "norm_eval", "=", "False", ",", "\n", "dcn", "=", "None", ",", "\n", "stage_with_dcn", "=", "(", "False", ",", "False", ",", "False", ",", "False", ")", ",", "\n", "plugins", "=", "None", ",", "\n", "multi_grid", "=", "None", ",", "\n", "contract_dilation", "=", "False", ",", "\n", "with_cp", "=", "False", ",", "\n", "zero_init_residual", "=", "True", ",", "\n", "pretrained", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "if", "depth", "not", "in", "self", ".", "arch_settings", ":", "\n", "            ", "raise", "KeyError", "(", "f'invalid depth {depth} for resnet'", ")", "\n", "\n", "", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "zero_init_residual", "=", "zero_init_residual", "\n", "block_init_cfg", "=", "None", "\n", "assert", "not", "(", "init_cfg", "and", "pretrained", ")", ",", "'init_cfg and pretrained cannot be setting at the same time'", "\n", "if", "isinstance", "(", "pretrained", ",", "str", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "'DeprecationWarning: pretrained is a deprecated, '", "\n", "'please use \"init_cfg\" instead'", ")", "\n", "self", ".", "init_cfg", "=", "dict", "(", "type", "=", "'Pretrained'", ",", "checkpoint", "=", "pretrained", ")", "\n", "", "elif", "pretrained", "is", "None", ":", "\n", "            ", "if", "init_cfg", "is", "None", ":", "\n", "                ", "self", ".", "init_cfg", "=", "[", "\n", "dict", "(", "type", "=", "'Kaiming'", ",", "layer", "=", "'Conv2d'", ")", ",", "\n", "dict", "(", "\n", "type", "=", "'Constant'", ",", "\n", "val", "=", "1", ",", "\n", "layer", "=", "[", "'_BatchNorm'", ",", "'GroupNorm'", "]", ")", "\n", "]", "\n", "block", "=", "self", ".", "arch_settings", "[", "depth", "]", "[", "0", "]", "\n", "if", "self", ".", "zero_init_residual", ":", "\n", "                    ", "if", "block", "is", "BasicBlock", ":", "\n", "                        ", "block_init_cfg", "=", "dict", "(", "\n", "type", "=", "'Constant'", ",", "\n", "val", "=", "0", ",", "\n", "override", "=", "dict", "(", "name", "=", "'norm2'", ")", ")", "\n", "", "elif", "block", "is", "Bottleneck", ":", "\n", "                        ", "block_init_cfg", "=", "dict", "(", "\n", "type", "=", "'Constant'", ",", "\n", "val", "=", "0", ",", "\n", "override", "=", "dict", "(", "name", "=", "'norm3'", ")", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "'pretrained must be a str or None'", ")", "\n", "\n", "", "self", ".", "depth", "=", "depth", "\n", "self", ".", "stem_channels", "=", "stem_channels", "\n", "self", ".", "base_channels", "=", "base_channels", "\n", "self", ".", "num_stages", "=", "num_stages", "\n", "assert", "num_stages", ">=", "1", "and", "num_stages", "<=", "4", "\n", "self", ".", "strides", "=", "strides", "\n", "self", ".", "dilations", "=", "dilations", "\n", "assert", "len", "(", "strides", ")", "==", "len", "(", "dilations", ")", "==", "num_stages", "\n", "self", ".", "out_indices", "=", "out_indices", "\n", "assert", "max", "(", "out_indices", ")", "<", "num_stages", "\n", "self", ".", "style", "=", "style", "\n", "self", ".", "deep_stem", "=", "deep_stem", "\n", "self", ".", "avg_down", "=", "avg_down", "\n", "self", ".", "frozen_stages", "=", "frozen_stages", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "with_cp", "=", "with_cp", "\n", "self", ".", "norm_eval", "=", "norm_eval", "\n", "self", ".", "dcn", "=", "dcn", "\n", "self", ".", "stage_with_dcn", "=", "stage_with_dcn", "\n", "if", "dcn", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "stage_with_dcn", ")", "==", "num_stages", "\n", "", "self", ".", "plugins", "=", "plugins", "\n", "self", ".", "multi_grid", "=", "multi_grid", "\n", "self", ".", "contract_dilation", "=", "contract_dilation", "\n", "self", ".", "block", ",", "stage_blocks", "=", "self", ".", "arch_settings", "[", "depth", "]", "\n", "self", ".", "stage_blocks", "=", "stage_blocks", "[", ":", "num_stages", "]", "\n", "self", ".", "inplanes", "=", "stem_channels", "\n", "\n", "self", ".", "_make_stem_layer", "(", "in_channels", ",", "stem_channels", ")", "\n", "\n", "self", ".", "res_layers", "=", "[", "]", "\n", "for", "i", ",", "num_blocks", "in", "enumerate", "(", "self", ".", "stage_blocks", ")", ":", "\n", "            ", "stride", "=", "strides", "[", "i", "]", "\n", "dilation", "=", "dilations", "[", "i", "]", "\n", "dcn", "=", "self", ".", "dcn", "if", "self", ".", "stage_with_dcn", "[", "i", "]", "else", "None", "\n", "if", "plugins", "is", "not", "None", ":", "\n", "                ", "stage_plugins", "=", "self", ".", "make_stage_plugins", "(", "plugins", ",", "i", ")", "\n", "", "else", ":", "\n", "                ", "stage_plugins", "=", "None", "\n", "# multi grid is applied to last layer only", "\n", "", "stage_multi_grid", "=", "multi_grid", "if", "i", "==", "len", "(", "\n", "self", ".", "stage_blocks", ")", "-", "1", "else", "None", "\n", "planes", "=", "base_channels", "*", "2", "**", "i", "\n", "res_layer", "=", "self", ".", "make_res_layer", "(", "\n", "block", "=", "self", ".", "block", ",", "\n", "inplanes", "=", "self", ".", "inplanes", ",", "\n", "planes", "=", "planes", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "dilation", ",", "\n", "style", "=", "self", ".", "style", ",", "\n", "avg_down", "=", "self", ".", "avg_down", ",", "\n", "with_cp", "=", "with_cp", ",", "\n", "conv_cfg", "=", "conv_cfg", ",", "\n", "norm_cfg", "=", "norm_cfg", ",", "\n", "dcn", "=", "dcn", ",", "\n", "plugins", "=", "stage_plugins", ",", "\n", "multi_grid", "=", "stage_multi_grid", ",", "\n", "contract_dilation", "=", "contract_dilation", ",", "\n", "init_cfg", "=", "block_init_cfg", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "self", ".", "block", ".", "expansion", "\n", "layer_name", "=", "f'layer{i+1}'", "\n", "self", ".", "add_module", "(", "layer_name", ",", "res_layer", ")", "\n", "self", ".", "res_layers", ".", "append", "(", "layer_name", ")", "\n", "\n", "", "self", ".", "_freeze_stages", "(", ")", "\n", "\n", "self", ".", "feat_dim", "=", "self", ".", "block", ".", "expansion", "*", "base_channels", "*", "2", "**", "(", "\n", "len", "(", "self", ".", "stage_blocks", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.make_stage_plugins": [[529, 581], ["plugin.copy.copy.copy", "plugin.copy.copy.pop", "stage_plugins.append", "len"], "methods", ["None"], ["", "def", "make_stage_plugins", "(", "self", ",", "plugins", ",", "stage_idx", ")", ":", "\n", "        ", "\"\"\"make plugins for ResNet 'stage_idx'th stage .\n\n        Currently we support to insert 'context_block',\n        'empirical_attention_block', 'nonlocal_block' into the backbone like\n        ResNet/ResNeXt. They could be inserted after conv1/conv2/conv3 of\n        Bottleneck.\n\n        An example of plugins format could be :\n        >>> plugins=[\n        ...     dict(cfg=dict(type='xxx', arg1='xxx'),\n        ...          stages=(False, True, True, True),\n        ...          position='after_conv2'),\n        ...     dict(cfg=dict(type='yyy'),\n        ...          stages=(True, True, True, True),\n        ...          position='after_conv3'),\n        ...     dict(cfg=dict(type='zzz', postfix='1'),\n        ...          stages=(True, True, True, True),\n        ...          position='after_conv3'),\n        ...     dict(cfg=dict(type='zzz', postfix='2'),\n        ...          stages=(True, True, True, True),\n        ...          position='after_conv3')\n        ... ]\n        >>> self = ResNet(depth=18)\n        >>> stage_plugins = self.make_stage_plugins(plugins, 0)\n        >>> assert len(stage_plugins) == 3\n\n        Suppose 'stage_idx=0', the structure of blocks in the stage would be:\n            conv1-> conv2->conv3->yyy->zzz1->zzz2\n        Suppose 'stage_idx=1', the structure of blocks in the stage would be:\n            conv1-> conv2->xxx->conv3->yyy->zzz1->zzz2\n\n        If stages is missing, the plugin would be applied to all stages.\n\n        Args:\n            plugins (list[dict]): List of plugins cfg to build. The postfix is\n                required if multiple same type plugins are inserted.\n            stage_idx (int): Index of stage to build\n\n        Returns:\n            list[dict]: Plugins for current stage\n        \"\"\"", "\n", "stage_plugins", "=", "[", "]", "\n", "for", "plugin", "in", "plugins", ":", "\n", "            ", "plugin", "=", "plugin", ".", "copy", "(", ")", "\n", "stages", "=", "plugin", ".", "pop", "(", "'stages'", ",", "None", ")", "\n", "assert", "stages", "is", "None", "or", "len", "(", "stages", ")", "==", "self", ".", "num_stages", "\n", "# whether to insert plugin into current stage", "\n", "if", "stages", "is", "None", "or", "stages", "[", "stage_idx", "]", ":", "\n", "                ", "stage_plugins", ".", "append", "(", "plugin", ")", "\n", "\n", "", "", "return", "stage_plugins", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.make_res_layer": [[582, 585], ["utils.ResLayer"], "methods", ["None"], ["", "def", "make_res_layer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Pack all blocks in a stage into a ``ResLayer``.\"\"\"", "\n", "return", "ResLayer", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.norm1": [[586, 590], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "norm1", "(", "self", ")", ":", "\n", "        ", "\"\"\"nn.Module: the normalization layer named \"norm1\" \"\"\"", "\n", "return", "getattr", "(", "self", ",", "self", ".", "norm1_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet._make_stem_layer": [[591, 639], ["torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "mmcv.cnn.build_conv_layer", "mmcv.cnn.build_norm_layer", "resnet.ResNet.add_module", "torch.ReLU", "torch.ReLU", "mmcv.cnn.build_conv_layer", "torch.ReLU", "torch.ReLU", "mmcv.cnn.build_conv_layer", "torch.ReLU", "torch.ReLU", "mmcv.cnn.build_conv_layer", "torch.ReLU", "torch.ReLU", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer", "mmcv.cnn.build_norm_layer"], "methods", ["None"], ["", "def", "_make_stem_layer", "(", "self", ",", "in_channels", ",", "stem_channels", ")", ":", "\n", "        ", "\"\"\"Make stem layer for ResNet.\"\"\"", "\n", "if", "self", ".", "deep_stem", ":", "\n", "            ", "self", ".", "stem", "=", "nn", ".", "Sequential", "(", "\n", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "in_channels", ",", "\n", "stem_channels", "//", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "stem_channels", "//", "2", ")", "[", "1", "]", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "stem_channels", "//", "2", ",", "\n", "stem_channels", "//", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "stem_channels", "//", "2", ")", "[", "1", "]", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "stem_channels", "//", "2", ",", "\n", "stem_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", ",", "\n", "build_norm_layer", "(", "self", ".", "norm_cfg", ",", "stem_channels", ")", "[", "1", "]", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "build_conv_layer", "(", "\n", "self", ".", "conv_cfg", ",", "\n", "in_channels", ",", "\n", "stem_channels", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "norm1_name", ",", "norm1", "=", "build_norm_layer", "(", "\n", "self", ".", "norm_cfg", ",", "stem_channels", ",", "postfix", "=", "1", ")", "\n", "self", ".", "add_module", "(", "self", ".", "norm1_name", ",", "norm1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet._freeze_stages": [[640, 658], ["range", "getattr", "getattr.eval", "getattr.parameters", "resnet.ResNet.stem.eval", "resnet.ResNet.stem.parameters", "resnet.ResNet.norm1.eval", "getattr.parameters"], "methods", ["None"], ["", "def", "_freeze_stages", "(", "self", ")", ":", "\n", "        ", "\"\"\"Freeze stages param and norm stats.\"\"\"", "\n", "if", "self", ".", "frozen_stages", ">=", "0", ":", "\n", "            ", "if", "self", ".", "deep_stem", ":", "\n", "                ", "self", ".", "stem", ".", "eval", "(", ")", "\n", "for", "param", "in", "self", ".", "stem", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "norm1", ".", "eval", "(", ")", "\n", "for", "m", "in", "[", "self", ".", "conv1", ",", "self", ".", "norm1", "]", ":", "\n", "                    ", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "frozen_stages", "+", "1", ")", ":", "\n", "            ", "m", "=", "getattr", "(", "self", ",", "f'layer{i}'", ")", "\n", "m", ".", "eval", "(", ")", "\n", "for", "param", "in", "m", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.forward": [[659, 675], ["resnet.ResNet.maxpool", "enumerate", "tuple", "resnet.ResNet.stem", "resnet.ResNet.conv1", "resnet.ResNet.norm1", "resnet.ResNet.relu", "getattr", "getattr.", "outs.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.norm1"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "if", "self", ".", "deep_stem", ":", "\n", "            ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "norm1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "outs", "=", "[", "]", "\n", "for", "i", ",", "layer_name", "in", "enumerate", "(", "self", ".", "res_layers", ")", ":", "\n", "            ", "res_layer", "=", "getattr", "(", "self", ",", "layer_name", ")", "\n", "x", "=", "res_layer", "(", "x", ")", "\n", "if", "i", "in", "self", ".", "out_indices", ":", "\n", "                ", "outs", ".", "append", "(", "x", ")", "\n", "", "", "return", "tuple", "(", "outs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.train": [[676, 686], ["super().train", "resnet.ResNet._freeze_stages", "resnet.ResNet.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet.train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNet._freeze_stages"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"Convert the model into training mode while keep normalization layer\n        freezed.\"\"\"", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "self", ".", "_freeze_stages", "(", ")", "\n", "if", "mode", "and", "self", ".", "norm_eval", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "# trick: eval have effect on BatchNorm only", "\n", "                ", "if", "isinstance", "(", "m", ",", "_BatchNorm", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNetV1c.__init__": [[698, 701], ["resnet.ResNet.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResNetV1c", ",", "self", ")", ".", "__init__", "(", "\n", "deep_stem", "=", "True", ",", "avg_down", "=", "False", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.resnet.ResNetV1d.__init__": [[712, 715], ["resnet.ResNet.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResNetV1d", ",", "self", ")", ".", "__init__", "(", "\n", "deep_stem", "=", "True", ",", "avg_down", "=", "True", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.__init__": [[16, 19], ["mmcv.runner.BaseModule.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "BaseSegmentor", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "self", ".", "fp16_enabled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.with_neck": [[20, 24], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_neck", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the segmentor has neck\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'neck'", ")", "and", "self", ".", "neck", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.with_auxiliary_head": [[25, 30], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_auxiliary_head", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the segmentor has auxiliary head\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "\n", "'auxiliary_head'", ")", "and", "self", ".", "auxiliary_head", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.with_decode_head": [[31, 35], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "with_decode_head", "(", "self", ")", ":", "\n", "        ", "\"\"\"bool: whether the segmentor has decode head\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "'decode_head'", ")", "and", "self", ".", "decode_head", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.extract_feat": [[36, 40], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "extract_feat", "(", "self", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"Placeholder for extract features from images.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.encode_decode": [[41, 46], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Placeholder for encode images with backbone and decode into a\n        semantic segmentation map of the same size as input.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.forward_train": [[47, 51], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward_train", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Placeholder for Forward function for training.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.simple_test": [[52, 56], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "simple_test", "(", "self", ",", "img", ",", "img_meta", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Placeholder for single image test.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.aug_test": [[57, 61], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Placeholder for augmentation test.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.forward_test": [[62, 94], ["len", "len", "ValueError", "all", "all", "all", "base.BaseSegmentor.simple_test", "base.BaseSegmentor.aug_test", "isinstance", "TypeError", "len", "len", "type"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pon_vpn_BEVSegmentor.simple_test", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.aug_test"], ["", "def", "forward_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "rescale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            imgs (List[Tensor]): the outer list indicates test-time\n                augmentations and inner Tensor should have a shape NxCxHxW,\n                which contains all images in the batch.\n            img_metas (List[List[dict]]): the outer list indicates test-time\n                augs (multiscale, flip, etc.) and the inner list indicates\n                images in a batch.\n        \"\"\"", "\n", "for", "var", ",", "name", "in", "[", "(", "imgs", ",", "'imgs'", ")", ",", "(", "img_metas", ",", "'img_metas'", ")", "]", ":", "\n", "            ", "if", "not", "isinstance", "(", "var", ",", "list", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f'{name} must be a list, but got '", "\n", "f'{type(var)}'", ")", "\n", "\n", "", "", "num_augs", "=", "len", "(", "imgs", ")", "\n", "if", "num_augs", "!=", "len", "(", "img_metas", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'num of augmentations ({len(imgs)}) != '", "\n", "f'num of image meta ({len(img_metas)})'", ")", "\n", "# all images in the same aug batch all of the same ori_shape and pad", "\n", "# shape", "\n", "", "for", "img_meta", "in", "img_metas", ":", "\n", "            ", "ori_shapes", "=", "[", "_", "[", "'ori_shape'", "]", "for", "_", "in", "img_meta", "]", "\n", "assert", "all", "(", "shape", "==", "ori_shapes", "[", "0", "]", "for", "shape", "in", "ori_shapes", ")", "\n", "img_shapes", "=", "[", "_", "[", "'img_shape'", "]", "for", "_", "in", "img_meta", "]", "\n", "assert", "all", "(", "shape", "==", "img_shapes", "[", "0", "]", "for", "shape", "in", "img_shapes", ")", "\n", "pad_shapes", "=", "[", "_", "[", "'pad_shape'", "]", "for", "_", "in", "img_meta", "]", "\n", "assert", "all", "(", "shape", "==", "pad_shapes", "[", "0", "]", "for", "shape", "in", "pad_shapes", ")", "\n", "", "if", "num_augs", "==", "1", ":", "\n", "            ", "return", "self", ".", "simple_test", "(", "imgs", "[", "0", "]", ",", "img_metas", "[", "0", "]", ",", "rescale", "=", "rescale", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "aug_test", "(", "imgs", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.forward": [[95, 110], ["mmcv.runner.auto_fp16", "base.BaseSegmentor.forward_train", "base.BaseSegmentor.forward_test"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_test"], ["", "", "@", "auto_fp16", "(", "apply_to", "=", "(", "'img'", ",", ")", ")", "\n", "def", "forward", "(", "self", ",", "img", ",", "img_metas", ",", "return_loss", "=", "True", ",", "rescale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Calls either :func:`forward_train` or :func:`forward_test` depending\n        on whether ``return_loss`` is ``True``.\n\n        Note this setting will change the expected inputs. When\n        ``return_loss=True``, img and img_meta are single-nested (i.e. Tensor\n        and List[dict]), and when ``resturn_loss=False``, img and img_meta\n        should be double nested (i.e.  List[Tensor], List[List[dict]]), with\n        the outer list indicating test time augmentations.\n        \"\"\"", "\n", "if", "return_loss", ":", "\n", "            ", "return", "self", ".", "forward_train", "(", "img", ",", "img_metas", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "forward_test", "(", "img", ",", "img_metas", ",", "rescale", "=", "rescale", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.train_step": [[111, 146], ["base.BaseSegmentor.", "base.BaseSegmentor._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor._parse_losses"], ["", "", "def", "train_step", "(", "self", ",", "data_batch", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"The iteration step during training.\n\n        This method defines an iteration step during training, except for the\n        back propagation and optimizer updating, which are done in an optimizer\n        hook. Note that in some complicated cases or models, the whole process\n        including back propagation and optimizer updating is also defined in\n        this method, such as GAN.\n\n        Args:\n            data (dict): The output of dataloader.\n            optimizer (:obj:`torch.optim.Optimizer` | dict): The optimizer of\n                runner is passed to ``train_step()``. This argument is unused\n                and reserved.\n\n        Returns:\n            dict: It should contain at least 3 keys: ``loss``, ``log_vars``,\n                ``num_samples``.\n                ``loss`` is a tensor for back propagation, which can be a\n                weighted sum of multiple losses.\n                ``log_vars`` contains all the variables to be sent to the\n                logger.\n                ``num_samples`` indicates the batch size (when the model is\n                DDP, it means the batch size on each GPU), which is used for\n                averaging the logs.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data_batch", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "\n", "log_vars", "=", "log_vars", ",", "\n", "num_samples", "=", "len", "(", "data_batch", "[", "'img_metas'", "]", ")", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.val_step": [[147, 163], ["base.BaseSegmentor.", "base.BaseSegmentor._parse_losses", "dict", "len"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor._parse_losses"], ["", "def", "val_step", "(", "self", ",", "data_batch", ",", "optimizer", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"The iteration step during validation.\n\n        This method shares the same signature as :func:`train_step`, but used\n        during val epochs. Note that the evaluation after training epochs is\n        not implemented with this method, but an evaluation hook.\n        \"\"\"", "\n", "losses", "=", "self", "(", "**", "data_batch", ")", "\n", "loss", ",", "log_vars", "=", "self", ".", "_parse_losses", "(", "losses", ")", "\n", "\n", "outputs", "=", "dict", "(", "\n", "loss", "=", "loss", ",", "\n", "log_vars", "=", "log_vars", ",", "\n", "num_samples", "=", "len", "(", "data_batch", "[", "'img_metas'", "]", ")", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor._parse_losses": [[164, 199], ["collections.OrderedDict", "losses.items", "sum", "collections.OrderedDict.items", "isinstance", "loss_value.data.clone.data.clone.item", "loss_value.data.clone.data.clone.mean", "isinstance", "torch.is_available", "torch.is_available", "torch.is_initialized", "torch.is_initialized", "loss_value.data.clone.data.clone.data.clone", "torch.all_reduce", "torch.all_reduce", "sum", "TypeError", "collections.OrderedDict.items", "loss_value.data.clone.data.clone.div_", "torch.get_world_size", "torch.get_world_size", "_loss.mean"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_parse_losses", "(", "losses", ")", ":", "\n", "        ", "\"\"\"Parse the raw outputs (losses) of the network.\n\n        Args:\n            losses (dict): Raw output of the network, which usually contain\n                losses and other necessary information.\n\n        Returns:\n            tuple[Tensor, dict]: (loss, log_vars), loss is the loss tensor\n                which may be a weighted sum of all losses, log_vars contains\n                all the variables to be sent to the logger.\n        \"\"\"", "\n", "log_vars", "=", "OrderedDict", "(", ")", "\n", "for", "loss_name", ",", "loss_value", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "loss_value", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "mean", "(", ")", "\n", "", "elif", "isinstance", "(", "loss_value", ",", "list", ")", ":", "\n", "                ", "log_vars", "[", "loss_name", "]", "=", "sum", "(", "_loss", ".", "mean", "(", ")", "for", "_loss", "in", "loss_value", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "\n", "f'{loss_name} is not a tensor or list of tensors'", ")", "\n", "\n", "", "", "loss", "=", "sum", "(", "_value", "for", "_key", ",", "_value", "in", "log_vars", ".", "items", "(", ")", "\n", "if", "'loss'", "in", "_key", ")", "\n", "\n", "log_vars", "[", "'loss'", "]", "=", "loss", "\n", "for", "loss_name", ",", "loss_value", "in", "log_vars", ".", "items", "(", ")", ":", "\n", "# reduce loss when distributed training", "\n", "            ", "if", "dist", ".", "is_available", "(", ")", "and", "dist", ".", "is_initialized", "(", ")", ":", "\n", "                ", "loss_value", "=", "loss_value", ".", "data", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "loss_value", ".", "div_", "(", "dist", ".", "get_world_size", "(", ")", ")", ")", "\n", "", "log_vars", "[", "loss_name", "]", "=", "loss_value", ".", "item", "(", ")", "\n", "\n", "", "return", "loss", ",", "log_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.base.BaseSegmentor.show_result": [[200, 266], ["mmcv.imread", "img.astype.astype.copy", "numpy.array", "numpy.zeros", "enumerate", "img.astype.astype.astype", "len", "len", "mmcv.imshow", "mmcv.imwrite", "warnings.warn", "numpy.random.randint", "len"], "methods", ["None"], ["", "def", "show_result", "(", "self", ",", "\n", "img", ",", "\n", "result", ",", "\n", "palette", "=", "None", ",", "\n", "win_name", "=", "''", ",", "\n", "show", "=", "False", ",", "\n", "wait_time", "=", "0", ",", "\n", "out_file", "=", "None", ",", "\n", "opacity", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"Draw `result` over `img`.\n\n        Args:\n            img (str or Tensor): The image to be displayed.\n            result (Tensor): The semantic segmentation results to draw over\n                `img`.\n            palette (list[list[int]]] | np.ndarray | None): The palette of\n                segmentation map. If None is given, random palette will be\n                generated. Default: None\n            win_name (str): The window name.\n            wait_time (int): Value of waitKey param.\n                Default: 0.\n            show (bool): Whether to show the image.\n                Default: False.\n            out_file (str or None): The filename to write the image.\n                Default: None.\n            opacity(float): Opacity of painted segmentation map.\n                Default 0.5.\n                Must be in (0, 1] range.\n        Returns:\n            img (Tensor): Only if not `show` or `out_file`\n        \"\"\"", "\n", "img", "=", "mmcv", ".", "imread", "(", "img", ")", "\n", "img", "=", "img", ".", "copy", "(", ")", "\n", "seg", "=", "result", "[", "0", "]", "\n", "if", "palette", "is", "None", ":", "\n", "            ", "if", "self", ".", "PALETTE", "is", "None", ":", "\n", "                ", "palette", "=", "np", ".", "random", ".", "randint", "(", "\n", "0", ",", "255", ",", "size", "=", "(", "len", "(", "self", ".", "CLASSES", ")", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "                ", "palette", "=", "self", ".", "PALETTE", "\n", "", "", "palette", "=", "np", ".", "array", "(", "palette", ")", "\n", "assert", "palette", ".", "shape", "[", "0", "]", "==", "len", "(", "self", ".", "CLASSES", ")", "\n", "assert", "palette", ".", "shape", "[", "1", "]", "==", "3", "\n", "assert", "len", "(", "palette", ".", "shape", ")", "==", "2", "\n", "assert", "0", "<", "opacity", "<=", "1.0", "\n", "color_seg", "=", "np", ".", "zeros", "(", "(", "seg", ".", "shape", "[", "0", "]", ",", "seg", ".", "shape", "[", "1", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "label", ",", "color", "in", "enumerate", "(", "palette", ")", ":", "\n", "            ", "color_seg", "[", "seg", "==", "label", ",", ":", "]", "=", "color", "\n", "# convert to BGR", "\n", "", "color_seg", "=", "color_seg", "[", "...", ",", ":", ":", "-", "1", "]", "\n", "\n", "img", "=", "img", "*", "(", "1", "-", "opacity", ")", "+", "color_seg", "*", "opacity", "\n", "img", "=", "img", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "# if out_file specified, do not show image in window", "\n", "if", "out_file", "is", "not", "None", ":", "\n", "            ", "show", "=", "False", "\n", "\n", "", "if", "show", ":", "\n", "            ", "mmcv", ".", "imshow", "(", "img", ",", "win_name", ",", "wait_time", ")", "\n", "", "if", "out_file", "is", "not", "None", ":", "\n", "            ", "mmcv", ".", "imwrite", "(", "img", ",", "out_file", ")", "\n", "\n", "", "if", "not", "(", "show", "or", "out_file", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "'show==False and out_file is not specified, only '", "\n", "'result image will be returned'", ")", "\n", "return", "img", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.__init__": [[22, 46], ["base.BaseSegmentor.__init__", "builder.build_backbone", "encoder_decoder.EncoderDecoder._init_decode_head", "encoder_decoder.EncoderDecoder._init_auxiliary_head", "builder.build_neck", "backbone.get"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_backbone", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_decode_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_auxiliary_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_neck"], ["def", "__init__", "(", "self", ",", "\n", "backbone", ",", "\n", "decode_head", ",", "\n", "neck", "=", "None", ",", "\n", "auxiliary_head", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ",", "\n", "pretrained", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "EncoderDecoder", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "            ", "assert", "backbone", ".", "get", "(", "'pretrained'", ")", "is", "None", ",", "'both backbone and segmentor set pretrained weight'", "\n", "backbone", ".", "pretrained", "=", "pretrained", "\n", "", "self", ".", "backbone", "=", "builder", ".", "build_backbone", "(", "backbone", ")", "\n", "if", "neck", "is", "not", "None", ":", "\n", "            ", "self", ".", "neck", "=", "builder", ".", "build_neck", "(", "neck", ")", "\n", "", "self", ".", "_init_decode_head", "(", "decode_head", ")", "\n", "self", ".", "_init_auxiliary_head", "(", "auxiliary_head", ")", "\n", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n", "assert", "self", ".", "with_decode_head", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder._init_decode_head": [[47, 52], ["builder.build_head"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head"], ["", "def", "_init_decode_head", "(", "self", ",", "decode_head", ")", ":", "\n", "        ", "\"\"\"Initialize ``decode_head``\"\"\"", "\n", "self", ".", "decode_head", "=", "builder", ".", "build_head", "(", "decode_head", ")", "\n", "self", ".", "align_corners", "=", "self", ".", "decode_head", ".", "align_corners", "\n", "self", ".", "num_classes", "=", "self", ".", "decode_head", ".", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder._init_auxiliary_head": [[53, 62], ["isinstance", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "builder.build_head", "encoder_decoder.EncoderDecoder.auxiliary_head.append", "builder.build_head"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head"], ["", "def", "_init_auxiliary_head", "(", "self", ",", "auxiliary_head", ")", ":", "\n", "        ", "\"\"\"Initialize ``auxiliary_head``\"\"\"", "\n", "if", "auxiliary_head", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "auxiliary_head", ",", "list", ")", ":", "\n", "                ", "self", ".", "auxiliary_head", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "head_cfg", "in", "auxiliary_head", ":", "\n", "                    ", "self", ".", "auxiliary_head", ".", "append", "(", "builder", ".", "build_head", "(", "head_cfg", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "auxiliary_head", "=", "builder", ".", "build_head", "(", "auxiliary_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.extract_feat": [[63, 69], ["encoder_decoder.EncoderDecoder.backbone", "encoder_decoder.EncoderDecoder.neck"], "methods", ["None"], ["", "", "", "def", "extract_feat", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.encode_decode": [[70, 81], ["encoder_decoder.EncoderDecoder.extract_feat", "encoder_decoder.EncoderDecoder._decode_head_forward_test", "mmseg.ops.resize"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "x", "=", "self", ".", "extract_feat", "(", "img", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "img_metas", ")", "\n", "out", "=", "resize", "(", "\n", "input", "=", "out", ",", "\n", "size", "=", "img", ".", "shape", "[", "2", ":", "]", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder._decode_head_forward_train": [[82, 92], ["dict", "encoder_decoder.EncoderDecoder.decode_head.forward_train", "dict.update", "mmseg.core.add_prefix"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix"], ["", "def", "_decode_head_forward_train", "(", "self", ",", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for decode head in\n        training.\"\"\"", "\n", "losses", "=", "dict", "(", ")", "\n", "loss_decode", "=", "self", ".", "decode_head", ".", "forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ",", "\n", "self", ".", "train_cfg", ")", "\n", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_decode", ",", "'decode'", ")", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder._decode_head_forward_test": [[93, 98], ["encoder_decoder.EncoderDecoder.decode_head.forward_test"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_test"], ["", "def", "_decode_head_forward_test", "(", "self", ",", "x", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for decode head in\n        inference.\"\"\"", "\n", "seg_logits", "=", "self", ".", "decode_head", ".", "forward_test", "(", "x", ",", "img_metas", ",", "self", ".", "test_cfg", ")", "\n", "return", "seg_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder._auxiliary_head_forward_train": [[99, 115], ["dict", "isinstance", "enumerate", "encoder_decoder.EncoderDecoder.auxiliary_head.forward_train", "dict.update", "aux_head.forward_train", "dict.update", "mmseg.core.add_prefix", "mmseg.core.add_prefix"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix"], ["", "def", "_auxiliary_head_forward_train", "(", "self", ",", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for auxiliary head in\n        training.\"\"\"", "\n", "losses", "=", "dict", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "auxiliary_head", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "for", "idx", ",", "aux_head", "in", "enumerate", "(", "self", ".", "auxiliary_head", ")", ":", "\n", "                ", "loss_aux", "=", "aux_head", ".", "forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ",", "\n", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_aux", ",", "f'aux_{idx}'", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "loss_aux", "=", "self", ".", "auxiliary_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_semantic_seg", ",", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_aux", ",", "'aux'", ")", ")", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.forward_dummy": [[116, 121], ["encoder_decoder.EncoderDecoder.encode_decode"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode"], ["", "def", "forward_dummy", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Dummy forward function.\"\"\"", "\n", "seg_logit", "=", "self", ".", "encode_decode", "(", "img", ",", "None", ")", "\n", "\n", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.forward_train": [[122, 153], ["encoder_decoder.EncoderDecoder.extract_feat", "dict", "encoder_decoder.EncoderDecoder._decode_head_forward_train", "dict.update", "encoder_decoder.EncoderDecoder._auxiliary_head_forward_train", "dict.update"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n\n        Args:\n            img (Tensor): Input images.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "\n", "x", "=", "self", ".", "extract_feat", "(", "img", ")", "\n", "\n", "losses", "=", "dict", "(", ")", "\n", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.slide_inference": [[155, 199], ["img.size", "img.new_zeros", "img.new_zeros", "range", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "range", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "mmseg.ops.resize", "max", "max", "min", "min", "max", "max", "encoder_decoder.EncoderDecoder.encode_decode", "torch.pad", "torch.pad", "torch.pad", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "int", "int", "int", "int", "torch.from_numpy().to.cpu().detach().numpy", "torch.from_numpy().to.cpu().detach().numpy", "torch.from_numpy().to.cpu().detach().numpy", "torch.from_numpy().to.cpu().detach", "torch.from_numpy().to.cpu().detach", "torch.from_numpy().to.cpu().detach", "torch.from_numpy().to.cpu", "torch.from_numpy().to.cpu", "torch.from_numpy().to.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode"], ["", "def", "slide_inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference by sliding-window with overlap.\n\n        If h_crop > h_img or w_crop > w_img, the small patch will be used to\n        decode without padding.\n        \"\"\"", "\n", "\n", "h_stride", ",", "w_stride", "=", "self", ".", "test_cfg", ".", "stride", "\n", "h_crop", ",", "w_crop", "=", "self", ".", "test_cfg", ".", "crop_size", "\n", "batch_size", ",", "_", ",", "h_img", ",", "w_img", "=", "img", ".", "size", "(", ")", "\n", "num_classes", "=", "self", ".", "num_classes", "\n", "h_grids", "=", "max", "(", "h_img", "-", "h_crop", "+", "h_stride", "-", "1", ",", "0", ")", "//", "h_stride", "+", "1", "\n", "w_grids", "=", "max", "(", "w_img", "-", "w_crop", "+", "w_stride", "-", "1", ",", "0", ")", "//", "w_stride", "+", "1", "\n", "preds", "=", "img", ".", "new_zeros", "(", "(", "batch_size", ",", "num_classes", ",", "h_img", ",", "w_img", ")", ")", "\n", "count_mat", "=", "img", ".", "new_zeros", "(", "(", "batch_size", ",", "1", ",", "h_img", ",", "w_img", ")", ")", "\n", "for", "h_idx", "in", "range", "(", "h_grids", ")", ":", "\n", "            ", "for", "w_idx", "in", "range", "(", "w_grids", ")", ":", "\n", "                ", "y1", "=", "h_idx", "*", "h_stride", "\n", "x1", "=", "w_idx", "*", "w_stride", "\n", "y2", "=", "min", "(", "y1", "+", "h_crop", ",", "h_img", ")", "\n", "x2", "=", "min", "(", "x1", "+", "w_crop", ",", "w_img", ")", "\n", "y1", "=", "max", "(", "y2", "-", "h_crop", ",", "0", ")", "\n", "x1", "=", "max", "(", "x2", "-", "w_crop", ",", "0", ")", "\n", "crop_img", "=", "img", "[", ":", ",", ":", ",", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "\n", "crop_seg_logit", "=", "self", ".", "encode_decode", "(", "crop_img", ",", "img_meta", ")", "\n", "preds", "+=", "F", ".", "pad", "(", "crop_seg_logit", ",", "\n", "(", "int", "(", "x1", ")", ",", "int", "(", "preds", ".", "shape", "[", "3", "]", "-", "x2", ")", ",", "int", "(", "y1", ")", ",", "\n", "int", "(", "preds", ".", "shape", "[", "2", "]", "-", "y2", ")", ")", ")", "\n", "\n", "count_mat", "[", ":", ",", ":", ",", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "+=", "1", "\n", "", "", "assert", "(", "count_mat", "==", "0", ")", ".", "sum", "(", ")", "==", "0", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "# cast count_mat to constant while exporting to ONNX", "\n", "            ", "count_mat", "=", "torch", ".", "from_numpy", "(", "\n", "count_mat", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", ".", "to", "(", "device", "=", "img", ".", "device", ")", "\n", "", "preds", "=", "preds", "/", "count_mat", "\n", "if", "rescale", ":", "\n", "            ", "preds", "=", "resize", "(", "\n", "preds", ",", "\n", "size", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "[", ":", "2", "]", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ",", "\n", "warning", "=", "False", ")", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.whole_inference": [[200, 218], ["encoder_decoder.EncoderDecoder.encode_decode", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "mmseg.ops.resize"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "def", "whole_inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference with full image.\"\"\"", "\n", "\n", "seg_logit", "=", "self", ".", "encode_decode", "(", "img", ",", "img_meta", ")", "\n", "if", "rescale", ":", "\n", "# support dynamic shape for onnx", "\n", "            ", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "                ", "size", "=", "img", ".", "shape", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "                ", "size", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "[", ":", "2", "]", "\n", "", "seg_logit", "=", "resize", "(", "\n", "seg_logit", ",", "\n", "size", "=", "size", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ",", "\n", "warning", "=", "False", ")", "\n", "\n", "", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.inference": [[219, 253], ["all", "torch.softmax", "torch.softmax", "torch.softmax", "encoder_decoder.EncoderDecoder.slide_inference", "encoder_decoder.EncoderDecoder.whole_inference", "output.flip.flip.flip", "output.flip.flip.flip"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.slide_inference", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.whole_inference"], ["", "def", "inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference with slide/whole style.\n\n        Args:\n            img (Tensor): The input image of shape (N, 3, H, W).\n            img_meta (dict): Image info dict where each dict has: 'img_shape',\n                'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            rescale (bool): Whether rescale back to original shape.\n\n        Returns:\n            Tensor: The output segmentation map.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "test_cfg", ".", "mode", "in", "[", "'slide'", ",", "'whole'", "]", "\n", "ori_shape", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "\n", "assert", "all", "(", "_", "[", "'ori_shape'", "]", "==", "ori_shape", "for", "_", "in", "img_meta", ")", "\n", "if", "self", ".", "test_cfg", ".", "mode", "==", "'slide'", ":", "\n", "            ", "seg_logit", "=", "self", ".", "slide_inference", "(", "img", ",", "img_meta", ",", "rescale", ")", "\n", "", "else", ":", "\n", "            ", "seg_logit", "=", "self", ".", "whole_inference", "(", "img", ",", "img_meta", ",", "rescale", ")", "\n", "", "output", "=", "F", ".", "softmax", "(", "seg_logit", ",", "dim", "=", "1", ")", "\n", "flip", "=", "img_meta", "[", "0", "]", "[", "'flip'", "]", "\n", "if", "flip", ":", "\n", "            ", "flip_direction", "=", "img_meta", "[", "0", "]", "[", "'flip_direction'", "]", "\n", "assert", "flip_direction", "in", "[", "'horizontal'", ",", "'vertical'", "]", "\n", "if", "flip_direction", "==", "'horizontal'", ":", "\n", "                ", "output", "=", "output", ".", "flip", "(", "dims", "=", "(", "3", ",", ")", ")", "\n", "", "elif", "flip_direction", "==", "'vertical'", ":", "\n", "                ", "output", "=", "output", ".", "flip", "(", "dims", "=", "(", "2", ",", ")", ")", "\n", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.simple_test": [[254, 264], ["encoder_decoder.EncoderDecoder.inference", "encoder_decoder.EncoderDecoder.argmax", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "seg_pred.unsqueeze.unsqueeze.cpu().numpy", "list", "seg_pred.unsqueeze.unsqueeze.unsqueeze", "seg_pred.unsqueeze.unsqueeze.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Simple test with single image.\"\"\"", "\n", "seg_logit", "=", "self", ".", "inference", "(", "img", ",", "img_meta", ",", "rescale", ")", "\n", "seg_pred", "=", "seg_logit", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "            ", "seg_pred", "=", "seg_pred", ".", "unsqueeze", "(", "0", ")", "\n", "return", "seg_pred", "\n", "", "seg_pred", "=", "seg_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "seg_pred", "=", "list", "(", "seg_pred", ")", "\n", "return", "seg_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.encoder_decoder.EncoderDecoder.aug_test": [[265, 283], ["encoder_decoder.EncoderDecoder.inference", "range", "len", "encoder_decoder.EncoderDecoder.argmax", "list.cpu().numpy", "list", "len", "encoder_decoder.EncoderDecoder.inference", "list.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference"], ["", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "rescale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Test with augmentations.\n\n        Only rescale=True is supported.\n        \"\"\"", "\n", "# aug_test rescale all imgs back to ori_shape for now", "\n", "assert", "rescale", "\n", "# to save memory, we get augmented seg logit inplace", "\n", "seg_logit", "=", "self", ".", "inference", "(", "imgs", "[", "0", "]", ",", "img_metas", "[", "0", "]", ",", "rescale", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "imgs", ")", ")", ":", "\n", "            ", "cur_seg_logit", "=", "self", ".", "inference", "(", "imgs", "[", "i", "]", ",", "img_metas", "[", "i", "]", ",", "rescale", ")", "\n", "seg_logit", "+=", "cur_seg_logit", "\n", "", "seg_logit", "/=", "len", "(", "imgs", ")", "\n", "seg_pred", "=", "seg_logit", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "seg_pred", "=", "seg_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# unravel batch dim", "\n", "seg_pred", "=", "list", "(", "seg_pred", ")", "\n", "return", "seg_pred", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.__init__": [[33, 60], ["base.BaseSegmentor.__init__", "builder.build_backbone", "builder.build_neck", "bevsegmentor.BEVSegmentor._init_decode_head", "bevsegmentor.BEVSegmentor._init_auxiliary_head", "builder.build_neck", "backbone.get"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_backbone", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_neck", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_decode_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_auxiliary_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_neck"], ["def", "__init__", "(", "self", ",", "\n", "backbone", ",", "\n", "decode_head", ",", "\n", "neck", "=", "None", ",", "\n", "transformer", "=", "None", ",", "\n", "auxiliary_head", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ",", "\n", "pretrained", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "BEVSegmentor", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "            ", "assert", "backbone", ".", "get", "(", "'pretrained'", ")", "is", "None", ",", "'both backbone and segmentor set pretrained weight'", "\n", "backbone", ".", "pretrained", "=", "pretrained", "\n", "", "self", ".", "backbone", "=", "builder", ".", "build_backbone", "(", "backbone", ")", "\n", "if", "neck", "is", "not", "None", ":", "\n", "            ", "self", ".", "neck", "=", "builder", ".", "build_neck", "(", "neck", ")", "\n", "", "assert", "transformer", "is", "not", "None", "\n", "self", ".", "transformer", "=", "builder", ".", "build_neck", "(", "transformer", ")", "\n", "self", ".", "_init_decode_head", "(", "decode_head", ")", "\n", "self", ".", "_init_auxiliary_head", "(", "auxiliary_head", ")", "\n", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n", "assert", "self", ".", "with_decode_head", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor._init_decode_head": [[61, 66], ["builder.build_head"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head"], ["", "def", "_init_decode_head", "(", "self", ",", "decode_head", ")", ":", "\n", "        ", "\"\"\"Initialize ``decode_head``\"\"\"", "\n", "self", ".", "decode_head", "=", "builder", ".", "build_head", "(", "decode_head", ")", "\n", "self", ".", "align_corners", "=", "self", ".", "decode_head", ".", "align_corners", "\n", "self", ".", "num_classes", "=", "self", ".", "decode_head", ".", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor._init_auxiliary_head": [[67, 76], ["isinstance", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "builder.build_head", "bevsegmentor.BEVSegmentor.auxiliary_head.append", "builder.build_head"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head"], ["", "def", "_init_auxiliary_head", "(", "self", ",", "auxiliary_head", ")", ":", "\n", "        ", "\"\"\"Initialize ``auxiliary_head``\"\"\"", "\n", "if", "auxiliary_head", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "auxiliary_head", ",", "list", ")", ":", "\n", "                ", "self", ".", "auxiliary_head", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "head_cfg", "in", "auxiliary_head", ":", "\n", "                    ", "self", ".", "auxiliary_head", ".", "append", "(", "builder", ".", "build_head", "(", "head_cfg", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "auxiliary_head", "=", "builder", ".", "build_head", "(", "auxiliary_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.extract_feat": [[77, 84], ["bevsegmentor.BEVSegmentor.backbone", "bevsegmentor.BEVSegmentor.transformer", "bevsegmentor.BEVSegmentor.neck"], "methods", ["None"], ["", "", "", "def", "extract_feat", "(", "self", ",", "img", ",", "calib", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "x", "=", "self", ".", "transformer", "(", "x", ",", "calib", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.encode_decode": [[85, 92], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.BEVSegmentor.extract_feat", "bevsegmentor.BEVSegmentor._decode_head_forward_test", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "img_metas", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor._decode_head_forward_train": [[93, 104], ["dict", "bevsegmentor.BEVSegmentor.decode_head.forward_train", "dict.update", "mmseg.core.add_prefix"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix"], ["", "def", "_decode_head_forward_train", "(", "self", ",", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for decode head in\n        training.\"\"\"", "\n", "losses", "=", "dict", "(", ")", "\n", "loss_decode", "=", "self", ".", "decode_head", ".", "forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ",", "\n", "self", ".", "train_cfg", ")", "\n", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_decode", ",", "'decode'", ")", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor._decode_head_forward_test": [[105, 110], ["bevsegmentor.BEVSegmentor.decode_head.forward_test"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_test"], ["", "def", "_decode_head_forward_test", "(", "self", ",", "x", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for decode head in\n        inference.\"\"\"", "\n", "seg_logits", "=", "self", ".", "decode_head", ".", "forward_test", "(", "x", ",", "img_metas", ",", "self", ".", "test_cfg", ")", "\n", "return", "seg_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor._auxiliary_head_forward_train": [[111, 127], ["dict", "isinstance", "enumerate", "bevsegmentor.BEVSegmentor.auxiliary_head.forward_train", "dict.update", "aux_head.forward_train", "dict.update", "mmseg.core.add_prefix", "mmseg.core.add_prefix"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix"], ["", "def", "_auxiliary_head_forward_train", "(", "self", ",", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for auxiliary head in\n        training.\"\"\"", "\n", "losses", "=", "dict", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "auxiliary_head", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "for", "idx", ",", "aux_head", "in", "enumerate", "(", "self", ".", "auxiliary_head", ")", ":", "\n", "                ", "loss_aux", "=", "aux_head", ".", "forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ",", "\n", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_aux", ",", "f'aux_{idx}'", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "loss_aux", "=", "self", ".", "auxiliary_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_semantic_seg", ",", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_aux", ",", "'aux'", ")", ")", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.forward_dummy": [[128, 133], ["bevsegmentor.BEVSegmentor.encode_decode"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode"], ["", "def", "forward_dummy", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Dummy forward function.\"\"\"", "\n", "seg_logit", "=", "self", ".", "encode_decode", "(", "img", ",", "None", ")", "\n", "\n", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.forward_train": [[134, 163], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.BEVSegmentor.extract_feat", "dict", "bevsegmentor.BEVSegmentor._decode_head_forward_train", "dict.update", "bevsegmentor.BEVSegmentor._auxiliary_head_forward_train", "dict.update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n\n        Args:\n            img (Tensor): Input images.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "# calib.shape [batch_size,3,3]", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.whole_inference": [[164, 180], ["bevsegmentor.BEVSegmentor.encode_decode", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "mmseg.ops.resize"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "def", "whole_inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference with full image.\"\"\"", "\n", "seg_logit", "=", "self", ".", "encode_decode", "(", "img", ",", "img_meta", ")", "\n", "if", "rescale", ":", "\n", "# support dynamic shape for onnx", "\n", "            ", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "                ", "size", "=", "img", ".", "shape", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "                ", "size", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "[", ":", "2", "]", "\n", "", "seg_logit", "=", "resize", "(", "\n", "seg_logit", ",", "\n", "size", "=", "size", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ",", "\n", "warning", "=", "False", ")", "\n", "", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.inference": [[181, 204], ["all", "bevsegmentor.BEVSegmentor.whole_inference"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.whole_inference"], ["", "def", "inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference with slide/whole style.\n\n        Args:\n            img (Tensor): The input image of shape (N, 3, H, W).\n            img_meta (dict): Image info dict where each dict has: 'img_shape',\n                'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            rescale (bool): Whether rescale back to original shape.\n\n        Returns:\n            Tensor: The output segmentation map.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "test_cfg", ".", "mode", "in", "[", "'slide'", ",", "'whole'", "]", "\n", "ori_shape", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "\n", "assert", "all", "(", "_", "[", "'ori_shape'", "]", "==", "ori_shape", "for", "_", "in", "img_meta", ")", "\n", "if", "self", ".", "test_cfg", ".", "mode", "==", "'slide'", ":", "\n", "            ", "assert", "False", "\n", "", "seg_logit", "=", "self", ".", "whole_inference", "(", "img", ",", "img_meta", ",", "rescale", ")", "\n", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.simple_test": [[205, 223], ["bevsegmentor.BEVSegmentor.inference", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu().sigmoid", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "bevsegmentor.BEVSegmentor.test_cfg.get", "bevsegmentor.BEVSegmentor.test_cfg.get", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "losses.iou", "seg.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "seg.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Simple test with single image.\"\"\"", "\n", "seg_logit", "=", "self", ".", "inference", "(", "img", ",", "img_meta", ",", "False", ")", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "# our inference backend only support 4D output", "\n", "            ", "assert", "False", "\n", "", "seg_logit", "=", "seg_logit", ".", "cpu", "(", ")", ".", "sigmoid", "(", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "img_meta", "[", "0", "]", "[", "'gt_semantic_seg'", "]", "[", "None", ",", "...", "]", ")", ".", "bool", "(", ")", "\n", "output_type", "=", "self", ".", "test_cfg", ".", "get", "(", "'output_type'", ",", "'iou'", ")", "\n", "positive_thred", "=", "self", ".", "test_cfg", ".", "get", "(", "'positive_thred'", ",", "0.5", ")", "\n", "if", "output_type", "==", "'iou'", ":", "\n", "            ", "return", "[", "iou", "(", "seg_logit", ">", "positive_thred", ",", "labels", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "labels", "[", ":", ",", "-", "1", ",", "...", "]", ",", "per_class", "=", "True", ")", ",", "]", "\n", "", "elif", "output_type", "==", "'seg'", ":", "\n", "            ", "seg", "=", "seg_logit", ">", "positive_thred", "\n", "return", "[", "(", "seg", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "img_meta", "[", "0", "]", "[", "'filename'", "]", ")", ",", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'unknown output type %s'", "%", "output_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.BEVSegmentor.aug_test": [[224, 230], ["None"], "methods", ["None"], ["", "", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "rescale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Test with augmentations\n        Only rescale=True is supported.\n        \"\"\"", "\n", "# aug_test rescale all imgs back to ori_shape for now", "\n", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.__init__": [[240, 266], ["base.BaseSegmentor.__init__", "builder.build_backbone", "builder.build_neck", "bevsegmentor.origin_pyva_BEVSegmentor._init_decode_head", "bevsegmentor.origin_pyva_BEVSegmentor._init_auxiliary_head", "builder.build_neck", "backbone.get"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_backbone", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_neck", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_decode_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_auxiliary_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_neck"], ["def", "__init__", "(", "self", ",", "\n", "backbone", ",", "\n", "decode_head", ",", "\n", "neck", "=", "None", ",", "\n", "transformer", "=", "None", ",", "\n", "auxiliary_head", "=", "None", ",", "\n", "train_cfg", "=", "None", ",", "\n", "test_cfg", "=", "None", ",", "\n", "pretrained", "=", "None", ",", "\n", "init_cfg", "=", "None", ")", ":", "\n", "        ", "super", "(", "pyva_BEVSegmentor", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "            ", "assert", "backbone", ".", "get", "(", "'pretrained'", ")", "is", "None", ",", "'both backbone and segmentor set pretrained weight'", "\n", "backbone", ".", "pretrained", "=", "pretrained", "\n", "", "self", ".", "backbone", "=", "builder", ".", "build_backbone", "(", "backbone", ")", "\n", "if", "neck", "is", "not", "None", ":", "\n", "            ", "self", ".", "neck", "=", "builder", ".", "build_neck", "(", "neck", ")", "\n", "", "assert", "transformer", "is", "not", "None", "\n", "self", ".", "transformer", "=", "builder", ".", "build_neck", "(", "transformer", ")", "\n", "self", ".", "_init_decode_head", "(", "decode_head", ")", "\n", "self", ".", "_init_auxiliary_head", "(", "auxiliary_head", ")", "\n", "self", ".", "train_cfg", "=", "train_cfg", "\n", "self", ".", "test_cfg", "=", "test_cfg", "\n", "\n", "assert", "self", ".", "with_decode_head", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_decode_head": [[267, 271], ["builder.build_head"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head"], ["", "def", "_init_decode_head", "(", "self", ",", "decode_head", ")", ":", "\n", "        ", "\"\"\"Initialize ``decode_head``\"\"\"", "\n", "self", ".", "decode_head", "=", "builder", ".", "build_head", "(", "decode_head", ")", "\n", "self", ".", "num_classes", "=", "self", ".", "decode_head", ".", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._init_auxiliary_head": [[272, 281], ["isinstance", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "builder.build_head", "bevsegmentor.origin_pyva_BEVSegmentor.auxiliary_head.append", "builder.build_head"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_head"], ["", "def", "_init_auxiliary_head", "(", "self", ",", "auxiliary_head", ")", ":", "\n", "        ", "\"\"\"Initialize ``auxiliary_head``\"\"\"", "\n", "if", "auxiliary_head", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "auxiliary_head", ",", "list", ")", ":", "\n", "                ", "self", ".", "auxiliary_head", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "head_cfg", "in", "auxiliary_head", ":", "\n", "                    ", "self", ".", "auxiliary_head", ".", "append", "(", "builder", ".", "build_head", "(", "head_cfg", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "auxiliary_head", "=", "builder", ".", "build_head", "(", "auxiliary_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.extract_feat": [[282, 289], ["bevsegmentor.origin_pyva_BEVSegmentor.backbone", "bevsegmentor.origin_pyva_BEVSegmentor.transformer", "bevsegmentor.origin_pyva_BEVSegmentor.neck"], "methods", ["None"], ["", "", "", "def", "extract_feat", "(", "self", ",", "img", ",", "calib", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "output", ",", "transform_feature", ",", "retransform_features", ",", "forward_features", "=", "self", ".", "transformer", "(", "x", ",", "calib", ")", "\n", "return", "output", ",", "transform_feature", ",", "retransform_features", ",", "forward_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.encode_decode": [[290, 297], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.origin_pyva_BEVSegmentor.extract_feat", "bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", ",", "_", ",", "_", ",", "forward_features", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "forward_features", ",", "img_metas", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train": [[298, 307], ["dict", "bevsegmentor.origin_pyva_BEVSegmentor.decode_head.forward_train", "dict.update", "mmseg.core.add_prefix"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix"], ["", "def", "_decode_head_forward_train", "(", "self", ",", "x", ",", "img_metas", ",", "gt_semantic_seg", ",", "forward_features", ",", "transform_feature", ",", "retransform_features", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for decode head in\n        training.\"\"\"", "\n", "losses", "=", "dict", "(", ")", "\n", "loss_decode", "=", "self", ".", "decode_head", ".", "forward_train", "(", "x", ",", "img_metas", ",", "gt_semantic_seg", ",", "forward_features", ",", "transform_feature", ",", "retransform_features", ",", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_decode", ",", "'decode'", ")", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test": [[309, 314], ["bevsegmentor.origin_pyva_BEVSegmentor.decode_head.forward_test"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_test"], ["", "def", "_decode_head_forward_test", "(", "self", ",", "inputs", ",", "forward_features", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for decode head in\n        inference.\"\"\"", "\n", "seg_logits", "=", "self", ".", "decode_head", ".", "forward_test", "(", "inputs", ",", "forward_features", ",", "img_metas", ",", "self", ".", "test_cfg", ")", "\n", "return", "seg_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train": [[315, 331], ["dict", "isinstance", "enumerate", "bevsegmentor.origin_pyva_BEVSegmentor.auxiliary_head.forward_train", "dict.update", "aux_head.forward_train", "dict.update", "mmseg.core.add_prefix", "mmseg.core.add_prefix"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.misc.add_prefix"], ["", "def", "_auxiliary_head_forward_train", "(", "self", ",", "x", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Run forward function and calculate loss for auxiliary head in\n        training.\"\"\"", "\n", "losses", "=", "dict", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "auxiliary_head", ",", "nn", ".", "ModuleList", ")", ":", "\n", "            ", "for", "idx", ",", "aux_head", "in", "enumerate", "(", "self", ".", "auxiliary_head", ")", ":", "\n", "                ", "loss_aux", "=", "aux_head", ".", "forward_train", "(", "x", ",", "img_metas", ",", "\n", "gt_semantic_seg", ",", "\n", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_aux", ",", "f'aux_{idx}'", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "loss_aux", "=", "self", ".", "auxiliary_head", ".", "forward_train", "(", "\n", "x", ",", "img_metas", ",", "gt_semantic_seg", ",", "self", ".", "train_cfg", ")", "\n", "losses", ".", "update", "(", "add_prefix", "(", "loss_aux", ",", "'aux'", ")", ")", "\n", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.forward_dummy": [[332, 337], ["bevsegmentor.origin_pyva_BEVSegmentor.encode_decode"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode"], ["", "def", "forward_dummy", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Dummy forward function.\"\"\"", "\n", "seg_logit", "=", "self", ".", "encode_decode", "(", "img", ",", "None", ")", "\n", "\n", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.forward_train": [[338, 366], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.origin_pyva_BEVSegmentor.extract_feat", "dict", "bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "dict.update", "bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train", "dict.update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n        Args:\n            img (Tensor): Input images.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x_feature", ",", "transform_feature", ",", "retransform_features", ",", "forward_features", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "\n", "losses", "=", "dict", "(", ")", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ",", "forward_features", ",", "transform_feature", ",", "retransform_features", ")", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x_feature", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.whole_inference": [[367, 385], ["bevsegmentor.origin_pyva_BEVSegmentor.encode_decode", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "mmseg.ops.resize"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode", "home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "def", "whole_inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference with full image.\"\"\"", "\n", "\n", "seg_logit", "=", "self", ".", "encode_decode", "(", "img", ",", "img_meta", ")", "\n", "if", "rescale", ":", "\n", "# support dynamic shape for onnx", "\n", "            ", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "                ", "size", "=", "img", ".", "shape", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "                ", "size", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "[", ":", "2", "]", "\n", "", "seg_logit", "=", "resize", "(", "\n", "seg_logit", ",", "\n", "size", "=", "size", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ",", "\n", "warning", "=", "False", ")", "\n", "\n", "", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference": [[386, 409], ["all", "bevsegmentor.origin_pyva_BEVSegmentor.whole_inference"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.whole_inference"], ["", "def", "inference", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", ")", ":", "\n", "        ", "\"\"\"Inference with slide/whole style.\n\n        Args:\n            img (Tensor): The input image of shape (N, 3, H, W).\n            img_meta (dict): Image info dict where each dict has: 'img_shape',\n                'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            rescale (bool): Whether rescale back to original shape.\n\n        Returns:\n            Tensor: The output segmentation map.\n        \"\"\"", "\n", "\n", "assert", "self", ".", "test_cfg", ".", "mode", "in", "[", "'slide'", ",", "'whole'", "]", "\n", "ori_shape", "=", "img_meta", "[", "0", "]", "[", "'ori_shape'", "]", "\n", "assert", "all", "(", "_", "[", "'ori_shape'", "]", "==", "ori_shape", "for", "_", "in", "img_meta", ")", "\n", "if", "self", ".", "test_cfg", ".", "mode", "==", "'slide'", "or", "img_meta", "[", "0", "]", "[", "'flip'", "]", ":", "\n", "            ", "assert", "False", "\n", "", "seg_logit", "=", "self", ".", "whole_inference", "(", "img", ",", "img_meta", ",", "rescale", ")", "\n", "return", "seg_logit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.simple_test": [[410, 428], ["bevsegmentor.origin_pyva_BEVSegmentor.inference", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu().sigmoid", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "bevsegmentor.origin_pyva_BEVSegmentor.test_cfg.get", "bevsegmentor.origin_pyva_BEVSegmentor.test_cfg.get", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "losses.iou", "seg.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "seg.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Simple test with single image.\"\"\"", "\n", "seg_logit", "=", "self", ".", "inference", "(", "img", ",", "img_meta", ",", "False", ")", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "            ", "assert", "False", "\n", "", "seg_logit", "=", "seg_logit", ".", "cpu", "(", ")", ".", "sigmoid", "(", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "img_meta", "[", "0", "]", "[", "'gt_semantic_seg'", "]", "[", "None", ",", "...", "]", ")", ".", "bool", "(", ")", "\n", "# seg_logits shape:[1,14,196,200]", "\n", "# labels shape:[1,15,196,200]", "\n", "output_type", "=", "self", ".", "test_cfg", ".", "get", "(", "'output_type'", ",", "'iou'", ")", "\n", "positive_thred", "=", "self", ".", "test_cfg", ".", "get", "(", "'positive_thred'", ",", "0.5", ")", "\n", "if", "output_type", "==", "'iou'", ":", "\n", "            ", "return", "[", "iou", "(", "seg_logit", ">", "positive_thred", ",", "labels", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "labels", "[", ":", ",", "-", "1", ",", "...", "]", ",", "per_class", "=", "True", ")", ",", "]", "\n", "", "elif", "output_type", "==", "'seg'", ":", "\n", "            ", "seg", "=", "seg_logit", ">", "positive_thred", "\n", "return", "[", "(", "seg", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "img_meta", "[", "0", "]", "[", "'filename'", "]", ")", ",", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'unknown output type %s'", "%", "output_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.aug_test": [[429, 434], ["None"], "methods", ["None"], ["", "", "def", "aug_test", "(", "self", ",", "imgs", ",", "img_metas", ",", "rescale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Test with augmentations.\n        Only rescale=True is supported.\n        \"\"\"", "\n", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.pyva_BEVSegmentor.__init__": [[437, 441], ["bevsegmentor.BEVSegmentor.__init__", "torch.L1Loss", "torch.L1Loss", "torch.L1Loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "pyva_BEVSegmentor", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "cycle_loss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "cycle_loss_weight", "=", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.pyva_BEVSegmentor.extract_feat": [[442, 449], ["bevsegmentor.pyva_BEVSegmentor.backbone", "bevsegmentor.pyva_BEVSegmentor.transformer", "bevsegmentor.pyva_BEVSegmentor.neck"], "methods", ["None"], ["", "def", "extract_feat", "(", "self", ",", "img", ",", "calib", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "output", ",", "transform_feature", ",", "retransform_features", ",", "forward_features", "=", "self", ".", "transformer", "(", "x", ",", "calib", ")", "\n", "return", "output", ",", "transform_feature", ",", "retransform_features", ",", "forward_features", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.pyva_BEVSegmentor.encode_decode": [[450, 457], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.pyva_BEVSegmentor.extract_feat", "bevsegmentor.pyva_BEVSegmentor._decode_head_forward_test", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", ",", "_", ",", "_", ",", "_", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "img_metas", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.pyva_BEVSegmentor.forward_train": [[458, 474], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.pyva_BEVSegmentor.extract_feat", "dict", "bevsegmentor.pyva_BEVSegmentor._decode_head_forward_train", "dict.update", "bevsegmentor.pyva_BEVSegmentor.cycle_loss().detach", "bevsegmentor.pyva_BEVSegmentor.cycle_loss", "bevsegmentor.pyva_BEVSegmentor._auxiliary_head_forward_train", "dict.update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bevsegmentor.pyva_BEVSegmentor.cycle_loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x_feature", ",", "_", ",", "retransform_features", ",", "forward_features", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "losses", "[", "'feature_loss'", "]", "=", "self", ".", "cycle_loss_weight", "*", "self", ".", "cycle_loss", "(", "retransform_features", ",", "forward_features", ")", ".", "detach", "(", ")", "\n", "losses_feature_loss", "=", "self", ".", "cycle_loss_weight", "*", "self", ".", "cycle_loss", "(", "retransform_features", ",", "forward_features", ")", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x_feature", ",", "img_metas", ",", "\n", "gt_semantic_seg", ")", "\n", "# loss_decode is a dict, loss_decode has the following keys: decode.acc_seg,decode.loss_seg", "\n", "loss_decode", "[", "'decode.loss_seg'", "]", "=", "loss_decode", "[", "'decode.loss_seg'", "]", "+", "losses_feature_loss", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pyva_BEVSegmentor.__init__": [[478, 486], ["bevsegmentor.BEVSegmentor.__init__", "torch.L1Loss", "torch.L1Loss", "torch.L1Loss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "kd_pyva_BEVSegmentor", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "cycle_loss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "kd_loss", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "self", ".", "kd_loss_branch", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "self", ".", "cycle_loss_weight", "=", "0.001", "\n", "self", ".", "kd_loss_weight_main", "=", "0.002", "\n", "self", ".", "kd_loss_weight_branch", "=", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pyva_BEVSegmentor.extract_feat": [[487, 494], ["bevsegmentor.kd_pyva_BEVSegmentor.backbone", "bevsegmentor.kd_pyva_BEVSegmentor.transformer", "bevsegmentor.kd_pyva_BEVSegmentor.neck"], "methods", ["None"], ["", "def", "extract_feat", "(", "self", ",", "img", ",", "calib", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "output", ",", "retransform_features", ",", "forward_features", ",", "notlearn_feats", ",", "learn_feats", ",", "notlearn_list", ",", "learn_list", "=", "self", ".", "transformer", "(", "x", ",", "calib", ")", "\n", "return", "output", ",", "retransform_features", ",", "forward_features", ",", "notlearn_feats", ",", "learn_feats", ",", "notlearn_list", ",", "learn_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pyva_BEVSegmentor.encode_decode": [[495, 502], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.kd_pyva_BEVSegmentor.extract_feat", "bevsegmentor.kd_pyva_BEVSegmentor._decode_head_forward_test", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "img_metas", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pyva_BEVSegmentor.forward_train": [[503, 522], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.kd_pyva_BEVSegmentor.extract_feat", "dict", "bevsegmentor.kd_pyva_BEVSegmentor._decode_head_forward_train", "dict.update", "bevsegmentor.kd_pyva_BEVSegmentor.cycle_loss().detach", "bevsegmentor.kd_pyva_BEVSegmentor.cycle_loss", "bevsegmentor.kd_pyva_BEVSegmentor.kd_loss().detach", "bevsegmentor.kd_pyva_BEVSegmentor.kd_loss", "sum().detach", "sum", "bevsegmentor.kd_pyva_BEVSegmentor._auxiliary_head_forward_train", "dict.update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bevsegmentor.kd_pyva_BEVSegmentor.cycle_loss", "bevsegmentor.kd_pyva_BEVSegmentor.kd_loss", "sum", "bevsegmentor.kd_pyva_BEVSegmentor.kd_loss_branch", "range", "bevsegmentor.kd_pyva_BEVSegmentor.kd_loss_branch", "range"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x_feature", ",", "retransform_features", ",", "forward_features", ",", "notlearn_feats", ",", "learn_feats", ",", "notlearn_list", ",", "learn_list", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "losses", "[", "'feature_loss'", "]", "=", "self", ".", "cycle_loss_weight", "*", "self", ".", "cycle_loss", "(", "retransform_features", ",", "forward_features", ")", ".", "detach", "(", ")", "\n", "losses_feature_loss", "=", "self", ".", "cycle_loss_weight", "*", "self", ".", "cycle_loss", "(", "retransform_features", ",", "forward_features", ")", "\n", "losses", "[", "'kd_loss'", "]", "=", "self", ".", "kd_loss_weight_main", "*", "self", ".", "kd_loss", "(", "learn_feats", ",", "notlearn_feats", ")", ".", "detach", "(", ")", "\n", "losses_kd_loss", "=", "self", ".", "kd_loss_weight_main", "*", "self", ".", "kd_loss", "(", "learn_feats", ",", "notlearn_feats", ")", "\n", "losses", "[", "'kd_loss_branch'", "]", "=", "self", ".", "kd_loss_weight_branch", "*", "sum", "(", "[", "self", ".", "kd_loss_branch", "(", "learn_list", "[", "i", "]", ",", "notlearn_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "5", ")", "]", ")", ".", "detach", "(", ")", "\n", "losses_kd_loss_branch", "=", "self", ".", "kd_loss_weight_branch", "*", "sum", "(", "[", "self", ".", "kd_loss_branch", "(", "learn_list", "[", "i", "]", ",", "notlearn_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "5", ")", "]", ")", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "# loss_decode is a dict, loss_decode has the following keys: decode.acc_seg,decode.loss_seg", "\n", "loss_decode", "[", "'decode.loss_seg'", "]", "=", "loss_decode", "[", "'decode.loss_seg'", "]", "+", "losses_feature_loss", "+", "losses_kd_loss", "+", "losses_kd_loss_branch", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pyva_BEVSegmentor.simple_test": [[523, 541], ["bevsegmentor.kd_pyva_BEVSegmentor.inference", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu().sigmoid", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "bevsegmentor.kd_pyva_BEVSegmentor.test_cfg.get", "bevsegmentor.kd_pyva_BEVSegmentor.test_cfg.get", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "losses.iou", "seg.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "seg.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Simple test with single image.\"\"\"", "\n", "seg_logit", "=", "self", ".", "inference", "(", "img", ",", "img_meta", ",", "False", ")", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "# our inference backend only support 4D output", "\n", "            ", "assert", "False", "\n", "", "seg_logit", "=", "seg_logit", ".", "cpu", "(", ")", ".", "sigmoid", "(", ")", "\n", "positive_thred", "=", "0.5", "\n", "labels", "=", "torch", ".", "tensor", "(", "img_meta", "[", "0", "]", "[", "'gt_semantic_seg'", "]", "[", "None", ",", "...", "]", ")", ".", "bool", "(", ")", "\n", "output_type", "=", "self", ".", "test_cfg", ".", "get", "(", "'output_type'", ",", "'iou'", ")", "\n", "positive_thred", "=", "self", ".", "test_cfg", ".", "get", "(", "'positive_thred'", ",", "0.5", ")", "\n", "if", "output_type", "==", "'iou'", ":", "\n", "            ", "return", "[", "iou", "(", "seg_logit", ">", "positive_thred", ",", "labels", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "labels", "[", ":", ",", "-", "1", ",", "...", "]", ",", "per_class", "=", "True", ")", ",", "]", "\n", "", "elif", "output_type", "==", "'seg'", ":", "\n", "            ", "seg", "=", "seg_logit", ">", "positive_thred", "\n", "return", "[", "(", "seg", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "img_meta", "[", "0", "]", "[", "'filename'", "]", ")", ",", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'unknown output type %s'", "%", "output_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pon_vpn_BEVSegmentor.__init__": [[545, 551], ["bevsegmentor.BEVSegmentor.__init__", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "kd_pon_vpn_BEVSegmentor", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "kd_loss", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "self", ".", "kd_loss_branch", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'mean'", ")", "\n", "self", ".", "kd_loss_weight_main", "=", "0.002", "\n", "self", ".", "kd_loss_weight_branch", "=", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pon_vpn_BEVSegmentor.extract_feat": [[552, 559], ["bevsegmentor.kd_pon_vpn_BEVSegmentor.backbone", "bevsegmentor.kd_pon_vpn_BEVSegmentor.transformer", "bevsegmentor.kd_pon_vpn_BEVSegmentor.neck"], "methods", ["None"], ["", "def", "extract_feat", "(", "self", ",", "img", ",", "calib", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "output", ",", "notlearn_feats", ",", "learn_feats", ",", "notlearn_list", ",", "learn_list", "=", "self", ".", "transformer", "(", "x", ",", "calib", ")", "\n", "return", "output", ",", "notlearn_feats", ",", "learn_feats", ",", "notlearn_list", ",", "learn_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pon_vpn_BEVSegmentor.encode_decode": [[560, 567], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.kd_pon_vpn_BEVSegmentor.extract_feat", "bevsegmentor.kd_pon_vpn_BEVSegmentor._decode_head_forward_test", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "img_metas", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pon_vpn_BEVSegmentor.forward_train": [[568, 585], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.kd_pon_vpn_BEVSegmentor.extract_feat", "dict", "bevsegmentor.kd_pon_vpn_BEVSegmentor._decode_head_forward_train", "dict.update", "bevsegmentor.kd_pon_vpn_BEVSegmentor.kd_loss().detach", "bevsegmentor.kd_pon_vpn_BEVSegmentor.kd_loss", "sum().detach", "sum", "bevsegmentor.kd_pon_vpn_BEVSegmentor._auxiliary_head_forward_train", "dict.update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bevsegmentor.kd_pon_vpn_BEVSegmentor.kd_loss", "sum", "bevsegmentor.kd_pon_vpn_BEVSegmentor.kd_loss_branch", "range", "bevsegmentor.kd_pon_vpn_BEVSegmentor.kd_loss_branch", "range"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x_feature", ",", "notlearn_feats", ",", "learn_feats", ",", "notlearn_list", ",", "learn_list", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "losses", "[", "'kd_loss'", "]", "=", "self", ".", "kd_loss_weight_main", "*", "self", ".", "kd_loss", "(", "learn_feats", ",", "notlearn_feats", ")", ".", "detach", "(", ")", "\n", "losses_kd_loss", "=", "self", ".", "kd_loss_weight_main", "*", "self", ".", "kd_loss", "(", "learn_feats", ",", "notlearn_feats", ")", "\n", "losses", "[", "'kd_loss_branch'", "]", "=", "self", ".", "kd_loss_weight_branch", "*", "sum", "(", "[", "self", ".", "kd_loss_branch", "(", "learn_list", "[", "i", "]", ",", "notlearn_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "5", ")", "]", ")", ".", "detach", "(", ")", "\n", "losses_kd_loss_branch", "=", "self", ".", "kd_loss_weight_branch", "*", "sum", "(", "[", "self", ".", "kd_loss_branch", "(", "learn_list", "[", "i", "]", ",", "notlearn_list", "[", "i", "]", ")", "for", "i", "in", "range", "(", "5", ")", "]", ")", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "# loss_decode is a dict, loss_decode has the following keys: decode.acc_seg,decode.loss_seg", "\n", "loss_decode", "[", "'decode.loss_seg'", "]", "=", "loss_decode", "[", "'decode.loss_seg'", "]", "+", "losses_kd_loss", "+", "losses_kd_loss_branch", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.kd_pon_vpn_BEVSegmentor.simple_test": [[586, 604], ["bevsegmentor.kd_pon_vpn_BEVSegmentor.inference", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "torch.onnx.is_in_onnx_export", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu().sigmoid", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "torch.tensor().bool", "bevsegmentor.kd_pon_vpn_BEVSegmentor.test_cfg.get", "bevsegmentor.kd_pon_vpn_BEVSegmentor.test_cfg.get", "seg_logit.cpu().sigmoid.cpu().sigmoid.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "losses.iou", "seg.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "torch.tensor().bool.cpu().numpy", "seg.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu", "torch.tensor().bool.cpu"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor.inference", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "def", "simple_test", "(", "self", ",", "img", ",", "img_meta", ",", "rescale", "=", "False", ")", ":", "\n", "        ", "\"\"\"Simple test with single image.\"\"\"", "\n", "seg_logit", "=", "self", ".", "inference", "(", "img", ",", "img_meta", ",", "False", ")", "\n", "if", "torch", ".", "onnx", ".", "is_in_onnx_export", "(", ")", ":", "\n", "# our inference backend only support 4D output", "\n", "            ", "assert", "False", "\n", "", "seg_logit", "=", "seg_logit", ".", "cpu", "(", ")", ".", "sigmoid", "(", ")", "\n", "positive_thred", "=", "0.5", "\n", "labels", "=", "torch", ".", "tensor", "(", "img_meta", "[", "0", "]", "[", "'gt_semantic_seg'", "]", "[", "None", ",", "...", "]", ")", ".", "bool", "(", ")", "\n", "output_type", "=", "self", ".", "test_cfg", ".", "get", "(", "'output_type'", ",", "'iou'", ")", "\n", "positive_thred", "=", "self", ".", "test_cfg", ".", "get", "(", "'positive_thred'", ",", "0.5", ")", "\n", "if", "output_type", "==", "'iou'", ":", "\n", "            ", "return", "[", "iou", "(", "seg_logit", ",", "labels", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "labels", "[", ":", ",", "-", "1", ",", "...", "]", ",", "per_class", "=", "True", ")", ",", "]", "\n", "", "elif", "output_type", "==", "'seg'", ":", "\n", "            ", "seg", "=", "seg_logit", ">", "positive_thred", "\n", "return", "[", "(", "seg", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "img_meta", "[", "0", "]", "[", "'filename'", "]", ")", ",", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "'unknown output type %s'", "%", "output_type", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.__init__": [[608, 612], ["bevsegmentor.BEVSegmentor.__init__", "torch.L1Loss", "torch.L1Loss", "torch.L1Loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "force_lss_BEVSegmentor", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "force_loss", "=", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "force_loss_weight", "=", "0.001", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat": [[613, 620], ["bevsegmentor.force_lss_BEVSegmentor.backbone", "bevsegmentor.force_lss_BEVSegmentor.transformer", "bevsegmentor.force_lss_BEVSegmentor.neck"], "methods", ["None"], ["", "def", "extract_feat", "(", "self", ",", "img", ",", "calib", ")", ":", "\n", "        ", "\"\"\"Extract features from images.\"\"\"", "\n", "x", "=", "self", ".", "backbone", "(", "img", ")", "\n", "if", "self", ".", "with_neck", ":", "\n", "            ", "x", "=", "self", ".", "neck", "(", "x", ")", "\n", "", "output", ",", "learn_feats", ",", "notlearn_feats", "=", "self", ".", "transformer", "(", "x", ",", "calib", ")", "\n", "return", "output", ",", "learn_feats", ",", "notlearn_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.encode_decode": [[621, 628], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.force_lss_BEVSegmentor.extract_feat", "bevsegmentor.force_lss_BEVSegmentor._decode_head_forward_test", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_test"], ["", "def", "encode_decode", "(", "self", ",", "img", ",", "img_metas", ")", ":", "\n", "        ", "\"\"\"Encode images with backbone and decode into a semantic segmentation\n        map of the same size as input.\"\"\"", "\n", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x", ",", "_", ",", "_", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "out", "=", "self", ".", "_decode_head_forward_test", "(", "x", ",", "img_metas", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.forward_train": [[629, 645], ["torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "bevsegmentor.force_lss_BEVSegmentor.extract_feat", "dict", "bevsegmentor.force_lss_BEVSegmentor._decode_head_forward_train", "dict.update", "bevsegmentor.force_lss_BEVSegmentor.force_loss().detach", "bevsegmentor.force_lss_BEVSegmentor.force_loss", "bevsegmentor.force_lss_BEVSegmentor._auxiliary_head_forward_train", "dict.update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bevsegmentor.force_lss_BEVSegmentor.force_loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.force_lss_BEVSegmentor.extract_feat", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._decode_head_forward_train", "home.repos.pwc.inspect_result.jiayuzou2020_hft.segmentors.bevsegmentor.origin_pyva_BEVSegmentor._auxiliary_head_forward_train"], ["", "def", "forward_train", "(", "self", ",", "img", ",", "img_metas", ",", "gt_semantic_seg", ")", ":", "\n", "        ", "calib", "=", "torch", ".", "stack", "(", "[", "data", "[", "'calib'", "]", "for", "data", "in", "img_metas", "]", ")", ".", "to", "(", "img", ")", "\n", "x_feature", ",", "learn_feats", ",", "notlearn_feats", "=", "self", ".", "extract_feat", "(", "img", ",", "calib", ")", "\n", "losses", "=", "dict", "(", ")", "\n", "losses", "[", "'learnable_loss'", "]", "=", "self", ".", "force_loss_weight", "*", "self", ".", "force_loss", "(", "learn_feats", ",", "notlearn_feats", ")", ".", "detach", "(", ")", "\n", "losses_learnable_loss", "=", "self", ".", "force_loss_weight", "*", "self", ".", "force_loss", "(", "learn_feats", ",", "notlearn_feats", ")", "\n", "loss_decode", "=", "self", ".", "_decode_head_forward_train", "(", "x_feature", ",", "img_metas", ",", "\n", "gt_semantic_seg", ")", "\n", "# loss_decode is a dict, loss_decode has the following keys: decode.acc_seg,decode.loss_seg", "\n", "loss_decode", "[", "'decode.loss_seg'", "]", "=", "loss_decode", "[", "'decode.loss_seg'", "]", "+", "losses_learnable_loss", "\n", "losses", ".", "update", "(", "loss_decode", ")", "\n", "if", "self", ".", "with_auxiliary_head", ":", "\n", "            ", "loss_aux", "=", "self", ".", "_auxiliary_head_forward_train", "(", "\n", "x_feature", ",", "img_metas", ",", "gt_semantic_seg", ")", "\n", "losses", ".", "update", "(", "loss_aux", ")", "\n", "", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.OccupancyCriterion.__init__": [[27, 44], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "priors", "=", "[", "0.34602", ",", "0.03698", ",", "0.00207", ",", "0.01085", ",", "0.00243", ",", "0.01085", ",", "0.02041", ",", "0.00132", "]", ",", "\n", "xent_weight", "=", "1.", ",", "uncert_weight", "=", "0.001", ",", "\n", "weight_mode", "=", "'sqrt_inverse'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "xent_weight", "=", "xent_weight", "\n", "self", ".", "uncert_weight", "=", "uncert_weight", "\n", "\n", "self", ".", "priors", "=", "torch", ".", "tensor", "(", "priors", ")", "\n", "if", "weight_mode", "==", "'inverse'", ":", "\n", "            ", "self", ".", "class_weights", "=", "1", "/", "self", ".", "priors", "\n", "", "elif", "weight_mode", "==", "'sqrt_inverse'", ":", "\n", "            ", "self", ".", "class_weights", "=", "torch", ".", "sqrt", "(", "1", "/", "self", ".", "priors", ")", "\n", "", "elif", "weight_mode", "==", "'equal'", ":", "\n", "            ", "self", ".", "class_weights", "=", "torch", ".", "ones_like", "(", "self", ".", "priors", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown weight mode option: '", "+", "weight_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.OccupancyCriterion.forward": [[45, 57], ["pyramid_head_argoverse.OccupancyCriterion.class_weights.to", "pyramid_head_argoverse.balanced_binary_cross_entropy", "pyramid_head_argoverse.OccupancyCriterion.priors.to", "pyramid_head_argoverse.prior_uncertainty_loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.balanced_binary_cross_entropy", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.prior_uncertainty_loss"], ["", "", "def", "forward", "(", "self", ",", "logits", ",", "labels", ",", "mask", ",", "*", "args", ")", ":", "\n", "# Compute binary cross entropy loss", "\n", "# only to load self.class_weights and logits to the same device", "\n", "        ", "self", ".", "class_weights", "=", "self", ".", "class_weights", ".", "to", "(", "logits", ")", "\n", "bce_loss", "=", "balanced_binary_cross_entropy", "(", "\n", "logits", ",", "labels", ",", "mask", ",", "self", ".", "class_weights", ")", "\n", "\n", "# Compute uncertainty loss for unknown image regions", "\n", "self", ".", "priors", "=", "self", ".", "priors", ".", "to", "(", "logits", ")", "\n", "uncert_loss", "=", "prior_uncertainty_loss", "(", "logits", ",", "mask", ",", "self", ".", "priors", ")", "\n", "\n", "return", "bce_loss", "*", "self", ".", "xent_weight", "+", "uncert_loss", "*", "self", ".", "uncert_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.LinearClassifier.__init__": [[61, 63], ["torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "num_classes", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.LinearClassifier.initialise": [[64, 68], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pyramid_head_argoverse.LinearClassifier.weight.data.zero_", "pyramid_head_argoverse.LinearClassifier.bias.data.copy_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "initialise", "(", "self", ",", "prior", ")", ":", "\n", "        ", "prior", "=", "torch", ".", "tensor", "(", "prior", ")", "\n", "self", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "log", "(", "prior", "/", "(", "1", "-", "prior", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.TopdownNetwork.__init__": [[72, 90], ["list", "zip", "torch.Sequential.__init__", "pyramid_head_argoverse.ResNetLayer", "list.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "layers", "=", "[", "6", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", "]", ",", "blocktype", "=", "'basic'", ")", ":", "\n", "        ", "modules", "=", "list", "(", ")", "\n", "self", ".", "downsample", "=", "1", "\n", "for", "nblocks", ",", "stride", "in", "zip", "(", "layers", ",", "strides", ")", ":", "\n", "# Add a new residual layer", "\n", "            ", "module", "=", "ResNetLayer", "(", "\n", "in_channels", ",", "channels", ",", "nblocks", ",", "1", "/", "stride", ",", "blocktype", "=", "blocktype", ")", "\n", "modules", ".", "append", "(", "module", ")", "\n", "\n", "# Halve the number of channels at each layer", "\n", "in_channels", "=", "module", ".", "out_channels", "\n", "channels", "=", "channels", "//", "2", "\n", "self", ".", "downsample", "*=", "stride", "\n", "\n", "", "self", ".", "out_channels", "=", "in_channels", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.BasicBlock.__init__": [[125, 139], ["torch.Module.__init__", "pyramid_head_argoverse.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head_argoverse.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyramid_head_argoverse.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "1", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "inplanes", ",", "planes", ",", "stride", ")", ",", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.BasicBlock.forward": [[140, 153], ["torch.relu", "torch.relu", "torch.relu", "pyramid_head_argoverse.BasicBlock.bn2", "torch.relu", "torch.relu", "torch.relu", "pyramid_head_argoverse.BasicBlock.bn1", "pyramid_head_argoverse.BasicBlock.conv2", "pyramid_head_argoverse.BasicBlock.downsample", "pyramid_head_argoverse.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu", "(", "out", ",", "inplace", "=", "True", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.Bottleneck.__init__": [[158, 173], ["torch.Module.__init__", "pyramid_head_argoverse.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head_argoverse.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head_argoverse.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyramid_head_argoverse.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "planes", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "self", ".", "expansion", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "inplanes", ",", "planes", "*", "self", ".", "expansion", ",", "stride", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "16", ",", "planes", "*", "self", ".", "expansion", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.Bottleneck.forward": [[174, 188], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "pyramid_head_argoverse.Bottleneck.bn3", "torch.relu", "torch.relu", "torch.relu", "pyramid_head_argoverse.Bottleneck.bn1", "pyramid_head_argoverse.Bottleneck.bn2", "pyramid_head_argoverse.Bottleneck.conv3", "pyramid_head_argoverse.Bottleneck.downsample", "pyramid_head_argoverse.Bottleneck.conv1", "pyramid_head_argoverse.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.ResNetLayer.__init__": [[192, 212], ["range", "torch.Sequential.__init__", "block", "layers.append", "Exception", "block", "str"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "num_blocks", ",", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "blocktype", "=", "'bottleneck'", ")", ":", "\n", "\n", "# Get block type", "\n", "        ", "if", "blocktype", "==", "'basic'", ":", "\n", "            ", "block", "=", "BasicBlock", "\n", "", "elif", "blocktype", "==", "'bottleneck'", ":", "\n", "            ", "block", "=", "Bottleneck", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Unknown residual block type: \"", "+", "str", "(", "blocktype", ")", ")", "\n", "\n", "# Construct layers", "\n", "", "layers", "=", "[", "block", "(", "in_channels", ",", "channels", ",", "stride", ",", "dilation", ")", "]", "\n", "for", "_", "in", "range", "(", "1", ",", "num_blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "channels", "*", "block", ".", "expansion", ",", "channels", ",", "1", ",", "dilation", ")", ")", "\n", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "channels", "*", "block", ".", "expansion", "\n", "\n", "super", "(", "ResNetLayer", ",", "self", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.PyramidHeadArgoverse.__init__": [[226, 238], ["mmcv.runner.BaseModule.__init__", "pyramid_head_argoverse.TopdownNetwork", "pyramid_head_argoverse.LinearClassifier", "pyramid_head_argoverse.PyramidHeadArgoverse.classifier.initialise", "pyramid_head_argoverse.OccupancyCriterion"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.LinearClassifier.initialise"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "align_corners", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PyramidHeadArgoverse", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "# Build topdown network", "\n", "self", ".", "topdown", "=", "TopdownNetwork", "(", "64", ",", "128", ",", "[", "4", ",", "4", "]", ",", "[", "1", ",", "2", "]", ",", "'bottleneck'", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "align_corners", "=", "align_corners", "\n", "\n", "# Build classifier", "\n", "self", ".", "classifier", "=", "LinearClassifier", "(", "self", ".", "topdown", ".", "out_channels", ",", "self", ".", "num_classes", ")", "\n", "\n", "self", ".", "classifier", ".", "initialise", "(", "[", "0.34602", ",", "0.03698", ",", "0.00207", ",", "0.01085", ",", "0.00243", ",", "0.01085", ",", "0.02041", ",", "0.00132", "]", ")", "\n", "self", ".", "criterion", "=", "OccupancyCriterion", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.PyramidHeadArgoverse.forward": [[239, 247], ["pyramid_head_argoverse.PyramidHeadArgoverse.topdown", "pyramid_head_argoverse.PyramidHeadArgoverse.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "# Apply topdown network", "\n", "td_feats", "=", "self", ".", "topdown", "(", "inputs", ")", "\n", "\n", "# Predict individual class log-probabilities", "\n", "logits", "=", "self", ".", "classifier", "(", "td_feats", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.PyramidHeadArgoverse.forward_train": [[248, 267], ["pyramid_head_argoverse.PyramidHeadArgoverse.forward", "pyramid_head_argoverse.PyramidHeadArgoverse.losses"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.losses"], ["", "def", "forward_train", "(", "self", ",", "inputs", ",", "img_metas", ",", "gt_semantic_seg", ",", "train_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n            train_cfg (dict): The training config.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "seg_logits", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "losses", "=", "self", ".", "losses", "(", "seg_logits", ",", "gt_semantic_seg", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.PyramidHeadArgoverse.forward_test": [[268, 284], ["pyramid_head_argoverse.PyramidHeadArgoverse.forward"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward"], ["", "def", "forward_test", "(", "self", ",", "inputs", ",", "img_metas", ",", "test_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for testing.\n\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            test_cfg (dict): The testing config.\n\n        Returns:\n            Tensor: Output segmentation map.\n        \"\"\"", "\n", "return", "self", ".", "forward", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.PyramidHeadArgoverse.losses": [[285, 293], ["mmcv.runner.force_fp32", "seg_label.squeeze().bool.squeeze().bool.squeeze().bool", "dict", "losses.iou", "pyramid_head_argoverse.PyramidHeadArgoverse.criterion", "seg_label.squeeze().bool.squeeze().bool.squeeze", "seg_logit.detach().sigmoid", "seg_logit.detach"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "@", "force_fp32", "(", "apply_to", "=", "(", "'seg_logit'", ",", ")", ")", "\n", "def", "losses", "(", "self", ",", "seg_logit", ",", "seg_label", ")", ":", "\n", "        ", "\"\"\"Compute segmentation loss.\"\"\"", "\n", "seg_label", "=", "seg_label", ".", "squeeze", "(", "1", ")", ".", "bool", "(", ")", "\n", "loss", "=", "dict", "(", ")", "\n", "loss", "[", "'acc_seg'", "]", "=", "iou", "(", "seg_logit", ".", "detach", "(", ")", ".", "sigmoid", "(", ")", ">", "0.5", ",", "seg_label", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "seg_label", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "loss", "[", "'loss_seg'", "]", "=", "self", ".", "criterion", "(", "seg_logit", ",", "seg_label", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "seg_label", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.prior_uncertainty_loss": [[14, 18], ["x.new().view().expand_as", "torch.binary_cross_entropy_with_logits", "x.new().view", "x.new"], "function", ["None"], ["def", "prior_uncertainty_loss", "(", "x", ",", "mask", ",", "priors", ")", ":", "\n", "    ", "priors", "=", "x", ".", "new", "(", "priors", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "xent", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "x", ",", "priors", ",", "reduce", "=", "False", ")", "\n", "return", "(", "xent", "*", "(", "~", "mask", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.balanced_binary_cross_entropy": [[19, 23], ["torch.binary_cross_entropy_with_logits", "mask.unsqueeze().float", "labels.float", "labels.float", "logits.new().view", "mask.unsqueeze", "logits.new"], "function", ["None"], ["", "def", "balanced_binary_cross_entropy", "(", "logits", ",", "labels", ",", "mask", ",", "weights", ")", ":", "\n", "    ", "weights", "=", "(", "logits", ".", "new", "(", "weights", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "-", "1", ")", "*", "labels", ".", "float", "(", ")", "+", "1.", "\n", "weights", "=", "weights", "*", "mask", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ".", "float", "(", ")", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.conv3x3": [[92, 107], ["torch.Conv2d", "int", "int", "torch.ConvTranspose2d", "round", "int"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "\n", "# Fractional strides correspond to transpose convolution", "\n", "if", "stride", "<", "1", ":", "\n", "        ", "stride", "=", "int", "(", "round", "(", "1", "/", "stride", ")", ")", "\n", "kernel_size", "=", "stride", "+", "2", "\n", "padding", "=", "int", "(", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", "-", "stride", "+", "1", ")", "/", "2", ")", "\n", "return", "nn", ".", "ConvTranspose2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "output_padding", "=", "0", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "\n", "# Otherwise return normal convolution", "\n", "", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "int", "(", "stride", ")", ",", "\n", "dilation", "=", "dilation", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_argoverse.conv1x1": [[109, 120], ["torch.Conv2d", "int", "int", "torch.ConvTranspose2d", "int"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "\n", "# Fractional strides correspond to transpose convolution", "\n", "if", "int", "(", "1", "/", "stride", ")", ">", "1", ":", "\n", "        ", "stride", "=", "int", "(", "1", "/", "stride", ")", "\n", "return", "nn", ".", "ConvTranspose2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "stride", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n", "", "return", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "int", "(", "stride", ")", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.OccupancyCriterion.__init__": [[26, 44], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "priors", "=", "[", "0.04", "]", ",", "\n", "xent_weight", "=", "1.", ",", "uncert_weight", "=", "0.001", ",", "\n", "weight_mode", "=", "'sqrt_inverse'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "xent_weight", "=", "xent_weight", "\n", "self", ".", "uncert_weight", "=", "uncert_weight", "\n", "\n", "self", ".", "priors", "=", "torch", ".", "tensor", "(", "priors", ")", "\n", "\n", "if", "weight_mode", "==", "'inverse'", ":", "\n", "            ", "self", ".", "class_weights", "=", "1", "/", "self", ".", "priors", "\n", "", "elif", "weight_mode", "==", "'sqrt_inverse'", ":", "\n", "            ", "self", ".", "class_weights", "=", "torch", ".", "sqrt", "(", "1", "/", "self", ".", "priors", ")", "\n", "", "elif", "weight_mode", "==", "'equal'", ":", "\n", "            ", "self", ".", "class_weights", "=", "torch", ".", "ones_like", "(", "self", ".", "priors", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown weight mode option: '", "+", "weight_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.OccupancyCriterion.forward": [[45, 56], ["pyramid_head_kitti.OccupancyCriterion.class_weights.to", "pyramid_head_kitti.balanced_binary_cross_entropy", "pyramid_head_kitti.OccupancyCriterion.priors.to", "pyramid_head_kitti.prior_uncertainty_loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.balanced_binary_cross_entropy", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.prior_uncertainty_loss"], ["", "", "def", "forward", "(", "self", ",", "logits", ",", "labels", ",", "mask", ",", "*", "args", ")", ":", "\n", "# Compute binary cross entropy loss", "\n", "        ", "self", ".", "class_weights", "=", "self", ".", "class_weights", ".", "to", "(", "logits", ")", "\n", "bce_loss", "=", "balanced_binary_cross_entropy", "(", "\n", "logits", ",", "labels", ",", "mask", ",", "self", ".", "class_weights", ")", "\n", "\n", "# Compute uncertainty loss for unknown image regions", "\n", "self", ".", "priors", "=", "self", ".", "priors", ".", "to", "(", "logits", ")", "\n", "uncert_loss", "=", "prior_uncertainty_loss", "(", "logits", ",", "mask", ",", "self", ".", "priors", ")", "\n", "\n", "return", "bce_loss", "*", "self", ".", "xent_weight", "+", "uncert_loss", "*", "self", ".", "uncert_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.LinearClassifier.__init__": [[60, 62], ["torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "num_classes", ",", "1", ")", "\n", "", "def", "initialise", "(", "self", ",", "prior", ")", ":", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.LinearClassifier.initialise": [[62, 66], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pyramid_head_kitti.LinearClassifier.weight.data.zero_", "pyramid_head_kitti.LinearClassifier.bias.data.copy_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "initialise", "(", "self", ",", "prior", ")", ":", "\n", "        ", "prior", "=", "torch", ".", "tensor", "(", "prior", ")", "\n", "self", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "log", "(", "prior", "/", "(", "1", "-", "prior", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.TopdownNetwork.__init__": [[69, 87], ["list", "zip", "torch.Sequential.__init__", "pyramid_head_kitti.ResNetLayer", "list.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "layers", "=", "[", "6", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", "]", ",", "blocktype", "=", "'basic'", ")", ":", "\n", "        ", "modules", "=", "list", "(", ")", "\n", "self", ".", "downsample", "=", "1", "\n", "for", "nblocks", ",", "stride", "in", "zip", "(", "layers", ",", "strides", ")", ":", "\n", "# Add a new residual layer", "\n", "            ", "module", "=", "ResNetLayer", "(", "\n", "in_channels", ",", "channels", ",", "nblocks", ",", "1", "/", "stride", ",", "blocktype", "=", "blocktype", ")", "\n", "modules", ".", "append", "(", "module", ")", "\n", "\n", "# Halve the number of channels at each layer", "\n", "in_channels", "=", "module", ".", "out_channels", "\n", "channels", "=", "channels", "//", "2", "\n", "self", ".", "downsample", "*=", "stride", "\n", "\n", "", "self", ".", "out_channels", "=", "in_channels", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.BasicBlock.__init__": [[122, 136], ["torch.Module.__init__", "pyramid_head_kitti.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head_kitti.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyramid_head_kitti.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "1", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "inplanes", ",", "planes", ",", "stride", ")", ",", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.BasicBlock.forward": [[137, 150], ["torch.relu", "torch.relu", "torch.relu", "pyramid_head_kitti.BasicBlock.bn2", "torch.relu", "torch.relu", "torch.relu", "pyramid_head_kitti.BasicBlock.bn1", "pyramid_head_kitti.BasicBlock.conv2", "pyramid_head_kitti.BasicBlock.downsample", "pyramid_head_kitti.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu", "(", "out", ",", "inplace", "=", "True", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.Bottleneck.__init__": [[155, 170], ["torch.Module.__init__", "pyramid_head_kitti.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head_kitti.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head_kitti.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyramid_head_kitti.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "planes", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "self", ".", "expansion", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "inplanes", ",", "planes", "*", "self", ".", "expansion", ",", "stride", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "16", ",", "planes", "*", "self", ".", "expansion", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.Bottleneck.forward": [[171, 185], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "pyramid_head_kitti.Bottleneck.bn3", "torch.relu", "torch.relu", "torch.relu", "pyramid_head_kitti.Bottleneck.bn1", "pyramid_head_kitti.Bottleneck.bn2", "pyramid_head_kitti.Bottleneck.conv3", "pyramid_head_kitti.Bottleneck.downsample", "pyramid_head_kitti.Bottleneck.conv1", "pyramid_head_kitti.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.ResNetLayer.__init__": [[189, 209], ["range", "torch.Sequential.__init__", "block", "layers.append", "Exception", "block", "str"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "num_blocks", ",", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "blocktype", "=", "'bottleneck'", ")", ":", "\n", "\n", "# Get block type", "\n", "        ", "if", "blocktype", "==", "'basic'", ":", "\n", "            ", "block", "=", "BasicBlock", "\n", "", "elif", "blocktype", "==", "'bottleneck'", ":", "\n", "            ", "block", "=", "Bottleneck", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Unknown residual block type: \"", "+", "str", "(", "blocktype", ")", ")", "\n", "\n", "# Construct layers", "\n", "", "layers", "=", "[", "block", "(", "in_channels", ",", "channels", ",", "stride", ",", "dilation", ")", "]", "\n", "for", "_", "in", "range", "(", "1", ",", "num_blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "channels", "*", "block", ".", "expansion", ",", "channels", ",", "1", ",", "dilation", ")", ")", "\n", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "channels", "*", "block", ".", "expansion", "\n", "\n", "super", "(", "ResNetLayer", ",", "self", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.PyramidHeadKitti.__init__": [[223, 234], ["mmcv.runner.BaseModule.__init__", "pyramid_head_kitti.TopdownNetwork", "pyramid_head_kitti.LinearClassifier", "pyramid_head_kitti.PyramidHeadKitti.classifier.initialise", "pyramid_head_kitti.OccupancyCriterion"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.LinearClassifier.initialise"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "align_corners", "=", "True", ",", "priors", "=", "[", "0.04", "]", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PyramidHeadKitti", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "# Build topdown network", "\n", "self", ".", "topdown", "=", "TopdownNetwork", "(", "64", ",", "128", ",", "[", "4", ",", "4", "]", ",", "[", "1", ",", "2", "]", ",", "'bottleneck'", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "align_corners", "=", "align_corners", "\n", "self", ".", "priors", "=", "priors", "\n", "# Build classifier", "\n", "self", ".", "classifier", "=", "LinearClassifier", "(", "self", ".", "topdown", ".", "out_channels", ",", "self", ".", "num_classes", ")", "\n", "self", ".", "classifier", ".", "initialise", "(", "self", ".", "priors", ")", "\n", "self", ".", "criterion", "=", "OccupancyCriterion", "(", "priors", "=", "self", ".", "priors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.PyramidHeadKitti.forward": [[235, 241], ["pyramid_head_kitti.PyramidHeadKitti.topdown", "pyramid_head_kitti.PyramidHeadKitti.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "# Apply topdown network", "\n", "td_feats", "=", "self", ".", "topdown", "(", "inputs", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "td_feats", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.PyramidHeadKitti.forward_train": [[242, 261], ["pyramid_head_kitti.PyramidHeadKitti.forward", "pyramid_head_kitti.PyramidHeadKitti.losses"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.losses"], ["", "def", "forward_train", "(", "self", ",", "inputs", ",", "img_metas", ",", "gt_semantic_seg", ",", "train_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n            train_cfg (dict): The training config.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "seg_logits", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "losses", "=", "self", ".", "losses", "(", "seg_logits", ",", "gt_semantic_seg", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.PyramidHeadKitti.forward_test": [[262, 278], ["pyramid_head_kitti.PyramidHeadKitti.forward"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward"], ["", "def", "forward_test", "(", "self", ",", "inputs", ",", "img_metas", ",", "test_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for testing.\n\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            test_cfg (dict): The testing config.\n\n        Returns:\n            Tensor: Output segmentation map.\n        \"\"\"", "\n", "return", "self", ".", "forward", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.PyramidHeadKitti.losses": [[279, 287], ["mmcv.runner.force_fp32", "seg_label.squeeze().bool.squeeze().bool.squeeze().bool", "dict", "losses.iou", "pyramid_head_kitti.PyramidHeadKitti.criterion", "seg_label.squeeze().bool.squeeze().bool.squeeze", "seg_logit.detach().sigmoid", "seg_logit.detach"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "@", "force_fp32", "(", "apply_to", "=", "(", "'seg_logit'", ",", ")", ")", "\n", "def", "losses", "(", "self", ",", "seg_logit", ",", "seg_label", ")", ":", "\n", "        ", "\"\"\"Compute segmentation loss.\"\"\"", "\n", "seg_label", "=", "seg_label", ".", "squeeze", "(", "1", ")", ".", "bool", "(", ")", "\n", "loss", "=", "dict", "(", ")", "\n", "loss", "[", "'acc_seg'", "]", "=", "iou", "(", "seg_logit", ".", "detach", "(", ")", ".", "sigmoid", "(", ")", ">", "0.5", ",", "seg_label", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "seg_label", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "loss", "[", "'loss_seg'", "]", "=", "self", ".", "criterion", "(", "seg_logit", ",", "seg_label", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "seg_label", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.prior_uncertainty_loss": [[13, 19], ["x.new().view().expand_as", "torch.binary_cross_entropy_with_logits", "x.new().view", "x.new"], "function", ["None"], ["def", "prior_uncertainty_loss", "(", "x", ",", "mask", ",", "priors", ")", ":", "\n", "# priors shape: [2]-->[1,2,1,1]-->[bs,2,196,200]", "\n", "    ", "priors", "=", "x", ".", "new", "(", "priors", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "# F.binary_cross_entropy_with_logits(x, priors, reduce=False) return a tensor with the shape of x, i.e. [bs,2,196,200]", "\n", "xent", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "x", ",", "priors", ",", "reduce", "=", "False", ")", "\n", "return", "(", "xent", "*", "(", "~", "mask", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.balanced_binary_cross_entropy": [[20, 24], ["torch.binary_cross_entropy_with_logits", "mask.unsqueeze().float", "labels.float", "labels.float", "logits.new().view", "mask.unsqueeze", "logits.new"], "function", ["None"], ["", "def", "balanced_binary_cross_entropy", "(", "logits", ",", "labels", ",", "mask", ",", "weights", ")", ":", "\n", "    ", "weights", "=", "(", "logits", ".", "new", "(", "weights", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "-", "1", ")", "*", "labels", ".", "float", "(", ")", "+", "1.", "\n", "weights", "=", "weights", "*", "mask", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ".", "float", "(", ")", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.conv3x3": [[89, 104], ["torch.Conv2d", "int", "int", "torch.ConvTranspose2d", "round", "int"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "\n", "# Fractional strides correspond to transpose convolution", "\n", "if", "stride", "<", "1", ":", "\n", "        ", "stride", "=", "int", "(", "round", "(", "1", "/", "stride", ")", ")", "\n", "kernel_size", "=", "stride", "+", "2", "\n", "padding", "=", "int", "(", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", "-", "stride", "+", "1", ")", "/", "2", ")", "\n", "return", "nn", ".", "ConvTranspose2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "output_padding", "=", "0", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "\n", "# Otherwise return normal convolution", "\n", "", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "int", "(", "stride", ")", ",", "\n", "dilation", "=", "dilation", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head_kitti.conv1x1": [[106, 117], ["torch.Conv2d", "int", "int", "torch.ConvTranspose2d", "int"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "\n", "# Fractional strides correspond to transpose convolution", "\n", "if", "int", "(", "1", "/", "stride", ")", ">", "1", ":", "\n", "        ", "stride", "=", "int", "(", "1", "/", "stride", ")", "\n", "return", "nn", ".", "ConvTranspose2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "stride", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n", "", "return", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "int", "(", "stride", ")", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.OccupancyCriterion.__init__": [[29, 47], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "priors", "=", "[", "0.44679", ",", "0.02407", ",", "0.14491", ",", "0.02994", ",", "0.02086", ",", "0.00477", ",", "0.00156", ",", "0.00189", ",", "0.00084", ",", "0.00119", ",", "0.00019", ",", "0.00012", ",", "0.00031", ",", "0.00176", "]", ",", "\n", "xent_weight", "=", "1.", ",", "uncert_weight", "=", "0.001", ",", "\n", "weight_mode", "=", "'sqrt_inverse'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "xent_weight", "=", "xent_weight", "\n", "self", ".", "uncert_weight", "=", "uncert_weight", "\n", "\n", "self", ".", "priors", "=", "torch", ".", "tensor", "(", "priors", ")", "\n", "\n", "if", "weight_mode", "==", "'inverse'", ":", "\n", "            ", "self", ".", "class_weights", "=", "1", "/", "self", ".", "priors", "\n", "", "elif", "weight_mode", "==", "'sqrt_inverse'", ":", "\n", "            ", "self", ".", "class_weights", "=", "torch", ".", "sqrt", "(", "1", "/", "self", ".", "priors", ")", "\n", "", "elif", "weight_mode", "==", "'equal'", ":", "\n", "            ", "self", ".", "class_weights", "=", "torch", ".", "ones_like", "(", "self", ".", "priors", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown weight mode option: '", "+", "weight_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.OccupancyCriterion.forward": [[48, 60], ["pyramid_head.OccupancyCriterion.class_weights.to", "pyramid_head.balanced_binary_cross_entropy", "pyramid_head.OccupancyCriterion.priors.to", "pyramid_head.prior_uncertainty_loss"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.balanced_binary_cross_entropy", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.prior_uncertainty_loss"], ["", "", "def", "forward", "(", "self", ",", "logits", ",", "labels", ",", "mask", ",", "*", "args", ")", ":", "\n", "# logits shape: bs,15,196,200,labels shape: bs,14,196,200,mask shape:bs,196,200", "\n", "# Compute binary cross entropy loss", "\n", "        ", "self", ".", "class_weights", "=", "self", ".", "class_weights", ".", "to", "(", "logits", ")", "\n", "bce_loss", "=", "balanced_binary_cross_entropy", "(", "\n", "logits", ",", "labels", ",", "mask", ",", "self", ".", "class_weights", ")", "\n", "\n", "# Compute uncertainty loss for unknown image regions", "\n", "self", ".", "priors", "=", "self", ".", "priors", ".", "to", "(", "logits", ")", "\n", "uncert_loss", "=", "prior_uncertainty_loss", "(", "logits", ",", "mask", ",", "self", ".", "priors", ")", "\n", "\n", "return", "bce_loss", "*", "self", ".", "xent_weight", "+", "uncert_loss", "*", "self", ".", "uncert_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.LinearClassifier.__init__": [[64, 66], ["torch.Conv2d.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "num_classes", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.LinearClassifier.initialise": [[67, 71], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pyramid_head.LinearClassifier.weight.data.zero_", "pyramid_head.LinearClassifier.bias.data.copy_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "initialise", "(", "self", ",", "prior", ")", ":", "\n", "        ", "prior", "=", "torch", ".", "tensor", "(", "prior", ")", "\n", "self", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "log", "(", "prior", "/", "(", "1", "-", "prior", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.TopdownNetwork.__init__": [[75, 93], ["list", "zip", "torch.Sequential.__init__", "pyramid_head.ResNetLayer", "list.append"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "layers", "=", "[", "6", ",", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", "]", ",", "blocktype", "=", "'basic'", ")", ":", "\n", "        ", "modules", "=", "list", "(", ")", "\n", "self", ".", "downsample", "=", "1", "\n", "for", "nblocks", ",", "stride", "in", "zip", "(", "layers", ",", "strides", ")", ":", "\n", "# Add a new residual layer", "\n", "            ", "module", "=", "ResNetLayer", "(", "\n", "in_channels", ",", "channels", ",", "nblocks", ",", "1", "/", "stride", ",", "blocktype", "=", "blocktype", ")", "\n", "modules", ".", "append", "(", "module", ")", "\n", "\n", "# Halve the number of channels at each layer", "\n", "in_channels", "=", "module", ".", "out_channels", "\n", "channels", "=", "channels", "//", "2", "\n", "self", ".", "downsample", "*=", "stride", "\n", "\n", "", "self", ".", "out_channels", "=", "in_channels", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "*", "modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.BasicBlock.__init__": [[127, 141], ["torch.Module.__init__", "pyramid_head.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyramid_head.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "1", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "inplanes", ",", "planes", ",", "stride", ")", ",", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.BasicBlock.forward": [[142, 155], ["torch.relu", "torch.relu", "torch.relu", "pyramid_head.BasicBlock.bn2", "torch.relu", "torch.relu", "torch.relu", "pyramid_head.BasicBlock.bn1", "pyramid_head.BasicBlock.conv2", "pyramid_head.BasicBlock.downsample", "pyramid_head.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu", "(", "out", ",", "inplace", "=", "True", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.Bottleneck.__init__": [[159, 174], ["torch.Module.__init__", "pyramid_head.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head.conv3x3", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "pyramid_head.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Sequential", "torch.Sequential", "torch.Sequential", "pyramid_head.conv1x1", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "planes", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "stride", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "GroupNorm", "(", "16", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "inplanes", "!=", "planes", "*", "self", ".", "expansion", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "inplanes", ",", "planes", "*", "self", ".", "expansion", ",", "stride", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "16", ",", "planes", "*", "self", ".", "expansion", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.Bottleneck.forward": [[175, 189], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "pyramid_head.Bottleneck.bn3", "torch.relu", "torch.relu", "torch.relu", "pyramid_head.Bottleneck.bn1", "pyramid_head.Bottleneck.bn2", "pyramid_head.Bottleneck.conv3", "pyramid_head.Bottleneck.downsample", "pyramid_head.Bottleneck.conv1", "pyramid_head.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ",", "inplace", "=", "True", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.ResNetLayer.__init__": [[192, 212], ["range", "torch.Sequential.__init__", "block", "layers.append", "Exception", "block", "str"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channels", ",", "num_blocks", ",", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ",", "blocktype", "=", "'bottleneck'", ")", ":", "\n", "\n", "# Get block type", "\n", "        ", "if", "blocktype", "==", "'basic'", ":", "\n", "            ", "block", "=", "BasicBlock", "\n", "", "elif", "blocktype", "==", "'bottleneck'", ":", "\n", "            ", "block", "=", "Bottleneck", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Unknown residual block type: \"", "+", "str", "(", "blocktype", ")", ")", "\n", "\n", "# Construct layers", "\n", "", "layers", "=", "[", "block", "(", "in_channels", ",", "channels", ",", "stride", ",", "dilation", ")", "]", "\n", "for", "_", "in", "range", "(", "1", ",", "num_blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "channels", "*", "block", ".", "expansion", ",", "channels", ",", "1", ",", "dilation", ")", ")", "\n", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "channels", "*", "block", ".", "expansion", "\n", "\n", "super", "(", "ResNetLayer", ",", "self", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.PyramidHead.__init__": [[226, 239], ["mmcv.runner.BaseModule.__init__", "pyramid_head.TopdownNetwork", "pyramid_head.LinearClassifier", "pyramid_head.PyramidHead.classifier.initialise", "pyramid_head.OccupancyCriterion"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.LinearClassifier.initialise"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "align_corners", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PyramidHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "# Build topdown network", "\n", "self", ".", "topdown", "=", "TopdownNetwork", "(", "64", ",", "128", ",", "[", "4", ",", "4", "]", ",", "[", "1", ",", "2", "]", ",", "'bottleneck'", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "align_corners", "=", "align_corners", "\n", "\n", "# Build classifier", "\n", "self", ".", "classifier", "=", "LinearClassifier", "(", "self", ".", "topdown", ".", "out_channels", ",", "self", ".", "num_classes", ")", "\n", "\n", "self", ".", "classifier", ".", "initialise", "(", "[", "0.44679", ",", "0.02407", ",", "0.14491", ",", "0.02994", ",", "0.02086", ",", "0.00477", ",", "0.00156", ",", "0.00189", ",", "\n", "0.00084", ",", "0.00119", ",", "0.00019", ",", "0.00012", ",", "0.00031", ",", "0.00176", "]", ")", "\n", "self", ".", "criterion", "=", "OccupancyCriterion", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.PyramidHead.forward": [[240, 248], ["pyramid_head.PyramidHead.topdown", "pyramid_head.PyramidHead.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "# Apply topdown network", "\n", "td_feats", "=", "self", ".", "topdown", "(", "inputs", ")", "\n", "\n", "# Predict individual class log-probabilities", "\n", "logits", "=", "self", ".", "classifier", "(", "td_feats", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.PyramidHead.forward_train": [[249, 270], ["pyramid_head.PyramidHead.forward", "pyramid_head.PyramidHead.losses"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.losses"], ["", "def", "forward_train", "(", "self", ",", "inputs", ",", "img_metas", ",", "gt_semantic_seg", ",", "train_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n            train_cfg (dict): The training config.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "seg_logits", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "losses", "=", "self", ".", "losses", "(", "seg_logits", ",", "gt_semantic_seg", ")", "\n", "# seg_logits.shape :[batch_size,14,196,200]", "\n", "# gt_semantic_seg.shape :[batch_size,1,15,196,200]", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.PyramidHead.forward_test": [[271, 287], ["pyramid_head.PyramidHead.forward"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward"], ["", "def", "forward_test", "(", "self", ",", "inputs", ",", "img_metas", ",", "test_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for testing.\n\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            test_cfg (dict): The testing config.\n\n        Returns:\n            Tensor: Output segmentation map.\n        \"\"\"", "\n", "return", "self", ".", "forward", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.PyramidHead.losses": [[288, 296], ["mmcv.runner.force_fp32", "seg_label.squeeze().bool.squeeze().bool.squeeze().bool", "dict", "losses.iou", "pyramid_head.PyramidHead.criterion", "seg_label.squeeze().bool.squeeze().bool.squeeze", "seg_logit.detach().sigmoid", "seg_logit.detach"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou"], ["", "@", "force_fp32", "(", "apply_to", "=", "(", "'seg_logit'", ",", ")", ")", "\n", "def", "losses", "(", "self", ",", "seg_logit", ",", "seg_label", ")", ":", "\n", "        ", "\"\"\"Compute segmentation loss.\"\"\"", "\n", "seg_label", "=", "seg_label", ".", "squeeze", "(", "1", ")", ".", "bool", "(", ")", "\n", "loss", "=", "dict", "(", ")", "\n", "loss", "[", "'acc_seg'", "]", "=", "iou", "(", "seg_logit", ".", "detach", "(", ")", ".", "sigmoid", "(", ")", ">", "0.5", ",", "seg_label", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "seg_label", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "loss", "[", "'loss_seg'", "]", "=", "self", ".", "criterion", "(", "seg_logit", ",", "seg_label", "[", ":", ",", ":", "-", "1", ",", "...", "]", ",", "seg_label", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.prior_uncertainty_loss": [[14, 20], ["x.new().view().expand_as", "torch.binary_cross_entropy_with_logits", "x.new().view", "x.new"], "function", ["None"], ["def", "prior_uncertainty_loss", "(", "x", ",", "mask", ",", "priors", ")", ":", "\n", "# priors shape: [14]-->[1,14,1,1]-->[bs,14,196,200]", "\n", "    ", "priors", "=", "x", ".", "new", "(", "priors", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "# F.binary_cross_entropy_with_logits(x, priors, reduce=False) return a tensor with the shape of x, i.e. [bs,14,196,200]", "\n", "xent", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "x", ",", "priors", ",", "reduce", "=", "False", ")", "\n", "return", "(", "xent", "*", "(", "~", "mask", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.balanced_binary_cross_entropy": [[21, 26], ["torch.binary_cross_entropy_with_logits", "mask.unsqueeze().float", "labels.float", "labels.float", "logits.new().view", "mask.unsqueeze", "logits.new"], "function", ["None"], ["", "def", "balanced_binary_cross_entropy", "(", "logits", ",", "labels", ",", "mask", ",", "weights", ")", ":", "\n", "# weights shape: [14]-->[14,1,1]-->[bs,14,196,200]", "\n", "    ", "weights", "=", "(", "logits", ".", "new", "(", "weights", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "-", "1", ")", "*", "labels", ".", "float", "(", ")", "+", "1.", "\n", "weights", "=", "weights", "*", "mask", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ".", "float", "(", ")", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv3x3": [[95, 110], ["torch.Conv2d", "int", "int", "torch.ConvTranspose2d", "round", "int"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "\n", "# Fractional strides correspond to transpose convolution", "\n", "if", "stride", "<", "1", ":", "\n", "        ", "stride", "=", "int", "(", "round", "(", "1", "/", "stride", ")", ")", "\n", "kernel_size", "=", "stride", "+", "2", "\n", "padding", "=", "int", "(", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", "-", "stride", "+", "1", ")", "/", "2", ")", "\n", "return", "nn", ".", "ConvTranspose2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "output_padding", "=", "0", ",", "dilation", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "\n", "# Otherwise return normal convolution", "\n", "", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "int", "(", "stride", ")", ",", "\n", "dilation", "=", "dilation", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.pyramid_head.conv1x1": [[112, 123], ["torch.Conv2d", "int", "int", "torch.ConvTranspose2d", "int"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "\n", "# Fractional strides correspond to transpose convolution", "\n", "if", "int", "(", "1", "/", "stride", ")", ">", "1", ":", "\n", "        ", "stride", "=", "int", "(", "1", "/", "stride", ")", "\n", "return", "nn", ".", "ConvTranspose2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "stride", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n", "", "return", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "int", "(", "stride", ")", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.__init__": [[54, 108], ["dict", "dict", "dict", "mmcv.runner.BaseModule.__init__", "decode_head.BaseDecodeHead._init_inputs", "torch.ModuleList", "torch.ModuleList", "isinstance", "torch.Conv2d", "torch.Conv2d", "decode_head.BaseDecodeHead.loss_decode.append", "isinstance", "mmseg.core.build_pixel_sampler", "torch.Dropout2d", "torch.Dropout2d", "dict", "builder.build_loss", "TypeError", "decode_head.BaseDecodeHead.loss_decode.append", "builder.build_loss", "type"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead._init_inputs", "home.repos.pwc.inspect_result.jiayuzou2020_hft.seg.builder.build_pixel_sampler", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_loss", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_loss"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", ",", "\n", "channels", ",", "\n", "*", ",", "\n", "num_classes", ",", "\n", "dropout_ratio", "=", "0.1", ",", "\n", "conv_cfg", "=", "None", ",", "\n", "norm_cfg", "=", "None", ",", "\n", "act_cfg", "=", "dict", "(", "type", "=", "'ReLU'", ")", ",", "\n", "in_index", "=", "-", "1", ",", "\n", "input_transform", "=", "None", ",", "\n", "loss_decode", "=", "dict", "(", "\n", "type", "=", "'CrossEntropyLoss'", ",", "\n", "use_sigmoid", "=", "False", ",", "\n", "loss_weight", "=", "1.0", ")", ",", "\n", "ignore_index", "=", "255", ",", "\n", "sampler", "=", "None", ",", "\n", "align_corners", "=", "False", ",", "\n", "init_cfg", "=", "dict", "(", "\n", "type", "=", "'Normal'", ",", "std", "=", "0.01", ",", "override", "=", "dict", "(", "name", "=", "'conv_seg'", ")", ")", ")", ":", "\n", "        ", "super", "(", "BaseDecodeHead", ",", "self", ")", ".", "__init__", "(", "init_cfg", ")", "\n", "self", ".", "_init_inputs", "(", "in_channels", ",", "in_index", ",", "input_transform", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "dropout_ratio", "=", "dropout_ratio", "\n", "self", ".", "conv_cfg", "=", "conv_cfg", "\n", "self", ".", "norm_cfg", "=", "norm_cfg", "\n", "self", ".", "act_cfg", "=", "act_cfg", "\n", "self", ".", "in_index", "=", "in_index", "\n", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "self", ".", "align_corners", "=", "align_corners", "\n", "self", ".", "loss_decode", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "if", "isinstance", "(", "loss_decode", ",", "dict", ")", ":", "\n", "            ", "self", ".", "loss_decode", ".", "append", "(", "build_loss", "(", "loss_decode", ")", ")", "\n", "", "elif", "isinstance", "(", "loss_decode", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "for", "loss", "in", "loss_decode", ":", "\n", "                ", "self", ".", "loss_decode", ".", "append", "(", "build_loss", "(", "loss", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f'loss_decode must be a dict or sequence of dict,\\\n                but got {type(loss_decode)}'", ")", "\n", "\n", "", "if", "sampler", "is", "not", "None", ":", "\n", "            ", "self", ".", "sampler", "=", "build_pixel_sampler", "(", "sampler", ",", "context", "=", "self", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sampler", "=", "None", "\n", "\n", "", "self", ".", "conv_seg", "=", "nn", ".", "Conv2d", "(", "channels", ",", "num_classes", ",", "kernel_size", "=", "1", ")", "\n", "if", "dropout_ratio", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout2d", "(", "dropout_ratio", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "", "self", ".", "fp16_enabled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.extra_repr": [[109, 115], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Extra repr.\"\"\"", "\n", "s", "=", "f'input_transform={self.input_transform}, '", "f'ignore_index={self.ignore_index}, '", "f'align_corners={self.align_corners}'", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead._init_inputs": [[116, 153], ["isinstance", "isinstance", "isinstance", "isinstance", "len", "len", "sum"], "methods", ["None"], ["", "def", "_init_inputs", "(", "self", ",", "in_channels", ",", "in_index", ",", "input_transform", ")", ":", "\n", "        ", "\"\"\"Check and initialize input transforms.\n\n        The in_channels, in_index and input_transform must match.\n        Specifically, when input_transform is None, only single feature map\n        will be selected. So in_channels and in_index must be of type int.\n        When input_transform\n\n        Args:\n            in_channels (int|Sequence[int]): Input channels.\n            in_index (int|Sequence[int]): Input feature index.\n            input_transform (str|None): Transformation type of input features.\n                Options: 'resize_concat', 'multiple_select', None.\n                'resize_concat': Multiple feature maps will be resize to the\n                    same size as first one and than concat together.\n                    Usually used in FCN head of HRNet.\n                'multiple_select': Multiple feature maps will be bundle into\n                    a list and passed into decode head.\n                None: Only one select feature map is allowed.\n        \"\"\"", "\n", "\n", "if", "input_transform", "is", "not", "None", ":", "\n", "            ", "assert", "input_transform", "in", "[", "'resize_concat'", ",", "'multiple_select'", "]", "\n", "", "self", ".", "input_transform", "=", "input_transform", "\n", "self", ".", "in_index", "=", "in_index", "\n", "if", "input_transform", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "in_channels", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "isinstance", "(", "in_index", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "in_channels", ")", "==", "len", "(", "in_index", ")", "\n", "if", "input_transform", "==", "'resize_concat'", ":", "\n", "                ", "self", ".", "in_channels", "=", "sum", "(", "in_channels", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "in_channels", "=", "in_channels", "\n", "", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "in_channels", ",", "int", ")", "\n", "assert", "isinstance", "(", "in_index", ",", "int", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead._transform_inputs": [[154, 180], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "mmseg.ops.resize"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize"], ["", "", "def", "_transform_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Transform inputs for decoder.\n\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n\n        Returns:\n            Tensor: The transformed inputs\n        \"\"\"", "\n", "\n", "if", "self", ".", "input_transform", "==", "'resize_concat'", ":", "\n", "            ", "inputs", "=", "[", "inputs", "[", "i", "]", "for", "i", "in", "self", ".", "in_index", "]", "\n", "upsampled_inputs", "=", "[", "\n", "resize", "(", "\n", "input", "=", "x", ",", "\n", "size", "=", "inputs", "[", "0", "]", ".", "shape", "[", "2", ":", "]", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ")", "for", "x", "in", "inputs", "\n", "]", "\n", "inputs", "=", "torch", ".", "cat", "(", "upsampled_inputs", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "input_transform", "==", "'multiple_select'", ":", "\n", "            ", "inputs", "=", "[", "inputs", "[", "i", "]", "for", "i", "in", "self", ".", "in_index", "]", "\n", "", "else", ":", "\n", "            ", "inputs", "=", "inputs", "[", "self", ".", "in_index", "]", "\n", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward": [[181, 186], ["mmcv.runner.auto_fp16"], "methods", ["None"], ["", "@", "auto_fp16", "(", ")", "\n", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Placeholder of forward function.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_train": [[187, 206], ["decode_head.BaseDecodeHead.forward", "decode_head.BaseDecodeHead.losses"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward", "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.losses"], ["", "def", "forward_train", "(", "self", ",", "inputs", ",", "img_metas", ",", "gt_semantic_seg", ",", "train_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for training.\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            gt_semantic_seg (Tensor): Semantic segmentation masks\n                used if the architecture supports semantic segmentation task.\n            train_cfg (dict): The training config.\n\n        Returns:\n            dict[str, Tensor]: a dictionary of loss components\n        \"\"\"", "\n", "seg_logits", "=", "self", ".", "forward", "(", "inputs", ")", "\n", "losses", "=", "self", ".", "losses", "(", "seg_logits", ",", "gt_semantic_seg", ")", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.forward_test": [[207, 223], ["decode_head.BaseDecodeHead.forward"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward"], ["", "def", "forward_test", "(", "self", ",", "inputs", ",", "img_metas", ",", "test_cfg", ")", ":", "\n", "        ", "\"\"\"Forward function for testing.\n\n        Args:\n            inputs (list[Tensor]): List of multi-level img features.\n            img_metas (list[dict]): List of image info dict where each dict\n                has: 'img_shape', 'scale_factor', 'flip', and may also contain\n                'filename', 'ori_shape', 'pad_shape', and 'img_norm_cfg'.\n                For details on the values of these keys see\n                `mmseg/datasets/pipelines/formatting.py:Collect`.\n            test_cfg (dict): The testing config.\n\n        Returns:\n            Tensor: Output segmentation map.\n        \"\"\"", "\n", "return", "self", ".", "forward", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.cls_seg": [[224, 230], ["decode_head.BaseDecodeHead.conv_seg", "decode_head.BaseDecodeHead.dropout"], "methods", ["None"], ["", "def", "cls_seg", "(", "self", ",", "feat", ")", ":", "\n", "        ", "\"\"\"Classify each pixel.\"\"\"", "\n", "if", "self", ".", "dropout", "is", "not", "None", ":", "\n", "            ", "feat", "=", "self", ".", "dropout", "(", "feat", ")", "\n", "", "output", "=", "self", ".", "conv_seg", "(", "feat", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.decode_heads.decode_head.BaseDecodeHead.losses": [[231, 261], ["mmcv.runner.force_fp32", "dict", "mmseg.ops.resize", "seg_label.squeeze.squeeze.squeeze", "losses.accuracy", "decode_head.BaseDecodeHead.sampler.sample", "loss_decode", "loss_decode"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.ops.wrappers.resize", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.accuracy.accuracy", "home.repos.pwc.inspect_result.jiayuzou2020_hft.sampler.base_pixel_sampler.BasePixelSampler.sample"], ["", "@", "force_fp32", "(", "apply_to", "=", "(", "'seg_logit'", ",", ")", ")", "\n", "def", "losses", "(", "self", ",", "seg_logit", ",", "seg_label", ")", ":", "\n", "        ", "\"\"\"Compute segmentation loss.\"\"\"", "\n", "loss", "=", "dict", "(", ")", "\n", "seg_logit", "=", "resize", "(", "\n", "input", "=", "seg_logit", ",", "\n", "size", "=", "seg_label", ".", "shape", "[", "2", ":", "]", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "self", ".", "align_corners", ")", "\n", "if", "self", ".", "sampler", "is", "not", "None", ":", "\n", "            ", "seg_weight", "=", "self", ".", "sampler", ".", "sample", "(", "seg_logit", ",", "seg_label", ")", "\n", "", "else", ":", "\n", "            ", "seg_weight", "=", "None", "\n", "", "seg_label", "=", "seg_label", ".", "squeeze", "(", "1", ")", "\n", "for", "loss_decode", "in", "self", ".", "loss_decode", ":", "\n", "            ", "if", "loss_decode", ".", "loss_name", "not", "in", "loss", ":", "\n", "                ", "loss", "[", "loss_decode", ".", "loss_name", "]", "=", "loss_decode", "(", "\n", "seg_logit", ",", "\n", "seg_label", ",", "\n", "weight", "=", "seg_weight", ",", "\n", "ignore_index", "=", "self", ".", "ignore_index", ")", "\n", "", "else", ":", "\n", "                ", "loss", "[", "loss_decode", ".", "loss_name", "]", "+=", "loss_decode", "(", "\n", "seg_logit", ",", "\n", "seg_label", ",", "\n", "weight", "=", "seg_weight", ",", "\n", "ignore_index", "=", "self", ".", "ignore_index", ")", "\n", "\n", "", "", "loss", "[", "'acc_seg'", "]", "=", "accuracy", "(", "seg_logit", ",", "seg_label", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.iou.iou": [[2, 37], ["preds.flatten().permute().reshape.flatten().permute().reshape", "labels.flatten().permute().reshape.flatten().permute().reshape", "true_pos.long", "false_pos.long", "false_neg.long", "preds.flatten().permute().reshape.flatten().permute", "labels.flatten().permute().reshape.flatten().permute", "true_pos.long.sum().float", "labels.flatten().permute().reshape.int().sum", "true_pos.long.sum", "false_pos.long.sum", "false_neg.long.sum", "preds.flatten().permute().reshape.flatten", "labels.flatten().permute().reshape.flatten", "mask.flatten", "mask.flatten", "true_pos.long.sum", "labels.flatten().permute().reshape.int", "false_pos.long.sum", "true_pos.long.sum", "false_neg.long.sum"], "function", ["None"], ["def", "iou", "(", "preds", ",", "labels", ",", "mask", "=", "None", ",", "per_class", "=", "False", ")", ":", "\n", "    ", "\"\"\"iou calculation.\n    Args:\n        pred (torch.Tensor): The model prediction, shape (N, num_class, ...)\n        labels (torch.Tensor): The target of each prediction, shape (N, num_class, ...)\n        mask (float, optional): The target of each prediction, shape (N,1, ...)\n    Returns:\n        float | tuple[float]: If the input ``topk`` is a single integer,\n            the function will return a single float as accuracy. If\n            ``topk`` is a tuple containing multiple integers, the\n            function will return a tuple containing accuracies of\n            each ``topk`` number.\n    \"\"\"", "\n", "num_class", "=", "preds", ".", "shape", "[", "1", "]", "\n", "# preds.shape:[n,c,h,w]   labels.shape:[n,c,h,w]  mask.shape:[n,1,h,w]", "\n", "preds", "=", "preds", ".", "flatten", "(", "2", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "reshape", "(", "num_class", ",", "-", "1", ")", "# preds.shape:[c,n x h x w]", "\n", "labels", "=", "labels", ".", "flatten", "(", "2", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "reshape", "(", "num_class", ",", "-", "1", ")", "# labelss.shape:[c,n x h x w]", "\n", "# mask is used to discriminate background and foreground ", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# ignore background both in preds and labels", "\n", "        ", "preds", "=", "preds", "[", ":", ",", "mask", ".", "flatten", "(", ")", "]", "\n", "labels", "=", "labels", "[", ":", ",", "mask", ".", "flatten", "(", ")", "]", "\n", "", "true_pos", "=", "preds", "&", "labels", "\n", "false_pos", "=", "preds", "&", "~", "labels", "\n", "false_neg", "=", "~", "preds", "&", "labels", "\n", "tp", "=", "true_pos", ".", "long", "(", ")", "\n", "fp", "=", "false_pos", ".", "long", "(", ")", "\n", "fn", "=", "false_neg", ".", "long", "(", ")", "\n", "# tp.sum() means all the tp in all the images,tp.sum(-1) means tp in each class", "\n", "if", "not", "per_class", ":", "\n", "        ", "return", "tp", ".", "sum", "(", ")", ".", "float", "(", ")", "/", "(", "tp", ".", "sum", "(", ")", "+", "fn", ".", "sum", "(", ")", "+", "fp", ".", "sum", "(", ")", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "# valids: only to choose the positive samples,tp.sum(-1).shape: [1,num_classes]", "\n", "        ", "valid", "=", "labels", ".", "int", "(", ")", ".", "sum", "(", "-", "1", ")", ">", "0", "\n", "return", "tp", ".", "sum", "(", "-", "1", ")", ",", "fp", ".", "sum", "(", "-", "1", ")", ",", "fn", ".", "sum", "(", "-", "1", ")", ",", "valid", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.prior_uncertainty_loss": [[5, 9], ["x.new().view().expand_as", "torch.binary_cross_entropy_with_logits", "x.new().view", "x.new"], "function", ["None"], ["def", "prior_uncertainty_loss", "(", "x", ",", "mask", ",", "priors", ")", ":", "\n", "    ", "priors", "=", "x", ".", "new", "(", "priors", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "xent", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "x", ",", "priors", ",", "reduce", "=", "False", ")", "\n", "return", "(", "xent", "*", "(", "~", "mask", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.balanced_binary_cross_entropy": [[10, 14], ["torch.binary_cross_entropy_with_logits", "mask.unsqueeze().float", "labels.float", "labels.float", "logits.new().view", "mask.unsqueeze", "logits.new"], "function", ["None"], ["", "def", "balanced_binary_cross_entropy", "(", "logits", ",", "labels", ",", "mask", ",", "weights", ")", ":", "\n", "    ", "weights", "=", "(", "logits", ".", "new", "(", "weights", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "-", "1", ")", "*", "labels", ".", "float", "(", ")", "+", "1.", "\n", "weights", "=", "weights", "*", "mask", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ".", "float", "(", ")", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.occupancyloss": [[15, 35], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.sqrt", "torch.sqrt", "torch.sqrt", "class_weights.cpu.to", "logits.cpu.cpu", "labels.cpu.cpu", "mask.cpu.cpu", "class_weights.cpu.cpu", "occupancy.balanced_binary_cross_entropy", "priors.to.to", "occupancy.prior_uncertainty_loss"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.balanced_binary_cross_entropy", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.occupancy.prior_uncertainty_loss"], ["", "def", "occupancyloss", "(", "logits", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "priors", "=", "[", "0.04", "]", "\n", "xent_weight", "=", "1.0", "\n", "uncert_weight", "=", "0.001", "\n", "\n", "priors", "=", "torch", ".", "tensor", "(", "priors", ")", "\n", "class_weights", "=", "torch", ".", "sqrt", "(", "1", "/", "priors", ")", "\n", "\n", "# Compute binary cross entropy loss", "\n", "class_weights", "=", "class_weights", ".", "to", "(", "logits", ")", "\n", "logits", "=", "logits", ".", "cpu", "(", ")", "\n", "labels", "=", "labels", ".", "cpu", "(", ")", "\n", "mask", "=", "mask", ".", "cpu", "(", ")", "\n", "class_weights", "=", "class_weights", ".", "cpu", "(", ")", "\n", "bce_loss", "=", "balanced_binary_cross_entropy", "(", "logits", ",", "labels", ",", "mask", ",", "class_weights", ")", "\n", "\n", "# Compute uncertainty loss for unknown image regions", "\n", "priors", "=", "priors", ".", "to", "(", "logits", ")", "\n", "uncert_loss", "=", "prior_uncertainty_loss", "(", "logits", ",", "mask", ",", "priors", ")", "\n", "return", "bce_loss", "*", "xent_weight", "+", "uncert_loss", "*", "uncert_weight", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.accuracy.Accuracy.__init__": [[60, 72], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "topk", "=", "(", "1", ",", ")", ",", "thresh", "=", "None", ")", ":", "\n", "        ", "\"\"\"Module to calculate the accuracy.\n\n        Args:\n            topk (tuple, optional): The criterion used to calculate the\n                accuracy. Defaults to (1,).\n            thresh (float, optional): If not None, predictions with scores\n                under this threshold are considered incorrect. Default to None.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "thresh", "=", "thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.accuracy.Accuracy.forward": [[73, 84], ["accuracy.accuracy"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.accuracy.accuracy"], ["", "def", "forward", "(", "self", ",", "pred", ",", "target", ")", ":", "\n", "        ", "\"\"\"Forward function to calculate accuracy.\n\n        Args:\n            pred (torch.Tensor): Prediction of models.\n            target (torch.Tensor): Target for each prediction.\n\n        Returns:\n            tuple[float]: The accuracies under different topk criterions.\n        \"\"\"", "\n", "return", "accuracy", "(", "pred", ",", "target", ",", "self", ".", "topk", ",", "self", ".", "thresh", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.accuracy.accuracy": [[5, 55], ["isinstance", "isinstance", "max", "pred.topk", "pred_label.transpose.transpose", "pred_label.transpose.eq", "pred.size", "pred.size", "target.size", "pred.size", "target.unsqueeze().expand_as", "correct[].reshape().float().sum", "res.append", "pred.new_tensor", "pred.size", "correct[].reshape().float().sum.mul_", "range", "target.unsqueeze", "correct[].reshape().float", "len", "target.numel", "correct[].reshape"], "function", ["None"], ["def", "accuracy", "(", "pred", ",", "target", ",", "topk", "=", "1", ",", "thresh", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate accuracy according to the prediction and target.\n\n    Args:\n        pred (torch.Tensor): The model prediction, shape (N, num_class, ...)\n        target (torch.Tensor): The target of each prediction, shape (N, , ...)\n        topk (int | tuple[int], optional): If the predictions in ``topk``\n            matches the target, the predictions will be regarded as\n            correct ones. Defaults to 1.\n        thresh (float, optional): If not None, predictions with scores under\n            this threshold are considered incorrect. Default to None.\n\n    Returns:\n        float | tuple[float]: If the input ``topk`` is a single integer,\n            the function will return a single float as accuracy. If\n            ``topk`` is a tuple containing multiple integers, the\n            function will return a tuple containing accuracies of\n            each ``topk`` number.\n    \"\"\"", "\n", "assert", "isinstance", "(", "topk", ",", "(", "int", ",", "tuple", ")", ")", "\n", "if", "isinstance", "(", "topk", ",", "int", ")", ":", "\n", "# topk = (topk,) can change topk from an integer to a list", "\n", "        ", "topk", "=", "(", "topk", ",", ")", "\n", "return_single", "=", "True", "\n", "", "else", ":", "\n", "        ", "return_single", "=", "False", "\n", "\n", "", "maxk", "=", "max", "(", "topk", ")", "\n", "if", "pred", ".", "size", "(", "0", ")", "==", "0", ":", "\n", "        ", "accu", "=", "[", "pred", ".", "new_tensor", "(", "0.", ")", "for", "i", "in", "range", "(", "len", "(", "topk", ")", ")", "]", "\n", "return", "accu", "[", "0", "]", "if", "return_single", "else", "accu", "\n", "# since we ignore target channel(the channel of target is 1)", "\n", "", "assert", "pred", ".", "ndim", "==", "target", ".", "ndim", "+", "1", "\n", "assert", "pred", ".", "size", "(", "0", ")", "==", "target", ".", "size", "(", "0", ")", "\n", "assert", "maxk", "<=", "pred", ".", "size", "(", "1", ")", ",", "f'maxk {maxk} exceeds pred dimension {pred.size(1)}'", "\n", "pred_value", ",", "pred_label", "=", "pred", ".", "topk", "(", "maxk", ",", "dim", "=", "1", ")", "\n", "# transpose to shape (maxk, N, ...)", "\n", "pred_label", "=", "pred_label", ".", "transpose", "(", "0", ",", "1", ")", "\n", "correct", "=", "pred_label", ".", "eq", "(", "target", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "pred_label", ")", ")", "\n", "if", "thresh", "is", "not", "None", ":", "\n", "# Only prediction values larger than thresh are counted as correct", "\n", "# since pred_label has been transposed, so we should also transpose pred_value", "\n", "        ", "correct", "=", "correct", "&", "(", "pred_value", ">", "thresh", ")", ".", "t", "(", ")", "\n", "", "res", "=", "[", "]", "\n", "# since topk may be a list of int, so we use a loop for the value in topk", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "target", ".", "numel", "(", ")", ")", ")", "\n", "", "return", "res", "[", "0", "]", "if", "return_single", "else", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.get_class_weight": [[9, 25], ["isinstance", "mmcv.load.endswith", "numpy.load", "mmcv.load"], "function", ["None"], ["def", "get_class_weight", "(", "class_weight", ")", ":", "\n", "    ", "\"\"\"Get class weight for loss function.\n\n    Args:\n        class_weight (list[float] | str | None): If class_weight is a str,\n            take it as a file name and read from it.\n    \"\"\"", "\n", "if", "isinstance", "(", "class_weight", ",", "str", ")", ":", "\n", "# take it as a file path", "\n", "        ", "if", "class_weight", ".", "endswith", "(", "'.npy'", ")", ":", "\n", "            ", "class_weight", "=", "np", ".", "load", "(", "class_weight", ")", "\n", "", "else", ":", "\n", "# pkl, json or yaml", "\n", "            ", "class_weight", "=", "mmcv", ".", "load", "(", "class_weight", ")", "\n", "\n", "", "", "return", "class_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.reduce_loss": [[27, 45], ["torch._Reduction.get_enum", "loss.mean", "loss.sum"], "function", ["None"], ["", "def", "reduce_loss", "(", "loss", ",", "reduction", ")", ":", "\n", "    ", "\"\"\"Reduce loss as specified.\n\n    Args:\n        loss (Tensor): Elementwise loss tensor.\n        reduction (str): Options are \"none\", \"mean\" and \"sum\".\n\n    Return:\n        Tensor: Reduced loss tensor.\n    \"\"\"", "\n", "reduction_enum", "=", "F", ".", "_Reduction", ".", "get_enum", "(", "reduction", ")", "\n", "# none: 0, elementwise_mean:1, sum: 2", "\n", "if", "reduction_enum", "==", "0", ":", "\n", "        ", "return", "loss", "\n", "", "elif", "reduction_enum", "==", "1", ":", "\n", "        ", "return", "loss", ".", "mean", "(", ")", "\n", "", "elif", "reduction_enum", "==", "2", ":", "\n", "        ", "return", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.weight_reduce_loss": [[47, 77], ["utils.reduce_loss", "weight.dim", "reduce_loss.dim", "weight.dim", "reduce_loss.sum", "ValueError", "weight.size", "weight.size", "reduce_loss.size"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.reduce_loss"], ["", "", "def", "weight_reduce_loss", "(", "loss", ",", "weight", "=", "None", ",", "reduction", "=", "'mean'", ",", "avg_factor", "=", "None", ")", ":", "\n", "    ", "\"\"\"Apply element-wise weight and reduce loss.\n\n    Args:\n        loss (Tensor): Element-wise loss.\n        weight (Tensor): Element-wise weights.\n        reduction (str): Same as built-in losses of PyTorch.\n        avg_factor (float): Average factor when computing the mean of losses.\n\n    Returns:\n        Tensor: Processed loss values.\n    \"\"\"", "\n", "# if weight is specified, apply element-wise weight", "\n", "if", "weight", "is", "not", "None", ":", "\n", "        ", "assert", "weight", ".", "dim", "(", ")", "==", "loss", ".", "dim", "(", ")", "\n", "if", "weight", ".", "dim", "(", ")", ">", "1", ":", "\n", "            ", "assert", "weight", ".", "size", "(", "1", ")", "==", "1", "or", "weight", ".", "size", "(", "1", ")", "==", "loss", ".", "size", "(", "1", ")", "\n", "", "loss", "=", "loss", "*", "weight", "\n", "\n", "# if avg_factor is not specified, just reduce the loss", "\n", "", "if", "avg_factor", "is", "None", ":", "\n", "        ", "loss", "=", "reduce_loss", "(", "loss", ",", "reduction", ")", "\n", "", "else", ":", "\n", "# if reduction is mean, then average the loss by avg_factor", "\n", "        ", "if", "reduction", "==", "'mean'", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "/", "avg_factor", "\n", "# if reduction is 'none', then do nothing, otherwise raise an error", "\n", "", "elif", "reduction", "!=", "'none'", ":", "\n", "            ", "raise", "ValueError", "(", "'avg_factor can not be used with reduction=\"sum\"'", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.weighted_loss": [[79, 123], ["functools.wraps", "loss_func", "utils.weight_reduce_loss"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.weight_reduce_loss"], ["", "def", "weighted_loss", "(", "loss_func", ")", ":", "\n", "    ", "\"\"\"Create a weighted version of a given loss function.\n\n    To use this decorator, the loss function must have the signature like\n    `loss_func(pred, target, **kwargs)`. The function only needs to compute\n    element-wise loss without any reduction. This decorator will add weight\n    and reduction arguments to the function. The decorated function will have\n    the signature like `loss_func(pred, target, weight=None, reduction='mean',\n    avg_factor=None, **kwargs)`.\n\n    :Example:\n\n    >>> import torch\n    >>> @weighted_loss\n    >>> def l1_loss(pred, target):\n    >>>     return (pred - target).abs()\n\n    >>> pred = torch.Tensor([0, 2, 3])\n    >>> target = torch.Tensor([1, 1, 1])\n    >>> weight = torch.Tensor([1, 0, 1])\n\n    >>> l1_loss(pred, target)\n    tensor(1.3333)\n    >>> l1_loss(pred, target, weight)\n    tensor(1.)\n    >>> l1_loss(pred, target, reduction='none')\n    tensor([1., 1., 2.])\n    >>> l1_loss(pred, target, weight, avg_factor=2)\n    tensor(1.5000)\n    \"\"\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "loss_func", ")", "\n", "def", "wrapper", "(", "pred", ",", "\n", "target", ",", "\n", "weight", "=", "None", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "avg_factor", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "# get element-wise loss", "\n", "        ", "loss", "=", "loss_func", "(", "pred", ",", "target", ",", "**", "kwargs", ")", "\n", "loss", "=", "weight_reduce_loss", "(", "loss", ",", "weight", ",", "reduction", ",", "avg_factor", ")", "\n", "return", "loss", "\n", "\n", "", "return", "wrapper", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.__init__": [[158, 180], ["torch.Module.__init__", "utils.get_class_weight"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.get_class_weight"], ["def", "__init__", "(", "self", ",", "\n", "use_sigmoid", "=", "False", ",", "\n", "use_mask", "=", "False", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "class_weight", "=", "None", ",", "\n", "loss_weight", "=", "1.0", ",", "\n", "loss_name", "=", "'loss_ce'", ")", ":", "\n", "        ", "super", "(", "CrossEntropyLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "use_sigmoid", "is", "False", ")", "or", "(", "use_mask", "is", "False", ")", "\n", "self", ".", "use_sigmoid", "=", "use_sigmoid", "\n", "self", ".", "use_mask", "=", "use_mask", "\n", "self", ".", "reduction", "=", "reduction", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "self", ".", "class_weight", "=", "get_class_weight", "(", "class_weight", ")", "\n", "\n", "if", "self", ".", "use_sigmoid", ":", "\n", "            ", "self", ".", "cls_criterion", "=", "binary_cross_entropy", "\n", "", "elif", "self", ".", "use_mask", ":", "\n", "            ", "self", ".", "cls_criterion", "=", "mask_cross_entropy", "\n", "", "else", ":", "\n", "            ", "self", ".", "cls_criterion", "=", "cross_entropy", "\n", "", "self", ".", "_loss_name", "=", "loss_name", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.forward": [[181, 205], ["cls_score.new_tensor", "cross_entropy_loss.CrossEntropyLoss.cls_criterion"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "cls_score", ",", "\n", "label", ",", "\n", "weight", "=", "None", ",", "\n", "avg_factor", "=", "None", ",", "\n", "reduction_override", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Forward function.\"\"\"", "\n", "assert", "reduction_override", "in", "(", "None", ",", "'none'", ",", "'mean'", ",", "'sum'", ")", "\n", "reduction", "=", "(", "\n", "reduction_override", "if", "reduction_override", "else", "self", ".", "reduction", ")", "\n", "if", "self", ".", "class_weight", "is", "not", "None", ":", "\n", "            ", "class_weight", "=", "cls_score", ".", "new_tensor", "(", "self", ".", "class_weight", ")", "\n", "", "else", ":", "\n", "            ", "class_weight", "=", "None", "\n", "", "loss_cls", "=", "self", ".", "loss_weight", "*", "self", ".", "cls_criterion", "(", "\n", "cls_score", ",", "\n", "label", ",", "\n", "weight", ",", "\n", "class_weight", "=", "class_weight", ",", "\n", "reduction", "=", "reduction", ",", "\n", "avg_factor", "=", "avg_factor", ",", "\n", "**", "kwargs", ")", "\n", "return", "loss_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.CrossEntropyLoss.loss_name": [[206, 219], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loss_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"Loss Name.\n\n        This function must be implemented and will return the name of this\n        loss function. This name will be used to combine different loss items\n        by simple sum operation. In addition, if you want this loss item to be\n        included into the backward graph, `loss_` must be the prefix of the\n        name.\n        Returns:\n            str: The name of this loss item.\n        \"\"\"", "\n", "return", "self", ".", "_loss_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.cross_entropy": [[10, 34], ["torch.cross_entropy", "utils.weight_reduce_loss", "weight.float.float"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.cross_entropy", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.weight_reduce_loss"], ["def", "cross_entropy", "(", "pred", ",", "\n", "label", ",", "\n", "weight", "=", "None", ",", "\n", "class_weight", "=", "None", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "avg_factor", "=", "None", ",", "\n", "ignore_index", "=", "-", "100", ")", ":", "\n", "    ", "\"\"\"The wrapper function for :func:`F.cross_entropy`\"\"\"", "\n", "# class_weight is a manual rescaling weight given to each class.", "\n", "# If given, has to be a Tensor of size C element-wise losses", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "\n", "pred", ",", "\n", "label", ",", "\n", "weight", "=", "class_weight", ",", "\n", "reduction", "=", "'none'", ",", "\n", "ignore_index", "=", "ignore_index", ")", "\n", "\n", "# apply weights and do the reduction", "\n", "if", "weight", "is", "not", "None", ":", "\n", "        ", "weight", "=", "weight", ".", "float", "(", ")", "\n", "", "loss", "=", "weight_reduce_loss", "(", "\n", "loss", ",", "weight", "=", "weight", ",", "reduction", "=", "reduction", ",", "avg_factor", "=", "avg_factor", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss._expand_onehot_labels": [[36, 56], ["labels.new_zeros", "torch.nonzero", "torch.nonzero", "torch.nonzero", "valid_mask.unsqueeze().expand().float.unsqueeze().expand().float", "inds[].numel", "label_weights.unsqueeze().expand", "labels.dim", "valid_mask.unsqueeze().expand().float.unsqueeze().expand", "label_weights.unsqueeze", "valid_mask.unsqueeze().expand().float.unsqueeze"], "function", ["None"], ["", "def", "_expand_onehot_labels", "(", "labels", ",", "label_weights", ",", "target_shape", ",", "ignore_index", ")", ":", "\n", "    ", "\"\"\"Expand onehot labels to match the size of prediction.\"\"\"", "\n", "bin_labels", "=", "labels", ".", "new_zeros", "(", "target_shape", ")", "\n", "valid_mask", "=", "(", "labels", ">=", "0", ")", "&", "(", "labels", "!=", "ignore_index", ")", "\n", "inds", "=", "torch", ".", "nonzero", "(", "valid_mask", ",", "as_tuple", "=", "True", ")", "\n", "\n", "if", "inds", "[", "0", "]", ".", "numel", "(", ")", ">", "0", ":", "\n", "        ", "if", "labels", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "bin_labels", "[", "inds", "[", "0", "]", ",", "labels", "[", "valid_mask", "]", ",", "inds", "[", "1", "]", ",", "inds", "[", "2", "]", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "bin_labels", "[", "inds", "[", "0", "]", ",", "labels", "[", "valid_mask", "]", "]", "=", "1", "\n", "\n", "", "", "valid_mask", "=", "valid_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "target_shape", ")", ".", "float", "(", ")", "\n", "if", "label_weights", "is", "None", ":", "\n", "        ", "bin_label_weights", "=", "valid_mask", "\n", "", "else", ":", "\n", "        ", "bin_label_weights", "=", "label_weights", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "target_shape", ")", "\n", "bin_label_weights", "*=", "valid_mask", "\n", "\n", "", "return", "bin_labels", ",", "bin_label_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.binary_cross_entropy": [[58, 99], ["torch.binary_cross_entropy_with_logits", "utils.weight_reduce_loss", "pred.dim", "label.dim", "cross_entropy_loss._expand_onehot_labels", "weight.float.float", "label.float", "pred.dim", "label.dim", "pred.dim", "label.dim"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.utils.weight_reduce_loss", "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss._expand_onehot_labels"], ["", "def", "binary_cross_entropy", "(", "pred", ",", "\n", "label", ",", "\n", "weight", "=", "None", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "avg_factor", "=", "None", ",", "\n", "class_weight", "=", "None", ",", "\n", "ignore_index", "=", "255", ")", ":", "\n", "    ", "\"\"\"Calculate the binary CrossEntropy loss.\n\n    Args:\n        pred (torch.Tensor): The prediction with shape (N, 1).\n        label (torch.Tensor): The learning label of the prediction.\n        weight (torch.Tensor, optional): Sample-wise loss weight.\n        reduction (str, optional): The method used to reduce the loss.\n            Options are \"none\", \"mean\" and \"sum\".\n        avg_factor (int, optional): Average factor that is used to average\n            the loss. Defaults to None.\n        class_weight (list[float], optional): The weight for each class.\n        ignore_index (int | None): The label index to be ignored. Default: 255\n\n    Returns:\n        torch.Tensor: The calculated loss\n    \"\"\"", "\n", "if", "pred", ".", "dim", "(", ")", "!=", "label", ".", "dim", "(", ")", ":", "\n", "        ", "assert", "(", "pred", ".", "dim", "(", ")", "==", "2", "and", "label", ".", "dim", "(", ")", "==", "1", ")", "or", "(", "\n", "pred", ".", "dim", "(", ")", "==", "4", "and", "label", ".", "dim", "(", ")", "==", "3", ")", ",", "'Only pred shape [N, C], label shape [N] or pred shape [N, C, '", "'H, W], label shape [N, H, W] are supported'", "\n", "label", ",", "weight", "=", "_expand_onehot_labels", "(", "label", ",", "weight", ",", "pred", ".", "shape", ",", "\n", "ignore_index", ")", "\n", "\n", "# weighted element-wise losses", "\n", "", "if", "weight", "is", "not", "None", ":", "\n", "        ", "weight", "=", "weight", ".", "float", "(", ")", "\n", "", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "pred", ",", "label", ".", "float", "(", ")", ",", "pos_weight", "=", "class_weight", ",", "reduction", "=", "'none'", ")", "\n", "# do the reduction for the weighted loss", "\n", "loss", "=", "weight_reduce_loss", "(", "\n", "loss", ",", "weight", ",", "reduction", "=", "reduction", ",", "avg_factor", "=", "avg_factor", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.losses.cross_entropy_loss.mask_cross_entropy": [[101, 137], ["torch.arange", "torch.arange", "torch.arange", "pred[].squeeze", "pred.size", "torch.binary_cross_entropy_with_logits"], "function", ["None"], ["", "def", "mask_cross_entropy", "(", "pred", ",", "\n", "target", ",", "\n", "label", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "avg_factor", "=", "None", ",", "\n", "class_weight", "=", "None", ",", "\n", "ignore_index", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the CrossEntropy loss for masks.\n\n    Args:\n        pred (torch.Tensor): The prediction with shape (N, C), C is the number\n            of classes.\n        target (torch.Tensor): The learning label of the prediction.\n        label (torch.Tensor): ``label`` indicates the class label of the mask'\n            corresponding object. This will be used to select the mask in the\n            of the class which the object belongs to when the mask prediction\n            if not class-agnostic.\n        reduction (str, optional): The method used to reduce the loss.\n            Options are \"none\", \"mean\" and \"sum\".\n        avg_factor (int, optional): Average factor that is used to average\n            the loss. Defaults to None.\n        class_weight (list[float], optional): The weight for each class.\n        ignore_index (None): Placeholder, to be consistent with other loss.\n            Default: None.\n\n    Returns:\n        torch.Tensor: The calculated loss\n    \"\"\"", "\n", "assert", "ignore_index", "is", "None", ",", "'BCE loss does not support ignore_index'", "\n", "# TODO: handle these two reserved arguments", "\n", "assert", "reduction", "==", "'mean'", "and", "avg_factor", "is", "None", "\n", "num_rois", "=", "pred", ".", "size", "(", ")", "[", "0", "]", "\n", "inds", "=", "torch", ".", "arange", "(", "0", ",", "num_rois", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "pred", ".", "device", ")", "\n", "pred_slice", "=", "pred", "[", "inds", ",", "label", "]", ".", "squeeze", "(", "1", ")", "\n", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "\n", "pred_slice", ",", "target", ",", "weight", "=", "class_weight", ",", "reduction", "=", "'mean'", ")", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.seg.builder.build_pixel_sampler": [[7, 10], ["mmcv.utils.build_from_cfg"], "function", ["None"], ["import", "numpy", "as", "np", "\n", "import", "torch", "\n", "from", "mmcv", ".", "parallel", "import", "collate", "\n", "from", "mmcv", ".", "runner", "import", "get_dist_info", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.sampler.ohem_pixel_sampler.OHEMPixelSampler.__init__": [[24, 30], ["base_pixel_sampler.BasePixelSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "context", ",", "thresh", "=", "None", ",", "min_kept", "=", "100000", ")", ":", "\n", "        ", "super", "(", "OHEMPixelSampler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context", "=", "context", "\n", "assert", "min_kept", ">", "1", "\n", "self", ".", "thresh", "=", "thresh", "\n", "self", ".", "min_kept", "=", "min_kept", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.sampler.ohem_pixel_sampler.OHEMPixelSampler.sample": [[31, 80], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "seg_label.squeeze().long.squeeze().long.squeeze().long", "seg_logit.new_zeros", "seg_label.squeeze().long.squeeze().long.size", "torch.softmax", "torch.softmax", "seg_label.squeeze().long.squeeze().long.clone().unsqueeze", "seg_prob.gather().squeeze.gather().squeeze.gather().squeeze", "seg_prob[].sort", "max", "losses[].sort", "seg_label.squeeze().long.squeeze().long.squeeze", "seg_label.squeeze().long.squeeze().long.size", "sort_prob.numel", "loss_module", "seg_label.squeeze().long.squeeze().long.clone", "seg_prob.gather().squeeze.gather().squeeze.gather", "min", "sort_prob.numel"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "seg_logit", ",", "seg_label", ")", ":", "\n", "        ", "\"\"\"Sample pixels that have high loss or with low prediction confidence.\n\n        Args:\n            seg_logit (torch.Tensor): segmentation logits, shape (N, C, H, W)\n            seg_label (torch.Tensor): segmentation label, shape (N, 1, H, W)\n\n        Returns:\n            torch.Tensor: segmentation weight, shape (N, H, W)\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "assert", "seg_logit", ".", "shape", "[", "2", ":", "]", "==", "seg_label", ".", "shape", "[", "2", ":", "]", "\n", "assert", "seg_label", ".", "shape", "[", "1", "]", "==", "1", "\n", "seg_label", "=", "seg_label", ".", "squeeze", "(", "1", ")", ".", "long", "(", ")", "\n", "batch_kept", "=", "self", ".", "min_kept", "*", "seg_label", ".", "size", "(", "0", ")", "\n", "valid_mask", "=", "seg_label", "!=", "self", ".", "context", ".", "ignore_index", "\n", "seg_weight", "=", "seg_logit", ".", "new_zeros", "(", "size", "=", "seg_label", ".", "size", "(", ")", ")", "\n", "valid_seg_weight", "=", "seg_weight", "[", "valid_mask", "]", "\n", "if", "self", ".", "thresh", "is", "not", "None", ":", "\n", "                ", "seg_prob", "=", "F", ".", "softmax", "(", "seg_logit", ",", "dim", "=", "1", ")", "\n", "\n", "tmp_seg_label", "=", "seg_label", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "tmp_seg_label", "[", "tmp_seg_label", "==", "self", ".", "context", ".", "ignore_index", "]", "=", "0", "\n", "seg_prob", "=", "seg_prob", ".", "gather", "(", "1", ",", "tmp_seg_label", ")", ".", "squeeze", "(", "1", ")", "\n", "sort_prob", ",", "sort_indices", "=", "seg_prob", "[", "valid_mask", "]", ".", "sort", "(", ")", "\n", "\n", "if", "sort_prob", ".", "numel", "(", ")", ">", "0", ":", "\n", "                    ", "min_threshold", "=", "sort_prob", "[", "min", "(", "batch_kept", ",", "\n", "sort_prob", ".", "numel", "(", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "min_threshold", "=", "0.0", "\n", "", "threshold", "=", "max", "(", "min_threshold", ",", "self", ".", "thresh", ")", "\n", "valid_seg_weight", "[", "seg_prob", "[", "valid_mask", "]", "<", "threshold", "]", "=", "1.", "\n", "", "else", ":", "\n", "                ", "losses", "=", "0.0", "\n", "for", "loss_module", "in", "self", ".", "context", ".", "loss_decode", ":", "\n", "                    ", "losses", "+=", "loss_module", "(", "\n", "seg_logit", ",", "\n", "seg_label", ",", "\n", "weight", "=", "None", ",", "\n", "ignore_index", "=", "self", ".", "context", ".", "ignore_index", ",", "\n", "reduction_override", "=", "'none'", ")", "\n", "# faster than topk according to https://github.com/pytorch/pytorch/issues/22812  # noqa", "\n", "", "_", ",", "sort_indices", "=", "losses", "[", "valid_mask", "]", ".", "sort", "(", "descending", "=", "True", ")", "\n", "valid_seg_weight", "[", "sort_indices", "[", ":", "batch_kept", "]", "]", "=", "1.", "\n", "\n", "", "seg_weight", "[", "valid_mask", "]", "=", "valid_seg_weight", "\n", "\n", "return", "seg_weight", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.sampler.base_pixel_sampler.BasePixelSampler.__init__": [[8, 10], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.sampler.base_pixel_sampler.BasePixelSampler.sample": [[11, 14], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "sample", "(", "self", ",", "seg_logit", ",", "seg_label", ")", ":", "\n", "        ", "\"\"\"Placeholder for sample function.\"\"\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.f_score": [[9, 24], ["None"], "function", ["None"], ["def", "f_score", "(", "precision", ",", "recall", ",", "beta", "=", "1", ")", ":", "\n", "    ", "\"\"\"calculate the f-score value.\n\n    Args:\n        precision (float | torch.Tensor): The precision value.\n        recall (float | torch.Tensor): The recall value.\n        beta (int): Determines the weight of recall in the combined score.\n            Default: False.\n\n    Returns:\n        [torch.tensor]: The f-score value.\n    \"\"\"", "\n", "score", "=", "(", "1", "+", "beta", "**", "2", ")", "*", "(", "precision", "*", "recall", ")", "/", "(", "\n", "(", "beta", "**", "2", "*", "precision", ")", "+", "recall", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.intersect_and_union": [[26, 87], ["dict", "isinstance", "isinstance", "torch.histc", "torch.histc", "torch.histc", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "label_map.items", "intersect.float", "torch.from_numpy.float", "torch.from_numpy.float", "numpy.load", "mmcv.imread"], "function", ["None"], ["", "def", "intersect_and_union", "(", "pred_label", ",", "\n", "label", ",", "\n", "num_classes", ",", "\n", "ignore_index", ",", "\n", "label_map", "=", "dict", "(", ")", ",", "\n", "reduce_zero_label", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate intersection and Union.\n\n    Args:\n        pred_label (ndarray | str): Prediction segmentation map\n            or predict result filename.\n        label (ndarray | str): Ground truth segmentation map\n            or label filename.\n        num_classes (int): Number of categories.\n        ignore_index (int): Index that will be ignored in evaluation.\n        label_map (dict): Mapping old labels to new labels. The parameter will\n            work only when label is str. Default: dict().\n        reduce_zero_label (bool): Whether ignore zero label. The parameter will\n            work only when label is str. Default: False.\n\n     Returns:\n         torch.Tensor: The intersection of prediction and ground truth\n            histogram on all classes.\n         torch.Tensor: The union of prediction and ground truth histogram on\n            all classes.\n         torch.Tensor: The prediction histogram on all classes.\n         torch.Tensor: The ground truth histogram on all classes.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "pred_label", ",", "str", ")", ":", "\n", "        ", "pred_label", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "pred_label", ")", ")", "\n", "", "else", ":", "\n", "        ", "pred_label", "=", "torch", ".", "from_numpy", "(", "(", "pred_label", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "label", ",", "str", ")", ":", "\n", "        ", "label", "=", "torch", ".", "from_numpy", "(", "\n", "mmcv", ".", "imread", "(", "label", ",", "flag", "=", "'unchanged'", ",", "backend", "=", "'pillow'", ")", ")", "\n", "", "else", ":", "\n", "        ", "label", "=", "torch", ".", "from_numpy", "(", "label", ")", "\n", "\n", "", "if", "label_map", "is", "not", "None", ":", "\n", "        ", "for", "old_id", ",", "new_id", "in", "label_map", ".", "items", "(", ")", ":", "\n", "            ", "label", "[", "label", "==", "old_id", "]", "=", "new_id", "\n", "", "", "if", "reduce_zero_label", ":", "\n", "        ", "label", "[", "label", "==", "0", "]", "=", "255", "\n", "label", "=", "label", "-", "1", "\n", "label", "[", "label", "==", "254", "]", "=", "255", "\n", "\n", "", "mask", "=", "(", "label", "!=", "ignore_index", ")", "\n", "pred_label", "=", "pred_label", "[", "mask", "]", "\n", "label", "=", "label", "[", "mask", "]", "\n", "\n", "intersect", "=", "pred_label", "[", "pred_label", "==", "label", "]", "\n", "area_intersect", "=", "torch", ".", "histc", "(", "\n", "intersect", ".", "float", "(", ")", ",", "bins", "=", "(", "num_classes", ")", ",", "min", "=", "0", ",", "max", "=", "num_classes", "-", "1", ")", "\n", "area_pred_label", "=", "torch", ".", "histc", "(", "\n", "pred_label", ".", "float", "(", ")", ",", "bins", "=", "(", "num_classes", ")", ",", "min", "=", "0", ",", "max", "=", "num_classes", "-", "1", ")", "\n", "area_label", "=", "torch", ".", "histc", "(", "\n", "label", ".", "float", "(", ")", ",", "bins", "=", "(", "num_classes", ")", ",", "min", "=", "0", ",", "max", "=", "num_classes", "-", "1", ")", "\n", "area_union", "=", "area_pred_label", "+", "area_label", "-", "area_intersect", "\n", "return", "area_intersect", ",", "area_union", ",", "area_pred_label", ",", "area_label", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.total_intersect_and_union": [[89, 130], ["dict", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "zip", "metrics.intersect_and_union"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.intersect_and_union"], ["", "def", "total_intersect_and_union", "(", "results", ",", "\n", "gt_seg_maps", ",", "\n", "num_classes", ",", "\n", "ignore_index", ",", "\n", "label_map", "=", "dict", "(", ")", ",", "\n", "reduce_zero_label", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate Total Intersection and Union.\n\n    Args:\n        results (list[ndarray] | list[str]): List of prediction segmentation\n            maps or list of prediction result filenames.\n        gt_seg_maps (list[ndarray] | list[str] | Iterables): list of ground\n            truth segmentation maps or list of label filenames.\n        num_classes (int): Number of categories.\n        ignore_index (int): Index that will be ignored in evaluation.\n        label_map (dict): Mapping old labels to new labels. Default: dict().\n        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n\n     Returns:\n         ndarray: The intersection of prediction and ground truth histogram\n             on all classes.\n         ndarray: The union of prediction and ground truth histogram on all\n             classes.\n         ndarray: The prediction histogram on all classes.\n         ndarray: The ground truth histogram on all classes.\n    \"\"\"", "\n", "total_area_intersect", "=", "torch", ".", "zeros", "(", "(", "num_classes", ",", ")", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "total_area_union", "=", "torch", ".", "zeros", "(", "(", "num_classes", ",", ")", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "total_area_pred_label", "=", "torch", ".", "zeros", "(", "(", "num_classes", ",", ")", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "total_area_label", "=", "torch", ".", "zeros", "(", "(", "num_classes", ",", ")", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "for", "result", ",", "gt_seg_map", "in", "zip", "(", "results", ",", "gt_seg_maps", ")", ":", "\n", "        ", "area_intersect", ",", "area_union", ",", "area_pred_label", ",", "area_label", "=", "intersect_and_union", "(", "\n", "result", ",", "gt_seg_map", ",", "num_classes", ",", "ignore_index", ",", "\n", "label_map", ",", "reduce_zero_label", ")", "\n", "total_area_intersect", "+=", "area_intersect", "\n", "total_area_union", "+=", "area_union", "\n", "total_area_pred_label", "+=", "area_pred_label", "\n", "total_area_label", "+=", "area_label", "\n", "", "return", "total_area_intersect", ",", "total_area_union", ",", "total_area_pred_label", ",", "total_area_label", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.mean_iou": [[132, 169], ["dict", "metrics.eval_metrics"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.eval_metrics"], ["", "def", "mean_iou", "(", "results", ",", "\n", "gt_seg_maps", ",", "\n", "num_classes", ",", "\n", "ignore_index", ",", "\n", "nan_to_num", "=", "None", ",", "\n", "label_map", "=", "dict", "(", ")", ",", "\n", "reduce_zero_label", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate Mean Intersection and Union (mIoU)\n\n    Args:\n        results (list[ndarray] | list[str]): List of prediction segmentation\n            maps or list of prediction result filenames.\n        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n            segmentation maps or list of label filenames.\n        num_classes (int): Number of categories.\n        ignore_index (int): Index that will be ignored in evaluation.\n        nan_to_num (int, optional): If specified, NaN values will be replaced\n            by the numbers defined by the user. Default: None.\n        label_map (dict): Mapping old labels to new labels. Default: dict().\n        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n\n     Returns:\n        dict[str, float | ndarray]:\n            <aAcc> float: Overall accuracy on all images.\n            <Acc> ndarray: Per category accuracy, shape (num_classes, ).\n            <IoU> ndarray: Per category IoU, shape (num_classes, ).\n    \"\"\"", "\n", "iou_result", "=", "eval_metrics", "(", "\n", "results", "=", "results", ",", "\n", "gt_seg_maps", "=", "gt_seg_maps", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "ignore_index", "=", "ignore_index", ",", "\n", "metrics", "=", "[", "'mIoU'", "]", ",", "\n", "nan_to_num", "=", "nan_to_num", ",", "\n", "label_map", "=", "label_map", ",", "\n", "reduce_zero_label", "=", "reduce_zero_label", ")", "\n", "return", "iou_result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.mean_dice": [[171, 209], ["dict", "metrics.eval_metrics"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.eval_metrics"], ["", "def", "mean_dice", "(", "results", ",", "\n", "gt_seg_maps", ",", "\n", "num_classes", ",", "\n", "ignore_index", ",", "\n", "nan_to_num", "=", "None", ",", "\n", "label_map", "=", "dict", "(", ")", ",", "\n", "reduce_zero_label", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate Mean Dice (mDice)\n\n    Args:\n        results (list[ndarray] | list[str]): List of prediction segmentation\n            maps or list of prediction result filenames.\n        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n            segmentation maps or list of label filenames.\n        num_classes (int): Number of categories.\n        ignore_index (int): Index that will be ignored in evaluation.\n        nan_to_num (int, optional): If specified, NaN values will be replaced\n            by the numbers defined by the user. Default: None.\n        label_map (dict): Mapping old labels to new labels. Default: dict().\n        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n\n     Returns:\n        dict[str, float | ndarray]: Default metrics.\n            <aAcc> float: Overall accuracy on all images.\n            <Acc> ndarray: Per category accuracy, shape (num_classes, ).\n            <Dice> ndarray: Per category dice, shape (num_classes, ).\n    \"\"\"", "\n", "\n", "dice_result", "=", "eval_metrics", "(", "\n", "results", "=", "results", ",", "\n", "gt_seg_maps", "=", "gt_seg_maps", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "ignore_index", "=", "ignore_index", ",", "\n", "metrics", "=", "[", "'mDice'", "]", ",", "\n", "nan_to_num", "=", "nan_to_num", ",", "\n", "label_map", "=", "label_map", ",", "\n", "reduce_zero_label", "=", "reduce_zero_label", ")", "\n", "return", "dice_result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.mean_fscore": [[211, 254], ["dict", "metrics.eval_metrics"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.eval_metrics"], ["", "def", "mean_fscore", "(", "results", ",", "\n", "gt_seg_maps", ",", "\n", "num_classes", ",", "\n", "ignore_index", ",", "\n", "nan_to_num", "=", "None", ",", "\n", "label_map", "=", "dict", "(", ")", ",", "\n", "reduce_zero_label", "=", "False", ",", "\n", "beta", "=", "1", ")", ":", "\n", "    ", "\"\"\"Calculate Mean Intersection and Union (mIoU)\n\n    Args:\n        results (list[ndarray] | list[str]): List of prediction segmentation\n            maps or list of prediction result filenames.\n        gt_seg_maps (list[ndarray] | list[str]): list of ground truth\n            segmentation maps or list of label filenames.\n        num_classes (int): Number of categories.\n        ignore_index (int): Index that will be ignored in evaluation.\n        nan_to_num (int, optional): If specified, NaN values will be replaced\n            by the numbers defined by the user. Default: None.\n        label_map (dict): Mapping old labels to new labels. Default: dict().\n        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n        beta (int): Determines the weight of recall in the combined score.\n            Default: False.\n\n\n     Returns:\n        dict[str, float | ndarray]: Default metrics.\n            <aAcc> float: Overall accuracy on all images.\n            <Fscore> ndarray: Per category recall, shape (num_classes, ).\n            <Precision> ndarray: Per category precision, shape (num_classes, ).\n            <Recall> ndarray: Per category f-score, shape (num_classes, ).\n    \"\"\"", "\n", "fscore_result", "=", "eval_metrics", "(", "\n", "results", "=", "results", ",", "\n", "gt_seg_maps", "=", "gt_seg_maps", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "ignore_index", "=", "ignore_index", ",", "\n", "metrics", "=", "[", "'mFscore'", "]", ",", "\n", "nan_to_num", "=", "nan_to_num", ",", "\n", "label_map", "=", "label_map", ",", "\n", "reduce_zero_label", "=", "reduce_zero_label", ",", "\n", "beta", "=", "beta", ")", "\n", "return", "fscore_result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.eval_metrics": [[256, 294], ["dict", "metrics.total_intersect_and_union", "metrics.total_area_to_metrics"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.total_intersect_and_union", "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.total_area_to_metrics"], ["", "def", "eval_metrics", "(", "results", ",", "\n", "gt_seg_maps", ",", "\n", "num_classes", ",", "\n", "ignore_index", ",", "\n", "metrics", "=", "[", "'mIoU'", "]", ",", "\n", "nan_to_num", "=", "None", ",", "\n", "label_map", "=", "dict", "(", ")", ",", "\n", "reduce_zero_label", "=", "False", ",", "\n", "beta", "=", "1", ")", ":", "\n", "    ", "\"\"\"Calculate evaluation metrics\n    Args:\n        results (list[ndarray] | list[str]): List of prediction segmentation\n            maps or list of prediction result filenames.\n        gt_seg_maps (list[ndarray] | list[str] | Iterables): list of ground\n            truth segmentation maps or list of label filenames.\n        num_classes (int): Number of categories.\n        ignore_index (int): Index that will be ignored in evaluation.\n        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n        nan_to_num (int, optional): If specified, NaN values will be replaced\n            by the numbers defined by the user. Default: None.\n        label_map (dict): Mapping old labels to new labels. Default: dict().\n        reduce_zero_label (bool): Whether ignore zero label. Default: False.\n     Returns:\n        float: Overall accuracy on all images.\n        ndarray: Per category accuracy, shape (num_classes, ).\n        ndarray: Per category evaluation metrics, shape (num_classes, ).\n    \"\"\"", "\n", "\n", "total_area_intersect", ",", "total_area_union", ",", "total_area_pred_label", ",", "total_area_label", "=", "total_intersect_and_union", "(", "\n", "results", ",", "gt_seg_maps", ",", "num_classes", ",", "ignore_index", ",", "label_map", ",", "\n", "reduce_zero_label", ")", "\n", "ret_metrics", "=", "total_area_to_metrics", "(", "total_area_intersect", ",", "total_area_union", ",", "\n", "total_area_pred_label", ",", "\n", "total_area_label", ",", "metrics", ",", "nan_to_num", ",", "\n", "beta", ")", "\n", "\n", "return", "ret_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.pre_eval_to_metrics": [[296, 331], ["tuple", "sum", "sum", "sum", "sum", "metrics.total_area_to_metrics", "zip", "len"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.total_area_to_metrics"], ["", "def", "pre_eval_to_metrics", "(", "pre_eval_results", ",", "\n", "metrics", "=", "[", "'mIoU'", "]", ",", "\n", "nan_to_num", "=", "None", ",", "\n", "beta", "=", "1", ")", ":", "\n", "    ", "\"\"\"Convert pre-eval results to metrics.\n\n    Args:\n        pre_eval_results (list[tuple[torch.Tensor]]): per image eval results\n            for computing evaluation metric\n        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n        nan_to_num (int, optional): If specified, NaN values will be replaced\n            by the numbers defined by the user. Default: None.\n     Returns:\n        float: Overall accuracy on all images.\n        ndarray: Per category accuracy, shape (num_classes, ).\n        ndarray: Per category evaluation metrics, shape (num_classes, ).\n    \"\"\"", "\n", "\n", "# convert list of tuples to tuple of lists, e.g.", "\n", "# [(A_1, B_1, C_1, D_1), ...,  (A_n, B_n, C_n, D_n)] to", "\n", "# ([A_1, ..., A_n], ..., [D_1, ..., D_n])", "\n", "pre_eval_results", "=", "tuple", "(", "zip", "(", "*", "pre_eval_results", ")", ")", "\n", "assert", "len", "(", "pre_eval_results", ")", "==", "4", "\n", "\n", "total_area_intersect", "=", "sum", "(", "pre_eval_results", "[", "0", "]", ")", "\n", "total_area_union", "=", "sum", "(", "pre_eval_results", "[", "1", "]", ")", "\n", "total_area_pred_label", "=", "sum", "(", "pre_eval_results", "[", "2", "]", ")", "\n", "total_area_label", "=", "sum", "(", "pre_eval_results", "[", "3", "]", ")", "\n", "\n", "ret_metrics", "=", "total_area_to_metrics", "(", "total_area_intersect", ",", "total_area_union", ",", "\n", "total_area_pred_label", ",", "\n", "total_area_label", ",", "metrics", ",", "nan_to_num", ",", "\n", "beta", ")", "\n", "\n", "return", "ret_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.total_area_to_metrics": [[333, 396], ["isinstance", "collections.OrderedDict", "set().issubset", "KeyError", "total_area_intersect.sum", "total_area_label.sum", "value.numpy", "collections.OrderedDict", "set", "collections.OrderedDict.items", "set", "numpy.nan_to_num", "torch.tensor", "collections.OrderedDict.items", "metrics.f_score", "zip"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.metrics.f_score"], ["", "def", "total_area_to_metrics", "(", "total_area_intersect", ",", "\n", "total_area_union", ",", "\n", "total_area_pred_label", ",", "\n", "total_area_label", ",", "\n", "metrics", "=", "[", "'mIoU'", "]", ",", "\n", "nan_to_num", "=", "None", ",", "\n", "beta", "=", "1", ")", ":", "\n", "    ", "\"\"\"Calculate evaluation metrics\n    Args:\n        total_area_intersect (ndarray): The intersection of prediction and\n            ground truth histogram on all classes.\n        total_area_union (ndarray): The union of prediction and ground truth\n            histogram on all classes.\n        total_area_pred_label (ndarray): The prediction histogram on all\n            classes.\n        total_area_label (ndarray): The ground truth histogram on all classes.\n        metrics (list[str] | str): Metrics to be evaluated, 'mIoU' and 'mDice'.\n        nan_to_num (int, optional): If specified, NaN values will be replaced\n            by the numbers defined by the user. Default: None.\n     Returns:\n        float: Overall accuracy on all images.\n        ndarray: Per category accuracy, shape (num_classes, ).\n        ndarray: Per category evaluation metrics, shape (num_classes, ).\n    \"\"\"", "\n", "if", "isinstance", "(", "metrics", ",", "str", ")", ":", "\n", "        ", "metrics", "=", "[", "metrics", "]", "\n", "", "allowed_metrics", "=", "[", "'mIoU'", ",", "'mDice'", ",", "'mFscore'", "]", "\n", "if", "not", "set", "(", "metrics", ")", ".", "issubset", "(", "set", "(", "allowed_metrics", ")", ")", ":", "\n", "        ", "raise", "KeyError", "(", "'metrics {} is not supported'", ".", "format", "(", "metrics", ")", ")", "\n", "\n", "", "all_acc", "=", "total_area_intersect", ".", "sum", "(", ")", "/", "total_area_label", ".", "sum", "(", ")", "\n", "ret_metrics", "=", "OrderedDict", "(", "{", "'aAcc'", ":", "all_acc", "}", ")", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "if", "metric", "==", "'mIoU'", ":", "\n", "            ", "iou", "=", "total_area_intersect", "/", "total_area_union", "\n", "acc", "=", "total_area_intersect", "/", "total_area_label", "\n", "ret_metrics", "[", "'IoU'", "]", "=", "iou", "\n", "ret_metrics", "[", "'Acc'", "]", "=", "acc", "\n", "", "elif", "metric", "==", "'mDice'", ":", "\n", "            ", "dice", "=", "2", "*", "total_area_intersect", "/", "(", "\n", "total_area_pred_label", "+", "total_area_label", ")", "\n", "acc", "=", "total_area_intersect", "/", "total_area_label", "\n", "ret_metrics", "[", "'Dice'", "]", "=", "dice", "\n", "ret_metrics", "[", "'Acc'", "]", "=", "acc", "\n", "", "elif", "metric", "==", "'mFscore'", ":", "\n", "            ", "precision", "=", "total_area_intersect", "/", "total_area_pred_label", "\n", "recall", "=", "total_area_intersect", "/", "total_area_label", "\n", "f_value", "=", "torch", ".", "tensor", "(", "\n", "[", "f_score", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "beta", ")", "for", "x", "in", "zip", "(", "precision", ",", "recall", ")", "]", ")", "\n", "ret_metrics", "[", "'Fscore'", "]", "=", "f_value", "\n", "ret_metrics", "[", "'Precision'", "]", "=", "precision", "\n", "ret_metrics", "[", "'Recall'", "]", "=", "recall", "\n", "\n", "", "", "ret_metrics", "=", "{", "\n", "metric", ":", "value", ".", "numpy", "(", ")", "\n", "for", "metric", ",", "value", "in", "ret_metrics", ".", "items", "(", ")", "\n", "}", "\n", "if", "nan_to_num", "is", "not", "None", ":", "\n", "        ", "ret_metrics", "=", "OrderedDict", "(", "{", "\n", "metric", ":", "np", ".", "nan_to_num", "(", "metric_value", ",", "nan", "=", "nan_to_num", ")", "\n", "for", "metric", ",", "metric_value", "in", "ret_metrics", ".", "items", "(", ")", "\n", "}", ")", "\n", "", "return", "ret_metrics", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.cityscapes_classes": [[5, 12], ["None"], "function", ["None"], ["def", "cityscapes_classes", "(", ")", ":", "\n", "    ", "\"\"\"Cityscapes class names for external use.\"\"\"", "\n", "return", "[", "\n", "'road'", ",", "'sidewalk'", ",", "'building'", ",", "'wall'", ",", "'fence'", ",", "'pole'", ",", "\n", "'traffic light'", ",", "'traffic sign'", ",", "'vegetation'", ",", "'terrain'", ",", "'sky'", ",", "\n", "'person'", ",", "'rider'", ",", "'car'", ",", "'truck'", ",", "'bus'", ",", "'train'", ",", "'motorcycle'", ",", "\n", "'bicycle'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.ade_classes": [[15, 42], ["None"], "function", ["None"], ["", "def", "ade_classes", "(", ")", ":", "\n", "    ", "\"\"\"ADE20K class names for external use.\"\"\"", "\n", "return", "[", "\n", "'wall'", ",", "'building'", ",", "'sky'", ",", "'floor'", ",", "'tree'", ",", "'ceiling'", ",", "'road'", ",", "'bed '", ",", "\n", "'windowpane'", ",", "'grass'", ",", "'cabinet'", ",", "'sidewalk'", ",", "'person'", ",", "'earth'", ",", "\n", "'door'", ",", "'table'", ",", "'mountain'", ",", "'plant'", ",", "'curtain'", ",", "'chair'", ",", "'car'", ",", "\n", "'water'", ",", "'painting'", ",", "'sofa'", ",", "'shelf'", ",", "'house'", ",", "'sea'", ",", "'mirror'", ",", "'rug'", ",", "\n", "'field'", ",", "'armchair'", ",", "'seat'", ",", "'fence'", ",", "'desk'", ",", "'rock'", ",", "'wardrobe'", ",", "\n", "'lamp'", ",", "'bathtub'", ",", "'railing'", ",", "'cushion'", ",", "'base'", ",", "'box'", ",", "'column'", ",", "\n", "'signboard'", ",", "'chest of drawers'", ",", "'counter'", ",", "'sand'", ",", "'sink'", ",", "\n", "'skyscraper'", ",", "'fireplace'", ",", "'refrigerator'", ",", "'grandstand'", ",", "'path'", ",", "\n", "'stairs'", ",", "'runway'", ",", "'case'", ",", "'pool table'", ",", "'pillow'", ",", "'screen door'", ",", "\n", "'stairway'", ",", "'river'", ",", "'bridge'", ",", "'bookcase'", ",", "'blind'", ",", "'coffee table'", ",", "\n", "'toilet'", ",", "'flower'", ",", "'book'", ",", "'hill'", ",", "'bench'", ",", "'countertop'", ",", "'stove'", ",", "\n", "'palm'", ",", "'kitchen island'", ",", "'computer'", ",", "'swivel chair'", ",", "'boat'", ",", "'bar'", ",", "\n", "'arcade machine'", ",", "'hovel'", ",", "'bus'", ",", "'towel'", ",", "'light'", ",", "'truck'", ",", "'tower'", ",", "\n", "'chandelier'", ",", "'awning'", ",", "'streetlight'", ",", "'booth'", ",", "'television receiver'", ",", "\n", "'airplane'", ",", "'dirt track'", ",", "'apparel'", ",", "'pole'", ",", "'land'", ",", "'bannister'", ",", "\n", "'escalator'", ",", "'ottoman'", ",", "'bottle'", ",", "'buffet'", ",", "'poster'", ",", "'stage'", ",", "'van'", ",", "\n", "'ship'", ",", "'fountain'", ",", "'conveyer belt'", ",", "'canopy'", ",", "'washer'", ",", "'plaything'", ",", "\n", "'swimming pool'", ",", "'stool'", ",", "'barrel'", ",", "'basket'", ",", "'waterfall'", ",", "'tent'", ",", "\n", "'bag'", ",", "'minibike'", ",", "'cradle'", ",", "'oven'", ",", "'ball'", ",", "'food'", ",", "'step'", ",", "'tank'", ",", "\n", "'trade name'", ",", "'microwave'", ",", "'pot'", ",", "'animal'", ",", "'bicycle'", ",", "'lake'", ",", "\n", "'dishwasher'", ",", "'screen'", ",", "'blanket'", ",", "'sculpture'", ",", "'hood'", ",", "'sconce'", ",", "\n", "'vase'", ",", "'traffic light'", ",", "'tray'", ",", "'ashcan'", ",", "'fan'", ",", "'pier'", ",", "'crt screen'", ",", "\n", "'plate'", ",", "'monitor'", ",", "'bulletin board'", ",", "'shower'", ",", "'radiator'", ",", "'glass'", ",", "\n", "'clock'", ",", "'flag'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.voc_classes": [[45, 52], ["None"], "function", ["None"], ["", "def", "voc_classes", "(", ")", ":", "\n", "    ", "\"\"\"Pascal VOC class names for external use.\"\"\"", "\n", "return", "[", "\n", "'background'", ",", "'aeroplane'", ",", "'bicycle'", ",", "'bird'", ",", "'boat'", ",", "'bottle'", ",", "'bus'", ",", "\n", "'car'", ",", "'cat'", ",", "'chair'", ",", "'cow'", ",", "'diningtable'", ",", "'dog'", ",", "'horse'", ",", "\n", "'motorbike'", ",", "'person'", ",", "'pottedplant'", ",", "'sheep'", ",", "'sofa'", ",", "'train'", ",", "\n", "'tvmonitor'", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.cityscapes_palette": [[55, 62], ["None"], "function", ["None"], ["", "def", "cityscapes_palette", "(", ")", ":", "\n", "    ", "\"\"\"Cityscapes palette for external use.\"\"\"", "\n", "return", "[", "[", "128", ",", "64", ",", "128", "]", ",", "[", "244", ",", "35", ",", "232", "]", ",", "[", "70", ",", "70", ",", "70", "]", ",", "[", "102", ",", "102", ",", "156", "]", ",", "\n", "[", "190", ",", "153", ",", "153", "]", ",", "[", "153", ",", "153", ",", "153", "]", ",", "[", "250", ",", "170", ",", "30", "]", ",", "[", "220", ",", "220", ",", "0", "]", ",", "\n", "[", "107", ",", "142", ",", "35", "]", ",", "[", "152", ",", "251", ",", "152", "]", ",", "[", "70", ",", "130", ",", "180", "]", ",", "[", "220", ",", "20", ",", "60", "]", ",", "\n", "[", "255", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "142", "]", ",", "[", "0", ",", "0", ",", "70", "]", ",", "[", "0", ",", "60", ",", "100", "]", ",", "[", "0", ",", "80", ",", "100", "]", ",", "\n", "[", "0", ",", "0", ",", "230", "]", ",", "[", "119", ",", "11", ",", "32", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.ade_palette": [[64, 104], ["None"], "function", ["None"], ["", "def", "ade_palette", "(", ")", ":", "\n", "    ", "\"\"\"ADE20K palette for external use.\"\"\"", "\n", "return", "[", "[", "120", ",", "120", ",", "120", "]", ",", "[", "180", ",", "120", ",", "120", "]", ",", "[", "6", ",", "230", ",", "230", "]", ",", "[", "80", ",", "50", ",", "50", "]", ",", "\n", "[", "4", ",", "200", ",", "3", "]", ",", "[", "120", ",", "120", ",", "80", "]", ",", "[", "140", ",", "140", ",", "140", "]", ",", "[", "204", ",", "5", ",", "255", "]", ",", "\n", "[", "230", ",", "230", ",", "230", "]", ",", "[", "4", ",", "250", ",", "7", "]", ",", "[", "224", ",", "5", ",", "255", "]", ",", "[", "235", ",", "255", ",", "7", "]", ",", "\n", "[", "150", ",", "5", ",", "61", "]", ",", "[", "120", ",", "120", ",", "70", "]", ",", "[", "8", ",", "255", ",", "51", "]", ",", "[", "255", ",", "6", ",", "82", "]", ",", "\n", "[", "143", ",", "255", ",", "140", "]", ",", "[", "204", ",", "255", ",", "4", "]", ",", "[", "255", ",", "51", ",", "7", "]", ",", "[", "204", ",", "70", ",", "3", "]", ",", "\n", "[", "0", ",", "102", ",", "200", "]", ",", "[", "61", ",", "230", ",", "250", "]", ",", "[", "255", ",", "6", ",", "51", "]", ",", "[", "11", ",", "102", ",", "255", "]", ",", "\n", "[", "255", ",", "7", ",", "71", "]", ",", "[", "255", ",", "9", ",", "224", "]", ",", "[", "9", ",", "7", ",", "230", "]", ",", "[", "220", ",", "220", ",", "220", "]", ",", "\n", "[", "255", ",", "9", ",", "92", "]", ",", "[", "112", ",", "9", ",", "255", "]", ",", "[", "8", ",", "255", ",", "214", "]", ",", "[", "7", ",", "255", ",", "224", "]", ",", "\n", "[", "255", ",", "184", ",", "6", "]", ",", "[", "10", ",", "255", ",", "71", "]", ",", "[", "255", ",", "41", ",", "10", "]", ",", "[", "7", ",", "255", ",", "255", "]", ",", "\n", "[", "224", ",", "255", ",", "8", "]", ",", "[", "102", ",", "8", ",", "255", "]", ",", "[", "255", ",", "61", ",", "6", "]", ",", "[", "255", ",", "194", ",", "7", "]", ",", "\n", "[", "255", ",", "122", ",", "8", "]", ",", "[", "0", ",", "255", ",", "20", "]", ",", "[", "255", ",", "8", ",", "41", "]", ",", "[", "255", ",", "5", ",", "153", "]", ",", "\n", "[", "6", ",", "51", ",", "255", "]", ",", "[", "235", ",", "12", ",", "255", "]", ",", "[", "160", ",", "150", ",", "20", "]", ",", "[", "0", ",", "163", ",", "255", "]", ",", "\n", "[", "140", ",", "140", ",", "140", "]", ",", "[", "250", ",", "10", ",", "15", "]", ",", "[", "20", ",", "255", ",", "0", "]", ",", "[", "31", ",", "255", ",", "0", "]", ",", "\n", "[", "255", ",", "31", ",", "0", "]", ",", "[", "255", ",", "224", ",", "0", "]", ",", "[", "153", ",", "255", ",", "0", "]", ",", "[", "0", ",", "0", ",", "255", "]", ",", "\n", "[", "255", ",", "71", ",", "0", "]", ",", "[", "0", ",", "235", ",", "255", "]", ",", "[", "0", ",", "173", ",", "255", "]", ",", "[", "31", ",", "0", ",", "255", "]", ",", "\n", "[", "11", ",", "200", ",", "200", "]", ",", "[", "255", ",", "82", ",", "0", "]", ",", "[", "0", ",", "255", ",", "245", "]", ",", "[", "0", ",", "61", ",", "255", "]", ",", "\n", "[", "0", ",", "255", ",", "112", "]", ",", "[", "0", ",", "255", ",", "133", "]", ",", "[", "255", ",", "0", ",", "0", "]", ",", "[", "255", ",", "163", ",", "0", "]", ",", "\n", "[", "255", ",", "102", ",", "0", "]", ",", "[", "194", ",", "255", ",", "0", "]", ",", "[", "0", ",", "143", ",", "255", "]", ",", "[", "51", ",", "255", ",", "0", "]", ",", "\n", "[", "0", ",", "82", ",", "255", "]", ",", "[", "0", ",", "255", ",", "41", "]", ",", "[", "0", ",", "255", ",", "173", "]", ",", "[", "10", ",", "0", ",", "255", "]", ",", "\n", "[", "173", ",", "255", ",", "0", "]", ",", "[", "0", ",", "255", ",", "153", "]", ",", "[", "255", ",", "92", ",", "0", "]", ",", "[", "255", ",", "0", ",", "255", "]", ",", "\n", "[", "255", ",", "0", ",", "245", "]", ",", "[", "255", ",", "0", ",", "102", "]", ",", "[", "255", ",", "173", ",", "0", "]", ",", "[", "255", ",", "0", ",", "20", "]", ",", "\n", "[", "255", ",", "184", ",", "184", "]", ",", "[", "0", ",", "31", ",", "255", "]", ",", "[", "0", ",", "255", ",", "61", "]", ",", "[", "0", ",", "71", ",", "255", "]", ",", "\n", "[", "255", ",", "0", ",", "204", "]", ",", "[", "0", ",", "255", ",", "194", "]", ",", "[", "0", ",", "255", ",", "82", "]", ",", "[", "0", ",", "10", ",", "255", "]", ",", "\n", "[", "0", ",", "112", ",", "255", "]", ",", "[", "51", ",", "0", ",", "255", "]", ",", "[", "0", ",", "194", ",", "255", "]", ",", "[", "0", ",", "122", ",", "255", "]", ",", "\n", "[", "0", ",", "255", ",", "163", "]", ",", "[", "255", ",", "153", ",", "0", "]", ",", "[", "0", ",", "255", ",", "10", "]", ",", "[", "255", ",", "112", ",", "0", "]", ",", "\n", "[", "143", ",", "255", ",", "0", "]", ",", "[", "82", ",", "0", ",", "255", "]", ",", "[", "163", ",", "255", ",", "0", "]", ",", "[", "255", ",", "235", ",", "0", "]", ",", "\n", "[", "8", ",", "184", ",", "170", "]", ",", "[", "133", ",", "0", ",", "255", "]", ",", "[", "0", ",", "255", ",", "92", "]", ",", "[", "184", ",", "0", ",", "255", "]", ",", "\n", "[", "255", ",", "0", ",", "31", "]", ",", "[", "0", ",", "184", ",", "255", "]", ",", "[", "0", ",", "214", ",", "255", "]", ",", "[", "255", ",", "0", ",", "112", "]", ",", "\n", "[", "92", ",", "255", ",", "0", "]", ",", "[", "0", ",", "224", ",", "255", "]", ",", "[", "112", ",", "224", ",", "255", "]", ",", "[", "70", ",", "184", ",", "160", "]", ",", "\n", "[", "163", ",", "0", ",", "255", "]", ",", "[", "153", ",", "0", ",", "255", "]", ",", "[", "71", ",", "255", ",", "0", "]", ",", "[", "255", ",", "0", ",", "163", "]", ",", "\n", "[", "255", ",", "204", ",", "0", "]", ",", "[", "255", ",", "0", ",", "143", "]", ",", "[", "0", ",", "255", ",", "235", "]", ",", "[", "133", ",", "255", ",", "0", "]", ",", "\n", "[", "255", ",", "0", ",", "235", "]", ",", "[", "245", ",", "0", ",", "255", "]", ",", "[", "255", ",", "0", ",", "122", "]", ",", "[", "255", ",", "245", ",", "0", "]", ",", "\n", "[", "10", ",", "190", ",", "212", "]", ",", "[", "214", ",", "255", ",", "0", "]", ",", "[", "0", ",", "204", ",", "255", "]", ",", "[", "20", ",", "0", ",", "255", "]", ",", "\n", "[", "255", ",", "255", ",", "0", "]", ",", "[", "0", ",", "153", ",", "255", "]", ",", "[", "0", ",", "41", ",", "255", "]", ",", "[", "0", ",", "255", ",", "204", "]", ",", "\n", "[", "41", ",", "0", ",", "255", "]", ",", "[", "41", ",", "255", ",", "0", "]", ",", "[", "173", ",", "0", ",", "255", "]", ",", "[", "0", ",", "245", ",", "255", "]", ",", "\n", "[", "71", ",", "0", ",", "255", "]", ",", "[", "122", ",", "0", ",", "255", "]", ",", "[", "0", ",", "255", ",", "184", "]", ",", "[", "0", ",", "92", ",", "255", "]", ",", "\n", "[", "184", ",", "255", ",", "0", "]", ",", "[", "0", ",", "133", ",", "255", "]", ",", "[", "255", ",", "214", ",", "0", "]", ",", "[", "25", ",", "194", ",", "194", "]", ",", "\n", "[", "102", ",", "255", ",", "0", "]", ",", "[", "92", ",", "0", ",", "255", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.voc_palette": [[106, 113], ["None"], "function", ["None"], ["", "def", "voc_palette", "(", ")", ":", "\n", "    ", "\"\"\"Pascal VOC palette for external use.\"\"\"", "\n", "return", "[", "[", "0", ",", "0", ",", "0", "]", ",", "[", "128", ",", "0", ",", "0", "]", ",", "[", "0", ",", "128", ",", "0", "]", ",", "[", "128", ",", "128", ",", "0", "]", ",", "[", "0", ",", "0", ",", "128", "]", ",", "\n", "[", "128", ",", "0", ",", "128", "]", ",", "[", "0", ",", "128", ",", "128", "]", ",", "[", "128", ",", "128", ",", "128", "]", ",", "[", "64", ",", "0", ",", "0", "]", ",", "\n", "[", "192", ",", "0", ",", "0", "]", ",", "[", "64", ",", "128", ",", "0", "]", ",", "[", "192", ",", "128", ",", "0", "]", ",", "[", "64", ",", "0", ",", "128", "]", ",", "\n", "[", "192", ",", "0", ",", "128", "]", ",", "[", "64", ",", "128", ",", "128", "]", ",", "[", "192", ",", "128", ",", "128", "]", ",", "[", "0", ",", "64", ",", "0", "]", ",", "\n", "[", "128", ",", "64", ",", "0", "]", ",", "[", "0", ",", "192", ",", "0", "]", ",", "[", "128", ",", "192", ",", "0", "]", ",", "[", "0", ",", "64", ",", "128", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.get_classes": [[122, 137], ["dataset_aliases.items", "mmcv.is_str", "TypeError", "eval", "ValueError", "type"], "function", ["None"], ["def", "get_classes", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Get class names of a dataset.\"\"\"", "\n", "alias2name", "=", "{", "}", "\n", "for", "name", ",", "aliases", "in", "dataset_aliases", ".", "items", "(", ")", ":", "\n", "        ", "for", "alias", "in", "aliases", ":", "\n", "            ", "alias2name", "[", "alias", "]", "=", "name", "\n", "\n", "", "", "if", "mmcv", ".", "is_str", "(", "dataset", ")", ":", "\n", "        ", "if", "dataset", "in", "alias2name", ":", "\n", "            ", "labels", "=", "eval", "(", "alias2name", "[", "dataset", "]", "+", "'_classes()'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unrecognized dataset: {dataset}'", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "f'dataset must a str, but got {type(dataset)}'", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.class_names.get_palette": [[139, 154], ["dataset_aliases.items", "mmcv.is_str", "TypeError", "eval", "ValueError", "type"], "function", ["None"], ["", "def", "get_palette", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Get class palette (RGB) of a dataset.\"\"\"", "\n", "alias2name", "=", "{", "}", "\n", "for", "name", ",", "aliases", "in", "dataset_aliases", ".", "items", "(", ")", ":", "\n", "        ", "for", "alias", "in", "aliases", ":", "\n", "            ", "alias2name", "[", "alias", "]", "=", "name", "\n", "\n", "", "", "if", "mmcv", ".", "is_str", "(", "dataset", ")", ":", "\n", "        ", "if", "dataset", "in", "alias2name", ":", "\n", "            ", "labels", "=", "eval", "(", "alias2name", "[", "dataset", "]", "+", "'_palette()'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unrecognized dataset: {dataset}'", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "f'dataset must a str, but got {type(dataset)}'", ")", "\n", "", "return", "labels", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.EvalHook.__init__": [[26, 36], ["mmcv.runner.EvalHook.__init__", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "*", "args", ",", "\n", "by_epoch", "=", "False", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "by_epoch", "=", "by_epoch", ",", "**", "kwargs", ")", "\n", "self", ".", "efficent_test", "=", "efficient_test", "\n", "if", "efficient_test", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'DeprecationWarning: ``efficient_test`` for evaluation hook '", "\n", "'is deprecated, the evaluation hook is CPU memory friendly '", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.EvalHook._do_evaluate": [[40, 55], ["single_gpu_test", "len", "eval_hooks.EvalHook.evaluate", "eval_hooks.EvalHook._should_evaluate", "eval_hooks.EvalHook._save_ckpt"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.single_gpu_test", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.evaluate"], ["", "", "def", "_do_evaluate", "(", "self", ",", "runner", ")", ":", "\n", "        ", "\"\"\"perform evaluation and save ckpt.\"\"\"", "\n", "if", "not", "self", ".", "_should_evaluate", "(", "runner", ")", ":", "\n", "            ", "return", "\n", "\n", "", "from", "mmseg", ".", "apis", "import", "single_gpu_test", "\n", "results", "=", "single_gpu_test", "(", "\n", "runner", ".", "model", ",", "\n", "self", ".", "dataloader", ",", "\n", "show", "=", "False", ",", "\n", "efficient_test", "=", "self", ".", "efficient_test", ")", "\n", "runner", ".", "log_buffer", ".", "output", "[", "'eval_iter_num'", "]", "=", "len", "(", "self", ".", "dataloader", ")", "\n", "key_score", "=", "self", ".", "evaluate", "(", "runner", ",", "results", ")", "\n", "if", "self", ".", "save_best", ":", "\n", "            ", "self", ".", "_save_ckpt", "(", "runner", ",", "key_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__": [[74, 84], ["mmcv.runner.DistEvalHook.__init__", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook.__init__"], ["def", "__init__", "(", "self", ",", "\n", "*", "args", ",", "\n", "by_epoch", "=", "False", ",", "\n", "efficient_test", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "by_epoch", "=", "by_epoch", ",", "**", "kwargs", ")", "\n", "self", ".", "efficient_test", "=", "efficient_test", "\n", "if", "efficient_test", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "'DeprecationWarning: ``efficient_test`` for evaluation hook '", "\n", "'is deprecated, the evaluation hook is CPU memory friendly '", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.evaluation.eval_hooks.DistEvalHook._do_evaluate": [[88, 125], ["multi_gpu_test", "model.named_modules", "eval_hooks.DistEvalHook._should_evaluate", "os.join", "print", "len", "eval_hooks.DistEvalHook.evaluate", "eval_hooks.DistEvalHook._save_ckpt", "isinstance", "torch.broadcast", "torch.broadcast"], "methods", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.multi_gpu_test", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.evaluate"], ["", "", "def", "_do_evaluate", "(", "self", ",", "runner", ")", ":", "\n", "        ", "\"\"\"perform evaluation and save ckpt.\"\"\"", "\n", "# Synchronization of BatchNorm's buffer (running_mean", "\n", "# and running_var) is not supported in the DDP of pytorch,", "\n", "# which may cause the inconsistent performance of models in", "\n", "# different ranks, so we broadcast BatchNorm's buffers", "\n", "# of rank 0 to other ranks to avoid this.", "\n", "if", "self", ".", "broadcast_bn_buffer", ":", "\n", "            ", "model", "=", "runner", ".", "model", "\n", "for", "name", ",", "module", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "\n", "_BatchNorm", ")", "and", "module", ".", "track_running_stats", ":", "\n", "                    ", "dist", ".", "broadcast", "(", "module", ".", "running_var", ",", "0", ")", "\n", "dist", ".", "broadcast", "(", "module", ".", "running_mean", ",", "0", ")", "\n", "\n", "", "", "", "if", "not", "self", ".", "_should_evaluate", "(", "runner", ")", ":", "\n", "            ", "return", "\n", "\n", "", "tmpdir", "=", "self", ".", "tmpdir", "\n", "if", "tmpdir", "is", "None", ":", "\n", "            ", "tmpdir", "=", "osp", ".", "join", "(", "runner", ".", "work_dir", ",", "'.eval_hook'", ")", "\n", "\n", "", "from", "mmseg", ".", "apis", "import", "multi_gpu_test", "\n", "results", "=", "multi_gpu_test", "(", "\n", "runner", ".", "model", ",", "\n", "self", ".", "dataloader", ",", "\n", "tmpdir", "=", "tmpdir", ",", "\n", "gpu_collect", "=", "self", ".", "gpu_collect", ",", "\n", "efficient_test", "=", "self", ".", "efficient_test", ")", "\n", "\n", "if", "runner", ".", "rank", "==", "0", ":", "\n", "            ", "print", "(", "'\\n'", ")", "\n", "runner", ".", "log_buffer", ".", "output", "[", "'eval_iter_num'", "]", "=", "len", "(", "self", ".", "dataloader", ")", "\n", "key_score", "=", "self", ".", "evaluate", "(", "runner", ",", "results", ")", "\n", "\n", "if", "self", ".", "save_best", ":", "\n", "                ", "self", ".", "_save_ckpt", "(", "runner", ",", "key_score", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.train.parse_args": [[22, 64], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_mutually_exclusive_group", "parser.add_mutually_exclusive_group.add_argument", "parser.add_mutually_exclusive_group.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args"], ["\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "if", "deterministic", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n", "\n", "", "", "def", "train_segmentor", "(", "model", ",", "\n", "dataset", ",", "\n", "cfg", ",", "\n", "distributed", "=", "False", ",", "\n", "validate", "=", "False", ",", "\n", "timestamp", "=", "None", ",", "\n", "meta", "=", "None", ")", ":", "\n", "    ", "\"\"\"Launch segmentor training.\"\"\"", "\n", "logger", "=", "get_root_logger", "(", "cfg", ".", "log_level", ")", "\n", "\n", "# prepare data loaders", "\n", "dataset", "=", "dataset", "if", "isinstance", "(", "dataset", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "dataset", "]", "\n", "data_loaders", "=", "[", "\n", "build_dataloader", "(", "\n", "ds", ",", "\n", "cfg", ".", "data", ".", "samples_per_gpu", ",", "\n", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "# cfg.gpus will be ignored if distributed", "\n", "len", "(", "cfg", ".", "gpu_ids", ")", ",", "\n", "dist", "=", "distributed", ",", "\n", "seed", "=", "cfg", ".", "seed", ",", "\n", "drop_last", "=", "True", ")", "for", "ds", "in", "dataset", "\n", "]", "\n", "\n", "# put model on gpus", "\n", "if", "distributed", ":", "\n", "        ", "find_unused_parameters", "=", "cfg", ".", "get", "(", "'find_unused_parameters'", ",", "False", ")", "\n", "# Sets the `find_unused_parameters` parameter in", "\n", "# torch.nn.parallel.DistributedDataParallel", "\n", "model", "=", "MMDistributedDataParallel", "(", "\n", "model", ".", "cuda", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.train.main": [[66, 177], ["train.parse_args", "mmcv.utils.Config.fromfile", "Config.fromfile.get", "mmcv.mkdir_or_exist", "Config.fromfile.dump", "time.strftime", "os.join", "mmseg.utils.get_root_logger", "dict", "mmseg.utils.collect_env", "mmseg.utils.get_root_logger.info", "mmseg.utils.get_root_logger.info", "mmseg.utils.get_root_logger.info", "os.basename", "mmseg.models.build_segmentor", "mmcv.cnn.utils.revert_sync_batchnorm.init_weights", "mmseg.utils.get_root_logger.info", "dict.update", "mmseg.apis.train_segmentor", "Config.fromfile.merge_from_dict", "mmcv.runner.init_dist", "mmcv.runner.get_dist_info", "range", "os.abspath", "os.join", "time.localtime", "mmseg.utils.get_root_logger.info", "mmseg.apis.set_random_seed", "warnings.warn", "mmcv.cnn.utils.revert_sync_batchnorm", "mmseg.datasets.build_dataset", "len", "copy.deepcopy", "datasets.append", "dict", "Config.fromfile.get", "os.join", "range", "range", "os.basename", "Config.fromfile.get", "Config.fromfile.get", "mmseg.datasets.build_dataset", "mmseg.utils.collect_env.items", "os.splitext", "os.basename", "mmcv.utils.get_git_hash"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.logger.get_root_logger", "home.repos.pwc.inspect_result.jiayuzou2020_hft.utils.collect_env.collect_env", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_segmentor", "home.repos.pwc.inspect_result.jiayuzou2020_hft.backbones.swin.SwinTransformer.init_weights", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.train.train_segmentor", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.train.set_random_seed", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset"], ["broadcast_buffers", "=", "False", ",", "\n", "find_unused_parameters", "=", "find_unused_parameters", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "MMDataParallel", "(", "\n", "model", ".", "cuda", "(", "cfg", ".", "gpu_ids", "[", "0", "]", ")", ",", "device_ids", "=", "cfg", ".", "gpu_ids", ")", "\n", "\n", "# build runner", "\n", "", "optimizer", "=", "build_optimizer", "(", "model", ",", "cfg", ".", "optimizer", ")", "\n", "\n", "if", "cfg", ".", "get", "(", "'runner'", ")", "is", "None", ":", "\n", "        ", "cfg", ".", "runner", "=", "{", "'type'", ":", "'IterBasedRunner'", ",", "'max_iters'", ":", "cfg", ".", "total_iters", "}", "\n", "warnings", ".", "warn", "(", "\n", "'config is now expected to have a `runner` section, '", "\n", "'please set `runner` in your config.'", ",", "UserWarning", ")", "\n", "\n", "", "runner", "=", "build_runner", "(", "\n", "cfg", ".", "runner", ",", "\n", "default_args", "=", "dict", "(", "\n", "model", "=", "model", ",", "\n", "batch_processor", "=", "None", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "work_dir", "=", "cfg", ".", "work_dir", ",", "\n", "logger", "=", "logger", ",", "\n", "meta", "=", "meta", ")", ")", "\n", "\n", "# register hooks", "\n", "runner", ".", "register_training_hooks", "(", "cfg", ".", "lr_config", ",", "cfg", ".", "optimizer_config", ",", "\n", "cfg", ".", "checkpoint_config", ",", "cfg", ".", "log_config", ",", "\n", "cfg", ".", "get", "(", "'momentum_config'", ",", "None", ")", ")", "\n", "\n", "# an ugly walkaround to make the .log and .log.json filenames the same", "\n", "runner", ".", "timestamp", "=", "timestamp", "\n", "\n", "# register eval hooks", "\n", "if", "validate", ":", "\n", "        ", "val_dataset", "=", "build_dataset", "(", "cfg", ".", "data", ".", "val", ",", "dict", "(", "test_mode", "=", "True", ")", ")", "\n", "val_dataloader", "=", "build_dataloader", "(", "\n", "val_dataset", ",", "\n", "samples_per_gpu", "=", "1", ",", "\n", "workers_per_gpu", "=", "cfg", ".", "data", ".", "workers_per_gpu", ",", "\n", "dist", "=", "distributed", ",", "\n", "shuffle", "=", "False", ")", "\n", "eval_cfg", "=", "cfg", ".", "get", "(", "'evaluation'", ",", "{", "}", ")", "\n", "eval_cfg", "[", "'by_epoch'", "]", "=", "cfg", ".", "runner", "[", "'type'", "]", "!=", "'IterBasedRunner'", "\n", "eval_hook", "=", "DistEvalHook", "if", "distributed", "else", "EvalHook", "\n", "# In this PR (https://github.com/open-mmlab/mmcv/pull/1193), the", "\n", "# priority of IterTimerHook has been modified from 'NORMAL' to 'LOW'.", "\n", "runner", ".", "register_hook", "(", "\n", "eval_hook", "(", "val_dataloader", ",", "**", "eval_cfg", ")", ",", "priority", "=", "'LOW'", ")", "\n", "\n", "", "if", "cfg", ".", "resume_from", ":", "\n", "        ", "runner", ".", "resume", "(", "cfg", ".", "resume_from", ")", "\n", "", "elif", "cfg", ".", "load_from", ":", "\n", "        ", "runner", ".", "load_checkpoint", "(", "cfg", ".", "load_from", ")", "\n", "", "runner", ".", "run", "(", "data_loaders", ",", "cfg", ".", "workflow", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args": [[21, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "str"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args"], ["data_loader", ",", "\n", "show", "=", "False", ",", "\n", "out_dir", "=", "None", ",", "\n", "efficient_test", "=", "False", ",", "\n", "opacity", "=", "0.5", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "results", "=", "[", "]", "\n", "dataset", "=", "data_loader", ".", "dataset", "\n", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "dataset", ")", ")", "\n", "if", "efficient_test", ":", "\n", "        ", "mmcv", ".", "mkdir_or_exist", "(", "'.efficient_test'", ")", "\n", "", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "**", "data", ")", "\n", "\n", "", "if", "show", "or", "out_dir", ":", "\n", "            ", "img_tensor", "=", "data", "[", "'img'", "]", "[", "0", "]", "\n", "img_metas", "=", "data", "[", "'img_metas'", "]", "[", "0", "]", ".", "data", "[", "0", "]", "\n", "imgs", "=", "tensor2imgs", "(", "img_tensor", ",", "**", "img_metas", "[", "0", "]", "[", "'img_norm_cfg'", "]", ")", "\n", "assert", "len", "(", "imgs", ")", "==", "len", "(", "img_metas", ")", "\n", "\n", "for", "img", ",", "img_meta", "in", "zip", "(", "imgs", ",", "img_metas", ")", ":", "\n", "                ", "h", ",", "w", ",", "_", "=", "img_meta", "[", "'img_shape'", "]", "\n", "img_show", "=", "img", "[", ":", "h", ",", ":", "w", ",", ":", "]", "\n", "\n", "ori_h", ",", "ori_w", "=", "img_meta", "[", "'ori_shape'", "]", "[", ":", "-", "1", "]", "\n", "img_show", "=", "mmcv", ".", "imresize", "(", "img_show", ",", "(", "ori_w", ",", "ori_h", ")", ")", "\n", "\n", "if", "out_dir", ":", "\n", "                    ", "out_file", "=", "osp", ".", "join", "(", "out_dir", ",", "img_meta", "[", "'ori_filename'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "out_file", "=", "None", "\n", "\n", "", "model", ".", "module", ".", "show_result", "(", "\n", "img_show", ",", "\n", "result", ",", "\n", "palette", "=", "dataset", ".", "PALETTE", ",", "\n", "show", "=", "show", ",", "\n", "out_file", "=", "out_file", ",", "\n", "opacity", "=", "opacity", ")", "\n", "\n", "", "", "if", "isinstance", "(", "result", ",", "list", ")", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "[", "np2tmp", "(", "_", ",", "tmpdir", "=", "'.efficient_test'", ")", "for", "_", "in", "result", "]", "\n", "", "results", ".", "extend", "(", "result", ")", "\n", "", "else", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "np2tmp", "(", "result", ",", "tmpdir", "=", "'.efficient_test'", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "batch_size", "=", "len", "(", "result", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "prog_bar", ".", "update", "(", ")", "\n", "", "", "return", "results", "\n", "\n", "\n", "", "def", "multi_gpu_test", "(", "model", ",", "\n", "data_loader", ",", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.main": [[80, 225], ["test.parse_args", "mmcv.Config.fromfile", "mmcv.Config.fromfile.get", "mmcv.runner.get_dist_info", "mmseg.datasets.build_dataset", "mmseg.datasets.build_dataloader", "mmseg.models.build_segmentor", "mmcv.Config.fromfile.get", "mmcv.runner.load_checkpoint", "torch.cuda.empty_cache", "eval_kwargs.get", "mmcv.runner.get_dist_info", "ValueError", "ValueError", "mmcv.Config.fromfile.merge_from_dict", "mmcv.runner.init_dist", "mmcv.mkdir_or_exist", "time.strftime", "os.join", "mmcv.runner.wrap_fp16_model", "mmcv.runner.load_checkpoint.get", "print", "mmcv.runner.load_checkpoint.get", "print", "warnings.warn", "mmcv.mkdir_or_exist", "mmcv.parallel.MMDataParallel", "mmseg.apis.single_gpu_test", "mmcv.parallel.MMDistributedDataParallel", "mmseg.apis.multi_gpu_test", "parse_args.out.endswith", "os.abspath", "time.localtime", "mmcv.Config.fromfile.get", "len", "eval_kwargs.setdefault", "mmcv.parallel.MMDistributedDataParallel.cuda", "warnings.warn", "print", "mmcv.dump", "mmseg.datasets.build_dataset.format_results", "eval_kwargs.update", "mmseg.datasets.build_dataset.evaluate", "dict", "mmcv.dump", "shutil.rmtree", "torch.cuda.current_device"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataset", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.builder.build_dataloader", "home.repos.pwc.inspect_result.jiayuzou2020_hft.models.builder.build_segmentor", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.single_gpu_test", "home.repos.pwc.inspect_result.jiayuzou2020_hft.apis.test.multi_gpu_test", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.format_results", "home.repos.pwc.inspect_result.jiayuzou2020_hft.datasets.argoverse.ArgoverseDataset.evaluate"], ["gpu_collect", "=", "False", ",", "\n", "efficient_test", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "results", "=", "[", "]", "\n", "dataset", "=", "data_loader", ".", "dataset", "\n", "rank", ",", "world_size", "=", "get_dist_info", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "prog_bar", "=", "mmcv", ".", "ProgressBar", "(", "len", "(", "dataset", ")", ")", "\n", "", "if", "efficient_test", ":", "\n", "        ", "mmcv", ".", "mkdir_or_exist", "(", "'.efficient_test'", ")", "\n", "", "for", "i", ",", "data", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "result", "=", "model", "(", "return_loss", "=", "False", ",", "rescale", "=", "True", ",", "**", "data", ")", "\n", "\n", "", "if", "isinstance", "(", "result", ",", "list", ")", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "[", "np2tmp", "(", "_", ",", "tmpdir", "=", "'.efficient_test'", ")", "for", "_", "in", "result", "]", "\n", "", "results", ".", "extend", "(", "result", ")", "\n", "", "else", ":", "\n", "            ", "if", "efficient_test", ":", "\n", "                ", "result", "=", "np2tmp", "(", "result", ",", "tmpdir", "=", "'.efficient_test'", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "\n", "", "if", "rank", "==", "0", ":", "\n", "            ", "batch_size", "=", "len", "(", "result", ")", "\n", "for", "_", "in", "range", "(", "batch_size", "*", "world_size", ")", ":", "\n", "                ", "prog_bar", ".", "update", "(", ")", "\n", "\n", "# collect results from all ranks", "\n", "", "", "", "if", "gpu_collect", ":", "\n", "        ", "results", "=", "collect_results_gpu", "(", "results", ",", "len", "(", "dataset", ")", ")", "\n", "", "else", ":", "\n", "        ", "results", "=", "collect_results_cpu", "(", "results", ",", "len", "(", "dataset", ")", ",", "tmpdir", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.swin2mmseg.convert_swin": [[11, 63], ["collections.OrderedDict", "ckpt.items", "x[].transpose().reshape.reshape", "x[].transpose().reshape", "x[].transpose().reshape.reshape", "x[].transpose().reshape", "k.startswith", "k.startswith", "x[].transpose", "x[].transpose", "k.replace.replace", "k.startswith", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace", "swin2mmseg.convert_swin.correct_unfold_reduction_order"], "function", ["None"], ["def", "convert_swin", "(", "ckpt", ")", ":", "\n", "    ", "new_ckpt", "=", "OrderedDict", "(", ")", "\n", "\n", "def", "correct_unfold_reduction_order", "(", "x", ")", ":", "\n", "        ", "out_channel", ",", "in_channel", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "reshape", "(", "out_channel", ",", "4", ",", "in_channel", "//", "4", ")", "\n", "x", "=", "x", "[", ":", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ",", ":", "]", ".", "transpose", "(", "1", ",", "\n", "2", ")", ".", "reshape", "(", "out_channel", ",", "in_channel", ")", "\n", "return", "x", "\n", "\n", "", "def", "correct_unfold_norm_order", "(", "x", ")", ":", "\n", "        ", "in_channel", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "x", ".", "reshape", "(", "4", ",", "in_channel", "//", "4", ")", "\n", "x", "=", "x", "[", "[", "0", ",", "2", ",", "1", ",", "3", "]", ",", ":", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "in_channel", ")", "\n", "return", "x", "\n", "\n", "", "for", "k", ",", "v", "in", "ckpt", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "continue", "\n", "", "elif", "k", ".", "startswith", "(", "'layers'", ")", ":", "\n", "            ", "new_v", "=", "v", "\n", "if", "'attn.'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'attn.'", ",", "'attn.w_msa.'", ")", "\n", "", "elif", "'mlp.'", "in", "k", ":", "\n", "                ", "if", "'mlp.fc1.'", "in", "k", ":", "\n", "                    ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc1.'", ",", "'ffn.layers.0.0.'", ")", "\n", "", "elif", "'mlp.fc2.'", "in", "k", ":", "\n", "                    ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc2.'", ",", "'ffn.layers.1.'", ")", "\n", "", "else", ":", "\n", "                    ", "new_k", "=", "k", ".", "replace", "(", "'mlp.'", ",", "'ffn.'", ")", "\n", "", "", "elif", "'downsample'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", "\n", "if", "'reduction.'", "in", "k", ":", "\n", "                    ", "new_v", "=", "correct_unfold_reduction_order", "(", "v", ")", "\n", "", "elif", "'norm.'", "in", "k", ":", "\n", "                    ", "new_v", "=", "correct_unfold_norm_order", "(", "v", ")", "\n", "", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "new_k", "=", "new_k", ".", "replace", "(", "'layers'", ",", "'stages'", ",", "1", ")", "\n", "", "elif", "k", ".", "startswith", "(", "'patch_embed'", ")", ":", "\n", "            ", "new_v", "=", "v", "\n", "if", "'proj'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'proj'", ",", "'projection'", ")", "\n", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "", "else", ":", "\n", "            ", "new_v", "=", "v", "\n", "new_k", "=", "k", "\n", "\n", "", "new_ckpt", "[", "new_k", "]", "=", "new_v", "\n", "\n", "", "return", "new_ckpt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.swin2mmseg.main": [[65, 84], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmcv.runner.CheckpointLoader.load_checkpoint", "swin2mmseg.convert_swin", "mmcv.mkdir_or_exist", "torch.save", "os.dirname"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args", "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.swin2mmseg.convert_swin"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Convert keys in official pretrained swin models to'", "\n", "'MMSegmentation style.'", ")", "\n", "parser", ".", "add_argument", "(", "'src'", ",", "help", "=", "'src model path or url'", ")", "\n", "# The dst path must be a full path of the new checkpoint.", "\n", "parser", ".", "add_argument", "(", "'dst'", ",", "help", "=", "'save path'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "checkpoint", "=", "CheckpointLoader", ".", "load_checkpoint", "(", "args", ".", "src", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'state_dict'", "in", "checkpoint", ":", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "", "elif", "'model'", "in", "checkpoint", ":", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'model'", "]", "\n", "", "else", ":", "\n", "        ", "state_dict", "=", "checkpoint", "\n", "", "weight", "=", "convert_swin", "(", "state_dict", ")", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "dirname", "(", "args", ".", "dst", ")", ")", "\n", "torch", ".", "save", "(", "weight", ",", "args", ".", "dst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.mit2mmseg.convert_mit": [[11, 58], ["collections.OrderedDict", "ckpt.items", "k.startswith", "k.startswith", "int", "k.replace", "k.startswith", "[].replace", "new_k.replace.replace", "int", "k.replace", "k.startswith", "[].replace", "k.replace", "new_k.replace.replace", "torch.cat", "int", "k.replace", "[].replace", "k.split", "new_k.replace.replace", "k.split", "new_k.replace.replace", "new_k.replace.replace", "new_k.replace.replace", "new_k.replace.replace", "new_k.replace.replace", "k.split", "v.reshape"], "function", ["None"], ["def", "convert_mit", "(", "ckpt", ")", ":", "\n", "    ", "new_ckpt", "=", "OrderedDict", "(", ")", "\n", "# Process the concat between q linear weights and kv linear weights", "\n", "for", "k", ",", "v", "in", "ckpt", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "continue", "\n", "# patch embedding conversion", "\n", "", "elif", "k", ".", "startswith", "(", "'patch_embed'", ")", ":", "\n", "            ", "stage_i", "=", "int", "(", "k", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "replace", "(", "'patch_embed'", ",", "''", ")", ")", "\n", "new_k", "=", "k", ".", "replace", "(", "f'patch_embed{stage_i}'", ",", "f'layers.{stage_i-1}.0'", ")", "\n", "new_v", "=", "v", "\n", "if", "'proj.'", "in", "new_k", ":", "\n", "                ", "new_k", "=", "new_k", ".", "replace", "(", "'proj.'", ",", "'projection.'", ")", "\n", "# transformer encoder layer conversion", "\n", "", "", "elif", "k", ".", "startswith", "(", "'block'", ")", ":", "\n", "            ", "stage_i", "=", "int", "(", "k", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "replace", "(", "'block'", ",", "''", ")", ")", "\n", "new_k", "=", "k", ".", "replace", "(", "f'block{stage_i}'", ",", "f'layers.{stage_i-1}.1'", ")", "\n", "new_v", "=", "v", "\n", "if", "'attn.q.'", "in", "new_k", ":", "\n", "                ", "sub_item_k", "=", "k", ".", "replace", "(", "'q.'", ",", "'kv.'", ")", "\n", "new_k", "=", "new_k", ".", "replace", "(", "'q.'", ",", "'attn.in_proj_'", ")", "\n", "new_v", "=", "torch", ".", "cat", "(", "[", "v", ",", "ckpt", "[", "sub_item_k", "]", "]", ",", "dim", "=", "0", ")", "\n", "", "elif", "'attn.kv.'", "in", "new_k", ":", "\n", "                ", "continue", "\n", "", "elif", "'attn.proj.'", "in", "new_k", ":", "\n", "                ", "new_k", "=", "new_k", ".", "replace", "(", "'proj.'", ",", "'attn.out_proj.'", ")", "\n", "", "elif", "'attn.sr.'", "in", "new_k", ":", "\n", "                ", "new_k", "=", "new_k", ".", "replace", "(", "'sr.'", ",", "'sr.'", ")", "\n", "", "elif", "'mlp.'", "in", "new_k", ":", "\n", "                ", "string", "=", "f'{new_k}-'", "\n", "new_k", "=", "new_k", ".", "replace", "(", "'mlp.'", ",", "'ffn.layers.'", ")", "\n", "if", "'fc1.weight'", "in", "new_k", "or", "'fc2.weight'", "in", "new_k", ":", "\n", "                    ", "new_v", "=", "v", ".", "reshape", "(", "(", "*", "v", ".", "shape", ",", "1", ",", "1", ")", ")", "\n", "", "new_k", "=", "new_k", ".", "replace", "(", "'fc1.'", ",", "'0.'", ")", "\n", "new_k", "=", "new_k", ".", "replace", "(", "'dwconv.dwconv.'", ",", "'1.'", ")", "\n", "new_k", "=", "new_k", ".", "replace", "(", "'fc2.'", ",", "'4.'", ")", "\n", "string", "+=", "f'{new_k} {v.shape}-{new_v.shape}'", "\n", "# norm layer conversion", "\n", "", "", "elif", "k", ".", "startswith", "(", "'norm'", ")", ":", "\n", "            ", "stage_i", "=", "int", "(", "k", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "replace", "(", "'norm'", ",", "''", ")", ")", "\n", "new_k", "=", "k", ".", "replace", "(", "f'norm{stage_i}'", ",", "f'layers.{stage_i-1}.2'", ")", "\n", "new_v", "=", "v", "\n", "", "else", ":", "\n", "            ", "new_k", "=", "k", "\n", "new_v", "=", "v", "\n", "", "new_ckpt", "[", "new_k", "]", "=", "new_v", "\n", "", "return", "new_ckpt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.mit2mmseg.main": [[60, 79], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmcv.runner.CheckpointLoader.load_checkpoint", "mit2mmseg.convert_mit", "mmcv.mkdir_or_exist", "torch.save", "os.dirname"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args", "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.mit2mmseg.convert_mit"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Convert keys in official pretrained segformer to '", "\n", "'MMSegmentation style.'", ")", "\n", "parser", ".", "add_argument", "(", "'src'", ",", "help", "=", "'src model path or url'", ")", "\n", "# The dst path must be a full path of the new checkpoint.", "\n", "parser", ".", "add_argument", "(", "'dst'", ",", "help", "=", "'save path'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "checkpoint", "=", "CheckpointLoader", ".", "load_checkpoint", "(", "args", ".", "src", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'state_dict'", "in", "checkpoint", ":", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "", "elif", "'model'", "in", "checkpoint", ":", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'model'", "]", "\n", "", "else", ":", "\n", "        ", "state_dict", "=", "checkpoint", "\n", "", "weight", "=", "convert_mit", "(", "state_dict", ")", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "dirname", "(", "args", ".", "dst", ")", ")", "\n", "torch", ".", "save", "(", "weight", ",", "args", ".", "dst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.vit2mmseg.convert_vit": [[11, 44], ["collections.OrderedDict", "ckpt.items", "k.startswith", "k.startswith", "k.replace", "k.startswith", "k.startswith", "k.replace", "k.replace.replace", "k.replace", "k.replace", "k.replace", "k.replace", "k.replace"], "function", ["None"], ["def", "convert_vit", "(", "ckpt", ")", ":", "\n", "\n", "    ", "new_ckpt", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "ckpt", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "'head'", ")", ":", "\n", "            ", "continue", "\n", "", "if", "k", ".", "startswith", "(", "'norm'", ")", ":", "\n", "            ", "new_k", "=", "k", ".", "replace", "(", "'norm.'", ",", "'ln1.'", ")", "\n", "", "elif", "k", ".", "startswith", "(", "'patch_embed'", ")", ":", "\n", "            ", "if", "'proj'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'proj'", ",", "'projection'", ")", "\n", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "", "elif", "k", ".", "startswith", "(", "'blocks'", ")", ":", "\n", "            ", "if", "'norm'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'norm'", ",", "'ln'", ")", "\n", "", "elif", "'mlp.fc1'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc1'", ",", "'ffn.layers.0.0'", ")", "\n", "", "elif", "'mlp.fc2'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'mlp.fc2'", ",", "'ffn.layers.1'", ")", "\n", "", "elif", "'attn.qkv'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'attn.qkv.'", ",", "'attn.attn.in_proj_'", ")", "\n", "", "elif", "'attn.proj'", "in", "k", ":", "\n", "                ", "new_k", "=", "k", ".", "replace", "(", "'attn.proj'", ",", "'attn.attn.out_proj'", ")", "\n", "", "else", ":", "\n", "                ", "new_k", "=", "k", "\n", "", "new_k", "=", "new_k", ".", "replace", "(", "'blocks.'", ",", "'layers.'", ")", "\n", "", "else", ":", "\n", "            ", "new_k", "=", "k", "\n", "", "new_ckpt", "[", "new_k", "]", "=", "v", "\n", "\n", "", "return", "new_ckpt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.vit2mmseg.main": [[46, 67], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "mmcv.runner.CheckpointLoader.load_checkpoint", "vit2mmseg.convert_vit", "mmcv.mkdir_or_exist", "torch.save", "os.dirname"], "function", ["home.repos.pwc.inspect_result.jiayuzou2020_hft.tools.test.parse_args", "home.repos.pwc.inspect_result.jiayuzou2020_hft.model_converters.vit2mmseg.convert_vit"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Convert keys in timm pretrained vit models to '", "\n", "'MMSegmentation style.'", ")", "\n", "parser", ".", "add_argument", "(", "'src'", ",", "help", "=", "'src model path or url'", ")", "\n", "# The dst path must be a full path of the new checkpoint.", "\n", "parser", ".", "add_argument", "(", "'dst'", ",", "help", "=", "'save path'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "checkpoint", "=", "CheckpointLoader", ".", "load_checkpoint", "(", "args", ".", "src", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "'state_dict'", "in", "checkpoint", ":", "\n", "# timm checkpoint", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "", "elif", "'model'", "in", "checkpoint", ":", "\n", "# deit checkpoint", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'model'", "]", "\n", "", "else", ":", "\n", "        ", "state_dict", "=", "checkpoint", "\n", "", "weight", "=", "convert_vit", "(", "state_dict", ")", "\n", "mmcv", ".", "mkdir_or_exist", "(", "osp", ".", "dirname", "(", "args", ".", "dst", ")", ")", "\n", "torch", ".", "save", "(", "weight", ",", "args", ".", "dst", ")", "\n", "\n"]]}