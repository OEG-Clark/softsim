{"home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.model_with_weights": [[46, 92], ["model.load_weights", "len", "crfnet.model.architectures.backbone", "train_crfnet.create_models", "img_model.load_weights", "model.get_layer().get_weights", "img_model.get_layer().get_weights", "model.get_layer().set_weights", "print", "model.get_layer", "img_model.get_layer", "model.get_layer"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.backbone", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.create_models"], ["def", "model_with_weights", "(", "model", ",", "weights", ",", "skip_mismatch", ",", "config", "=", "None", ",", "num_classes", "=", "None", ")", ":", "\n", "    ", "\"\"\" Load weights for model.\n\n    :param model:           <keras.Model>       The model to load weights for\n    :param weights:         <string>            Path to the weights file to load\n    :param skip_mismatch:   <bool>              If True, skips layers whose shape of weights doesn't match with the model.\n\n    :return model:          <keras.Model>       The model with loaded weights\n    \"\"\"", "\n", "\n", "if", "weights", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_weights", "(", "weights", ",", "by_name", "=", "True", ",", "skip_mismatch", "=", "skip_mismatch", ")", "\n", "if", "len", "(", "config", ".", "channels", ")", ">", "3", ":", "\n", "            ", "config", ".", "channels", "=", "[", "0", ",", "1", ",", "2", "]", "\n", "img_backbone", "=", "architectures", ".", "backbone", "(", "'vgg16'", ")", "\n", "## get img weights", "\n", "# create img model", "\n", "img_model", ",", "_", ",", "_", "=", "create_models", "(", "\n", "backbone_retinanet", "=", "img_backbone", ".", "retinanet", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "weights", "=", "weights", ",", "\n", "multi_gpu", "=", "0", ",", "\n", "freeze_backbone", "=", "False", ",", "\n", "lr", "=", "config", ".", "learning_rate", ",", "\n", "inputs", "=", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "cfg", "=", "config", ",", "\n", "distance", "=", "config", ".", "distance_detection", ",", "\n", "distance_alpha", "=", "config", ".", "distance_alpha", "\n", ")", "\n", "\n", "img_model", ".", "load_weights", "(", "weights", ",", "by_name", "=", "True", ",", "skip_mismatch", "=", "skip_mismatch", ")", "\n", "# layers with mismatch", "\n", "if", "'max'", "in", "config", ".", "network", ":", "\n", "                ", "layers", "=", "[", "'block1_conv1'", ",", "'block2_conv1'", ",", "'block3_conv1'", ",", "'block4_conv1'", ",", "'block5_conv1'", "]", "\n", "", "else", ":", "\n", "                ", "layers", "=", "[", "'block1_conv1'", "]", "\n", "", "for", "layer_name", "in", "layers", ":", "\n", "                ", "model_weights", "=", "model", ".", "get_layer", "(", "layer_name", ")", ".", "get_weights", "(", ")", "\n", "img_weights", "=", "img_model", ".", "get_layer", "(", "layer_name", ")", ".", "get_weights", "(", ")", "\n", "# [0] is weights", "\n", "model_weights", "[", "0", "]", "[", ":", ",", ":", ",", ":", "img_weights", "[", "0", "]", ".", "shape", "[", "2", "]", ",", ":", "]", "=", "img_weights", "[", "0", "]", "\n", "# [1] is bias", "\n", "model_weights", "[", "1", "]", "=", "img_weights", "[", "1", "]", "\n", "model", ".", "get_layer", "(", "layer_name", ")", ".", "set_weights", "(", "model_weights", ")", "\n", "print", "(", "'Loaded available image weights for layer {}'", ".", "format", "(", "layer_name", ")", ")", "\n", "", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.create_models": [[94, 172], ["crfnet.model.architectures.retinanet.retinanet_bbox", "crfnet.utils.anchor_parameters.AnchorParameters.small.num_anchors", "multi_gpu_model", "train_crfnet.model_with_weights", "os.path.join", "crfnet.utils.helpers.makedirs", "plot_model", "multi_gpu_model.compile", "multi_gpu_model.compile", "tensorflow.device", "train_crfnet.model_with_weights", "backbone_retinanet", "print", "print", "backbone_retinanet", "copy.deepcopy", "traceback.format_exc", "keras.optimizers.adam", "keras.optimizers.adam", "keras.optimizers.adam", "keras.optimizers.adam", "copy.deepcopy", "os.path.join", "sys.exc_info", "crfnet.model.losses.smooth_l1", "crfnet.model.losses.focal", "crfnet.model.losses.smooth_l1", "crfnet.model.losses.smooth_l1", "crfnet.model.losses.focal"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.retinanet_bbox", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_parameters.AnchorParameters.num_anchors", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.model_with_weights", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.makedirs", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.model_with_weights", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.smooth_l1", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.focal", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.smooth_l1", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.smooth_l1", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.focal"], ["", "def", "create_models", "(", "backbone_retinanet", ",", "num_classes", ",", "weights", ",", "multi_gpu", "=", "0", ",", "\n", "freeze_backbone", "=", "False", ",", "distance", "=", "False", ",", "distance_alpha", "=", "1.0", ",", "lr", "=", "1e-5", ",", "cfg", "=", "None", ",", "inputs", "=", "(", "None", ",", "None", ",", "3", ")", ")", ":", "\n", "    ", "\"\"\" Creates three models (model, training_model, prediction_model).\n\n    :param backbone_retinanet:      <func>              A function to call to create a retinanet model with a given backbone\n    :param num_classes:             <int>               The number of classes to train\n    :param weights:                 <keras.Weights>     The weights to load into the model\n    :param multi_gpu:               <int>               The number of GPUs to use for training\n    :param freeze_backbone:         <bool>              If True, disables learning for the backbone\n    :param distance:                <bool>              If True, distance detection is enabled\n    :param distance_alpha:          <float>             Weighted loss factor for distance loss\n    :param lr:                      <float>             Learning rate for network training\n    :param cfg:                     <Configuration>     Config class with config parameters\n    :param inputs:                  <tuple>             Input shape for neural network\n\n    :return model:                  <keras.Model>       The base model. This is also the model that is saved in snapshots.\n    :return training_model:         <keras.Model>       The training model. If multi_gpu=0, this is identical to model.\n    :return prediction_model:       <keras.Model>       The model wrapped with utility functions to perform object detection \n                                                        (applies regression values and performs NMS).\n    \"\"\"", "\n", "\n", "modifier", "=", "freeze_model", "if", "freeze_backbone", "else", "None", "\n", "\n", "# load anchor parameters, or pass None (so that defaults will be used)", "\n", "if", "'small'", "in", "cfg", ".", "anchor_params", ":", "\n", "        ", "anchor_params", "=", "AnchorParameters", ".", "small", "\n", "num_anchors", "=", "AnchorParameters", ".", "small", ".", "num_anchors", "(", ")", "\n", "", "else", ":", "\n", "        ", "anchor_params", "=", "None", "\n", "num_anchors", "=", "None", "\n", "\n", "# Keras recommends initialising a multi-gpu model on the CPU to ease weight sharing, and to prevent OOM errors.", "\n", "# optionally wrap in a parallel model", "\n", "", "if", "multi_gpu", ">", "1", ":", "\n", "        ", "from", "keras", ".", "utils", "import", "multi_gpu_model", "\n", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "model", "=", "model_with_weights", "(", "backbone_retinanet", "(", "num_classes", ",", "num_anchors", "=", "num_anchors", ",", "modifier", "=", "modifier", ",", "inputs", "=", "inputs", ",", "distance", "=", "distance", ")", ",", "weights", "=", "weights", ",", "skip_mismatch", "=", "True", ",", "config", "=", "copy", ".", "deepcopy", "(", "cfg", ")", ",", "num_classes", "=", "num_classes", ")", "\n", "\n", "", "training_model", "=", "multi_gpu_model", "(", "model", ",", "gpus", "=", "multi_gpu", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model_with_weights", "(", "backbone_retinanet", "(", "num_classes", ",", "num_anchors", "=", "num_anchors", ",", "modifier", "=", "modifier", ",", "inputs", "=", "inputs", ",", "distance", "=", "distance", ",", "cfg", "=", "cfg", ")", ",", "weights", "=", "weights", ",", "skip_mismatch", "=", "True", ",", "config", "=", "copy", ".", "deepcopy", "(", "cfg", ")", ",", "num_classes", "=", "num_classes", ")", "\n", "training_model", "=", "model", "\n", "\n", "", "try", ":", "\n", "        ", "from", "keras", ".", "utils", "import", "plot_model", "\n", "# Write the keras model plot into a file", "\n", "plot_path", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "tb_logdir", ",", "cfg", ".", "model_name", ")", "\n", "makedirs", "(", "plot_path", ")", "\n", "plot_model", "(", "training_model", ",", "to_file", "=", "(", "os", ".", "path", ".", "join", "(", "plot_path", ",", "cfg", ".", "network", ")", "+", "'.png'", ")", ",", "show_shapes", "=", "True", ")", "\n", "", "except", "Exception", ":", "\n", "# TODO: Catch the particular exceptions", "\n", "        ", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "print", "(", "sys", ".", "exc_info", "(", ")", "[", "2", "]", ")", "\n", "\n", "# make prediction model", "\n", "", "prediction_model", "=", "retinanet_bbox", "(", "model", "=", "model", ",", "anchor_params", "=", "anchor_params", ",", "score_thresh_train", "=", "cfg", ".", "score_thresh_train", ",", "class_specific_filter", "=", "cfg", ".", "class_specific_nms", ")", "\n", "\n", "# compile model", "\n", "if", "distance", ":", "\n", "        ", "training_model", ".", "compile", "(", "\n", "loss", "=", "{", "\n", "'regression'", ":", "losses", ".", "smooth_l1", "(", ")", ",", "\n", "'classification'", ":", "losses", ".", "focal", "(", ")", ",", "\n", "'distance'", ":", "losses", ".", "smooth_l1", "(", "alpha", "=", "distance_alpha", ")", "\n", "}", ",", "\n", "optimizer", "=", "keras", ".", "optimizers", ".", "adam", "(", "lr", "=", "lr", ",", "clipnorm", "=", "0.001", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "training_model", ".", "compile", "(", "\n", "loss", "=", "{", "\n", "'regression'", ":", "losses", ".", "smooth_l1", "(", ")", ",", "\n", "'classification'", ":", "losses", ".", "focal", "(", ")", ",", "\n", "}", ",", "\n", "optimizer", "=", "keras", ".", "optimizers", ".", "adam", "(", "lr", "=", "lr", ",", "clipnorm", "=", "0.001", ")", "\n", ")", "\n", "\n", "", "return", "model", ",", "training_model", ",", "prediction_model", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.create_callbacks": [[174, 255], ["keras.callbacks.ProgbarLogger", "keras.callbacks.ProgbarLogger", "callbacks.append", "crfnet.utils.callbacks.RedirectModel", "callbacks.append", "callbacks.append", "os.path.join", "crfnet.utils.helpers.makedirs", "keras.callbacks.TensorBoard", "keras.callbacks.TensorBoard", "keras.callbacks.TensorBoard.set_model", "callbacks.append", "CocoEval", "crfnet.utils.callbacks.Evaluate", "crfnet.utils.helpers.makedirs", "keras.callbacks.ModelCheckpoint", "keras.callbacks.ModelCheckpoint", "crfnet.utils.callbacks.RedirectModel", "callbacks.append", "keras.callbacks.ReduceLROnPlateau", "keras.callbacks.ReduceLROnPlateau", "os.makedirs", "os.path.join"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.makedirs", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.makedirs", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.makedirs"], ["", "def", "create_callbacks", "(", "model", ",", "prediction_model", ",", "validation_generator", ",", "cfg", ")", ":", "\n", "    ", "\"\"\" Creates the callbacks to use during training.\n\n    :param model:                   <keras.Model>           The base model.\n    :param prediction_model:        <keras.Model>           The model that should be used for validation.\n    :param validation_generator:    <Generator>             The generator for creating validation data.\n    :param cfg:                     <Configuration>         Config class with config parameters.\n\n    :return callbacks:              <list>                  A list of callbacks used for training.\n    \"\"\"", "\n", "callbacks", "=", "[", "]", "\n", "\n", "# Add progbar", "\n", "progbar_callback", "=", "keras", ".", "callbacks", ".", "ProgbarLogger", "(", "count_mode", "=", "'steps'", ",", "stateful_metrics", "=", "None", ")", "\n", "callbacks", ".", "append", "(", "progbar_callback", ")", "\n", "\n", "if", "cfg", ".", "tensorboard", ":", "\n", "        ", "tb_logdir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "tb_logdir", ",", "cfg", ".", "model_name", ")", "\n", "makedirs", "(", "tb_logdir", ")", "\n", "tensorboard_callback", "=", "keras", ".", "callbacks", ".", "TensorBoard", "(", "\n", "log_dir", "=", "tb_logdir", ",", "\n", "histogram_freq", "=", "0", ",", "\n", "batch_size", "=", "cfg", ".", "batchsize", ",", "\n", "write_graph", "=", "True", ",", "\n", "write_grads", "=", "False", ",", "\n", "write_images", "=", "True", ",", "\n", "embeddings_freq", "=", "0", ",", "\n", "embeddings_layer_names", "=", "None", ",", "\n", "embeddings_metadata", "=", "None", "\n", ")", "\n", "tensorboard_callback", ".", "set_model", "(", "model", ")", "\n", "\n", "callbacks", ".", "append", "(", "tensorboard_callback", ")", "\n", "", "else", ":", "\n", "        ", "tensorboard_callback", "=", "None", "\n", "\n", "\n", "", "if", "cfg", ".", "data_set", "==", "'coco'", ":", "\n", "        ", "from", ".", "utils", ".", "coco", "import", "CocoEval", "\n", "\n", "# use prediction model for evaluation", "\n", "evaluation", "=", "CocoEval", "(", "validation_generator", ",", "tensorboard", "=", "tensorboard_callback", ")", "\n", "", "else", ":", "\n", "        ", "save_path", "=", "None", "\n", "if", "cfg", ".", "save_val_img_path", ":", "\n", "            ", "save_path", "=", "cfg", ".", "save_val_img_path", "+", "cfg", ".", "model_name", "\n", "os", ".", "makedirs", "(", "save_path", ")", "\n", "", "evaluation", "=", "Evaluate", "(", "validation_generator", ",", "distance", "=", "cfg", ".", "distance_detection", ",", "tensorboard", "=", "tensorboard_callback", ",", "\n", "weighted_average", "=", "cfg", ".", "weighted_map", ",", "render", "=", "False", ",", "save_path", "=", "save_path", ",", "workers", "=", "cfg", ".", "workers", ")", "\n", "", "evaluation", "=", "RedirectModel", "(", "evaluation", ",", "prediction_model", ")", "\n", "callbacks", ".", "append", "(", "evaluation", ")", "\n", "\n", "# save the model", "\n", "if", "cfg", ".", "save_model", ":", "\n", "# ensure directory created first; otherwise h5py will error after epoch.", "\n", "        ", "makedirs", "(", "cfg", ".", "save_model", ")", "\n", "checkpoint", "=", "keras", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "\n", "cfg", ".", "save_model", ",", "\n", "'{model_name}.h5'", ".", "format", "(", "model_name", "=", "cfg", ".", "model_name", ")", "\n", ")", ",", "\n", "verbose", "=", "1", ",", "\n", "save_best_only", "=", "True", ",", "\n", "monitor", "=", "\"mAP\"", ",", "\n", "mode", "=", "'max'", "\n", ")", "\n", "checkpoint", "=", "RedirectModel", "(", "checkpoint", ",", "model", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "\n", "", "callbacks", ".", "append", "(", "keras", ".", "callbacks", ".", "ReduceLROnPlateau", "(", "\n", "monitor", "=", "'loss'", ",", "\n", "factor", "=", "0.75", ",", "\n", "patience", "=", "2", ",", "\n", "verbose", "=", "1", ",", "\n", "mode", "=", "'auto'", ",", "\n", "min_delta", "=", "0.0001", ",", "\n", "cooldown", "=", "0", ",", "\n", "min_lr", "=", "1e-6", "\n", ")", ")", "\n", "\n", "return", "callbacks", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.main": [[258, 419], ["os.path.dirname", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "initialize_seed", "crfnet.model.architectures.backbone", "crfnet.utils.keras_version.check_keras_version", "keras.backend.tensorflow_backend.set_session", "keras.backend.tensorflow_backend.set_session", "print", "print", "train_crfnet.create_callbacks", "print", "print", "print", "print", "crfnet.utils.config.get_config.get_description", "os.linesep.join", "print", "print", "print", "print", "print", "training_model.fit_generator", "print", "print", "print", "keras.models.load_model", "keras.models.load_model", "crfnet.model.architectures.retinanet.retinanet_bbox", "evaluate_test_set", "print", "print", "print", "evaluate_test_set", "print", "print", "print", "evaluate_test_set", "print", "print", "print", "os.path.abspath", "os.path.exists", "FileNotFoundError", "crfnet.utils.config.get_config", "parser.parse_args.config.split", "model_name.split", "crfnet.utils.helpers.get_session", "crfnet.data_processing.generator.crf_main_generator.create_generators", "crfnet.data_processing.generator.crf_main_generator.create_generators", "print", "crfnet.model.architectures.load_model", "crfnet.model.architectures.retinanet.retinanet_bbox", "print", "train_crfnet.create_models", "architectures.load_model.summary", "architectures.load_model.count_params", "crfnet.utils.anchor.make_shapes_callback", "class_weights_names.keys", "os.path.join", "architectures.backbone.download_imagenet", "len", "float", "len", "len", "train_generator.num_classes", "os.linesep.join.splitlines", "s.strip", "train_generator.name_to_label"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.initialize_seed", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.backbone", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.check_keras_version", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.create_callbacks", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.load_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.load_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.retinanet_bbox", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval_test.evaluate_test_set", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval_test.evaluate_test_set", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval_test.evaluate_test_set", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.get_config", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.get_session", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.crf_main_generator.create_generators", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.crf_main_generator.create_generators", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.load_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.retinanet_bbox", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.train_crfnet.create_models", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.make_shapes_callback", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.download_imagenet", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.name_to_label"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "FILE_DIRECTORY", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "\n", "# Parse arguments", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "type", "=", "str", ",", "default", "=", "os", ".", "path", ".", "join", "(", "FILE_DIRECTORY", ",", "\"configs/local.cfg\"", ")", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "config", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"ERROR: Config file \\\"%s\\\" not found\"", "%", "(", "args", ".", "config", ")", ")", "\n", "", "else", ":", "\n", "        ", "cfg", "=", "get_config", "(", "args", ".", "config", ")", "\n", "\n", "", "model_name", "=", "args", ".", "config", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "model_name", "=", "model_name", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "cfg", ".", "model_name", "=", "cfg", ".", "runtime", "+", "\"_\"", "+", "model_name", "\n", "\n", "assert", "cfg", ".", "inference", "is", "False", ",", "\"You are running a training in inference mode. Please check your config!\"", "\n", "\n", "# setting seed", "\n", "from", ".", "utils", ".", "helpers", "import", "initialize_seed", "\n", "# Set seed to compare trainings and exclude randomness", "\n", "initialize_seed", "(", "cfg", ".", "seed", ")", "\n", "\n", "# create object that stores backbone information", "\n", "backbone", "=", "architectures", ".", "backbone", "(", "cfg", ".", "network", ")", "\n", "\n", "# make sure keras is the minimum required version", "\n", "check_keras_version", "(", ")", "\n", "\n", "# optionally choose specific GPU", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "cfg", ".", "gpu", "\n", "\n", "keras", ".", "backend", ".", "tensorflow_backend", ".", "set_session", "(", "get_session", "(", "cfg", ".", "gpu_mem_usage", ")", ")", "\n", "\n", "# create the generators", "\n", "if", "'nuscenes'", "in", "cfg", ".", "data_set", ":", "\n", "        ", "train_generator", ",", "validation_generator", ",", "test_generator", ",", "test_night_generator", ",", "test_rain_generator", "=", "create_generators", "(", "cfg", ",", "backbone", ")", "\n", "", "else", ":", "\n", "        ", "train_generator", ",", "validation_generator", "=", "create_generators", "(", "cfg", ",", "backbone", ")", "\n", "\n", "\n", "# create the model", "\n", "", "weights", "=", "None", "\n", "if", "cfg", ".", "load_model", ":", "\n", "        ", "print", "(", "'Loading model, this may take a second...'", ")", "\n", "model", "=", "architectures", ".", "load_model", "(", "cfg", ".", "load_model", ",", "backbone_name", "=", "cfg", ".", "network", ")", "\n", "\n", "training_model", "=", "model", "\n", "prediction_model", "=", "retinanet_bbox", "(", "model", "=", "model", ",", "anchor_params", "=", "None", ",", "class_specific_filter", "=", "cfg", ".", "class_specific_nms", ")", "\n", "", "else", ":", "\n", "        ", "if", "cfg", ".", "pretrain_basenet", ":", "\n", "            ", "weights", "=", "backbone", ".", "download_imagenet", "(", ")", "\n", "\n", "", "in_shape", "=", "(", "cfg", ".", "image_size", "[", "0", "]", ",", "cfg", ".", "image_size", "[", "1", "]", ",", "len", "(", "train_generator", ".", "channels", ")", ")", "\n", "\n", "print", "(", "'Creating model, this may take a second...'", ")", "\n", "model", ",", "training_model", ",", "prediction_model", "=", "create_models", "(", "\n", "backbone_retinanet", "=", "backbone", ".", "retinanet", ",", "\n", "num_classes", "=", "train_generator", ".", "num_classes", "(", ")", ",", "\n", "weights", "=", "weights", ",", "\n", "multi_gpu", "=", "0", ",", "\n", "freeze_backbone", "=", "False", ",", "\n", "lr", "=", "cfg", ".", "learning_rate", ",", "\n", "inputs", "=", "in_shape", ",", "\n", "cfg", "=", "cfg", ",", "\n", "distance", "=", "cfg", ".", "distance_detection", ",", "\n", "distance_alpha", "=", "cfg", ".", "distance_alpha", "\n", ")", "\n", "\n", "# print model summary", "\n", "", "print", "(", "model", ".", "summary", "(", ")", ")", "\n", "print", "(", "\"Model Parameters: \"", ",", "model", ".", "count_params", "(", ")", ")", "\n", "\n", "\n", "# this lets the generator compute backbone layer shapes using the actual backbone model", "\n", "if", "'vgg'", "in", "cfg", ".", "network", "or", "'densenet'", "in", "cfg", ".", "network", ":", "\n", "        ", "train_generator", ".", "compute_shapes", "=", "make_shapes_callback", "(", "model", ")", "\n", "if", "validation_generator", ":", "\n", "            ", "validation_generator", ".", "compute_shapes", "=", "train_generator", ".", "compute_shapes", "\n", "\n", "# create the callbacks", "\n", "", "", "callbacks", "=", "create_callbacks", "(", "\n", "model", ",", "\n", "prediction_model", ",", "\n", "validation_generator", ",", "\n", "cfg", ",", "\n", ")", "\n", "\n", "# Use multiprocessing if cpu_count > 0", "\n", "use_multiprocessing", "=", "cfg", ".", "workers", ">", "0", "\n", "\n", "# class weights", "\n", "class_weights_labels", "=", "{", "}", "\n", "if", "cfg", ".", "class_weights", ":", "\n", "        ", "class_weights_names", "=", "cfg", ".", "class_weights", "\n", "\n", "for", "key", "in", "class_weights_names", ".", "keys", "(", ")", ":", "\n", "            ", "class_weights_labels", "[", "train_generator", ".", "name_to_label", "(", "key", ")", "]", "=", "float", "(", "class_weights_names", "[", "key", "]", ")", "\n", "\n", "# Print outputs", "\n", "", "", "print", "(", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "print", "(", "\"\\t\\t##### Parameters #####\"", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "descr", "=", "cfg", ".", "get_description", "(", ")", "\n", "descr", "=", "os", ".", "linesep", ".", "join", "(", "[", "s", "for", "s", "in", "descr", ".", "splitlines", "(", ")", "if", "s", ".", "strip", "(", ")", "]", ")", "\n", "print", "(", "descr", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "print", "(", "\"\\t\\t##### Start Training #####\"", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "\n", "\n", "## Start training", "\n", "training_model", ".", "fit_generator", "(", "\n", "generator", "=", "train_generator", ",", "\n", "steps_per_epoch", "=", "len", "(", "train_generator", ")", ",", "\n", "epochs", "=", "cfg", ".", "epochs", ",", "\n", "validation_data", "=", "validation_generator", ",", "\n", "validation_steps", "=", "len", "(", "validation_generator", ")", ",", "\n", "verbose", "=", "1", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "workers", "=", "cfg", ".", "workers", ",", "\n", "use_multiprocessing", "=", "use_multiprocessing", ",", "\n", "class_weight", "=", "class_weights_labels", "\n", ")", "\n", "\n", "\n", "## Evaluate on test data_set", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "print", "(", "\"\\t\\t##### Evaluate Test Set #####\"", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "\n", "# Load best model", "\n", "best_model", "=", "keras", ".", "models", ".", "load_model", "(", "cfg", ".", "save_model", "+", "cfg", ".", "model_name", "+", "'.h5'", ",", "custom_objects", "=", "backbone", ".", "custom_objects", ")", "\n", "# load anchor parameters, or pass None (so that defaults will be used)", "\n", "if", "'small'", "in", "cfg", ".", "anchor_params", ":", "\n", "        ", "anchor_params", "=", "AnchorParameters", ".", "small", "\n", "", "else", ":", "\n", "        ", "anchor_params", "=", "None", "\n", "\n", "", "best_prediction_model", "=", "retinanet_bbox", "(", "model", "=", "best_model", ",", "anchor_params", "=", "anchor_params", ",", "class_specific_filter", "=", "False", ")", "\n", "\n", "# Evaluate", "\n", "from", ".", "utils", ".", "eval_test", "import", "evaluate_test_set", "\n", "evaluate_test_set", "(", "best_prediction_model", ",", "test_generator", ",", "cfg", ",", "mode", "=", "'all'", ",", "tensorboard", "=", "callbacks", "[", "1", "]", ",", "verbose", "=", "1", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "print", "(", "\"\\t##### Evaluate Test Set at Night #####\"", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "evaluate_test_set", "(", "best_prediction_model", ",", "test_night_generator", ",", "cfg", ",", "mode", "=", "'night'", ",", "tensorboard", "=", "callbacks", "[", "1", "]", ",", "verbose", "=", "1", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "print", "(", "\"\\t##### Evaluate Test Set at Rain #####\"", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "evaluate_test_set", "(", "best_prediction_model", ",", "test_rain_generator", ",", "cfg", ",", "mode", "=", "'rain'", ",", "tensorboard", "=", "callbacks", "[", "1", "]", ",", "verbose", "=", "1", ")", "\n", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "print", "(", "\"\\t######## Finished successfully ########\"", ")", "\n", "print", "(", "\"=\"", "*", "60", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.__init__": [[11, 16], ["SetupToolsBuildExt"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "from", "setuptools", ".", "command", ".", "build_ext", "import", "build_ext", "as", "SetupToolsBuildExt", "\n", "\n", "# Bypass __setatrr__ to avoid infinite recursion.", "\n", "self", ".", "__dict__", "[", "'_command'", "]", "=", "SetupToolsBuildExt", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.__getattr__": [[17, 19], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "_command", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.__setattr__": [[20, 22], ["setattr"], "methods", ["None"], ["", "def", "__setattr__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "setattr", "(", "self", ".", "_command", ",", "name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.initialize_options": [[23, 25], ["setup.BuildExtension._command.initialize_options"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.initialize_options"], ["", "def", "initialize_options", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_command", ".", "initialize_options", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.finalize_options": [[26, 31], ["setup.BuildExtension._command.finalize_options", "setup.BuildExtension.include_dirs.append", "numpy.get_include"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.finalize_options"], ["", "def", "finalize_options", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "ret", "=", "self", ".", "_command", ".", "finalize_options", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "import", "numpy", "\n", "self", ".", "include_dirs", ".", "append", "(", "numpy", ".", "get_include", "(", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.run": [[32, 34], ["setup.BuildExtension._command.run"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.setup.BuildExtension.run"], ["", "def", "run", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_command", ".", "run", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.crfnet.test_crfnet.visualize_predictions": [[55, 98], ["range", "generator.label_to_name", "cv2.rectangle", "cv2.getTextSize", "cv2.rectangle", "cv2.putText", "pprint.pprint", "all_dets.append", "all_dets.append", "int", "int", "int", "generator.label_to_name.split", "generator.label_to_name.split"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name"], ["def", "visualize_predictions", "(", "predictions", ",", "image_data_vis", ",", "generator", ",", "dist", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Visualizes the predictions as bounding boxes with distances or confidence score in a given image.\n\n    :param predictions:         <list>              List with [bboxes, probs, labels]\n    :param image_data_vis:      <np.array>          Image where the predictions should be visualized\n    :param generator:           <Generator>         Data generator used for name to label mapping\n    :dist:                      <bool>              True if distance detection is enabled\n    :verbose:                   <bool>              True if detetions should be printed \n\n    \"\"\"", "\n", "\n", "font", "=", "cv2", ".", "FONT_HERSHEY_SIMPLEX", "\n", "fontScale", "=", "0.4", "\n", "\n", "# Visualization prediction", "\n", "all_dets", "=", "[", "]", "\n", "[", "bboxes", ",", "probs", ",", "labels", "]", "=", "predictions", "\n", "\n", "\n", "\n", "for", "jk", "in", "range", "(", "bboxes", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", "=", "bboxes", "[", "0", ",", "jk", ",", ":", "]", "\n", "\n", "key", "=", "generator", ".", "label_to_name", "(", "labels", "[", "0", ",", "jk", "]", ")", "\n", "color", "=", "class_to_color", "[", "key", "]", "*", "255", "\n", "cv2", ".", "rectangle", "(", "image_data_vis", ",", "(", "x1", ",", "y1", ")", ",", "(", "x2", ",", "y2", ")", ",", "color", ",", "2", ")", "\n", "\n", "if", "dist", "is", "not", "False", ":", "\n", "            ", "textLabel", "=", "'{0}: {1:3.1f} {2}'", ".", "format", "(", "key", ".", "split", "(", "'.'", ",", "1", ")", "[", "-", "1", "]", ",", "dist", "[", "0", ",", "jk", "]", ",", "'m'", ")", "\n", "all_dets", ".", "append", "(", "(", "key", ",", "100", "*", "probs", "[", "0", ",", "jk", "]", ",", "dist", "[", "0", ",", "jk", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "textLabel", "=", "'{}: {}'", ".", "format", "(", "key", ".", "split", "(", "'.'", ",", "1", ")", "[", "-", "1", "]", ",", "int", "(", "100", "*", "probs", "[", "0", ",", "jk", "]", ")", ")", "\n", "all_dets", ".", "append", "(", "(", "key", ",", "100", "*", "probs", "[", "0", ",", "jk", "]", ")", ")", "\n", "\n", "", "(", "retval", ",", "baseLine", ")", "=", "cv2", ".", "getTextSize", "(", "textLabel", ",", "font", ",", "fontScale", ",", "1", ")", "\n", "\n", "textOrg", "=", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "image_data_vis", ",", "(", "textOrg", "[", "0", "]", "-", "1", ",", "textOrg", "[", "1", "]", "+", "baseLine", "-", "1", ")", ",", "(", "textOrg", "[", "0", "]", "+", "retval", "[", "0", "]", "+", "1", ",", "textOrg", "[", "1", "]", "-", "retval", "[", "1", "]", "-", "1", ")", ",", "color", ",", "-", "1", ")", "\n", "cv2", ".", "putText", "(", "image_data_vis", ",", "textLabel", ",", "textOrg", ",", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "fontScale", ",", "(", "1", ",", "1", ",", "1", ")", ",", "1", ")", "\n", "\n", "", "if", "verbose", ":", "pprint", ".", "pprint", "(", "all_dets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.coco_eval.evaluate_coco": [[27, 94], ["progressbar.progressbar", "json.dump", "json.dump", "coco_true.loadRes", "pycocotools.cocoeval.COCOeval", "pycocotools.cocoeval.COCOeval.evaluate", "pycocotools.cocoeval.COCOeval.accumulate", "pycocotools.cocoeval.COCOeval.summarize", "range", "generator.load_image", "generator.preprocess_image", "generator.resize_image", "model.predict_on_batch", "zip", "image_ids.append", "len", "open", "open", "generator.size", "keras.backend.image_data_format", "image.transpose.transpose", "numpy.expand_dims", "results.append", "generator.label_to_coco_label", "float", "box.tolist"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval.evaluate", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.resize_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose"], ["def", "evaluate_coco", "(", "generator", ",", "model", ",", "threshold", "=", "0.05", ")", ":", "\n", "    ", "\"\"\" Use the pycocotools to evaluate a COCO model on a dataset.\n\n    Args\n        generator : The generator for generating the evaluation data.\n        model     : The model to evaluate.\n        threshold : The score threshold to use.\n    \"\"\"", "\n", "# start collecting results", "\n", "results", "=", "[", "]", "\n", "image_ids", "=", "[", "]", "\n", "for", "index", "in", "progressbar", ".", "progressbar", "(", "range", "(", "generator", ".", "size", "(", ")", ")", ",", "prefix", "=", "'COCO evaluation: '", ")", ":", "\n", "        ", "image", "=", "generator", ".", "load_image", "(", "index", ")", "\n", "image", "=", "generator", ".", "preprocess_image", "(", "image", ")", "\n", "image", ",", "scale", "=", "generator", ".", "resize_image", "(", "image", ")", "\n", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "image", "=", "image", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# run network", "\n", "", "boxes", ",", "scores", ",", "labels", "=", "model", ".", "predict_on_batch", "(", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# correct boxes for image scale", "\n", "boxes", "/=", "scale", "\n", "\n", "# change to (x, y, w, h) (MS COCO standard)", "\n", "boxes", "[", ":", ",", ":", ",", "2", "]", "-=", "boxes", "[", ":", ",", ":", ",", "0", "]", "\n", "boxes", "[", ":", ",", ":", ",", "3", "]", "-=", "boxes", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "# compute predicted labels and scores", "\n", "for", "box", ",", "score", ",", "label", "in", "zip", "(", "boxes", "[", "0", "]", ",", "scores", "[", "0", "]", ",", "labels", "[", "0", "]", ")", ":", "\n", "# scores are sorted, so we can break", "\n", "            ", "if", "score", "<", "threshold", ":", "\n", "                ", "break", "\n", "\n", "# append detection for each positively labeled class", "\n", "", "image_result", "=", "{", "\n", "'image_id'", ":", "generator", ".", "image_ids", "[", "index", "]", ",", "\n", "'category_id'", ":", "generator", ".", "label_to_coco_label", "(", "label", ")", ",", "\n", "'score'", ":", "float", "(", "score", ")", ",", "\n", "'bbox'", ":", "box", ".", "tolist", "(", ")", ",", "\n", "}", "\n", "\n", "# append detection to results", "\n", "results", ".", "append", "(", "image_result", ")", "\n", "\n", "# append image to list of processed images", "\n", "", "image_ids", ".", "append", "(", "generator", ".", "image_ids", "[", "index", "]", ")", "\n", "\n", "", "if", "not", "len", "(", "results", ")", ":", "\n", "        ", "return", "\n", "\n", "# write output", "\n", "", "json", ".", "dump", "(", "results", ",", "open", "(", "'{}_bbox_results.json'", ".", "format", "(", "generator", ".", "set_name", ")", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "json", ".", "dump", "(", "image_ids", ",", "open", "(", "'{}_processed_image_ids.json'", ".", "format", "(", "generator", ".", "set_name", ")", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "\n", "# load results in COCO evaluation tool", "\n", "coco_true", "=", "generator", ".", "coco", "\n", "coco_pred", "=", "coco_true", ".", "loadRes", "(", "'{}_bbox_results.json'", ".", "format", "(", "generator", ".", "set_name", ")", ")", "\n", "\n", "# run COCO evaluation", "\n", "coco_eval", "=", "COCOeval", "(", "coco_true", ",", "coco_pred", ",", "'bbox'", ")", "\n", "coco_eval", ".", "params", ".", "imgIds", "=", "image_ids", "\n", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "return", "coco_eval", ".", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.__init__": [[21, 28], ["super().__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ",", "fps", "=", "24", ",", "threaded", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "threaded", "and", "self", ".", "instance", "and", "self", ".", "instance", ".", "threaded", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cv2Thread has already been started\"", ")", "\n", "\n", "", "self", ".", "threaded", "=", "threaded", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.get_instance": [[29, 38], ["visualization_helpers.Cv2Threaded", "visualization_helpers.Cv2Threaded"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_instance", "(", "cls", ",", "threaded", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "threaded", ":", "\n", "            ", "if", "cls", ".", "instance", "is", "None", ":", "\n", "                ", "cls", ".", "instance", "=", "Cv2Threaded", "(", "threaded", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "cls", ".", "instance", "\n", "", "else", ":", "\n", "            ", "return", "Cv2Threaded", "(", "threaded", "=", "False", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.waitKey": [[39, 48], ["cls._keys_queue.get"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "waitKey", "(", "cls", ",", "duration", ")", ":", "\n", "        ", "key", "=", "-", "1", "\n", "try", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "key", "=", "cls", ".", "_keys_queue", ".", "get", "(", "block", "=", "False", ")", "# get all the keys, until no key is left", "\n", "", "", "except", "queue", ".", "Empty", ":", "\n", "            ", "pass", "\n", "", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.__rendering_loop": [[49, 68], ["set", "max", "cv2.waitKey", "cv2.destroyWindow", "cls._rendering_queue.get", "cv2.imshow", "set.add", "cls._keys_queue.put"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.waitKey", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.imshow"], ["", "@", "classmethod", "\n", "def", "__rendering_loop", "(", "cls", ")", ":", "\n", "        ", "window_names", "=", "set", "(", ")", "\n", "while", "cls", ".", "_rendering_thread", ":", "\n", "            ", "try", ":", "\n", "                ", "winname", ",", "img", "=", "cls", ".", "_rendering_queue", ".", "get", "(", "block", "=", "False", ")", "\n", "cv2", ".", "imshow", "(", "winname", ",", "img", ")", "\n", "window_names", ".", "add", "(", "winname", ")", "\n", "", "except", "queue", ".", "Empty", ":", "\n", "                ", "pass", "\n", "\n", "", "event_time", "=", "max", "(", "1000", "//", "cls", ".", "FPS", ",", "1", ")", "\n", "key", "=", "cv2", ".", "waitKey", "(", "event_time", ")", "\n", "if", "key", "!=", "-", "1", ":", "\n", "                ", "cls", ".", "_keys_queue", ".", "put", "(", "key", ")", "\n", "\n", "# finalize", "\n", "", "", "for", "winname", "in", "window_names", ":", "\n", "            ", "cv2", ".", "destroyWindow", "(", "winname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.imshow": [[69, 84], ["cls._rendering_queue.put", "cv2.imshow", "threading.Thread", "cls._rendering_thread.start"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.imshow"], ["", "", "def", "imshow", "(", "self", ",", "winname", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Same usage as cv2.imshow\n        \"\"\"", "\n", "\n", "if", "self", ".", "threaded", ":", "\n", "            ", "cls", "=", "self", ".", "__class__", "\n", "if", "cls", ".", "_rendering_thread", "is", "None", ":", "\n", "                ", "r_thread", "=", "threading", ".", "Thread", "(", "target", "=", "cls", ".", "__rendering_loop", ",", "daemon", "=", "True", ")", "\n", "cls", ".", "_rendering_thread", "=", "r_thread", "\n", "cls", ".", "_rendering_thread", ".", "start", "(", ")", "\n", "\n", "", "cls", ".", "_rendering_queue", ".", "put", "(", "(", "winname", ",", "img", ")", ")", "\n", "", "else", ":", "\n", "            ", "cv2", ".", "imshow", "(", "winname", ",", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.__del__": [[85, 87], ["None"], "methods", ["None"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "__class__", ".", "_rendering_thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.coco.CocoEval.__init__": [[24, 37], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tensorboard", "=", "None", ",", "threshold", "=", "0.05", ")", ":", "\n", "        ", "\"\"\" CocoEval callback intializer.\n\n        Args\n            generator   : The generator used for creating validation data.\n            tensorboard : If given, the results will be written to tensorboard.\n            threshold   : The score threshold to use.\n        \"\"\"", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "tensorboard", "=", "tensorboard", "\n", "\n", "super", "(", "CocoEval", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.coco.CocoEval.on_epoch_end": [[38, 63], ["utils.coco_eval.evaluate_coco", "tf.Summary", "enumerate", "tf.Summary.value.add", "coco.CocoEval.tensorboard.writer.add_summary"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.coco_eval.evaluate_coco"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "logs", "=", "logs", "or", "{", "}", "\n", "\n", "coco_tag", "=", "[", "'AP @[ IoU=0.50:0.95 | area=   all | maxDets=100 ]'", ",", "\n", "'AP @[ IoU=0.50      | area=   all | maxDets=100 ]'", ",", "\n", "'AP @[ IoU=0.75      | area=   all | maxDets=100 ]'", ",", "\n", "'AP @[ IoU=0.50:0.95 | area= small | maxDets=100 ]'", ",", "\n", "'AP @[ IoU=0.50:0.95 | area=medium | maxDets=100 ]'", ",", "\n", "'AP @[ IoU=0.50:0.95 | area= large | maxDets=100 ]'", ",", "\n", "'AR @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ]'", ",", "\n", "'AR @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ]'", ",", "\n", "'AR @[ IoU=0.50:0.95 | area=   all | maxDets=100 ]'", ",", "\n", "'AR @[ IoU=0.50:0.95 | area= small | maxDets=100 ]'", ",", "\n", "'AR @[ IoU=0.50:0.95 | area=medium | maxDets=100 ]'", ",", "\n", "'AR @[ IoU=0.50:0.95 | area= large | maxDets=100 ]'", "]", "\n", "coco_eval_stats", "=", "evaluate_coco", "(", "self", ".", "generator", ",", "self", ".", "model", ",", "self", ".", "threshold", ")", "\n", "if", "coco_eval_stats", "is", "not", "None", "and", "self", ".", "tensorboard", "is", "not", "None", "and", "self", ".", "tensorboard", ".", "writer", "is", "not", "None", ":", "\n", "            ", "import", "tensorflow", "as", "tf", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "for", "index", ",", "result", "in", "enumerate", "(", "coco_eval_stats", ")", ":", "\n", "                ", "summary_value", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_value", ".", "simple_value", "=", "result", "\n", "summary_value", ".", "tag", "=", "'{}. {}'", ".", "format", "(", "index", "+", "1", ",", "coco_tag", "[", "index", "]", ")", "\n", "self", ".", "tensorboard", ".", "writer", ".", "add_summary", "(", "summary", ",", "epoch", ")", "\n", "logs", "[", "coco_tag", "[", "index", "]", "]", "=", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.nuscenes_helper.get_nusc_split_samples": [[22, 58], ["len", "int", "print", "range", "range", "min", "int", "int", "range", "len", "list", "list", "int", "int", "int", "int", "range", "range", "int", "int", "range", "range", "list", "list", "list", "range", "range", "list", "list", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["def", "get_nusc_split_samples", "(", "nusc", ",", "val_indices", ",", "validation_ratio", "=", "0.2", ",", "sample_limit", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    :param val_indices: first, mixed or mixed2. Determines the split mode\n    :returns: training indices, validation indices\n    \"\"\"", "\n", "\n", "samples_count", "=", "len", "(", "nusc", ".", "sample", ")", "\n", "split_index", "=", "int", "(", "(", "1", "-", "validation_ratio", ")", "*", "samples_count", ")", "\n", "\n", "if", "val_indices", "==", "'first'", ":", "\n", "        ", "print", "(", "\"Taking the first {} samples for validation\"", ".", "format", "(", "samples_count", "-", "split_index", ")", ")", "\n", "sample_indices_train", "=", "range", "(", "samples_count", "-", "split_index", ",", "samples_count", ")", "\n", "sample_indices_val", "=", "range", "(", "0", ",", "samples_count", "-", "split_index", ")", "\n", "", "elif", "val_indices", "==", "'mixed'", ":", "\n", "        ", "split_1", "=", "int", "(", "validation_ratio", "/", "2", "*", "samples_count", ")", "\n", "split_2", "=", "int", "(", "(", "1", "-", "(", "validation_ratio", "/", "2", ")", ")", "*", "samples_count", ")", "\n", "sample_indices_train", "=", "range", "(", "split_1", ",", "split_2", ")", "\n", "sample_indices_val", "=", "list", "(", "range", "(", "0", ",", "split_1", ")", ")", "+", "list", "(", "range", "(", "split_2", ",", "samples_count", ")", ")", "\n", "", "elif", "val_indices", "==", "'mixed2'", ":", "\n", "        ", "split_1", "=", "int", "(", "validation_ratio", "*", "0.4", "*", "samples_count", ")", "\n", "split_2", "=", "int", "(", "(", "1", "-", "validation_ratio", "*", "0.25", ")", "*", "samples_count", ")", "\n", "split_3", "=", "int", "(", "0.55", "*", "samples_count", ")", "\n", "split_4", "=", "int", "(", "0.55", "*", "samples_count", "+", "0.35", "*", "validation_ratio", "*", "samples_count", ")", "\n", "sample_indices_train", "=", "list", "(", "range", "(", "split_1", ",", "split_3", ")", ")", "+", "list", "(", "range", "(", "split_4", ",", "split_2", ")", ")", "\n", "sample_indices_val", "=", "list", "(", "range", "(", "0", ",", "split_1", ")", ")", "+", "list", "(", "range", "(", "split_2", ",", "samples_count", ")", ")", "+", "list", "(", "range", "(", "split_3", ",", "split_4", ")", ")", "\n", "", "else", ":", "\n", "        ", "sample_indices_train", "=", "range", "(", "0", ",", "split_index", ")", "\n", "sample_indices_val", "=", "range", "(", "split_index", ",", "samples_count", ")", "\n", "\n", "# limit samples", "\n", "", "if", "sample_limit", ":", "\n", "        ", "limit", "=", "min", "(", "sample_limit", ",", "len", "(", "sample_indices_train", ")", ")", "\n", "sample_indices_train", "=", "sample_indices_train", "[", "0", ":", "int", "(", "limit", "*", "(", "1", "-", "validation_ratio", ")", ")", "]", "\n", "sample_indices_val", "=", "sample_indices_val", "[", "0", ":", "int", "(", "limit", "*", "validation_ratio", ")", "]", "\n", "\n", "", "return", "sample_indices_train", ",", "sample_indices_val", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.nuscenes_helper.get_sensor_sample_data": [[61, 139], ["nusc.get", "os.join", "os.exists", "FileNotFoundError", "nuscenes.utils.data_classes.RadarPointCloud.from_file", "RadarPointCloud.from_file.points.astype", "radar.enrich_radar_data", "PIL.Image.open", "numpy.array", "numpy.issubdtype", "Exception", "iter", "i.resize.resize", "i.resize.thumbnail"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.enrich_radar_data"], ["", "def", "get_sensor_sample_data", "(", "nusc", ",", "sample", ",", "sensor_channel", ",", "dtype", "=", "np", ".", "float32", ",", "size", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function takes the token of a sample and a sensor sensor_channel and returns the according data\n    :param sample: the nuscenes sample dict\n    :param sensor_channel: the target sensor channel of the given sample to load the data from\n    :param dtype: the target numpy type\n    :param size: for resizing the image\n\n    Radar Format:\n        - Shape: 19 x n\n        - Semantics: \n            [0]: x (1)\n            [1]: y (2)\n            [2]: z (3)\n            [3]: dyn_prop (4)\n            [4]: id (5)\n            [5]: rcs (6)\n            [6]: vx (7)\n            [7]: vy (8)\n            [8]: vx_comp (9)\n            [9]: vy_comp (10)\n            [10]: is_quality_valid (11)\n            [11]: ambig_state (12)\n            [12]: x_rms (13)\n            [13]: y_rms (14)\n            [14]: invalid_state (15)\n            [15]: pdh0 (16)\n            [16]: vx_rms (17)\n            [17]: vy_rms (18)\n            [18]: distance (19)\n\n    Image Format:\n        - Shape: h x w x 3\n        - Channels: RGB\n        - size:\n            - [int] size to limit image size\n            - [tuple[int]] size to limit image size\n    \"\"\"", "\n", "\n", "# Get filepath", "\n", "sd_rec", "=", "nusc", ".", "get", "(", "'sample_data'", ",", "sample", "[", "'data'", "]", "[", "sensor_channel", "]", ")", "\n", "file_name", "=", "osp", ".", "join", "(", "nusc", ".", "dataroot", ",", "sd_rec", "[", "'filename'", "]", ")", "\n", "\n", "# Check conditions", "\n", "if", "not", "osp", ".", "exists", "(", "file_name", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\n", "\"nuscenes data must be located in %s\"", "%", "file_name", ")", "\n", "\n", "# Read the data", "\n", "", "if", "\"RADAR\"", "in", "sensor_channel", ":", "\n", "        ", "pc", "=", "RadarPointCloud", ".", "from_file", "(", "file_name", ")", "# Load radar points", "\n", "data", "=", "pc", ".", "points", ".", "astype", "(", "dtype", ")", "\n", "data", "=", "radar", ".", "enrich_radar_data", "(", "data", ")", "# enrich the radar data an bring them into proper format", "\n", "", "elif", "\"CAM\"", "in", "sensor_channel", ":", "\n", "        ", "i", "=", "Image", ".", "open", "(", "file_name", ")", "\n", "\n", "# resize if size is given", "\n", "if", "size", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "_", "=", "iter", "(", "size", ")", "\n", "", "except", "TypeError", ":", "\n", "# not iterable", "\n", "# limit both dimension to size, but keep aspect ration", "\n", "                ", "size", "=", "(", "size", ",", "size", ")", "\n", "i", ".", "thumbnail", "(", "size", "=", "size", ")", "\n", "", "else", ":", "\n", "                ", "size", "=", "size", "[", ":", ":", "-", "1", "]", "# revert dimensions", "\n", "i", "=", "i", ".", "resize", "(", "size", "=", "size", ")", "\n", "\n", "", "", "data", "=", "np", ".", "array", "(", "i", ",", "dtype", "=", "dtype", ")", "\n", "\n", "if", "np", ".", "issubdtype", "(", "dtype", ",", "np", ".", "floating", ")", ":", "\n", "            ", "data", "=", "data", "/", "255", "# floating images usually are on [0,1] interval", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"\\\"%s\\\" is not supported\"", "%", "sensor_channel", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.nuscenes_helper.calc_mask": [[141, 179], ["nusc.get_boxes", "nusc.get", "nusc.get", "numpy.zeros", "numpy.clip", "box.translate", "box.rotate", "box.translate", "box.rotate", "numpy.logical_or", "nuscenes.utils.geometry_utils.points_in_box2", "nuscenes.utils.geometry_utils.points_in_box", "numpy.array", "pyquaternion.Quaternion", "numpy.array", "pyquaternion.Quaternion"], "function", ["None"], ["", "def", "calc_mask", "(", "nusc", ",", "nusc_sample_data", ",", "points3d", ",", "category_selection", ",", "tolerance", "=", "0.0", ",", "angle_tolerance", "=", "0.0", ",", "use_points_in_box2", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param points3d: <np array of channels x samples]>\n    :param category_selection: list of categories, which will be masked\n    :param tolerance: cartesian tolerance in meters\n    :param angle_tolerances: angular tolerance in rad\n    \"\"\"", "\n", "\n", "# Create Boxes:", "\n", "# _, boxes, camera_intrinsic = nusc.get_sample_data(nusc_sample_data['token'], box_vis_level=nuscenes.utils.geometry_utils.BoxVisibility.ANY)", "\n", "boxes", "=", "nusc", ".", "get_boxes", "(", "nusc_sample_data", "[", "'token'", "]", ")", "\n", "cs_record", "=", "nusc", ".", "get", "(", "'calibrated_sensor'", ",", "nusc_sample_data", "[", "'calibrated_sensor_token'", "]", ")", "\n", "pose_record", "=", "nusc", ".", "get", "(", "'ego_pose'", ",", "nusc_sample_data", "[", "'ego_pose_token'", "]", ")", "\n", "\n", "\n", "mask", "=", "np", ".", "zeros", "(", "points3d", ".", "shape", "[", "-", "1", "]", ")", "\n", "for", "box", "in", "boxes", ":", "\n", "        ", "if", "category_selection", "is", "None", "or", "box", ".", "name", "in", "category_selection", ":", "\n", "\n", "##### Transform with respect to current sensor #####", "\n", "# Move box to ego vehicle coord system", "\n", "            ", "box", ".", "translate", "(", "-", "np", ".", "array", "(", "pose_record", "[", "'translation'", "]", ")", ")", "\n", "box", ".", "rotate", "(", "Quaternion", "(", "pose_record", "[", "'rotation'", "]", ")", ".", "inverse", ")", "\n", "\n", "#  Move box to sensor coord system", "\n", "box", ".", "translate", "(", "-", "np", ".", "array", "(", "cs_record", "[", "'translation'", "]", ")", ")", "\n", "box", ".", "rotate", "(", "Quaternion", "(", "cs_record", "[", "'rotation'", "]", ")", ".", "inverse", ")", "\n", "\n", "##### Check if points are inside box #####", "\n", "if", "use_points_in_box2", ":", "\n", "                ", "cur_mask", "=", "nuscenes", ".", "utils", ".", "geometry_utils", ".", "points_in_box2", "(", "box", ",", "points3d", ",", "wlh_tolerance", "=", "tolerance", ",", "angle_tolerance", "=", "angle_tolerance", ")", "\n", "", "else", ":", "\n", "                ", "cur_mask", "=", "nuscenes", ".", "utils", ".", "geometry_utils", ".", "points_in_box", "(", "box", ",", "points3d", ")", "\n", "", "mask", "=", "np", ".", "logical_or", "(", "mask", ",", "cur_mask", ")", "\n", "\n", "", "", "mask", "=", "np", ".", "clip", "(", "mask", ",", "a_min", "=", "0", ",", "a_max", "=", "1", ")", "\n", "\n", "return", "mask", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.config.read_config_file": [[35, 40], ["configparser.ConfigParser", "configparser.ConfigParser.read"], "function", ["None"], ["def", "read_config_file", "(", "config_path", ")", ":", "\n", "    ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "config_path", ")", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.config.parse_anchor_parameters": [[42, 49], ["numpy.array", "numpy.array", "list", "list", "utils.anchor_parameters.AnchorParameters", "list", "keras.backend.floatx", "list", "keras.backend.floatx", "map", "map", "map", "map", "[].split", "[].split", "[].split", "[].split"], "function", ["None"], ["", "def", "parse_anchor_parameters", "(", "config", ")", ":", "\n", "    ", "ratios", "=", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "config", "[", "'anchor_parameters'", "]", "[", "'ratios'", "]", ".", "split", "(", "' '", ")", ")", ")", ",", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "scales", "=", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "config", "[", "'anchor_parameters'", "]", "[", "'scales'", "]", ".", "split", "(", "' '", ")", ")", ")", ",", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "sizes", "=", "list", "(", "map", "(", "int", ",", "config", "[", "'anchor_parameters'", "]", "[", "'sizes'", "]", ".", "split", "(", "' '", ")", ")", ")", "\n", "strides", "=", "list", "(", "map", "(", "int", ",", "config", "[", "'anchor_parameters'", "]", "[", "'strides'", "]", ".", "split", "(", "' '", ")", ")", ")", "\n", "\n", "return", "AnchorParameters", "(", "sizes", ",", "strides", ",", "ratios", ",", "scales", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.config.get_config": [[51, 246], ["configparser.ConfigParser", "configparser.ConfigParser.read", "str().strip", "str().strip", "Configuation", "str", "str", "datetime.datetime.now().strftime", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getint", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getint", "configparser.ConfigParser.getint", "ast.literal_eval", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getint", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getboolean", "enumerate", "subprocess.check_output", "subprocess.check_output().strip", "configparser.ConfigParser.get", "configparser.ConfigParser.getint", "configparser.ConfigParser.getint", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getboolean", "ast.literal_eval", "ast.literal_eval", "ast.literal_eval", "configparser.ConfigParser.getint", "configparser.ConfigParser.getint", "configparser.ConfigParser.getfloat", "ast.literal_eval", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "dict", "dict", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getint", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getboolean", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "configparser.ConfigParser.getfloat", "ast.literal_eval", "configparser.ConfigParser.getint", "getattr", "datetime.datetime.now", "configparser.ConfigParser.getint", "configparser.ConfigParser.get", "configparser.ConfigParser.get", "configparser.ConfigParser.get", "configparser.ConfigParser.get", "configparser.ConfigParser.get", "dir", "subprocess.check_output", "pprint.pformat", "a.startswith", "callable", "getattr"], "function", ["None"], ["", "def", "get_config", "(", "config_file", ")", ":", "\n", "    ", "import", "configparser", "\n", "import", "ast", "\n", "\n", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "config_file", ")", "\n", "\n", "commit", "=", "str", "(", "subprocess", ".", "check_output", "(", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"HEAD\"", "]", ")", ",", "'utf-8'", ")", ".", "strip", "(", ")", "\n", "branch", "=", "str", "(", "subprocess", ".", "check_output", "(", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--abbrev-ref\"", ",", "\"HEAD\"", "]", ")", ".", "strip", "(", ")", ",", "'utf-8'", ")", ".", "strip", "(", ")", "\n", "\n", "class", "Configuation", "(", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "self", ".", "runtime", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d-%H-%M-%S'", ")", "\n", "self", ".", "git_commit", "=", "commit", "\n", "self", ".", "git_branch", "=", "branch", "\n", "self", ".", "save_model", "=", "config", "[", "'PATH'", "]", "[", "'save_model'", "]", "\n", "self", ".", "load_model", "=", "config", "[", "'PATH'", "]", "[", "'load_model'", "]", "\n", "self", ".", "tensorboard", "=", "config", ".", "getboolean", "(", "'TENSORBOARD'", ",", "'tensorboard'", ")", "\n", "self", ".", "tb_logdir", "=", "config", "[", "'TENSORBOARD'", "]", "[", "'logdir'", "]", "\n", "self", ".", "histogram", "=", "config", ".", "getboolean", "(", "'TENSORBOARD'", ",", "'histogram'", ")", "\n", "self", ".", "gpu", "=", "config", "[", "'COMPUTING'", "]", "[", "'gpu'", "]", "\n", "self", ".", "workers", "=", "config", ".", "getint", "(", "'COMPUTING'", ",", "'workers'", ")", "\n", "self", ".", "learning_rate", "=", "config", ".", "getfloat", "(", "'HYPERPARAMETERS'", ",", "'learning_rate'", ")", "\n", "self", ".", "batchsize", "=", "config", ".", "getint", "(", "'HYPERPARAMETERS'", ",", "'batchsize'", ")", "\n", "self", ".", "epochs", "=", "config", ".", "getint", "(", "'HYPERPARAMETERS'", ",", "'epochs'", ")", "\n", "self", ".", "channels", "=", "ast", ".", "literal_eval", "(", "config", ".", "get", "(", "'CRF-Net'", ",", "'channels'", ")", ")", "\n", "self", ".", "image_size", "=", "(", "config", ".", "getint", "(", "'CRF-Net'", ",", "'image_height'", ")", ",", "config", ".", "getint", "(", "'CRF-Net'", ",", "'image_width'", ")", ")", "\n", "self", ".", "dropout_radar", "=", "config", ".", "getfloat", "(", "'CRF-Net'", ",", "'dropout_radar'", ")", "\n", "self", ".", "dropout_image", "=", "config", ".", "getfloat", "(", "'CRF-Net'", ",", "'dropout_image'", ")", "\n", "self", ".", "network", "=", "config", "[", "'CRF-Net'", "]", "[", "'network'", "]", "\n", "self", ".", "pretrain_basenet", "=", "config", ".", "getboolean", "(", "'CRF-Net'", ",", "'pretrain_basenet'", ")", "\n", "self", ".", "distance_detection", "=", "config", ".", "getboolean", "(", "'CRF-Net'", ",", "'distance_detection'", ")", "\n", "try", ":", "\n", "                ", "self", ".", "inference", "=", "config", ".", "getboolean", "(", "'CRF-Net'", ",", "'inference'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "inference", "=", "False", "\n", "", "try", ":", "\n", "                ", "self", ".", "gpu_mem_usage", "=", "config", ".", "getfloat", "(", "'COMPUTING'", ",", "'gpu_mem_usage'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "gpu_mem_usage", "=", "None", "\n", "", "self", ".", "data_set", "=", "config", "[", "'DATA'", "]", "[", "'data_set'", "]", "\n", "self", ".", "data_path", "=", "config", "[", "'DATA'", "]", "[", "'data_path'", "]", "\n", "self", ".", "n_sweeps", "=", "config", ".", "getint", "(", "'DATA'", ",", "'n_sweeps'", ")", "\n", "self", ".", "weighted_map", "=", "config", ".", "getboolean", "(", "'HYPERPARAMETERS'", ",", "'weighted_map'", ")", "\n", "try", ":", "\n", "                ", "self", ".", "normalize_radar", "=", "config", ".", "getboolean", "(", "'PREPROCESSING'", ",", "'normalize_radar'", ")", "\n", "", "except", "ValueError", ":", "\n", "# we also allow integer", "\n", "                ", "self", ".", "normalize_radar", "=", "config", ".", "getint", "(", "'PREPROCESSING'", ",", "'normalize_radar'", ")", "\n", "\n", "", "self", ".", "random_transform", "=", "config", ".", "getboolean", "(", "'PREPROCESSING'", ",", "'random_transform'", ")", "\n", "self", ".", "model_name", "=", "None", "\n", "\n", "try", ":", "\n", "                ", "self", ".", "anchor_box_scales", "=", "ast", ".", "literal_eval", "(", "config", ".", "get", "(", "'FRCNN'", ",", "'anchor_box_scales'", ")", ")", "\n", "self", ".", "anchor_box_ratios", "=", "ast", ".", "literal_eval", "(", "config", ".", "get", "(", "'FRCNN'", ",", "'anchor_box_ratios'", ")", ")", "\n", "self", ".", "anchors", "=", "ast", ".", "literal_eval", "(", "config", ".", "get", "(", "'FRCNN'", ",", "'anchors'", ")", ")", "\n", "self", ".", "num_rois", "=", "config", ".", "getint", "(", "'FRCNN'", ",", "'num_rois'", ")", "\n", "self", ".", "rpn_stride", "=", "config", ".", "getint", "(", "'FRCNN'", ",", "'rpn_stride'", ")", "\n", "self", ".", "std_scaling", "=", "config", ".", "getfloat", "(", "'FRCNN'", ",", "'std_scaling'", ")", "\n", "self", ".", "classifier_regr_std", "=", "ast", ".", "literal_eval", "(", "config", ".", "get", "(", "'FRCNN'", ",", "'classifier_regr_std'", ")", ")", "\n", "self", ".", "rpn_min_overlap", "=", "config", ".", "getfloat", "(", "'FRCNN'", ",", "'rpn_min_overlap'", ")", "\n", "self", ".", "rpn_max_overlap", "=", "config", ".", "getfloat", "(", "'FRCNN'", ",", "'rpn_max_overlap'", ")", "\n", "self", ".", "classifier_min_overlap", "=", "config", ".", "getfloat", "(", "'FRCNN'", ",", "'classifier_min_overlap'", ")", "\n", "self", ".", "classifier_max_overlap", "=", "config", ".", "getfloat", "(", "'FRCNN'", ",", "'classifier_max_overlap'", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "try", ":", "\n", "                ", "self", ".", "radar_filter_dist", "=", "config", ".", "getfloat", "(", "'DATA'", ",", "'radar_filter_dist'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "radar_filter_dist", "=", "None", "\n", "\n", "\n", "", "try", ":", "\n", "                ", "self", ".", "decay", "=", "config", ".", "getfloat", "(", "'HYPERPARAMETERS'", ",", "'decay'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "decay", "=", "0.0", "\n", "", "try", ":", "\n", "                ", "self", ".", "kernel_init", "=", "config", "[", "'HYPERPARAMETERS'", "]", "[", "'kernel_init'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "kernel_init", "=", "'zero'", "\n", "", "try", ":", "\n", "                ", "self", ".", "category_mapping", "=", "dict", "(", "config", "[", "'CATEGORY_MAPPING'", "]", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "category_mapping", "=", "{", "\n", "\"vehicle.car\"", ":", "\"vehicle.car\"", ",", "\n", "\"vehicle.motorcycle\"", ":", "\"vehicle.motorcycle\"", ",", "\n", "\"vehicle.bicycle\"", ":", "\"vehicle.bicycle\"", ",", "\n", "\"vehicle.bus\"", ":", "\"vehicle.bus\"", ",", "\n", "\"vehicle.truck\"", ":", "\"vehicle.truck\"", ",", "\n", "\"vehicle.emergency\"", ":", "\"vehicle.truck\"", ",", "\n", "\"vehicle.trailer\"", ":", "\"vehicle.trailer\"", ",", "\n", "\"human\"", ":", "\"human\"", ",", "}", "\n", "", "try", ":", "\n", "                ", "self", ".", "class_weights", "=", "dict", "(", "config", "[", "'CLASS_WEIGHTS'", "]", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "class_weights", "=", "None", "\n", "", "try", ":", "\n", "                ", "self", ".", "distance_alpha", "=", "config", ".", "getfloat", "(", "'CRF-Net'", ",", "'distance_alpha'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "distance_alpha", "=", "1.0", "\n", "", "try", ":", "\n", "                ", "self", ".", "scene_selection", "=", "config", "[", "'DATA'", "]", "[", "'scene_selection'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "scene_selection", "=", "config", "[", "'DATA'", "]", "[", "'val_indices'", "]", "\n", "", "try", ":", "\n", "                ", "self", ".", "sample_selection", "=", "config", ".", "getboolean", "(", "'PREPROCESSING'", ",", "'sample_selection'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "sample_selection", "=", "False", "\n", "", "try", ":", "\n", "                ", "self", ".", "only_radar_annotated", "=", "config", ".", "getint", "(", "'PREPROCESSING'", ",", "'only_radar_annotated'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "only_radar_annotated", "=", "False", "\n", "", "try", ":", "\n", "                ", "self", ".", "save_val_img_path", "=", "config", "[", "'DATA'", "]", "[", "'save_val_img_path'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "save_val_img_path", "=", "None", "\n", "", "try", ":", "\n", "                ", "self", ".", "noise_filter_model", "=", "config", "[", "'DATA'", "]", "[", "'noise_filter_model'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "noise_filter_model", "=", "None", "\n", "", "try", ":", "\n", "                ", "self", ".", "noise_filter_cfg", "=", "config", "[", "'DATA'", "]", "[", "'noise_filter_cfg'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "noise_filter_cfg", "=", "None", "\n", "", "try", ":", "\n", "                ", "self", ".", "noise_filter_perfect", "=", "config", ".", "getboolean", "(", "'DATA'", ",", "'noise_filter_perfect'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "noise_filter_perfect", "=", "False", "\n", "", "try", ":", "\n", "                ", "self", ".", "noise_filter_threshold", "=", "config", ".", "getfloat", "(", "'DATA'", ",", "'noise_filter_threshold'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "noise_filter_threshold", "=", "0.0", "\n", "", "try", ":", "\n", "                ", "self", ".", "class_specific_nms", "=", "config", ".", "getboolean", "(", "'CRF-Net'", ",", "'class_specific_nms'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "class_specific_nms", "=", "False", "\n", "", "try", ":", "\n", "                ", "self", ".", "score_thresh_train", "=", "config", ".", "getfloat", "(", "'CRF-Net'", ",", "'score_thresh_train'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "score_thresh_train", "=", "0.05", "\n", "", "try", ":", "\n", "                ", "self", ".", "noisy_image_method", "=", "config", "[", "'PREPROCESSING'", "]", "[", "'noisy_image_method'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "noisy_image_method", "=", "None", "\n", "", "try", ":", "\n", "                ", "self", ".", "noise_factor", "=", "config", ".", "getfloat", "(", "'PREPROCESSING'", ",", "'noise_factor'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "noise_factor", "=", "0.0", "\n", "", "try", ":", "\n", "                ", "self", ".", "radar_projection_height", "=", "config", ".", "getfloat", "(", "'DATA'", ",", "'radar_projection_height'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "radar_projection_height", "=", "3", "\n", "", "try", ":", "\n", "                ", "self", ".", "network_width", "=", "config", ".", "getfloat", "(", "'CRF-Net'", ",", "'network_width'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "network_width", "=", "1.0", "\n", "", "try", ":", "\n", "                ", "self", ".", "pooling", "=", "config", "[", "'CRF-Net'", "]", "[", "'pooling'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "pooling", "=", "'max'", "\n", "", "try", ":", "\n", "                ", "self", ".", "fusion_blocks", "=", "ast", ".", "literal_eval", "(", "config", ".", "get", "(", "'CRF-Net'", ",", "'fusion_blocks'", ")", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "fusion_blocks", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n", "", "if", "'coco'", "in", "self", ".", "data_set", ":", "\n", "                ", "self", ".", "class_weights", "=", "None", "\n", "self", ".", "distance_detection", "=", "False", "\n", "\n", "", "try", ":", "\n", "                ", "self", ".", "anchor_params", "=", "config", "[", "'CRF-Net'", "]", "[", "'anchor_params'", "]", "\n", "", "except", ":", "\n", "                ", "self", ".", "anchor_params", "=", "'default'", "\n", "\n", "", "try", ":", "\n", "                ", "self", ".", "seed", "=", "config", ".", "getint", "(", "'COMPUTING'", ",", "'seed'", ")", "\n", "", "except", ":", "\n", "                ", "self", ".", "seed", "=", "0", "\n", "\n", "", "", "def", "get_description", "(", "self", ")", ":", "\n", "            ", "attributes", "=", "[", "a", "for", "a", "in", "dir", "(", "self", ")", "if", "not", "a", ".", "startswith", "(", "'__'", ")", "and", "not", "callable", "(", "getattr", "(", "self", ",", "a", ")", ")", "]", "\n", "values", "=", "[", "getattr", "(", "self", ",", "attr", ")", "for", "attr", "in", "attributes", "]", "\n", "\n", "out_string", "=", "\"\"", "\n", "\n", "for", "i", ",", "attr", "in", "enumerate", "(", "attributes", ")", ":", "\n", "                ", "out_string", "+=", "\"%s = %s\\n\\n\"", "%", "(", "attr", ",", "pprint", ".", "pformat", "(", "values", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "out_string", "\n", "\n", "\n", "", "", "cfg", "=", "Configuation", "(", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.keras_version": [[25, 32], ["tuple", "map", "keras.__version__.split"], "function", ["None"], ["def", "keras_version", "(", ")", ":", "\n", "    ", "\"\"\" Get the Keras version.\n\n    Returns\n        tuple of (major, minor, patch).\n    \"\"\"", "\n", "return", "tuple", "(", "map", "(", "int", ",", "keras", ".", "__version__", ".", "split", "(", "'.'", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.keras_version_ok": [[34, 38], ["keras_version.keras_version"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.keras_version"], ["", "def", "keras_version_ok", "(", ")", ":", "\n", "    ", "\"\"\" Check if the current Keras version is higher than the minimum version.\n    \"\"\"", "\n", "return", "keras_version", "(", ")", ">=", "minimum_keras_version", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.assert_keras_version": [[40, 46], ["map", "keras_version.keras_version"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.keras_version"], ["", "def", "assert_keras_version", "(", ")", ":", "\n", "    ", "\"\"\" Assert that the Keras version is up to date.\n    \"\"\"", "\n", "detected", "=", "keras", ".", "__version__", "\n", "required", "=", "'.'", ".", "join", "(", "map", "(", "str", ",", "minimum_keras_version", ")", ")", "\n", "assert", "(", "keras_version", "(", ")", ">=", "minimum_keras_version", ")", ",", "'You are using keras version {}. The minimum required version is {}.'", ".", "format", "(", "detected", ",", "required", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.check_keras_version": [[48, 56], ["keras_version.assert_keras_version", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.keras_version.assert_keras_version"], ["", "def", "check_keras_version", "(", ")", ":", "\n", "    ", "\"\"\" Check that the Keras version is up to date. If it isn't, print an error message and exit the script.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "assert_keras_version", "(", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.colors.label_color": [[5, 21], ["len", "warnings.warn"], "function", ["None"], ["def", "label_color", "(", "label", ")", ":", "\n", "    ", "\"\"\" Return a color from a set of predefined colors. Contains 80 colors in total.\n\n    Args\n        label: The label to get the color for.\n\n    Returns\n        A list of three values representing a RGB color.\n\n        If no color is defined for a certain label, the color green is returned and a warning is printed.\n    \"\"\"", "\n", "if", "label", "<", "len", "(", "colors", ")", ":", "\n", "        ", "return", "colors", "[", "label", "]", "\n", "", "else", ":", "\n", "        ", "warnings", ".", "warn", "(", "'Label {} has no color, returning default.'", ".", "format", "(", "label", ")", ")", "\n", "return", "(", "0", ",", "255", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval_test.evaluate_test_set": [[4, 105], ["numpy.nanmean", "numpy.nanmean", "best_aps.items", "crfnet.utils.eval.evaluate", "crfnet.utils.eval.evaluate", "total_instances.append", "precisions.append", "tf.Summary", "tf.Summary.value.add", "tf.Summary.value.add", "tf.Summary.value.add", "best_aps.items", "tensorboard.writer.reopen", "tensorboard.writer.add_summary", "tensorboard.writer.close", "print", "print", "print", "sum", "sum", "numpy.count_nonzero", "sum", "sum", "numpy.nanmean", "numpy.nanmean", "tf.Summary.value.add", "tf.Summary.value.add", "print", "print", "print", "sum", "sum", "sum", "sum", "generator.label_to_name", "summary_aps.append", "generator.label_to_name", "generator.label_to_name", "numpy.isnan", "tf.Summary.value.add", "zip", "str", "zip", "numpy.isnan", "zip", "numpy.isnan", "int", "generator.label_to_name"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval.evaluate", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval.evaluate", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name"], ["def", "evaluate_test_set", "(", "model", ",", "generator", ",", "cfg", ",", "mode", "=", "'test'", ",", "tensorboard", "=", "None", ",", "verbose", "=", "1", ")", ":", "\n", "\n", "# run evaluation", "\n", "    ", "if", "cfg", ".", "distance_detection", ":", "\n", "        ", "best_map", ",", "best_st", ",", "best_aps", ",", "best_precisions", ",", "best_recalls", ",", "best_mean_loss_errors", ",", "best_mean_loss_errors_rel", "=", "evaluate", "(", "\n", "generator", ",", "\n", "model", ",", "\n", "distance", "=", "cfg", ".", "distance_detection", ",", "\n", "iou_threshold", "=", "0.5", ",", "\n", "score_threshold", "=", "0.05", ",", "\n", "max_detections", "=", "100", ",", "\n", "save_path", "=", "None", ",", "\n", "render", "=", "False", ",", "\n", "workers", "=", "cfg", ".", "workers", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "best_map", ",", "best_st", ",", "best_aps", ",", "best_precisions", ",", "best_recalls", "=", "evaluate", "(", "\n", "generator", ",", "\n", "model", ",", "\n", "distance", "=", "cfg", ".", "distance_detection", ",", "\n", "iou_threshold", "=", "0.5", ",", "\n", "score_threshold", "=", "0.05", ",", "\n", "max_detections", "=", "100", ",", "\n", "save_path", "=", "None", ",", "\n", "render", "=", "False", ",", "\n", "workers", "=", "cfg", ".", "workers", "\n", ")", "\n", "# ignore bg with [:-1]", "\n", "", "mean_precision", "=", "np", ".", "nanmean", "(", "best_precisions", "[", ":", "-", "1", "]", ")", "\n", "mean_recall", "=", "np", ".", "nanmean", "(", "best_recalls", "[", ":", "-", "1", "]", ")", "\n", "\n", "\n", "# compute per class average precision", "\n", "total_instances", "=", "[", "]", "\n", "precisions", "=", "[", "]", "\n", "mean_loss_error", "=", "np", ".", "nan", "\n", "mean_loss_error_rel", "=", "np", ".", "nan", "\n", "for", "label", ",", "(", "average_precision", ",", "num_annotations", ")", "in", "best_aps", ".", "items", "(", ")", ":", "\n", "        ", "if", "verbose", "==", "1", ":", "\n", "            ", "if", "cfg", ".", "distance_detection", ":", "\n", "                ", "print", "(", "'{:.0f} instances of class'", ".", "format", "(", "num_annotations", ")", ",", "\n", "generator", ".", "label_to_name", "(", "label", ")", ",", "'with average precision: {0:.4f} (precision: {1:.4f}, recall: {2:.4f}) and mean distance error:{3:.2f} or {4:.2f}%'", ".", "format", "(", "average_precision", ",", "best_precisions", "[", "label", "]", ",", "best_recalls", "[", "label", "]", ",", "best_mean_loss_errors", "[", "label", "]", ",", "best_mean_loss_errors_rel", "[", "label", "]", "*", "100", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'{:.0f} instances of class'", ".", "format", "(", "num_annotations", ")", ",", "\n", "generator", ".", "label_to_name", "(", "label", ")", ",", "'with average precision: {0:.4f} (precision: {1:.4f}, recall: {2:.4f})'", ".", "format", "(", "average_precision", ",", "best_precisions", "[", "label", "]", ",", "best_recalls", "[", "label", "]", ")", ")", "\n", "", "", "total_instances", ".", "append", "(", "num_annotations", ")", "\n", "precisions", ".", "append", "(", "average_precision", ")", "\n", "\n", "", "if", "cfg", ".", "weighted_map", ":", "\n", "        ", "mean_ap", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "precisions", ")", "]", ")", "/", "sum", "(", "total_instances", ")", "\n", "if", "cfg", ".", "distance_detection", "and", "np", ".", "count_nonzero", "(", "~", "np", ".", "isnan", "(", "best_mean_loss_errors", ")", ")", ":", "\n", "            ", "mean_loss_error", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "best_mean_loss_errors", ")", "if", "(", "b", "==", "b", ")", "]", ")", "/", "sum", "(", "~", "np", ".", "isnan", "(", "best_mean_loss_errors", ")", "*", "total_instances", ")", "\n", "mean_loss_error_rel", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "best_mean_loss_errors_rel", ")", "if", "(", "b", "==", "b", ")", "]", ")", "/", "sum", "(", "~", "np", ".", "isnan", "(", "best_mean_loss_errors_rel", ")", "*", "total_instances", ")", "\n", "", "", "else", ":", "\n", "        ", "mean_ap", "=", "sum", "(", "precisions", ")", "/", "sum", "(", "x", ">", "0", "for", "x", "in", "total_instances", ")", "\n", "if", "cfg", ".", "distance_detection", ":", "\n", "            ", "mean_loss_error", "=", "np", ".", "nanmean", "(", "best_mean_loss_errors", ")", "\n", "mean_loss_error_rel", "=", "np", ".", "nanmean", "(", "best_mean_loss_errors_rel", ")", "\n", "\n", "\n", "", "", "if", "tensorboard", "is", "not", "None", "and", "tensorboard", ".", "writer", "is", "not", "None", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "summary_map", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_map", ".", "simple_value", "=", "mean_ap", "\n", "summary_map", ".", "tag", "=", "\"mAP_test_\"", "+", "mode", "\n", "summary_precision", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_precision", ".", "simple_value", "=", "mean_precision", "\n", "summary_precision", ".", "tag", "=", "'precision_test_'", "+", "mode", "\n", "summary_recall", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_recall", ".", "simple_value", "=", "mean_recall", "\n", "summary_recall", ".", "tag", "=", "'recall_test_'", "+", "mode", "\n", "if", "cfg", ".", "distance_detection", ":", "\n", "            ", "summary_dist", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_dist", ".", "simple_value", "=", "mean_loss_error", "\n", "summary_dist", ".", "tag", "=", "'mADE_test_'", "+", "mode", "\n", "summary_dist_rel", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_dist_rel", ".", "simple_value", "=", "mean_loss_error_rel", "\n", "summary_dist_rel", ".", "tag", "=", "'mRDE_test_'", "+", "mode", "\n", "\n", "### class average precisions to tensorboard", "\n", "", "summary_aps", "=", "[", "]", "\n", "for", "label", ",", "(", "average_precision", ",", "num_annotations", ")", "in", "best_aps", ".", "items", "(", ")", ":", "\n", "            ", "if", "generator", ".", "label_to_name", "(", "label", ")", "is", "not", "'bg'", ":", "\n", "                ", "summary_aps", ".", "append", "(", "summary", ".", "value", ".", "add", "(", ")", ")", "\n", "summary_aps", "[", "label", "]", ".", "simple_value", "=", "average_precision", "\n", "summary_aps", "[", "label", "]", ".", "tag", "=", "'ap_test_'", "+", "mode", "+", "'_'", "+", "generator", ".", "label_to_name", "(", "label", ")", "+", "' ('", "+", "str", "(", "int", "(", "num_annotations", ")", ")", "+", "' instances)'", "\n", "\n", "", "", "tensorboard", ".", "writer", ".", "reopen", "(", ")", "\n", "tensorboard", ".", "writer", ".", "add_summary", "(", "summary", ",", "0", ")", "\n", "tensorboard", ".", "writer", ".", "close", "(", ")", "\n", "\n", "\n", "", "if", "verbose", "==", "1", ":", "\n", "        ", "print", "(", "'='", "*", "60", ")", "\n", "print", "(", "'mAP_test: {0:.4f} \\t precision_test:{1:.4f} \\t recall_test:{2:.4f}'", ".", "format", "(", "mean_ap", ",", "mean_precision", ",", "mean_recall", ")", ")", "\n", "if", "cfg", ".", "distance_detection", ":", "print", "(", "'mADE_test: {0:.2f} \\t mRDE_test:{1:.2f}'", ".", "format", "(", "mean_loss_error", ",", "mean_loss_error_rel", ")", ")", "\n", "print", "(", "'@scorethreshold {0:.2f}'", ".", "format", "(", "best_st", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.pretrained_weights.get_weights_path": [[9, 68], ["keras.utils.get_file", "keras.utils.get_file", "keras.utils.get_file", "keras.utils.get_file", "print"], "function", ["None"], ["def", "get_weights_path", "(", "network", ")", ":", "\n", "\n", "    ", "if", "network", "==", "'resnet'", ":", "\n", "        ", "WEIGHTS_PATH", "=", "(", "'https://github.com/fchollet/deep-learning-models/'", "\n", "'releases/download/v0.2/'", "\n", "'resnet50_weights_tf_dim_ordering_tf_kernels.h5'", ")", "\n", "# WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'", "\n", "#                     'releases/download/v0.2/'", "\n", "#                     'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')", "\n", "\n", "\n", "# Load weights.", "\n", "weights_path", "=", "keras", ".", "utils", ".", "get_file", "(", "\n", "'resnet50_weights_tf_dim_ordering_tf_kernels.h5'", ",", "\n", "WEIGHTS_PATH", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "md5_hash", "=", "'a7b3fe01876f51b976af0dea6bc144eb'", ")", "\n", "\n", "", "elif", "'vgg'", "in", "network", ":", "\n", "        ", "WEIGHTS_PATH", "=", "(", "'https://github.com/fchollet/deep-learning-models/'", "\n", "'releases/download/v0.1/'", "\n", "'vgg16_weights_tf_dim_ordering_tf_kernels.h5'", ")", "\n", "# WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'", "\n", "#         'releases/download/v0.1/'", "\n", "#         'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')", "\n", "\n", "weights_path", "=", "keras", ".", "utils", ".", "get_file", "(", "\n", "'vgg16_weights_tf_dim_ordering_tf_kernels.h5'", ",", "\n", "WEIGHTS_PATH", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "'64373286793e3c8b2b4e3219cbf3544b'", ")", "\n", "\n", "", "elif", "network", "==", "'inception_resnet'", ":", "\n", "        ", "BASE_WEIGHT_URL", "=", "(", "'https://github.com/fchollet/deep-learning-models/'", "\n", "'releases/download/v0.7/'", ")", "\n", "\n", "fname", "=", "'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5'", "\n", "weights_path", "=", "keras", ".", "utils", ".", "get_file", "(", "\n", "fname", ",", "\n", "BASE_WEIGHT_URL", "+", "fname", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "'e693bd0210a403b3192acc6073ad2e96'", ")", "\n", "\n", "", "elif", "network", "==", "'xception'", ":", "\n", "        ", "TF_WEIGHTS_PATH", "=", "(", "\n", "'https://github.com/fchollet/deep-learning-models/'", "\n", "'releases/download/v0.4/'", "\n", "'xception_weights_tf_dim_ordering_tf_kernels.h5'", ")", "\n", "weights_path", "=", "keras", ".", "utils", ".", "get_file", "(", "\n", "'xception_weights_tf_dim_ordering_tf_kernels.h5'", ",", "\n", "TF_WEIGHTS_PATH", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "'0a58e3b7378bc2990ea3b43d5981f1f6'", ")", "\n", "\n", "", "else", ":", "\n", "# Raise Error", "\n", "        ", "print", "(", "'No weights path found for this base net.'", ")", "\n", "\n", "", "return", "weights_path", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval._compute_ap": [[36, 63], ["numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "numpy.maximum", "numpy.where"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where"], ["def", "_compute_ap", "(", "recall", ",", "precision", ")", ":", "\n", "    ", "\"\"\" Compute the average precision, given the recall and precision curves.\n\n    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n\n    # Arguments\n        recall:    The recall curve (list).\n        precision: The precision curve (list).\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    \"\"\"", "\n", "# correct AP calculation", "\n", "# first append sentinel values at the end", "\n", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0.", "]", ",", "recall", ",", "[", "1.", "]", ")", ")", "\n", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "0.", "]", ",", "precision", ",", "[", "0.", "]", ")", ")", "\n", "\n", "# compute the precision envelope", "\n", "for", "i", "in", "range", "(", "mpre", ".", "size", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "        ", "mpre", "[", "i", "-", "1", "]", "=", "np", ".", "maximum", "(", "mpre", "[", "i", "-", "1", "]", ",", "mpre", "[", "i", "]", ")", "\n", "\n", "# to calculate area under PR curve, look for points", "\n", "# where X axis (recall) changes value", "\n", "", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# and sum (\\Delta recall) * prec", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval._get_detections": [[65, 156], ["progressbar.progressbar", "keras.utils.data_utils.OrderedEnqueuer", "keras.utils.data_utils.OrderedEnqueuer.start", "keras.utils.data_utils.OrderedEnqueuer.get", "range", "range", "keras.utils.data_utils.OrderedEnqueuer.stop", "range", "generator.size", "next", "generator.compute_input_output", "generator.load_image", "model.predict_on_batch", "numpy.squeeze", "model.predict_on_batch", "numpy.where", "numpy.argsort", "numpy.concatenate", "numpy.concatenate", "crfnet.data_processing.fusion.fusion_projection_lines.create_imagep_visualization", "visualization.draw_detections", "cv2.imwrite", "generator.num_classes", "range", "generator.has_label", "generator.size", "multiprocessing.cpu_count", "cv2.imshow", "cv2.waitKey", "os.path.join", "generator.has_label", "generator.num_classes", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "print", "print"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.compute_input_output", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.create_imagep_visualization", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_detections", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.has_label", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.imshow", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization_helpers.Cv2Threaded.waitKey", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.has_label", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes"], ["", "def", "_get_detections", "(", "generator", ",", "model", ",", "distance", "=", "False", ",", "score_threshold", "=", "0.05", ",", "max_detections", "=", "100", ",", "\n", "save_path", "=", "None", ",", "render", "=", "False", ",", "distance_scale", "=", "100", ",", "workers", "=", "0", ",", "cfg", "=", "None", ")", ":", "\n", "    ", "\"\"\" Get the detections from the model using the generator.\n\n    The result is a list of lists such that the size is:\n        all_detections[num_images][num_classes] = detections[num_detections, 4 + num_classes]\n\n    # Arguments\n        generator       : The generator used to run images through the model.\n        model           : The model to run on the images.\n        score_threshold : The score confidence threshold to use.\n        max_detections  : The maximum number of detections to use per image.\n        save_path       : The path to save the images with visualized detections to.\n    # Returns\n        A list of lists containing the detections for each image in the generator.\n    \"\"\"", "\n", "all_detections", "=", "[", "[", "None", "for", "i", "in", "range", "(", "generator", ".", "num_classes", "(", ")", ")", "if", "generator", ".", "has_label", "(", "i", ")", "]", "for", "j", "in", "range", "(", "generator", ".", "size", "(", ")", ")", "]", "\n", "\n", "\n", "use_multiprocessing", "=", "workers", ">", "0", "\n", "if", "use_multiprocessing", ":", "\n", "        ", "enqueuer", "=", "keras", ".", "utils", ".", "data_utils", ".", "OrderedEnqueuer", "(", "generator", ",", "use_multiprocessing", "=", "use_multiprocessing", ",", "shuffle", "=", "False", ")", "\n", "enqueuer", ".", "start", "(", "workers", "=", "workers", ",", "max_queue_size", "=", "multiprocessing", ".", "cpu_count", "(", ")", ")", "\n", "val_generator", "=", "enqueuer", ".", "get", "(", ")", "\n", "\n", "\n", "", "for", "i", "in", "progressbar", ".", "progressbar", "(", "range", "(", "generator", ".", "size", "(", ")", ")", ",", "prefix", "=", "'Running network on {} workers: '", ".", "format", "(", "workers", ")", ")", ":", "\n", "        ", "if", "use_multiprocessing", ":", "\n", "            ", "inputs", ",", "_", "=", "next", "(", "val_generator", ")", "\n", "", "else", ":", "\n", "            ", "inputs", ",", "_", "=", "generator", ".", "compute_input_output", "(", "[", "i", "]", ")", "\n", "\n", "", "if", "save_path", "or", "render", ":", "\n", "            ", "raw_image", "=", "generator", ".", "load_image", "(", "i", ")", "\n", "\n", "# run network", "\n", "", "if", "distance", ":", "\n", "            ", "boxes", ",", "scores", ",", "labels", ",", "dists", "=", "model", ".", "predict_on_batch", "(", "inputs", ")", "\n", "dists", "=", "np", ".", "squeeze", "(", "dists", ",", "axis", "=", "2", ")", "\n", "dists", "=", "dists", "*", "distance_scale", "\n", "", "else", ":", "\n", "            ", "boxes", ",", "scores", ",", "labels", "=", "model", ".", "predict_on_batch", "(", "inputs", ")", "\n", "\n", "# select indices which have a score above the threshold", "\n", "", "indices", "=", "np", ".", "where", "(", "scores", "[", "0", ",", ":", "]", ">", "score_threshold", ")", "[", "0", "]", "\n", "\n", "# select those scores", "\n", "scores", "=", "scores", "[", "0", "]", "[", "indices", "]", "\n", "\n", "# find the order with which to sort the scores", "\n", "scores_sort", "=", "np", ".", "argsort", "(", "-", "scores", ")", "[", ":", "max_detections", "]", "\n", "\n", "# select detections", "\n", "image_boxes", "=", "boxes", "[", "0", ",", "indices", "[", "scores_sort", "]", ",", ":", "]", "\n", "image_scores", "=", "scores", "[", "scores_sort", "]", "\n", "image_labels", "=", "labels", "[", "0", ",", "indices", "[", "scores_sort", "]", "]", "\n", "if", "distance", ":", "\n", "            ", "image_distances", "=", "dists", "[", "0", ",", "scores_sort", "]", "\n", "image_detections", "=", "np", ".", "concatenate", "(", "[", "image_boxes", ",", "np", ".", "expand_dims", "(", "image_scores", ",", "axis", "=", "1", ")", ",", "np", ".", "expand_dims", "(", "image_distances", ",", "axis", "=", "1", ")", ",", "np", ".", "expand_dims", "(", "image_labels", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "image_detections", "=", "np", ".", "concatenate", "(", "[", "image_boxes", ",", "np", ".", "expand_dims", "(", "image_scores", ",", "axis", "=", "1", ")", ",", "np", ".", "expand_dims", "(", "image_labels", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Create Visualization", "\n", "", "if", "save_path", "or", "render", ":", "\n", "            ", "viz_image", "=", "create_imagep_visualization", "(", "raw_image", ",", "cfg", "=", "cfg", ")", "\n", "#draw_annotations(viz_image, generator.load_annotations(i), label_to_name=generator.label_to_name) # Draw annotations", "\n", "draw_detections", "(", "viz_image", ",", "image_boxes", ",", "image_scores", ",", "image_labels", ",", "score_threshold", "=", "0.3", ",", "label_to_name", "=", "generator", ".", "label_to_name", ")", "# Draw detections", "\n", "\n", "", "if", "render", ":", "\n", "# Show ", "\n", "            ", "try", ":", "\n", "                ", "cv2", ".", "imshow", "(", "\"debug\"", ",", "viz_image", ")", "\n", "cv2", ".", "waitKey", "(", "1", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"Render error:\"", ")", "\n", "print", "(", "e", ")", "\n", "", "", "if", "save_path", "is", "not", "None", ":", "\n", "# Store", "\n", "            ", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'{}.png'", ".", "format", "(", "i", ")", ")", ",", "viz_image", ")", "\n", "\n", "# copy detections to all_detections", "\n", "", "for", "label", "in", "range", "(", "generator", ".", "num_classes", "(", ")", ")", ":", "\n", "            ", "if", "not", "generator", ".", "has_label", "(", "label", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "all_detections", "[", "i", "]", "[", "label", "]", "=", "image_detections", "[", "image_detections", "[", ":", ",", "-", "1", "]", "==", "label", ",", ":", "-", "1", "]", "\n", "\n", "", "", "if", "use_multiprocessing", ":", "\n", "        ", "enqueuer", ".", "stop", "(", ")", "\n", "\n", "", "return", "all_detections", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval._get_annotations": [[158, 190], ["progressbar.progressbar", "range", "generator.load_annotations", "range", "range", "generator.size", "generator.num_classes", "numpy.concatenate", "box_and_dist_and_vis[].copy", "range", "generator.size", "generator.has_label", "len", "[].copy", "generator.num_classes", "numpy.expand_dims", "numpy.expand_dims().astype", "numpy.expand_dims"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_annotations", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.has_label", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes"], ["", "def", "_get_annotations", "(", "generator", ")", ":", "\n", "    ", "\"\"\" Get the ground truth annotations from the generator.\n\n    The result is a list of lists such that the size is:\n        all_detections[num_images][num_classes] = annotations[num_detections, 5]\n\n    # Arguments\n        generator : The generator used to retrieve ground truth annotations.\n    # Returns\n        A list of lists containing the annotations for each image in the generator.\n    \"\"\"", "\n", "all_annotations", "=", "[", "[", "None", "for", "i", "in", "range", "(", "generator", ".", "num_classes", "(", ")", ")", "]", "for", "j", "in", "range", "(", "generator", ".", "size", "(", ")", ")", "]", "\n", "\n", "for", "i", "in", "progressbar", ".", "progressbar", "(", "range", "(", "generator", ".", "size", "(", ")", ")", ",", "prefix", "=", "'Parsing annotations: '", ")", ":", "\n", "# load the annotations", "\n", "        ", "annotations", "=", "generator", ".", "load_annotations", "(", "i", ")", "\n", "\n", "# copy detections to all_annotations", "\n", "for", "label", "in", "range", "(", "generator", ".", "num_classes", "(", ")", ")", ":", "\n", "            ", "if", "not", "generator", ".", "has_label", "(", "label", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "len", "(", "annotations", "[", "'bboxes'", "]", ")", "==", "0", ":", "\n", "                ", "all_annotations", "[", "i", "]", "[", "label", "]", "=", "annotations", "[", "'bboxes'", "]", "[", "annotations", "[", "'labels'", "]", "==", "label", "]", ".", "copy", "(", ")", "\n", "continue", "\n", "\n", "", "box_and_dist_and_vis", "=", "np", ".", "concatenate", "(", "(", "annotations", "[", "'bboxes'", "]", ",", "np", ".", "expand_dims", "(", "annotations", "[", "'distances'", "]", ",", "axis", "=", "1", ")", ",", "np", ".", "expand_dims", "(", "annotations", "[", "'visibilities'", "]", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float64", ")", ")", ",", "axis", "=", "1", ")", "\n", "all_annotations", "[", "i", "]", "[", "label", "]", "=", "box_and_dist_and_vis", "[", "annotations", "[", "'labels'", "]", "==", "label", "]", ".", "copy", "(", ")", "\n", "\n", "\n", "", "", "return", "all_annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval.evaluate": [[192, 370], ["eval._get_detections", "eval._get_annotations", "numpy.arange", "numpy.append", "numpy.unique", "print", "numpy.arange", "numpy.sort", "numpy.zeros", "numpy.zeros", "range", "average_precisions.items", "numpy.nanmean", "numpy.nanmean", "print", "generator.num_classes", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "numpy.argsort", "numpy.cumsum", "numpy.cumsum", "eval._compute_ap", "numpy.mean", "numpy.mean", "total_instances.append", "precisions.append", "p_list.append", "r_list.append", "sum", "sum", "numpy.count_nonzero", "generator.has_label", "generator.size", "numpy.maximum", "len", "len", "numpy.mean", "numpy.mean", "numpy.append", "numpy.append", "sum", "sum", "sum", "sum", "numpy.append", "anchor_calc.compute_overlap", "numpy.argmax", "numpy.isnan", "numpy.append", "numpy.append", "numpy.expand_dims", "numpy.append", "numpy.append", "detected_annotations.append", "numpy.append", "numpy.append", "numpy.finfo", "zip", "numpy.abs", "numpy.append", "numpy.append", "zip", "numpy.isnan", "zip", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval._get_detections", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval._get_annotations", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval._compute_ap", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.has_label", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size"], ["", "def", "evaluate", "(", "\n", "generator", ",", "\n", "model", ",", "\n", "distance", ",", "\n", "iou_threshold", "=", "0.5", ",", "\n", "score_threshold", "=", "0.05", ",", "\n", "max_detections", "=", "100", ",", "\n", "save_path", "=", "None", ",", "\n", "render", "=", "False", ",", "\n", "workers", "=", "0", "\n", ")", ":", "\n", "    ", "\"\"\" Evaluate a given dataset using a given model.\n\n    # Arguments\n        generator       : The generator that represents the dataset to evaluate.\n        model           : The model to evaluate.\n        iou_threshold   : The threshold used to consider when a detection is positive or negative.\n        score_threshold : The score confidence threshold to use for detections.\n        max_detections  : The maximum number of detections to use per image.\n        save_path       : The path to save images with visualized detections to.\n    # Returns\n        A dict mapping class names to mAP scores.\n    \"\"\"", "\n", "assert", "generator", ".", "shuffle_groups", "==", "False", ",", "'validation data must not be shuffled, you fucktrumpet'", "\n", "# gather all detections and annotations", "\n", "all_detections", "=", "_get_detections", "(", "generator", ",", "model", ",", "distance", "=", "distance", ",", "score_threshold", "=", "score_threshold", ",", "max_detections", "=", "max_detections", ",", "save_path", "=", "save_path", ",", "render", "=", "render", ",", "workers", "=", "workers", ")", "\n", "all_annotations", "=", "_get_annotations", "(", "generator", ")", "\n", "\n", "\n", "# all_detections = pickle.load(open('all_detections.pkl', 'rb'))", "\n", "# all_annotations = pickle.load(open('all_annotations.pkl', 'rb'))", "\n", "# pickle.dump(all_detections, open('all_detections.pkl', 'wb'))", "\n", "# pickle.dump(all_annotations, open('all_annotations.pkl', 'wb'))", "\n", "\n", "# process detections and annotations", "\n", "score_thresholds", "=", "np", ".", "arange", "(", "0.05", ",", "1.00", ",", "0.05", ")", "\n", "score_thresholds", "=", "np", ".", "append", "(", "score_thresholds", ",", "np", ".", "arange", "(", "0.05", ",", "0.1", ",", "0.01", ")", ")", "\n", "score_thresholds", "=", "np", ".", "unique", "(", "np", ".", "sort", "(", "score_thresholds", ")", ")", "\n", "\n", "best_map", "=", "0.0", "\n", "for", "st", "in", "score_thresholds", ":", "\n", "        ", "loss_errors", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "loss_errors_rel", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "p_list", "=", "[", "]", "\n", "r_list", "=", "[", "]", "\n", "average_precisions", "=", "{", "}", "\n", "recall_dict", "=", "{", "}", "\n", "precision_dict", "=", "{", "}", "\n", "mean_dist_errors", "=", "{", "}", "\n", "mean_dist_errors_rel", "=", "{", "}", "\n", "for", "label", "in", "range", "(", "generator", ".", "num_classes", "(", ")", ")", ":", "\n", "            ", "if", "not", "generator", ".", "has_label", "(", "label", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "false_positives", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "true_positives", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "scores", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "dist_errors", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "rel_dist_errors", "=", "np", ".", "zeros", "(", "(", "0", ",", ")", ")", "\n", "num_annotations", "=", "0.0", "\n", "\n", "for", "i", "in", "range", "(", "generator", ".", "size", "(", ")", ")", ":", "\n", "                ", "detections", "=", "all_detections", "[", "i", "]", "[", "label", "]", "\n", "annotations", "=", "all_annotations", "[", "i", "]", "[", "label", "]", "\n", "num_annotations", "+=", "annotations", ".", "shape", "[", "0", "]", "\n", "detected_annotations", "=", "[", "]", "\n", "\n", "for", "d", "in", "detections", ":", "\n", "                    ", "score", "=", "d", "[", "4", "]", "\n", "if", "score", "<", "st", ":", "\n", "                        ", "continue", "\n", "", "scores", "=", "np", ".", "append", "(", "scores", ",", "score", ")", "\n", "if", "distance", ":", "dist", "=", "d", "[", "5", "]", "\n", "\n", "if", "annotations", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "                        ", "false_positives", "=", "np", ".", "append", "(", "false_positives", ",", "1", ")", "\n", "true_positives", "=", "np", ".", "append", "(", "true_positives", ",", "0", ")", "\n", "continue", "\n", "\n", "", "overlaps", "=", "compute_overlap", "(", "np", ".", "expand_dims", "(", "d", ",", "axis", "=", "0", ")", ",", "annotations", "[", ":", ",", ":", "4", "]", ")", "\n", "assigned_annotation", "=", "np", ".", "argmax", "(", "overlaps", ",", "axis", "=", "1", ")", "\n", "max_overlap", "=", "overlaps", "[", "0", ",", "assigned_annotation", "]", "\n", "\n", "if", "max_overlap", ">=", "iou_threshold", "and", "assigned_annotation", "not", "in", "detected_annotations", ":", "\n", "                        ", "false_positives", "=", "np", ".", "append", "(", "false_positives", ",", "0", ")", "\n", "true_positives", "=", "np", ".", "append", "(", "true_positives", ",", "1", ")", "\n", "detected_annotations", ".", "append", "(", "assigned_annotation", ")", "\n", "if", "distance", ":", "\n", "                            ", "dist_err", "=", "np", ".", "abs", "(", "dist", "-", "annotations", "[", "assigned_annotation", "[", "0", "]", ",", "4", "]", ")", "\n", "rel_dist_err", "=", "dist_err", "/", "annotations", "[", "assigned_annotation", "[", "0", "]", ",", "4", "]", "\n", "dist_errors", "=", "np", ".", "append", "(", "dist_errors", ",", "dist_err", ")", "\n", "rel_dist_errors", "=", "np", ".", "append", "(", "rel_dist_errors", ",", "rel_dist_err", ")", "\n", "", "", "else", ":", "\n", "                        ", "false_positives", "=", "np", ".", "append", "(", "false_positives", ",", "1", ")", "\n", "true_positives", "=", "np", ".", "append", "(", "true_positives", ",", "0", ")", "\n", "\n", "\n", "# no annotations -> AP for this class is 0 (is this correct?)", "\n", "", "", "", "if", "num_annotations", "==", "0", ":", "\n", "                ", "average_precisions", "[", "label", "]", "=", "0", ",", "0", "\n", "recall_dict", "[", "label", "]", "=", "0", "\n", "precision_dict", "[", "label", "]", "=", "0", "\n", "if", "distance", ":", "\n", "                    ", "mean_dist_errors", "[", "label", "]", "=", "np", ".", "nan", "\n", "mean_dist_errors_rel", "[", "label", "]", "=", "np", ".", "nan", "\n", "", "continue", "\n", "\n", "# sort by score", "\n", "", "indices", "=", "np", ".", "argsort", "(", "-", "scores", ")", "\n", "false_positives", "=", "false_positives", "[", "indices", "]", "\n", "true_positives", "=", "true_positives", "[", "indices", "]", "\n", "\n", "# compute false positives and true positives", "\n", "false_positives", "=", "np", ".", "cumsum", "(", "false_positives", ")", "\n", "true_positives", "=", "np", ".", "cumsum", "(", "true_positives", ")", "\n", "\n", "# compute recall and precision", "\n", "recall", "=", "true_positives", "/", "num_annotations", "\n", "precision", "=", "true_positives", "/", "np", ".", "maximum", "(", "true_positives", "+", "false_positives", ",", "np", ".", "finfo", "(", "np", ".", "float64", ")", ".", "eps", ")", "\n", "\n", "# compute average precision", "\n", "average_precision", "=", "_compute_ap", "(", "recall", ",", "precision", ")", "\n", "average_precisions", "[", "label", "]", "=", "average_precision", ",", "num_annotations", "\n", "if", "len", "(", "recall", ")", "==", "0", ":", "\n", "                ", "recall", "=", "0", "\n", "", "if", "len", "(", "precision", ")", "==", "0", ":", "\n", "                ", "precision", "=", "0", "\n", "", "recall_dict", "[", "label", "]", "=", "np", ".", "mean", "(", "recall", ")", "\n", "precision_dict", "[", "label", "]", "=", "np", ".", "mean", "(", "precision", ")", "\n", "if", "distance", ":", "\n", "                ", "mean_dist_errors", "[", "label", "]", "=", "np", ".", "mean", "(", "dist_errors", ")", "\n", "mean_dist_errors_rel", "[", "label", "]", "=", "np", ".", "mean", "(", "rel_dist_errors", ")", "\n", "\n", "\n", "# compute per class average precision", "\n", "", "", "total_instances", "=", "[", "]", "\n", "precisions", "=", "[", "]", "\n", "for", "label", ",", "(", "average_precision", ",", "num_annotations", ")", "in", "average_precisions", ".", "items", "(", ")", ":", "\n", "            ", "total_instances", ".", "append", "(", "num_annotations", ")", "\n", "precisions", ".", "append", "(", "average_precision", ")", "\n", "if", "distance", ":", "\n", "                ", "loss_errors", "=", "np", ".", "append", "(", "loss_errors", ",", "mean_dist_errors", "[", "label", "]", ")", "\n", "loss_errors_rel", "=", "np", ".", "append", "(", "loss_errors_rel", ",", "mean_dist_errors_rel", "[", "label", "]", ")", "\n", "", "p_list", ".", "append", "(", "precision_dict", "[", "label", "]", ")", "\n", "r_list", ".", "append", "(", "recall_dict", "[", "label", "]", ")", "\n", "\n", "# ignore bg with [:-1]", "\n", "", "mean_precision", "=", "np", ".", "nanmean", "(", "p_list", "[", ":", "-", "1", "]", ")", "\n", "mean_recall", "=", "np", ".", "nanmean", "(", "r_list", "[", ":", "-", "1", "]", ")", "\n", "mean_ap", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "precisions", ")", "]", ")", "/", "sum", "(", "total_instances", ")", "\n", "if", "distance", "and", "np", ".", "count_nonzero", "(", "~", "np", ".", "isnan", "(", "loss_errors", ")", ")", ":", "\n", "            ", "mean_loss_error", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "loss_errors", ")", "if", "(", "b", "==", "b", ")", "]", ")", "/", "sum", "(", "~", "np", ".", "isnan", "(", "loss_errors", ")", "*", "total_instances", ")", "\n", "mean_loss_error_rel", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "loss_errors_rel", ")", "if", "(", "b", "==", "b", ")", "]", ")", "/", "sum", "(", "~", "np", ".", "isnan", "(", "loss_errors_rel", ")", "*", "total_instances", ")", "\n", "", "else", ":", "\n", "            ", "mean_loss_error", "=", "np", ".", "nan", "\n", "mean_loss_error_rel", "=", "np", ".", "nan", "\n", "", "print", "(", "'mAP @ scorethreshold {0:.2f}: {1:.4f} (precision: {2:.4f}, recall: {3:.4f}, mADE: {4:.4f}, mRDE: {5:.4f})'", ".", "format", "(", "st", ",", "mean_ap", ",", "mean_precision", ",", "mean_recall", ",", "mean_loss_error", ",", "mean_loss_error_rel", ")", ")", "\n", "\n", "\n", "\n", "if", "mean_ap", ">=", "best_map", ":", "\n", "            ", "best_map", "=", "mean_ap", "\n", "best_st", "=", "st", "\n", "best_aps", "=", "average_precisions", "\n", "best_mean_loss_errors", "=", "loss_errors", "\n", "best_mean_loss_errors_rel", "=", "loss_errors_rel", "\n", "best_precisions", "=", "p_list", "\n", "best_recalls", "=", "r_list", "\n", "\n", "\n", "\n", "", "", "print", "(", "'='", "*", "60", ")", "\n", "\n", "if", "distance", ":", "\n", "        ", "return", "best_map", ",", "best_st", ",", "best_aps", ",", "best_precisions", ",", "best_recalls", ",", "best_mean_loss_errors", ",", "best_mean_loss_errors_rel", "\n", "", "else", ":", "\n", "        ", "return", "best_map", ",", "best_st", ",", "best_aps", ",", "best_precisions", ",", "best_recalls", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.visualize_predictions": [[26, 71], ["range", "generator.label_to_name", "cv2.rectangle", "cv2.getTextSize", "cv2.rectangle", "cv2.putText", "pprint.pprint", "all_dets.append", "all_dets.append", "int", "int", "int", "generator.label_to_name.split", "generator.label_to_name.split"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name"], ["def", "visualize_predictions", "(", "predictions", ",", "image_data_vis", ",", "generator", ",", "dist", "=", "False", ",", "verbose", "=", "False", ",", "cfg", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Visualizes the predictions as bounding boxes with distances or confidence score in a given image.\n\n    :param predictions:         <list>              List with [bboxes, probs, labels]\n    :param image_data_vis:      <np.array>          Image where the predictions should be visualized\n    :param generator:           <Generator>         Data generator used for name to label mapping\n    :dist:                      <bool>              True if distance detection is enabled\n    :verbose:                   <bool>              True if detetions should be printed \n\n    \"\"\"", "\n", "\n", "font", "=", "cv2", ".", "FONT_HERSHEY_SIMPLEX", "\n", "fontScale", "=", "0.4", "\n", "\n", "# Visualization prediction", "\n", "all_dets", "=", "[", "]", "\n", "[", "bboxes", ",", "probs", ",", "labels", "]", "=", "predictions", "\n", "\n", "\n", "\n", "for", "jk", "in", "range", "(", "bboxes", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", "=", "bboxes", "[", "0", ",", "jk", ",", ":", "]", "\n", "\n", "key", "=", "generator", ".", "label_to_name", "(", "labels", "[", "0", ",", "jk", "]", ")", "\n", "color", "=", "tum_colors", "[", "key", "]", "*", "255", "\n", "cv2", ".", "rectangle", "(", "image_data_vis", ",", "(", "x1", ",", "y1", ")", ",", "(", "x2", ",", "y2", ")", ",", "color", ",", "2", ")", "\n", "\n", "if", "dist", "is", "not", "False", ":", "\n", "            ", "textLabel", "=", "'{0}: {1:3.1f} {2}'", ".", "format", "(", "key", ".", "split", "(", "'.'", ",", "1", ")", "[", "-", "1", "]", ",", "dist", "[", "0", ",", "jk", "]", ",", "'m'", ")", "\n", "all_dets", ".", "append", "(", "(", "key", ",", "100", "*", "probs", "[", "0", ",", "jk", "]", ",", "dist", "[", "0", ",", "jk", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "textLabel", "=", "'{}: {}'", ".", "format", "(", "key", ".", "split", "(", "'.'", ",", "1", ")", "[", "-", "1", "]", ",", "int", "(", "100", "*", "probs", "[", "0", ",", "jk", "]", ")", ")", "\n", "all_dets", ".", "append", "(", "(", "key", ",", "100", "*", "probs", "[", "0", ",", "jk", "]", ")", ")", "\n", "\n", "", "(", "retval", ",", "baseLine", ")", "=", "cv2", ".", "getTextSize", "(", "textLabel", ",", "font", ",", "fontScale", ",", "1", ")", "\n", "\n", "textOrg", "=", "int", "(", "x1", ")", ",", "int", "(", "y1", ")", "\n", "\n", "cv2", ".", "rectangle", "(", "image_data_vis", ",", "(", "textOrg", "[", "0", "]", "-", "1", ",", "textOrg", "[", "1", "]", "+", "baseLine", "-", "1", ")", ",", "(", "textOrg", "[", "0", "]", "+", "retval", "[", "0", "]", "+", "1", ",", "textOrg", "[", "1", "]", "-", "retval", "[", "1", "]", "-", "1", ")", ",", "color", ",", "-", "1", ")", "\n", "cv2", ".", "putText", "(", "image_data_vis", ",", "textLabel", ",", "textOrg", ",", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "fontScale", ",", "(", "1", ",", "1", ",", "1", ")", ",", "1", ")", "\n", "\n", "", "if", "verbose", ":", "pprint", ".", "pprint", "(", "all_dets", ")", "\n", "\n", "return", "image_data_vis", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_box": [[72, 83], ["numpy.array().astype", "cv2.rectangle", "numpy.array"], "function", ["None"], ["", "def", "draw_box", "(", "image", ",", "box", ",", "color", ",", "thickness", "=", "2", ")", ":", "\n", "    ", "\"\"\" Draws a box on an image with a given color.\n\n    # Arguments\n        image     : The image to draw on.\n        box       : A list of 4 elements (x1, y1, x2, y2).\n        color     : The color of the box.\n        thickness : The thickness of the lines to draw a box with.\n    \"\"\"", "\n", "b", "=", "np", ".", "array", "(", "box", ")", ".", "astype", "(", "int", ")", "\n", "cv2", ".", "rectangle", "(", "image", ",", "(", "b", "[", "0", "]", ",", "b", "[", "1", "]", ")", ",", "(", "b", "[", "2", "]", ",", "b", "[", "3", "]", ")", ",", "color", ",", "thickness", ",", "cv2", ".", "LINE_AA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_caption": [[85, 96], ["numpy.array().astype", "cv2.putText", "cv2.putText", "numpy.array"], "function", ["None"], ["", "def", "draw_caption", "(", "image", ",", "box", ",", "caption", ")", ":", "\n", "    ", "\"\"\" Draws a caption above the box in an image.\n\n    # Arguments\n        image   : The image to draw on.\n        box     : A list of 4 elements (x1, y1, x2, y2).\n        caption : String containing the text to draw.\n    \"\"\"", "\n", "b", "=", "np", ".", "array", "(", "box", ")", ".", "astype", "(", "int", ")", "\n", "cv2", ".", "putText", "(", "image", ",", "caption", ",", "(", "b", "[", "0", "]", ",", "b", "[", "1", "]", "-", "10", ")", ",", "cv2", ".", "FONT_HERSHEY_PLAIN", ",", "1", ",", "(", "0", ",", "0", ",", "0", ")", ",", "2", ")", "\n", "cv2", ".", "putText", "(", "image", ",", "caption", ",", "(", "b", "[", "0", "]", ",", "b", "[", "1", "]", "-", "10", ")", ",", "cv2", ".", "FONT_HERSHEY_PLAIN", ",", "1", ",", "(", "255", ",", "255", ",", "255", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_boxes": [[98, 109], ["visualization.draw_box"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_box"], ["", "def", "draw_boxes", "(", "image", ",", "boxes", ",", "color", ",", "thickness", "=", "2", ")", ":", "\n", "    ", "\"\"\" Draws boxes on an image with a given color.\n\n    # Arguments\n        image     : The image to draw on.\n        boxes     : A [N, 4] matrix (x1, y1, x2, y2).\n        color     : The color of the boxes.\n        thickness : The thickness of the lines to draw boxes with.\n    \"\"\"", "\n", "for", "b", "in", "boxes", ":", "\n", "        ", "draw_box", "(", "image", ",", "b", ",", "color", ",", "thickness", "=", "thickness", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_detections": [[111, 135], ["numpy.where", "visualization.draw_box", "visualization.draw_caption", "colors.label_color", "label_to_name", "label_to_name"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_box", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_caption", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.colors.label_color", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name"], ["", "", "def", "draw_detections", "(", "image", ",", "boxes", ",", "scores", ",", "labels", ",", "dist", "=", "False", ",", "color", "=", "None", ",", "label_to_name", "=", "None", ",", "score_threshold", "=", "0.5", ")", ":", "\n", "    ", "\"\"\" Draws detections in an image.\n\n    # Arguments\n        image           : The image to draw on.\n        boxes           : A [N, 4] matrix (x1, y1, x2, y2).\n        scores          : A list of N classification scores.\n        labels          : A list of N labels.\n        color           : The color of the boxes. By default the color from keras_retinanet.utils.colors.label_color will be used.\n        label_to_name   : (optional) Functor for mapping a label to a name.\n        score_threshold : Threshold used for determining what detections to draw.\n    \"\"\"", "\n", "selection", "=", "np", ".", "where", "(", "scores", ">", "score_threshold", ")", "[", "0", "]", "\n", "\n", "for", "i", "in", "selection", ":", "\n", "        ", "c", "=", "color", "if", "color", "is", "not", "None", "else", "label_color", "(", "labels", "[", "i", "]", ")", "\n", "draw_box", "(", "image", ",", "boxes", "[", "i", ",", ":", "]", ",", "color", "=", "c", ")", "\n", "\n", "# draw labels", "\n", "if", "dist", "is", "False", ":", "\n", "            ", "caption", "=", "(", "label_to_name", "(", "labels", "[", "i", "]", ")", "if", "label_to_name", "else", "labels", "[", "i", "]", ")", "+", "': {0:.2f}'", ".", "format", "(", "scores", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "caption", "=", "(", "label_to_name", "(", "labels", "[", "i", "]", ")", "if", "label_to_name", "else", "labels", "[", "i", "]", ")", "+", "': {0:.2f}   {1:.2f}m'", ".", "format", "(", "scores", "[", "i", "]", ",", "dist", "[", "i", "]", ")", "\n", "", "draw_caption", "(", "image", ",", "boxes", "[", "i", ",", ":", "]", ",", "caption", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_annotations": [[137, 159], ["isinstance", "range", "visualization.draw_caption", "visualization.draw_box", "colors.label_color", "label_to_name"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_caption", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.visualization.draw_box", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.colors.label_color", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name"], ["", "", "def", "draw_annotations", "(", "image", ",", "annotations", ",", "color", "=", "(", "0", ",", "255", ",", "0", ")", ",", "label_to_name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Draws annotations in an image.\n\n    # Arguments\n        image         : The image to draw on.\n        annotations   : A [N, 5] matrix (x1, y1, x2, y2, label) or dictionary containing bboxes (shaped [N, 4]) and labels (shaped [N]).\n        color         : The color of the boxes. By default the color from keras_retinanet.utils.colors.label_color will be used.\n        label_to_name : (optional) Functor for mapping a label to a name.\n    \"\"\"", "\n", "if", "isinstance", "(", "annotations", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "annotations", "=", "{", "'bboxes'", ":", "annotations", "[", ":", ",", ":", "4", "]", ",", "'labels'", ":", "annotations", "[", ":", ",", "4", "]", "}", "\n", "\n", "", "assert", "(", "'bboxes'", "in", "annotations", ")", "\n", "assert", "(", "'labels'", "in", "annotations", ")", "\n", "assert", "(", "annotations", "[", "'bboxes'", "]", ".", "shape", "[", "0", "]", "==", "annotations", "[", "'labels'", "]", ".", "shape", "[", "0", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "annotations", "[", "'bboxes'", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "label", "=", "annotations", "[", "'labels'", "]", "[", "i", "]", "\n", "c", "=", "color", "if", "color", "is", "not", "None", "else", "label_color", "(", "label", ")", "\n", "caption", "=", "'{}'", ".", "format", "(", "label_to_name", "(", "label", ")", "if", "label_to_name", "else", "label", ")", "\n", "draw_caption", "(", "image", ",", "annotations", "[", "'bboxes'", "]", "[", "i", "]", ",", "caption", ")", "\n", "draw_box", "(", "image", ",", "annotations", "[", "'bboxes'", "]", "[", "i", "]", ",", "color", "=", "c", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.layer_shapes": [[12, 45], ["keras.utils.generic_utils.to_list", "enumerate", "layer.compute_output_shape", "Exception", "len"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.FilterDetections.compute_output_shape"], ["def", "layer_shapes", "(", "image_shape", ",", "model", ")", ":", "\n", "    ", "\"\"\"Compute layer shapes given input image shape and the model.\n\n    Args\n        image_shape: The shape of the image.\n        model: The model to use for computing how the image shape is transformed in the pyramid.\n\n    Returns\n        A dictionary mapping layer names to image shapes.\n    \"\"\"", "\n", "shape", "=", "{", "}", "\n", "\n", "input_shapes", "=", "to_list", "(", "model", ".", "input_shape", ")", "\n", "for", "i", ",", "input_name", "in", "enumerate", "(", "model", ".", "input_names", ")", ":", "\n", "# shape[input_name] = (None,) + image_shape", "\n", "        ", "shape", "[", "input_name", "]", "=", "input_shapes", "[", "i", "]", "\n", "if", "None", "in", "input_shapes", "[", "i", "]", "[", "1", ":", "]", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "raise", "Exception", "(", "\"Variable image size unsupported when multiple \\\n                    inputs are active.\"", ")", "\n", "", "else", ":", "\n", "                ", "shape", "[", "input_name", "]", "=", "(", "None", ",", ")", "+", "image_shape", "\n", "\n", "\n", "", "", "", "for", "layer", "in", "model", ".", "layers", "[", "1", ":", "]", ":", "\n", "        ", "nodes", "=", "layer", ".", "_inbound_nodes", "\n", "for", "node", "in", "nodes", ":", "\n", "            ", "inputs", "=", "[", "shape", "[", "lr", ".", "name", "]", "for", "lr", "in", "node", ".", "inbound_layers", "]", "\n", "if", "not", "inputs", ":", "\n", "                ", "continue", "\n", "", "shape", "[", "layer", ".", "name", "]", "=", "layer", ".", "compute_output_shape", "(", "inputs", "[", "0", "]", "if", "len", "(", "inputs", ")", "==", "1", "else", "inputs", ")", "\n", "\n", "", "", "return", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.make_shapes_callback": [[47, 56], ["anchor.layer_shapes"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.layer_shapes"], ["", "def", "make_shapes_callback", "(", "model", ")", ":", "\n", "    ", "\"\"\" Make a function for getting the shape of the pyramid levels.\n    \"\"\"", "\n", "def", "get_shapes", "(", "image_shape", ",", "pyramid_levels", ")", ":", "\n", "        ", "shape", "=", "layer_shapes", "(", "image_shape", ",", "model", ")", "\n", "image_shapes", "=", "[", "shape", "[", "\"P{}\"", ".", "format", "(", "level", ")", "]", "[", "1", ":", "3", "]", "for", "level", "in", "pyramid_levels", "]", "\n", "return", "image_shapes", "\n", "\n", "", "return", "get_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.guess_shapes": [[58, 71], ["numpy.array"], "function", ["None"], ["", "def", "guess_shapes", "(", "image_shape", ",", "pyramid_levels", ")", ":", "\n", "    ", "\"\"\"Guess shapes based on pyramid levels.\n\n    Args\n         image_shape: The shape of the image.\n         pyramid_levels: A list of what pyramid levels are used.\n\n    Returns\n        A list of image shapes at each pyramid level.\n    \"\"\"", "\n", "image_shape", "=", "np", ".", "array", "(", "image_shape", "[", ":", "2", "]", ")", "\n", "image_shapes", "=", "[", "(", "image_shape", "+", "2", "**", "x", "-", "1", ")", "//", "(", "2", "**", "x", ")", "for", "x", "in", "pyramid_levels", "]", "\n", "return", "image_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.anchors_for_shape": [[73, 113], ["shapes_callback", "numpy.zeros", "enumerate", "anchor.generate_anchors", "anchor.shift", "numpy.append"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.generate_anchors", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.common.shift"], ["", "def", "anchors_for_shape", "(", "\n", "image_shape", ",", "\n", "pyramid_levels", "=", "None", ",", "\n", "anchor_params", "=", "None", ",", "\n", "shapes_callback", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\" Generators anchors for a given shape.\n\n    Args\n        image_shape: The shape of the image.\n        pyramid_levels: List of ints representing which pyramids to use (defaults to [3, 4, 5, 6, 7]).\n        anchor_params: Struct containing anchor parameters. If None, default values are used.\n        shapes_callback: Function to call for getting the shape of the image at different pyramid levels.\n\n    Returns\n        np.array of shape (N, 4) containing the (x1, y1, x2, y2) coordinates for the anchors.\n    \"\"\"", "\n", "\n", "if", "pyramid_levels", "is", "None", ":", "\n", "        ", "pyramid_levels", "=", "[", "3", ",", "4", ",", "5", ",", "6", ",", "7", "]", "\n", "\n", "", "if", "anchor_params", "is", "None", ":", "\n", "        ", "anchor_params", "=", "AnchorParameters", ".", "default", "\n", "\n", "", "if", "shapes_callback", "is", "None", ":", "\n", "        ", "shapes_callback", "=", "guess_shapes", "\n", "", "image_shapes", "=", "shapes_callback", "(", "image_shape", ",", "pyramid_levels", ")", "\n", "\n", "# compute anchors over all pyramid levels", "\n", "all_anchors", "=", "np", ".", "zeros", "(", "(", "0", ",", "4", ")", ")", "\n", "for", "idx", ",", "p", "in", "enumerate", "(", "pyramid_levels", ")", ":", "\n", "        ", "anchors", "=", "generate_anchors", "(", "\n", "base_size", "=", "anchor_params", ".", "sizes", "[", "idx", "]", ",", "\n", "ratios", "=", "anchor_params", ".", "ratios", ",", "\n", "scales", "=", "anchor_params", ".", "scales", "\n", ")", "\n", "shifted_anchors", "=", "shift", "(", "image_shapes", "[", "idx", "]", ",", "anchor_params", ".", "strides", "[", "idx", "]", ",", "anchors", ")", "\n", "all_anchors", "=", "np", ".", "append", "(", "all_anchors", ",", "shifted_anchors", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "all_anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.shift": [[115, 145], ["numpy.meshgrid", "numpy.vstack().transpose", "all_anchors.reshape.reshape", "anchors.reshape", "np.vstack().transpose.reshape().transpose", "numpy.arange", "numpy.arange", "numpy.vstack", "np.vstack().transpose.reshape", "shift_x.ravel", "shift_y.ravel", "shift_x.ravel", "shift_y.ravel"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.meshgrid", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose"], ["", "def", "shift", "(", "shape", ",", "stride", ",", "anchors", ")", ":", "\n", "    ", "\"\"\" Produce shifted anchors based on shape of the map and stride size.\n\n    Args\n        shape  : Shape to shift the anchors over.\n        stride : Stride to shift the anchors with over the shape.\n        anchors: The anchors to apply at each location.\n    \"\"\"", "\n", "\n", "# create a grid starting from half stride from the top left corner", "\n", "shift_x", "=", "(", "np", ".", "arange", "(", "0", ",", "shape", "[", "1", "]", ")", "+", "0.5", ")", "*", "stride", "\n", "shift_y", "=", "(", "np", ".", "arange", "(", "0", ",", "shape", "[", "0", "]", ")", "+", "0.5", ")", "*", "stride", "\n", "\n", "shift_x", ",", "shift_y", "=", "np", ".", "meshgrid", "(", "shift_x", ",", "shift_y", ")", "\n", "\n", "shifts", "=", "np", ".", "vstack", "(", "(", "\n", "shift_x", ".", "ravel", "(", ")", ",", "shift_y", ".", "ravel", "(", ")", ",", "\n", "shift_x", ".", "ravel", "(", ")", ",", "shift_y", ".", "ravel", "(", ")", "\n", ")", ")", ".", "transpose", "(", ")", "\n", "\n", "# add A anchors (1, A, 4) to", "\n", "# cell K shifts (K, 1, 4) to get", "\n", "# shift anchors (K, A, 4)", "\n", "# reshape to (K*A, 4) shifted anchors", "\n", "A", "=", "anchors", ".", "shape", "[", "0", "]", "\n", "K", "=", "shifts", ".", "shape", "[", "0", "]", "\n", "all_anchors", "=", "(", "anchors", ".", "reshape", "(", "(", "1", ",", "A", ",", "4", ")", ")", "+", "shifts", ".", "reshape", "(", "(", "1", ",", "K", ",", "4", ")", ")", ".", "transpose", "(", "(", "1", ",", "0", ",", "2", ")", ")", ")", "\n", "all_anchors", "=", "all_anchors", ".", "reshape", "(", "(", "K", "*", "A", ",", "4", ")", ")", "\n", "\n", "return", "all_anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.generate_anchors": [[147, 179], ["numpy.zeros", "numpy.sqrt", "len", "len", "numpy.repeat", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.repeat", "len", "len", "len"], "function", ["None"], ["", "def", "generate_anchors", "(", "base_size", "=", "16", ",", "ratios", "=", "None", ",", "scales", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Generate anchor (reference) windows by enumerating aspect ratios X\n    scales w.r.t. a reference window.\n    \"\"\"", "\n", "\n", "if", "ratios", "is", "None", ":", "\n", "        ", "ratios", "=", "AnchorParameters", ".", "default", ".", "ratios", "\n", "\n", "", "if", "scales", "is", "None", ":", "\n", "        ", "scales", "=", "AnchorParameters", ".", "default", ".", "scales", "\n", "\n", "", "num_anchors", "=", "len", "(", "ratios", ")", "*", "len", "(", "scales", ")", "\n", "\n", "# initialize output anchors", "\n", "anchors", "=", "np", ".", "zeros", "(", "(", "num_anchors", ",", "4", ")", ")", "\n", "\n", "# scale base_size", "\n", "anchors", "[", ":", ",", "2", ":", "]", "=", "base_size", "*", "np", ".", "tile", "(", "scales", ",", "(", "2", ",", "len", "(", "ratios", ")", ")", ")", ".", "T", "\n", "\n", "# compute areas of anchors", "\n", "areas", "=", "anchors", "[", ":", ",", "2", "]", "*", "anchors", "[", ":", ",", "3", "]", "\n", "\n", "# correct for ratios", "\n", "anchors", "[", ":", ",", "2", "]", "=", "np", ".", "sqrt", "(", "areas", "/", "np", ".", "repeat", "(", "ratios", ",", "len", "(", "scales", ")", ")", ")", "\n", "anchors", "[", ":", ",", "3", "]", "=", "anchors", "[", ":", ",", "2", "]", "*", "np", ".", "repeat", "(", "ratios", ",", "len", "(", "scales", ")", ")", "\n", "\n", "# transform from (x_ctr, y_ctr, w, h) -> (x1, y1, x2, y2)", "\n", "anchors", "[", ":", ",", "0", ":", ":", "2", "]", "-=", "np", ".", "tile", "(", "anchors", "[", ":", ",", "2", "]", "*", "0.5", ",", "(", "2", ",", "1", ")", ")", ".", "T", "\n", "anchors", "[", ":", ",", "1", ":", ":", "2", "]", "-=", "np", ".", "tile", "(", "anchors", "[", ":", ",", "3", "]", "*", "0.5", ",", "(", "2", ",", "1", ")", ")", ".", "T", "\n", "\n", "return", "anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.bbox_transform": [[181, 213], ["isinstance", "isinstance", "numpy.stack", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "isinstance", "ValueError", "isinstance", "ValueError", "type", "type"], "function", ["None"], ["", "def", "bbox_transform", "(", "anchors", ",", "gt_boxes", ",", "mean", "=", "None", ",", "std", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute bounding-box regression targets for an image.\"\"\"", "\n", "\n", "if", "mean", "is", "None", ":", "\n", "        ", "mean", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "if", "std", "is", "None", ":", "\n", "        ", "std", "=", "np", ".", "array", "(", "[", "0.2", ",", "0.2", ",", "0.2", ",", "0.2", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "mean", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n", "", "elif", "not", "isinstance", "(", "mean", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Expected mean to be a np.ndarray, list or tuple. Received: {}'", ".", "format", "(", "type", "(", "mean", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "std", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "std", "=", "np", ".", "array", "(", "std", ")", "\n", "", "elif", "not", "isinstance", "(", "std", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Expected std to be a np.ndarray, list or tuple. Received: {}'", ".", "format", "(", "type", "(", "std", ")", ")", ")", "\n", "\n", "", "anchor_widths", "=", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "\n", "anchor_heights", "=", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "\n", "\n", "targets_dx1", "=", "(", "gt_boxes", "[", ":", ",", "0", "]", "-", "anchors", "[", ":", ",", "0", "]", ")", "/", "anchor_widths", "\n", "targets_dy1", "=", "(", "gt_boxes", "[", ":", ",", "1", "]", "-", "anchors", "[", ":", ",", "1", "]", ")", "/", "anchor_heights", "\n", "targets_dx2", "=", "(", "gt_boxes", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "2", "]", ")", "/", "anchor_widths", "\n", "targets_dy2", "=", "(", "gt_boxes", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "3", "]", ")", "/", "anchor_heights", "\n", "\n", "targets", "=", "np", ".", "stack", "(", "(", "targets_dx1", ",", "targets_dy1", ",", "targets_dx2", ",", "targets_dy2", ")", ")", "\n", "targets", "=", "targets", ".", "T", "\n", "\n", "targets", "=", "(", "targets", "-", "mean", ")", "/", "std", "\n", "\n", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.compute_gt_annotations": [[214, 241], ["anchor_calc.compute_overlap", "numpy.argmax", "anchors.astype", "annotations.astype", "numpy.arange"], "function", ["None"], ["", "def", "compute_gt_annotations", "(", "\n", "anchors", ",", "\n", "annotations", ",", "\n", "negative_overlap", "=", "0.4", ",", "\n", "positive_overlap", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\" Obtain indices of gt annotations with the greatest overlap.\n    Args\n        anchors: np.array of annotations of shape (N, 4) for (x1, y1, x2, y2).\n        annotations: np.array of shape (N, 5) for (x1, y1, x2, y2, label).\n        negative_overlap: IoU overlap for negative anchors (all anchors with overlap < negative_overlap are negative).\n        positive_overlap: IoU overlap or positive anchors (all anchors with overlap > positive_overlap are positive).\n    Returns\n        positive_indices: indices of positive anchors\n        ignore_indices: indices of ignored anchors\n        argmax_overlaps_inds: ordered overlaps indices\n    \"\"\"", "\n", "\n", "overlaps", "=", "compute_overlap", "(", "anchors", ".", "astype", "(", "np", ".", "float64", ")", ",", "annotations", ".", "astype", "(", "np", ".", "float64", ")", ")", "\n", "argmax_overlaps_inds", "=", "np", ".", "argmax", "(", "overlaps", ",", "axis", "=", "1", ")", "\n", "max_overlaps", "=", "overlaps", "[", "np", ".", "arange", "(", "overlaps", ".", "shape", "[", "0", "]", ")", ",", "argmax_overlaps_inds", "]", "\n", "\n", "# assign \"dont care\" labels", "\n", "positive_indices", "=", "max_overlaps", ">=", "positive_overlap", "\n", "ignore_indices", "=", "(", "max_overlaps", ">", "negative_overlap", ")", "&", "~", "positive_indices", "\n", "\n", "return", "positive_indices", ",", "ignore_indices", ",", "argmax_overlaps_inds", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.noise_img.psnr": [[21, 27], ["numpy.mean", "math.log10", "math.sqrt"], "function", ["None"], ["def", "psnr", "(", "img1", ",", "img2", ")", ":", "\n", "    ", "mse", "=", "np", ".", "mean", "(", "(", "img1", "-", "img2", ")", "**", "2", ")", "\n", "if", "mse", "==", "0", ":", "\n", "        ", "mse", "=", "1e-10", "\n", "", "PIXEL_MAX", "=", "1.0", "\n", "return", "20", "*", "math", ".", "log10", "(", "PIXEL_MAX", "/", "math", ".", "sqrt", "(", "mse", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.noise_img.noisy": [[28, 98], ["numpy.random.normal", "numpy.copy", "numpy.ceil", "numpy.ceil", "numpy.random.randint", "numpy.random.randint", "numpy.copy", "numpy.ceil", "numpy.ceil", "int", "int", "numpy.random.randint", "numpy.random.randint", "int", "tuple", "int", "tuple", "len", "numpy.ceil", "numpy.random.poisson", "float", "numpy.random.randn", "gauss.reshape.reshape", "numpy.unique", "numpy.log2", "int", "cv2.GaussianBlur"], "function", ["None"], ["", "def", "noisy", "(", "noise_typ", ",", "image", ",", "noise_factor", ")", ":", "\n", "    ", "\"\"\"\n    image : ndarray Input image data. Will be converted to float.\n    noise_typ : str\n    One of the following strings, selecting the type of noise to add:\n\n    'gauss'     Gaussian-distributed additive noise.\n    'poisson'   Poisson-distributed noise generated from the data.\n    's&p'       Replaces random pixels with 0 or 1.\n    'speckle'   Multiplicative noise using out = image + n*image,where\n                n is uniform noise with specified mean & variance.\n    \"\"\"", "\n", "if", "noise_typ", "==", "\"gauss\"", ":", "\n", "        ", "row", ",", "col", ",", "ch", "=", "image", ".", "shape", "\n", "mean", "=", "0", "\n", "var", "=", "noise_factor", "\n", "sigma", "=", "var", "**", "0.5", "\n", "gauss", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "sigma", ",", "(", "row", ",", "col", ",", "ch", ")", ")", "\n", "noisy", "=", "image", "+", "gauss", "\n", "return", "noisy", "\n", "", "elif", "noise_typ", "==", "\"s&p-perchannel\"", ":", "\n", "        ", "row", ",", "col", ",", "ch", "=", "image", ".", "shape", "\n", "s_vs_p", "=", "0.5", "\n", "amount", "=", "noise_factor", "\n", "out", "=", "np", ".", "copy", "(", "image", ")", "\n", "# Salt mode", "\n", "num_salt", "=", "np", ".", "ceil", "(", "amount", "*", "image", ".", "size", "*", "s_vs_p", ")", "\n", "coords", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "i", "-", "1", ",", "int", "(", "num_salt", ")", ")", "\n", "for", "i", "in", "image", ".", "shape", "]", "\n", "out", "[", "coords", "]", "=", "1", "\n", "\n", "# Pepper mode", "\n", "num_pepper", "=", "np", ".", "ceil", "(", "amount", "*", "image", ".", "size", "*", "(", "1.", "-", "s_vs_p", ")", ")", "\n", "coords", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "i", "-", "1", ",", "int", "(", "num_pepper", ")", ")", "\n", "for", "i", "in", "image", ".", "shape", "]", "\n", "out", "[", "coords", "]", "=", "0", "\n", "return", "out", "\n", "", "elif", "noise_typ", "==", "\"s&p-perpixel\"", ":", "\n", "        ", "row", ",", "col", ",", "ch", "=", "image", ".", "shape", "\n", "s_vs_p", "=", "0.5", "\n", "amount", "=", "noise_factor", "\n", "out", "=", "np", ".", "copy", "(", "image", ")", "\n", "# Salt mode", "\n", "num_salt", "=", "np", ".", "ceil", "(", "amount", "*", "image", ".", "shape", "[", "0", "]", "*", "image", ".", "shape", "[", "1", "]", "*", "s_vs_p", ")", "\n", "coords", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "i", "-", "1", ",", "int", "(", "num_salt", ")", ")", "\n", "for", "i", "in", "image", ".", "shape", "[", "0", ":", "2", "]", "]", "\n", "out", "[", "tuple", "(", "coords", ")", "]", "=", "1", "\n", "\n", "# Pepper mode", "\n", "num_pepper", "=", "np", ".", "ceil", "(", "amount", "*", "image", ".", "shape", "[", "0", "]", "*", "image", ".", "shape", "[", "1", "]", "*", "(", "1.", "-", "s_vs_p", ")", ")", "\n", "coords", "=", "[", "np", ".", "random", ".", "randint", "(", "0", ",", "i", "-", "1", ",", "int", "(", "num_pepper", ")", ")", "\n", "for", "i", "in", "image", ".", "shape", "[", "0", ":", "2", "]", "]", "\n", "out", "[", "tuple", "(", "coords", ")", "]", "=", "0", "\n", "return", "out", "\n", "", "elif", "noise_typ", "==", "\"poisson\"", ":", "\n", "        ", "if", "noise_factor", "==", "0", ":", "\n", "            ", "return", "image", "\n", "", "vals", "=", "len", "(", "np", ".", "unique", "(", "image", ")", ")", "/", "noise_factor", "\n", "vals", "=", "2", "**", "np", ".", "ceil", "(", "np", ".", "log2", "(", "vals", ")", ")", "\n", "noisy", "=", "np", ".", "random", ".", "poisson", "(", "image", "*", "vals", ")", "/", "float", "(", "vals", ")", "\n", "return", "noisy", "\n", "", "elif", "noise_typ", "==", "\"speckle\"", ":", "\n", "        ", "row", ",", "col", ",", "ch", "=", "image", ".", "shape", "\n", "gauss", "=", "np", ".", "random", ".", "randn", "(", "row", ",", "col", ",", "ch", ")", "\n", "gauss", "=", "gauss", ".", "reshape", "(", "row", ",", "col", ",", "ch", ")", "\n", "noisy", "=", "image", "+", "image", "*", "gauss", "\n", "return", "noisy", "\n", "", "elif", "noise_typ", "==", "\"blur\"", ":", "\n", "        ", "noise_factor", "=", "int", "(", "noise_factor", ")", "\n", "return", "cv2", ".", "GaussianBlur", "(", "image", ",", "(", "noise_factor", ",", "noise_factor", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.noise_img.nothing": [[101, 103], ["None"], "function", ["None"], ["", "", "def", "nothing", "(", "x", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.model.freeze": [[18, 29], ["None"], "function", ["None"], ["def", "freeze", "(", "model", ")", ":", "\n", "    ", "\"\"\" Set all layers in a model to non-trainable.\n\n    The weights for these layers will not be updated during training.\n\n    This function modifies the given model in-place,\n    but it also returns the modified model to allow easy chaining with other functions.\n    \"\"\"", "\n", "for", "layer", "in", "model", ".", "layers", ":", "\n", "        ", "layer", ".", "trainable", "=", "False", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.makedirs": [[10, 20], ["os.makedirs", "os.path.isdir"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.makedirs"], ["def", "makedirs", "(", "path", ")", ":", "\n", "    ", "\"\"\" Try to create the directory, pass if the directory exists already, fails otherwise.\n    :param path:            <string>            directory path, that should be created\n\n    \"\"\"", "\n", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "", "except", "OSError", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.layer_to_index": [[21, 43], ["isinstance", "Exception", "enumerate", "isinstance", "TypeError", "str"], "function", ["None"], ["", "", "", "def", "layer_to_index", "(", "target_layer", ",", "model", ")", ":", "\n", "    ", "\"\"\"\n    Turns the identifier of an layer into a \n    layer index, regardless if it is a str or already index\n\n    :param target_layer: <str or int> identifier for the target layer. None will return None\n    :param model: <keras.Model> The model containing the target layer\n\n    :returns: <int> index of target layer\n    \"\"\"", "\n", "if", "target_layer", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "target_layer", ",", "str", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "model", ".", "layers", ")", ":", "\n", "            ", "if", "layer", ".", "name", "==", "target_layer", ":", "\n", "                ", "return", "idx", "\n", "", "", "", "elif", "isinstance", "(", "target_layer", ",", "int", ")", ":", "\n", "        ", "return", "target_layer", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "\"layer has to be int or str\"", ")", "\n", "\n", "", "raise", "Exception", "(", "\"Layer %s could not be found\"", "%", "(", "str", "(", "target_layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.tb_write_images": [[44, 58], ["zip", "[].tostring", "tensorflow.image.decode_jpeg", "tensorflow.expand_dims", "tensorflow.summary.image", "callback.writer.add_summary", "callback.writer.flush", "tf.summary.image.eval", "cv2.imencode", "tensorflow.Session"], "function", ["None"], ["", "def", "tb_write_images", "(", "callback", ",", "names", ",", "imgs", ")", ":", "\n", "    ", "\"\"\"\n    :param callback: <tensorflow.python.keras.callbacks.TensorBoard> Tensorboard callback\n    :param names: <list of str> headings for the iamges\n    :param imgs: <list of numpy.array> Images as Bitmaps\n    \"\"\"", "\n", "for", "name", ",", "img", "in", "zip", "(", "names", ",", "imgs", ")", ":", "\n", "        ", "tf_img_enc", "=", "cv2", ".", "imencode", "(", "'.jpg'", ",", "img", ")", "[", "1", "]", ".", "tostring", "(", ")", "\n", "tf_img_tensor", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "tf_img_enc", ",", "channels", "=", "3", ")", "\n", "tf_img_tensor", "=", "tf", ".", "expand_dims", "(", "tf_img_tensor", ",", "axis", "=", "0", ")", "\n", "\n", "imgsumarry", "=", "tf", ".", "summary", ".", "image", "(", "name", ",", "tf_img_tensor", ",", "max_outputs", "=", "3", ",", "collections", "=", "None", ")", "\n", "callback", ".", "writer", ".", "add_summary", "(", "imgsumarry", ".", "eval", "(", "session", "=", "tf", ".", "Session", "(", ")", ")", ")", "\n", "callback", ".", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.tb_write_texts": [[59, 70], ["zip", "tensorflow.summary.text", "callback.writer.add_summary", "callback.writer.flush", "tensorflow.convert_to_tensor", "tf.summary.text.eval", "tensorflow.keras.backend.get_session"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.get_session"], ["", "", "def", "tb_write_texts", "(", "callback", ",", "names", ",", "texts", ")", ":", "\n", "    ", "\"\"\"\n    :param callback: <tensorflow.python.keras.callbacks.TensorBoard> Tensorboard callback\n    :param names: <list of str> headings for the texts\n    :param imgs: <list of str> Contents \n    \"\"\"", "\n", "\n", "for", "name", ",", "text", "in", "zip", "(", "names", ",", "texts", ")", ":", "\n", "        ", "txtsummary", "=", "tf", ".", "summary", ".", "text", "(", "name", ",", "tf", ".", "convert_to_tensor", "(", "text", ")", ")", "\n", "callback", ".", "writer", ".", "add_summary", "(", "txtsummary", ".", "eval", "(", "session", "=", "tf", ".", "keras", ".", "backend", ".", "get_session", "(", ")", ")", ")", "\n", "callback", ".", "writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.initialize_seed": [[72, 89], ["random.seed", "numpy.random.seed", "hasattr", "tensorflow.set_random_seed", "hasattr", "tensorflow.random.set_random_seed", "hasattr", "tensorflow.random.set_seed", "AttributeError"], "function", ["None"], ["", "", "def", "initialize_seed", "(", "seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    This makes experiments more comparable by\n    forcing the random number generator to produce\n    the same numbers in each run\n    \"\"\"", "\n", "random", ".", "seed", "(", "a", "=", "seed", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "if", "hasattr", "(", "tf", ",", "'set_random_seed'", ")", ":", "\n", "        ", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "", "elif", "hasattr", "(", "tf", ".", "random", ",", "'set_random_seed'", ")", ":", "\n", "        ", "tf", ".", "random", ".", "set_random_seed", "(", "seed", ")", "\n", "", "elif", "hasattr", "(", "tf", ".", "random", ",", "'set_seed'", ")", ":", "\n", "        ", "tf", ".", "random", ".", "set_seed", "(", "seed", ")", "\n", "", "else", ":", "\n", "        ", "raise", "AttributeError", "(", "\"Could not set seed for TensorFlow\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.get_session": [[91, 108], ["tensorflow.ConfigProto", "tensorflow.Session", "tensorflow.GPUOptions", "tensorflow.GPUOptions"], "function", ["None"], ["", "", "def", "get_session", "(", "gpu_usage", "=", "None", ")", ":", "\n", "    ", "\"\"\" Construct a modified tf session.\n\n    :param gpu_usage:       <float>             GPU memory usage from 0 to 1, None for dynamic growth\n\n    :return tf.Session:     <tf.Session>        Tensorflow Session object\n    \"\"\"", "\n", "\n", "if", "gpu_usage", ":", "\n", "        ", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "gpu_usage", ",", "allow_growth", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "allow_growth", "=", "True", ")", "\n", "\n", "", "config", "=", "tf", ".", "ConfigProto", "(", "gpu_options", "=", "gpu_options", ")", "\n", "\n", "return", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.output_index_by_name": [[110, 119], ["enumerate"], "function", ["None"], ["", "def", "output_index_by_name", "(", "model", ",", "output_name", ")", ":", "\n", "    ", "\"\"\"\n    :param model: the keras model\n    :param output_name: the string name for a specific output\n\n    :returns: <int> specifying the index of the requested output\n    \"\"\"", "\n", "name_to_index", "=", "{", "name", ":", "i", "for", "i", ",", "name", "in", "enumerate", "(", "model", ".", "output_names", ")", "}", "\n", "return", "name_to_index", "[", "output_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.helpers.input_index_by_name": [[121, 130], ["enumerate"], "function", ["None"], ["", "def", "input_index_by_name", "(", "model", ",", "input_name", ")", ":", "\n", "    ", "\"\"\"\n    :param model: the keras model\n    :param output_name: the string name for a specific output\n\n    :returns: <int> specifying the index of the requested output\n    \"\"\"", "\n", "name_to_index", "=", "{", "name", ":", "i", "for", "i", ",", "name", "in", "enumerate", "(", "model", ".", "input_names", ")", "}", "\n", "return", "name_to_index", "[", "input_name", "]", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.colvec": [[24, 27], ["numpy.array"], "function", ["None"], ["def", "colvec", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\" Create a numpy array representing a column vector. \"\"\"", "\n", "return", "np", ".", "array", "(", "[", "args", "]", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.transform_aabb": [[29, 57], ["transform.dot", "transform.dot.min", "transform.dot.max"], "function", ["None"], ["", "def", "transform_aabb", "(", "transform", ",", "aabb", ")", ":", "\n", "    ", "\"\"\" Apply a transformation to an axis aligned bounding box.\n\n    The result is a new AABB in the same coordinate system as the original AABB.\n    The new AABB contains all corner points of the original AABB after applying the given transformation.\n\n    Args\n        transform: The transformation to apply.\n        x1:        The minimum x value of the AABB.\n        y1:        The minimum y value of the AABB.\n        x2:        The maximum x value of the AABB.\n        y2:        The maximum y value of the AABB.\n    Returns\n        The new AABB as tuple (x1, y1, x2, y2)\n    \"\"\"", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "aabb", "\n", "# Transform all 4 corners of the AABB.", "\n", "points", "=", "transform", ".", "dot", "(", "[", "\n", "[", "x1", ",", "x2", ",", "x1", ",", "x2", "]", ",", "\n", "[", "y1", ",", "y2", ",", "y2", ",", "y1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", ")", "\n", "\n", "# Extract the min and max corners again.", "\n", "min_corner", "=", "points", ".", "min", "(", "axis", "=", "1", ")", "\n", "max_corner", "=", "points", ".", "max", "(", "axis", "=", "1", ")", "\n", "\n", "return", "[", "min_corner", "[", "0", "]", ",", "min_corner", "[", "1", "]", ",", "max_corner", "[", "0", "]", ",", "max_corner", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform._random_vector": [[59, 70], ["numpy.array", "numpy.array", "prng.uniform", "len"], "function", ["None"], ["", "def", "_random_vector", "(", "min", ",", "max", ",", "prng", "=", "DEFAULT_PRNG", ")", ":", "\n", "    ", "\"\"\" Construct a random vector between min and max.\n    Args\n        min: the minimum value for each component\n        max: the maximum value for each component\n    \"\"\"", "\n", "min", "=", "np", ".", "array", "(", "min", ")", "\n", "max", "=", "np", ".", "array", "(", "max", ")", "\n", "assert", "min", ".", "shape", "==", "max", ".", "shape", "\n", "assert", "len", "(", "min", ".", "shape", ")", "==", "1", "\n", "return", "prng", ".", "uniform", "(", "min", ",", "max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.rotation": [[72, 83], ["numpy.array", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["", "def", "rotation", "(", "angle", ")", ":", "\n", "    ", "\"\"\" Construct a homogeneous 2D rotation matrix.\n    Args\n        angle: the angle in radians\n    Returns\n        the rotation matrix as 3 by 3 numpy array\n    \"\"\"", "\n", "return", "np", ".", "array", "(", "[", "\n", "[", "np", ".", "cos", "(", "angle", ")", ",", "-", "np", ".", "sin", "(", "angle", ")", ",", "0", "]", ",", "\n", "[", "np", ".", "sin", "(", "angle", ")", ",", "np", ".", "cos", "(", "angle", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_rotation": [[86, 96], ["transform.rotation", "prng.uniform"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.rotation"], ["", "def", "random_rotation", "(", "min", ",", "max", ",", "prng", "=", "DEFAULT_PRNG", ")", ":", "\n", "    ", "\"\"\" Construct a random rotation between -max and max.\n    Args\n        min:  a scalar for the minimum absolute angle in radians\n        max:  a scalar for the maximum absolute angle in radians\n        prng: the pseudo-random number generator to use.\n    Returns\n        a homogeneous 3 by 3 rotation matrix\n    \"\"\"", "\n", "return", "rotation", "(", "prng", ".", "uniform", "(", "min", ",", "max", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.translation": [[98, 109], ["numpy.array"], "function", ["None"], ["", "def", "translation", "(", "translation", ")", ":", "\n", "    ", "\"\"\" Construct a homogeneous 2D translation matrix.\n    # Arguments\n        translation: the translation 2D vector\n    # Returns\n        the translation matrix as 3 by 3 numpy array\n    \"\"\"", "\n", "return", "np", ".", "array", "(", "[", "\n", "[", "1", ",", "0", ",", "translation", "[", "0", "]", "]", ",", "\n", "[", "0", ",", "1", ",", "translation", "[", "1", "]", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_translation": [[112, 122], ["transform.translation", "transform._random_vector"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.translation", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform._random_vector"], ["", "def", "random_translation", "(", "min", ",", "max", ",", "prng", "=", "DEFAULT_PRNG", ")", ":", "\n", "    ", "\"\"\" Construct a random 2D translation between min and max.\n    Args\n        min:  a 2D vector with the minimum translation for each dimension\n        max:  a 2D vector with the maximum translation for each dimension\n        prng: the pseudo-random number generator to use.\n    Returns\n        a homogeneous 3 by 3 translation matrix\n    \"\"\"", "\n", "return", "translation", "(", "_random_vector", "(", "min", ",", "max", ",", "prng", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.shear": [[124, 135], ["numpy.array", "numpy.cos", "numpy.sin"], "function", ["None"], ["", "def", "shear", "(", "angle", ")", ":", "\n", "    ", "\"\"\" Construct a homogeneous 2D shear matrix.\n    Args\n        angle: the shear angle in radians\n    Returns\n        the shear matrix as 3 by 3 numpy array\n    \"\"\"", "\n", "return", "np", ".", "array", "(", "[", "\n", "[", "1", ",", "-", "np", ".", "sin", "(", "angle", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "np", ".", "cos", "(", "angle", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_shear": [[138, 148], ["transform.shear", "prng.uniform"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.shear"], ["", "def", "random_shear", "(", "min", ",", "max", ",", "prng", "=", "DEFAULT_PRNG", ")", ":", "\n", "    ", "\"\"\" Construct a random 2D shear matrix with shear angle between -max and max.\n    Args\n        min:  the minimum shear angle in radians.\n        max:  the maximum shear angle in radians.\n        prng: the pseudo-random number generator to use.\n    Returns\n        a homogeneous 3 by 3 shear matrix\n    \"\"\"", "\n", "return", "shear", "(", "prng", ".", "uniform", "(", "min", ",", "max", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.scaling": [[150, 161], ["numpy.array"], "function", ["None"], ["", "def", "scaling", "(", "factor", ")", ":", "\n", "    ", "\"\"\" Construct a homogeneous 2D scaling matrix.\n    Args\n        factor: a 2D vector for X and Y scaling\n    Returns\n        the zoom matrix as 3 by 3 numpy array\n    \"\"\"", "\n", "return", "np", ".", "array", "(", "[", "\n", "[", "factor", "[", "0", "]", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "factor", "[", "1", "]", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_scaling": [[164, 174], ["transform.scaling", "transform._random_vector"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.scaling", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform._random_vector"], ["", "def", "random_scaling", "(", "min", ",", "max", ",", "prng", "=", "DEFAULT_PRNG", ")", ":", "\n", "    ", "\"\"\" Construct a random 2D scale matrix between -max and max.\n    Args\n        min:  a 2D vector containing the minimum scaling factor for X and Y.\n        min:  a 2D vector containing The maximum scaling factor for X and Y.\n        prng: the pseudo-random number generator to use.\n    Returns\n        a homogeneous 3 by 3 scaling matrix\n    \"\"\"", "\n", "return", "scaling", "(", "_random_vector", "(", "min", ",", "max", ",", "prng", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_flip": [[176, 189], ["transform.scaling", "prng.uniform", "prng.uniform"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.scaling"], ["", "def", "random_flip", "(", "flip_x_chance", ",", "flip_y_chance", ",", "prng", "=", "DEFAULT_PRNG", ")", ":", "\n", "    ", "\"\"\" Construct a transformation randomly containing X/Y flips (or not).\n    Args\n        flip_x_chance: The chance that the result will contain a flip along the X axis.\n        flip_y_chance: The chance that the result will contain a flip along the Y axis.\n        prng:          The pseudo-random number generator to use.\n    Returns\n        a homogeneous 3 by 3 transformation matrix\n    \"\"\"", "\n", "flip_x", "=", "prng", ".", "uniform", "(", "0", ",", "1", ")", "<", "flip_x_chance", "\n", "flip_y", "=", "prng", ".", "uniform", "(", "0", ",", "1", ")", "<", "flip_y_chance", "\n", "# 1 - 2 * bool gives 1 for False and -1 for True.", "\n", "return", "scaling", "(", "(", "1", "-", "2", "*", "flip_x", ",", "1", "-", "2", "*", "flip_y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.change_transform_origin": [[191, 202], ["numpy.array", "numpy.linalg.multi_dot", "transform.translation", "transform.translation"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.translation", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.translation"], ["", "def", "change_transform_origin", "(", "transform", ",", "center", ")", ":", "\n", "    ", "\"\"\" Create a new transform representing the same transformation,\n        only with the origin of the linear part changed.\n    Args\n        transform: the transformation matrix\n        center: the new origin of the transformation\n    Returns\n        translate(center) * transform * translate(-center)\n    \"\"\"", "\n", "center", "=", "np", ".", "array", "(", "center", ")", "\n", "return", "np", ".", "linalg", ".", "multi_dot", "(", "[", "translation", "(", "center", ")", ",", "transform", ",", "translation", "(", "-", "center", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_transform": [[204, 251], ["numpy.linalg.multi_dot", "transform.random_rotation", "transform.random_translation", "transform.random_shear", "transform.random_scaling", "transform.random_flip"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_rotation", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_translation", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_shear", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_scaling", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_flip"], ["", "def", "random_transform", "(", "\n", "min_rotation", "=", "0", ",", "\n", "max_rotation", "=", "0", ",", "\n", "min_translation", "=", "(", "0", ",", "0", ")", ",", "\n", "max_translation", "=", "(", "0", ",", "0", ")", ",", "\n", "min_shear", "=", "0", ",", "\n", "max_shear", "=", "0", ",", "\n", "min_scaling", "=", "(", "1", ",", "1", ")", ",", "\n", "max_scaling", "=", "(", "1", ",", "1", ")", ",", "\n", "flip_x_chance", "=", "0", ",", "\n", "flip_y_chance", "=", "0", ",", "\n", "prng", "=", "DEFAULT_PRNG", "\n", ")", ":", "\n", "    ", "\"\"\" Create a random transformation.\n\n    The transformation consists of the following operations in this order (from left to right):\n      * rotation\n      * translation\n      * shear\n      * scaling\n      * flip x (if applied)\n      * flip y (if applied)\n\n    Note that by default, the data generators in `keras_retinanet.preprocessing.generators` interpret the translation\n    as factor of the image size. So an X translation of 0.1 would translate the image by 10% of it's width.\n    Set `relative_translation` to `False` in the `TransformParameters` of a data generator to have it interpret\n    the translation directly as pixel distances instead.\n\n    Args\n        min_rotation:    The minimum rotation in radians for the transform as scalar.\n        max_rotation:    The maximum rotation in radians for the transform as scalar.\n        min_translation: The minimum translation for the transform as 2D column vector.\n        max_translation: The maximum translation for the transform as 2D column vector.\n        min_shear:       The minimum shear angle for the transform in radians.\n        max_shear:       The maximum shear angle for the transform in radians.\n        min_scaling:     The minimum scaling for the transform as 2D column vector.\n        max_scaling:     The maximum scaling for the transform as 2D column vector.\n        flip_x_chance:   The chance (0 to 1) that a transform will contain a flip along X direction.\n        flip_y_chance:   The chance (0 to 1) that a transform will contain a flip along Y direction.\n        prng:            The pseudo-random number generator to use.\n    \"\"\"", "\n", "return", "np", ".", "linalg", ".", "multi_dot", "(", "[", "\n", "random_rotation", "(", "min_rotation", ",", "max_rotation", ",", "prng", ")", ",", "\n", "random_translation", "(", "min_translation", ",", "max_translation", ",", "prng", ")", ",", "\n", "random_shear", "(", "min_shear", ",", "max_shear", ",", "prng", ")", ",", "\n", "random_scaling", "(", "min_scaling", ",", "max_scaling", ",", "prng", ")", ",", "\n", "random_flip", "(", "flip_x_chance", ",", "flip_y_chance", ",", "prng", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_transform_generator": [[254, 292], ["numpy.random.RandomState", "transform.random_transform"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_transform"], ["", "def", "random_transform_generator", "(", "prng", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Create a random transform generator.\n\n    Uses a dedicated, newly created, properly seeded PRNG by default instead of the global DEFAULT_PRNG.\n\n    The transformation consists of the following operations in this order (from left to right):\n      * rotation\n      * translation\n      * shear\n      * scaling\n      * flip x (if applied)\n      * flip y (if applied)\n\n    Note that by default, the data generators in `keras_retinanet.preprocessing.generators` interpret the translation\n    as factor of the image size. So an X translation of 0.1 would translate the image by 10% of it's width.\n    Set `relative_translation` to `False` in the `TransformParameters` of a data generator to have it interpret\n    the translation directly as pixel distances instead.\n\n    Args\n        min_rotation:    The minimum rotation in radians for the transform as scalar.\n        max_rotation:    The maximum rotation in radians for the transform as scalar.\n        min_translation: The minimum translation for the transform as 2D column vector.\n        max_translation: The maximum translation for the transform as 2D column vector.\n        min_shear:       The minimum shear angle for the transform in radians.\n        max_shear:       The maximum shear angle for the transform in radians.\n        min_scaling:     The minimum scaling for the transform as 2D column vector.\n        max_scaling:     The maximum scaling for the transform as 2D column vector.\n        flip_x_chance:   The chance (0 to 1) that a transform will contain a flip along X direction.\n        flip_y_chance:   The chance (0 to 1) that a transform will contain a flip along Y direction.\n        prng:            The pseudo-random number generator to use.\n    \"\"\"", "\n", "\n", "if", "prng", "is", "None", ":", "\n", "# RandomState automatically seeds using the best available method.", "\n", "        ", "prng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "", "while", "True", ":", "\n", "        ", "yield", "random_transform", "(", "prng", "=", "prng", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.normalize": [[116, 137], ["isinstance", "max"], "function", ["None"], ["def", "normalize", "(", "channel", ",", "value", ",", "normalization_interval", "=", "(", "-", "1", ",", "1", ")", ",", "sigma_factor", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    :param channel: the radar channel of the corresponding radar_channel map\n    :param value: <float or numpy.array> the value to normalize\n    :param sigma_factor: multiples of sigma used for normalizing the value\n\n    :returns: the normalized channel values\n    \"\"\"", "\n", "if", "isinstance", "(", "channel", ",", "int", ")", ":", "\n", "# convert channel integer into string", "\n", "        ", "channel", "=", "channel_map", "[", "channel", "]", "\n", "\n", "", "if", "normalizing_mask", "[", "channel", "]", ":", "\n", "        ", "std", "=", "max", "(", "std_map", "[", "channel", "]", ",", "MINIMAL_STD", ")", "# we do not want to divide by 0", "\n", "normalized_value", "=", "(", "value", "-", "mean_map", "[", "channel", "]", ")", "/", "(", "std", "*", "sigma_factor", ")", "# standardize to [-1, 1]", "\n", "normalized_value", "=", "(", "(", "normalized_value", "+", "1", ")", "/", "2", ")", "# standardize to [0, 1]", "\n", "normalized_value", "=", "(", "normalized_value", "*", "(", "normalization_interval", "[", "1", "]", "-", "normalization_interval", "[", "0", "]", ")", ")", "+", "normalization_interval", "[", "0", "]", "# normalization interval", "\n", "return", "normalized_value", "\n", "", "else", ":", "\n", "# The value is ignored by the normalizing mask", "\n", "        ", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.denormalize": [[139, 161], ["isinstance", "max"], "function", ["None"], ["", "", "def", "denormalize", "(", "channel", ",", "value", ",", "normalization_interval", "=", "(", "-", "1", ",", "1", ")", ",", "sigma_factor", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    :param channel: the radar channel of the corresponding radar_channel map\n    :param value: <float or numpy.array> the value to normalize\n    :param sigma_factor: multiples of sigma used for normalizing the value\n\n    :returns: the normalized channel values\n    \"\"\"", "\n", "if", "isinstance", "(", "channel", ",", "int", ")", ":", "\n", "# convert channel integer into string", "\n", "        ", "channel", "=", "channel_map", "[", "channel", "]", "\n", "\n", "", "if", "normalizing_mask", "[", "channel", "]", ":", "\n", "        ", "std", "=", "max", "(", "std_map", "[", "channel", "]", ",", "MINIMAL_STD", ")", "\n", "\n", "denormalized_value", "=", "(", "value", "-", "normalization_interval", "[", "0", "]", ")", "/", "(", "normalization_interval", "[", "1", "]", "-", "normalization_interval", "[", "0", "]", ")", "# [0,1]", "\n", "denormalized_value", "=", "(", "(", "denormalized_value", "*", "2", ")", "-", "1", ")", "# standardize to [-1, 1]", "\n", "denormalized_value", "=", "denormalized_value", "*", "(", "std", "*", "sigma_factor", ")", "+", "mean_map", "[", "channel", "]", "\n", "return", "denormalized_value", "\n", "", "else", ":", "\n", "# The value is ignored by the normalizing mask", "\n", "        ", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.filter_radar_byDist": [[162, 177], ["range", "numpy.sqrt", "numpy.delete"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "", "def", "filter_radar_byDist", "(", "radar_data", ",", "distance", ")", ":", "\n", "    ", "\"\"\"\n    :param radar_data: axis0 is channels, axis1 is points\n    :param distance: [float] -1 for no distance filtering\n    \"\"\"", "\n", "if", "distance", ">", "0", ":", "\n", "        ", "no_of_points", "=", "radar_data", ".", "shape", "[", "1", "]", "\n", "deleter", "=", "0", "\n", "for", "point", "in", "range", "(", "0", ",", "no_of_points", ")", ":", "\n", "            ", "dist", "=", "np", ".", "sqrt", "(", "radar_data", "[", "0", ",", "point", "-", "deleter", "]", "**", "2", "+", "radar_data", "[", "1", ",", "point", "-", "deleter", "]", "**", "2", ")", "\n", "if", "dist", ">", "distance", ":", "\n", "                ", "radar_data", "=", "np", ".", "delete", "(", "radar_data", ",", "point", "-", "deleter", ",", "1", ")", "\n", "deleter", "+=", "1", "\n", "\n", "", "", "", "return", "radar_data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.calculate_distances": [[178, 184], ["numpy.sqrt"], "function", ["None"], ["", "def", "calculate_distances", "(", "radar_data", ")", ":", "\n", "    ", "\"\"\"\n    :param radar_data: axis0 is channels, axis1 is points\n    \"\"\"", "\n", "dist", "=", "np", ".", "sqrt", "(", "radar_data", "[", "0", ",", ":", "]", "**", "2", "+", "radar_data", "[", "1", ",", ":", "]", "**", "2", ")", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.enrich_radar_data": [[186, 243], ["numpy.sqrt", "numpy.expand_dims", "numpy.arctan2", "numpy.expand_dims", "numpy.array", "numpy.array", "numpy.sum", "numpy.concatenate", "numpy.linalg.norm"], "function", ["None"], ["", "def", "enrich_radar_data", "(", "radar_data", ")", ":", "\n", "    ", "\"\"\"\n    This function adds additional data to the given radar data\n    \n    :param radar_data: The source data which are used to calculate additional metadata\n        Semantics: x y z dyn_prop id rcs vx vy vx_comp vy_comp is_quality_valid ambig_state x_rms y_rms invalid_state pdh0\n\n    :returns enriched_radar_data:\n            [0]: x\n            [1]: y\n            [2]: z\n            [3]: dyn_prop\n            [4]: id\n            [5]: rcs\n            [6]: vx\n            [7]: vy\n            [8]: vx_comp\n            [9]: vy_comp\n            [10]: is_quality_valid\n            [11]: ambig_state\n            [12]: x_rms\n            [13]: y_rms\n            [14]: invalid_state\n            [15]: pdh0\n            [16]: vx_rms\n            [17]: vy_rms\n            [18]: distance\n            [19]: azimuth\n            [20]: vrad_comp\n    \"\"\"", "\n", "assert", "radar_data", ".", "shape", "[", "0", "]", "==", "18", ",", "\"Channel count mismatch.\"", "\n", "\n", "# Adding distance", "\n", "# Calculate distance", "\n", "dist", "=", "np", ".", "sqrt", "(", "radar_data", "[", "0", ",", ":", "]", "**", "2", "+", "radar_data", "[", "1", ",", ":", "]", "**", "2", ")", "\n", "dist", "=", "np", ".", "expand_dims", "(", "dist", ",", "axis", "=", "0", ")", "\n", "\n", "# calculate the azimuth values", "\n", "azimuth", "=", "np", ".", "arctan2", "(", "radar_data", "[", "1", ",", ":", "]", ",", "radar_data", "[", "0", ",", ":", "]", ")", "\n", "azimuth", "=", "np", ".", "expand_dims", "(", "azimuth", ",", "axis", "=", "0", ")", "\n", "\n", "# Calculate vrad comp", "\n", "radial", "=", "np", ".", "array", "(", "[", "radar_data", "[", "0", ",", ":", "]", ",", "radar_data", "[", "1", ",", ":", "]", "]", ")", "# Calculate the distance vector", "\n", "radial", "=", "radial", "/", "np", ".", "linalg", ".", "norm", "(", "radial", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "# Normalize these vectors", "\n", "v", "=", "np", ".", "array", "(", "[", "radar_data", "[", "8", ",", ":", "]", ",", "radar_data", "[", "9", ",", ":", "]", "]", ")", "# Create the speed vector", "\n", "vrad_comp", "=", "np", ".", "sum", "(", "v", "*", "radial", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "# Project the speed component onto this vector", "\n", "\n", "data_collections", "=", "[", "\n", "radar_data", ",", "\n", "dist", ",", "\n", "azimuth", ",", "\n", "vrad_comp", "\n", "]", "\n", "\n", "enriched_radar_data", "=", "np", ".", "concatenate", "(", "data_collections", ",", "axis", "=", "0", ")", "\n", "\n", "return", "enriched_radar_data", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_parameters.AnchorParameters.__init__": [[32, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sizes", ",", "strides", ",", "ratios", ",", "scales", ")", ":", "\n", "        ", "self", ".", "sizes", "=", "sizes", "\n", "self", ".", "strides", "=", "strides", "\n", "self", ".", "ratios", "=", "ratios", "\n", "self", ".", "scales", "=", "scales", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_parameters.AnchorParameters.num_anchors": [[38, 40], ["len", "len"], "methods", ["None"], ["", "def", "num_anchors", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ratios", ")", "*", "len", "(", "self", ".", "scales", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.__init__": [[22, 29], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ",", "\n", "callback", ",", "\n", "model", ")", ":", "\n", "        ", "super", "(", "RedirectModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "callback", "=", "callback", "\n", "self", ".", "redirect_model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_epoch_begin": [[30, 32], ["callbacks.RedirectModel.callback.on_epoch_begin"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_epoch_begin"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "callback", ".", "on_epoch_begin", "(", "epoch", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_epoch_end": [[33, 35], ["callbacks.RedirectModel.callback.on_epoch_end"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.on_epoch_end"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "callback", ".", "on_epoch_end", "(", "epoch", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_batch_begin": [[36, 38], ["callbacks.RedirectModel.callback.on_batch_begin"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_batch_begin"], ["", "def", "on_batch_begin", "(", "self", ",", "batch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "callback", ".", "on_batch_begin", "(", "batch", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_batch_end": [[39, 41], ["callbacks.RedirectModel.callback.on_batch_end"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_batch_end"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "callback", ".", "on_batch_end", "(", "batch", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_train_begin": [[42, 47], ["callbacks.RedirectModel.callback.set_model", "callbacks.RedirectModel.callback.on_train_begin"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_train_begin"], ["", "def", "on_train_begin", "(", "self", ",", "logs", "=", "None", ")", ":", "\n", "# overwrite the model with our custom model", "\n", "        ", "self", ".", "callback", ".", "set_model", "(", "self", ".", "redirect_model", ")", "\n", "\n", "self", ".", "callback", ".", "on_train_begin", "(", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_train_end": [[48, 50], ["callbacks.RedirectModel.callback.on_train_end"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.RedirectModel.on_train_end"], ["", "def", "on_train_end", "(", "self", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "callback", ".", "on_train_end", "(", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.Evaluate.__init__": [[57, 96], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "generator", ",", "\n", "iou_threshold", "=", "0.5", ",", "\n", "score_threshold", "=", "0.05", ",", "\n", "max_detections", "=", "100", ",", "\n", "save_path", "=", "None", ",", "\n", "tensorboard", "=", "None", ",", "\n", "weighted_average", "=", "False", ",", "\n", "verbose", "=", "1", ",", "\n", "render", "=", "False", ",", "\n", "distance", "=", "False", ",", "\n", "workers", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\" Evaluate a given dataset using a given model at the end of every epoch during training.\n\n        # Arguments\n            generator        : The generator that represents the dataset to evaluate.\n            iou_threshold    : The threshold used to consider when a detection is positive or negative.\n            score_threshold  : The score confidence threshold to use for detections.\n            max_detections   : The maximum number of detections to use per image.\n            save_path        : The path to save images with visualized detections to.\n            tensorboard      : Instance of keras.callbacks.TensorBoard used to log the mAP value.\n            weighted_average : Compute the mAP using the weighted average of precisions among classes.\n            verbose          : Set the verbosity level, by default this is set to 1.\n        \"\"\"", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "iou_threshold", "=", "iou_threshold", "\n", "self", ".", "score_threshold", "=", "score_threshold", "\n", "self", ".", "max_detections", "=", "max_detections", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "tensorboard", "=", "tensorboard", "\n", "self", ".", "weighted_average", "=", "weighted_average", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "distance", "=", "distance", "\n", "self", ".", "workers", "=", "workers", "\n", "\n", "super", "(", "Evaluate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.callbacks.Evaluate.on_epoch_end": [[97, 198], ["numpy.nanmean", "numpy.nanmean", "best_aps.items", "crfnet.utils.eval.evaluate", "crfnet.utils.eval.evaluate", "total_instances.append", "precisions.append", "tf.Summary", "tf.Summary.value.add", "tf.Summary.value.add", "tf.Summary.value.add", "best_aps.items", "callbacks.Evaluate.tensorboard.writer.add_summary", "print", "print", "print", "sum", "sum", "numpy.count_nonzero", "sum", "sum", "numpy.nanmean", "numpy.nanmean", "tf.Summary.value.add", "tf.Summary.value.add", "print", "print", "print", "sum", "sum", "sum", "sum", "callbacks.Evaluate.generator.label_to_name", "summary_aps.append", "callbacks.Evaluate.generator.label_to_name", "callbacks.Evaluate.generator.label_to_name", "numpy.isnan", "tf.Summary.value.add", "zip", "str", "zip", "numpy.isnan", "zip", "numpy.isnan", "int", "callbacks.Evaluate.generator.label_to_name"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval.evaluate", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.eval.evaluate", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "logs", "=", "logs", "or", "{", "}", "\n", "\n", "# run evaluation", "\n", "if", "self", ".", "distance", ":", "\n", "            ", "best_map", ",", "best_st", ",", "best_aps", ",", "best_precisions", ",", "best_recalls", ",", "best_mean_loss_errors", ",", "best_mean_loss_errors_rel", "=", "evaluate", "(", "\n", "self", ".", "generator", ",", "\n", "self", ".", "model", ",", "\n", "distance", "=", "self", ".", "distance", ",", "\n", "iou_threshold", "=", "self", ".", "iou_threshold", ",", "\n", "score_threshold", "=", "self", ".", "score_threshold", ",", "\n", "max_detections", "=", "self", ".", "max_detections", ",", "\n", "save_path", "=", "self", ".", "save_path", ",", "\n", "render", "=", "self", ".", "render", ",", "\n", "workers", "=", "self", ".", "workers", "\n", ")", "\n", "\n", "", "else", ":", "\n", "             ", "best_map", ",", "best_st", ",", "best_aps", ",", "best_precisions", ",", "best_recalls", "=", "evaluate", "(", "\n", "self", ".", "generator", ",", "\n", "self", ".", "model", ",", "\n", "distance", "=", "self", ".", "distance", ",", "\n", "iou_threshold", "=", "self", ".", "iou_threshold", ",", "\n", "score_threshold", "=", "self", ".", "score_threshold", ",", "\n", "max_detections", "=", "self", ".", "max_detections", ",", "\n", "save_path", "=", "self", ".", "save_path", ",", "\n", "render", "=", "self", ".", "render", ",", "\n", "workers", "=", "self", ".", "workers", "\n", ")", "\n", "# ignore bg with [:-1]", "\n", "", "self", ".", "mean_precision", "=", "np", ".", "nanmean", "(", "best_precisions", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "mean_recall", "=", "np", ".", "nanmean", "(", "best_recalls", "[", ":", "-", "1", "]", ")", "\n", "\n", "\n", "# compute per class average precision", "\n", "total_instances", "=", "[", "]", "\n", "precisions", "=", "[", "]", "\n", "self", ".", "mean_loss_error", "=", "np", ".", "nan", "\n", "self", ".", "mean_loss_error_rel", "=", "np", ".", "nan", "\n", "for", "label", ",", "(", "average_precision", ",", "num_annotations", ")", "in", "best_aps", ".", "items", "(", ")", ":", "\n", "            ", "if", "self", ".", "verbose", "==", "1", ":", "\n", "                ", "if", "self", ".", "distance", ":", "\n", "                    ", "print", "(", "'{:.0f} instances of class'", ".", "format", "(", "num_annotations", ")", ",", "\n", "self", ".", "generator", ".", "label_to_name", "(", "label", ")", ",", "'with average precision: {0:.4f} (precision: {1:.4f}, recall: {2:.4f}) and mean distance error:{3:.2f} or {4:.2f}%'", ".", "format", "(", "average_precision", ",", "best_precisions", "[", "label", "]", ",", "best_recalls", "[", "label", "]", ",", "best_mean_loss_errors", "[", "label", "]", ",", "best_mean_loss_errors_rel", "[", "label", "]", "*", "100", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'{:.0f} instances of class'", ".", "format", "(", "num_annotations", ")", ",", "\n", "self", ".", "generator", ".", "label_to_name", "(", "label", ")", ",", "'with average precision: {0:.4f} (precision: {1:.4f}, recall: {2:.4f})'", ".", "format", "(", "average_precision", ",", "best_precisions", "[", "label", "]", ",", "best_recalls", "[", "label", "]", ")", ")", "\n", "", "", "total_instances", ".", "append", "(", "num_annotations", ")", "\n", "precisions", ".", "append", "(", "average_precision", ")", "\n", "\n", "", "if", "self", ".", "weighted_average", ":", "\n", "            ", "self", ".", "mean_ap", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "precisions", ")", "]", ")", "/", "sum", "(", "total_instances", ")", "\n", "if", "self", ".", "distance", "and", "np", ".", "count_nonzero", "(", "~", "np", ".", "isnan", "(", "best_mean_loss_errors", ")", ")", ":", "\n", "                ", "self", ".", "mean_loss_error", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "best_mean_loss_errors", ")", "if", "(", "b", "==", "b", ")", "]", ")", "/", "sum", "(", "~", "np", ".", "isnan", "(", "best_mean_loss_errors", ")", "*", "total_instances", ")", "\n", "self", ".", "mean_loss_error_rel", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "total_instances", ",", "best_mean_loss_errors_rel", ")", "if", "(", "b", "==", "b", ")", "]", ")", "/", "sum", "(", "~", "np", ".", "isnan", "(", "best_mean_loss_errors_rel", ")", "*", "total_instances", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "mean_ap", "=", "sum", "(", "precisions", ")", "/", "sum", "(", "x", ">", "0", "for", "x", "in", "total_instances", ")", "\n", "if", "self", ".", "distance", ":", "\n", "                ", "self", ".", "mean_loss_error", "=", "np", ".", "nanmean", "(", "best_mean_loss_errors", ")", "\n", "self", ".", "mean_loss_error_rel", "=", "np", ".", "nanmean", "(", "best_mean_loss_errors_rel", ")", "\n", "\n", "\n", "", "", "if", "self", ".", "tensorboard", "is", "not", "None", "and", "self", ".", "tensorboard", ".", "writer", "is", "not", "None", ":", "\n", "            ", "import", "tensorflow", "as", "tf", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "summary_map", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_map", ".", "simple_value", "=", "self", ".", "mean_ap", "\n", "summary_map", ".", "tag", "=", "\"mAP_val\"", "\n", "summary_precision", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_precision", ".", "simple_value", "=", "self", ".", "mean_precision", "\n", "summary_precision", ".", "tag", "=", "'precision_val'", "\n", "summary_recall", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_recall", ".", "simple_value", "=", "self", ".", "mean_recall", "\n", "summary_recall", ".", "tag", "=", "'recall_val'", "\n", "if", "self", ".", "distance", ":", "\n", "                ", "summary_dist", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_dist", ".", "simple_value", "=", "self", ".", "mean_loss_error", "\n", "summary_dist", ".", "tag", "=", "'mADE_val'", "\n", "summary_dist_rel", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "summary_dist_rel", ".", "simple_value", "=", "self", ".", "mean_loss_error_rel", "\n", "summary_dist_rel", ".", "tag", "=", "'mRDE_val'", "\n", "\n", "### class average precisions to tensorboard", "\n", "", "summary_aps", "=", "[", "]", "\n", "for", "label", ",", "(", "average_precision", ",", "num_annotations", ")", "in", "best_aps", ".", "items", "(", ")", ":", "\n", "                ", "if", "self", ".", "generator", ".", "label_to_name", "(", "label", ")", "is", "not", "'bg'", ":", "\n", "                    ", "summary_aps", ".", "append", "(", "summary", ".", "value", ".", "add", "(", ")", ")", "\n", "summary_aps", "[", "label", "]", ".", "simple_value", "=", "average_precision", "\n", "summary_aps", "[", "label", "]", ".", "tag", "=", "'ap_val_'", "+", "self", ".", "generator", ".", "label_to_name", "(", "label", ")", "+", "' ('", "+", "str", "(", "int", "(", "num_annotations", ")", ")", "+", "' instances)'", "\n", "\n", "", "", "self", ".", "tensorboard", ".", "writer", ".", "add_summary", "(", "summary", ",", "epoch", ")", "\n", "\n", "", "logs", "[", "'mAP'", "]", "=", "self", ".", "mean_ap", "\n", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "            ", "print", "(", "'='", "*", "60", ")", "\n", "print", "(", "'mAP: {0:.4f} \\t precision:{1:.4f} \\t recall:{2:.4f}'", ".", "format", "(", "self", ".", "mean_ap", ",", "self", ".", "mean_precision", ",", "self", ".", "mean_recall", ")", ")", "\n", "if", "self", ".", "distance", ":", "print", "(", "'mADE: {0:.2f} \\t mRDE:{1:.2f}'", ".", "format", "(", "self", ".", "mean_loss_error", ",", "self", ".", "mean_loss_error_rel", ")", ")", "\n", "print", "(", "'@scorethreshold {0:.2f}'", ".", "format", "(", "best_st", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_calc.bbox_transform": [[15, 47], ["isinstance", "isinstance", "numpy.stack", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "isinstance", "ValueError", "isinstance", "ValueError", "type", "type"], "function", ["None"], ["def", "bbox_transform", "(", "anchors", ",", "gt_boxes", ",", "mean", "=", "None", ",", "std", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute bounding-box regression targets for an image.\"\"\"", "\n", "\n", "if", "mean", "is", "None", ":", "\n", "        ", "mean", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "if", "std", "is", "None", ":", "\n", "        ", "std", "=", "np", ".", "array", "(", "[", "0.2", ",", "0.2", ",", "0.2", ",", "0.2", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "mean", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n", "", "elif", "not", "isinstance", "(", "mean", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Expected mean to be a np.ndarray, list or tuple. Received: {}'", ".", "format", "(", "type", "(", "mean", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "std", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "std", "=", "np", ".", "array", "(", "std", ")", "\n", "", "elif", "not", "isinstance", "(", "std", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Expected std to be a np.ndarray, list or tuple. Received: {}'", ".", "format", "(", "type", "(", "std", ")", ")", ")", "\n", "\n", "", "anchor_widths", "=", "anchors", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "0", "]", "\n", "anchor_heights", "=", "anchors", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "1", "]", "\n", "\n", "targets_dx1", "=", "(", "gt_boxes", "[", ":", ",", "0", "]", "-", "anchors", "[", ":", ",", "0", "]", ")", "/", "anchor_widths", "\n", "targets_dy1", "=", "(", "gt_boxes", "[", ":", ",", "1", "]", "-", "anchors", "[", ":", ",", "1", "]", ")", "/", "anchor_heights", "\n", "targets_dx2", "=", "(", "gt_boxes", "[", ":", ",", "2", "]", "-", "anchors", "[", ":", ",", "2", "]", ")", "/", "anchor_widths", "\n", "targets_dy2", "=", "(", "gt_boxes", "[", ":", ",", "3", "]", "-", "anchors", "[", ":", ",", "3", "]", ")", "/", "anchor_heights", "\n", "\n", "targets", "=", "np", ".", "stack", "(", "(", "targets_dx1", ",", "targets_dy1", ",", "targets_dx2", ",", "targets_dy2", ")", ")", "\n", "targets", "=", "targets", ".", "T", "\n", "\n", "targets", "=", "(", "targets", "-", "mean", ")", "/", "std", "\n", "\n", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_calc.anchor_targets_bbox": [[48, 129], ["len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "len", "len", "len", "zip", "keras.backend.floatx", "keras.backend.floatx", "keras.backend.floatx", "anchor_calc.compute_gt_annotations", "[].astype", "anchor_calc.bbox_transform", "numpy.logical_or", "numpy.vstack", "tuple"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_calc.compute_gt_annotations", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_calc.bbox_transform"], ["", "def", "anchor_targets_bbox", "(", "\n", "anchors", ",", "\n", "image_group", ",", "\n", "annotations_group", ",", "\n", "num_classes", ",", "\n", "negative_overlap", "=", "0.4", ",", "\n", "positive_overlap", "=", "0.5", ",", "\n", "distance", "=", "False", ",", "\n", "distance_scaling", "=", "100", "\n", ")", ":", "\n", "    ", "\"\"\" Generate anchor targets for bbox detection.\n\n    Args\n        anchors: np.array of annotations of shape (N, 4) for (x1, y1, x2, y2).\n        image_group: List of BGR images.\n        annotations_group: List of annotations (np.array of shape (N, 5) for (x1, y1, x2, y2, label)).\n        num_classes: Number of classes to predict.\n        mask_shape: If the image is padded with zeros, mask_shape can be used to mark the relevant part of the image.\n        negative_overlap: IoU overlap for negative anchors (all anchors with overlap < negative_overlap are negative).\n        positive_overlap: IoU overlap or positive anchors (all anchors with overlap > positive_overlap are positive).\n\n    Returns\n        labels_batch: batch that contains labels & anchor states (np.array of shape (batch_size, N, num_classes + 1),\n                      where N is the number of anchors for an image and the last column defines the anchor state (-1 for ignore, 0 for bg, 1 for fg).\n        regression_batch: batch that contains bounding-box regression targets for an image & anchor states (np.array of shape (batch_size, N, 4 + 1),\n                      where N is the number of anchors for an image, the first 4 columns define regression targets for (x1, y1, x2, y2) and the\n                      last column defines anchor states (-1 for ignore, 0 for bg, 1 for fg).\n    \"\"\"", "\n", "\n", "assert", "(", "len", "(", "image_group", ")", "==", "len", "(", "annotations_group", ")", ")", ",", "\"The length of the images and annotations need to be equal.\"", "\n", "assert", "(", "len", "(", "annotations_group", ")", ">", "0", ")", ",", "\"No data received to compute anchor targets for.\"", "\n", "for", "annotations", "in", "annotations_group", ":", "\n", "        ", "assert", "(", "'bboxes'", "in", "annotations", ")", ",", "\"Annotations should contain bboxes.\"", "\n", "assert", "(", "'labels'", "in", "annotations", ")", ",", "\"Annotations should contain labels.\"", "\n", "\n", "", "batch_size", "=", "len", "(", "image_group", ")", "\n", "\n", "regression_batch", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "anchors", ".", "shape", "[", "0", "]", ",", "4", "+", "1", ")", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "labels_batch", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "anchors", ".", "shape", "[", "0", "]", ",", "num_classes", "+", "1", ")", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "distance_batch", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "anchors", ".", "shape", "[", "0", "]", ",", "1", "+", "1", ")", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "\n", "# compute labels and regression targets", "\n", "for", "index", ",", "(", "image", ",", "annotations", ")", "in", "enumerate", "(", "zip", "(", "image_group", ",", "annotations_group", ")", ")", ":", "\n", "        ", "if", "annotations", "[", "'bboxes'", "]", ".", "shape", "[", "0", "]", ":", "\n", "# obtain indices of gt annotations with the greatest overlap", "\n", "            ", "positive_indices", ",", "ignore_indices", ",", "argmax_overlaps_inds", "=", "compute_gt_annotations", "(", "anchors", ",", "annotations", "[", "'bboxes'", "]", ",", "negative_overlap", ",", "positive_overlap", ")", "\n", "\n", "labels_batch", "[", "index", ",", "ignore_indices", ",", "-", "1", "]", "=", "-", "1", "\n", "labels_batch", "[", "index", ",", "positive_indices", ",", "-", "1", "]", "=", "1", "\n", "\n", "regression_batch", "[", "index", ",", "ignore_indices", ",", "-", "1", "]", "=", "-", "1", "\n", "regression_batch", "[", "index", ",", "positive_indices", ",", "-", "1", "]", "=", "1", "\n", "\n", "distance_batch", "[", "index", ",", "ignore_indices", ",", "-", "1", "]", "=", "-", "1", "\n", "distance_batch", "[", "index", ",", "positive_indices", ",", "-", "1", "]", "=", "1", "\n", "\n", "# compute target class labels", "\n", "pos_overlap_inds", "=", "[", "argmax_overlaps_inds", "[", "positive_indices", "]", "]", "\n", "label_indices", "=", "annotations", "[", "'labels'", "]", "[", "tuple", "(", "pos_overlap_inds", ")", "]", ".", "astype", "(", "int", ")", "\n", "\n", "labels_batch", "[", "index", ",", "positive_indices", ",", "label_indices", "]", "=", "1", "\n", "\n", "regression_batch", "[", "index", ",", ":", ",", ":", "-", "1", "]", "=", "bbox_transform", "(", "anchors", ",", "annotations", "[", "'bboxes'", "]", "[", "argmax_overlaps_inds", ",", ":", "]", ")", "\n", "\n", "\n", "if", "distance", ":", "\n", "                ", "distance_batch", "[", "index", ",", "positive_indices", ",", "0", "]", "=", "annotations", "[", "'distances'", "]", "[", "pos_overlap_inds", "[", "0", "]", "[", ":", "]", "]", "/", "distance_scaling", "\n", "\n", "\n", "# ignore annotations outside of image", "\n", "", "", "if", "image", ".", "shape", ":", "\n", "            ", "anchors_centers", "=", "np", ".", "vstack", "(", "[", "(", "anchors", "[", ":", ",", "0", "]", "+", "anchors", "[", ":", ",", "2", "]", ")", "/", "2", ",", "(", "anchors", "[", ":", ",", "1", "]", "+", "anchors", "[", ":", ",", "3", "]", ")", "/", "2", "]", ")", ".", "T", "\n", "indices", "=", "np", ".", "logical_or", "(", "anchors_centers", "[", ":", ",", "0", "]", ">=", "image", ".", "shape", "[", "1", "]", ",", "anchors_centers", "[", ":", ",", "1", "]", ">=", "image", ".", "shape", "[", "0", "]", ")", "\n", "\n", "labels_batch", "[", "index", ",", "indices", ",", "-", "1", "]", "=", "-", "1", "\n", "regression_batch", "[", "index", ",", "indices", ",", "-", "1", "]", "=", "-", "1", "\n", "distance_batch", "[", "index", ",", "indices", ",", "-", "1", "]", "=", "-", "1", "\n", "", "", "if", "distance", ":", "\n", "        ", "return", "regression_batch", ",", "labels_batch", ",", "distance_batch", "\n", "", "else", ":", "\n", "        ", "return", "regression_batch", ",", "labels_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_calc.compute_gt_annotations": [[131, 160], ["utils.compute_overlap.compute_overlap", "numpy.argmax", "anchors.astype", "annotations.astype", "numpy.arange"], "function", ["None"], ["", "", "def", "compute_gt_annotations", "(", "\n", "anchors", ",", "\n", "annotations", ",", "\n", "negative_overlap", "=", "0.4", ",", "\n", "positive_overlap", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\" Obtain indices of gt annotations with the greatest overlap.\n\n    Args\n        anchors: np.array of annotations of shape (N, 4) for (x1, y1, x2, y2).\n        annotations: np.array of shape (N, 5) for (x1, y1, x2, y2, label).\n        negative_overlap: IoU overlap for negative anchors (all anchors with overlap < negative_overlap are negative).\n        positive_overlap: IoU overlap or positive anchors (all anchors with overlap > positive_overlap are positive).\n\n    Returns\n        positive_indices: indices of positive anchors\n        ignore_indices: indices of ignored anchors\n        argmax_overlaps_inds: ordered overlaps indices\n    \"\"\"", "\n", "\n", "overlaps", "=", "compute_overlap", "(", "anchors", ".", "astype", "(", "np", ".", "float64", ")", ",", "annotations", ".", "astype", "(", "np", ".", "float64", ")", ")", "\n", "argmax_overlaps_inds", "=", "np", ".", "argmax", "(", "overlaps", ",", "axis", "=", "1", ")", "\n", "max_overlaps", "=", "overlaps", "[", "np", ".", "arange", "(", "overlaps", ".", "shape", "[", "0", "]", ")", ",", "argmax_overlaps_inds", "]", "\n", "\n", "# assign \"dont care\" labels", "\n", "positive_indices", "=", "max_overlaps", ">=", "positive_overlap", "\n", "ignore_indices", "=", "(", "max_overlaps", ">", "negative_overlap", ")", "&", "~", "positive_indices", "\n", "\n", "return", "positive_indices", ",", "ignore_indices", ",", "argmax_overlaps_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.TransformParameters.__init__": [[163, 174], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fill_mode", "=", "'nearest'", ",", "\n", "interpolation", "=", "'linear'", ",", "\n", "cval", "=", "0", ",", "\n", "relative_translation", "=", "True", ",", "\n", ")", ":", "\n", "        ", "self", ".", "fill_mode", "=", "fill_mode", "\n", "self", ".", "cval", "=", "cval", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "self", ".", "relative_translation", "=", "relative_translation", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.TransformParameters.cvBorderMode": [[175, 184], ["None"], "methods", ["None"], ["", "def", "cvBorderMode", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "fill_mode", "==", "'constant'", ":", "\n", "            ", "return", "cv2", ".", "BORDER_CONSTANT", "\n", "", "if", "self", ".", "fill_mode", "==", "'nearest'", ":", "\n", "            ", "return", "cv2", ".", "BORDER_REPLICATE", "\n", "", "if", "self", ".", "fill_mode", "==", "'reflect'", ":", "\n", "            ", "return", "cv2", ".", "BORDER_REFLECT_101", "\n", "", "if", "self", ".", "fill_mode", "==", "'wrap'", ":", "\n", "            ", "return", "cv2", ".", "BORDER_WRAP", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.TransformParameters.cvInterpolation": [[185, 196], ["None"], "methods", ["None"], ["", "", "def", "cvInterpolation", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "interpolation", "==", "'nearest'", ":", "\n", "            ", "return", "cv2", ".", "INTER_NEAREST", "\n", "", "if", "self", ".", "interpolation", "==", "'linear'", ":", "\n", "            ", "return", "cv2", ".", "INTER_LINEAR", "\n", "", "if", "self", ".", "interpolation", "==", "'cubic'", ":", "\n", "            ", "return", "cv2", ".", "INTER_CUBIC", "\n", "", "if", "self", ".", "interpolation", "==", "'area'", ":", "\n", "            ", "return", "cv2", ".", "INTER_AREA", "\n", "", "if", "self", ".", "interpolation", "==", "'lanczos4'", ":", "\n", "            ", "return", "cv2", ".", "INTER_LANCZOS4", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.read_image_bgr": [[26, 34], ["numpy.asarray", "image[].copy", "PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["def", "read_image_bgr", "(", "path", ")", ":", "\n", "    ", "\"\"\" Read an image in BGR format.\n    Args\n        path: Path to the image.\n    \"\"\"", "\n", "image", "=", "np", ".", "asarray", "(", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", ")", "\n", "\n", "return", "image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.read_image_rgb": [[36, 44], ["numpy.asarray", "PIL.Image.open"], "function", ["None"], ["", "def", "read_image_rgb", "(", "path", ")", ":", "\n", "    ", "\"\"\" Read an image in BGR format.\n\n    Args\n        path: Path to the image.\n    \"\"\"", "\n", "image", "=", "np", ".", "asarray", "(", "Image", ".", "open", "(", "path", ")", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.preprocess_image": [[46, 93], ["numpy.issubdtype", "x.astype.astype", "image_channels.values", "image_channels.values"], "function", ["None"], ["", "def", "preprocess_image", "(", "x", ",", "mode", "=", "'caffe'", ",", "image_channels", "=", "{", "'r'", ":", "0", ",", "'g'", ":", "1", ",", "'b'", ":", "2", "}", ")", ":", "\n", "    ", "\"\"\" Preprocess an image by subtracting the ImageNet mean.\n\n    Args\n        x: np.array of shape (None, None, 3).\n        mode: One of \"caffe\" or \"tf\".\n            - caffe: will scaled between -127.5 and 127.5\n            - tf: will scale pixels between -1 and 1, sample-wise.\n        image_channels: the channels of the sample which contain image data like RGB\n    Returns\n        The preprocessed image. Ready for the neural network.\n    \"\"\"", "\n", "\n", "is_int_representation", "=", "np", ".", "issubdtype", "(", "x", ".", "dtype", ",", "np", ".", "integer", ")", "\n", "\n", "# covert always to float32 to keep compatibility with opencv", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "if", "mode", "==", "'tf'", ":", "\n", "# scale pixels between -1 and 1", "\n", "        ", "for", "color_channel", "in", "image_channels", ".", "values", "(", ")", ":", "\n", "            ", "if", "is_int_representation", ":", "\n", "# Between 0 and 255", "\n", "                ", "x", "[", "...", ",", "color_channel", "]", "/=", "127.5", "\n", "", "else", ":", "\n", "# Between 0 and 1", "\n", "                ", "x", "[", "...", ",", "color_channel", "]", "*=", "2.", "\n", "\n", "# Between 0 and 2", "\n", "", "x", "[", "...", ",", "color_channel", "]", "-=", "1.", "\n", "\n", "# Between -1 and 1", "\n", "\n", "", "", "elif", "mode", "==", "'caffe'", ":", "\n", "# scale pixels between -127.5 and 127.5", "\n", "        ", "for", "color_channel", "in", "image_channels", ".", "values", "(", ")", ":", "\n", "            ", "if", "not", "is_int_representation", ":", "\n", "# Between 0 and 1", "\n", "                ", "x", "[", "...", ",", "color_channel", "]", "*=", "255", "\n", "\n", "# Between 0 and 255", "\n", "# zero-center each color channel", "\n", "", "x", "[", "...", ",", "color_channel", "]", "-=", "127.5", "\n", "\n", "# Between -127.5 and 127.5", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.preprocess_image_inverted": [[96, 132], ["x.astype.astype", "image_channels.values", "image_channels.values"], "function", ["None"], ["", "def", "preprocess_image_inverted", "(", "x", ",", "mode", "=", "'caffe'", ",", "image_channels", "=", "{", "'r'", ":", "0", ",", "'g'", ":", "1", ",", "'b'", ":", "2", "}", ")", ":", "\n", "    ", "\"\"\" undo the preprocess_image function\n\n    Args\n        x: np.array of shape (None, None, 3)\n        mode: One of \"caffe\" or \"tf\".\n            - caffe: input pixels are scaled between -127.5 and 127.5\n            - tf: input pixels are scaled between -1 and 1\n        image_channels: the channels of the sample which contain image data like RGB\n    Returns\n        The image with rgb in range [0,1]\n    \"\"\"", "\n", "\n", "# covert always to float32 to keep compatibility with opencv", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "if", "mode", "==", "'tf'", ":", "\n", "\n", "# scale pixels between 0 and 1", "\n", "        ", "for", "color_channel", "in", "image_channels", ".", "values", "(", ")", ":", "\n", "# Between -1 and 1", "\n", "            ", "x", "[", "...", ",", "color_channel", "]", "+=", "1.", "\n", "# Between 0 and 2", "\n", "x", "[", "...", ",", "color_channel", "]", "/=", "2.", "\n", "# Between 0 and 1", "\n", "\n", "", "", "elif", "mode", "==", "'caffe'", ":", "\n", "# scale pixels between", "\n", "        ", "for", "color_channel", "in", "image_channels", ".", "values", "(", ")", ":", "\n", "# Between -127.5 and 127.5", "\n", "            ", "x", "[", "...", ",", "color_channel", "]", "+=", "127.5", "\n", "# Between 0 and 255", "\n", "x", "[", "...", ",", "color_channel", "]", "/=", "255", "\n", "# Between 0 and 1", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.adjust_transform_for_image": [[133, 151], ["transform.change_transform_origin"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.change_transform_origin"], ["", "def", "adjust_transform_for_image", "(", "transform", ",", "image", ",", "relative_translation", ")", ":", "\n", "    ", "\"\"\" Adjust a transformation for a specific image.\n\n    The translation of the matrix will be scaled with the size of the image.\n    The linear part of the transformation will adjusted so that the origin of the transformation will be at the center of the image.\n    \"\"\"", "\n", "height", ",", "width", ",", "channels", "=", "image", ".", "shape", "\n", "\n", "result", "=", "transform", "\n", "\n", "# Scale the translation with the image size if specified.", "\n", "if", "relative_translation", ":", "\n", "        ", "result", "[", "0", ":", "2", ",", "2", "]", "*=", "[", "width", ",", "height", "]", "\n", "\n", "# Move the origin of transformation.", "\n", "", "result", "=", "change_transform_origin", "(", "transform", ",", "(", "0.5", "*", "width", ",", "0.5", "*", "height", ")", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.apply_transform": [[198, 221], ["cv2.warpAffine", "params.cvInterpolation", "params.cvBorderMode"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.TransformParameters.cvInterpolation", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.TransformParameters.cvBorderMode"], ["", "", "", "def", "apply_transform", "(", "matrix", ",", "image", ",", "params", ")", ":", "\n", "    ", "\"\"\"\n    Apply a transformation to an image.\n\n    The origin of transformation is at the top left corner of the image.\n\n    The matrix is interpreted such that a point (x, y) on the original image is moved to transform * (x, y) in the generated image.\n    Mathematically speaking, that means that the matrix is a transformation from the transformed image space to the original image space.\n\n    Args\n      matrix: A homogeneous 3 by 3 matrix holding representing the transformation to apply.\n      image:  The image to transform.\n      params: The transform parameters (see TransformParameters)\n    \"\"\"", "\n", "output", "=", "cv2", ".", "warpAffine", "(", "\n", "image", ",", "\n", "matrix", "[", ":", "2", ",", ":", "]", ",", "\n", "dsize", "=", "(", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "0", "]", ")", ",", "\n", "flags", "=", "params", ".", "cvInterpolation", "(", ")", ",", "\n", "borderMode", "=", "params", ".", "cvBorderMode", "(", ")", ",", "\n", "borderValue", "=", "params", ".", "cval", ",", "\n", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.compute_resize_scale": [[223, 247], ["min", "max"], "function", ["None"], ["", "def", "compute_resize_scale", "(", "image_shape", ",", "min_side", "=", "800", ",", "max_side", "=", "1333", ")", ":", "\n", "    ", "\"\"\" Compute an image scale such that the image size is constrained to min_side and max_side.\n\n    Args\n        min_side: The image's min side will be equal to min_side after resizing.\n        max_side: If after resizing the image's max side is above max_side, resize until the max side is equal to max_side.\n\n    Returns\n        A resizing scale.\n    \"\"\"", "\n", "(", "rows", ",", "cols", ",", "_", ")", "=", "image_shape", "\n", "\n", "smallest_side", "=", "min", "(", "rows", ",", "cols", ")", "\n", "\n", "# rescale the image so the smallest side is min_side", "\n", "scale", "=", "min_side", "/", "smallest_side", "\n", "\n", "# check if the largest side is now greater than max_side, which can happen", "\n", "# when images have a large aspect ratio", "\n", "largest_side", "=", "max", "(", "rows", ",", "cols", ")", "\n", "if", "largest_side", "*", "scale", ">", "max_side", ":", "\n", "        ", "scale", "=", "max_side", "/", "largest_side", "\n", "\n", "", "return", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.resize_image": [[249, 266], ["image.compute_resize_scale", "cv2.resize"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.compute_resize_scale"], ["", "def", "resize_image", "(", "img", ",", "min_side", "=", "800", ",", "max_side", "=", "1333", ")", ":", "\n", "    ", "\"\"\" Resize an image such that the size is constrained to min_side and max_side.\n\n    Args\n        min_side: The image's min side will be equal to min_side after resizing.\n        max_side: If after resizing the image's max side is above max_side, resize until the max side is equal to max_side.\n\n    Returns\n        A resized image.\n    \"\"\"", "\n", "# compute scale to resize the image", "\n", "scale", "=", "compute_resize_scale", "(", "img", ".", "shape", ",", "min_side", "=", "min_side", ",", "max_side", "=", "max_side", ")", "\n", "\n", "# resize the image with the computed scale", "\n", "img", "=", "cv2", ".", "resize", "(", "img", ",", "None", ",", "fx", "=", "scale", ",", "fy", "=", "scale", ")", "\n", "\n", "return", "img", ",", "scale", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.crf_main_generator.create_generators": [[7, 144], ["crfnet.utils.transform.random_transform_generator", "crfnet.utils.transform.random_transform_generator", "NuscenesGenerator", "NuscenesGenerator", "NuscenesGenerator", "NuscenesGenerator", "NuscenesGenerator", "ValueError", "cfg.class_weights.keys", "NuScenes", "NuScenes", "NuScenes"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_transform_generator", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.random_transform_generator"], ["def", "create_generators", "(", "cfg", ",", "backbone", ")", ":", "\n", "  ", "\"\"\" Create generators for training and validation and test data.\n\n  :param cfg:                     <Configuration>         Config class with config parameters.\n  :param backbone:                <Backbone>              Backbone class e.g. VGGBackbone\n\n  :return train_generator:        <Generator>             The generator for creating training data.\n  :return validation_generator:   <Generator>             The generator for creating validation data.\n\n  TODO: @Max make the create generators consistently return train, val and test\n  \"\"\"", "\n", "if", "cfg", ".", "anchor_params", ":", "\n", "    ", "if", "'small'", "in", "cfg", ".", "anchor_params", ":", "\n", "      ", "anchor_params", "=", "AnchorParameters", ".", "small", "\n", "", "else", ":", "\n", "      ", "anchor_params", "=", "None", "\n", "", "", "else", ":", "\n", "    ", "anchor_params", "=", "None", "\n", "\n", "", "common_args", "=", "{", "\n", "'batch_size'", ":", "cfg", ".", "batchsize", ",", "\n", "'config'", ":", "None", ",", "\n", "'image_min_side'", ":", "cfg", ".", "image_size", "[", "0", "]", ",", "\n", "'image_max_side'", ":", "cfg", ".", "image_size", "[", "1", "]", ",", "\n", "'filter_annotations_enabled'", ":", "False", ",", "\n", "'preprocess_image'", ":", "backbone", ".", "preprocess_image", ",", "\n", "'normalize_radar'", ":", "cfg", ".", "normalize_radar", ",", "\n", "'camera_dropout'", ":", "cfg", ".", "dropout_image", ",", "\n", "'radar_dropout'", ":", "cfg", ".", "dropout_radar", ",", "\n", "'channels'", ":", "cfg", ".", "channels", ",", "\n", "'distance'", ":", "cfg", ".", "distance_detection", ",", "\n", "'sample_selection'", ":", "cfg", ".", "sample_selection", ",", "\n", "'only_radar_annotated'", ":", "cfg", ".", "only_radar_annotated", ",", "\n", "'n_sweeps'", ":", "cfg", ".", "n_sweeps", ",", "\n", "'noise_filter'", ":", "cfg", ".", "noise_filter_cfg", ",", "\n", "'noise_filter_threshold'", ":", "cfg", ".", "noise_filter_threshold", ",", "\n", "'noisy_image_method'", ":", "cfg", ".", "noisy_image_method", ",", "\n", "'noise_factor'", ":", "cfg", ".", "noise_factor", ",", "\n", "'perfect_noise_filter'", ":", "cfg", ".", "noise_filter_perfect", ",", "\n", "'radar_projection_height'", ":", "cfg", ".", "radar_projection_height", ",", "\n", "'noise_category_selection'", ":", "None", "if", "cfg", ".", "class_weights", "is", "None", "else", "cfg", ".", "class_weights", ".", "keys", "(", ")", ",", "\n", "'inference'", ":", "cfg", ".", "inference", ",", "\n", "'anchor_params'", ":", "anchor_params", ",", "\n", "}", "\n", "\n", "# create random transform generator for augmenting training data", "\n", "if", "cfg", ".", "random_transform", ":", "\n", "    ", "transform_generator", "=", "random_transform_generator", "(", "\n", "min_rotation", "=", "-", "0.1", ",", "\n", "max_rotation", "=", "0.1", ",", "\n", "min_translation", "=", "(", "-", "0.1", ",", "-", "0.1", ")", ",", "\n", "max_translation", "=", "(", "0.1", ",", "0.1", ")", ",", "\n", "min_shear", "=", "-", "0.1", ",", "\n", "max_shear", "=", "0.1", ",", "\n", "min_scaling", "=", "(", "0.9", ",", "0.9", ")", ",", "\n", "max_scaling", "=", "(", "1.1", ",", "1.1", ")", ",", "\n", "flip_x_chance", "=", "0.5", ",", "\n", "flip_y_chance", "=", "0.0", ",", "\n", ")", "\n", "", "else", ":", "\n", "    ", "transform_generator", "=", "random_transform_generator", "(", "flip_x_chance", "=", "0.5", ")", "\n", "\n", "", "category_mapping", "=", "cfg", ".", "category_mapping", "\n", "\n", "if", "'nuscenes'", "in", "cfg", ".", "data_set", ":", "\n", "# import here to prevent unnecessary dependency on nuscenes", "\n", "    ", "from", "crfnet", ".", "data_processing", ".", "generator", ".", "nuscenes_generator", "import", "NuscenesGenerator", "\n", "from", "nuscenes", ".", "nuscenes", "import", "NuScenes", "\n", "\n", "if", "'mini'", "in", "cfg", ".", "data_set", ":", "\n", "      ", "nusc", "=", "NuScenes", "(", "version", "=", "'v1.0-mini'", ",", "dataroot", "=", "cfg", ".", "data_path", ",", "verbose", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "try", ":", "\n", "        ", "nusc", "=", "NuScenes", "(", "version", "=", "'v1.0-trainval'", ",", "dataroot", "=", "cfg", ".", "data_path", ",", "verbose", "=", "True", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "nusc", "=", "NuScenes", "(", "version", "=", "'v1.0-mini'", ",", "dataroot", "=", "cfg", ".", "data_path", ",", "verbose", "=", "True", ")", "\n", "\n", "\n", "", "", "if", "'debug'", "in", "cfg", ".", "scene_selection", "or", "'mini'", "in", "cfg", ".", "data_set", ":", "\n", "      ", "scenes", "=", "Scenes", ".", "debug", "\n", "", "else", ":", "\n", "      ", "scenes", "=", "Scenes", ".", "default", "\n", "\n", "", "train_generator", "=", "NuscenesGenerator", "(", "\n", "nusc", ",", "\n", "scene_indices", "=", "scenes", ".", "train", ",", "\n", "transform_generator", "=", "transform_generator", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "compute_anchor_targets", "=", "anchor_targets_bbox", ",", "\n", "compute_shapes", "=", "guess_shapes", ",", "\n", "shuffle_groups", "=", "True", ",", "\n", "group_method", "=", "'random'", ",", "\n", "**", "common_args", "\n", ")", "\n", "\n", "# no dropouts in validation", "\n", "common_args", "[", "'camera_dropout'", "]", "=", "0", "\n", "common_args", "[", "'radar_dropout'", "]", "=", "0", "\n", "\n", "validation_generator", "=", "NuscenesGenerator", "(", "\n", "nusc", ",", "\n", "scene_indices", "=", "scenes", ".", "val", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "compute_anchor_targets", "=", "anchor_targets_bbox", ",", "\n", "compute_shapes", "=", "guess_shapes", ",", "\n", "**", "common_args", "\n", ")", "\n", "\n", "test_generator", "=", "NuscenesGenerator", "(", "\n", "nusc", ",", "\n", "scene_indices", "=", "scenes", ".", "test", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "compute_anchor_targets", "=", "anchor_targets_bbox", ",", "\n", "compute_shapes", "=", "guess_shapes", ",", "\n", "**", "common_args", "\n", ")", "\n", "\n", "test_night_generator", "=", "NuscenesGenerator", "(", "\n", "nusc", ",", "\n", "scene_indices", "=", "scenes", ".", "test_night", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "compute_anchor_targets", "=", "anchor_targets_bbox", ",", "\n", "compute_shapes", "=", "guess_shapes", ",", "\n", "**", "common_args", "\n", ")", "\n", "\n", "test_rain_generator", "=", "NuscenesGenerator", "(", "\n", "nusc", ",", "\n", "scene_indices", "=", "scenes", ".", "test_rain", ",", "\n", "category_mapping", "=", "category_mapping", ",", "\n", "compute_anchor_targets", "=", "anchor_targets_bbox", ",", "\n", "compute_shapes", "=", "guess_shapes", ",", "\n", "**", "common_args", "\n", ")", "\n", "return", "train_generator", ",", "validation_generator", ",", "test_generator", ",", "test_night_generator", ",", "test_rain_generator", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Invalid data type received: {}'", ".", "format", "(", "cfg", ".", "data_set", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.__init__": [[44, 99], ["int", "generator.Generator.group_images", "crfnet.utils.image.TransformParameters", "generator.Generator.on_epoch_end"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.group_images", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.on_epoch_end"], ["def", "__init__", "(", "\n", "self", ",", "\n", "transform_generator", "=", "None", ",", "\n", "batch_size", "=", "1", ",", "\n", "group_method", "=", "None", ",", "# one of 'none', 'random', 'ratio'", "\n", "shuffle_groups", "=", "False", ",", "\n", "image_min_side", "=", "800", ",", "\n", "image_max_side", "=", "1333", ",", "\n", "transform_parameters", "=", "None", ",", "\n", "compute_anchor_targets", "=", "None", ",", "\n", "compute_shapes", "=", "None", ",", "\n", "preprocess_image", "=", "None", ",", "\n", "filter_annotations_enabled", "=", "True", ",", "\n", "config", "=", "None", ",", "\n", "distance", "=", "False", ",", "\n", "radar_projection_height", "=", "3", ",", "\n", "anchor_params", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Initialize Generator object.\n\n        Args\n            transform_generator             : A generator used to randomly transform images and annotations.\n            batch_size                      : The size of the batches to generate.\n            group_method                    : Determines how images are grouped together (defaults to 'ratio', one of ('none', 'random', 'ratio')).\n            shuffle_groups                  : If True, shuffles the groups each epoch.\n            image_min_side                  : After resizing the minimum side of an image is equal to image_min_side.\n            image_max_side                  : If after resizing the maximum side is larger than image_max_side, scales down further so that the max side is equal to image_max_side.\n            transform_parameters            : The transform parameters used for data augmentation.\n            compute_anchor_targets          : Function handler for computing the targets of anchors for an image and its annotations.\n            compute_shapes                  : Function handler for computing the shapes of the pyramid for a given input.\n            preprocess_image                : Function handler for preprocessing an image (scaling / normalizing) for passing through a network.\n            filter_annotations_enabled      : True for removing bounding boxed bigger than image or with zero size\n        \"\"\"", "\n", "self", ".", "transform_generator", "=", "transform_generator", "\n", "self", ".", "batch_size", "=", "int", "(", "batch_size", ")", "\n", "self", ".", "group_method", "=", "group_method", "\n", "self", ".", "shuffle_groups", "=", "shuffle_groups", "\n", "self", ".", "image_min_side", "=", "image_min_side", "\n", "self", ".", "image_max_side", "=", "image_max_side", "\n", "self", ".", "transform_parameters", "=", "transform_parameters", "or", "TransformParameters", "(", ")", "\n", "self", ".", "compute_anchor_targets", "=", "compute_anchor_targets", "\n", "self", ".", "compute_shapes", "=", "compute_shapes", "\n", "self", ".", "preprocess_image", "=", "preprocess_image", "\n", "self", ".", "filter_annotations_enabled", "=", "filter_annotations_enabled", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "distance", "=", "distance", "\n", "self", ".", "radar_projection_height", "=", "radar_projection_height", "\n", "self", ".", "anchor_params", "=", "anchor_params", "\n", "\n", "# Define groups", "\n", "self", ".", "group_images", "(", ")", "\n", "\n", "# Shuffle when initializing", "\n", "if", "self", ".", "shuffle_groups", ":", "\n", "            ", "self", ".", "on_epoch_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.on_epoch_end": [[100, 103], ["random.shuffle"], "methods", ["None"], ["", "", "def", "on_epoch_end", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle_groups", ":", "\n", "            ", "random", ".", "shuffle", "(", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.size": [[104, 108], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the dataset.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'size method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.num_classes": [[109, 113], ["NotImplementedError"], "methods", ["None"], ["", "def", "num_classes", "(", "self", ")", ":", "\n", "        ", "\"\"\" Number of classes in the dataset.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'num_classes method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.has_label": [[114, 118], ["NotImplementedError"], "methods", ["None"], ["", "def", "has_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\" Returns True if label is a known label.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'has_label method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.has_name": [[119, 123], ["NotImplementedError"], "methods", ["None"], ["", "def", "has_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\" Returns True if name is a known class.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'has_name method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.name_to_label": [[124, 128], ["NotImplementedError"], "methods", ["None"], ["", "def", "name_to_label", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\" Map name to label.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'name_to_label method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.label_to_name": [[129, 133], ["NotImplementedError"], "methods", ["None"], ["", "def", "label_to_name", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\" Map label to name.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'label_to_name method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.image_aspect_ratio": [[134, 138], ["NotImplementedError"], "methods", ["None"], ["", "def", "image_aspect_ratio", "(", "self", ",", "image_index", ")", ":", "\n", "        ", "\"\"\" Compute the aspect ratio for an image with image_index.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'image_aspect_ratio method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.load_image": [[139, 143], ["NotImplementedError"], "methods", ["None"], ["", "def", "load_image", "(", "self", ",", "image_index", ")", ":", "\n", "        ", "\"\"\" Load an image at the image_index.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'load_image method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.load_annotations": [[144, 148], ["NotImplementedError"], "methods", ["None"], ["", "def", "load_annotations", "(", "self", ",", "image_index", ")", ":", "\n", "        ", "\"\"\" Load annotations for an image_index.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "'load_annotations method not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.load_annotations_group": [[149, 159], ["generator.Generator.load_annotations"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_annotations"], ["", "def", "load_annotations_group", "(", "self", ",", "group", ")", ":", "\n", "        ", "\"\"\" Load annotations for all images in group.\n        \"\"\"", "\n", "annotations_group", "=", "[", "self", ".", "load_annotations", "(", "image_index", ")", "for", "image_index", "in", "group", "]", "\n", "# for annotations in annotations_group:", "\n", "#     assert(isinstance(annotations, dict)), '\\'load_annotations\\' should return a list of dictionaries, received: {}'.format(type(annotations))", "\n", "#     assert('labels' in annotations), '\\'load_annotations\\' should return a list of dictionaries that contain \\'labels\\' and \\'bboxes\\'.'", "\n", "#     assert('bboxes' in annotations), '\\'load_annotations\\' should return a list of dictionaries that contain \\'labels\\' and \\'bboxes\\'.'", "\n", "\n", "return", "annotations_group", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.filter_annotations": [[160, 186], ["enumerate", "zip", "len", "numpy.where", "warnings.warn", "annotations_group[].keys", "numpy.delete"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where"], ["", "def", "filter_annotations", "(", "self", ",", "image_group", ",", "annotations_group", ",", "group", ")", ":", "\n", "        ", "\"\"\" Filter annotations by removing those that are outside of the image bounds or whose width/height < 0.\n        \"\"\"", "\n", "# test all annotations", "\n", "for", "index", ",", "(", "image", ",", "annotations", ")", "in", "enumerate", "(", "zip", "(", "image_group", ",", "annotations_group", ")", ")", ":", "\n", "# test x2 < x1 | y2 < y1 | x1 < 0 | y1 < 0 | x2 <= 0 | y2 <= 0 | x2 >= image.shape[1] | y2 >= image.shape[0]", "\n", "            ", "invalid_indices", "=", "np", ".", "where", "(", "\n", "(", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "2", "]", "<=", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "0", "]", ")", "|", "\n", "(", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "3", "]", "<=", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "1", "]", ")", "|", "\n", "(", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "0", "]", "<", "0", ")", "|", "\n", "(", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "1", "]", "<", "0", ")", "|", "\n", "(", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "2", "]", ">", "image", ".", "shape", "[", "1", "]", ")", "|", "\n", "(", "annotations", "[", "'bboxes'", "]", "[", ":", ",", "3", "]", ">", "image", ".", "shape", "[", "0", "]", ")", "\n", ")", "[", "0", "]", "\n", "\n", "# delete invalid indices", "\n", "if", "len", "(", "invalid_indices", ")", ":", "\n", "                ", "warnings", ".", "warn", "(", "'Image with id {} (shape {}) contains the following invalid boxes: {}.'", ".", "format", "(", "\n", "group", "[", "index", "]", ",", "\n", "image", ".", "shape", ",", "\n", "annotations", "[", "'bboxes'", "]", "[", "invalid_indices", ",", ":", "]", "\n", ")", ")", "\n", "for", "k", "in", "annotations_group", "[", "index", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "annotations_group", "[", "index", "]", "[", "k", "]", "=", "np", ".", "delete", "(", "annotations", "[", "k", "]", ",", "invalid_indices", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "", "return", "image_group", ",", "annotations_group", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.load_image_group": [[187, 191], ["generator.Generator.load_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_image"], ["", "def", "load_image_group", "(", "self", ",", "group", ")", ":", "\n", "        ", "\"\"\" Load images for all images in a group.\n        \"\"\"", "\n", "return", "[", "self", ".", "load_image", "(", "image_index", ")", "for", "image_index", "in", "group", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.random_transform_group_entry": [[192, 209], ["crfnet.utils.image.apply_transform", "annotations[].copy", "range", "crfnet.utils.image.adjust_transform_for_image", "crfnet.utils.transform.transform_aabb", "next"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.apply_transform", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.image.adjust_transform_for_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.transform.transform_aabb"], ["", "def", "random_transform_group_entry", "(", "self", ",", "image", ",", "annotations", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\" Randomly transforms image and annotation.\n        \"\"\"", "\n", "# randomly transform both image and annotations", "\n", "if", "transform", "is", "not", "None", "or", "self", ".", "transform_generator", ":", "\n", "            ", "if", "transform", "is", "None", ":", "\n", "                ", "transform", "=", "adjust_transform_for_image", "(", "next", "(", "self", ".", "transform_generator", ")", ",", "image", ",", "self", ".", "transform_parameters", ".", "relative_translation", ")", "\n", "\n", "# apply transformation to image", "\n", "", "image", "=", "apply_transform", "(", "transform", ",", "image", ",", "self", ".", "transform_parameters", ")", "\n", "\n", "# Transform the bounding boxes in the annotations.", "\n", "annotations", "[", "'bboxes'", "]", "=", "annotations", "[", "'bboxes'", "]", ".", "copy", "(", ")", "\n", "for", "index", "in", "range", "(", "annotations", "[", "'bboxes'", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "annotations", "[", "'bboxes'", "]", "[", "index", ",", ":", "]", "=", "transform_aabb", "(", "transform", ",", "annotations", "[", "'bboxes'", "]", "[", "index", ",", ":", "]", ")", "\n", "\n", "", "", "return", "image", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.random_transform_group": [[210, 221], ["range", "len", "len", "len", "generator.Generator.random_transform_group_entry"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.random_transform_group_entry"], ["", "def", "random_transform_group", "(", "self", ",", "image_group", ",", "annotations_group", ")", ":", "\n", "        ", "\"\"\" Randomly transforms each image and its annotations.\n        \"\"\"", "\n", "\n", "assert", "(", "len", "(", "image_group", ")", "==", "len", "(", "annotations_group", ")", ")", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "image_group", ")", ")", ":", "\n", "# transform a single group entry", "\n", "            ", "image_group", "[", "index", "]", ",", "annotations_group", "[", "index", "]", "=", "self", ".", "random_transform_group_entry", "(", "image_group", "[", "index", "]", ",", "annotations_group", "[", "index", "]", ")", "\n", "\n", "", "return", "image_group", ",", "annotations_group", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.resize_image": [[222, 226], ["crfnet.utils.image.resize_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.resize_image"], ["", "def", "resize_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\" Resize an image using image_min_side and image_max_side.\n        \"\"\"", "\n", "return", "resize_image", "(", "image", ",", "min_side", "=", "self", ".", "image_min_side", ",", "max_side", "=", "self", ".", "image_max_side", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.preprocess_group_entry": [[227, 245], ["generator.Generator.resize_image", "keras.backend.cast_to_floatx", "generator.Generator.preprocess_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.resize_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image"], ["", "def", "preprocess_group_entry", "(", "self", ",", "image", ",", "annotations", ")", ":", "\n", "        ", "\"\"\" Preprocess image and its annotations.\n        \"\"\"", "\n", "# preprocess the image", "\n", "if", "self", ".", "preprocess_image", ":", "\n", "            ", "image", "=", "self", ".", "preprocess_image", "(", "image", ")", "\n", "\n", "# resize image", "\n", "", "image", ",", "image_scale", "=", "self", ".", "resize_image", "(", "image", ")", "\n", "\n", "if", "annotations", ":", "\n", "# apply resizing to annotations too", "\n", "            ", "annotations", "[", "'bboxes'", "]", "*=", "image_scale", "\n", "\n", "# convert to the wanted keras floatx", "\n", "", "image", "=", "keras", ".", "backend", ".", "cast_to_floatx", "(", "image", ")", "\n", "\n", "return", "image", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.preprocess_group": [[246, 261], ["range", "len", "generator.Generator.preprocess_group_entry", "len", "len"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.preprocess_group_entry"], ["", "def", "preprocess_group", "(", "self", ",", "image_group", ",", "annotations_group", ")", ":", "\n", "        ", "\"\"\" Preprocess each image and its annotations in its group.\n        \"\"\"", "\n", "if", "annotations_group", ":", "\n", "            ", "assert", "(", "len", "(", "image_group", ")", "==", "len", "(", "annotations_group", ")", ")", "\n", "\n", "", "for", "index", "in", "range", "(", "len", "(", "image_group", ")", ")", ":", "\n", "# preprocess a single group entry", "\n", "            ", "anns_group_entry", "=", "annotations_group", "[", "index", "]", "if", "annotations_group", "else", "None", "\n", "image_group", "[", "index", "]", ",", "preprocessed_anns", "=", "self", ".", "preprocess_group_entry", "(", "image_group", "[", "index", "]", ",", "anns_group_entry", ")", "\n", "\n", "if", "annotations_group", ":", "\n", "                ", "annotations_group", "[", "index", "]", "=", "preprocessed_anns", "\n", "\n", "", "", "return", "image_group", ",", "annotations_group", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.group_images": [[262, 274], ["list", "range", "random.shuffle", "generator.Generator.size", "list.sort", "range", "range", "len", "generator.Generator.image_aspect_ratio", "len"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.image_aspect_ratio"], ["", "def", "group_images", "(", "self", ")", ":", "\n", "        ", "\"\"\" Order the images according to self.order and makes groups of self.batch_size.\n        \"\"\"", "\n", "# determine the order of the images", "\n", "order", "=", "list", "(", "range", "(", "self", ".", "size", "(", ")", ")", ")", "\n", "if", "self", ".", "group_method", "==", "'random'", ":", "\n", "            ", "random", ".", "shuffle", "(", "order", ")", "\n", "", "elif", "self", ".", "group_method", "==", "'ratio'", ":", "\n", "            ", "order", ".", "sort", "(", "key", "=", "lambda", "x", ":", "self", ".", "image_aspect_ratio", "(", "x", ")", ")", "\n", "\n", "# divide into groups, one group = one batch", "\n", "", "self", ".", "groups", "=", "[", "[", "order", "[", "x", "%", "len", "(", "order", ")", "]", "for", "x", "in", "range", "(", "i", ",", "i", "+", "self", ".", "batch_size", ")", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "order", ")", ",", "self", ".", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.compute_inputs": [[275, 293], ["tuple", "numpy.zeros", "enumerate", "keras.backend.image_data_format", "image_batch.transpose.transpose.transpose", "max", "keras.backend.floatx", "range", "len"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "compute_inputs", "(", "self", ",", "image_group", ")", ":", "\n", "        ", "\"\"\" Compute inputs for the network using an image_group.\n        \"\"\"", "\n", "# get the max image shape", "\n", "max_shape", "=", "tuple", "(", "max", "(", "image", ".", "shape", "[", "x", "]", "for", "image", "in", "image_group", ")", "for", "x", "in", "range", "(", "3", ")", ")", "\n", "\n", "# construct an image batch object", "\n", "# image_batch = np.zeros((self.batch_size,) + max_shape, dtype=keras.backend.floatx())", "\n", "image_batch", "=", "np", ".", "zeros", "(", "(", "len", "(", "image_group", ")", ",", ")", "+", "max_shape", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "\n", "# copy all images to the upper left part of the image batch object", "\n", "for", "image_index", ",", "image", "in", "enumerate", "(", "image_group", ")", ":", "\n", "            ", "image_batch", "[", "image_index", ",", ":", "image", ".", "shape", "[", "0", "]", ",", ":", "image", ".", "shape", "[", "1", "]", ",", ":", "image", ".", "shape", "[", "2", "]", "]", "=", "image", "\n", "\n", "", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "image_batch", "=", "image_batch", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n", "", "return", "image_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.generate_anchors": [[294, 297], ["crfnet.utils.anchor.anchors_for_shape"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor.anchors_for_shape"], ["", "def", "generate_anchors", "(", "self", ",", "image_shape", ")", ":", "\n", "        ", "anchor_params", "=", "self", ".", "anchor_params", "\n", "return", "anchors_for_shape", "(", "image_shape", ",", "anchor_params", "=", "anchor_params", ",", "shapes_callback", "=", "self", ".", "compute_shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.compute_targets": [[298, 314], ["tuple", "generator.Generator.generate_anchors", "generator.Generator.compute_anchor_targets", "list", "generator.Generator.num_classes", "max", "range"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.generate_anchors", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "compute_targets", "(", "self", ",", "image_group", ",", "annotations_group", ")", ":", "\n", "        ", "\"\"\" Compute target outputs for the network using images and their annotations.\n        \"\"\"", "\n", "# get the max image shape", "\n", "max_shape", "=", "tuple", "(", "max", "(", "image", ".", "shape", "[", "x", "]", "for", "image", "in", "image_group", ")", "for", "x", "in", "range", "(", "3", ")", ")", "\n", "anchors", "=", "self", ".", "generate_anchors", "(", "max_shape", ")", "\n", "\n", "batches", "=", "self", ".", "compute_anchor_targets", "(", "\n", "anchors", ",", "\n", "image_group", ",", "\n", "annotations_group", ",", "\n", "self", ".", "num_classes", "(", ")", ",", "\n", "distance", "=", "self", ".", "distance", "\n", ")", "\n", "\n", "return", "list", "(", "batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.compute_input_output": [[315, 348], ["generator.Generator.load_image_group", "generator.Generator.preprocess_group", "generator.Generator.compute_inputs", "generator.Generator.load_annotations_group", "generator.Generator.random_transform_group", "generator.Generator.compute_targets", "generator.Generator.filter_annotations"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.load_image_group", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.preprocess_group", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.compute_inputs", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.load_annotations_group", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.random_transform_group", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.compute_targets", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.filter_annotations"], ["", "def", "compute_input_output", "(", "self", ",", "group", ",", "inference", "=", "False", ")", ":", "\n", "        ", "\"\"\" Compute inputs and target outputs for the network.\n        \"\"\"", "\n", "# load images and annotations", "\n", "image_group", "=", "self", ".", "load_image_group", "(", "group", ")", "\n", "\n", "if", "inference", ":", "\n", "            ", "annotations_group", "=", "None", "\n", "", "else", ":", "\n", "            ", "annotations_group", "=", "self", ".", "load_annotations_group", "(", "group", ")", "\n", "\n", "# Load annotation", "\n", "if", "self", ".", "filter_annotations_enabled", ":", "\n", "# check validity of annotations", "\n", "                ", "image_group", ",", "annotations_group", "=", "self", ".", "filter_annotations", "(", "image_group", ",", "annotations_group", ",", "group", ")", "\n", "\n", "# randomly transform data", "\n", "", "image_group", ",", "annotations_group", "=", "self", ".", "random_transform_group", "(", "image_group", ",", "annotations_group", ")", "\n", "\n", "\n", "# perform preprocessing steps", "\n", "", "image_group", ",", "annotations_group", "=", "self", ".", "preprocess_group", "(", "image_group", ",", "annotations_group", ")", "\n", "\n", "# compute network inputs", "\n", "inputs", "=", "self", ".", "compute_inputs", "(", "image_group", ")", "\n", "\n", "if", "annotations_group", ":", "\n", "# compute network targets", "\n", "            ", "targets", "=", "self", ".", "compute_targets", "(", "image_group", ",", "annotations_group", ")", "\n", "", "else", ":", "\n", "            ", "targets", "=", "None", "\n", "\n", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.__len__": [[349, 355], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Number of batches for generator.\n        \"\"\"", "\n", "\n", "return", "len", "(", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.__getitem__": [[356, 364], ["generator.Generator.compute_input_output"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.compute_input_output"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Keras sequence method for generating batches.\n        \"\"\"", "\n", "group", "=", "self", ".", "groups", "[", "index", "]", "\n", "inputs", ",", "targets", "=", "self", ".", "compute_input_output", "(", "group", ",", "inference", "=", "self", ".", "inference", ")", "\n", "\n", "return", "inputs", ",", "targets", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.__init__": [[57, 186], ["dict", "nuscenes_generator.NuscenesGenerator._get_class_label_mapping", "math.radians", "progressbar.ProgressBar", "hasattr", "generator.Generator.__init__", "nuscenes_generator.NuscenesGenerator._is_image_plus_enabled", "NotImplementedError", "range", "nusc.get", "range", "print", "isinstance", "len", "progressbar.ProgressBar.update", "nusc.get"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator._get_class_label_mapping", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator._is_image_plus_enabled", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nusc", ",", "\n", "scene_indices", "=", "None", ",", "\n", "channels", "=", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "category_mapping", "=", "None", ",", "\n", "radar_input_name", "=", "None", ",", "\n", "radar_width", "=", "None", ",", "\n", "image_radar_fusion", "=", "True", ",", "\n", "camera_dropout", "=", "0.0", ",", "\n", "radar_dropout", "=", "0.0", ",", "\n", "normalize_radar", "=", "False", ",", "\n", "sample_selection", "=", "False", ",", "\n", "only_radar_annotated", "=", "False", ",", "\n", "n_sweeps", "=", "1", ",", "\n", "noise_filter", "=", "None", ",", "\n", "noise_filter_threshold", "=", "0.5", ",", "\n", "noisy_image_method", "=", "None", ",", "\n", "noise_factor", "=", "0", ",", "\n", "perfect_noise_filter", "=", "False", ",", "\n", "noise_category_selection", "=", "None", ",", "\n", "inference", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\" Initialize a nuScenes data generator.\n        : use param config for giving the arguments to this class\n\n        :param nusc: Object pointing at a nuscenes database\n        :param sample_indices: <int> Which samples to take from nusc database\n        :param channels: Which image and radar channels to use. Only in combination with\n            image_radar_fusion=True will return image_plus data. Otherwise the given channels\n            are split into radar_infeed and image_infeed.\n        :param category_mapping: <dict> dictionary between original classes and target classes.\n            Only classes given by this dict will be used for annotations. None for all categories.\n        :param radar_input_name: <str> name of the input_tensor for radar infeed into the nn\n        :param radar_width: width of the radar-data-array\n        :param image_radar_fusion: <bool> Determines if the data_generator performs the \n            default image_plus fusion.\n        \"\"\"", "\n", "\n", "# Parameters", "\n", "self", ".", "nusc", "=", "nusc", "\n", "self", ".", "dropout_chance", "=", "0.0", "\n", "self", ".", "radar_sensors", "=", "[", "'RADAR_FRONT'", "]", "\n", "self", ".", "camera_sensors", "=", "[", "'CAM_FRONT'", "]", "\n", "self", ".", "labels", "=", "{", "}", "\n", "self", ".", "image_data", "=", "dict", "(", ")", "\n", "self", ".", "classes", ",", "self", ".", "labels", "=", "self", ".", "_get_class_label_mapping", "(", "[", "c", "[", "'name'", "]", "for", "c", "in", "nusc", ".", "category", "]", ",", "category_mapping", ")", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "radar_channels", "=", "[", "ch", "for", "ch", "in", "channels", "if", "ch", ">=", "3", "]", "\n", "self", ".", "image_channels", "=", "[", "ch", "for", "ch", "in", "channels", "if", "ch", "<", "3", "]", "\n", "self", ".", "normalize_bbox", "=", "False", "# True for normalizing the bbox to [0,1]", "\n", "self", ".", "radar_input_name", "=", "radar_input_name", "\n", "self", ".", "radar_width", "=", "radar_width", "\n", "self", ".", "radar_dropout", "=", "radar_dropout", "\n", "self", ".", "camera_dropout", "=", "camera_dropout", "\n", "self", ".", "sample_selection", "=", "sample_selection", "\n", "self", ".", "only_radar_annotated", "=", "only_radar_annotated", "\n", "self", ".", "n_sweeps", "=", "n_sweeps", "\n", "self", ".", "noisy_image_method", "=", "noisy_image_method", "\n", "self", ".", "noise_factor", "=", "noise_factor", "\n", "self", ".", "cartesian_uncertainty", "=", "(", "0", ",", "0", ",", "0", ")", "# meters", "\n", "self", ".", "angular_uncertainty", "=", "math", ".", "radians", "(", "0", ")", "# degree", "\n", "self", ".", "inference", "=", "inference", "\n", "\n", "#todo we cannot initialize the parent class first, because it depends on size()", "\n", "self", ".", "image_min_side", "=", "kwargs", "[", "'image_min_side'", "]", "\n", "self", ".", "image_max_side", "=", "kwargs", "[", "'image_max_side'", "]", "\n", "\n", "# assign functions", "\n", "self", ".", "image_radar_fusion", "=", "image_radar_fusion", "\n", "self", ".", "normalize_radar", "=", "normalize_radar", "\n", "\n", "# Optional imports", "\n", "self", ".", "radar_array_creation", "=", "None", "\n", "if", "self", ".", "_is_image_plus_enabled", "(", ")", "or", "self", ".", "camera_dropout", ">", "0.0", ":", "\n", "# Installing vizdom is required", "\n", "            ", "from", "crfnet", ".", "data_processing", ".", "fusion", ".", "fusion_projection_lines", "import", "imageplus_creation", ",", "create_spatial_point_array", "\n", "\n", "self", ".", "image_plus_creation", "=", "imageplus_creation", "\n", "self", ".", "radar_array_creation", "=", "create_spatial_point_array", "\n", "\n", "", "self", ".", "noise_filter_threshold", "=", "noise_filter_threshold", "\n", "self", ".", "perfect_noise_filter", "=", "perfect_noise_filter", "\n", "self", ".", "noise_category_selection", "=", "noise_category_selection", "\n", "\n", "\n", "# TEST: Create immediately", "\n", "if", "noise_filter", "and", "not", "isinstance", "(", "noise_filter", ",", "NfDockerClient", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Neural Filter not in opensource repository '", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "noise_filter", "=", "None", "\n", "\n", "# Create all sample tokens", "\n", "", "self", ".", "sample_tokens", "=", "{", "}", "\n", "prog", "=", "0", "\n", "progbar", "=", "progressbar", ".", "ProgressBar", "(", "prefix", "=", "'Initializing data generator: '", ")", "\n", "skip_count", "=", "0", "\n", "\n", "\n", "\n", "# Resolve sample indexing", "\n", "if", "scene_indices", "is", "None", ":", "\n", "# We are using all scenes", "\n", "            ", "scene_indices", "=", "range", "(", "len", "(", "nusc", ".", "scene", ")", ")", "\n", "\n", "", "assert", "hasattr", "(", "scene_indices", ",", "'__iter__'", ")", ",", "\"Iterable object containing sample indices expected\"", "\n", "\n", "for", "scene_index", "in", "scene_indices", ":", "\n", "            ", "first_sample_token", "=", "nusc", ".", "scene", "[", "scene_index", "]", "[", "'first_sample_token'", "]", "\n", "nbr_samples", "=", "nusc", ".", "scene", "[", "scene_index", "]", "[", "'nbr_samples'", "]", "\n", "\n", "curr_sample", "=", "nusc", ".", "get", "(", "'sample'", ",", "first_sample_token", ")", "\n", "\n", "for", "_", "in", "range", "(", "nbr_samples", ")", ":", "\n", "                ", "self", ".", "sample_tokens", "[", "prog", "]", "=", "curr_sample", "[", "'token'", "]", "\n", "if", "curr_sample", "[", "'next'", "]", ":", "\n", "                    ", "next_token", "=", "curr_sample", "[", "'next'", "]", "\n", "curr_sample", "=", "nusc", ".", "get", "(", "'sample'", ",", "next_token", ")", "\n", "", "prog", "+=", "1", "\n", "progbar", ".", "update", "(", "prog", ")", "\n", "\n", "\n", "", "", "if", "self", ".", "sample_selection", ":", "print", "(", "\"\\nSkipped {} samples due to zero annotations\"", ".", "format", "(", "skip_count", ")", ")", "\n", "# Create all annotations and put into image_data", "\n", "self", ".", "image_data", "=", "{", "image_index", ":", "None", "for", "image_index", "in", "self", ".", "sample_tokens", "}", "\n", "\n", "# Finalize", "\n", "super", "(", "NuscenesGenerator", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator._get_class_label_mapping": [[187, 238], ["category_names.copy", "category_names.copy.append", "set", "list", "list.sort", "label_to_name.items", "original_name_to_label.values", "range", "all", "dict", "dict.values", "enumerate", "len", "max", "original_name_to_label.keys"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "@", "staticmethod", "\n", "def", "_get_class_label_mapping", "(", "category_names", ",", "category_mapping", ")", ":", "\n", "        ", "\"\"\"\n        :param category_mapping: [dict] Map from original name to target name. Subsets of names are supported. \n            e.g. {'pedestrian' : 'pedestrian'} will map all pedestrian types to the same label\n\n        :returns: \n            [0]: [dict of (str, int)] mapping from category name to the corresponding index-number\n            [1]: [dict of (int, str)] mapping from index number to category name\n        \"\"\"", "\n", "# Initialize local variables", "\n", "original_name_to_label", "=", "{", "}", "\n", "original_category_names", "=", "category_names", ".", "copy", "(", ")", "\n", "original_category_names", ".", "append", "(", "'bg'", ")", "\n", "if", "category_mapping", "is", "None", ":", "\n", "# Create identity mapping and ignore no class", "\n", "            ", "category_mapping", "=", "dict", "(", ")", "\n", "for", "cat_name", "in", "category_names", ":", "\n", "                ", "category_mapping", "[", "cat_name", "]", "=", "cat_name", "\n", "\n", "# List of unique class_names", "\n", "", "", "selected_category_names", "=", "set", "(", "category_mapping", ".", "values", "(", ")", ")", "# unordered", "\n", "selected_category_names", "=", "list", "(", "selected_category_names", ")", "\n", "selected_category_names", ".", "sort", "(", ")", "# ordered", "\n", "\n", "# Create the label to class_name mapping", "\n", "label_to_name", "=", "{", "label", ":", "name", "for", "label", ",", "name", "in", "enumerate", "(", "selected_category_names", ")", "}", "\n", "label_to_name", "[", "len", "(", "label_to_name", ")", "]", "=", "'bg'", "# Add the background class", "\n", "\n", "# Create original class name to label mapping", "\n", "for", "label", ",", "label_name", "in", "label_to_name", ".", "items", "(", ")", ":", "\n", "\n", "# Looking for all the original names that are adressed by label name", "\n", "            ", "targets", "=", "[", "original_name", "for", "original_name", "in", "original_category_names", "if", "label_name", "in", "original_name", "]", "\n", "\n", "# Assigning the same label for all adressed targets", "\n", "for", "target", "in", "targets", ":", "\n", "\n", "# Check for ambiguity", "\n", "                ", "assert", "target", "not", "in", "original_name_to_label", ".", "keys", "(", ")", ",", "'ambigous mapping found for (%s->%s)'", "%", "(", "target", ",", "label_name", ")", "\n", "\n", "# Assign label to original name", "\n", "# Some label_names will have the same label, which is totally fine", "\n", "original_name_to_label", "[", "target", "]", "=", "label", "\n", "\n", "# Check for correctness", "\n", "", "", "actual_labels", "=", "original_name_to_label", ".", "values", "(", ")", "\n", "expected_labels", "=", "range", "(", "0", ",", "max", "(", "actual_labels", ")", "+", "1", ")", "# we want to start labels at 0", "\n", "assert", "all", "(", "[", "label", "in", "actual_labels", "for", "label", "in", "expected_labels", "]", ")", ",", "'Expected labels do not match actual labels'", "\n", "\n", "return", "original_name_to_label", ",", "label_to_name", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator._is_image_plus_enabled": [[239, 248], ["len"], "methods", ["None"], ["", "def", "_is_image_plus_enabled", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        True if image radar fusion is enabled and \n        radar channels are requested.\n        \"\"\"", "\n", "r", "=", "0", "in", "self", ".", "channels", "\n", "g", "=", "1", "in", "self", ".", "channels", "\n", "b", "=", "2", "in", "self", ".", "channels", "\n", "return", "self", ".", "image_radar_fusion", "and", "len", "(", "self", ".", "channels", ")", ">", "r", "+", "g", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.size": [[249, 253], ["len"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the dataset.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "sample_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.num_classes": [[254, 258], ["len"], "methods", ["None"], ["", "def", "num_classes", "(", "self", ")", ":", "\n", "        ", "\"\"\" Number of classes in the dataset.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.has_label": [[259, 263], ["None"], "methods", ["None"], ["", "def", "has_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\" Return True if label is a known label.\n        \"\"\"", "\n", "return", "label", "in", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.has_name": [[264, 268], ["None"], "methods", ["None"], ["", "def", "has_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\" Returns True if name is a known class.\n        \"\"\"", "\n", "return", "name", "in", "self", ".", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.name_to_label": [[269, 273], ["None"], "methods", ["None"], ["", "def", "name_to_label", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\" Map name to label.\n        \"\"\"", "\n", "return", "self", ".", "classes", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.label_to_name": [[274, 278], ["None"], "methods", ["None"], ["", "def", "label_to_name", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\" Map label to name.\n        \"\"\"", "\n", "return", "self", ".", "labels", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.inv_label_to_name": [[279, 284], ["nuscenes_generator.NuscenesGenerator.labels.items"], "methods", ["None"], ["", "def", "inv_label_to_name", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\" Map name to label.\n        \"\"\"", "\n", "class_dict", "=", "{", "y", ":", "x", "for", "x", ",", "y", "in", "self", ".", "labels", ".", "items", "(", ")", "}", "\n", "return", "class_dict", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.image_aspect_ratio": [[285, 291], ["None"], "methods", ["None"], ["", "def", "image_aspect_ratio", "(", "self", ",", "image_index", ")", ":", "\n", "        ", "\"\"\" Compute the aspect ratio for an image with image_index.\n        All images of nuscenes dataset have the same aspect ratio which is 16/9\n        \"\"\"", "\n", "# All images of nuscenes dataset have the same aspect ratio", "\n", "return", "16", "/", "9", "\n", "# sample_token = self.sample_tokens[image_index]", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_radar_array": [[298, 321], ["nuscenes_generator.NuscenesGenerator.nusc.get", "nuscenes_generator.NuscenesGenerator.load_sample_data", "nuscenes_generator.NuscenesGenerator.radar_array_creation"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_sample_data"], ["", "def", "load_radar_array", "(", "self", ",", "sample_index", ",", "target_width", ")", ":", "\n", "# Initialize local variables", "\n", "        ", "if", "not", "self", ".", "radar_array_creation", ":", "\n", "            ", "from", ".", ".", "raw_data_fusion", ".", "fusion_projection_lines", "import", "create_spatial_point_array", "\n", "self", ".", "radar_array_creation", "=", "create_spatial_point_array", "\n", "\n", "", "radar_name", "=", "self", ".", "radar_sensors", "[", "0", "]", "\n", "camera_name", "=", "self", ".", "camera_sensors", "[", "0", "]", "\n", "\n", "# Gettign data from nuscenes database", "\n", "sample_token", "=", "self", ".", "sample_tokens", "[", "sample_index", "]", "\n", "sample", "=", "self", ".", "nusc", ".", "get", "(", "'sample'", ",", "sample_token", ")", "\n", "\n", "# Grab the front camera and the radar sensor.", "\n", "radar_token", "=", "sample", "[", "'data'", "]", "[", "radar_name", "]", "\n", "camera_token", "=", "sample", "[", "'data'", "]", "[", "camera_name", "]", "\n", "image_target_shape", "=", "(", "self", ".", "image_min_side", ",", "self", ".", "image_max_side", ")", "\n", "\n", "# Create the array", "\n", "radar_sample", "=", "self", ".", "load_sample_data", "(", "sample", ",", "radar_name", ")", "# Load samples from disk", "\n", "radar_array", "=", "self", ".", "radar_array_creation", "(", "self", ".", "nusc", ",", "radar_sample", ",", "radar_token", ",", "camera_token", ",", "target_width", "=", "target_width", ")", "\n", "\n", "return", "radar_array", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.set_noise_factor": [[322, 327], ["None"], "methods", ["None"], ["", "def", "set_noise_factor", "(", "self", ",", "noise_factor", ")", ":", "\n", "        ", "\"\"\"\n        This function turns off the noise factor: It is useful for rendering. \n        \"\"\"", "\n", "self", ".", "noise_factor", "=", "noise_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_image": [[328, 438], ["nuscenes_generator.NuscenesGenerator.nusc.get", "nuscenes_generator.NuscenesGenerator.load_sample_data", "utils.noise_img.noisy", "nuscenes_generator.NuscenesGenerator._is_image_plus_enabled", "nuscenes.utils.data_classes.RadarPointCloud.from_file_multisweep", "numpy.compress.astype", "nuscenes_generator.NuscenesGenerator.image_plus_creation", "cv2.resize", "range", "utils.radar.enrich_radar_data", "list", "len", "numpy.zeros", "numpy.concatenate", "math.radians", "nuscenes_generator.NuscenesGenerator.nusc.get", "utils.nuscenes_helper.calc_mask", "numpy.compress", "int", "range", "numpy.random.rand", "numpy.random.rand", "pcs.insert", "nuscenes_generator.NuscenesGenerator.noise_filter.denoise", "utils.radar.normalize", "len", "nuscenes.utils.data_classes.RadarPointCloud", "numpy.zeros", "len", "nuscenes.utils.data_classes.RadarPointCloud.nbr_dims"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_sample_data", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.noise_img.noisy", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator._is_image_plus_enabled", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.enrich_radar_data", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.nuscenes_helper.calc_mask", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.normalize"], ["", "def", "load_image", "(", "self", ",", "image_index", ")", ":", "\n", "        ", "\"\"\"\n        Returns the image plus from given image and radar samples.\n        It takes the requested channels into account.\n\n        :param sample_token: [str] the token pointing to a certain sample\n\n        :returns: imageplus\n        \"\"\"", "\n", "# Initialize local variables", "\n", "radar_name", "=", "self", ".", "radar_sensors", "[", "0", "]", "\n", "camera_name", "=", "self", ".", "camera_sensors", "[", "0", "]", "\n", "\n", "# Gettign data from nuscenes database", "\n", "sample_token", "=", "self", ".", "sample_tokens", "[", "image_index", "]", "\n", "sample", "=", "self", ".", "nusc", ".", "get", "(", "'sample'", ",", "sample_token", ")", "\n", "\n", "# Grab the front camera and the radar sensor.", "\n", "radar_token", "=", "sample", "[", "'data'", "]", "[", "radar_name", "]", "\n", "camera_token", "=", "sample", "[", "'data'", "]", "[", "camera_name", "]", "\n", "image_target_shape", "=", "(", "self", ".", "image_min_side", ",", "self", ".", "image_max_side", ")", "\n", "\n", "# Load the image", "\n", "image_sample", "=", "self", ".", "load_sample_data", "(", "sample", ",", "camera_name", ")", "\n", "\n", "# Add noise to the image if enabled", "\n", "if", "self", ".", "noisy_image_method", "is", "not", "None", "and", "self", ".", "noise_factor", ">", "0", ":", "\n", "            ", "image_sample", "=", "noisy", "(", "self", ".", "noisy_image_method", ",", "image_sample", ",", "self", ".", "noise_factor", ")", "\n", "\n", "", "if", "self", ".", "_is_image_plus_enabled", "(", ")", "or", "self", ".", "camera_dropout", ">", "0.0", ":", "\n", "\n", "# Parameters", "\n", "            ", "kwargs", "=", "{", "\n", "'pointsensor_token'", ":", "radar_token", ",", "\n", "'camera_token'", ":", "camera_token", ",", "\n", "'height'", ":", "(", "0", ",", "self", ".", "radar_projection_height", ")", ",", "\n", "'image_target_shape'", ":", "image_target_shape", ",", "\n", "'clear_radar'", ":", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "radar_dropout", ",", "\n", "'clear_image'", ":", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "camera_dropout", ",", "\n", "}", "\n", "\n", "# Create image plus", "\n", "# radar_sample = self.load_sample_data(sample, radar_name) # Load samples from disk", "\n", "\n", "\n", "# Get filepath", "\n", "if", "self", ".", "noise_filter", ":", "\n", "                ", "required_sweep_count", "=", "self", ".", "n_sweeps", "+", "self", ".", "noise_filter", ".", "num_sweeps_required", "-", "1", "\n", "", "else", ":", "\n", "                ", "required_sweep_count", "=", "self", ".", "n_sweeps", "\n", "\n", "# sd_rec = self.nusc.get('sample_data', sample['data'][sensor_channel])", "\n", "", "sensor_channel", "=", "radar_name", "\n", "pcs", ",", "times", "=", "RadarPointCloud", ".", "from_file_multisweep", "(", "self", ".", "nusc", ",", "sample", ",", "sensor_channel", ",", "sensor_channel", ",", "nsweeps", "=", "required_sweep_count", ",", "min_distance", "=", "0.0", ",", "merge", "=", "False", ")", "\n", "\n", "\n", "if", "self", ".", "noise_filter", ":", "\n", "# fill up with zero sweeps", "\n", "                ", "for", "_", "in", "range", "(", "required_sweep_count", "-", "len", "(", "pcs", ")", ")", ":", "\n", "                    ", "pcs", ".", "insert", "(", "0", ",", "RadarPointCloud", "(", "np", ".", "zeros", "(", "shape", "=", "(", "RadarPointCloud", ".", "nbr_dims", "(", ")", ",", "0", ")", ")", ")", ")", "\n", "\n", "", "", "radar_sample", "=", "[", "radar", ".", "enrich_radar_data", "(", "pc", ".", "points", ")", "for", "pc", "in", "pcs", "]", "\n", "\n", "if", "self", ".", "noise_filter", ":", "\n", "##### Filter the pcs #####", "\n", "                ", "radar_sample", "=", "list", "(", "self", ".", "noise_filter", ".", "denoise", "(", "radar_sample", ",", "self", ".", "n_sweeps", ")", ")", "\n", "\n", "", "if", "len", "(", "radar_sample", ")", "==", "0", ":", "\n", "                ", "radar_sample", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "radar", ".", "channel_map", ")", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "##### merge pcs into single radar samples array #####", "\n", "                ", "radar_sample", "=", "np", ".", "concatenate", "(", "radar_sample", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "radar_sample", "=", "radar_sample", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "if", "self", ".", "perfect_noise_filter", ":", "\n", "                ", "cartesian_uncertainty", "=", "0.5", "# meters", "\n", "angular_uncertainty", "=", "math", ".", "radians", "(", "1.7", ")", "# degree", "\n", "category_selection", "=", "self", ".", "noise_category_selection", "\n", "\n", "nusc_sample_data", "=", "self", ".", "nusc", ".", "get", "(", "'sample_data'", ",", "radar_token", ")", "\n", "radar_gt_mask", "=", "calc_mask", "(", "nusc", "=", "self", ".", "nusc", ",", "nusc_sample_data", "=", "nusc_sample_data", ",", "points3d", "=", "radar_sample", "[", "0", ":", "3", ",", ":", "]", ",", "tolerance", "=", "cartesian_uncertainty", ",", "angle_tolerance", "=", "angular_uncertainty", ",", "category_selection", "=", "category_selection", ")", "\n", "\n", "# radar_sample = radar_sample[:, radar_gt_mask.astype(np.bool)]", "\n", "radar_sample", "=", "np", ".", "compress", "(", "radar_gt_mask", ",", "radar_sample", ",", "axis", "=", "-", "1", ")", "\n", "\n", "\n", "", "if", "self", ".", "normalize_radar", ":", "\n", "# we need to noramlize", "\n", "# : use preprocess method analog to image preprocessing", "\n", "                ", "sigma_factor", "=", "int", "(", "self", ".", "normalize_radar", ")", "\n", "for", "ch", "in", "range", "(", "3", ",", "radar_sample", ".", "shape", "[", "0", "]", ")", ":", "# neural fusion requires x y and z to be not normalized", "\n", "                    ", "norm_interval", "=", "(", "-", "127.5", ",", "127.5", ")", "# caffee mode is default and has these norm interval for img", "\n", "radar_sample", "[", "ch", ",", ":", "]", "=", "radar", ".", "normalize", "(", "ch", ",", "radar_sample", "[", "ch", ",", ":", "]", ",", "normalization_interval", "=", "norm_interval", ",", "sigma_factor", "=", "sigma_factor", ")", "\n", "\n", "\n", "", "", "img_p_full", "=", "self", ".", "image_plus_creation", "(", "self", ".", "nusc", ",", "image_data", "=", "image_sample", ",", "radar_data", "=", "radar_sample", ",", "**", "kwargs", ")", "\n", "\n", "# reduce to requested channels", "\n", "#self.channels = [ch - 1 for ch in self.channels] # Shift channels by 1, cause we have a weird convetion starting at 1", "\n", "input_data", "=", "img_p_full", "[", ":", ",", ":", ",", "self", ".", "channels", "]", "\n", "\n", "", "else", ":", "# We are not in image_plus mode", "\n", "# Only resize, because in the other case this is contained in image_plus_creation", "\n", "            ", "input_data", "=", "cv2", ".", "resize", "(", "image_sample", ",", "image_target_shape", "[", ":", ":", "-", "1", "]", ")", "\n", "\n", "", "return", "input_data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_sample_data": [[440, 454], ["utils.nuscenes_helper.get_sensor_sample_data"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.nuscenes_helper.get_sensor_sample_data"], ["", "def", "load_sample_data", "(", "self", ",", "sample", ",", "sensor_channel", ")", ":", "\n", "        ", "\"\"\"\n        This function takes the token of a sample and a sensor sensor_channel and returns the according data\n\n        Radar format: <np.array>\n            - Shape: 18 x n\n            - Semantics: x y z dyn_prop id rcs vx vy vx_comp vy_comp is_quality_valid ambig_state x_rms y_rms invalid_state pdh0\n\n        Image format: <np.array>\n            - Shape: h x w x 3\n            - Values: [0,255]\n            - Channels: RGB\n        \"\"\"", "\n", "return", "get_sensor_sample_data", "(", "self", ".", "nusc", ",", "sample", ",", "sensor_channel", ",", "dtype", "=", "np", ".", "float32", ",", "size", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.create_annotations": [[456, 569], ["any", "nuscenes_generator.NuscenesGenerator.nusc.get", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "print", "nuscenes_generator.NuscenesGenerator.nusc.get", "nuscenes_generator.NuscenesGenerator.nusc.get_sample_data", "float", "float", "numpy.where", "nuscenes.utils.geometry_utils.box_in_image", "box.box2d", "annotations[].insert", "annotations[].insert", "annotations[].insert", "annotations[].insert", "annotations[].insert", "nuscenes.utils.data_classes.RadarPointCloud.from_file_multisweep", "numpy.zeros.astype", "nuscenes.utils.geometry_utils.points_in_box", "int", "utils.radar.enrich_radar_data", "len", "numpy.concatenate", "print", "numpy.zeros", "nuscenes_generator.NuscenesGenerator.nusc.get", "nuscenes_generator.NuscenesGenerator.nusc.get", "len"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.enrich_radar_data"], ["", "def", "create_annotations", "(", "self", ",", "sample_token", ",", "sensor_channels", ")", ":", "\n", "        ", "\"\"\"\n        Create annotations for the the given sample token.\n\n        1 bounding box vector contains:\n\n\n        :param sample_token: the sample_token to get the annotation for\n        :param sensor_channels: list of channels for cropping the labels, e.g. ['CAM_FRONT', 'RADAR_FRONT']\n            This works only for CAMERA atm\n\n        :returns: \n            annotations dictionary:\n            {\n                'labels': [] # <list of n int>  \n                'bboxes': [] # <list of n x 4 float> [xmin, ymin, xmax, ymax]\n                'distances': [] # <list of n float>  Center of box given as x, y, z.\n                'visibilities': [] # <list of n float>  Visibility of annotated object\n            }\n        \"\"\"", "\n", "\n", "if", "any", "(", "[", "s", "for", "s", "in", "sensor_channels", "if", "'RADAR'", "in", "s", "]", ")", ":", "\n", "            ", "print", "(", "\"[WARNING] Cropping to RADAR is not supported atm\"", ")", "\n", "sensor_channels", "=", "[", "c", "for", "c", "in", "sensor_channels", "if", "'CAM'", "in", "sensor_channels", "]", "\n", "\n", "", "sample", "=", "self", ".", "nusc", ".", "get", "(", "'sample'", ",", "sample_token", ")", "\n", "annotations_count", "=", "0", "\n", "annotations", "=", "{", "\n", "'labels'", ":", "[", "]", ",", "# <list of n int>  ", "\n", "'bboxes'", ":", "[", "]", ",", "# <list of n x 4 float> [xmin, ymin, xmax, ymax]", "\n", "'distances'", ":", "[", "]", ",", "# <list of n float>  Center of box given as x, y, z.", "\n", "'visibilities'", ":", "[", "]", ",", "\n", "'num_radar_pts'", ":", "[", "]", "#<list of n int>  number of radar points that cover that annotation", "\n", "}", "\n", "\n", "# Camera parameters", "\n", "for", "selected_sensor_channel", "in", "sensor_channels", ":", "\n", "            ", "sd_rec", "=", "self", ".", "nusc", ".", "get", "(", "'sample_data'", ",", "sample", "[", "'data'", "]", "[", "selected_sensor_channel", "]", ")", "\n", "\n", "# Create Boxes:", "\n", "_", ",", "boxes", ",", "camera_intrinsic", "=", "self", ".", "nusc", ".", "get_sample_data", "(", "sd_rec", "[", "'token'", "]", ",", "box_vis_level", "=", "BoxVisibility", ".", "ANY", ")", "\n", "imsize_src", "=", "(", "sd_rec", "[", "'width'", "]", ",", "sd_rec", "[", "'height'", "]", ")", "# nuscenes has (width, height) convention", "\n", "\n", "bbox_resize", "=", "[", "1.", "/", "sd_rec", "[", "'height'", "]", ",", "1.", "/", "sd_rec", "[", "'width'", "]", "]", "\n", "if", "not", "self", ".", "normalize_bbox", ":", "\n", "                ", "bbox_resize", "[", "0", "]", "*=", "float", "(", "self", ".", "image_min_side", ")", "\n", "bbox_resize", "[", "1", "]", "*=", "float", "(", "self", ".", "image_max_side", ")", "\n", "\n", "# Create labels for all boxes that are visible", "\n", "", "for", "box", "in", "boxes", ":", "\n", "\n", "# Add labels to boxes ", "\n", "                ", "if", "box", ".", "name", "in", "self", ".", "classes", ":", "\n", "                    ", "box", ".", "label", "=", "self", ".", "classes", "[", "box", ".", "name", "]", "\n", "# Check if box is visible and transform box to 1D vector", "\n", "if", "box_in_image", "(", "box", "=", "box", ",", "intrinsic", "=", "camera_intrinsic", ",", "imsize", "=", "imsize_src", ",", "vis_level", "=", "BoxVisibility", ".", "ANY", ")", ":", "\n", "\n", "## Points in box method for annotation filterS", "\n", "# check if bounding box has an according radar point", "\n", "                        ", "if", "self", ".", "only_radar_annotated", "==", "2", ":", "\n", "\n", "                            ", "pcs", ",", "times", "=", "RadarPointCloud", ".", "from_file_multisweep", "(", "self", ".", "nusc", ",", "sample", ",", "self", ".", "radar_sensors", "[", "0", "]", ",", "selected_sensor_channel", ",", "nsweeps", "=", "self", ".", "n_sweeps", ",", "min_distance", "=", "0.0", ",", "merge", "=", "False", ")", "\n", "\n", "for", "pc", "in", "pcs", ":", "\n", "                                ", "pc", ".", "points", "=", "radar", ".", "enrich_radar_data", "(", "pc", ".", "points", ")", "\n", "\n", "", "if", "len", "(", "pcs", ")", ">", "0", ":", "\n", "                                ", "radar_sample", "=", "np", ".", "concatenate", "(", "[", "pc", ".", "points", "for", "pc", "in", "pcs", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                                ", "print", "(", "\"[WARNING] only_radar_annotated=2 and sweeps=0 removes all annotations\"", ")", "\n", "radar_sample", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "radar", ".", "channel_map", ")", ",", "0", ")", ")", "\n", "", "radar_sample", "=", "radar_sample", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "mask", "=", "points_in_box", "(", "box", ",", "radar_sample", "[", "0", ":", "3", ",", ":", "]", ")", "\n", "if", "True", "not", "in", "mask", ":", "\n", "                                ", "continue", "\n", "\n", "\n", "# If visible, we create the corresponding label", "\n", "", "", "box2d", "=", "box", ".", "box2d", "(", "camera_intrinsic", ")", "# returns [xmin, ymin, xmax, ymax]", "\n", "box2d", "[", "0", "]", "*=", "bbox_resize", "[", "1", "]", "\n", "box2d", "[", "1", "]", "*=", "bbox_resize", "[", "0", "]", "\n", "box2d", "[", "2", "]", "*=", "bbox_resize", "[", "1", "]", "\n", "box2d", "[", "3", "]", "*=", "bbox_resize", "[", "0", "]", "\n", "\n", "annotations", "[", "'bboxes'", "]", ".", "insert", "(", "annotations_count", ",", "box2d", ")", "\n", "annotations", "[", "'labels'", "]", ".", "insert", "(", "annotations_count", ",", "box", ".", "label", ")", "\n", "annotations", "[", "'num_radar_pts'", "]", ".", "insert", "(", "annotations_count", ",", "self", ".", "nusc", ".", "get", "(", "'sample_annotation'", ",", "box", ".", "token", ")", "[", "'num_radar_pts'", "]", ")", "\n", "\n", "distance", "=", "(", "box", ".", "center", "[", "0", "]", "**", "2", "+", "box", ".", "center", "[", "1", "]", "**", "2", "+", "box", ".", "center", "[", "2", "]", "**", "2", ")", "**", "0.5", "\n", "annotations", "[", "'distances'", "]", ".", "insert", "(", "annotations_count", ",", "distance", ")", "\n", "annotations", "[", "'visibilities'", "]", ".", "insert", "(", "annotations_count", ",", "int", "(", "self", ".", "nusc", ".", "get", "(", "'sample_annotation'", ",", "box", ".", "token", ")", "[", "'visibility_token'", "]", ")", ")", "\n", "annotations_count", "+=", "1", "\n", "", "", "else", ":", "\n", "# The current name has been ignored", "\n", "                    ", "pass", "\n", "\n", "", "", "", "annotations", "[", "'labels'", "]", "=", "np", ".", "array", "(", "annotations", "[", "'labels'", "]", ")", "\n", "annotations", "[", "'bboxes'", "]", "=", "np", ".", "array", "(", "annotations", "[", "'bboxes'", "]", ")", "\n", "annotations", "[", "'distances'", "]", "=", "np", ".", "array", "(", "annotations", "[", "'distances'", "]", ")", "\n", "annotations", "[", "'num_radar_pts'", "]", "=", "np", ".", "array", "(", "annotations", "[", "'num_radar_pts'", "]", ")", "\n", "annotations", "[", "'visibilities'", "]", "=", "np", ".", "array", "(", "annotations", "[", "'visibilities'", "]", ")", "\n", "\n", "# num_radar_pts mathod for annotation filter", "\n", "if", "self", ".", "only_radar_annotated", "==", "1", ":", "\n", "\n", "            ", "anns_to_keep", "=", "np", ".", "where", "(", "annotations", "[", "'num_radar_pts'", "]", ")", "[", "0", "]", "\n", "\n", "for", "key", "in", "annotations", ":", "\n", "                ", "annotations", "[", "key", "]", "=", "annotations", "[", "key", "]", "[", "anns_to_keep", "]", "\n", "\n", "", "", "return", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_annotations": [[570, 582], ["nuscenes_generator.NuscenesGenerator.create_annotations"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.create_annotations"], ["", "def", "load_annotations", "(", "self", ",", "image_index", ")", ":", "\n", "        ", "\"\"\" Load annotations for an image_index.\n        \"\"\"", "\n", "annotations", "=", "self", ".", "image_data", "[", "image_index", "]", "\n", "\n", "if", "annotations", "is", "None", ":", "\n", "            ", "sample_token", "=", "self", ".", "sample_tokens", "[", "image_index", "]", "\n", "annotations", "=", "self", ".", "create_annotations", "(", "sample_token", ",", "self", ".", "camera_sensors", ")", "\n", "\n", "self", ".", "image_data", "[", "image_index", "]", "=", "annotations", "\n", "\n", "", "return", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.compute_input_output": [[583, 605], ["super().compute_input_output", "numpy.array", "nuscenes_generator.NuscenesGenerator.load_radar_array", "numpy.array.append"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.compute_input_output", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.nuscenes_generator.NuscenesGenerator.load_radar_array"], ["", "def", "compute_input_output", "(", "self", ",", "group", ",", "inference", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Extends the basic function with the capability to \n        add radar input data to the input batch.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "super", "(", "NuscenesGenerator", ",", "self", ")", ".", "compute_input_output", "(", "group", ")", "\n", "\n", "if", "self", ".", "radar_input_name", ":", "\n", "# Load radar data", "\n", "            ", "radar_input_batch", "=", "[", "]", "\n", "for", "sample_index", "in", "group", ":", "\n", "                ", "radar_array", "=", "self", ".", "load_radar_array", "(", "sample_index", ",", "target_width", "=", "self", ".", "radar_width", ")", "\n", "radar_input_batch", ".", "append", "(", "radar_array", ")", "\n", "\n", "", "radar_input_batch", "=", "np", ".", "array", "(", "radar_input_batch", ")", "\n", "\n", "inputs", "=", "{", "\n", "'input_1'", ":", "inputs", ",", "\n", "self", ".", "radar_input_name", ":", "radar_input_batch", "\n", "}", "\n", "\n", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.splits.nuscenes_splits.Scenes.__init__": [[7, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train", ",", "val", ",", "test", ",", "test_rain", ",", "test_night", ")", ":", "\n", "        ", "self", ".", "train", "=", "train", "\n", "self", ".", "val", "=", "val", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "test_rain", "=", "test_rain", "\n", "self", ".", "test_night", "=", "test_night", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.rotation_helper._isRotationMatrix": [[10, 16], ["numpy.transpose", "numpy.dot", "numpy.identity", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose"], ["def", "_isRotationMatrix", "(", "R", ")", ":", "\n", "    ", "Rt", "=", "np", ".", "transpose", "(", "R", ")", "\n", "shouldBeIdentity", "=", "np", ".", "dot", "(", "Rt", ",", "R", ")", "\n", "I", "=", "np", ".", "identity", "(", "3", ",", "dtype", "=", "R", ".", "dtype", ")", "\n", "n", "=", "np", ".", "linalg", ".", "norm", "(", "I", "-", "shouldBeIdentity", ")", "\n", "return", "n", "<", "1e-6", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.rotation_helper.rotationMatrixToEulerAngles": [[17, 35], ["rotation_helper._isRotationMatrix", "math.sqrt", "numpy.array", "math.atan2", "math.atan2", "math.atan2", "math.atan2", "math.atan2"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.rotation_helper._isRotationMatrix"], ["", "def", "rotationMatrixToEulerAngles", "(", "R", ")", ":", "\n", "\n", "    ", "assert", "(", "_isRotationMatrix", "(", "R", ")", ")", "\n", "\n", "sy", "=", "math", ".", "sqrt", "(", "R", "[", "0", ",", "0", "]", "*", "R", "[", "0", ",", "0", "]", "+", "R", "[", "1", ",", "0", "]", "*", "R", "[", "1", ",", "0", "]", ")", "\n", "\n", "singular", "=", "sy", "<", "1e-6", "\n", "\n", "if", "not", "singular", ":", "\n", "        ", "x", "=", "math", ".", "atan2", "(", "R", "[", "2", ",", "1", "]", ",", "R", "[", "2", ",", "2", "]", ")", "\n", "y", "=", "math", ".", "atan2", "(", "-", "R", "[", "2", ",", "0", "]", ",", "sy", ")", "\n", "z", "=", "math", ".", "atan2", "(", "R", "[", "1", ",", "0", "]", ",", "R", "[", "0", ",", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "math", ".", "atan2", "(", "-", "R", "[", "1", ",", "2", "]", ",", "R", "[", "1", ",", "1", "]", ")", "\n", "y", "=", "math", ".", "atan2", "(", "-", "R", "[", "2", ",", "0", "]", ",", "sy", ")", "\n", "z", "=", "0", "\n", "\n", "", "return", "np", ".", "array", "(", "[", "x", ",", "y", ",", "z", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.rotation_helper.eulerAnglesToRotationMatrix": [[37, 60], ["numpy.array", "numpy.array", "numpy.array", "numpy.dot", "numpy.dot", "math.cos", "math.sin", "math.cos", "math.cos", "math.sin", "math.cos", "math.cos", "math.sin", "math.cos", "math.sin", "math.sin", "math.sin"], "function", ["None"], ["", "def", "eulerAnglesToRotationMatrix", "(", "theta", ")", ":", "\n", "\n", "    ", "R_x", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "math", ".", "cos", "(", "theta", "[", "0", "]", ")", ",", "-", "math", ".", "sin", "(", "theta", "[", "0", "]", ")", "]", ",", "\n", "[", "0", ",", "math", ".", "sin", "(", "theta", "[", "0", "]", ")", ",", "math", ".", "cos", "(", "theta", "[", "0", "]", ")", "]", "\n", "]", ")", "\n", "\n", "\n", "\n", "R_y", "=", "np", ".", "array", "(", "[", "[", "math", ".", "cos", "(", "theta", "[", "1", "]", ")", ",", "0", ",", "math", ".", "sin", "(", "theta", "[", "1", "]", ")", "]", ",", "\n", "[", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "-", "math", ".", "sin", "(", "theta", "[", "1", "]", ")", ",", "0", ",", "math", ".", "cos", "(", "theta", "[", "1", "]", ")", "]", "\n", "]", ")", "\n", "\n", "R_z", "=", "np", ".", "array", "(", "[", "[", "math", ".", "cos", "(", "theta", "[", "2", "]", ")", ",", "-", "math", ".", "sin", "(", "theta", "[", "2", "]", ")", ",", "0", "]", ",", "\n", "[", "math", ".", "sin", "(", "theta", "[", "2", "]", ")", ",", "math", ".", "cos", "(", "theta", "[", "2", "]", ")", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n", "\n", "\n", "R", "=", "np", ".", "dot", "(", "R_z", ",", "np", ".", "dot", "(", "R_y", ",", "R_x", ")", ")", "\n", "\n", "return", "R", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._resize_image": [[34, 50], ["cv2.resize", "numpy.eye"], "function", ["None"], ["def", "_resize_image", "(", "image_data", ",", "target_shape", ")", ":", "\n", "    ", "\"\"\"\n    Perfomrs resizing of the image and calculates a matrix to adapt the intrinsic camera matrix\n    :param image_data: [np.array] with shape (height x width x 3)\n    :param target_shape: [tuple] with (width, height)\n\n    :return resized image: [np.array] with shape (height x width x 3)\n    :return resize matrix: [numpy array (3 x 3)]\n    \"\"\"", "\n", "# print('resized', type(image_data))", "\n", "stupid_confusing_cv2_size_because_width_and_height_are_in_wrong_order", "=", "(", "target_shape", "[", "1", "]", ",", "target_shape", "[", "0", "]", ")", "\n", "resized_image", "=", "cv2", ".", "resize", "(", "image_data", ",", "stupid_confusing_cv2_size_because_width_and_height_are_in_wrong_order", ")", "\n", "resize_matrix", "=", "np", ".", "eye", "(", "3", ",", "dtype", "=", "resized_image", ".", "dtype", ")", "\n", "resize_matrix", "[", "1", ",", "1", "]", "=", "target_shape", "[", "0", "]", "/", "image_data", ".", "shape", "[", "0", "]", "\n", "resize_matrix", "[", "0", ",", "0", "]", "=", "target_shape", "[", "1", "]", "/", "image_data", ".", "shape", "[", "1", "]", "\n", "return", "resized_image", ",", "resize_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._radar_transformation": [[51, 100], ["radar_data[].copy", "numpy.ones", "numpy.ones", "numpy.tan", "numpy.tan"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones"], ["", "def", "_radar_transformation", "(", "radar_data", ",", "height", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Transforms the given radar data with height z = 0 and another height as input using extrinsic radar matrix to vehicle's co-sy\n\n    This function appends the distance to the radar point.\n\n    Parameters:\n    :param radar_data: [numpy array] with radar parameter (e.g. velocity) in rows and radar points for one timestep in columns\n        Semantics: x y z dyn_prop id rcs vx vy vx_comp vy_comp is_quality_valid ambig_state x_rms y_rms invalid_state pdh0 distance\n    :param radar_extrinsic: [numpy array (3x4)] that consists of the extrinsic parameters of the given radar sensor\n    :param height: [tuple] (min height, max height) that defines the (unknown) height of the radar points\n\n    Returns:\n    :returns radar_data: [numpy array (m x no of points)] that consists of the transformed radar points with z = 0\n    :returns radar_xyz_endpoint: [numpy array (3 x no of points)] that consits of the transformed radar points z = height  \n    \"\"\"", "\n", "\n", "# Field of view (global)", "\n", "ELEVATION_FOV_SR", "=", "20", "\n", "ELEVATION_FOV_FR", "=", "14", "\n", "\n", "# initialization", "\n", "num_points", "=", "radar_data", ".", "shape", "[", "1", "]", "\n", "\n", "# Radar points for the endpoint", "\n", "radar_xyz_endpoint", "=", "radar_data", "[", "0", ":", "3", ",", ":", "]", ".", "copy", "(", ")", "\n", "\n", "# variant 1: constant height substracted by RADAR_HEIGHT", "\n", "RADAR_HEIGHT", "=", "0.5", "\n", "if", "height", ":", "\n", "        ", "radar_data", "[", "2", ",", ":", "]", "=", "np", ".", "ones", "(", "(", "num_points", ",", ")", ")", "*", "(", "height", "[", "0", "]", "-", "RADAR_HEIGHT", ")", "# lower points", "\n", "radar_xyz_endpoint", "[", "2", ",", ":", "]", "=", "np", ".", "ones", "(", "(", "num_points", ",", ")", ")", "*", "(", "height", "[", "1", "]", "-", "RADAR_HEIGHT", ")", "# upper points", "\n", "\n", "# variant 2: field of view", "\n", "", "else", ":", "\n", "        ", "dist", "=", "radar_data", "[", "-", "1", ",", ":", "]", "\n", "count", "=", "0", "\n", "for", "d", "in", "dist", ":", "\n", "# short range mode", "\n", "            ", "if", "d", "<=", "70", ":", "\n", "                ", "radar_xyz_endpoint", "[", "2", ",", "count", "]", "=", "-", "d", "*", "np", ".", "tan", "(", "ELEVATION_FOV_SR", "/", "2", ")", "\n", "\n", "# long range mode", "\n", "", "else", ":", "\n", "                ", "radar_xyz_endpoint", "[", "2", ",", "count", "]", "=", "-", "d", "*", "np", ".", "tan", "(", "ELEVATION_FOV_FR", "/", "2", ")", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "", "", "return", "radar_data", ",", "radar_xyz_endpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._create_line": [[101, 171], ["numpy.abs", "numpy.abs", "numpy.empty", "np.empty.fill", "itbuffer[].astype", "itbuffer[].astype", "numpy.arange", "numpy.arange", "numpy.maximum", "numpy.arange", "numpy.arange", "int", "int", "dX.astype", "dY.astype", "numpy.arange", "numpy.arange", "dY.astype", "dX.astype", "numpy.arange", "numpy.arange"], "function", ["None"], ["", "def", "_create_line", "(", "P1", ",", "P2", ",", "img", ")", ":", "\n", "    ", "\"\"\"\n    Produces and array that consists of the coordinates and intensities of each pixel in a line between two points\n\n    :param P1: [numpy array] that consists of the coordinate of the first point (x,y)\n    :param P2: [numpy array] that consists of the coordinate of the second point (x,y)\n    :param img: [numpy array] the image being processed\n\n    :return itbuffer: [numpy array] that consists of the coordinates and intensities of each pixel in the radii (shape: [numPixels, 3], row = [x,y])     \n    \"\"\"", "\n", "# define local variables for readability", "\n", "imageH", "=", "img", ".", "shape", "[", "0", "]", "\n", "imageW", "=", "img", ".", "shape", "[", "1", "]", "\n", "\n", "P1X", "=", "P1", "[", "0", "]", "\n", "P1Y", "=", "P1", "[", "1", "]", "\n", "P2X", "=", "P2", "[", "0", "]", "\n", "P2Y", "=", "P2", "[", "1", "]", "\n", "\n", "# difference and absolute difference between points", "\n", "# used to calculate slope and relative location between points", "\n", "dX", "=", "P2X", "-", "P1X", "\n", "dY", "=", "P2Y", "-", "P1Y", "\n", "dXa", "=", "np", ".", "abs", "(", "dX", ")", "\n", "dYa", "=", "np", ".", "abs", "(", "dY", ")", "\n", "\n", "# predefine numpy array for output based on distance between points", "\n", "itbuffer", "=", "np", ".", "empty", "(", "\n", "shape", "=", "(", "np", ".", "maximum", "(", "int", "(", "dYa", ")", ",", "int", "(", "dXa", ")", ")", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "itbuffer", ".", "fill", "(", "np", ".", "nan", ")", "\n", "\n", "# Obtain coordinates along the line using a form of Bresenham's algorithm", "\n", "negY", "=", "P1Y", ">", "P2Y", "\n", "negX", "=", "P1X", ">", "P2X", "\n", "if", "P1X", "==", "P2X", ":", "# vertical line segment", "\n", "        ", "itbuffer", "[", ":", ",", "0", "]", "=", "P1X", "\n", "if", "negY", ":", "\n", "            ", "itbuffer", "[", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "P1Y", "-", "1", ",", "P1Y", "-", "dYa", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "itbuffer", "[", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "P1Y", "+", "1", ",", "P1Y", "+", "dYa", "+", "1", ")", "\n", "", "", "elif", "P1Y", "==", "P2Y", ":", "# horizontal line segment", "\n", "        ", "itbuffer", "[", ":", ",", "1", "]", "=", "P1Y", "\n", "if", "negX", ":", "\n", "            ", "itbuffer", "[", ":", ",", "0", "]", "=", "np", ".", "arange", "(", "P1X", "-", "1", ",", "P1X", "-", "dXa", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "itbuffer", "[", ":", ",", "0", "]", "=", "np", ".", "arange", "(", "P1X", "+", "1", ",", "P1X", "+", "dXa", "+", "1", ")", "\n", "", "", "else", ":", "# diagonal line segment", "\n", "        ", "steepSlope", "=", "dYa", ">", "dXa", "\n", "if", "steepSlope", ":", "\n", "            ", "slope", "=", "dX", ".", "astype", "(", "np", ".", "float32", ")", "/", "dY", ".", "astype", "(", "np", ".", "float32", ")", "\n", "if", "negY", ":", "\n", "                ", "itbuffer", "[", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "P1Y", "-", "1", ",", "P1Y", "-", "dYa", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "itbuffer", "[", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "P1Y", "+", "1", ",", "P1Y", "+", "dYa", "+", "1", ")", "\n", "", "itbuffer", "[", ":", ",", "0", "]", "=", "(", "slope", "*", "(", "itbuffer", "[", ":", ",", "1", "]", "-", "P1Y", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "+", "P1X", "\n", "", "else", ":", "\n", "            ", "slope", "=", "dY", ".", "astype", "(", "np", ".", "float32", ")", "/", "dX", ".", "astype", "(", "np", ".", "float32", ")", "\n", "if", "negX", ":", "\n", "                ", "itbuffer", "[", ":", ",", "0", "]", "=", "np", ".", "arange", "(", "P1X", "-", "1", ",", "P1X", "-", "dXa", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "itbuffer", "[", ":", ",", "0", "]", "=", "np", ".", "arange", "(", "P1X", "+", "1", ",", "P1X", "+", "dXa", "+", "1", ")", "\n", "", "itbuffer", "[", ":", ",", "1", "]", "=", "(", "slope", "*", "(", "itbuffer", "[", ":", ",", "0", "]", "-", "P1X", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "+", "P1Y", "\n", "\n", "# Remove points outside of image", "\n", "", "", "colX", "=", "itbuffer", "[", ":", ",", "0", "]", ".", "astype", "(", "int", ")", "\n", "colY", "=", "itbuffer", "[", ":", ",", "1", "]", ".", "astype", "(", "int", ")", "\n", "itbuffer", "=", "itbuffer", "[", "(", "colX", ">=", "0", ")", "&", "(", "colY", ">=", "0", ")", "&", "\n", "(", "colX", "<", "imageW", ")", "&", "(", "colY", "<", "imageH", ")", "]", "\n", "\n", "return", "itbuffer", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._create_vertical_line": [[172, 217], ["int", "int", "numpy.abs", "numpy.abs", "numpy.empty", "np.empty.fill", "int", "itbuffer[].astype", "itbuffer[].astype", "numpy.arange", "numpy.arange", "numpy.maximum", "int", "int"], "function", ["None"], ["", "def", "_create_vertical_line", "(", "P1", ",", "P2", ",", "img", ")", ":", "\n", "    ", "\"\"\"\n    Produces and array that consists of the coordinates and intensities of each pixel in a line between two points\n\n    :param P1: [numpy array] that consists of the coordinate of the first point (x,y)\n    :param P2: [numpy array] that consists of the coordinate of the second point (x,y)\n    :param img: [numpy array] the image being processed\n\n    :return itbuffer: [numpy array] that consists of the coordinates and intensities of each pixel in the radii (shape: [numPixels, 3], row = [x,y])     \n    \"\"\"", "\n", "# define local variables for readability", "\n", "imageH", "=", "img", ".", "shape", "[", "0", "]", "\n", "imageW", "=", "img", ".", "shape", "[", "1", "]", "\n", "\n", "# difference and absolute difference between points", "\n", "# used to calculate slope and relative location between points", "\n", "P1_y", "=", "int", "(", "P1", "[", "1", "]", ")", "\n", "P2_y", "=", "int", "(", "P2", "[", "1", "]", ")", "\n", "dX", "=", "0", "\n", "dY", "=", "P2_y", "-", "P1_y", "\n", "if", "dY", "==", "0", ":", "\n", "        ", "dY", "=", "1", "\n", "", "dXa", "=", "np", ".", "abs", "(", "dX", ")", "\n", "dYa", "=", "np", ".", "abs", "(", "dY", ")", "\n", "\n", "# predefine numpy array for output based on distance between points", "\n", "itbuffer", "=", "np", ".", "empty", "(", "\n", "shape", "=", "(", "np", ".", "maximum", "(", "int", "(", "dYa", ")", ",", "int", "(", "dXa", ")", ")", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "itbuffer", ".", "fill", "(", "np", ".", "nan", ")", "\n", "\n", "# vertical line segment", "\n", "itbuffer", "[", ":", ",", "0", "]", "=", "int", "(", "P1", "[", "0", "]", ")", "\n", "if", "P1_y", ">", "P2_y", ":", "\n", "# Obtain coordinates along the line using a form of Bresenham's algorithm", "\n", "        ", "itbuffer", "[", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "P1_y", "-", "1", ",", "P1_y", "-", "dYa", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "itbuffer", "[", ":", ",", "1", "]", "=", "np", ".", "arange", "(", "P1_y", "+", "1", ",", "P1_y", "+", "dYa", "+", "1", ")", "\n", "\n", "# Remove points outside of image", "\n", "", "colX", "=", "itbuffer", "[", ":", ",", "0", "]", ".", "astype", "(", "int", ")", "\n", "colY", "=", "itbuffer", "[", ":", ",", "1", "]", ".", "astype", "(", "int", ")", "\n", "itbuffer", "=", "itbuffer", "[", "(", "colX", ">=", "0", ")", "&", "(", "colY", ">=", "0", ")", "&", "\n", "(", "colX", "<", "imageW", ")", "&", "(", "colY", "<", "imageH", ")", "]", "\n", "\n", "return", "itbuffer", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._radar2camera": [[218, 257], ["numpy.zeros", "numpy.concatenate", "range", "fusion_projection_lines._create_vertical_line", "range", "projection_line[].astype", "projection_line[].astype", "numpy.any"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._create_vertical_line", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "_radar2camera", "(", "image_data", ",", "radar_data", ",", "radar_xyz_endpoints", ",", "clear_radar", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    \n    Calculates a line of two radar points and puts the radar_meta data as additonal layers to the image -> image_plus\n\n\n    :param image_data: [numpy array (900 x 1600 x 3)] of image data\n    :param radar_data: [numpy array (xyz+meta x no of points)] that consists of the transformed radar points with z = 0\n        default semantics: x y z dyn_prop id rcs vx vy vx_comp vy_comp is_quality_valid ambig_state x_rms y_rms invalid_state pdh0 vx_rms vy_rms distance\n    :param radar_xyz_endpoints: [numpy array (3 x no of points)] that consits of the transformed radar points z = height\n    :param clear_radar: [boolean] True if radar data should be all zero\n\n    :return image_plus: a numpy array (900 x 1600 x (3 + number of radar_meta (e.g. velocity)))\n    \"\"\"", "\n", "\n", "radar_meta_count", "=", "radar_data", ".", "shape", "[", "0", "]", "-", "3", "\n", "radar_extension", "=", "np", ".", "zeros", "(", "\n", "(", "image_data", ".", "shape", "[", "0", "]", ",", "image_data", ".", "shape", "[", "1", "]", ",", "radar_meta_count", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "no_of_points", "=", "radar_data", ".", "shape", "[", "1", "]", "\n", "\n", "if", "clear_radar", ":", "\n", "        ", "pass", "# we just don't add it to the image", "\n", "", "else", ":", "\n", "        ", "for", "radar_point", "in", "range", "(", "0", ",", "no_of_points", ")", ":", "\n", "            ", "projection_line", "=", "_create_vertical_line", "(", "\n", "radar_data", "[", "0", ":", "2", ",", "radar_point", "]", ",", "radar_xyz_endpoints", "[", "0", ":", "2", ",", "radar_point", "]", ",", "image_data", ")", "\n", "\n", "for", "pixel_point", "in", "range", "(", "0", ",", "projection_line", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "y", "=", "projection_line", "[", "pixel_point", ",", "1", "]", ".", "astype", "(", "int", ")", "\n", "x", "=", "projection_line", "[", "pixel_point", ",", "0", "]", ".", "astype", "(", "int", ")", "\n", "\n", "# Check if pixel is already filled with radar data and overwrite if distance is less than the existing", "\n", "if", "not", "np", ".", "any", "(", "radar_extension", "[", "y", ",", "x", "]", ")", "or", "radar_data", "[", "-", "1", ",", "radar_point", "]", "<", "radar_extension", "[", "y", ",", "x", ",", "-", "1", "]", ":", "\n", "                    ", "radar_extension", "[", "y", ",", "x", "]", "=", "radar_data", "[", "3", ":", ",", "radar_point", "]", "\n", "\n", "\n", "", "", "", "", "image_plus", "=", "np", ".", "concatenate", "(", "(", "image_data", ",", "radar_extension", ")", ",", "axis", "=", "2", ")", "\n", "\n", "return", "image_plus", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.view_points": [[259, 302], ["numpy.eye", "numpy.concatenate", "numpy.dot", "numpy.ones", "points[].repeat().reshape", "points[].repeat"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones"], ["", "def", "view_points", "(", "points", ":", "np", ".", "ndarray", ",", "view", ":", "np", ".", "ndarray", ",", "normalize", ":", "bool", ")", ":", "\n", "    ", "\"\"\"\n    This function is a modification of nuscenes.geometry_utils.view_points function\n\n    This is a helper class that maps 3d points to a 2d plane. It can be used to implement both perspective and\n    orthographic projections. It first applies the dot product between the points and the view. By convention,\n    the view should be such that the data is projected onto the first 2 axis. It then optionally applies a\n    normalization along the third dimension.\n\n    For a perspective projection the view should be a 3x3 camera matrix, and normalize=True\n    For an orthographic projection with translation the view is a 3x4 matrix and normalize=False\n    For an orthographic projection without translation the view is a 3x3 matrix (optionally 3x4 with last columns\n     all zeros) and normalize=False\n\n    :param points: <np.float32: 3, n> Matrix of points, where each point (x, y, z) is along each column.\n    :param view: <np.float32: n, n>. Defines an arbitrary projection (n <= 4).\n        The projection should be such that the corners are projected onto the first 2 axis.\n    :param normalize: Whether to normalize the remaining coordinate (along the third axis).\n    :return: <np.float32: 3, n>. Mapped point. If normalize=False, the third coordinate is the height.\n    \"\"\"", "\n", "\n", "output", "=", "points", "\n", "\n", "assert", "view", ".", "shape", "[", "0", "]", "<=", "4", "\n", "assert", "view", ".", "shape", "[", "1", "]", "<=", "4", "\n", "assert", "points", ".", "shape", "[", "0", "]", ">=", "3", "\n", "points", "=", "output", "[", "0", ":", "3", ",", ":", "]", "\n", "\n", "viewpad", "=", "np", ".", "eye", "(", "4", ")", "\n", "viewpad", "[", ":", "view", ".", "shape", "[", "0", "]", ",", ":", "view", ".", "shape", "[", "1", "]", "]", "=", "view", "\n", "\n", "nbr_points", "=", "points", ".", "shape", "[", "1", "]", "\n", "\n", "# Do operation in homogenous coordinates", "\n", "points", "=", "np", ".", "concatenate", "(", "(", "points", ",", "np", ".", "ones", "(", "(", "1", ",", "nbr_points", ")", ")", ")", ")", "\n", "points", "=", "np", ".", "dot", "(", "viewpad", ",", "points", ")", "\n", "points", "=", "points", "[", ":", "3", ",", ":", "]", "\n", "\n", "if", "normalize", ":", "\n", "        ", "points", "=", "points", "/", "points", "[", "2", ":", "3", ",", ":", "]", ".", "repeat", "(", "3", ",", "0", ")", ".", "reshape", "(", "3", ",", "nbr_points", ")", "\n", "\n", "", "output", "[", "0", ":", "3", ",", ":", "]", "=", "points", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.map_pointcloud_to_image": [[303, 363], ["nusc.get", "nusc.get", "nuscenes.utils.data_classes.PointCloud", "nusc.get", "nuscenes.utils.data_classes.PointCloud.rotate", "nuscenes.utils.data_classes.PointCloud.translate", "nusc.get", "nuscenes.utils.data_classes.PointCloud.rotate", "nuscenes.utils.data_classes.PointCloud.translate", "nusc.get", "nuscenes.utils.data_classes.PointCloud.translate", "nuscenes.utils.data_classes.PointCloud.rotate", "nusc.get", "nuscenes.utils.data_classes.PointCloud.translate", "nuscenes.utils.data_classes.PointCloud.rotate", "numpy.array", "fusion_projection_lines.view_points", "numpy.array", "numpy.array", "pyquaternion.Quaternion", "pyquaternion.Quaternion", "numpy.array", "numpy.array", "pyquaternion.Quaternion", "pyquaternion.Quaternion"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.view_points"], ["", "def", "map_pointcloud_to_image", "(", "nusc", ",", "radar_points", ",", "pointsensor_token", ",", "camera_token", ",", "target_resolution", "=", "(", "None", ",", "None", ")", ")", ":", "\n", "    ", "\"\"\"\n    Given a point sensor (lidar/radar) token and camera sample_data token, load point-cloud and map it to the image\n    plane.\n    :param radar_pints: [list] list of radar points\n    :param pointsensor_token: [str] Lidar/radar sample_data token.\n    :param camera_token: [str] Camera sample_data token.\n    :param target_resolution: [tuple of int] determining the output size for the radar_image. None for no change\n\n    :return (points <np.float: 2, n)\n    \"\"\"", "\n", "\n", "# Initialize the database", "\n", "cam", "=", "nusc", ".", "get", "(", "'sample_data'", ",", "camera_token", ")", "\n", "pointsensor", "=", "nusc", ".", "get", "(", "'sample_data'", ",", "pointsensor_token", ")", "\n", "\n", "pc", "=", "PointCloud", "(", "radar_points", ")", "\n", "\n", "# Points live in the point sensor frame. So they need to be transformed via global to the image plane.", "\n", "# First step: transform the point-cloud to the ego vehicle frame for the timestamp of the sweep.", "\n", "cs_record", "=", "nusc", ".", "get", "(", "'calibrated_sensor'", ",", "pointsensor", "[", "'calibrated_sensor_token'", "]", ")", "\n", "pc", ".", "rotate", "(", "Quaternion", "(", "cs_record", "[", "'rotation'", "]", ")", ".", "rotation_matrix", ")", "\n", "pc", ".", "translate", "(", "np", ".", "array", "(", "cs_record", "[", "'translation'", "]", ")", ")", "\n", "\n", "# Second step: transform to the global frame.", "\n", "poserecord", "=", "nusc", ".", "get", "(", "'ego_pose'", ",", "pointsensor", "[", "'ego_pose_token'", "]", ")", "\n", "pc", ".", "rotate", "(", "Quaternion", "(", "poserecord", "[", "'rotation'", "]", ")", ".", "rotation_matrix", ")", "\n", "pc", ".", "translate", "(", "np", ".", "array", "(", "poserecord", "[", "'translation'", "]", ")", ")", "\n", "\n", "# Third step: transform into the ego vehicle frame for the timestamp of the image.", "\n", "poserecord", "=", "nusc", ".", "get", "(", "'ego_pose'", ",", "cam", "[", "'ego_pose_token'", "]", ")", "\n", "pc", ".", "translate", "(", "-", "np", ".", "array", "(", "poserecord", "[", "'translation'", "]", ")", ")", "\n", "pc", ".", "rotate", "(", "Quaternion", "(", "poserecord", "[", "'rotation'", "]", ")", ".", "rotation_matrix", ".", "T", ")", "\n", "\n", "# Fourth step: transform into the camera.", "\n", "cs_record", "=", "nusc", ".", "get", "(", "'calibrated_sensor'", ",", "cam", "[", "'calibrated_sensor_token'", "]", ")", "\n", "pc", ".", "translate", "(", "-", "np", ".", "array", "(", "cs_record", "[", "'translation'", "]", ")", ")", "\n", "pc", ".", "rotate", "(", "Quaternion", "(", "cs_record", "[", "'rotation'", "]", ")", ".", "rotation_matrix", ".", "T", ")", "\n", "\n", "# Fifth step: actually take a \"picture\" of the point cloud.", "\n", "# Grab the depths (camera frame z axis points away from the camera).", "\n", "\n", "# intrinsic_resized = np.matmul(camera_resize, np.array(cs_record['camera_intrinsic']))", "\n", "view", "=", "np", ".", "array", "(", "cs_record", "[", "'camera_intrinsic'", "]", ")", "\n", "# Take the actual picture (matrix multiplication with camera-matrix + renormalization).", "\n", "points", "=", "view_points", "(", "pc", ".", "points", ",", "view", ",", "normalize", "=", "True", ")", "#resize here", "\n", "\n", "# Resizing to target resolution", "\n", "if", "target_resolution", "[", "1", "]", ":", "# resizing width", "\n", "        ", "points", "[", "0", ",", ":", "]", "*=", "(", "target_resolution", "[", "1", "]", "/", "cam", "[", "'width'", "]", ")", "\n", "\n", "", "if", "target_resolution", "[", "0", "]", ":", "# resizing height", "\n", "        ", "points", "[", "1", ",", ":", "]", "*=", "(", "target_resolution", "[", "0", "]", "/", "cam", "[", "'height'", "]", ")", "\n", "\n", "# actual_resolution = (cam['height'], cam['width'])", "\n", "# for i in range(len(target_resolution)):", "\n", "#     if target_resolution[i]:", "\n", "#         points[i,:] *= (target_resolution[i]/actual_resolution[i])", "\n", "\n", "", "return", "points", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.create_spatial_point_array": [[364, 404], ["nusc.get", "numpy.zeros", "fusion_projection_lines.map_pointcloud_to_image", "range", "projected_radar_points[].astype"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.map_pointcloud_to_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "create_spatial_point_array", "(", "nusc", ",", "radar_data", ",", "pointsensor_token", ",", "camera_token", ",", "target_width", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function turns a radar point cloud into a 1-D array by encoding the spatial information.\n    The position in the array reflects the direction of the radar point with respect to a camera.\n\n    :param nusc: [nuscenes.nuscenes.Nuscenes] nuScenes database\n    :param target_width: [int] the target resolution along x-axis for the output array\n    :param dim: dimensionality of the target array\n    \"\"\"", "\n", "##########################", "\n", "##### Initialization #####", "\n", "##########################", "\n", "radar_meta_count", "=", "radar_data", ".", "shape", "[", "0", "]", "-", "3", "# -3 for substracting the image positions x y z ", "\n", "img_data", "=", "nusc", ".", "get", "(", "'sample_data'", ",", "camera_token", ")", "\n", "target_width", "=", "target_width", "or", "img_data", "[", "'width'", "]", "\n", "target_resolution", "=", "(", "1", ",", "target_width", ")", "\n", "radar_array", "=", "np", ".", "zeros", "(", "(", "*", "target_resolution", ",", "radar_meta_count", ")", ")", "\n", "\n", "######################################", "\n", "##### Perform the array creation #####", "\n", "######################################", "\n", "# Get radar points with x and y coordinates", "\n", "projected_radar_points", "=", "map_pointcloud_to_image", "(", "nusc", ",", "radar_data", ",", "pointsensor_token", "=", "pointsensor_token", ",", "camera_token", "=", "camera_token", ",", "target_resolution", "=", "target_resolution", ")", "\n", "\n", "for", "i", "in", "range", "(", "projected_radar_points", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "x", ",", "y", "=", "projected_radar_points", "[", "0", ":", "2", ",", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", "# first ", "\n", "if", "x", "<", "0", "or", "x", ">=", "target_width", ":", "\n", "            ", "continue", "# we skip this point, because it lies outside of the image", "\n", "", "y", "=", "0", "# Set height to zero in case the point is outside of the image", "\n", "radar_array", "[", "y", ",", "x", "]", "=", "projected_radar_points", "[", "3", ":", ",", "i", "]", "\n", "\n", "\n", "################################", "\n", "##### Postprocess the data #####", "\n", "################################", "\n", "# Remove x,y,z from radar data", "\n", "# radar_array = radar_array[3:,:]", "\n", "\n", "", "return", "radar_array", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.imageplus_creation": [[405, 513], ["fusion_projection_lines._resize_image", "fusion_projection_lines._radar_transformation", "fusion_projection_lines.map_pointcloud_to_image", "fusion_projection_lines.map_pointcloud_to_image", "fusion_projection_lines._radar2camera", "cur_img.fill"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._resize_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._radar_transformation", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.map_pointcloud_to_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.map_pointcloud_to_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._radar2camera"], ["", "def", "imageplus_creation", "(", "nusc", ",", "image_data", ",", "radar_data", ",", "pointsensor_token", ",", "camera_token", ",", "height", "=", "(", "0", ",", "3", ")", ",", "image_target_shape", "=", "(", "900", ",", "1600", ")", ",", "clear_radar", "=", "False", ",", "clear_image", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Superordinate function that creates image_plus data of raw camera and radar data\n\n    :param nusc: nuScenes initialization\n    :param image_data: [numpy array] (900 x 1600 x 3)\n    :param radar_data: [numpy array](SHAPE?) with radar parameter (e.g. velocity) in rows and radar points for one timestep in columns\n        Semantics:\n            [0]: x (1)\n            [1]: y (2)\n            [2]: z (3)\n            [3]: dyn_prop (4)\n            [4]: id (5)\n            [5]: rcs (6)\n            [6]: vx (7)\n            [7]: vy (8)\n            [8]: vx_comp (9)\n            [9]: vy_comp (10)\n            [10]: is_quality_valid (11)\n            [11]: ambig_state (12)\n            [12]: x_rms (13)\n            [13]: y_rms (14)\n            [14]: invalid_state (15)\n            [15]: pdh0 (16)\n            [16]: vx_rms (17)\n            [17]: vy_rms (18)\n            [18]: distance (19)\n\n    :param pointsensor_token: [str] token of the pointsensor that should be used, most likely radar\n    :param camera_token: [str] token of the camera sensor\n    :param height: 2 options for 2 different modi\n            a.) [tuple] (e.g. height=(0,3)) to define lower and upper boundary\n            b.) [str] height = 'FOV' for calculating the heights after the field of view of the radar\n    :param image_target_shape: [tuple] with (height, width), default is (900, 1600)\n    :param clear_radar: [boolean] True if radar data should be all zero\n    :param clear_image: [boolean] True if image data should be all zero\n\n    :returns: [tuple] image_plus, image\n        -image_plus: [numpy array] (900 x 1600 x (3 + number of radar_meta (e.g. velocity)))\n           Semantics:\n            [0]: R (1)\n            [1]: G (2)\n            [2]: B (3)\n            [3]: dyn_prop (4)\n            [4]: id (5)\n            [5]: rcs (6)\n            [6]: vx (7)\n            [7]: vy (8)\n            [8]: vx_comp (9)\n            [9]: vy_comp (10)\n            [10]: is_quality_valid (11)\n            [11]: ambig_state (12)\n            [12]: x_rms (13)\n            [13]: y_rms (14)\n            [14]: invalid_state (15)\n            [15]: pdh0 (16)\n            [16]: vx_rms (17)\n            [17]: vy_rms (18)\n            [18]: distance (19)\n\n        -cur_image: [numpy array] the original, resized image\n    \"\"\"", "\n", "\n", "###############################", "\n", "##### Preprocess the data #####", "\n", "###############################", "\n", "# enable barcode method", "\n", "barcode", "=", "False", "\n", "if", "height", "[", "1", "]", ">", "20", ":", "\n", "        ", "height", "=", "(", "0", ",", "1", ")", "\n", "barcode", "=", "True", "\n", "\n", "# Resize the image due to a target shape", "\n", "", "cur_img", ",", "camera_resize", "=", "_resize_image", "(", "image_data", ",", "image_target_shape", ")", "\n", "\n", "# Get radar points with the desired height and radar meta data", "\n", "radar_points", ",", "radar_xyz_endpoint", "=", "_radar_transformation", "(", "radar_data", ",", "height", ")", "\n", "\n", "#######################", "\n", "##### Filter Data #####", "\n", "#######################", "\n", "# Clear the image if clear_image is True", "\n", "if", "clear_image", ":", "\n", "        ", "cur_img", ".", "fill", "(", "0", ")", "\n", "\n", "#####################################", "\n", "##### Perform the actual Fusion #####", "\n", "#####################################", "\n", "# Map the radar points into the image", "\n", "", "radar_points", "=", "map_pointcloud_to_image", "(", "nusc", ",", "radar_points", ",", "pointsensor_token", "=", "pointsensor_token", ",", "camera_token", "=", "camera_token", ",", "target_resolution", "=", "image_target_shape", ")", "\n", "radar_xyz_endpoint", "=", "map_pointcloud_to_image", "(", "nusc", ",", "radar_xyz_endpoint", ",", "pointsensor_token", "=", "pointsensor_token", ",", "camera_token", "=", "camera_token", ",", "target_resolution", "=", "image_target_shape", ")", "\n", "\n", "if", "barcode", ":", "\n", "        ", "radar_points", "[", "1", ",", ":", "]", "=", "image_data", ".", "shape", "[", "0", "]", "\n", "radar_xyz_endpoint", "[", "1", ",", ":", "]", "=", "0", "\n", "\n", "# Create image plus by creating projection lines and store them as additional channels in the image", "\n", "", "image_plus", "=", "_radar2camera", "(", "cur_img", ",", "radar_points", ",", "radar_xyz_endpoint", ",", "clear_radar", "=", "clear_radar", ")", "\n", "\n", "#########################", "\n", "##### Quality Check #####", "\n", "#########################", "\n", "# Check if clear_image worked", "\n", "# if clear_image and np.count_nonzero(image_plus[0:3]):", "\n", "#     print(\"Clearing image did not work\")", "\n", "\n", "return", "image_plus", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.imageplus_creation_camra": [[515, 566], ["fusion_projection_lines._resize_image", "numpy.array", "numpy.array().astype", "numpy.array", "numpy.array().astype", "numpy.zeros", "range", "numpy.concatenate", "numpy.ones", "calibrator.world2cam", "numpy.ones", "calibrator.world2cam", "fusion_projection_lines._create_vertical_line", "range", "numpy.array", "numpy.array", "projection_line[].astype", "projection_line[].astype", "numpy.any"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._resize_image", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines._create_vertical_line", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "imageplus_creation_camra", "(", "image_data", ",", "radar_data", ",", "calibrator", ",", "height", "=", "(", "0", ",", "3", ")", ",", "image_target_shape", "=", "(", "800", ",", "1280", ")", ")", ":", "\n", "\n", "    ", "ratio", "=", "[", "image_target_shape", "[", "0", "]", "/", "image_data", ".", "shape", "[", "0", "]", ",", "image_target_shape", "[", "1", "]", "/", "image_data", ".", "shape", "[", "1", "]", "]", "\n", "image_data", ",", "_", "=", "_resize_image", "(", "image_data", ",", "image_target_shape", ")", "\n", "\n", "image_data", "=", "image_data", "/", "255", "\n", "\n", "x", ",", "y", ",", "z", "=", "radar_data", "[", "0", ":", "3", "]", "\n", "\n", "## Bottom point of projection line", "\n", "z", "=", "np", ".", "ones", "(", "x", ".", "shape", ")", "*", "(", "height", "[", "0", "]", "+", "0.5", ")", "\n", "\n", "# radar points according to world2cam convention", "\n", "radar_points", "=", "[", "z", ",", "y", ",", "-", "x", "]", "\n", "cam_points_low", "=", "np", ".", "array", "(", "calibrator", ".", "world2cam", "(", "radar_points", ")", ")", "\n", "cam_points_low", "=", "np", ".", "array", "(", "[", "ratio", "[", "1", "]", "*", "cam_points_low", "[", "0", "]", ",", "ratio", "[", "0", "]", "*", "cam_points_low", "[", "1", "]", "]", ")", ".", "astype", "(", "np", ".", "uint16", ")", "\n", "\n", "\n", "## Ceiling point of projection line", "\n", "z", "=", "np", ".", "ones", "(", "x", ".", "shape", ")", "*", "(", "-", "height", "[", "1", "]", "+", "0.5", ")", "\n", "\n", "# radar points according to world2cam convention", "\n", "radar_points", "=", "[", "z", ",", "y", ",", "-", "x", "]", "\n", "cam_points_high", "=", "np", ".", "array", "(", "calibrator", ".", "world2cam", "(", "radar_points", ")", ")", "\n", "cam_points_high", "=", "np", ".", "array", "(", "[", "ratio", "[", "1", "]", "*", "cam_points_high", "[", "0", "]", ",", "ratio", "[", "0", "]", "*", "cam_points_high", "[", "1", "]", "]", ")", ".", "astype", "(", "np", ".", "uint16", ")", "\n", "\n", "# Prevent errors in projection where the high point is lower than the low point", "\n", "points_to_keep", "=", "cam_points_high", "[", "1", ",", ":", "]", "<", "cam_points_low", "[", "1", ",", ":", "]", "\n", "cam_points_high", "=", "cam_points_high", "[", ":", ",", "points_to_keep", "]", "\n", "cam_points_low", "=", "cam_points_low", "[", ":", ",", "points_to_keep", "]", "\n", "\n", "\n", "radar_meta_count", "=", "radar_data", ".", "shape", "[", "0", "]", "-", "3", "\n", "radar_extension", "=", "np", ".", "zeros", "(", "(", "image_data", ".", "shape", "[", "0", "]", ",", "image_data", ".", "shape", "[", "1", "]", ",", "radar_meta_count", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "no_of_points", "=", "cam_points_low", ".", "shape", "[", "1", "]", "\n", "\n", "for", "radar_point", "in", "range", "(", "0", ",", "no_of_points", ")", ":", "\n", "        ", "projection_line", "=", "_create_vertical_line", "(", "\n", "cam_points_low", "[", ":", ",", "radar_point", "]", ",", "cam_points_high", "[", ":", ",", "radar_point", "]", ",", "image_data", ")", "\n", "\n", "for", "pixel_point", "in", "range", "(", "0", ",", "projection_line", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "y", "=", "projection_line", "[", "pixel_point", ",", "1", "]", ".", "astype", "(", "int", ")", "\n", "x", "=", "projection_line", "[", "pixel_point", ",", "0", "]", ".", "astype", "(", "int", ")", "\n", "\n", "# Check if pixel is already filled with radar data and overwrite if distance is less than the existing", "\n", "if", "not", "np", ".", "any", "(", "radar_extension", "[", "y", ",", "x", "]", ")", "or", "radar_data", "[", "-", "1", ",", "radar_point", "]", "<", "radar_extension", "[", "y", ",", "x", ",", "-", "1", "]", ":", "\n", "                ", "radar_extension", "[", "y", ",", "x", "]", "=", "radar_data", "[", "3", ":", ",", "radar_point", "]", "\n", "\n", "", "", "", "image_plus", "=", "np", ".", "concatenate", "(", "(", "image_data", ",", "radar_extension", ")", ",", "axis", "=", "2", ")", "\n", "return", "image_plus", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.fusion.fusion_projection_lines.create_imagep_visualization": [[567, 644], ["numpy.ones", "numpy.array().astype", "cv2.cvtColor", "len", "image_plus_data[].copy", "numpy.array", "range", "numpy.array", "print", "numpy.zeros", "numpy.clip", "cv2.applyColorMap", "range", "utils.radar.normalize", "radar.normalize.astype", "numpy.count_nonzero", "enumerate", "numpy.array", "numpy.squeeze", "cv2.circle", "cv2.addWeighted", "numpy.any", "radar_colormap[].astype"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.radar.normalize"], ["", "def", "create_imagep_visualization", "(", "image_plus_data", ",", "color_channel", "=", "\"distance\"", ",", "draw_circles", "=", "False", ",", "cfg", "=", "None", ",", "radar_lines_opacity", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"\n    Visualization of image plus data\n\n    Parameters:\n        :image_plus_data: a numpy array (900 x 1600 x (3 + number of radar_meta (e.g. velocity)))\n        :image_data: a numpy array (900 x 1600 x 3)\n        :color_channel: <str> Image plus channel for colorizing the radar lines. according to radar.channel_map.\n        :draw_circles: Draws circles at the bottom of the radar lines\n    Returns:\n        :image_data: a numpy array (900 x 1600 x 3)\n    \"\"\"", "\n", "# read dimensions", "\n", "image_plus_height", "=", "image_plus_data", ".", "shape", "[", "0", "]", "\n", "image_plus_width", "=", "image_plus_data", ".", "shape", "[", "1", "]", "\n", "n_channels", "=", "image_plus_data", ".", "shape", "[", "2", "]", "\n", "\n", "##### Extract the image Channels #####", "\n", "if", "cfg", "is", "None", ":", "\n", "        ", "image_channels", "=", "[", "0", ",", "1", ",", "2", "]", "\n", "", "else", ":", "\n", "        ", "image_channels", "=", "[", "i_ch", "for", "i_ch", "in", "cfg", ".", "channels", "if", "i_ch", "in", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "", "image_data", "=", "np", ".", "ones", "(", "shape", "=", "(", "*", "image_plus_data", ".", "shape", "[", ":", "2", "]", ",", "3", ")", ")", "\n", "if", "len", "(", "image_channels", ")", ">", "0", ":", "\n", "        ", "image_data", "[", ":", ",", ":", ",", "image_channels", "]", "=", "image_plus_data", "[", ":", ",", ":", ",", "image_channels", "]", ".", "copy", "(", ")", "# copy so we dont change the old image", "\n", "\n", "# Draw the Horizon", "\n", "", "image_data", "=", "np", ".", "array", "(", "image_data", "*", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "image_data", "=", "cv2", ".", "cvtColor", "(", "image_data", ",", "cv2", ".", "COLOR_RGB2BGR", ")", "\n", "\n", "##### Paint every augmented pixel on the image #####", "\n", "if", "n_channels", ">", "3", ":", "\n", "# transfer it to the currently selected channels", "\n", "        ", "if", "cfg", "is", "None", ":", "\n", "            ", "print", "(", "\"Warning, no cfg provided. Thus, its not possible to find out \\\n                which channel shall be used for colorization\"", ")", "\n", "radar_img", "=", "np", ".", "zeros", "(", "image_plus_data", ".", "shape", "[", ":", "-", "1", "]", ")", "# we expect the channel index to be the last axis", "\n", "", "else", ":", "\n", "            ", "available_channels", "=", "{", "radar", ".", "channel_map", "[", "ch", "]", ":", "ch_idx", "for", "ch_idx", ",", "ch", "in", "enumerate", "(", "cfg", ".", "channels", ")", "if", "ch", ">", "2", "}", "\n", "ch_idx", "=", "available_channels", "[", "color_channel", "]", "\n", "# Normalize the radar", "\n", "if", "cfg", ".", "normalize_radar", ":", "# normalization happens from -127 to 127", "\n", "                ", "radar_img", "=", "image_plus_data", "[", "...", ",", "ch_idx", "]", "+", "127.5", "\n", "", "else", ":", "\n", "                ", "radar_img", "=", "radar", ".", "normalize", "(", "color_channel", ",", "image_plus_data", "[", "...", ",", "ch_idx", "]", ",", "\n", "normalization_interval", "=", "[", "0", ",", "255", "]", ",", "sigma_factor", "=", "2", ")", "\n", "\n", "", "radar_img", "=", "np", ".", "clip", "(", "radar_img", ",", "0", ",", "255", ")", "\n", "\n", "", "radar_colormap", "=", "np", ".", "array", "(", "cv2", ".", "applyColorMap", "(", "radar_img", ".", "astype", "(", "np", ".", "uint8", ")", ",", "cv2", ".", "COLORMAP_AUTUMN", ")", ")", "\n", "\n", "for", "x", "in", "range", "(", "0", ",", "image_plus_width", ")", ":", "\n", "            ", "for", "y", "in", "range", "(", "0", ",", "image_plus_height", ")", ":", "\n", "                ", "radar_channels", "=", "image_plus_data", "[", "y", ",", "x", ",", "3", ":", "]", "\n", "pixel_contains_radar", "=", "np", ".", "count_nonzero", "(", "radar_channels", ")", "\n", "if", "not", "pixel_contains_radar", ":", "\n", "                    ", "continue", "\n", "\n", "", "radar_color", "=", "radar_colormap", "[", "y", ",", "x", "]", "\n", "for", "pixel", "in", "[", "(", "y", ",", "x", ")", "]", ":", "#[(y,x-1),(y,x),(y,x+1)]:", "\n", "                    ", "if", "image_data", ".", "shape", ">", "pixel", ":", "\n", "\n", "# Calculate the color", "\n", "                        ", "pixel_color", "=", "np", ".", "array", "(", "image_data", "[", "pixel", "]", "[", "0", ":", "3", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "pixel_color", "=", "np", ".", "squeeze", "(", "cv2", ".", "addWeighted", "(", "pixel_color", ",", "1", "-", "radar_lines_opacity", ",", "radar_color", ",", "radar_lines_opacity", ",", "0", ")", ")", "\n", "\n", "# Draw on image", "\n", "image_data", "[", "pixel", "]", "=", "pixel_color", "\n", "\n", "# only if some radar information is there", "\n", "", "", "if", "draw_circles", ":", "\n", "                    ", "if", "image_plus_data", ".", "shape", "[", "0", "]", ">", "y", "+", "1", "and", "not", "np", ".", "any", "(", "image_plus_data", "[", "y", "+", "1", ",", "x", ",", "3", ":", "]", ")", ":", "\n", "                        ", "cv2", ".", "circle", "(", "image_data", ",", "(", "x", ",", "y", ")", ",", "3", ",", "color", "=", "radar_colormap", "[", "(", "y", ",", "x", ")", "]", ".", "astype", "(", "np", ".", "float", ")", ",", "thickness", "=", "1", ")", "\n", "\n", "\n", "", "", "", "", "", "return", "image_data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.initializers.PriorProbability.__init__": [[27, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "probability", "=", "0.01", ")", ":", "\n", "        ", "self", ".", "probability", "=", "probability", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.initializers.PriorProbability.get_config": [[30, 33], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'probability'", ":", "self", ".", "probability", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.initializers.PriorProbability.__call__": [[35, 40], ["numpy.ones", "math.log"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones"], ["", "def", "__call__", "(", "self", ",", "shape", ",", "dtype", "=", "None", ")", ":", "\n", "# set bias to -log((1 - p)/p) for foreground", "\n", "        ", "result", "=", "np", ".", "ones", "(", "shape", ",", "dtype", "=", "dtype", ")", "*", "-", "math", ".", "log", "(", "(", "1", "-", "self", ".", "probability", ")", "/", "self", ".", "probability", ")", "\n", "\n", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.focal": [[21, 68], ["crfnet.model.backend.where", "crfnet.model.backend.gather_nd", "crfnet.model.backend.gather_nd", "crfnet.model.backend.where", "crfnet.model.backend.where", "crfnet.model.backend.where", "keras.backend.cast", "keras.backend.maximum", "keras.backend.not_equal", "keras.backend.ones_like", "keras.backend.equal", "keras.backend.equal", "keras.backend.binary_crossentropy", "keras.backend.equal", "keras.backend.floatx", "keras.backend.cast_to_floatx", "keras.backend.sum", "keras.backend.shape"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where"], ["def", "focal", "(", "alpha", "=", "0.25", ",", "gamma", "=", "2.0", ")", ":", "\n", "    ", "\"\"\" Create a functor for computing the focal loss.\n\n    Args\n        alpha: Scale the focal weight with alpha.\n        gamma: Take the power of the focal weight with gamma.\n\n    Returns\n        A functor that computes the focal loss using the alpha and gamma.\n    \"\"\"", "\n", "def", "_focal", "(", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\" Compute the focal loss given the target tensor and the predicted tensor.\n\n        As defined in https://arxiv.org/abs/1708.02002\n\n        Args\n            y_true: Tensor of target data from the generator with shape (B, N, num_classes).\n            y_pred: Tensor of predicted data from the network with shape (B, N, num_classes).\n\n        Returns\n            The focal loss of y_pred w.r.t. y_true.\n        \"\"\"", "\n", "labels", "=", "y_true", "[", ":", ",", ":", ",", ":", "-", "1", "]", "\n", "anchor_state", "=", "y_true", "[", ":", ",", ":", ",", "-", "1", "]", "# -1 for ignore, 0 for background, 1 for object", "\n", "classification", "=", "y_pred", "\n", "\n", "# filter out \"ignore\" anchors", "\n", "indices", "=", "backend", ".", "where", "(", "keras", ".", "backend", ".", "not_equal", "(", "anchor_state", ",", "-", "1", ")", ")", "\n", "labels", "=", "backend", ".", "gather_nd", "(", "labels", ",", "indices", ")", "\n", "classification", "=", "backend", ".", "gather_nd", "(", "classification", ",", "indices", ")", "\n", "\n", "# compute the focal loss", "\n", "alpha_factor", "=", "keras", ".", "backend", ".", "ones_like", "(", "labels", ")", "*", "alpha", "\n", "alpha_factor", "=", "backend", ".", "where", "(", "keras", ".", "backend", ".", "equal", "(", "labels", ",", "1", ")", ",", "alpha_factor", ",", "1", "-", "alpha_factor", ")", "\n", "focal_weight", "=", "backend", ".", "where", "(", "keras", ".", "backend", ".", "equal", "(", "labels", ",", "1", ")", ",", "1", "-", "classification", ",", "classification", ")", "\n", "focal_weight", "=", "alpha_factor", "*", "focal_weight", "**", "gamma", "\n", "\n", "cls_loss", "=", "focal_weight", "*", "keras", ".", "backend", ".", "binary_crossentropy", "(", "labels", ",", "classification", ")", "\n", "\n", "# compute the normalizer: the number of positive anchors", "\n", "normalizer", "=", "backend", ".", "where", "(", "keras", ".", "backend", ".", "equal", "(", "anchor_state", ",", "1", ")", ")", "\n", "normalizer", "=", "keras", ".", "backend", ".", "cast", "(", "keras", ".", "backend", ".", "shape", "(", "normalizer", ")", "[", "0", "]", ",", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "normalizer", "=", "keras", ".", "backend", ".", "maximum", "(", "keras", ".", "backend", ".", "cast_to_floatx", "(", "1.0", ")", ",", "normalizer", ")", "\n", "\n", "return", "keras", ".", "backend", ".", "sum", "(", "cls_loss", ")", "/", "normalizer", "\n", "\n", "", "return", "_focal", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.smooth_l1": [[70, 118], ["crfnet.model.backend.where", "crfnet.model.backend.gather_nd", "crfnet.model.backend.gather_nd", "keras.backend.abs", "crfnet.model.backend.where", "keras.backend.maximum", "keras.backend.cast", "keras.backend.equal", "keras.backend.less", "keras.backend.pow", "keras.backend.shape", "keras.backend.floatx", "keras.backend.sum"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where"], ["", "def", "smooth_l1", "(", "sigma", "=", "3.0", ",", "alpha", "=", "1.0", ")", ":", "\n", "    ", "\"\"\" Create a smooth L1 loss functor.\n\n    Args\n        sigma: This argument defines the point where the loss changes from L2 to L1.\n\n    Returns\n        A functor for computing the smooth L1 loss given target data and predicted data.\n    \"\"\"", "\n", "sigma_squared", "=", "sigma", "**", "2", "\n", "\n", "def", "_smooth_l1", "(", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\" Compute the smooth L1 loss of y_pred w.r.t. y_true.\n\n        Args\n            y_true: Tensor from the generator of shape (B, N, 5). The last value for each box is the state of the anchor (ignore, negative, positive).\n            y_pred: Tensor from the network of shape (B, N, 4).\n\n        Returns\n            The smooth L1 loss of y_pred w.r.t. y_true.\n        \"\"\"", "\n", "# separate target and state", "\n", "regression", "=", "y_pred", "\n", "regression_target", "=", "y_true", "[", ":", ",", ":", ",", ":", "-", "1", "]", "\n", "anchor_state", "=", "y_true", "[", ":", ",", ":", ",", "-", "1", "]", "\n", "\n", "# filter out \"ignore\" anchors", "\n", "indices", "=", "backend", ".", "where", "(", "keras", ".", "backend", ".", "equal", "(", "anchor_state", ",", "1", ")", ")", "\n", "regression", "=", "backend", ".", "gather_nd", "(", "regression", ",", "indices", ")", "\n", "regression_target", "=", "backend", ".", "gather_nd", "(", "regression_target", ",", "indices", ")", "\n", "\n", "# compute smooth L1 loss", "\n", "# f(x) = 0.5 * (sigma * x)^2          if |x| < 1 / sigma / sigma", "\n", "#        |x| - 0.5 / sigma / sigma    otherwise", "\n", "regression_diff", "=", "regression", "-", "regression_target", "\n", "regression_diff", "=", "keras", ".", "backend", ".", "abs", "(", "regression_diff", ")", "\n", "regression_loss", "=", "backend", ".", "where", "(", "\n", "keras", ".", "backend", ".", "less", "(", "regression_diff", ",", "1.0", "/", "sigma_squared", ")", ",", "\n", "0.5", "*", "sigma_squared", "*", "keras", ".", "backend", ".", "pow", "(", "regression_diff", ",", "2", ")", ",", "\n", "regression_diff", "-", "0.5", "/", "sigma_squared", "\n", ")", "\n", "\n", "# compute the normalizer: the number of positive anchors", "\n", "normalizer", "=", "keras", ".", "backend", ".", "maximum", "(", "1", ",", "keras", ".", "backend", ".", "shape", "(", "indices", ")", "[", "0", "]", ")", "\n", "normalizer", "=", "keras", ".", "backend", ".", "cast", "(", "normalizer", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "return", "alpha", "*", "keras", ".", "backend", ".", "sum", "(", "regression_loss", ")", "/", "normalizer", "\n", "\n", "", "return", "_smooth_l1", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses_neural_filter.binary_focal_loss": [[6, 49], ["tensorflow.keras.backend.greater", "tensorflow.where", "tensorflow.where", "tensorflow.clip_by_value", "tensorflow.squeeze", "tensorflow.identity", "tensorflow.identity", "tensorflow.where", "tensorflow.keras.backend.cast", "tensorflow.keras.backend.maximum", "tensorflow.keras.backend.sum", "tensorflow.identity", "tensorflow.keras.backend.ones_like", "tensorflow.keras.backend.epsilon", "loss_fn", "tensorflow.keras.backend.floatx", "tensorflow.keras.backend.cast_to_floatx", "tensorflow.keras.backend.shape"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where"], ["def", "binary_focal_loss", "(", "loss_fn", ",", "threshold", "=", "0.5", ",", "alpha", "=", "0.2", ",", "gamma", "=", "2.0", ")", ":", "\n", "    ", "\"\"\"\n    Compared to focal loss, the binary focal loss\n\n    :param alpha: Scale the focal weight with alpha.\n    :param gamma: Take the power of the focal weight with gamma.\n\n    \"\"\"", "\n", "\n", "def", "_binary_focal_loss", "(", "y_true", ",", "y_pred", ")", ":", "\n", "\n", "# apply threshold to get clearly positive and negative predictions", "\n", "        ", "y_true_binary", "=", "tf", ".", "keras", ".", "backend", ".", "greater", "(", "y_true", ",", "threshold", ")", "\n", "\n", "# compute the focal loss", "\n", "alpha_factor", "=", "tf", ".", "keras", ".", "backend", ".", "ones_like", "(", "y_true", ",", "dtype", "=", "tf", ".", "float32", ")", "*", "alpha", "# create an array with alpha values, same shape as y_true", "\n", "alpha_factor", "=", "tf", ".", "where", "(", "y_true_binary", ",", "alpha_factor", ",", "1", "-", "alpha_factor", ")", "# alpha on true, 1-alpha on false", "\n", "alpha_factor", "=", "alpha_factor", "*", "2", "# we don't want to half the learning rate", "\n", "\n", "focal_weight", "=", "tf", ".", "where", "(", "y_true_binary", ",", "1", "-", "y_pred", ",", "y_pred", ")", "\n", "\n", "# this is needed, because the output contains 0.0 after applying to the input grid", "\n", "focal_weight", "=", "tf", ".", "clip_by_value", "(", "focal_weight", ",", "tf", ".", "keras", ".", "backend", ".", "epsilon", "(", ")", ",", "1.0", ")", "\n", "\n", "focal_weight", "=", "alpha_factor", "*", "focal_weight", "**", "gamma", "\n", "focal_weight", "=", "tf", ".", "squeeze", "(", "focal_weight", ",", "axis", "=", "-", "1", ")", "\n", "focal_weight", "=", "tf", ".", "identity", "(", "focal_weight", ",", "name", "=", "\"focal_weight\"", ")", "\n", "\n", "cls_loss", "=", "focal_weight", "*", "loss_fn", "(", "y_true", ",", "y_pred", ")", "\n", "cls_loss", "=", "tf", ".", "identity", "(", "cls_loss", ",", "name", "=", "\"cls_loss\"", ")", "\n", "\n", "# compute the normalizer: the number of positive anchors", "\n", "normalizer", "=", "tf", ".", "where", "(", "y_true_binary", ")", "\n", "normalizer", "=", "tf", ".", "keras", ".", "backend", ".", "cast", "(", "tf", ".", "keras", ".", "backend", ".", "shape", "(", "normalizer", ")", "[", "0", "]", ",", "tf", ".", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "normalizer", "=", "tf", ".", "keras", ".", "backend", ".", "maximum", "(", "tf", ".", "keras", ".", "backend", ".", "cast_to_floatx", "(", "1", ")", ",", "normalizer", ")", "\n", "\n", "cls_loss_sum", "=", "tf", ".", "keras", ".", "backend", ".", "sum", "(", "cls_loss", ")", "\n", "loss", "=", "cls_loss_sum", "/", "normalizer", "\n", "\n", "loss", "=", "tf", ".", "identity", "(", "loss", ",", "name", "=", "\"focal_loss\"", ")", "\n", "return", "loss", "#tf.keras.backend.sum(cls_loss) / normalizer", "\n", "\n", "", "return", "_binary_focal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses_neural_filter.roc_auc_score": [[51, 82], ["tensorflow.name_scope", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.boolean_mask", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.pow", "tensorflow.cast", "tensorflow.zeros_like"], "function", ["None"], ["", "def", "roc_auc_score", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\" ROC AUC Score.\n    Source: https://github.com/tflearn/tflearn/blob/master/tflearn/objectives.py\n    Modifications: argument order y_pred and y_true\n\n    Approximates the Area Under Curve score, using approximation based on\n    the Wilcoxon-Mann-Whitney U statistic.\n    Yan, L., Dodier, R., Mozer, M. C., & Wolniewicz, R. (2003).\n    Optimizing Classifier Performance via an Approximation to the Wilcoxon-Mann-Whitney Statistic.\n    Measures overall performance for a full range of threshold levels.\n    Arguments:\n        y_true: `Tensor` . Targets (labels), a probability distribution.\n        y_pred: `Tensor`. Predicted values.\n    \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"RocAucScore\"", ")", ":", "\n", "\n", "        ", "pos", "=", "tf", ".", "boolean_mask", "(", "y_pred", ",", "tf", ".", "cast", "(", "y_true", ",", "tf", ".", "bool", ")", ")", "\n", "neg", "=", "tf", ".", "boolean_mask", "(", "y_pred", ",", "~", "tf", ".", "cast", "(", "y_true", ",", "tf", ".", "bool", ")", ")", "\n", "\n", "pos", "=", "tf", ".", "expand_dims", "(", "pos", ",", "0", ")", "\n", "neg", "=", "tf", ".", "expand_dims", "(", "neg", ",", "1", ")", "\n", "\n", "# original paper suggests performance is robust to exact parameter choice", "\n", "gamma", "=", "0.2", "\n", "p", "=", "3", "\n", "\n", "difference", "=", "tf", ".", "zeros_like", "(", "pos", "*", "neg", ")", "+", "pos", "-", "neg", "-", "gamma", "\n", "\n", "masked", "=", "tf", ".", "boolean_mask", "(", "difference", ",", "difference", "<", "0.0", ")", "\n", "\n", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "-", "masked", ",", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.Anchors.__init__": [[31, 62], ["keras.backend.variable", "super().__init__", "isinstance", "isinstance", "len", "len", "crfnet.utils.anchor.generate_anchors", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.generator.generator.Generator.generate_anchors"], ["def", "__init__", "(", "self", ",", "size", ",", "stride", ",", "ratios", "=", "None", ",", "scales", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Initializer for an Anchors layer.\n\n        Args\n            size: The base size of the anchors to generate.\n            stride: The stride of the anchors to generate.\n            ratios: The ratios of the anchors to generate (defaults to AnchorParameters.default.ratios).\n            scales: The scales of the anchors to generate (defaults to AnchorParameters.default.scales).\n        \"\"\"", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "ratios", "=", "ratios", "\n", "self", ".", "scales", "=", "scales", "\n", "\n", "if", "ratios", "is", "None", ":", "\n", "            ", "self", ".", "ratios", "=", "AnchorParameters", ".", "default", ".", "ratios", "\n", "", "elif", "isinstance", "(", "ratios", ",", "list", ")", ":", "\n", "            ", "self", ".", "ratios", "=", "np", ".", "array", "(", "ratios", ")", "\n", "", "if", "scales", "is", "None", ":", "\n", "            ", "self", ".", "scales", "=", "AnchorParameters", ".", "default", ".", "scales", "\n", "", "elif", "isinstance", "(", "scales", ",", "list", ")", ":", "\n", "            ", "self", ".", "scales", "=", "np", ".", "array", "(", "scales", ")", "\n", "\n", "", "self", ".", "num_anchors", "=", "len", "(", "ratios", ")", "*", "len", "(", "scales", ")", "\n", "self", ".", "anchors", "=", "keras", ".", "backend", ".", "variable", "(", "generate_anchors", "(", "\n", "base_size", "=", "size", ",", "\n", "ratios", "=", "ratios", ",", "\n", "scales", "=", "scales", ",", "\n", ")", ")", "\n", "\n", "super", "(", "Anchors", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.Anchors.call": [[63, 75], ["keras.backend.shape", "keras.backend.tile", "keras.backend.image_data_format", "crfnet.model.backend.shift", "crfnet.model.backend.shift", "keras.backend.expand_dims"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.common.shift", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.common.shift"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "features", "=", "inputs", "\n", "features_shape", "=", "keras", ".", "backend", ".", "shape", "(", "features", ")", "\n", "\n", "# generate proposals from bbox deltas and shifted anchors", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "anchors", "=", "backend", ".", "shift", "(", "features_shape", "[", "2", ":", "4", "]", ",", "self", ".", "stride", ",", "self", ".", "anchors", ")", "\n", "", "else", ":", "\n", "            ", "anchors", "=", "backend", ".", "shift", "(", "features_shape", "[", "1", ":", "3", "]", ",", "self", ".", "stride", ",", "self", ".", "anchors", ")", "\n", "", "anchors", "=", "keras", ".", "backend", ".", "tile", "(", "keras", ".", "backend", ".", "expand_dims", "(", "anchors", ",", "axis", "=", "0", ")", ",", "(", "features_shape", "[", "0", "]", ",", "1", ",", "1", ")", ")", "\n", "\n", "return", "anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.Anchors.compute_output_shape": [[76, 86], ["keras.backend.image_data_format", "numpy.prod", "numpy.prod"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "None", "not", "in", "input_shape", "[", "1", ":", "]", ":", "\n", "            ", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "                ", "total", "=", "np", ".", "prod", "(", "input_shape", "[", "2", ":", "4", "]", ")", "*", "self", ".", "num_anchors", "\n", "", "else", ":", "\n", "                ", "total", "=", "np", ".", "prod", "(", "input_shape", "[", "1", ":", "3", "]", ")", "*", "self", ".", "num_anchors", "\n", "\n", "", "return", "(", "input_shape", "[", "0", "]", ",", "total", ",", "4", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", "None", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.Anchors.get_config": [[87, 97], ["super().get_config", "super().get_config.update", "_misc.Anchors.ratios.tolist", "_misc.Anchors.scales.tolist"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.get_config"], ["", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "Anchors", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "'size'", ":", "self", ".", "size", ",", "\n", "'stride'", ":", "self", ".", "stride", ",", "\n", "'ratios'", ":", "self", ".", "ratios", ".", "tolist", "(", ")", ",", "\n", "'scales'", ":", "self", ".", "scales", ".", "tolist", "(", ")", ",", "\n", "}", ")", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.UpsampleLike.call": [[103, 113], ["keras.backend.shape", "keras.backend.image_data_format", "crfnet.model.backend.transpose", "crfnet.model.backend.resize_images", "crfnet.model.backend.transpose", "crfnet.model.backend.resize_images"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.resize_images", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.resize_images"], ["def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "source", ",", "target", "=", "inputs", "\n", "target_shape", "=", "keras", ".", "backend", ".", "shape", "(", "target", ")", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "source", "=", "backend", ".", "transpose", "(", "source", ",", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "output", "=", "backend", ".", "resize_images", "(", "source", ",", "(", "target_shape", "[", "2", "]", ",", "target_shape", "[", "3", "]", ")", ",", "method", "=", "'nearest'", ")", "\n", "output", "=", "backend", ".", "transpose", "(", "output", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "return", "output", "\n", "", "else", ":", "\n", "            ", "return", "backend", ".", "resize_images", "(", "source", ",", "(", "target_shape", "[", "1", "]", ",", "target_shape", "[", "2", "]", ")", ",", "method", "=", "'nearest'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.UpsampleLike.compute_output_shape": [[114, 119], ["keras.backend.image_data_format"], "methods", ["None"], ["", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", "[", "0", "]", ",", "input_shape", "[", "0", "]", "[", "1", "]", ")", "+", "input_shape", "[", "1", "]", "[", "2", ":", "4", "]", "\n", "", "else", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", "[", "0", "]", ",", ")", "+", "input_shape", "[", "1", "]", "[", "1", ":", "3", "]", "+", "(", "input_shape", "[", "0", "]", "[", "-", "1", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.RegressBoxes.__init__": [[125, 151], ["isinstance", "isinstance", "super().__init__", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "isinstance", "ValueError", "isinstance", "ValueError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ",", "mean", "=", "None", ",", "std", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Initializer for the RegressBoxes layer.\n\n        Args\n            mean: The mean value of the regression values which was used for normalization.\n            std: The standard value of the regression values which was used for normalization.\n        \"\"\"", "\n", "if", "mean", "is", "None", ":", "\n", "            ", "mean", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "if", "std", "is", "None", ":", "\n", "            ", "std", "=", "np", ".", "array", "(", "[", "0.2", ",", "0.2", ",", "0.2", ",", "0.2", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "mean", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "mean", "=", "np", ".", "array", "(", "mean", ")", "\n", "", "elif", "not", "isinstance", "(", "mean", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Expected mean to be a np.ndarray, list or tuple. Received: {}'", ".", "format", "(", "type", "(", "mean", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "std", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "std", "=", "np", ".", "array", "(", "std", ")", "\n", "", "elif", "not", "isinstance", "(", "std", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Expected std to be a np.ndarray, list or tuple. Received: {}'", ".", "format", "(", "type", "(", "std", ")", ")", ")", "\n", "\n", "", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n", "super", "(", "RegressBoxes", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.RegressBoxes.call": [[152, 155], ["crfnet.model.backend.bbox_transform_inv"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.common.bbox_transform_inv"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "anchors", ",", "regression", "=", "inputs", "\n", "return", "backend", ".", "bbox_transform_inv", "(", "anchors", ",", "regression", ",", "mean", "=", "self", ".", "mean", ",", "std", "=", "self", ".", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.RegressBoxes.compute_output_shape": [[156, 158], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.RegressBoxes.get_config": [[159, 167], ["super().get_config", "super().get_config.update", "_misc.RegressBoxes.mean.tolist", "_misc.RegressBoxes.std.tolist"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "RegressBoxes", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "'mean'", ":", "self", ".", "mean", ".", "tolist", "(", ")", ",", "\n", "'std'", ":", "self", ".", "std", ".", "tolist", "(", ")", ",", "\n", "}", ")", "\n", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.ClipBoxes.call": [[173, 188], ["keras.backend.cast", "crfnet.model.backend.clip_by_value", "crfnet.model.backend.clip_by_value", "crfnet.model.backend.clip_by_value", "crfnet.model.backend.clip_by_value", "keras.backend.stack", "keras.backend.shape", "keras.backend.floatx", "keras.backend.image_data_format"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value"], ["def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "image", ",", "boxes", "=", "inputs", "\n", "shape", "=", "keras", ".", "backend", ".", "cast", "(", "keras", ".", "backend", ".", "shape", "(", "image", ")", ",", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "height", "=", "shape", "[", "2", "]", "\n", "width", "=", "shape", "[", "3", "]", "\n", "", "else", ":", "\n", "            ", "height", "=", "shape", "[", "1", "]", "\n", "width", "=", "shape", "[", "2", "]", "\n", "", "x1", "=", "backend", ".", "clip_by_value", "(", "boxes", "[", ":", ",", ":", ",", "0", "]", ",", "0", ",", "width", ")", "\n", "y1", "=", "backend", ".", "clip_by_value", "(", "boxes", "[", ":", ",", ":", ",", "1", "]", ",", "0", ",", "height", ")", "\n", "x2", "=", "backend", ".", "clip_by_value", "(", "boxes", "[", ":", ",", ":", ",", "2", "]", ",", "0", ",", "width", ")", "\n", "y2", "=", "backend", ".", "clip_by_value", "(", "boxes", "[", ":", ",", ":", ",", "3", "]", ",", "0", ",", "height", ")", "\n", "\n", "return", "keras", ".", "backend", ".", "stack", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", "]", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers._misc.ClipBoxes.compute_output_shape": [[189, 191], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.FilterDetections.__init__": [[119, 146], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nms", "=", "True", ",", "\n", "class_specific_filter", "=", "True", ",", "\n", "nms_threshold", "=", "0.5", ",", "\n", "score_threshold", "=", "0.05", ",", "\n", "max_detections", "=", "300", ",", "\n", "parallel_iterations", "=", "32", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\" Filters detections using score threshold, NMS and selecting the top-k detections.\n\n        Args\n            nms                   : Flag to enable/disable NMS.\n            class_specific_filter : Whether to perform filtering per class, or take the best scoring class and filter those.\n            nms_threshold         : Threshold for the IoU value to determine when a box should be suppressed.\n            score_threshold       : Threshold used to prefilter the boxes with.\n            max_detections        : Maximum number of detections to keep.\n            parallel_iterations   : Number of batch items to process in parallel.\n        \"\"\"", "\n", "self", ".", "nms", "=", "nms", "\n", "self", ".", "class_specific_filter", "=", "class_specific_filter", "\n", "self", ".", "nms_threshold", "=", "nms_threshold", "\n", "self", ".", "score_threshold", "=", "score_threshold", "\n", "self", ".", "max_detections", "=", "max_detections", "\n", "self", ".", "parallel_iterations", "=", "parallel_iterations", "\n", "super", "(", "FilterDetections", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.FilterDetections.call": [[147, 183], ["backend.map_fn", "filter_detections.filter_detections", "keras.backend.floatx", "keras.backend.floatx"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.map_fn", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.filter_detections"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Constructs the NMS graph.\n\n        Args\n            inputs : List of [boxes, classification, other[0], other[1], ...] tensors.\n        \"\"\"", "\n", "boxes", "=", "inputs", "[", "0", "]", "\n", "classification", "=", "inputs", "[", "1", "]", "\n", "other", "=", "inputs", "[", "2", ":", "]", "\n", "\n", "# wrap nms with our parameters", "\n", "def", "_filter_detections", "(", "args", ")", ":", "\n", "            ", "boxes", "=", "args", "[", "0", "]", "\n", "classification", "=", "args", "[", "1", "]", "\n", "other", "=", "args", "[", "2", "]", "\n", "\n", "return", "filter_detections", "(", "\n", "boxes", ",", "\n", "classification", ",", "\n", "other", ",", "\n", "nms", "=", "self", ".", "nms", ",", "\n", "class_specific_filter", "=", "self", ".", "class_specific_filter", ",", "\n", "score_threshold", "=", "self", ".", "score_threshold", ",", "\n", "max_detections", "=", "self", ".", "max_detections", ",", "\n", "nms_threshold", "=", "self", ".", "nms_threshold", ",", "\n", ")", "\n", "\n", "# call filter_detections on each batch", "\n", "", "outputs", "=", "backend", ".", "map_fn", "(", "\n", "_filter_detections", ",", "\n", "elems", "=", "[", "boxes", ",", "classification", ",", "other", "]", ",", "\n", "dtype", "=", "[", "keras", ".", "backend", ".", "floatx", "(", ")", ",", "keras", ".", "backend", ".", "floatx", "(", ")", ",", "'int32'", "]", "+", "[", "o", ".", "dtype", "for", "o", "in", "other", "]", ",", "\n", "parallel_iterations", "=", "self", ".", "parallel_iterations", "\n", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.FilterDetections.compute_output_shape": [[184, 200], ["tuple", "range", "list", "len"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\" Computes the output shapes given the input shapes.\n\n        Args\n            input_shape : List of input shapes [boxes, classification, other[0], other[1], ...].\n\n        Returns\n            List of tuples representing the output shapes:\n            [filtered_boxes.shape, filtered_scores.shape, filtered_labels.shape, filtered_other[0].shape, filtered_other[1].shape, ...]\n        \"\"\"", "\n", "return", "[", "\n", "(", "input_shape", "[", "0", "]", "[", "0", "]", ",", "self", ".", "max_detections", ",", "4", ")", ",", "\n", "(", "input_shape", "[", "1", "]", "[", "0", "]", ",", "self", ".", "max_detections", ")", ",", "\n", "(", "input_shape", "[", "1", "]", "[", "0", "]", ",", "self", ".", "max_detections", ")", ",", "\n", "]", "+", "[", "\n", "tuple", "(", "[", "input_shape", "[", "i", "]", "[", "0", "]", ",", "self", ".", "max_detections", "]", "+", "list", "(", "input_shape", "[", "i", "]", "[", "2", ":", "]", ")", ")", "for", "i", "in", "range", "(", "2", ",", "len", "(", "input_shape", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.FilterDetections.compute_mask": [[202, 206], ["len"], "methods", ["None"], ["", "def", "compute_mask", "(", "self", ",", "inputs", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" This is required in Keras when there is more than 1 output.\n        \"\"\"", "\n", "return", "(", "len", "(", "inputs", ")", "+", "1", ")", "*", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.FilterDetections.get_config": [[207, 224], ["super().get_config", "super().get_config.update"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "\"\"\" Gets the configuration of this layer.\n\n        Returns\n            Dictionary containing the parameters of this layer.\n        \"\"\"", "\n", "config", "=", "super", "(", "FilterDetections", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "'nms'", ":", "self", ".", "nms", ",", "\n", "'class_specific_filter'", ":", "self", ".", "class_specific_filter", ",", "\n", "'nms_threshold'", ":", "self", ".", "nms_threshold", ",", "\n", "'score_threshold'", ":", "self", ".", "score_threshold", ",", "\n", "'max_detections'", ":", "self", ".", "max_detections", ",", "\n", "'parallel_iterations'", ":", "self", ".", "parallel_iterations", ",", "\n", "}", ")", "\n", "\n", "return", "config", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.layers.filter_detections.filter_detections": [[21, 113], ["backend.gather_nd", "backend.top_k", "keras.backend.gather", "keras.backend.gather", "keras.backend.gather", "keras.backend.maximum", "backend.pad", "backend.pad", "backend.pad", "keras.backend.cast", "backend.pad.set_shape", "keras.backend.max.set_shape", "keras.backend.argmax.set_shape", "zip", "backend.where", "backend.gather_nd", "keras.backend.stack", "range", "keras.backend.concatenate", "keras.backend.max", "keras.backend.argmax", "filter_detections.filter_detections._filter_detections"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.top_k", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.pad", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.pad", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.pad", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["def", "filter_detections", "(", "\n", "boxes", ",", "\n", "classification", ",", "\n", "other", "=", "[", "]", ",", "\n", "class_specific_filter", "=", "True", ",", "\n", "nms", "=", "True", ",", "\n", "score_threshold", "=", "0.05", ",", "\n", "max_detections", "=", "300", ",", "\n", "nms_threshold", "=", "0.5", "\n", ")", ":", "\n", "    ", "\"\"\" Filter detections using the boxes and classification values.\n\n    Args\n        boxes                 : Tensor of shape (num_boxes, 4) containing the boxes in (x1, y1, x2, y2) format.\n        classification        : Tensor of shape (num_boxes, num_classes) containing the classification scores.\n        other                 : List of tensors of shape (num_boxes, ...) to filter along with the boxes and classification scores.\n        class_specific_filter : Whether to perform filtering per class, or take the best scoring class and filter those.\n        nms                   : Flag to enable/disable non maximum suppression.\n        score_threshold       : Threshold used to prefilter the boxes with.\n        max_detections        : Maximum number of detections to keep.\n        nms_threshold         : Threshold for the IoU value to determine when a box should be suppressed.\n\n    Returns\n        A list of [boxes, scores, labels, other[0], other[1], ...].\n        boxes is shaped (max_detections, 4) and contains the (x1, y1, x2, y2) of the non-suppressed boxes.\n        scores is shaped (max_detections,) and contains the scores of the predicted class.\n        labels is shaped (max_detections,) and contains the predicted label.\n        other[i] is shaped (max_detections, ...) and contains the filtered other[i] data.\n        In case there are less than max_detections detections, the tensors are padded with -1's.\n    \"\"\"", "\n", "def", "_filter_detections", "(", "scores", ",", "labels", ")", ":", "\n", "# threshold based on score", "\n", "        ", "indices", "=", "backend", ".", "where", "(", "keras", ".", "backend", ".", "greater", "(", "scores", ",", "score_threshold", ")", ")", "\n", "\n", "if", "nms", ":", "\n", "            ", "filtered_boxes", "=", "backend", ".", "gather_nd", "(", "boxes", ",", "indices", ")", "\n", "filtered_scores", "=", "keras", ".", "backend", ".", "gather", "(", "scores", ",", "indices", ")", "[", ":", ",", "0", "]", "\n", "\n", "# perform NMS", "\n", "nms_indices", "=", "backend", ".", "non_max_suppression", "(", "filtered_boxes", ",", "filtered_scores", ",", "max_output_size", "=", "max_detections", ",", "iou_threshold", "=", "nms_threshold", ")", "\n", "\n", "# filter indices based on NMS", "\n", "indices", "=", "keras", ".", "backend", ".", "gather", "(", "indices", ",", "nms_indices", ")", "\n", "\n", "# add indices to list of all indices", "\n", "", "labels", "=", "backend", ".", "gather_nd", "(", "labels", ",", "indices", ")", "\n", "indices", "=", "keras", ".", "backend", ".", "stack", "(", "[", "indices", "[", ":", ",", "0", "]", ",", "labels", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "indices", "\n", "\n", "", "if", "class_specific_filter", ":", "\n", "        ", "all_indices", "=", "[", "]", "\n", "# perform per class filtering", "\n", "for", "c", "in", "range", "(", "int", "(", "classification", ".", "shape", "[", "1", "]", ")", ")", ":", "\n", "            ", "scores", "=", "classification", "[", ":", ",", "c", "]", "\n", "labels", "=", "c", "*", "backend", ".", "ones", "(", "(", "keras", ".", "backend", ".", "shape", "(", "scores", ")", "[", "0", "]", ",", ")", ",", "dtype", "=", "'int64'", ")", "\n", "all_indices", ".", "append", "(", "_filter_detections", "(", "scores", ",", "labels", ")", ")", "\n", "\n", "# concatenate indices to single tensor", "\n", "", "indices", "=", "keras", ".", "backend", ".", "concatenate", "(", "all_indices", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "scores", "=", "keras", ".", "backend", ".", "max", "(", "classification", ",", "axis", "=", "1", ")", "\n", "labels", "=", "keras", ".", "backend", ".", "argmax", "(", "classification", ",", "axis", "=", "1", ")", "\n", "indices", "=", "_filter_detections", "(", "scores", ",", "labels", ")", "\n", "\n", "# select top k", "\n", "", "scores", "=", "backend", ".", "gather_nd", "(", "classification", ",", "indices", ")", "\n", "labels", "=", "indices", "[", ":", ",", "1", "]", "\n", "scores", ",", "top_indices", "=", "backend", ".", "top_k", "(", "scores", ",", "k", "=", "keras", ".", "backend", ".", "minimum", "(", "max_detections", ",", "keras", ".", "backend", ".", "shape", "(", "scores", ")", "[", "0", "]", ")", ")", "\n", "\n", "# filter input using the final set of indices", "\n", "indices", "=", "keras", ".", "backend", ".", "gather", "(", "indices", "[", ":", ",", "0", "]", ",", "top_indices", ")", "\n", "boxes", "=", "keras", ".", "backend", ".", "gather", "(", "boxes", ",", "indices", ")", "\n", "labels", "=", "keras", ".", "backend", ".", "gather", "(", "labels", ",", "top_indices", ")", "\n", "other_", "=", "[", "keras", ".", "backend", ".", "gather", "(", "o", ",", "indices", ")", "for", "o", "in", "other", "]", "\n", "\n", "# zero pad the outputs", "\n", "pad_size", "=", "keras", ".", "backend", ".", "maximum", "(", "0", ",", "max_detections", "-", "keras", ".", "backend", ".", "shape", "(", "scores", ")", "[", "0", "]", ")", "\n", "boxes", "=", "backend", ".", "pad", "(", "boxes", ",", "[", "[", "0", ",", "pad_size", "]", ",", "[", "0", ",", "0", "]", "]", ",", "constant_values", "=", "-", "1", ")", "\n", "scores", "=", "backend", ".", "pad", "(", "scores", ",", "[", "[", "0", ",", "pad_size", "]", "]", ",", "constant_values", "=", "-", "1", ")", "\n", "labels", "=", "backend", ".", "pad", "(", "labels", ",", "[", "[", "0", ",", "pad_size", "]", "]", ",", "constant_values", "=", "-", "1", ")", "\n", "labels", "=", "keras", ".", "backend", ".", "cast", "(", "labels", ",", "'int32'", ")", "\n", "other_", "=", "[", "backend", ".", "pad", "(", "o", ",", "[", "[", "0", ",", "pad_size", "]", "]", "+", "[", "[", "0", ",", "0", "]", "for", "_", "in", "range", "(", "1", ",", "len", "(", "o", ".", "shape", ")", ")", "]", ",", "constant_values", "=", "-", "1", ")", "for", "o", "in", "other_", "]", "\n", "\n", "# set shapes, since we know what they are", "\n", "boxes", ".", "set_shape", "(", "[", "max_detections", ",", "4", "]", ")", "\n", "scores", ".", "set_shape", "(", "[", "max_detections", "]", ")", "\n", "labels", ".", "set_shape", "(", "[", "max_detections", "]", ")", "\n", "for", "o", ",", "s", "in", "zip", "(", "other_", ",", "[", "list", "(", "keras", ".", "backend", ".", "int_shape", "(", "o", ")", ")", "for", "o", "in", "other", "]", ")", ":", "\n", "        ", "o", ".", "set_shape", "(", "[", "max_detections", "]", "+", "s", "[", "1", ":", "]", ")", "\n", "\n", "", "return", "[", "boxes", ",", "scores", ",", "labels", "]", "+", "other_", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.common.bbox_transform_inv": [[21, 53], ["keras.backend.stack"], "function", ["None"], ["def", "bbox_transform_inv", "(", "boxes", ",", "deltas", ",", "mean", "=", "None", ",", "std", "=", "None", ")", ":", "\n", "    ", "\"\"\" Applies deltas (usually regression results) to boxes (usually anchors).\n\n    Before applying the deltas to the boxes, the normalization that was previously applied (in the generator) has to be removed.\n    The mean and std are the mean and std as applied in the generator. They are unnormalized in this function and then applied to the boxes.\n\n    Args\n        boxes : np.array of shape (B, N, 4), where B is the batch size, N the number of boxes and 4 values for (x1, y1, x2, y2).\n        deltas: np.array of same shape as boxes. These deltas (d_x1, d_y1, d_x2, d_y2) are a factor of the width/height.\n        mean  : The mean value used when computing deltas (defaults to [0, 0, 0, 0]).\n        std   : The standard deviation used when computing deltas (defaults to [0.2, 0.2, 0.2, 0.2]).\n\n    Returns\n        A np.array of the same shape as boxes, but with deltas applied to each box.\n        The mean and std are used during training to normalize the regression values (networks love normalization).\n    \"\"\"", "\n", "if", "mean", "is", "None", ":", "\n", "        ", "mean", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "", "if", "std", "is", "None", ":", "\n", "        ", "std", "=", "[", "0.2", ",", "0.2", ",", "0.2", ",", "0.2", "]", "\n", "\n", "", "width", "=", "boxes", "[", ":", ",", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", ":", ",", "0", "]", "\n", "height", "=", "boxes", "[", ":", ",", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", ":", ",", "1", "]", "\n", "\n", "x1", "=", "boxes", "[", ":", ",", ":", ",", "0", "]", "+", "(", "deltas", "[", ":", ",", ":", ",", "0", "]", "*", "std", "[", "0", "]", "+", "mean", "[", "0", "]", ")", "*", "width", "\n", "y1", "=", "boxes", "[", ":", ",", ":", ",", "1", "]", "+", "(", "deltas", "[", ":", ",", ":", ",", "1", "]", "*", "std", "[", "1", "]", "+", "mean", "[", "1", "]", ")", "*", "height", "\n", "x2", "=", "boxes", "[", ":", ",", ":", ",", "2", "]", "+", "(", "deltas", "[", ":", ",", ":", ",", "2", "]", "*", "std", "[", "2", "]", "+", "mean", "[", "2", "]", ")", "*", "width", "\n", "y2", "=", "boxes", "[", ":", ",", ":", ",", "3", "]", "+", "(", "deltas", "[", ":", ",", ":", ",", "3", "]", "*", "std", "[", "3", "]", "+", "mean", "[", "3", "]", ")", "*", "height", "\n", "\n", "pred_boxes", "=", "keras", ".", "backend", ".", "stack", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", "]", ",", "axis", "=", "2", ")", "\n", "\n", "return", "pred_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.common.shift": [[55, 86], ["dynamic.meshgrid", "keras.backend.reshape", "keras.backend.reshape", "keras.backend.stack", "keras.backend.transpose", "keras.backend.reshape", "keras.backend.shape", "keras.backend.shape", "keras.backend.reshape", "keras.backend.cast", "keras.backend.arange", "keras.backend.constant", "keras.backend.arange", "keras.backend.constant", "keras.backend.reshape", "keras.backend.floatx", "keras.backend.floatx", "keras.backend.floatx", "keras.backend.floatx", "keras.backend.floatx"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.meshgrid", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose"], ["", "def", "shift", "(", "shape", ",", "stride", ",", "anchors", ")", ":", "\n", "    ", "\"\"\" Produce shifted anchors based on shape of the map and stride size.\n\n    Args\n        shape  : Shape to shift the anchors over.\n        stride : Stride to shift the anchors with over the shape.\n        anchors: The anchors to apply at each location.\n    \"\"\"", "\n", "shift_x", "=", "(", "keras", ".", "backend", ".", "arange", "(", "0", ",", "shape", "[", "1", "]", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "+", "keras", ".", "backend", ".", "constant", "(", "0.5", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", ")", "*", "stride", "\n", "shift_y", "=", "(", "keras", ".", "backend", ".", "arange", "(", "0", ",", "shape", "[", "0", "]", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "+", "keras", ".", "backend", ".", "constant", "(", "0.5", ",", "dtype", "=", "keras", ".", "backend", ".", "floatx", "(", ")", ")", ")", "*", "stride", "\n", "\n", "shift_x", ",", "shift_y", "=", "meshgrid", "(", "shift_x", ",", "shift_y", ")", "\n", "shift_x", "=", "keras", ".", "backend", ".", "reshape", "(", "shift_x", ",", "[", "-", "1", "]", ")", "\n", "shift_y", "=", "keras", ".", "backend", ".", "reshape", "(", "shift_y", ",", "[", "-", "1", "]", ")", "\n", "\n", "shifts", "=", "keras", ".", "backend", ".", "stack", "(", "[", "\n", "shift_x", ",", "\n", "shift_y", ",", "\n", "shift_x", ",", "\n", "shift_y", "\n", "]", ",", "axis", "=", "0", ")", "\n", "\n", "shifts", "=", "keras", ".", "backend", ".", "transpose", "(", "shifts", ")", "\n", "number_of_anchors", "=", "keras", ".", "backend", ".", "shape", "(", "anchors", ")", "[", "0", "]", "\n", "\n", "k", "=", "keras", ".", "backend", ".", "shape", "(", "shifts", ")", "[", "0", "]", "# number of base points = feat_h * feat_w", "\n", "\n", "shifted_anchors", "=", "keras", ".", "backend", ".", "reshape", "(", "anchors", ",", "[", "1", ",", "number_of_anchors", ",", "4", "]", ")", "+", "keras", ".", "backend", ".", "cast", "(", "keras", ".", "backend", ".", "reshape", "(", "shifts", ",", "[", "k", ",", "1", ",", "4", "]", ")", ",", "keras", ".", "backend", ".", "floatx", "(", ")", ")", "\n", "shifted_anchors", "=", "keras", ".", "backend", ".", "reshape", "(", "shifted_anchors", ",", "[", "k", "*", "number_of_anchors", ",", "4", "]", ")", "\n", "\n", "return", "shifted_anchors", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones": [[20, 24], ["tensorflow.ones"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.ones"], ["def", "ones", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/ones .\n    \"\"\"", "\n", "return", "tensorflow", ".", "ones", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose": [[26, 30], ["tensorflow.transpose"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.transpose"], ["", "def", "transpose", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/transpose .\n    \"\"\"", "\n", "return", "tensorflow", ".", "transpose", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.map_fn": [[32, 36], ["tensorflow.map_fn"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.map_fn"], ["", "def", "map_fn", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/map_fn .\n    \"\"\"", "\n", "return", "tensorflow", ".", "map_fn", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.pad": [[38, 42], ["tensorflow.pad"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.pad"], ["", "def", "pad", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/pad .\n    \"\"\"", "\n", "return", "tensorflow", ".", "pad", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.top_k": [[44, 48], ["tensorflow.nn.top_k"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.top_k"], ["", "def", "top_k", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/nn/top_k .\n    \"\"\"", "\n", "return", "tensorflow", ".", "nn", ".", "top_k", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value": [[50, 54], ["tensorflow.clip_by_value"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.clip_by_value"], ["", "def", "clip_by_value", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/clip_by_value .\n    \"\"\"", "\n", "return", "tensorflow", ".", "clip_by_value", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.resize_images": [[56, 69], ["tensorflow.image.resize_images"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.resize_images"], ["", "def", "resize_images", "(", "images", ",", "size", ",", "method", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/image/resize_images .\n\n    Args\n        method: The method used for interpolation. One of ('bilinear', 'nearest', 'bicubic', 'area').\n    \"\"\"", "\n", "methods", "=", "{", "\n", "'bilinear'", ":", "tensorflow", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "\n", "'nearest'", ":", "tensorflow", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ",", "\n", "'bicubic'", ":", "tensorflow", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ",", "\n", "'area'", ":", "tensorflow", ".", "image", ".", "ResizeMethod", ".", "AREA", ",", "\n", "}", "\n", "return", "tensorflow", ".", "image", ".", "resize_images", "(", "images", ",", "size", ",", "methods", "[", "method", "]", ",", "align_corners", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.non_max_suppression": [[71, 75], ["tensorflow.image.non_max_suppression"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.non_max_suppression"], ["", "def", "non_max_suppression", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/image/non_max_suppression .\n    \"\"\"", "\n", "return", "tensorflow", ".", "image", ".", "non_max_suppression", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range": [[76, 80], ["tensorflow.range"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "range", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/range .\n    \"\"\"", "\n", "return", "tensorflow", ".", "range", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.scatter_nd": [[82, 86], ["tensorflow.scatter_nd"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.scatter_nd"], ["", "def", "scatter_nd", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/scatter_nd .\n    \"\"\"", "\n", "return", "tensorflow", ".", "scatter_nd", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd": [[88, 92], ["tensorflow.gather_nd"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.gather_nd"], ["", "def", "gather_nd", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/gather_nd .\n    \"\"\"", "\n", "return", "tensorflow", ".", "gather_nd", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.meshgrid": [[94, 98], ["tensorflow.meshgrid"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.meshgrid"], ["", "def", "meshgrid", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/meshgrid .\n    \"\"\"", "\n", "return", "tensorflow", ".", "meshgrid", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where": [[100, 104], ["tensorflow.where"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.where"], ["", "def", "where", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" See https://www.tensorflow.org/versions/master/api_docs/python/tf/where .\n    \"\"\"", "\n", "return", "tensorflow", ".", "where", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.custom": [[17, 20], ["vggmax.vggmax"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.vggmax"], ["@", "keras_modules_injection", "\n", "def", "custom", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "vggmax", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.min_max_pool2d": [[30, 34], ["keras.pool2d", "vggmax.min_pool2d", "keras.concatenate"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.min_pool2d"], ["def", "min_max_pool2d", "(", "x", ")", ":", "\n", "    ", "max_x", "=", "K", ".", "pool2d", "(", "x", ",", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "min_x", "=", "min_pool2d", "(", "x", ")", "\n", "return", "K", ".", "concatenate", "(", "[", "max_x", ",", "min_x", "]", ",", "axis", "=", "3", ")", "# concatenate on channel", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.min_max_pool2d_output_shape": [[35, 41], ["list", "int", "int", "tuple"], "function", ["None"], ["", "def", "min_max_pool2d_output_shape", "(", "input_shape", ")", ":", "\n", "    ", "shape", "=", "list", "(", "input_shape", ")", "\n", "shape", "[", "1", "]", "=", "int", "(", "shape", "[", "1", "]", "/", "2", ")", "\n", "shape", "[", "2", "]", "=", "int", "(", "shape", "[", "2", "]", "/", "2", ")", "\n", "shape", "[", "3", "]", "*=", "2", "\n", "return", "tuple", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.min_pool2d": [[42, 58], ["keras.max", "keras.cast", "keras.cast", "keras.equal", "keras.layers.MaxPooling2D", "keras.layers.MaxPooling2D", "keras.equal", "keras.floatx", "keras.floatx"], "function", ["None"], ["", "def", "min_pool2d", "(", "x", ",", "padding", "=", "'valid'", ")", ":", "\n", "    ", "max_val", "=", "K", ".", "max", "(", "x", ")", "+", "1", "# we gonna replace all zeros with that value", "\n", "if", "x", ".", "_keras_shape", "[", "2", "]", "<=", "20", ":", "\n", "        ", "padding", "=", "'same'", "\n", "# replace all 0s with very high numbers", "\n", "", "is_zero", "=", "max_val", "*", "K", ".", "cast", "(", "K", ".", "equal", "(", "x", ",", "0", ")", ",", "dtype", "=", "K", ".", "floatx", "(", ")", ")", "\n", "x", "=", "is_zero", "+", "x", "\n", "\n", "# execute pooling with 0s being replaced by a high number", "\n", "min_x", "=", "-", "keras", ".", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "padding", ")", "(", "-", "x", ")", "\n", "\n", "# depending on the value we either substract the zero replacement or not", "\n", "is_result_zero", "=", "max_val", "*", "K", ".", "cast", "(", "K", ".", "equal", "(", "min_x", ",", "max_val", ")", ",", "dtype", "=", "K", ".", "floatx", "(", ")", ")", "\n", "min_x", "=", "min_x", "-", "is_result_zero", "\n", "\n", "return", "min_x", "# concatenate on channel", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.min_pool2d_output_shape": [[59, 64], ["list", "int", "int", "tuple"], "function", ["None"], ["", "def", "min_pool2d_output_shape", "(", "input_shape", ")", ":", "\n", "    ", "shape", "=", "list", "(", "input_shape", ")", "\n", "shape", "[", "1", "]", "=", "int", "(", "shape", "[", "1", "]", "/", "2", ")", "\n", "shape", "[", "2", "]", "=", "int", "(", "shape", "[", "2", "]", "/", "2", ")", "\n", "return", "tuple", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.vggmax": [[65, 385], ["keras_applications.get_submodules_from_kwargs", "keras_applications.imagenet_utils._obtain_input_shape", "models.Model", "ValueError", "ValueError", "layers.Input", "len", "len", "layers.Conv2D", "layers.Conv2D", "len", "layers.Conv2D", "layers.Conv2D", "len", "layers.Conv2D", "layers.Conv2D", "layers.Conv2D", "len", "layers.Conv2D", "layers.Conv2D", "layers.Conv2D", "len", "layers.Conv2D", "layers.Conv2D", "layers.Conv2D", "layers.MaxPooling2D", "len", "keras_utils.get_source_inputs", "models.Model.load_weights", "os.path.exists", "backend.image_data_format", "backend.is_keras_tensor", "layers.Input", "keras.layers.Lambda", "keras.layers.Lambda", "int", "int", "keras.layers.Lambda", "layers.MaxPooling2D", "int", "int", "keras.layers.Lambda", "layers.MaxPooling2D", "int", "int", "int", "keras.layers.Lambda", "layers.MaxPooling2D", "int", "int", "int", "keras.layers.Lambda", "layers.MaxPooling2D", "int", "int", "int", "layers.Flatten", "layers.Dense", "layers.Dense", "layers.Dense", "keras_utils.get_file", "keras_utils.get_file", "backend.backend", "keras_utils.convert_all_kernels_in_model", "models.Model.load_weights", "keras.layers.Concatenate", "keras.layers.Lambda", "keras.layers.Concatenate", "keras.layers.Lambda", "keras.layers.Concatenate", "keras.layers.Lambda", "keras.layers.Concatenate", "keras.layers.Lambda", "keras.layers.Concatenate", "keras.layers.Lambda", "keras.layers.Concatenate", "layers.GlobalAveragePooling2D", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Lambda", "layers.GlobalMaxPooling2D", "layers.Conv2D", "layers.MaxPooling2D", "layers.Conv2D", "layers.MaxPooling2D", "layers.Conv2D", "layers.MaxPooling2D", "layers.Conv2D", "layers.MaxPooling2D", "layers.Conv2D", "layers.MaxPooling2D", "int", "int", "int", "int", "int"], "function", ["None"], ["", "def", "vggmax", "(", "include_top", "=", "True", ",", "\n", "weights", "=", "'imagenet'", ",", "\n", "input_tensor", "=", "None", ",", "\n", "input_shape", "=", "None", ",", "\n", "pooling", "=", "None", ",", "\n", "classes", "=", "1000", ",", "\n", "cfg", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Instantiates the VGG16 architecture.\n\n    Optionally loads weights pre-trained on ImageNet.\n    Note that the data format convention used by the model is\n    the one specified in your Keras config at `~/.keras/keras.json`.\n\n    # Arguments\n        include_top: whether to include the 3 fully-connected\n            layers at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet),\n              or the path to the weights file to be loaded.\n        input_tensor: optional Keras tensor\n            (i.e. output of `layers.Input()`)\n            to use as image input for the model.\n        input_shape: optional shape tuple, only to be specified\n            if `include_top` is False (otherwise the input shape\n            has to be `(224, 224, 3)`\n            (with `channels_last` data format)\n            or `(3, 224, 224)` (with `channels_first` data format).\n            It should have exactly 3 input channels,\n            and width and height should be no smaller than 32.\n            E.g. `(200, 200, 3)` would be one valid value.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model will be\n                the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a 2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        fusion_blocks: list of indexes giving the blocks where radar and image is \n            concatenated. Input Layer is targeted by 0.\n    # Returns\n        A Keras model instance.\n\n    # Raises\n        ValueError: in case of invalid argument for `weights`,\n            or invalid input shape.\n    \"\"\"", "\n", "backend", ",", "layers", ",", "models", ",", "keras_utils", "=", "get_submodules_from_kwargs", "(", "kwargs", ")", "\n", "\n", "if", "not", "(", "weights", "in", "{", "'imagenet'", ",", "None", "}", "or", "os", ".", "path", ".", "exists", "(", "weights", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The `weights` argument should be either '", "\n", "'`None` (random initialization), `imagenet` '", "\n", "'(pre-training on ImageNet), '", "\n", "'or the path to the weights file to be loaded.'", ")", "\n", "\n", "", "if", "weights", "==", "'imagenet'", "and", "include_top", "and", "classes", "!=", "1000", ":", "\n", "        ", "raise", "ValueError", "(", "'If using `weights` as `\"imagenet\"` with `include_top`'", "\n", "' as true, `classes` should be 1000'", ")", "\n", "# Determine proper input shape", "\n", "", "input_shape", "=", "_obtain_input_shape", "(", "input_shape", ",", "\n", "default_size", "=", "224", ",", "\n", "min_size", "=", "32", ",", "\n", "data_format", "=", "backend", ".", "image_data_format", "(", ")", ",", "\n", "require_flatten", "=", "include_top", ",", "\n", "weights", "=", "weights", ")", "\n", "\n", "if", "input_tensor", "is", "None", ":", "\n", "        ", "all_input", "=", "layers", ".", "Input", "(", "shape", "=", "input_shape", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "backend", ".", "is_keras_tensor", "(", "input_tensor", ")", ":", "\n", "            ", "all_input", "=", "layers", ".", "Input", "(", "tensor", "=", "input_tensor", ",", "shape", "=", "input_shape", ")", "\n", "", "else", ":", "\n", "            ", "all_input", "=", "input_tensor", "\n", "\n", "## Read config variables", "\n", "", "", "fusion_blocks", "=", "cfg", ".", "fusion_blocks", "\n", "\n", "\n", "## Model", "\n", "\n", "# Seperate input", "\n", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "image_input", "=", "Lambda", "(", "lambda", "x", ":", "x", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", ",", "name", "=", "'image_channels'", ")", "(", "all_input", ")", "\n", "radar_input", "=", "Lambda", "(", "lambda", "x", ":", "x", "[", ":", ",", ":", ",", ":", ",", "3", ":", "]", ",", "name", "=", "'radar_channels'", ")", "(", "all_input", ")", "\n", "\n", "# Bock 0 Fusion", "\n", "", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "if", "0", "in", "fusion_blocks", ":", "\n", "            ", "x", "=", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'concat_0'", ")", "(", "[", "image_input", ",", "radar_input", "]", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "image_input", "\n", "", "", "else", ":", "\n", "        ", "x", "=", "all_input", "\n", "\n", "# Block 1 - Image", "\n", "", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block1_conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block1_conv2'", ")", "(", "x", ")", "\n", "if", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "        ", "x", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'block1_pool'", ")", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block1_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 1 - Radar", "\n", "", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "if", "cfg", ".", "pooling", "==", "'min'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block1_pool'", ")", "(", "radar_input", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'rad_block1_pool'", ")", "(", "radar_input", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'conv'", ":", "\n", "            ", "y", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block1_pool'", ")", "(", "radar_input", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block1_pool'", ")", "(", "radar_input", ")", "\n", "\n", "## Concatenate Block 1 Radar to image", "\n", "", "if", "1", "in", "fusion_blocks", ":", "\n", "            ", "x", "=", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'concat_1'", ")", "(", "[", "x", ",", "y", "]", ")", "\n", "\n", "\n", "# Block 2", "\n", "", "", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "128", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block2_conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "128", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block2_conv2'", ")", "(", "x", ")", "\n", "if", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "        ", "x", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'block2_pool'", ")", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block2_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 2 - Radar", "\n", "", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "if", "cfg", ".", "pooling", "==", "'min'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block2_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'rad_block2_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'conv'", ":", "\n", "            ", "y", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block2_pool'", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block2_pool'", ")", "(", "y", ")", "\n", "\n", "## Concatenate Block 2 Radar to image", "\n", "", "if", "2", "in", "fusion_blocks", ":", "\n", "            ", "x", "=", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'concat_2'", ")", "(", "[", "x", ",", "y", "]", ")", "\n", "\n", "# Block 3", "\n", "", "", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "256", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block3_conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "256", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block3_conv2'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "256", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block3_conv3'", ")", "(", "x", ")", "\n", "if", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "        ", "x", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'block3_pool'", ")", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block3_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 3 - Radar", "\n", "", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "if", "cfg", ".", "pooling", "==", "'min'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block3_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'rad_block3_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'conv'", ":", "\n", "            ", "y", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block3_pool'", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block3_pool'", ")", "(", "y", ")", "\n", "\n", "## Concatenate Block 3 Radar to image", "\n", "", "if", "3", "in", "fusion_blocks", ":", "\n", "            ", "x", "=", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'concat_3'", ")", "(", "[", "x", ",", "y", "]", ")", "\n", "\n", "\n", "# Block 4", "\n", "", "", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "512", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block4_conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "512", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block4_conv2'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "512", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block4_conv3'", ")", "(", "x", ")", "\n", "if", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "        ", "x", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'block4_pool'", ")", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block4_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 4 - Radar", "\n", "", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "if", "cfg", ".", "pooling", "==", "'min'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block4_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'rad_block4_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'conv'", ":", "\n", "            ", "y", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "2", ",", "2", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'valid'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block4_pool'", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block4_pool'", ")", "(", "y", ")", "\n", "\n", "## Concatenate Block 4 Radar to image", "\n", "", "if", "4", "in", "fusion_blocks", ":", "\n", "            ", "x", "=", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'concat_4'", ")", "(", "[", "x", ",", "y", "]", ")", "\n", "\n", "# Block 5", "\n", "", "", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "512", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block5_conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "512", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block5_conv2'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "int", "(", "512", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "name", "=", "'block5_conv3'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'block5_pool'", ")", "(", "x", ")", "\n", "\n", "# Block 5 - Radar", "\n", "if", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "if", "cfg", ".", "pooling", "==", "'min'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block5_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'maxmin'", ":", "\n", "            ", "y", "=", "Lambda", "(", "min_max_pool2d", ",", "name", "=", "'rad_block5_pool'", ")", "(", "y", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'conv'", ":", "\n", "            ", "y", "=", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "2", ",", "2", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'valid'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block5_pool'", ")", "(", "y", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block5_pool'", ")", "(", "y", ")", "\n", "\n", "## Concatenate Block 5 Radar to image", "\n", "", "if", "5", "in", "fusion_blocks", ":", "\n", "            ", "x", "=", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'concat_5'", ")", "(", "[", "x", ",", "y", "]", ")", "\n", "\n", "\n", "", "", "if", "include_top", ":", "\n", "# Classification block", "\n", "        ", "x", "=", "layers", ".", "Flatten", "(", "name", "=", "'flatten'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Dense", "(", "4096", ",", "activation", "=", "'relu'", ",", "name", "=", "'fc1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Dense", "(", "4096", ",", "activation", "=", "'relu'", ",", "name", "=", "'fc2'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Dense", "(", "classes", ",", "activation", "=", "'softmax'", ",", "name", "=", "'predictions'", ")", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "if", "pooling", "==", "'avg'", ":", "\n", "            ", "x", "=", "layers", ".", "GlobalAveragePooling2D", "(", ")", "(", "x", ")", "\n", "", "elif", "pooling", "==", "'max'", ":", "\n", "            ", "x", "=", "layers", ".", "GlobalMaxPooling2D", "(", ")", "(", "x", ")", "\n", "\n", "# Ensure that the model takes into account", "\n", "# any potential predecessors of `input_tensor`.", "\n", "", "", "if", "input_tensor", "is", "not", "None", ":", "\n", "        ", "inputs", "=", "keras_utils", ".", "get_source_inputs", "(", "input_tensor", ")", "\n", "", "else", ":", "\n", "        ", "inputs", "=", "all_input", "\n", "# Create model.", "\n", "", "model", "=", "models", ".", "Model", "(", "inputs", ",", "x", ",", "name", "=", "'vgg16'", ")", "\n", "\n", "# Load weights.", "\n", "if", "weights", "==", "'imagenet'", ":", "\n", "        ", "if", "include_top", ":", "\n", "            ", "weights_path", "=", "keras_utils", ".", "get_file", "(", "\n", "'vgg16_weights_tf_dim_ordering_tf_kernels.h5'", ",", "\n", "WEIGHTS_PATH", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "'64373286793e3c8b2b4e3219cbf3544b'", ")", "\n", "", "else", ":", "\n", "            ", "weights_path", "=", "keras_utils", ".", "get_file", "(", "\n", "'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'", ",", "\n", "WEIGHTS_PATH_NO_TOP", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "'6d6bbae143d832006294945121d1f1fc'", ")", "\n", "", "model", ".", "load_weights", "(", "weights_path", ")", "\n", "if", "backend", ".", "backend", "(", ")", "==", "'theano'", ":", "\n", "            ", "keras_utils", ".", "convert_all_kernels_in_model", "(", "model", ")", "\n", "", "", "elif", "weights", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_weights", "(", "weights", ")", "\n", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.mobilenet.MobileNetBackbone.retinanet": [[32, 36], ["mobilenet.mobilenet_retinanet"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.mobilenet.mobilenet_retinanet"], ["def", "retinanet", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Returns a retinanet model using the correct backbone.\n        \"\"\"", "\n", "return", "mobilenet_retinanet", "(", "*", "args", ",", "backbone", "=", "self", ".", "backbone", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.mobilenet.MobileNetBackbone.download_imagenet": [[37, 65], ["float", "int", "keras.utils.get_file", "[].replace", "keras.backend.image_data_format", "ValueError", "keras.applications.mobilenet.MobileNetBackbone.backbone.split", "keras.applications.mobilenet.MobileNetBackbone.backbone.split"], "methods", ["None"], ["", "def", "download_imagenet", "(", "self", ")", ":", "\n", "        ", "\"\"\" Download pre-trained weights for the specified backbone name.\n        This name is in the format mobilenet{rows}_{alpha} where rows is the\n        imagenet shape dimension and 'alpha' controls the width of the network.\n        For more info check the explanation from the keras mobilenet script itself.\n        \"\"\"", "\n", "\n", "alpha", "=", "float", "(", "self", ".", "backbone", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "rows", "=", "int", "(", "self", ".", "backbone", ".", "split", "(", "'_'", ")", "[", "0", "]", ".", "replace", "(", "'mobilenet'", ",", "''", ")", ")", "\n", "\n", "# load weights", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "raise", "ValueError", "(", "'Weights for \"channels_last\" format '", "\n", "'are not available.'", ")", "\n", "", "if", "alpha", "==", "1.0", ":", "\n", "            ", "alpha_text", "=", "'1_0'", "\n", "", "elif", "alpha", "==", "0.75", ":", "\n", "            ", "alpha_text", "=", "'7_5'", "\n", "", "elif", "alpha", "==", "0.50", ":", "\n", "            ", "alpha_text", "=", "'5_0'", "\n", "", "else", ":", "\n", "            ", "alpha_text", "=", "'2_5'", "\n", "\n", "", "model_name", "=", "'mobilenet_{}_{}_tf_no_top.h5'", ".", "format", "(", "alpha_text", ",", "rows", ")", "\n", "weights_url", "=", "mobilenet", ".", "mobilenet", ".", "BASE_WEIGHT_PATH", "+", "model_name", "\n", "weights_path", "=", "get_file", "(", "model_name", ",", "weights_url", ",", "cache_subdir", "=", "'models'", ")", "\n", "\n", "return", "weights_path", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.mobilenet.MobileNetBackbone.validate": [[66, 73], ["keras.applications.mobilenet.MobileNetBackbone.backbone.split", "ValueError"], "methods", ["None"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks whether the backbone string is correct.\n        \"\"\"", "\n", "backbone", "=", "self", ".", "backbone", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "\n", "if", "backbone", "not", "in", "MobileNetBackbone", ".", "allowed_backbones", ":", "\n", "            ", "raise", "ValueError", "(", "'Backbone (\\'{}\\') not in allowed backbones ({}).'", ".", "format", "(", "backbone", ",", "MobileNetBackbone", ".", "allowed_backbones", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.mobilenet.MobileNetBackbone.preprocess_image": [[74, 78], ["crfnet.utils.image.preprocess_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image"], ["", "", "def", "preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Takes as input an image and prepares it for being passed through the network.\n        \"\"\"", "\n", "return", "preprocess_image", "(", "inputs", ",", "mode", "=", "'tf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.mobilenet.mobilenet_retinanet": [[80, 112], ["float", "keras.applications.mobilenet.MobileNet", "keras.models.Model", "retinanet.retinanet", "keras.layers.Input", "isinstance", "modifier", "modifier.split", "keras.layers.Input", "modifier.get_layer"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet"], ["", "", "def", "mobilenet_retinanet", "(", "num_classes", ",", "backbone", "=", "'mobilenet224_1.0'", ",", "inputs", "=", "None", ",", "modifier", "=", "None", ",", "cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Constructs a retinanet model using a mobilenet backbone.\n\n    Args\n        num_classes: Number of classes to predict.\n        backbone: Which backbone to use (one of ('mobilenet128', 'mobilenet160', 'mobilenet192', 'mobilenet224')).\n        inputs: The inputs to the network (defaults to a Tensor of shape (None, None, 3)).\n        modifier: A function handler which can modify the backbone before using it in retinanet (this can be used to freeze backbone layers for example).\n\n    Returns\n        RetinaNet model with a MobileNet backbone.\n    \"\"\"", "\n", "alpha", "=", "float", "(", "backbone", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "\n", "# choose default input", "\n", "if", "inputs", "is", "None", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "(", "None", ",", "None", ",", "3", ")", ")", "\n", "", "elif", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "inputs", ")", "\n", "\n", "", "backbone", "=", "mobilenet", ".", "MobileNet", "(", "input_tensor", "=", "inputs", ",", "alpha", "=", "alpha", ",", "include_top", "=", "False", ",", "pooling", "=", "None", ",", "weights", "=", "None", ")", "\n", "\n", "# create the full model", "\n", "layer_names", "=", "[", "'conv_pw_5_relu'", ",", "'conv_pw_11_relu'", ",", "'conv_pw_13_relu'", "]", "\n", "layer_outputs", "=", "[", "backbone", ".", "get_layer", "(", "name", ")", ".", "output", "for", "name", "in", "layer_names", "]", "\n", "backbone", "=", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "layer_outputs", ",", "name", "=", "backbone", ".", "name", ")", "\n", "\n", "# invoke modifier if given", "\n", "if", "modifier", ":", "\n", "        ", "backbone", "=", "modifier", "(", "backbone", ")", "\n", "\n", "", "return", "retinanet", ".", "retinanet", "(", "inputs", "=", "inputs", ",", "num_classes", "=", "num_classes", ",", "backbone_layers", "=", "backbone", ".", "outputs", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_classification_model": [[24, 80], ["range", "keras.models.Model", "keras.backend.image_data_format", "keras.layers.Input", "keras.layers.Input", "keras.layers.Conv2D", "keras.backend.image_data_format", "keras.layers.Reshape", "keras.layers.Activation", "keras.layers.Conv2D", "keras.layers.Permute", "keras.initializers.normal", "crfnet.model.initializers.PriorProbability", "keras.initializers.normal"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["def", "default_classification_model", "(", "\n", "num_classes", ",", "\n", "num_anchors", ",", "\n", "pyramid_feature_size", "=", "256", ",", "\n", "prior_probability", "=", "0.01", ",", "\n", "classification_feature_size", "=", "256", ",", "\n", "name", "=", "'classification_submodel'", "\n", ")", ":", "\n", "    ", "\"\"\" Creates the default regression submodel.\n\n    Args\n        num_classes                 : Number of classes to predict a score for at each feature level.\n        num_anchors                 : Number of anchors to predict classification scores for at each feature level.\n        pyramid_feature_size        : The number of filters to expect from the feature pyramid levels.\n        classification_feature_size : The number of filters to use in the layers in the classification submodel.\n        name                        : The name of the submodel.\n\n    Returns\n        A keras.models.Model that predicts classes for each anchor.\n    \"\"\"", "\n", "options", "=", "{", "\n", "'kernel_size'", ":", "3", ",", "\n", "'strides'", ":", "1", ",", "\n", "'padding'", ":", "'same'", ",", "\n", "}", "\n", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "pyramid_feature_size", ",", "None", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "None", ",", "None", ",", "pyramid_feature_size", ")", ")", "\n", "", "outputs", "=", "inputs", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "outputs", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "classification_feature_size", ",", "\n", "activation", "=", "'relu'", ",", "\n", "name", "=", "'pyramid_classification_{}'", ".", "format", "(", "i", ")", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "normal", "(", "mean", "=", "0.0", ",", "stddev", "=", "0.01", ",", "seed", "=", "None", ")", ",", "\n", "bias_initializer", "=", "'zeros'", ",", "\n", "**", "options", "\n", ")", "(", "outputs", ")", "\n", "\n", "", "outputs", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "num_classes", "*", "num_anchors", ",", "\n", "kernel_initializer", "=", "keras", ".", "initializers", ".", "normal", "(", "mean", "=", "0.0", ",", "stddev", "=", "0.01", ",", "seed", "=", "None", ")", ",", "\n", "bias_initializer", "=", "initializers", ".", "PriorProbability", "(", "probability", "=", "prior_probability", ")", ",", "\n", "name", "=", "'pyramid_classification'", ",", "\n", "**", "options", "\n", ")", "(", "outputs", ")", "\n", "\n", "# reshape output and apply sigmoid", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "        ", "outputs", "=", "keras", ".", "layers", ".", "Permute", "(", "(", "2", ",", "3", ",", "1", ")", ",", "name", "=", "'pyramid_classification_permute'", ")", "(", "outputs", ")", "\n", "", "outputs", "=", "keras", ".", "layers", ".", "Reshape", "(", "(", "-", "1", ",", "num_classes", ")", ",", "name", "=", "'pyramid_classification_reshape'", ")", "(", "outputs", ")", "\n", "outputs", "=", "keras", ".", "layers", ".", "Activation", "(", "'sigmoid'", ",", "name", "=", "'pyramid_classification_sigmoid'", ")", "(", "outputs", ")", "\n", "\n", "return", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "outputs", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_regression_model": [[82, 125], ["range", "keras.models.Model", "keras.initializers.normal", "keras.backend.image_data_format", "keras.layers.Input", "keras.layers.Input", "keras.layers.Conv2D", "keras.backend.image_data_format", "keras.layers.Reshape", "keras.layers.Conv2D", "keras.layers.Permute"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range"], ["", "def", "default_regression_model", "(", "num_values", ",", "num_anchors", ",", "pyramid_feature_size", "=", "256", ",", "regression_feature_size", "=", "256", ",", "name", "=", "'regression_submodel'", ")", ":", "\n", "    ", "\"\"\" Creates the default regression submodel.\n\n    Args\n        num_values              : Number of values to regress.\n        num_anchors             : Number of anchors to regress for each feature level.\n        pyramid_feature_size    : The number of filters to expect from the feature pyramid levels.\n        regression_feature_size : The number of filters to use in the layers in the regression submodel.\n        name                    : The name of the submodel.\n\n    Returns\n        A keras.models.Model that predicts regression values for each anchor.\n    \"\"\"", "\n", "# All new conv layers except the final one in the", "\n", "# RetinaNet (classification) subnets are initialized", "\n", "# with bias b = 0 and a Gaussian weight fill with stddev = 0.01.", "\n", "options", "=", "{", "\n", "'kernel_size'", ":", "3", ",", "\n", "'strides'", ":", "1", ",", "\n", "'padding'", ":", "'same'", ",", "\n", "'kernel_initializer'", ":", "keras", ".", "initializers", ".", "normal", "(", "mean", "=", "0.0", ",", "stddev", "=", "0.01", ",", "seed", "=", "None", ")", ",", "\n", "'bias_initializer'", ":", "'zeros'", "\n", "}", "\n", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "pyramid_feature_size", ",", "None", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "None", ",", "None", ",", "pyramid_feature_size", ")", ")", "\n", "", "outputs", "=", "inputs", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "outputs", "=", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "regression_feature_size", ",", "\n", "activation", "=", "'relu'", ",", "\n", "name", "=", "'pyramid_regression_{}'", ".", "format", "(", "i", ")", ",", "\n", "**", "options", "\n", ")", "(", "outputs", ")", "\n", "\n", "", "outputs", "=", "keras", ".", "layers", ".", "Conv2D", "(", "num_anchors", "*", "num_values", ",", "name", "=", "'pyramid_regression'", ",", "**", "options", ")", "(", "outputs", ")", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "        ", "outputs", "=", "keras", ".", "layers", ".", "Permute", "(", "(", "2", ",", "3", ",", "1", ")", ",", "name", "=", "'pyramid_regression_permute'", ")", "(", "outputs", ")", "\n", "", "outputs", "=", "keras", ".", "layers", ".", "Reshape", "(", "(", "-", "1", ",", "num_values", ")", ",", "name", "=", "'pyramid_regression_reshape'", ")", "(", "outputs", ")", "\n", "\n", "return", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "outputs", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__create_pyramid_features": [[127, 181], ["keras.layers.Conv2D", "layers.UpsampleLike", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Add", "layers.UpsampleLike", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Add", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.Conv2D", "keras.layers.Concatenate", "keras.layers.Concatenate", "keras.layers.Concatenate", "keras.layers.Concatenate", "keras.layers.Concatenate"], "function", ["None"], ["", "def", "__create_pyramid_features", "(", "C3", ",", "C4", ",", "C5", ",", "radar_layers", "=", "None", ",", "feature_size", "=", "256", ")", ":", "\n", "    ", "\"\"\" Creates the FPN layers on top of the backbone features.\n\n    Args\n        C3           : Feature stage C3 from the backbone.\n        C4           : Feature stage C4 from the backbone.\n        C5           : Feature stage C5 from the backbone.\n        feature_size : The feature size to use for the resulting feature levels.\n\n    Returns\n        A list of feature levels [P3, P4, P5, P6, P7].\n    \"\"\"", "\n", "# update feature size for radar channels", "\n", "if", "radar_layers", ":", "\n", "        ", "num_radar_channels", "=", "radar_layers", "[", "0", "]", ".", "_shape", ".", "dims", "[", "-", "1", "]", ".", "value", "\n", "feature_size", "-=", "num_radar_channels", "\n", "\n", "# upsample C5 to get P5 from the FPN paper", "\n", "", "P5", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "1", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "name", "=", "'C5_reduced'", ")", "(", "C5", ")", "\n", "P5_upsampled", "=", "layers", ".", "UpsampleLike", "(", "name", "=", "'P5_upsampled'", ")", "(", "[", "P5", ",", "C4", "]", ")", "\n", "P5", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "name", "=", "'P5'", ")", "(", "P5", ")", "\n", "\n", "# add P5 elementwise to C4", "\n", "P4", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "1", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "name", "=", "'C4_reduced'", ")", "(", "C4", ")", "\n", "P4", "=", "keras", ".", "layers", ".", "Add", "(", "name", "=", "'P4_merged'", ")", "(", "[", "P5_upsampled", ",", "P4", "]", ")", "\n", "P4_upsampled", "=", "layers", ".", "UpsampleLike", "(", "name", "=", "'P4_upsampled'", ")", "(", "[", "P4", ",", "C3", "]", ")", "\n", "P4", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "name", "=", "'P4'", ")", "(", "P4", ")", "\n", "\n", "# add P4 elementwise to C3", "\n", "P3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "1", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "name", "=", "'C3_reduced'", ")", "(", "C3", ")", "\n", "P3", "=", "keras", ".", "layers", ".", "Add", "(", "name", "=", "'P3_merged'", ")", "(", "[", "P4_upsampled", ",", "P3", "]", ")", "\n", "P3", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "3", ",", "strides", "=", "1", ",", "padding", "=", "'same'", ",", "name", "=", "'P3'", ")", "(", "P3", ")", "\n", "\n", "# \"P6 is obtained via a 3x3 stride-2 conv on C5\"", "\n", "P6", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'same'", ",", "name", "=", "'P6'", ")", "(", "C5", ")", "\n", "\n", "# \"P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6\"", "\n", "P7", "=", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ",", "name", "=", "'C6_relu'", ")", "(", "P6", ")", "\n", "P7", "=", "keras", ".", "layers", ".", "Conv2D", "(", "feature_size", ",", "kernel_size", "=", "3", ",", "strides", "=", "2", ",", "padding", "=", "'same'", ",", "name", "=", "'P7'", ")", "(", "P7", ")", "\n", "\n", "if", "radar_layers", ":", "\n", "        ", "R3", "=", "radar_layers", "[", "2", "]", "\n", "R4", "=", "radar_layers", "[", "3", "]", "\n", "R5", "=", "radar_layers", "[", "4", "]", "\n", "R6", "=", "radar_layers", "[", "5", "]", "#keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='rad_block6_pool',border_mode=\"same\")(R5)", "\n", "R7", "=", "radar_layers", "[", "6", "]", "#keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='rad_block7_pool',border_mode=\"same\")(R6)", "\n", "P3", "=", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'P3_rad'", ")", "(", "[", "P3", ",", "R3", "]", ")", "\n", "P4", "=", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'P4_rad'", ")", "(", "[", "P4", ",", "R4", "]", ")", "\n", "P5", "=", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'P5_rad'", ")", "(", "[", "P5", ",", "R5", "]", ")", "\n", "P6", "=", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'P6_rad'", ")", "(", "[", "P6", ",", "R6", "]", ")", "\n", "P7", "=", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "3", ",", "name", "=", "'P7_rad'", ")", "(", "[", "P7", ",", "R7", "]", ")", "\n", "\n", "\n", "", "return", "[", "P3", ",", "P4", ",", "P5", ",", "P6", ",", "P7", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_submodels": [[183, 205], ["retinanet.default_regression_model", "retinanet.default_classification_model", "retinanet.default_regression_model", "retinanet.default_regression_model", "retinanet.default_classification_model"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_regression_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_classification_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_regression_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_regression_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_classification_model"], ["", "def", "default_submodels", "(", "num_classes", ",", "num_anchors", ",", "distance", "=", "False", ")", ":", "\n", "    ", "\"\"\" Create a list of default submodels used for object detection.\n\n    The default submodels contains a regression submodel and a classification submodel.\n\n    Args\n        num_classes : Number of classes to use.\n        num_anchors : Number of base anchors.\n\n    Returns\n        A list of tuple, where the first element is the name of the submodel and the second element is the submodel itself.\n    \"\"\"", "\n", "if", "distance", ":", "\n", "        ", "return", "[", "\n", "(", "'regression'", ",", "default_regression_model", "(", "4", ",", "num_anchors", ")", ")", ",", "\n", "(", "'classification'", ",", "default_classification_model", "(", "num_classes", ",", "num_anchors", ")", ")", ",", "\n", "(", "'distance'", ",", "default_regression_model", "(", "1", ",", "num_anchors", ",", "name", "=", "'distance_submodul'", ")", ")", "\n", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "\n", "(", "'regression'", ",", "default_regression_model", "(", "4", ",", "num_anchors", ")", ")", ",", "\n", "(", "'classification'", ",", "default_classification_model", "(", "num_classes", ",", "num_anchors", ")", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__build_model_pyramid": [[207, 219], ["keras.layers.Concatenate", "model"], "function", ["None"], ["", "", "def", "__build_model_pyramid", "(", "name", ",", "model", ",", "features", ")", ":", "\n", "    ", "\"\"\" Applies a single submodel to each FPN level.\n\n    Args\n        name     : Name of the submodel.\n        model    : The submodel to evaluate.\n        features : The FPN features.\n\n    Returns\n        A tensor containing the response from the submodel on the FPN features.\n    \"\"\"", "\n", "return", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "1", ",", "name", "=", "name", ")", "(", "[", "model", "(", "f", ")", "for", "f", "in", "features", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__build_pyramid": [[221, 232], ["retinanet.__build_model_pyramid"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__build_model_pyramid"], ["", "def", "__build_pyramid", "(", "models", ",", "features", ")", ":", "\n", "    ", "\"\"\" Applies all submodels to each FPN level.\n\n    Args\n        models   : List of sumodels to run on each pyramid level (by default only regression, classifcation).\n        features : The FPN features.\n\n    Returns\n        A list of tensors, one for each submodel.\n    \"\"\"", "\n", "return", "[", "__build_model_pyramid", "(", "n", ",", "m", ",", "features", ")", "for", "n", ",", "m", "in", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__build_anchors": [[234, 260], ["keras.layers.Concatenate", "layers.Anchors", "enumerate"], "function", ["None"], ["", "def", "__build_anchors", "(", "anchor_parameters", ",", "features", ")", ":", "\n", "    ", "\"\"\" Builds anchors for the shape of the features from FPN.\n\n    Args\n        anchor_parameters : Parameteres that determine how anchors are generated.\n        features          : The FPN features.\n\n    Returns\n        A tensor containing the anchors for the FPN features.\n\n        The shape is:\n        ```\n        (batch_size, num_anchors, 4)\n        ```\n    \"\"\"", "\n", "anchors", "=", "[", "\n", "layers", ".", "Anchors", "(", "\n", "size", "=", "anchor_parameters", ".", "sizes", "[", "i", "]", ",", "\n", "stride", "=", "anchor_parameters", ".", "strides", "[", "i", "]", ",", "\n", "ratios", "=", "anchor_parameters", ".", "ratios", ",", "\n", "scales", "=", "anchor_parameters", ".", "scales", ",", "\n", "name", "=", "'anchors_{}'", ".", "format", "(", "i", ")", "\n", ")", "(", "f", ")", "for", "i", ",", "f", "in", "enumerate", "(", "features", ")", "\n", "]", "\n", "\n", "return", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "1", ",", "name", "=", "'anchors'", ")", "(", "anchors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.retinanet": [[262, 311], ["create_pyramid_features", "retinanet.__build_pyramid", "keras.models.Model", "crfnet.utils.anchor_parameters.AnchorParameters.default.num_anchors", "retinanet.default_submodels"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__build_pyramid", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_parameters.AnchorParameters.num_anchors", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.default_submodels"], ["", "def", "retinanet", "(", "\n", "inputs", ",", "\n", "backbone_layers", ",", "\n", "num_classes", ",", "\n", "radar_layers", "=", "None", ",", "\n", "num_anchors", "=", "None", ",", "\n", "create_pyramid_features", "=", "__create_pyramid_features", ",", "\n", "submodels", "=", "None", ",", "\n", "distance", "=", "False", ",", "\n", "name", "=", "'retinanet'", "\n", ")", ":", "\n", "    ", "\"\"\" Construct a RetinaNet model on top of a backbone.\n\n    This model is the minimum model necessary for training (with the unfortunate exception of anchors as output).\n\n    Args\n        inputs                  : keras.layers.Input (or list of) for the input to the model.\n        num_classes             : Number of classes to classify.\n        num_anchors             : Number of base anchors.\n        create_pyramid_features : Functor for creating pyramid features given the features C3, C4, C5 from the backbone.\n        submodels               : Submodels to run on each feature map (default is regression and classification submodels).\n        name                    : Name of the model.\n\n    Returns\n        A keras.models.Model which takes an image as input and outputs generated anchors and the result from each submodel on every pyramid level.\n\n        The order of the outputs is as defined in submodels:\n        ```\n        [\n            regression, classification, other[0], other[1], ...\n        ]\n        ```\n    \"\"\"", "\n", "\n", "if", "num_anchors", "is", "None", ":", "\n", "        ", "num_anchors", "=", "AnchorParameters", ".", "default", ".", "num_anchors", "(", ")", "\n", "\n", "", "if", "submodels", "is", "None", ":", "\n", "        ", "submodels", "=", "default_submodels", "(", "num_classes", ",", "num_anchors", ",", "distance", ")", "\n", "\n", "", "C3", ",", "C4", ",", "C5", "=", "backbone_layers", "\n", "\n", "# compute pyramid features as per https://arxiv.org/abs/1708.02002", "\n", "features", "=", "create_pyramid_features", "(", "C3", ",", "C4", ",", "C5", ",", "radar_layers", "=", "radar_layers", ")", "\n", "\n", "# for all pyramid levels, run available submodels", "\n", "pyramids", "=", "__build_pyramid", "(", "submodels", ",", "features", ")", "\n", "\n", "return", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "pyramids", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.retinanet_bbox": [[313, 382], ["retinanet.__build_anchors", "keras.models.Model", "retinanet.retinanet", "assert_training_model", "layers.RegressBoxes", "layers.ClipBoxes", "layers.FilterDetections", "retinanet.get_layer", "anchor_params.num_anchors"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.__build_anchors", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.assert_training_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.utils.anchor_parameters.AnchorParameters.num_anchors"], ["", "def", "retinanet_bbox", "(", "\n", "model", "=", "None", ",", "\n", "nms", "=", "True", ",", "\n", "class_specific_filter", "=", "True", ",", "\n", "name", "=", "'retinanet-bbox'", ",", "\n", "anchor_params", "=", "None", ",", "\n", "score_thresh_train", "=", "0.05", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "    ", "\"\"\" Construct a RetinaNet model on top of a backbone and adds convenience functions to output boxes directly.\n\n    This model uses the minimum retinanet model and appends a few layers to compute boxes within the graph.\n    These layers include applying the regression values to the anchors and performing NMS.\n\n    Args\n        model                 : RetinaNet model to append bbox layers to. If None, it will create a RetinaNet model using **kwargs.\n        nms                   : Whether to use non-maximum suppression for the filtering step.\n        class_specific_filter : Whether to use class specific filtering or filter for the best scoring class only.\n        name                  : Name of the model.\n        anchor_params         : Struct containing anchor parameters. If None, default values are used.\n        *kwargs               : Additional kwargs to pass to the minimal retinanet model.\n\n    Returns\n        A keras.models.Model which takes an image as input and outputs the detections on the image.\n\n        The order is defined as follows:\n        ```\n        [\n            boxes, scores, labels, other[0], other[1], ...\n        ]\n        ```\n    \"\"\"", "\n", "\n", "# if no anchor parameters are passed, use default values", "\n", "if", "anchor_params", "is", "None", ":", "\n", "        ", "anchor_params", "=", "AnchorParameters", ".", "default", "\n", "\n", "# create RetinaNet model", "\n", "", "if", "model", "is", "None", ":", "\n", "        ", "model", "=", "retinanet", "(", "num_anchors", "=", "anchor_params", ".", "num_anchors", "(", ")", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "assert_training_model", "(", "model", ")", "\n", "\n", "# compute the anchors", "\n", "", "features", "=", "[", "model", ".", "get_layer", "(", "p_name", ")", ".", "output", "for", "p_name", "in", "[", "'P3'", ",", "'P4'", ",", "'P5'", ",", "'P6'", ",", "'P7'", "]", "]", "\n", "anchors", "=", "__build_anchors", "(", "anchor_params", ",", "features", ")", "\n", "\n", "# we expect the anchors, regression and classification values as first output", "\n", "regression", "=", "model", ".", "outputs", "[", "0", "]", "\n", "classification", "=", "model", ".", "outputs", "[", "1", "]", "\n", "\n", "# \"other\" can be any additional output from custom submodels, by default this will be []", "\n", "other", "=", "model", ".", "outputs", "[", "2", ":", "]", "\n", "\n", "# apply predicted regression to anchors", "\n", "boxes", "=", "layers", ".", "RegressBoxes", "(", "name", "=", "'boxes'", ")", "(", "[", "anchors", ",", "regression", "]", ")", "\n", "boxes", "=", "layers", ".", "ClipBoxes", "(", "name", "=", "'clipped_boxes'", ")", "(", "[", "model", ".", "inputs", "[", "0", "]", ",", "boxes", "]", ")", "\n", "\n", "# filter detections (apply NMS / score threshold / select top-k)", "\n", "detections", "=", "layers", ".", "FilterDetections", "(", "\n", "nms", "=", "nms", ",", "\n", "nms_threshold", "=", "0.3", ",", "\n", "class_specific_filter", "=", "class_specific_filter", ",", "\n", "name", "=", "'filtered_detections'", ",", "\n", "score_threshold", "=", "score_thresh_train", "\n", ")", "(", "[", "boxes", ",", "classification", "]", "+", "other", ")", "\n", "\n", "# construct the model", "\n", "return", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "model", ".", "inputs", ",", "outputs", "=", "detections", ",", "name", "=", "name", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.EfficientNetConvInitializer.__init__": [[25, 27], ["keras.initializers.Initializer.__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "EfficientNetConvInitializer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.EfficientNetConvInitializer.__call__": [[28, 35], ["int", "tensorflow.random_normal", "keras.backend.floatx", "numpy.sqrt"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "shape", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "dtype", "=", "dtype", "or", "K", ".", "floatx", "(", ")", "\n", "\n", "kernel_height", ",", "kernel_width", ",", "_", ",", "out_filters", "=", "shape", "\n", "fan_out", "=", "int", "(", "kernel_height", "*", "kernel_width", "*", "out_filters", ")", "\n", "return", "tf", ".", "random_normal", "(", "\n", "shape", ",", "mean", "=", "0.0", ",", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.EfficientNetDenseInitializer.__init__": [[51, 53], ["keras.initializers.Initializer.__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "EfficientNetDenseInitializer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.EfficientNetDenseInitializer.__call__": [[54, 59], ["tensorflow.random_uniform", "keras.backend.floatx", "numpy.sqrt"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "shape", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "dtype", "=", "dtype", "or", "K", ".", "floatx", "(", ")", "\n", "\n", "init_range", "=", "1.0", "/", "np", ".", "sqrt", "(", "shape", "[", "1", "]", ")", "\n", "return", "tf", ".", "random_uniform", "(", "shape", ",", "-", "init_range", ",", "init_range", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.Swish.__init__": [[64, 67], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Swish", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "supports_masking", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.Swish.call": [[68, 70], ["tensorflow.nn.swish"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "None", ")", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "swish", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.__init__": [[75, 78], ["keras.layers.Layer.__init__", "float"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["    ", "def", "__init__", "(", "self", ",", "drop_connect_rate", "=", "0.", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DropConnect", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "drop_connect_rate", "=", "float", "(", "drop_connect_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.call": [[79, 93], ["keras.backend.in_train_phase", "tensorflow.random_uniform", "tensorflow.floor", "tensorflow.shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "None", ")", ":", "\n", "\n", "        ", "def", "drop_connect", "(", ")", ":", "\n", "            ", "keep_prob", "=", "1.0", "-", "self", ".", "drop_connect_rate", "\n", "\n", "# Compute drop_connect tensor", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "random_tensor", "=", "keep_prob", "\n", "random_tensor", "+=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", ",", "1", ",", "1", "]", ",", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "binary_tensor", "=", "tf", ".", "floor", "(", "random_tensor", ")", "\n", "output", "=", "(", "inputs", "/", "keep_prob", ")", "*", "binary_tensor", "\n", "return", "output", "\n", "\n", "", "return", "K", ".", "in_train_phase", "(", "drop_connect", ",", "inputs", ",", "training", "=", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.get_config": [[94, 100], ["super().get_config", "dict", "list", "list", "super().get_config.items", "config.items"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.DropConnect.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "'drop_connect_rate'", ":", "self", ".", "drop_connect_rate", ",", "\n", "}", "\n", "base_config", "=", "super", "(", "DropConnect", ",", "self", ")", ".", "get_config", "(", ")", "\n", "return", "dict", "(", "list", "(", "base_config", ".", "items", "(", ")", ")", "+", "list", "(", "config", ".", "items", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.BlockArgs.__init__": [[112, 129], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_filters", "=", "None", ",", "\n", "output_filters", "=", "None", ",", "\n", "kernel_size", "=", "None", ",", "\n", "strides", "=", "None", ",", "\n", "num_repeat", "=", "None", ",", "\n", "se_ratio", "=", "None", ",", "\n", "expand_ratio", "=", "None", ",", "\n", "identity_skip", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "input_filters", "=", "input_filters", "\n", "self", ".", "output_filters", "=", "output_filters", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "strides", "=", "strides", "\n", "self", ".", "num_repeat", "=", "num_repeat", "\n", "self", ".", "se_ratio", "=", "se_ratio", "\n", "self", ".", "expand_ratio", "=", "expand_ratio", "\n", "self", ".", "identity_skip", "=", "identity_skip", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.BlockArgs.decode_block_string": [[130, 154], ["isinstance", "block_string.split", "int", "int", "int", "int", "int", "re.split", "ValueError", "float", "int", "int", "len", "len"], "methods", ["None"], ["", "def", "decode_block_string", "(", "self", ",", "block_string", ")", ":", "\n", "        ", "\"\"\"Gets a block through a string notation of arguments.\"\"\"", "\n", "assert", "isinstance", "(", "block_string", ",", "str", ")", "\n", "ops", "=", "block_string", ".", "split", "(", "'_'", ")", "\n", "options", "=", "{", "}", "\n", "for", "op", "in", "ops", ":", "\n", "            ", "splits", "=", "re", ".", "split", "(", "r'(\\d.*)'", ",", "op", ")", "\n", "if", "len", "(", "splits", ")", ">=", "2", ":", "\n", "                ", "key", ",", "value", "=", "splits", "[", ":", "2", "]", "\n", "options", "[", "key", "]", "=", "value", "\n", "\n", "", "", "if", "'s'", "not", "in", "options", "or", "len", "(", "options", "[", "'s'", "]", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'Strides options should be a pair of integers.'", ")", "\n", "\n", "", "self", ".", "input_filters", "=", "int", "(", "options", "[", "'i'", "]", ")", "\n", "self", ".", "output_filters", "=", "int", "(", "options", "[", "'o'", "]", ")", "\n", "self", ".", "kernel_size", "=", "int", "(", "options", "[", "'k'", "]", ")", "\n", "self", ".", "num_repeat", "=", "int", "(", "options", "[", "'r'", "]", ")", "\n", "self", ".", "identity_skip", "=", "(", "'noskip'", "not", "in", "block_string", ")", "\n", "self", ".", "se_ratio", "=", "float", "(", "options", "[", "'se'", "]", ")", "if", "'se'", "in", "options", "else", "None", "\n", "self", ".", "expand_ratio", "=", "int", "(", "options", "[", "'e'", "]", ")", "\n", "self", ".", "strides", "=", "[", "int", "(", "options", "[", "'s'", "]", "[", "0", "]", ")", ",", "int", "(", "options", "[", "'s'", "]", "[", "1", "]", ")", "]", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.BlockArgs.encode_block_string": [[155, 183], ["args.append", "args.append"], "methods", ["None"], ["", "def", "encode_block_string", "(", "self", ",", "block", ")", ":", "\n", "        ", "\"\"\"Encodes a block to a string.\n        Encoding Schema:\n        \"rX_kX_sXX_eX_iX_oX{_se0.XX}{_noskip}\"\n         - X is replaced by a any number ranging from 0-9\n         - {} encapsulates optional arguments\n        To deserialize an encoded block string, use\n        the class method :\n        ```python\n        BlockArgs.from_block_string(block_string)\n        ```\n        \"\"\"", "\n", "args", "=", "[", "\n", "'r%d'", "%", "block", ".", "num_repeat", ",", "\n", "'k%d'", "%", "block", ".", "kernel_size", ",", "\n", "'s%d%d'", "%", "(", "block", ".", "strides", "[", "0", "]", ",", "block", ".", "strides", "[", "1", "]", ")", ",", "\n", "'e%s'", "%", "block", ".", "expand_ratio", ",", "\n", "'i%d'", "%", "block", ".", "input_filters", ",", "\n", "'o%d'", "%", "block", ".", "output_filters", "\n", "]", "\n", "\n", "if", "block", ".", "se_ratio", ">", "0", "and", "block", ".", "se_ratio", "<=", "1", ":", "\n", "            ", "args", ".", "append", "(", "'se%s'", "%", "block", ".", "se_ratio", ")", "\n", "\n", "", "if", "block", ".", "id_skip", "is", "False", ":", "\n", "            ", "args", ".", "append", "(", "'noskip'", ")", "\n", "\n", "", "return", "'_'", ".", "join", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.BlockArgs.from_block_string": [[184, 202], ["cls", "cls.decode_block_string"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.custom_objects.BlockArgs.decode_block_string"], ["", "@", "classmethod", "\n", "def", "from_block_string", "(", "cls", ",", "block_string", ")", ":", "\n", "        ", "\"\"\"\n        Encoding Schema:\n        \"rX_kX_sXX_eX_iX_oX{_se0.XX}{_noskip}\"\n         - X is replaced by a any number ranging from 0-9\n         - {} encapsulates optional arguments\n        To deserialize an encoded block string, use\n        the class method :\n        ```python\n        BlockArgs.from_block_string(block_string)\n        ```\n        Returns:\n            BlockArgs object initialized with the block\n            string args.\n        \"\"\"", "\n", "block", "=", "cls", "(", ")", "\n", "return", "block", ".", "decode_block_string", "(", "block_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vgg.VGGBackbone.retinanet": [[31, 35], ["vgg.vgg_retinanet"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vgg.vgg_retinanet"], ["def", "retinanet", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Returns a retinanet model using the correct backbone.\n        \"\"\"", "\n", "return", "vgg_retinanet", "(", "*", "args", ",", "backbone", "=", "self", ".", "backbone", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vgg.VGGBackbone.download_imagenet": [[36, 57], ["keras.utils.get_file", "ValueError"], "methods", ["None"], ["", "def", "download_imagenet", "(", "self", ")", ":", "\n", "        ", "\"\"\" Downloads ImageNet weights and returns path to weights file.\n        Weights can be downloaded at https://github.com/fizyr/keras-models/releases .\n        \"\"\"", "\n", "if", "self", ".", "backbone", "==", "'vgg16'", ":", "\n", "            ", "resource", "=", "keras", ".", "applications", ".", "vgg16", ".", "vgg16", ".", "WEIGHTS_PATH_NO_TOP", "\n", "checksum", "=", "'6d6bbae143d832006294945121d1f1fc'", "\n", "", "elif", "'vgg-max'", "in", "self", ".", "backbone", ":", "\n", "            ", "resource", "=", "keras", ".", "applications", ".", "vgg16", ".", "vgg16", ".", "WEIGHTS_PATH_NO_TOP", "\n", "checksum", "=", "'6d6bbae143d832006294945121d1f1fc'", "\n", "", "elif", "self", ".", "backbone", "==", "'vgg19'", ":", "\n", "            ", "resource", "=", "keras", ".", "applications", ".", "vgg19", ".", "vgg19", ".", "WEIGHTS_PATH_NO_TOP", "\n", "checksum", "=", "'253f8cb515780f3b799900260a226db6'", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Backbone '{}' not recognized.\"", ".", "format", "(", "self", ".", "backbone", ")", ")", "\n", "\n", "", "return", "get_file", "(", "\n", "'{}_weights_tf_dim_ordering_tf_kernels_notop.h5'", ".", "format", "(", "self", ".", "backbone", ")", ",", "\n", "resource", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "checksum", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vgg.VGGBackbone.validate": [[59, 66], ["ValueError"], "methods", ["None"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks whether the backbone string is correct.\n        \"\"\"", "\n", "allowed_backbones", "=", "[", "'vgg16'", ",", "'vgg19'", ",", "'vgg-max'", ",", "'vgg-max-fpn'", "]", "\n", "\n", "if", "self", ".", "backbone", "not", "in", "allowed_backbones", ":", "\n", "            ", "raise", "ValueError", "(", "'Backbone (\\'{}\\') not in allowed backbones ({}).'", ".", "format", "(", "self", ".", "backbone", ",", "allowed_backbones", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vgg.VGGBackbone.preprocess_image": [[67, 71], ["utils.image.preprocess_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image"], ["", "", "def", "preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Takes as input an image and prepares it for being passed through the network.\n        \"\"\"", "\n", "return", "preprocess_image", "(", "inputs", ",", "mode", "=", "'caffe'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vgg.vgg_retinanet": [[73, 147], ["retinanet.retinanet", "keras.layers.Input", "isinstance", "keras.applications.VGG16", "modifier", "range", "keras.layers.Input", "keras.applications.VGG19", "len", "vggmax.custom.get_layer", "vggmax.custom", "ValueError", "layer_names.append", "layer_names.append", "radar_outputs.append", "radar_outputs.append", "vggmax.custom.get_layer", "radar_outputs.append", "radar_outputs.append", "radar_outputs.append", "radar_outputs.append", "keras.layers.Lambda", "keras.layers.Lambda", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.MaxPooling2D", "int", "int"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.vggmax.custom"], ["", "", "def", "vgg_retinanet", "(", "num_classes", ",", "backbone", "=", "'vgg16'", ",", "inputs", "=", "None", ",", "modifier", "=", "None", ",", "distance", "=", "False", ",", "cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Constructs a retinanet model using a vgg backbone.\n\n    Args\n        num_classes: Number of classes to predict.\n        backbone: Which backbone to use (one of ('vgg16', 'vgg19')).\n        inputs: The inputs to the network (defaults to a Tensor of shape (None, None, 3)).\n        modifier: A function handler which can modify the backbone before using it in retinanet (this can be used to freeze backbone layers for example).\n\n    Returns\n        RetinaNet model with a VGG backbone.\n    \"\"\"", "\n", "# choose default input", "\n", "if", "inputs", "is", "None", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "None", ",", "None", ",", "3", ")", ")", "\n", "", "elif", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "inputs", ")", "\n", "\n", "# create the vgg backbone", "\n", "", "if", "backbone", "==", "'vgg16'", ":", "\n", "        ", "vgg", "=", "keras", ".", "applications", ".", "VGG16", "(", "input_tensor", "=", "inputs", ",", "include_top", "=", "False", ",", "weights", "=", "None", ")", "\n", "", "elif", "backbone", "==", "'vgg19'", ":", "\n", "        ", "vgg", "=", "keras", ".", "applications", ".", "VGG19", "(", "input_tensor", "=", "inputs", ",", "include_top", "=", "False", ",", "weights", "=", "None", ")", "\n", "", "elif", "'vgg-max'", "in", "backbone", ":", "\n", "        ", "vgg", "=", "vggmax", ".", "custom", "(", "input_tensor", "=", "inputs", ",", "include_top", "=", "False", ",", "weights", "=", "None", ",", "cfg", "=", "cfg", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Backbone '{}' not recognized.\"", ".", "format", "(", "backbone", ")", ")", "\n", "\n", "", "if", "modifier", ":", "\n", "        ", "vgg", "=", "modifier", "(", "vgg", ")", "\n", "\n", "# create the full model", "\n", "\n", "", "if", "'max'", "in", "backbone", "and", "len", "(", "cfg", ".", "channels", ")", ">", "3", ":", "\n", "        ", "layer_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "3", ",", "6", ")", ":", "\n", "            ", "if", "i", "in", "cfg", ".", "fusion_blocks", ":", "\n", "                ", "layer_names", ".", "append", "(", "\"concat_%i\"", "%", "i", ")", "\n", "", "else", ":", "\n", "                ", "layer_names", ".", "append", "(", "\"block%i_pool\"", "%", "i", ")", "\n", "", "", "", "else", ":", "\n", "        ", "layer_names", "=", "[", "\"block3_pool\"", ",", "\"block4_pool\"", ",", "\"block5_pool\"", "]", "\n", "\n", "", "layer_outputs", "=", "[", "vgg", ".", "get_layer", "(", "name", ")", ".", "output", "for", "name", "in", "layer_names", "]", "\n", "\n", "radar_names", "=", "[", "\"rad_block1_pool\"", ",", "\"rad_block2_pool\"", ",", "\"rad_block3_pool\"", ",", "\"rad_block4_pool\"", ",", "\"rad_block5_pool\"", "]", "\n", "try", ":", "\n", "        ", "if", "'fpn'", "in", "backbone", ":", "\n", "            ", "radar_outputs", "=", "[", "vgg", ".", "get_layer", "(", "name", ")", ".", "output", "for", "name", "in", "radar_names", "]", "\n", "if", "cfg", ".", "pooling", "==", "'min'", ":", "\n", "                ", "radar_outputs", ".", "append", "(", "keras", ".", "layers", ".", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block6_pool'", ")", "(", "radar_outputs", "[", "-", "1", "]", ")", ")", "\n", "radar_outputs", ".", "append", "(", "keras", ".", "layers", ".", "Lambda", "(", "min_pool2d", ",", "name", "=", "'rad_block7_pool'", ")", "(", "radar_outputs", "[", "-", "1", "]", ")", ")", "\n", "", "elif", "cfg", ".", "pooling", "==", "'conv'", ":", "\n", "                ", "radar_outputs", ".", "append", "(", "keras", ".", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block6_pool'", ")", "(", "radar_outputs", "[", "-", "1", "]", ")", ")", "\n", "radar_outputs", ".", "append", "(", "keras", ".", "layers", ".", "Conv2D", "(", "int", "(", "64", "*", "cfg", ".", "network_width", ")", ",", "(", "3", ",", "3", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "padding", "=", "'same'", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "name", "=", "'rad_block7_pool'", ")", "(", "radar_outputs", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "radar_outputs", ".", "append", "(", "keras", ".", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block6_pool'", ",", "padding", "=", "\"same\"", ")", "(", "radar_outputs", "[", "-", "1", "]", ")", ")", "\n", "radar_outputs", ".", "append", "(", "keras", ".", "layers", ".", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "name", "=", "'rad_block7_pool'", ",", "padding", "=", "\"same\"", ")", "(", "radar_outputs", "[", "-", "1", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "radar_outputs", "=", "None", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "radar_outputs", "=", "None", "\n", "# TODO: catch the specific exception. Exception is too broad.", "\n", "raise", "e", "\n", "\n", "", "return", "retinanet", ".", "retinanet", "(", "inputs", "=", "inputs", ",", "num_classes", "=", "num_classes", ",", "backbone_layers", "=", "layer_outputs", ",", "radar_layers", "=", "radar_outputs", ",", "distance", "=", "distance", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.EfficientNetBackbone.retinanet": [[28, 32], ["efficientnet.efficientnet_retinanet"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.efficientnet_retinanet"], ["def", "retinanet", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Returns a retinanet model using the correct backbone.\n        \"\"\"", "\n", "return", "efficientnet_retinanet", "(", "*", "args", ",", "backbone", "=", "self", ".", "backbone", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.EfficientNetBackbone.download_imagenet": [[33, 51], ["keras.utils.get_file", "ValueError"], "methods", ["None"], ["", "def", "download_imagenet", "(", "self", ")", ":", "\n", "        ", "\"\"\" Downloads ImageNet weights and returns path to weights file.\n        Weights can be downloaded at https://github.com/fizyr/keras-models/releases .\n        \"\"\"", "\n", "if", "self", ".", "backbone", "==", "'vgg16'", ":", "\n", "            ", "resource", "=", "keras", ".", "applications", ".", "vgg16", ".", "vgg16", ".", "WEIGHTS_PATH_NO_TOP", "\n", "checksum", "=", "'6d6bbae143d832006294945121d1f1fc'", "\n", "", "elif", "self", ".", "backbone", "==", "'vgg19'", ":", "\n", "            ", "resource", "=", "keras", ".", "applications", ".", "vgg19", ".", "vgg19", ".", "WEIGHTS_PATH_NO_TOP", "\n", "checksum", "=", "'253f8cb515780f3b799900260a226db6'", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Backbone '{}' not recognized.\"", ".", "format", "(", "self", ".", "backbone", ")", ")", "\n", "\n", "", "return", "get_file", "(", "\n", "'{}_weights_tf_dim_ordering_tf_kernels_notop.h5'", ".", "format", "(", "self", ".", "backbone", ")", ",", "\n", "resource", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "file_hash", "=", "checksum", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.EfficientNetBackbone.validate": [[53, 61], ["ValueError"], "methods", ["None"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks whether the backbone string is correct.\n        \"\"\"", "\n", "allowed_backbones", "=", "[", "'vgg16'", ",", "'vgg19'", ",", "'vgg-max'", ",", "'vgg-max2'", ",", "'vgg-max2-large'", ",", "'vgg-max2-kernelx2'", ",", "'vgg-min'", ",", "'vgg-min2'", ",", "'vgg-min2-large'", ",", "'vgg-min2-kernelx2'", ",", "'vgg-min3'", ",", "'efficientnet'", "]", "\n", "\n", "if", "self", ".", "backbone", "not", "in", "allowed_backbones", ":", "\n", "            ", "raise", "ValueError", "(", "'Backbone (\\'{}\\') not in allowed backbones ({}).'", ".", "format", "(", "self", ".", "backbone", ",", "allowed_backbones", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.EfficientNetBackbone.preprocess_image": [[62, 66], ["crfnet.utils.image.preprocess_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image"], ["", "", "def", "preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Takes as input an image and prepares it for being passed through the network.\n        \"\"\"", "\n", "return", "preprocess_image", "(", "inputs", ",", "mode", "=", "'caffe'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.efficientnet_retinanet": [[68, 100], ["efficientnet.EfficientNet", "retinanet.retinanet", "keras.layers.Input", "isinstance", "modifier", "keras.layers.Input", "modifier.get_layer"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.EfficientNet", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet"], ["", "", "def", "efficientnet_retinanet", "(", "num_classes", ",", "backbone", "=", "'EfficientNet'", ",", "inputs", "=", "None", ",", "modifier", "=", "None", ",", "distance", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Constructs a retinanet model using a EfficientNet backbone.\n\n    Args\n        num_classes: Number of classes to predict.\n        backbone: Which backbone to use (one of ('vgg16', 'vgg19')).\n        inputs: The inputs to the network (defaults to a Tensor of shape (None, None, 3)).\n        modifier: A function handler which can modify the backbone before using it in retinanet (this can be used to freeze backbone layers for example).\n\n    Returns\n        RetinaNet model with a VGG backbone.\n    \"\"\"", "\n", "# choose default input", "\n", "if", "inputs", "is", "None", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "None", ",", "None", ",", "3", ")", ")", "\n", "", "elif", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "inputs", ")", "\n", "\n", "# create the vgg backbone", "\n", "", "efficientnet", "=", "EfficientNet", "(", "input_shape", "=", "None", ",", "\n", "block_args_list", "=", "DEFAULT_BLOCK_LIST", ",", "\n", "width_coefficient", "=", "2.0", ",", "\n", "depth_coefficient", "=", "1.0", ",", "\n", "input_tensor", "=", "inputs", ",", "\n", "pooling", "=", "'max'", ")", "\n", "if", "modifier", ":", "\n", "        ", "efficientnet", "=", "modifier", "(", "efficientnet", ")", "#", "\n", "\n", "", "layer_names", "=", "[", "\"swish_11\"", ",", "\"swish_17\"", ",", "\"swish_47\"", "]", "\n", "layer_outputs", "=", "[", "efficientnet", ".", "get_layer", "(", "name", ")", ".", "output", "for", "name", "in", "layer_names", "]", "\n", "\n", "return", "retinanet", ".", "retinanet", "(", "inputs", "=", "inputs", ",", "num_classes", "=", "num_classes", ",", "backbone_layers", "=", "layer_outputs", ",", "distance", "=", "distance", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_filters": [[109, 126], ["float", "int", "max", "int", "int"], "function", ["None"], ["", "def", "round_filters", "(", "filters", ",", "width_coefficient", ",", "depth_divisor", ",", "min_depth", ")", ":", "\n", "    ", "\"\"\"Round number of filters based on depth multiplier.\"\"\"", "\n", "multiplier", "=", "float", "(", "width_coefficient", ")", "\n", "divisor", "=", "int", "(", "depth_divisor", ")", "\n", "min_depth", "=", "min_depth", "\n", "\n", "if", "not", "multiplier", ":", "\n", "        ", "return", "filters", "\n", "\n", "", "filters", "*=", "multiplier", "\n", "min_depth", "=", "min_depth", "or", "divisor", "\n", "new_filters", "=", "max", "(", "min_depth", ",", "int", "(", "filters", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than 10%.", "\n", "if", "new_filters", "<", "0.9", "*", "filters", ":", "\n", "        ", "new_filters", "+=", "divisor", "\n", "\n", "", "return", "int", "(", "new_filters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_repeats": [[129, 137], ["int", "math.ceil"], "function", ["None"], ["", "def", "round_repeats", "(", "repeats", ",", "depth_coefficient", ")", ":", "\n", "    ", "\"\"\"Round number of filters based on depth multiplier.\"\"\"", "\n", "multiplier", "=", "depth_coefficient", "\n", "\n", "if", "not", "multiplier", ":", "\n", "        ", "return", "repeats", "\n", "\n", "", "return", "int", "(", "math", ".", "ceil", "(", "multiplier", "*", "repeats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.SEBlock": [[140, 179], ["max", "keras.backend.image_data_format", "int", "keras.layers.Lambda", "keras.layers.Conv2D", "custom_objects.Swish", "keras.layers.Conv2D", "keras.layers.Activation", "keras.layers.Multiply", "keras.backend.mean", "custom_objects.EfficientNetConvInitializer", "custom_objects.EfficientNetConvInitializer"], "function", ["None"], ["", "def", "SEBlock", "(", "input_filters", ",", "se_ratio", ",", "expand_ratio", ",", "data_format", "=", "None", ")", ":", "\n", "    ", "if", "data_format", "is", "None", ":", "\n", "        ", "data_format", "=", "K", ".", "image_data_format", "(", ")", "\n", "\n", "", "num_reduced_filters", "=", "max", "(", "\n", "1", ",", "int", "(", "input_filters", "*", "se_ratio", ")", ")", "\n", "filters", "=", "input_filters", "*", "expand_ratio", "\n", "\n", "if", "data_format", "==", "'channels_first'", ":", "\n", "        ", "channel_axis", "=", "1", "\n", "spatial_dims", "=", "[", "2", ",", "3", "]", "\n", "", "else", ":", "\n", "        ", "channel_axis", "=", "-", "1", "\n", "spatial_dims", "=", "[", "1", ",", "2", "]", "\n", "\n", "", "def", "block", "(", "inputs", ")", ":", "\n", "        ", "x", "=", "inputs", "\n", "x", "=", "layers", ".", "Lambda", "(", "lambda", "a", ":", "K", ".", "mean", "(", "a", ",", "axis", "=", "spatial_dims", ",", "keepdims", "=", "True", ")", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "num_reduced_filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "True", ")", "(", "x", ")", "\n", "x", "=", "Swish", "(", ")", "(", "x", ")", "\n", "# Excite", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "True", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'sigmoid'", ")", "(", "x", ")", "\n", "out", "=", "layers", ".", "Multiply", "(", ")", "(", "[", "x", ",", "inputs", "]", ")", "\n", "return", "out", "\n", "\n", "", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.MBConvBlock": [[182, 264], ["keras.backend.image_data_format", "keras.layers.DepthwiseConv2D", "keras.layers.BatchNormalization", "custom_objects.Swish", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "custom_objects.Swish", "efficientnet.SEBlock", "all", "custom_objects.EfficientNetConvInitializer", "custom_objects.EfficientNetConvInitializer", "keras.layers.Add", "custom_objects.EfficientNetConvInitializer", "custom_objects.DropConnect"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.SEBlock"], ["", "def", "MBConvBlock", "(", "input_filters", ",", "output_filters", ",", "\n", "kernel_size", ",", "strides", ",", "\n", "expand_ratio", ",", "se_ratio", ",", "\n", "id_skip", ",", "drop_connect_rate", ",", "\n", "batch_norm_momentum", "=", "0.99", ",", "\n", "batch_norm_epsilon", "=", "1e-3", ",", "\n", "data_format", "=", "None", ")", ":", "\n", "\n", "    ", "if", "data_format", "is", "None", ":", "\n", "        ", "data_format", "=", "K", ".", "image_data_format", "(", ")", "\n", "\n", "", "if", "data_format", "==", "'channels_first'", ":", "\n", "        ", "channel_axis", "=", "1", "\n", "spatial_dims", "=", "[", "2", ",", "3", "]", "\n", "", "else", ":", "\n", "        ", "channel_axis", "=", "-", "1", "\n", "spatial_dims", "=", "[", "1", ",", "2", "]", "\n", "\n", "", "has_se", "=", "(", "se_ratio", "is", "not", "None", ")", "and", "(", "se_ratio", ">", "0", ")", "and", "(", "se_ratio", "<=", "1", ")", "\n", "filters", "=", "input_filters", "*", "expand_ratio", "\n", "\n", "def", "block", "(", "inputs", ")", ":", "\n", "\n", "        ", "if", "expand_ratio", "!=", "1", ":", "\n", "            ", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ")", "(", "inputs", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "(", "x", ")", "\n", "x", "=", "Swish", "(", ")", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "inputs", "\n", "\n", "", "x", "=", "layers", ".", "DepthwiseConv2D", "(", "\n", "[", "kernel_size", ",", "kernel_size", "]", ",", "\n", "strides", "=", "strides", ",", "\n", "depthwise_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "(", "x", ")", "\n", "x", "=", "Swish", "(", ")", "(", "x", ")", "\n", "\n", "if", "has_se", ":", "\n", "            ", "x", "=", "SEBlock", "(", "input_filters", ",", "se_ratio", ",", "expand_ratio", ",", "\n", "data_format", ")", "(", "x", ")", "\n", "\n", "# output phase", "\n", "\n", "", "x", "=", "layers", ".", "Conv2D", "(", "\n", "output_filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "(", "x", ")", "\n", "\n", "if", "id_skip", ":", "\n", "            ", "if", "all", "(", "s", "==", "1", "for", "s", "in", "strides", ")", "and", "(", "\n", "input_filters", "==", "output_filters", ")", ":", "\n", "\n", "# only apply drop_connect if skip presents.", "\n", "                ", "if", "drop_connect_rate", ":", "\n", "                    ", "x", "=", "DropConnect", "(", "drop_connect_rate", ")", "(", "x", ")", "\n", "\n", "", "x", "=", "layers", ".", "Add", "(", ")", "(", "[", "x", ",", "inputs", "]", ")", "\n", "\n", "", "", "return", "x", "\n", "\n", "", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.EfficientNet": [[266, 488], ["int", "keras_applications.imagenet_utils._obtain_input_shape", "sum", "enumerate", "keras.models.Model", "ValueError", "ValueError", "keras.backend.image_data_format", "keras.layers.Input", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "custom_objects.Swish", "float", "efficientnet.round_filters", "efficientnet.round_filters", "efficientnet.round_repeats", "range", "outputs.append", "keras.layers.Conv2D", "keras.layers.BatchNormalization", "custom_objects.Swish", "outputs.append", "keras.utils.get_source_inputs", "keras.models.Model.load_weights", "os.path.exists", "keras.backend.is_keras_tensor", "keras.layers.Input", "efficientnet.MBConvBlock", "keras.layers.GlobalAveragePooling2D", "keras.layers.Dense", "keras.layers.Activation", "efficientnet.round_filters", "custom_objects.EfficientNetConvInitializer", "efficientnet.MBConvBlock", "efficientnet.round_filters", "custom_objects.EfficientNetConvInitializer", "keras.layers.Dropout", "keras.layers.GlobalAveragePooling2D", "custom_objects.EfficientNetDenseInitializer", "keras.layers.GlobalMaxPooling2D"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_filters", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_filters", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_repeats", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.backend.tensorflow_backend.range", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.MBConvBlock", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_filters", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.MBConvBlock", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.efficientnet.round_filters"], ["", "def", "EfficientNet", "(", "input_shape", ",", "\n", "block_args_list", ":", "List", "[", "BlockArgs", "]", ",", "\n", "width_coefficient", ":", "float", ",", "\n", "depth_coefficient", ":", "float", ",", "\n", "include_top", "=", "False", ",", "\n", "weights", "=", "None", ",", "\n", "input_tensor", "=", "None", ",", "\n", "pooling", "=", "None", ",", "\n", "classes", "=", "None", ",", "\n", "dropout_rate", "=", "0.", ",", "\n", "drop_connect_rate", "=", "0.", ",", "\n", "batch_norm_momentum", "=", "0.99", ",", "\n", "batch_norm_epsilon", "=", "1e-3", ",", "\n", "depth_divisor", "=", "8", ",", "\n", "min_depth", "=", "None", ",", "\n", "data_format", "=", "None", ",", "\n", "default_size", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Builder model for EfficientNets.\n    # Arguments:\n        input_shape: Optional shape tuple, the input shape\n            depends on the configuration, with a minimum\n            decided by the number of stride 2 operations.\n            When None is provided, it defaults to 224.\n            Considered the \"Resolution\" parameter from\n            the paper (inherently Resolution coefficient).\n        block_args_list: Optional List of BlockArgs, each\n            of which detail the arguments of the MBConvBlock.\n            If left as None, it defaults to the blocks\n            from the paper.\n        width_coefficient: Determines the number of channels\n            available per layer. Compound Coefficient that\n            needs to be found using grid search on a base\n            configuration model.\n        depth_coefficient: Determines the number of layers\n            available to the model. Compound Coefficient that\n            needs to be found using grid search on a base\n            configuration model.\n        include_top: Whether to include the fully-connected\n            layer at the top of the network.\n        weights: `None` (random initialization) or\n            `imagenet` (ImageNet weights)\n        input_tensor: Optional Keras tensor (i.e. output of\n            `layers.Input()`)\n            to use as image input for the model.\n        pooling: Optional pooling mode for feature extraction\n            when `include_top` is `False`.\n            - `None` means that the output of the model\n                will be the 4D tensor output of the\n                last convolutional layer.\n            - `avg` means that global average pooling\n                will be applied to the output of the\n                last convolutional layer, and thus\n                the output of the model will be a\n                2D tensor.\n            - `max` means that global max pooling will\n                be applied.\n        classes: Optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        dropout_rate: Float, percentage of random dropout.\n        drop_connect_rate: Float, percentage of random droped\n            connections.\n        batch_norm_momentum: Float, default batch normalization\n            momentum. Obtained from the paper.\n        batch_norm_epsilon: Float, default batch normalization\n            epsilon. Obtained from the paper.\n        depth_divisor: Optional. Used when rounding off the coefficient\n             scaled channels and depth of the layers.\n        min_depth: Optional. Minimum depth value in order to\n            avoid blocks with 0 layers.\n        data_format: \"channels_first\" or \"channels_last\". If left\n            as None, defaults to the value set in ~/.keras.\n        default_size: Specifies the default image size of the model\n    # Raises:\n        - ValueError: If weights are not in 'imagenet' or None.\n        - ValueError: If weights are 'imagenet' and `classes` is\n            not 1000.\n    # Returns:\n        A Keras Model.\n    \"\"\"", "\n", "if", "not", "(", "weights", "in", "{", "'imagenet'", ",", "None", "}", "or", "os", ".", "path", ".", "exists", "(", "weights", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The `weights` argument should be either '", "\n", "'`None` (random initialization), `imagenet` '", "\n", "'(pre-training on ImageNet), '", "\n", "'or the path to the weights file to be loaded.'", ")", "\n", "\n", "", "if", "weights", "==", "'imagenet'", "and", "include_top", "and", "classes", "!=", "1000", ":", "\n", "        ", "raise", "ValueError", "(", "'If using `weights` as `\"imagenet\"` with `include_top` '", "\n", "'as true, `classes` should be 1000'", ")", "\n", "\n", "", "if", "data_format", "is", "None", ":", "\n", "        ", "data_format", "=", "K", ".", "image_data_format", "(", ")", "\n", "\n", "", "if", "data_format", "==", "'channels_first'", ":", "\n", "        ", "channel_axis", "=", "1", "\n", "", "else", ":", "\n", "        ", "channel_axis", "=", "-", "1", "\n", "\n", "", "if", "default_size", "is", "None", ":", "\n", "        ", "default_size", "=", "224", "\n", "\n", "", "if", "block_args_list", "is", "None", ":", "\n", "        ", "block_args_list", "=", "DEFAULT_BLOCK_LIST", "\n", "\n", "# count number of strides to compute min size", "\n", "", "stride_count", "=", "1", "\n", "for", "block_args", "in", "block_args_list", ":", "\n", "        ", "if", "block_args", ".", "strides", "is", "not", "None", "and", "block_args", ".", "strides", "[", "0", "]", ">", "1", ":", "\n", "            ", "stride_count", "+=", "1", "\n", "\n", "", "", "min_size", "=", "int", "(", "2", "**", "stride_count", ")", "\n", "\n", "# Determine proper input shape and default size.", "\n", "input_shape", "=", "_obtain_input_shape", "(", "input_shape", ",", "\n", "default_size", "=", "default_size", ",", "\n", "min_size", "=", "min_size", ",", "\n", "data_format", "=", "data_format", ",", "\n", "require_flatten", "=", "include_top", ",", "\n", "weights", "=", "weights", ")", "\n", "\n", "# Stem part", "\n", "if", "input_tensor", "is", "None", ":", "\n", "        ", "inputs", "=", "layers", ".", "Input", "(", "shape", "=", "input_shape", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "K", ".", "is_keras_tensor", "(", "input_tensor", ")", ":", "\n", "            ", "inputs", "=", "layers", ".", "Input", "(", "tensor", "=", "input_tensor", ",", "shape", "=", "input_shape", ")", "\n", "", "else", ":", "\n", "            ", "inputs", "=", "input_tensor", "\n", "\n", "", "", "outputs", "=", "[", "]", "\n", "\n", "x", "=", "inputs", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "round_filters", "(", "32", ",", "width_coefficient", ",", "\n", "depth_divisor", ",", "min_depth", ")", ",", "\n", "kernel_size", "=", "[", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", "]", ",", "\n", "kernel_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "(", "x", ")", "\n", "x", "=", "Swish", "(", ")", "(", "x", ")", "\n", "\n", "num_blocks", "=", "sum", "(", "[", "block_args", ".", "num_repeat", "for", "block_args", "in", "block_args_list", "]", ")", "\n", "drop_connect_rate_per_block", "=", "drop_connect_rate", "/", "float", "(", "num_blocks", ")", "\n", "\n", "# Blocks part", "\n", "for", "block_idx", ",", "block_args", "in", "enumerate", "(", "block_args_list", ")", ":", "\n", "        ", "assert", "block_args", ".", "num_repeat", ">", "0", "\n", "\n", "# Update block input and output filters based on depth multiplier.", "\n", "block_args", ".", "input_filters", "=", "round_filters", "(", "block_args", ".", "input_filters", ",", "width_coefficient", ",", "depth_divisor", ",", "min_depth", ")", "\n", "block_args", ".", "output_filters", "=", "round_filters", "(", "block_args", ".", "output_filters", ",", "width_coefficient", ",", "depth_divisor", ",", "min_depth", ")", "\n", "block_args", ".", "num_repeat", "=", "round_repeats", "(", "block_args", ".", "num_repeat", ",", "depth_coefficient", ")", "\n", "\n", "# The first block needs to take care of stride and filter size increase.", "\n", "x", "=", "MBConvBlock", "(", "block_args", ".", "input_filters", ",", "block_args", ".", "output_filters", ",", "\n", "block_args", ".", "kernel_size", ",", "block_args", ".", "strides", ",", "\n", "block_args", ".", "expand_ratio", ",", "block_args", ".", "se_ratio", ",", "\n", "block_args", ".", "identity_skip", ",", "drop_connect_rate_per_block", "*", "block_idx", ",", "\n", "batch_norm_momentum", ",", "batch_norm_epsilon", ",", "data_format", ")", "(", "x", ")", "\n", "\n", "if", "block_args", ".", "num_repeat", ">", "1", ":", "\n", "            ", "block_args", ".", "input_filters", "=", "block_args", ".", "output_filters", "\n", "block_args", ".", "strides", "=", "[", "1", ",", "1", "]", "\n", "\n", "", "for", "_", "in", "range", "(", "block_args", ".", "num_repeat", "-", "1", ")", ":", "\n", "            ", "x", "=", "MBConvBlock", "(", "block_args", ".", "input_filters", ",", "block_args", ".", "output_filters", ",", "\n", "block_args", ".", "kernel_size", ",", "block_args", ".", "strides", ",", "\n", "block_args", ".", "expand_ratio", ",", "block_args", ".", "se_ratio", ",", "\n", "block_args", ".", "identity_skip", ",", "drop_connect_rate_per_block", "*", "block_idx", ",", "\n", "batch_norm_momentum", ",", "batch_norm_epsilon", ",", "data_format", ")", "(", "x", ")", "\n", "", "outputs", ".", "append", "(", "x", ")", "\n", "\n", "# Head part", "\n", "", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "round_filters", "(", "1280", ",", "width_coefficient", ",", "depth_coefficient", ",", "min_depth", ")", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "EfficientNetConvInitializer", "(", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "(", "x", ")", "\n", "x", "=", "Swish", "(", ")", "(", "x", ")", "\n", "\n", "if", "include_top", ":", "\n", "        ", "x", "=", "layers", ".", "GlobalAveragePooling2D", "(", "data_format", "=", "data_format", ")", "(", "x", ")", "\n", "\n", "if", "dropout_rate", ">", "0", ":", "\n", "            ", "x", "=", "layers", ".", "Dropout", "(", "dropout_rate", ")", "(", "x", ")", "\n", "\n", "", "x", "=", "layers", ".", "Dense", "(", "classes", ",", "kernel_initializer", "=", "EfficientNetDenseInitializer", "(", ")", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'softmax'", ")", "(", "x", ")", "\n", "\n", "", "else", ":", "\n", "        ", "if", "pooling", "==", "'avg'", ":", "\n", "            ", "x", "=", "layers", ".", "GlobalAveragePooling2D", "(", ")", "(", "x", ")", "\n", "", "elif", "pooling", "==", "'max'", ":", "\n", "            ", "x", "=", "layers", ".", "GlobalMaxPooling2D", "(", ")", "(", "x", ")", "\n", "", "outputs", ".", "append", "(", "x", ")", "\n", "\n", "\n", "\n", "# Ensure that the model takes into account", "\n", "# any potential predecessors of `input_tensor`.", "\n", "", "if", "input_tensor", "is", "not", "None", ":", "\n", "        ", "inputs", "=", "get_source_inputs", "(", "input_tensor", ")", "\n", "\n", "", "model", "=", "Model", "(", "inputs", ",", "outputs", ")", "\n", "\n", "if", "weights", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_weights", "(", "weights", ")", "\n", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.ResNetBackbone.__init__": [[31, 34], ["Backbone.__init__", "resnet.ResNetBackbone.custom_objects.update"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__"], ["def", "__init__", "(", "self", ",", "backbone", ")", ":", "\n", "        ", "super", "(", "ResNetBackbone", ",", "self", ")", ".", "__init__", "(", "backbone", ")", "\n", "self", ".", "custom_objects", ".", "update", "(", "keras_resnet", ".", "custom_objects", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.ResNetBackbone.retinanet": [[35, 39], ["resnet.resnet_retinanet"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet_retinanet"], ["", "def", "retinanet", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Returns a retinanet model using the correct backbone.\n        \"\"\"", "\n", "return", "resnet_retinanet", "(", "*", "args", ",", "backbone", "=", "self", ".", "backbone", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.ResNetBackbone.download_imagenet": [[40, 61], ["int", "resnet_filename.format", "resnet_resource.format", "keras.utils.get_file", "resnet.ResNetBackbone.backbone.replace"], "methods", ["None"], ["", "def", "download_imagenet", "(", "self", ")", ":", "\n", "        ", "\"\"\" Downloads ImageNet weights and returns path to weights file.\n        \"\"\"", "\n", "resnet_filename", "=", "'ResNet-{}-model.keras.h5'", "\n", "resnet_resource", "=", "'https://github.com/fizyr/keras-models/releases/download/v0.0.1/{}'", ".", "format", "(", "resnet_filename", ")", "\n", "depth", "=", "int", "(", "self", ".", "backbone", ".", "replace", "(", "'resnet'", ",", "''", ")", ")", "\n", "\n", "filename", "=", "resnet_filename", ".", "format", "(", "depth", ")", "\n", "resource", "=", "resnet_resource", ".", "format", "(", "depth", ")", "\n", "if", "depth", "==", "50", ":", "\n", "            ", "checksum", "=", "'3e9f4e4f77bbe2c9bec13b53ee1c2319'", "\n", "", "elif", "depth", "==", "101", ":", "\n", "            ", "checksum", "=", "'05dc86924389e5b401a9ea0348a3213c'", "\n", "", "elif", "depth", "==", "152", ":", "\n", "            ", "checksum", "=", "'6ee11ef2b135592f8031058820bb9e71'", "\n", "\n", "", "return", "get_file", "(", "\n", "filename", ",", "\n", "resource", ",", "\n", "cache_subdir", "=", "'models'", ",", "\n", "md5_hash", "=", "checksum", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.ResNetBackbone.validate": [[63, 71], ["resnet.ResNetBackbone.backbone.split", "ValueError"], "methods", ["None"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks whether the backbone string is correct.\n        \"\"\"", "\n", "allowed_backbones", "=", "[", "'resnet50'", ",", "'resnet101'", ",", "'resnet152'", "]", "\n", "backbone", "=", "self", ".", "backbone", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "\n", "if", "backbone", "not", "in", "allowed_backbones", ":", "\n", "            ", "raise", "ValueError", "(", "'Backbone (\\'{}\\') not in allowed backbones ({}).'", ".", "format", "(", "backbone", ",", "allowed_backbones", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.ResNetBackbone.preprocess_image": [[72, 76], ["crfnet.utils.image.preprocess_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image"], ["", "", "def", "preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Takes as input an image and prepares it for being passed through the network.\n        \"\"\"", "\n", "return", "preprocess_image", "(", "inputs", ",", "mode", "=", "'caffe'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet_retinanet": [[78, 115], ["retinanet.retinanet", "isinstance", "keras_resnet.models.ResNet50", "keras_resnet.models.ResNet50", "modifier", "keras.backend.image_data_format", "keras.layers.Input", "keras.layers.Input", "keras.layers.Input", "keras_resnet.models.ResNet101", "keras_resnet.models.ResNet101", "keras_resnet.models.ResNet152", "keras_resnet.models.ResNet152", "ValueError"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet"], ["", "", "def", "resnet_retinanet", "(", "num_classes", ",", "backbone", "=", "'resnet50'", ",", "inputs", "=", "None", ",", "modifier", "=", "None", ",", "cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Constructs a retinanet model using a resnet backbone.\n\n    Args\n        num_classes: Number of classes to predict.\n        backbone: Which backbone to use (one of ('resnet50', 'resnet101', 'resnet152')).\n        inputs: The inputs to the network (defaults to a Tensor of shape (None, None, 3)).\n        modifier: A function handler which can modify the backbone before using it in retinanet (this can be used to freeze backbone layers for example).\n\n    Returns\n        RetinaNet model with a ResNet backbone.\n    \"\"\"", "\n", "# choose default input", "\n", "if", "inputs", "is", "None", ":", "\n", "        ", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "3", ",", "None", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "            ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "None", ",", "None", ",", "3", ")", ")", "\n", "", "", "elif", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "inputs", ")", "\n", "\n", "# create the resnet backbone", "\n", "", "if", "backbone", "==", "'resnet50'", ":", "\n", "        ", "resnet", "=", "keras_resnet", ".", "models", ".", "ResNet50", "(", "inputs", ",", "include_top", "=", "False", ",", "freeze_bn", "=", "True", ")", "\n", "", "elif", "backbone", "==", "'resnet101'", ":", "\n", "        ", "resnet", "=", "keras_resnet", ".", "models", ".", "ResNet101", "(", "inputs", ",", "include_top", "=", "False", ",", "freeze_bn", "=", "True", ")", "\n", "", "elif", "backbone", "==", "'resnet152'", ":", "\n", "        ", "resnet", "=", "keras_resnet", ".", "models", ".", "ResNet152", "(", "inputs", ",", "include_top", "=", "False", ",", "freeze_bn", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Backbone (\\'{}\\') is invalid.'", ".", "format", "(", "backbone", ")", ")", "\n", "\n", "# invoke modifier if given", "\n", "", "if", "modifier", ":", "\n", "        ", "resnet", "=", "modifier", "(", "resnet", ")", "\n", "\n", "# create the full model", "\n", "", "return", "retinanet", ".", "retinanet", "(", "inputs", "=", "inputs", ",", "num_classes", "=", "num_classes", ",", "backbone_layers", "=", "resnet", ".", "outputs", "[", "1", ":", "]", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet50_retinanet": [[117, 119], ["resnet.resnet_retinanet"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet_retinanet"], ["", "def", "resnet50_retinanet", "(", "num_classes", ",", "inputs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "resnet_retinanet", "(", "num_classes", "=", "num_classes", ",", "backbone", "=", "'resnet50'", ",", "inputs", "=", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet101_retinanet": [[121, 123], ["resnet.resnet_retinanet"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet_retinanet"], ["", "def", "resnet101_retinanet", "(", "num_classes", ",", "inputs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "resnet_retinanet", "(", "num_classes", "=", "num_classes", ",", "backbone", "=", "'resnet101'", ",", "inputs", "=", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet152_retinanet": [[125, 127], ["resnet.resnet_retinanet"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.resnet.resnet_retinanet"], ["", "def", "resnet152_retinanet", "(", "num_classes", ",", "inputs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "resnet_retinanet", "(", "num_classes", "=", "num_classes", ",", "backbone", "=", "'resnet152'", ",", "inputs", "=", "inputs", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.densenet.DenseNetBackbone.retinanet": [[37, 41], ["densenet.densenet_retinanet"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.densenet.densenet_retinanet"], ["def", "retinanet", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Returns a retinanet model using the correct backbone.\n        \"\"\"", "\n", "return", "densenet_retinanet", "(", "*", "args", ",", "backbone", "=", "self", ".", "backbone", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.densenet.DenseNetBackbone.download_imagenet": [[42, 58], ["keras.utils.get_file", "keras.backend.image_data_format", "ValueError", "file_name.format", "file_name.format"], "methods", ["None"], ["", "def", "download_imagenet", "(", "self", ")", ":", "\n", "        ", "\"\"\" Download pre-trained weights for the specified backbone name.\n        This name is in the format {backbone}_weights_tf_dim_ordering_tf_kernels_notop\n        where backbone is the densenet + number of layers (e.g. densenet121).\n        For more info check the explanation from the keras densenet script itself:\n            https://github.com/keras-team/keras/blob/master/keras/applications/densenet.py\n        \"\"\"", "\n", "origin", "=", "'https://github.com/fchollet/deep-learning-models/releases/download/v0.8/'", "\n", "file_name", "=", "'{}_weights_tf_dim_ordering_tf_kernels_notop.h5'", "\n", "\n", "# load weights", "\n", "if", "keras", ".", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "            ", "raise", "ValueError", "(", "'Weights for \"channels_first\" format are not available.'", ")", "\n", "\n", "", "weights_url", "=", "origin", "+", "file_name", ".", "format", "(", "self", ".", "backbone", ")", "\n", "return", "get_file", "(", "file_name", ".", "format", "(", "self", ".", "backbone", ")", ",", "weights_url", ",", "cache_subdir", "=", "'models'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.densenet.DenseNetBackbone.validate": [[59, 66], ["keras.applications.densenet.DenseNetBackbone.backbone.split", "ValueError", "allowed_backbones.keys"], "methods", ["None"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "\"\"\" Checks whether the backbone string is correct.\n        \"\"\"", "\n", "backbone", "=", "self", ".", "backbone", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "\n", "if", "backbone", "not", "in", "allowed_backbones", ":", "\n", "            ", "raise", "ValueError", "(", "'Backbone (\\'{}\\') not in allowed backbones ({}).'", ".", "format", "(", "backbone", ",", "allowed_backbones", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.densenet.DenseNetBackbone.preprocess_image": [[67, 71], ["crfnet.utils.image.preprocess_image"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image"], ["", "", "def", "preprocess_image", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\" Takes as input an image and prepares it for being passed through the network.\n        \"\"\"", "\n", "return", "preprocess_image", "(", "inputs", ",", "mode", "=", "'tf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.densenet.densenet_retinanet": [[73, 108], ["creator", "keras.models.Model", "retinanet.retinanet", "keras.layers.Input", "isinstance", "modifier", "keras.layers.Input", "modifier.get_layer", "enumerate"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet"], ["", "", "def", "densenet_retinanet", "(", "num_classes", ",", "backbone", "=", "'densenet121'", ",", "inputs", "=", "None", ",", "modifier", "=", "None", ",", "cfg", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Constructs a retinanet model using a densenet backbone.\n\n    Args\n        num_classes: Number of classes to predict.\n        backbone: Which backbone to use (one of ('densenet121', 'densenet169', 'densenet201')).\n        inputs: The inputs to the network (defaults to a Tensor of shape (None, None, 3)).\n        modifier: A function handler which can modify the backbone before using it in retinanet (this can be used to freeze backbone layers for example).\n\n    Returns\n        RetinaNet model with a DenseNet backbone.\n    \"\"\"", "\n", "# choose default input", "\n", "if", "inputs", "is", "None", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "(", "None", ",", "None", ",", "3", ")", ")", "\n", "", "elif", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "inputs", "=", "keras", ".", "layers", ".", "Input", "(", "inputs", ")", "\n", "\n", "", "blocks", ",", "creator", "=", "allowed_backbones", "[", "backbone", "]", "\n", "model", "=", "creator", "(", "input_tensor", "=", "inputs", ",", "include_top", "=", "False", ",", "pooling", "=", "None", ",", "weights", "=", "None", ")", "\n", "\n", "# get last conv layer from the end of each dense block", "\n", "layer_outputs", "=", "[", "model", ".", "get_layer", "(", "name", "=", "'conv{}_block{}_concat'", ".", "format", "(", "idx", "+", "2", ",", "block_num", ")", ")", ".", "output", "for", "idx", ",", "block_num", "in", "enumerate", "(", "blocks", ")", "]", "\n", "\n", "# create the densenet backbone", "\n", "model", "=", "keras", ".", "models", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "layer_outputs", "[", "1", ":", "]", ",", "name", "=", "model", ".", "name", ")", "\n", "\n", "# invoke modifier if given", "\n", "if", "modifier", ":", "\n", "        ", "model", "=", "modifier", "(", "model", ")", "\n", "\n", "# create the full model", "\n", "", "model", "=", "retinanet", ".", "retinanet", "(", "inputs", "=", "inputs", ",", "num_classes", "=", "num_classes", ",", "backbone_layers", "=", "model", ".", "outputs", ",", "**", "kwargs", ")", "\n", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.__init__": [[8, 26], ["__init__.Backbone.validate", "losses.smooth_l1", "losses.focal"], "methods", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.validate", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.smooth_l1", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.model.losses.focal"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.retinanet": [[27, 31], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.download_imagenet": [[32, 36], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.validate": [[37, 41], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.Backbone.preprocess_image": [[42, 47], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.backbone": [[49, 66], ["b", "NotImplementedError"], "function", ["None"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.load_model": [[68, 86], ["keras.models.load_model", "__init__.backbone"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.load_model", "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.backbone"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.convert_model": [[88, 106], ["retinanet_bbox"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.retinanet.retinanet_bbox"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.assert_training_model": [[108, 113], ["all"], "function", ["None"], []], "home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.check_training_model": [[115, 123], ["__init__.assert_training_model", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.TUMFTM_CameraRadarFusionNet.architectures.__init__.assert_training_model"], []]}