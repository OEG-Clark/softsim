{"home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.verifypronoun.text_from_lines": [[6, 17], ["open", "enumerate", "len"], "function", ["None"], ["def", "text_from_lines", "(", "filename", ",", "line_idxs", ")", ":", "\n", "    ", "text", "=", "''", "\n", "with", "open", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "p", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "if", "i", "==", "line_idxs", "[", "p", "]", ":", "\n", "                ", "text", "+=", "line", "\n", "p", "+=", "1", "\n", "if", "p", ">=", "len", "(", "line_idxs", ")", ":", "\n", "                    ", "break", "\n", "", "", "", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.verifypronoun.verify_mentions": [[19, 33], ["verifypronoun.text_from_lines", "hashlib.md5().hexdigest", "open", "sum", "open", "next().strip", "print", "print", "int", "hashlib.md5", "next().strip", "range", "next", "text_from_lines.encode", "next"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.verifypronoun.text_from_lines"], ["", "def", "verify_mentions", "(", ")", ":", "\n", "    ", "with", "open", "(", "fixed_pronoun_verification_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "n_lines", "=", "sum", "(", "1", "for", "_", "in", "f", ")", "\n", "\n", "", "with", "open", "(", "fixed_pronoun_verification_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "line_idxs", "=", "[", "int", "(", "next", "(", "f", ")", ".", "strip", "(", ")", ")", "for", "i", "in", "range", "(", "n_lines", "-", "1", ")", "]", "\n", "target_md5_str", "=", "next", "(", "f", ")", ".", "strip", "(", ")", "\n", "\n", "", "text", "=", "text_from_lines", "(", "pronoun_file", ",", "line_idxs", ")", "\n", "md5_str", "=", "hashlib", ".", "md5", "(", "text", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", "\n", "if", "md5_str", "==", "target_md5_str", ":", "\n", "        ", "print", "(", "'Verification passed.'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Verification FAILED!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genlabels.__labels_for_named": [[10, 19], ["os.path.join", "os.path.join", "exp.labelgenexp.gen_mask_hyp_for_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.gen_mask_hyp_for_uf"], ["def", "__labels_for_named", "(", ")", ":", "\n", "    ", "patterns", "=", "[", "'andanyother'", ",", "'suchas'", ",", "'andsomeother'", "]", "\n", "# patterns = ['andsomeother']", "\n", "output_file_prefix", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_20types'", ")", "\n", "for", "pattern", "in", "patterns", ":", "\n", "        ", "mentions_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/el_train.json'", ")", "\n", "output_file", "=", "'{}_{}.json'", ".", "format", "(", "output_file_prefix", ",", "pattern", ")", "\n", "labelgenexp", ".", "gen_mask_hyp_for_uf", "(", "\n", "device", ",", "uf_type_vocab_file", ",", "mentions_file", ",", "output_file", ",", "pattern", "=", "pattern", ",", "use_head", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genlabels.__labels_for_nominal": [[21, 35], ["range", "os.path.join", "os.path.join", "exp.labelgenexp.gen_mask_hyp_for_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.gen_mask_hyp_for_uf"], ["", "", "def", "__labels_for_nominal", "(", ")", ":", "\n", "    ", "patterns", "=", "[", "'andanyother'", ",", "'suchas'", ",", "'andsomeother'", "]", "\n", "for", "i", "in", "range", "(", "21", ")", ":", "\n", "# for i in range(15, 21):", "\n", "        ", "output_file_prefix", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/open_train_{:02d}_20types'", ".", "format", "(", "i", ")", ")", "\n", "for", "pattern", "in", "patterns", ":", "\n", "            ", "mentions_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/open_train_{:02d}.json'", ".", "format", "(", "i", ")", ")", "\n", "output_file", "=", "'{}_{}.json'", ".", "format", "(", "output_file_prefix", ",", "pattern", ")", "\n", "head_words_file", "=", "None", "\n", "labelgenexp", ".", "gen_mask_hyp_for_uf", "(", "\n", "device", ",", "uf_type_vocab_file", ",", "mentions_file", ",", "output_file", ",", "pattern", "=", "pattern", ",", "use_head", "=", "True", ",", "\n", "head_words_file", "=", "head_words_file", ",", "y_str_as_headwords", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genlabels.__labels_for_pronouns": [[37, 46], ["os.path.join", "os.path.join", "exp.labelgenexp.gen_mask_hyp_for_pronouns"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.gen_mask_hyp_for_pronouns"], ["", "", "", "def", "__labels_for_pronouns", "(", ")", ":", "\n", "    ", "pronoun_mentions_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/gigaword_eng_5_texts_pronoun_s005.txt'", ")", "\n", "output_file_prefix", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_20types'", ")", "\n", "patterns", "=", "[", "'andanyother'", ",", "'suchas'", ",", "'andsomeother'", "]", "\n", "for", "pattern", "in", "patterns", ":", "\n", "        ", "output_file", "=", "'{}_{}.json'", ".", "format", "(", "output_file_prefix", ",", "pattern", ")", "\n", "labelgenexp", ".", "gen_mask_hyp_for_pronouns", "(", "\n", "device", ",", "uf_type_vocab_file", ",", "pronoun_mentions_file", ",", "output_file", ",", "pattern", "=", "pattern", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genlabels.__select_with_model_named": [[48, 62], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.labelgenexp.select_with_model_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.select_with_model_uf"], ["", "", "def", "__select_with_model_named", "(", ")", ":", "\n", "    ", "is_my_mention", "=", "False", "\n", "discard_no_match", "=", "False", "\n", "n_types_use", "=", "10", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_ama_ms_10types.json'", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/el_train.json'", ")", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_pre_ft.pth'", ")", "\n", "aao_labels_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_20types_andanyother.json'", ")", "\n", "aso_labels_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_20types_andsomeother.json'", ")", "\n", "msa_labels_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_20types_suchas.json'", ")", "\n", "ex_labels_files", "=", "[", "aao_labels_file", ",", "msa_labels_file", ",", "aso_labels_file", "]", "\n", "labelgenexp", ".", "select_with_model_uf", "(", "\n", "device", ",", "uf_type_vocab_file", ",", "data_file", ",", "is_my_mention", ",", "model_file", ",", "ex_labels_files", ",", "discard_no_match", ",", "\n", "output_file", ",", "n_types_use", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genlabels.__select_with_model_nominal": [[64, 84], ["range", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.labelgenexp.select_with_model_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.select_with_model_uf"], ["", "def", "__select_with_model_nominal", "(", ")", ":", "\n", "# idx = 3", "\n", "    ", "is_my_mention", "=", "False", "\n", "discard_no_match", "=", "False", "\n", "n_types_use", "=", "10", "\n", "for", "idx", "in", "range", "(", "0", ",", "21", ")", ":", "\n", "        ", "output_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/open_train_{:02d}_ama_ms_10types.json'", ".", "format", "(", "idx", ")", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/open_train_{:02d}.json'", ".", "format", "(", "idx", ")", ")", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_pre_ft.pth'", ")", "\n", "aao_labels_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/open_train_{:02d}_20types_andanyother.json'", ".", "format", "(", "idx", ")", ")", "\n", "aso_labels_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/open_train_{:02d}_20types_andsomeother.json'", ".", "format", "(", "idx", ")", ")", "\n", "msa_labels_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/open_train_{:02d}_20types_suchas.json'", ".", "format", "(", "idx", ")", ")", "\n", "ex_labels_files", "=", "[", "aao_labels_file", ",", "msa_labels_file", ",", "aso_labels_file", "]", "\n", "labelgenexp", ".", "select_with_model_uf", "(", "\n", "device", ",", "uf_type_vocab_file", ",", "data_file", ",", "is_my_mention", ",", "model_file", ",", "ex_labels_files", ",", "\n", "discard_no_match", ",", "output_file", ",", "n_types_use", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genlabels.__select_with_model_pronoun": [[86, 104], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.labelgenexp.select_with_model_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.select_with_model_uf"], ["", "", "def", "__select_with_model_pronoun", "(", ")", ":", "\n", "    ", "is_my_mention", "=", "True", "\n", "discard_no_match", "=", "False", "\n", "n_types_use", "=", "10", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_ama_ms_10types.json'", ")", "\n", "data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/gigaword_eng_5_texts_pronoun_s005.txt'", ")", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_pre_ft.pth'", ")", "\n", "aao_labels_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_20types_andanyother.json'", ")", "\n", "aso_labels_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_20types_andsomeother.json'", ")", "\n", "msa_labels_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_20types_suchas.json'", ")", "\n", "ex_labels_files", "=", "[", "aao_labels_file", ",", "msa_labels_file", ",", "aso_labels_file", "]", "\n", "labelgenexp", ".", "select_with_model_uf", "(", "\n", "device", ",", "uf_type_vocab_file", ",", "data_file", ",", "is_my_mention", ",", "model_file", ",", "ex_labels_files", ",", "discard_no_match", ",", "\n", "output_file", ",", "n_types_use", "=", "n_types_use", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainbertuf.__setup_logging": [[10, 15], ["utils.utils.init_universal_logging", "logging.info", "os.path.join", "os.path.splitext", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.init_universal_logging"], ["def", "__setup_logging", "(", "to_file", ")", ":", "\n", "    ", "log_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/log/{}-{}-{}-{}.log'", ".", "format", "(", "os", ".", "path", ".", "splitext", "(", "\n", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", "[", "0", "]", ",", "args", ".", "idx", ",", "str_today", ",", "config", ".", "MACHINE_NAME", ")", ")", "if", "to_file", "else", "None", "\n", "utils", ".", "init_universal_logging", "(", "log_file", ",", "mode", "=", "'a'", ",", "to_stdout", "=", "True", ")", "\n", "logging", ".", "info", "(", "'logging to {}'", ".", "format", "(", "log_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainbertuf.__train1": [[17, 35], ["print", "trainbertuf.__setup_logging", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.bertufexp.TrainConfig", "exp.bertufexp.train_bert_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__setup_logging", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.train_bert_uf"], ["", "def", "__train1", "(", ")", ":", "\n", "    ", "print", "(", "'train 1'", ")", "\n", "__setup_logging", "(", "True", ")", "\n", "\n", "train_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/train.json'", ")", "\n", "dev_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/dev.json'", ")", "\n", "test_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/test.json'", ")", "\n", "type_vocab_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/ontology/types.txt'", ")", "\n", "load_model_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_weak_ama_ms-[best_on_dev_after_finetune].pth'", ")", "\n", "save_model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_ama_ms_ft.pth'", ")", "\n", "# load_model_file = os.path.join(", "\n", "#     config.DATA_DIR, 'ultrafine/output/models/uf_bert_weak_ama_ms-700000.pth')", "\n", "# save_model_file = os.path.join(config.DATA_DIR, 'ultrafine/output/models/uf_bert_ama_ms_ft_70w.pth')", "\n", "tc", "=", "bertufexp", ".", "TrainConfig", "(", "device", ",", "bert_model", "=", "'bert-base-cased'", ",", "batch_size", "=", "48", ",", "eval_interval", "=", "500", ",", "\n", "lr", "=", "2e-5", ",", "w_decay", "=", "0.01", ",", "n_iter", "=", "1000", ",", "lr_schedule", "=", "True", ")", "\n", "bertufexp", ".", "train_bert_uf", "(", "tc", ",", "type_vocab_file", ",", "train_data_file", ",", "dev_data_file", ",", "test_data_file", ",", "\n", "load_model_file", ",", "save_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainbertuf.__train": [[37, 54], ["print", "trainbertuf.__setup_logging", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.bertufexp.TrainConfig", "exp.bertufexp.train_bert_uf"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__setup_logging", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.train_bert_uf"], ["", "def", "__train", "(", ")", ":", "\n", "    ", "print", "(", "'train 0'", ")", "\n", "__setup_logging", "(", "True", ")", "\n", "\n", "train_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/train.json'", ")", "\n", "dev_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/dev.json'", ")", "\n", "test_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/test.json'", ")", "\n", "type_vocab_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/ontology/types.txt'", ")", "\n", "load_model_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_weak-[best_on_dev_after_finetune].pth'", ")", "\n", "# load_model_file = os.path.join(", "\n", "#     config.DATA_DIR, 'ultrafine/output/models/uf_bert_weak-200000.pth')", "\n", "save_model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_pre_ft.pth'", ")", "\n", "tc", "=", "bertufexp", ".", "TrainConfig", "(", "device", ",", "bert_model", "=", "'bert-base-cased'", ",", "batch_size", "=", "48", ",", "eval_interval", "=", "500", ",", "\n", "lr", "=", "2e-5", ",", "w_decay", "=", "0.01", ",", "n_iter", "=", "1000", ",", "lr_schedule", "=", "True", ")", "\n", "bertufexp", ".", "train_bert_uf", "(", "tc", ",", "type_vocab_file", ",", "train_data_file", ",", "dev_data_file", ",", "test_data_file", ",", "\n", "load_model_file", ",", "save_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.__process_doc_file": [[15, 51], ["gzip.open", "gzip.open.read", "list", "re.finditer", "gzip.open.close", "m.group", "doc_str.replace.replace", "list.append", "xml.fromstring", "print", "child.text.strip", "child.text.strip", "child.text.strip", "list", "list.append", "p.text.strip"], "function", ["None"], ["def", "__process_doc_file", "(", "file_name", ")", ":", "\n", "    ", "f", "=", "gzip", ".", "open", "(", "file_name", ",", "'rt'", ",", "encoding", "=", "'utf-8'", ")", "\n", "text", "=", "f", ".", "read", "(", ")", "\n", "\n", "# print(text.count('</DOC>'))", "\n", "docs", "=", "list", "(", ")", "\n", "miter", "=", "re", ".", "finditer", "(", "r'<DOC id=\\\"(.*?)\\\".*?>(.*?)</DOC>'", ",", "text", ",", "re", ".", "DOTALL", ")", "\n", "for", "m", "in", "miter", ":", "\n", "        ", "doc_str", "=", "m", ".", "group", "(", "0", ")", "\n", "doc_str", "=", "doc_str", ".", "replace", "(", "'&AMP;'", ",", "'&amp;'", ")", "\n", "# print(m.group(0))", "\n", "try", ":", "\n", "            ", "root", "=", "ET", ".", "fromstring", "(", "doc_str", ")", "\n", "", "except", "ET", ".", "ParseError", ":", "\n", "            ", "print", "(", "'skip'", ")", "\n", "continue", "\n", "# print(root.tag, root.attrib)", "\n", "\n", "", "doc", "=", "{", "'id'", ":", "root", ".", "attrib", "[", "'id'", "]", "}", "\n", "for", "child", "in", "root", ":", "\n", "            ", "if", "child", ".", "tag", "==", "'HEADLINE'", ":", "\n", "                ", "doc", "[", "'headline'", "]", "=", "child", ".", "text", ".", "strip", "(", ")", "\n", "", "if", "child", ".", "tag", "==", "'DATELINE'", ":", "\n", "                ", "doc", "[", "'dateline'", "]", "=", "child", ".", "text", ".", "strip", "(", ")", "\n", "", "if", "child", ".", "tag", "==", "'TEXT'", ":", "\n", "                ", "text", "=", "child", ".", "text", ".", "strip", "(", ")", "\n", "if", "text", ":", "\n", "                    ", "doc", "[", "'text'", "]", "=", "text", "\n", "", "paragraphs", "=", "list", "(", ")", "\n", "for", "p", "in", "child", ":", "\n", "                    ", "paragraphs", ".", "append", "(", "p", ".", "text", ".", "strip", "(", ")", ")", "\n", "", "if", "paragraphs", ":", "\n", "                    ", "doc", "[", "'p'", "]", "=", "paragraphs", "\n", "", "", "", "docs", ".", "append", "(", "doc", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "return", "docs", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.process_gigaword": [[53, 69], ["open", "os.listdir", "open.close", "print", "os.path.join", "enumerate", "os.listdir", "os.path.join", "prep.__process_doc_file", "print", "open.write", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.__process_doc_file"], ["", "def", "process_gigaword", "(", ")", ":", "\n", "    ", "fout", "=", "open", "(", "gigaword_data_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "doc_dir", "in", "os", ".", "listdir", "(", "gigaword_data_dir", ")", ":", "\n", "        ", "print", "(", "doc_dir", ")", "\n", "doc_dir", "=", "os", ".", "path", ".", "join", "(", "gigaword_data_dir", ",", "doc_dir", ")", "\n", "for", "i", ",", "filename", "in", "enumerate", "(", "os", ".", "listdir", "(", "doc_dir", ")", ")", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "doc_dir", ",", "filename", ")", "\n", "docs", "=", "__process_doc_file", "(", "filename", ")", "\n", "for", "doc", "in", "docs", ":", "\n", "                ", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "doc", ")", ")", ")", "\n", "", "print", "(", "filename", ")", "\n", "# break", "\n", "if", "i", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "i", ")", "\n", "# break", "\n", "", "", "", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.gen_gigaword_texts_file": [[71, 94], ["open", "open", "enumerate", "open.close", "open.close", "json.loads", "list", "json.loads.get", "json.loads.get", "print", "list.append", "re.sub", "open.write", "re.sub.strip"], "function", ["None"], ["", "def", "gen_gigaword_texts_file", "(", ")", ":", "\n", "    ", "f", "=", "open", "(", "gigaword_data_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "\n", "fout", "=", "open", "(", "gigaword_text_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "        ", "if", "i", "%", "100000", "==", "0", ":", "\n", "            ", "print", "(", "i", ")", "\n", "", "x", "=", "json", ".", "loads", "(", "line", ")", "\n", "texts", "=", "list", "(", ")", "\n", "text", "=", "x", ".", "get", "(", "'text'", ",", "None", ")", "\n", "if", "text", "is", "not", "None", ":", "\n", "            ", "texts", ".", "append", "(", "text", ")", "\n", "", "paragraphs", "=", "x", ".", "get", "(", "'p'", ",", "None", ")", "\n", "if", "paragraphs", "is", "not", "None", ":", "\n", "            ", "texts", "+=", "paragraphs", "\n", "\n", "", "for", "text", "in", "texts", ":", "\n", "            ", "text", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "text", ")", "\n", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "text", ".", "strip", "(", ")", ")", ")", "\n", "\n", "# if i > 100:", "\n", "#     break", "\n", "", "", "f", ".", "close", "(", ")", "\n", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.find_pronouns": [[96, 107], ["len", "list", "range", "text[].isalnum", "text_tmp.startswith", "list.append", "text[].isalnum", "len", "len", "len"], "function", ["None"], ["", "def", "find_pronouns", "(", "text", ":", "str", ")", ":", "\n", "    ", "text_len", "=", "len", "(", "text", ")", "\n", "spans", "=", "list", "(", ")", "\n", "for", "p", "in", "range", "(", "text_len", ")", ":", "\n", "        ", "if", "p", "==", "0", "or", "not", "text", "[", "p", "-", "1", "]", ".", "isalnum", "(", ")", ":", "\n", "            ", "text_tmp", "=", "text", "[", "p", ":", "]", "\n", "for", "pn", "in", "pronouns", ":", "\n", "                ", "if", "text_tmp", ".", "startswith", "(", "pn", ")", "and", "(", "p", "+", "len", "(", "pn", ")", "==", "text_len", "or", "not", "text", "[", "p", "+", "len", "(", "pn", ")", "]", ".", "isalnum", "(", ")", ")", ":", "\n", "                    ", "spans", ".", "append", "(", "(", "p", ",", "p", "+", "len", "(", "pn", ")", ")", ")", "\n", "# print(text[p:])", "\n", "", "", "", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.gen_pronoun_mentions": [[109, 141], ["random.seed", "open", "open", "enumerate", "open.close", "open.close", "line.strip", "prep.find_pronouns", "len", "print", "open.write", "random.uniform", "json.dumps"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.find_pronouns"], ["", "def", "gen_pronoun_mentions", "(", ")", ":", "\n", "    ", "import", "random", "\n", "random", ".", "seed", "(", "127", ")", "\n", "\n", "sample_rate", "=", "0.05", "\n", "\n", "f", "=", "open", "(", "gigaword_text_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "fout", "=", "open", "(", "pronoun_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "hcnt", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "        ", "text", "=", "line", ".", "strip", "(", ")", "\n", "spans", "=", "find_pronouns", "(", "text", ")", "\n", "# print(text)", "\n", "# for span in spans:", "\n", "#     print(text[span[0]:span[1]])", "\n", "# print()", "\n", "if", "len", "(", "spans", ")", ">", "0", ":", "\n", "            ", "for", "span", "in", "spans", ":", "\n", "                ", "if", "0", "<", "sample_rate", "<", "1", ":", "\n", "                    ", "v", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "v", ">", "sample_rate", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "x", "=", "{", "'id'", ":", "hcnt", ",", "'text'", ":", "text", ",", "'span'", ":", "span", "}", "\n", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "x", ")", ")", ")", "\n", "hcnt", "+=", "1", "\n", "", "", "if", "i", "%", "1000000", "==", "0", ":", "\n", "            ", "print", "(", "i", ",", "hcnt", ")", "\n", "# if i > 10000:", "\n", "#     break", "\n", "", "", "f", ".", "close", "(", ")", "\n", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainweak.__setup_logging": [[10, 15], ["utils.utils.init_universal_logging", "logging.info", "os.path.join", "os.path.splitext", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.init_universal_logging"], ["def", "__setup_logging", "(", "to_file", ")", ":", "\n", "    ", "log_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/log/{}-{}-{}-{}.log'", ".", "format", "(", "os", ".", "path", ".", "splitext", "(", "\n", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", "[", "0", "]", ",", "args", ".", "idx", ",", "str_today", ",", "config", ".", "MACHINE_NAME", ")", ")", "if", "to_file", "else", "None", "\n", "utils", ".", "init_universal_logging", "(", "log_file", ",", "mode", "=", "'a'", ",", "to_stdout", "=", "True", ")", "\n", "logging", ".", "info", "(", "'logging to {}'", ".", "format", "(", "log_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainweak.__train1": [[17, 45], ["print", "trainweak.__setup_logging", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.bertufexp.TrainConfig", "exp.bertufexp.train_wuf", "os.path.join", "os.path.join", "range", "range"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__setup_logging", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.train_wuf"], ["", "def", "__train1", "(", ")", ":", "\n", "    ", "print", "(", "'train 1'", ")", "\n", "__setup_logging", "(", "True", ")", "\n", "\n", "el_train_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/el_train.json'", ")", "\n", "el_extra_label_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_ama_ms_10types.json'", ")", "\n", "open_train_files", "=", "[", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/open_train_{:02d}.json'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "21", ")", "]", "\n", "open_extra_label_files", "=", "[", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "\n", "'ultrafine/bert_labels/open_train_{:02d}_ama_ms_10types.json'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "21", ")", "]", "\n", "pronoun_mention_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/gigaword_eng_5_texts_pronoun_s005.txt'", ")", "\n", "pronoun_type_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_ama_ms_10types.json'", ")", "\n", "\n", "dev_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/dev.json'", ")", "\n", "type_vocab_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/ontology/types.txt'", ")", "\n", "load_model_file", "=", "None", "\n", "save_model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_weak_ama_ms'", ")", "\n", "# save_model_file = None", "\n", "tc", "=", "bertufexp", ".", "TrainConfig", "(", "device", ",", "bert_model", "=", "'bert-base-cased'", ",", "batch_size", "=", "32", ",", "max_n_ex_types", "=", "10", ",", "\n", "eval_interval", "=", "1000", ",", "lr", "=", "1e-5", ",", "w_decay", "=", "0.01", ",", "n_steps", "=", "1502000", ",", "save_interval", "=", "100000", ",", "\n", "weighted_loss", "=", "True", ",", "weight_for_origin_label", "=", "5.0", ",", "ex_tids", "=", "True", ")", "\n", "# bertufexp.train_bert_uf(tc, type_vocab_file, train_data_file, dev_data_file, save_model_file)", "\n", "bertufexp", ".", "train_wuf", "(", "\n", "tc", ",", "type_vocab_file", ",", "el_train_file", ",", "el_extra_label_file", ",", "open_train_files", ",", "\n", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "dev_data_file", ",", "\n", "None", ",", "save_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainweak.__train": [[47, 71], ["print", "trainweak.__setup_logging", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.bertufexp.TrainConfig", "exp.bertufexp.train_wuf", "os.path.join", "range"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__setup_logging", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.train_wuf"], ["", "def", "__train", "(", ")", ":", "\n", "    ", "print", "(", "'train 0'", ")", "\n", "__setup_logging", "(", "True", ")", "\n", "\n", "el_train_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/el_train.json'", ")", "\n", "el_extra_label_file", "=", "None", "\n", "open_train_files", "=", "[", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/open_train_{:02d}.json'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "21", ")", "]", "\n", "open_extra_label_files", "=", "None", "\n", "dev_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/dev.json'", ")", "\n", "pronoun_mention_file", "=", "None", "\n", "pronoun_type_file", "=", "None", "\n", "type_vocab_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/ontology/types.txt'", ")", "\n", "load_model_file", "=", "None", "\n", "save_model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_weak'", ")", "\n", "# save_model_file = None", "\n", "tc", "=", "bertufexp", ".", "TrainConfig", "(", "\n", "device", ",", "bert_model", "=", "'bert-base-cased'", ",", "batch_size", "=", "32", ",", "eval_interval", "=", "1000", ",", "lr", "=", "1e-5", ",", "w_decay", "=", "0.01", ",", "\n", "n_iter", "=", "400", ",", "n_steps", "=", "1002000", ",", "save_interval", "=", "100000", ")", "\n", "# bertufexp.train_bert_uf(tc, type_vocab_file, train_data_file, dev_data_file, save_model_file)", "\n", "bertufexp", ".", "train_wuf", "(", "\n", "tc", ",", "type_vocab_file", ",", "el_train_file", ",", "el_extra_label_file", ",", "open_train_files", ",", "\n", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "dev_data_file", ",", "\n", "None", ",", "save_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.genpronfixed.gen_pronoun_mentions_fixed_rand": [[7, 41], ["list", "open", "open", "enumerate", "open.close", "open.close", "open", "line.strip", "prep.find_pronouns", "list.append", "len", "print", "int", "len", "line.strip", "open.write", "len", "json.dumps"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.prep.find_pronouns"], ["def", "gen_pronoun_mentions_fixed_rand", "(", ")", ":", "\n", "    ", "span_ids", "=", "list", "(", ")", "\n", "with", "open", "(", "pronoun_span_ids_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "span_ids", ".", "append", "(", "int", "(", "line", ".", "strip", "(", ")", ")", ")", "\n", "\n", "", "", "f", "=", "open", "(", "gigaword_text_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "fout", "=", "open", "(", "pronoun_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "hcnt", "=", "0", "\n", "span_cnt", "=", "0", "\n", "p_span_id", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "        ", "text", "=", "line", ".", "strip", "(", ")", "\n", "spans", "=", "find_pronouns", "(", "text", ")", "\n", "if", "len", "(", "spans", ")", ">", "0", ":", "\n", "            ", "for", "span", "in", "spans", ":", "\n", "                ", "if", "span_cnt", "==", "span_ids", "[", "p_span_id", "]", ":", "\n", "                    ", "p_span_id", "+=", "1", "\n", "x", "=", "{", "'id'", ":", "hcnt", ",", "'text'", ":", "text", ",", "'span'", ":", "span", "}", "\n", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "x", ")", ")", ")", "\n", "hcnt", "+=", "1", "\n", "\n", "if", "p_span_id", ">=", "len", "(", "span_ids", ")", ":", "\n", "                        ", "break", "\n", "", "", "span_cnt", "+=", "1", "\n", "\n", "", "if", "p_span_id", ">=", "len", "(", "span_ids", ")", ":", "\n", "                ", "break", "\n", "", "", "if", "i", "%", "1000000", "==", "0", ":", "\n", "            ", "print", "(", "i", ",", "hcnt", ")", "\n", "# if i > 100:", "\n", "#     break", "\n", "", "", "f", ".", "close", "(", ")", "\n", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__setup_logging": [[10, 15], ["utils.utils.init_universal_logging", "logging.info", "os.path.join", "os.path.splitext", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.init_universal_logging"], ["def", "__setup_logging", "(", "to_file", ")", ":", "\n", "    ", "log_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/log/{}-{}-{}-{}.log'", ".", "format", "(", "os", ".", "path", ".", "splitext", "(", "\n", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", "[", "0", "]", ",", "args", ".", "idx", ",", "str_today", ",", "config", ".", "MACHINE_NAME", ")", ")", "if", "to_file", "else", "None", "\n", "utils", ".", "init_universal_logging", "(", "log_file", ",", "mode", "=", "'a'", ",", "to_stdout", "=", "True", ")", "\n", "logging", ".", "info", "(", "'logging to {}'", ".", "format", "(", "log_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__train": [[17, 54], ["print", "trainufst.__setup_logging", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "exp.ufstexp.TrainConfig", "exp.ufstexp.train_st", "os.path.join", "os.path.join", "range", "range"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.None.trainufst.__setup_logging", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.train_st"], ["", "def", "__train", "(", ")", ":", "\n", "    ", "print", "(", "'train 0'", ")", "\n", "__setup_logging", "(", "True", ")", "\n", "\n", "el_train_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/el_train.json'", ")", "\n", "el_extra_label_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/el_train_ama_ms_10types.json'", ")", "\n", "open_train_files", "=", "[", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/total_train/open_train_{:02d}.json'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "21", ")", "]", "\n", "open_extra_label_files", "=", "[", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "\n", "'ultrafine/bert_labels/open_train_{:02d}_ama_ms_10types.json'", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "21", ")", "]", "\n", "pronoun_mention_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/gigaword_eng_5_texts_pronoun_s005.txt'", ")", "\n", "pronoun_type_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/bert_labels/gigaword5_pronoun_s005_ama_ms_10types.json'", ")", "\n", "\n", "train_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/train.json'", ")", "\n", "# train_data_file = None", "\n", "dev_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/dev.json'", ")", "\n", "test_data_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/crowd/test.json'", ")", "\n", "type_vocab_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/uf_data/ontology/types.txt'", ")", "\n", "teacher_model_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_ama_ms_ft.pth'", ")", "\n", "load_model_file", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "DATA_DIR", ",", "'ultrafine/output/models/uf_bert_weak_ama_ms-[best_on_dev_after_finetune].pth'", ")", "\n", "# teacher_model_file = os.path.join(config.DATA_DIR, 'ultrafine/output/models/uf_bert_ama_ms_ft_80w.pth')", "\n", "# load_model_file = os.path.join(", "\n", "#     config.DATA_DIR, 'ultrafine/output/models/uf_bert_weak_ama_ms-800000.pth')", "\n", "# load_model_file = None", "\n", "save_model_file", "=", "None", "\n", "tc", "=", "ufstexp", ".", "TrainConfig", "(", "device_ids", ",", "bert_model", "=", "'bert-base-cased'", ",", "batch_size", "=", "96", ",", "max_n_ex_types", "=", "10", ",", "\n", "eval_interval", "=", "500", ",", "lr", "=", "1e-5", ",", "w_decay", "=", "0.1", ",", "mask_pos_prob_thres", "=", "0.9", ",", "eval_bs", "=", "16", ",", "\n", "mask_neg_prob_thres", "=", "0.1", ",", "n_steps", "=", "32000", ",", "save_interval", "=", "100000", ",", "\n", "sample_nums", "=", "(", "48", ",", "8", ",", "20", ",", "20", ")", ",", "lr_schedule", "=", "False", ",", "lr_decay", "=", "0.5", ",", "weak_lamb", "=", "1e-2", ",", "\n", "weak_to_pos_thres", "=", "0.7", ",", "lr_decay_thres", "=", "0.47", ")", "\n", "ufstexp", ".", "train_st", "(", "\n", "tc", ",", "type_vocab_file", ",", "el_train_file", ",", "el_extra_label_file", ",", "open_train_files", ",", "\n", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "train_data_file", ",", "dev_data_file", ",", "\n", "test_data_file", ",", "teacher_model_file", ",", "load_model_file", ",", "save_model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.read_json_objs": [[4, 7], ["open", "json.loads"], "function", ["None"], ["def", "read_json_objs", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "return", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.write_json_objs": [[9, 13], ["open", "f.write", "json.dumps"], "function", ["None"], ["", "", "def", "write_json_objs", "(", "objs", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'w'", ",", "encoding", "=", "'utf-8'", ",", "newline", "=", "'\\n'", ")", "as", "f", ":", "\n", "        ", "for", "x", "in", "objs", ":", "\n", "            ", "f", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file": [[15, 19], ["open", "line.strip", "enumerate"], "function", ["None"], ["", "", "", "def", "load_vocab_file", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "vocab", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "", "return", "vocab", ",", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "vocab", ")", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.bertutils.get_bert_adam_optim": [[2, 18], ["AdamW", "AdamW", "len", "any", "any"], "function", ["None"], ["def", "get_bert_adam_optim", "(", "named_params", ",", "learning_rate", ",", "w_decay", ")", ":", "\n", "    ", "from", "transformers", ".", "optimization", "import", "AdamW", "\n", "\n", "if", "w_decay", "==", "0", ":", "\n", "        ", "return", "AdamW", "(", "[", "p", "for", "_", ",", "p", "in", "named_params", "]", ",", "lr", "=", "learning_rate", ",", "correct_bias", "=", "False", ")", "\n", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm'", "]", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "w_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "assert", "len", "(", "optimizer_grouped_parameters", "[", "1", "]", "[", "'params'", "]", ")", "!=", "0", "\n", "# print('opp', len(optimizer_grouped_parameters[0]['params']), len(optimizer_grouped_parameters[1]['params']))", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "learning_rate", ",", "weight_decay", "=", "w_decay", ",", "correct_bias", "=", "False", ")", "\n", "return", "optimizer", "\n", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.calc_f1": [[10, 14], ["float"], "function", ["None"], ["def", "calc_f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "if", "r", "==", "0.", ":", "\n", "        ", "return", "0.", "\n", "", "return", "2", "*", "p", "*", "r", "/", "float", "(", "p", "+", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.macro_f1_gptups": [[16, 39], ["utils.calc_f1", "len", "len", "len", "len", "float", "len", "float", "set().intersection", "len", "set().intersection", "len", "set", "set", "set", "set"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.calc_f1"], ["", "def", "macro_f1_gptups", "(", "true_and_prediction", ")", ":", "\n", "# num_examples = len(true_and_prediction)", "\n", "    ", "p", ",", "r", "=", "0.", ",", "0.", "\n", "pred_example_count", ",", "gold_example_count", "=", "0.", ",", "0.", "\n", "pred_label_count", "=", "0.", "\n", "for", "true_labels", ",", "predicted_labels", "in", "true_and_prediction", ":", "\n", "# print(predicted_labels)", "\n", "        ", "if", "len", "(", "predicted_labels", ")", ">", "0", ":", "\n", "            ", "pred_example_count", "+=", "1", "\n", "pred_label_count", "+=", "len", "(", "predicted_labels", ")", "\n", "per_p", "=", "len", "(", "set", "(", "predicted_labels", ")", ".", "intersection", "(", "set", "(", "true_labels", ")", ")", ")", "/", "float", "(", "len", "(", "predicted_labels", ")", ")", "\n", "p", "+=", "per_p", "\n", "", "if", "len", "(", "true_labels", ")", ">", "0", ":", "\n", "            ", "gold_example_count", "+=", "1", "\n", "per_r", "=", "len", "(", "set", "(", "predicted_labels", ")", ".", "intersection", "(", "set", "(", "true_labels", ")", ")", ")", "/", "float", "(", "len", "(", "true_labels", ")", ")", "\n", "r", "+=", "per_r", "\n", "", "", "precision", ",", "recall", "=", "0", ",", "0", "\n", "if", "pred_example_count", ">", "0", ":", "\n", "        ", "precision", "=", "p", "/", "pred_example_count", "\n", "", "if", "gold_example_count", ">", "0", ":", "\n", "        ", "recall", "=", "r", "/", "gold_example_count", "\n", "# avg_elem_per_pred = pred_label_count / pred_example_count", "\n", "", "return", "precision", ",", "recall", ",", "calc_f1", "(", "precision", ",", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.init_universal_logging": [[41, 49], ["list", "logging.basicConfig", "list.append", "list.append", "logging.FileHandler", "logging.StreamHandler"], "function", ["None"], ["", "def", "init_universal_logging", "(", "logfile", "=", "'main.log'", ",", "mode", "=", "'a'", ",", "to_stdout", "=", "True", ")", ":", "\n", "    ", "handlers", "=", "list", "(", ")", "\n", "if", "logfile", "is", "not", "None", ":", "\n", "        ", "handlers", ".", "append", "(", "logging", ".", "FileHandler", "(", "logfile", ",", "mode", "=", "mode", ")", ")", "\n", "", "if", "to_stdout", ":", "\n", "        ", "handlers", ".", "append", "(", "logging", ".", "StreamHandler", "(", ")", ")", "\n", "", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s %(filename)s:%(lineno)s %(levelname)s - %(message)s'", ",", "\n", "datefmt", "=", "'%y-%m-%d %H:%M:%S'", ",", "handlers", "=", "handlers", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.parse_idx_device_args": [[51, 58], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "parse_idx_device_args", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'mlmuf'", ")", "\n", "parser", ".", "add_argument", "(", "'idx'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "nargs", "=", "'?'", ")", "\n", "parser", ".", "add_argument", "(", "'-d'", ",", "type", "=", "int", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.are_words_cap": [[60, 68], ["mstr.split", "w.lower", "w[].islower", "len"], "function", ["None"], ["", "def", "are_words_cap", "(", "mstr", ":", "str", ")", ":", "\n", "    ", "words", "=", "mstr", ".", "split", "(", "' '", ")", "\n", "for", "w", "in", "words", ":", "\n", "        ", "if", "w", ".", "lower", "(", ")", "in", "{", "'the'", ",", "'of'", ",", "'and'", ",", "'a'", ",", "','", "}", ":", "\n", "            ", "continue", "\n", "", "if", "len", "(", "w", ")", ">", "0", "and", "w", "[", "0", "]", ".", "islower", "(", ")", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.get_mention_type": [[70, 76], ["utils.are_words_cap", "mstr.lower"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.are_words_cap"], ["", "def", "get_mention_type", "(", "mstr", ")", ":", "\n", "    ", "if", "mstr", ".", "lower", "(", ")", "in", "pronouns", ":", "\n", "        ", "return", "1", "\n", "", "if", "are_words_cap", "(", "mstr", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "2", "\n", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.TrainConfig.__init__": [[10, 31], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "lr", "=", "1e-5", ",", "batch_size", "=", "32", ",", "w_decay", "=", "0.01", ",", "n_iter", "=", "20", ",", "max_n_ex_types", "=", "10", ",", "\n", "bert_model", "=", "'bert-base-cased'", ",", "eval_interval", "=", "100", ",", "eval_bs", "=", "32", ",", "n_steps", "=", "-", "1", ",", "\n", "save_interval", "=", "20000", ",", "ex_tids", "=", "False", ",", "weighted_loss", "=", "False", ",", "weight_for_origin_label", "=", "-", "1", ",", "\n", "weight_for_mlm", "=", "-", "1", ",", "lr_schedule", "=", "False", ",", "lr_decay", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "w_decay", "=", "w_decay", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "bert_model", "=", "bert_model", "\n", "self", ".", "eval_interval", "=", "eval_interval", "\n", "self", ".", "max_n_ex_types", "=", "max_n_ex_types", "\n", "self", ".", "eval_bs", "=", "eval_bs", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "save_interval", "=", "save_interval", "\n", "self", ".", "ex_tids", "=", "ex_tids", "\n", "self", ".", "weighted_loss", "=", "weighted_loss", "\n", "self", ".", "weight_for_origin_label", "=", "weight_for_origin_label", "\n", "self", ".", "lr_schedule", "=", "lr_schedule", "\n", "self", ".", "weight_for_mlm", "=", "weight_for_mlm", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.WeakBatchLoader.__init__": [[116, 160], ["list", "len", "print", "exp.expdatautils.UfDataBatchLoader", "exp.expdatautils.UfDataBatchLoader", "list.append", "list.append", "list.append", "logging.info", "logging.info", "exp.expdatautils.MyMentionTypeDataBatchLoader", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "BertTokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "el_data_file", ",", "el_extra_label_file", ",", "\n", "open_data_files", ",", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "\n", "batch_size", ",", "max_n_pn_types", ",", "n_steps", ",", "ex_tids", ",", "weight_for_origin_label", ",", "weight_for_mlm", ")", ":", "\n", "        ", "max_seq_len", "=", "128", "\n", "self", ".", "type_id_dict", "=", "type_id_dict", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "# self.el_data_file = el_data_file", "\n", "# self.open_data_files = open_data_files", "\n", "self", ".", "pronoun_mention_file", "=", "pronoun_mention_file", "\n", "self", ".", "pronoun_type_file", "=", "pronoun_type_file", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "states", "=", "list", "(", ")", "\n", "if", "el_data_file", "is", "not", "None", ":", "\n", "            ", "states", ".", "append", "(", "'wiki'", ")", "\n", "", "if", "open_data_files", "is", "not", "None", ":", "\n", "            ", "states", ".", "append", "(", "'open'", ")", "\n", "", "if", "pronoun_mention_file", "is", "not", "None", ":", "\n", "            ", "states", ".", "append", "(", "'pn'", ")", "\n", "", "n_states", "=", "len", "(", "states", ")", "\n", "self", ".", "next_state", "=", "{", "states", "[", "i", "]", ":", "states", "[", "(", "i", "+", "1", ")", "%", "n_states", "]", "for", "i", "in", "range", "(", "n_states", ")", "}", "\n", "print", "(", "self", ".", "next_state", ")", "\n", "\n", "el_extra_label_files", "=", "None", "if", "el_extra_label_file", "is", "None", "else", "[", "el_extra_label_file", "]", "\n", "self", ".", "el_batch_loader", "=", "expdatautils", ".", "UfDataBatchLoader", "(", "\n", "tokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "[", "el_data_file", "]", ",", "el_extra_label_files", ",", "batch_size", ",", "max_seq_len", ",", "\n", "max_n_pn_types", ",", "ex_tids", "=", "ex_tids", ",", "weight_for_original_labels", "=", "weight_for_origin_label", ",", "\n", "weight_for_mlm", "=", "weight_for_mlm", ")", "\n", "self", ".", "open_batch_loader", "=", "expdatautils", ".", "UfDataBatchLoader", "(", "\n", "tokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "open_data_files", ",", "open_extra_label_files", ",", "batch_size", ",", "\n", "max_seq_len", ",", "max_n_pn_types", ",", "ex_tids", "=", "ex_tids", ",", "\n", "weight_for_original_labels", "=", "weight_for_origin_label", ",", "weight_for_mlm", "=", "weight_for_mlm", ")", "\n", "self", ".", "pn_batch_loader", "=", "None", "\n", "use_weighted_loss", "=", "weight_for_origin_label", ">", "0", "\n", "if", "pronoun_mention_file", "is", "not", "None", ":", "\n", "# self.pn_batch_loader = expdatautils.SepMTDataBatchLoader(", "\n", "#     tokenizer, type_id_dict, pronoun_mention_file, pronoun_type_file, batch_size,", "\n", "#     max_n_pn_types, max_seq_len, use_type_logits)", "\n", "            ", "logging", ".", "info", "(", "pronoun_mention_file", ")", "\n", "logging", ".", "info", "(", "pronoun_type_file", ")", "\n", "self", ".", "pn_batch_loader", "=", "expdatautils", ".", "MyMentionTypeDataBatchLoader", "(", "\n", "tokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "batch_size", ",", "\n", "max_n_pn_types", ",", "max_seq_len", ",", "ex_tids", "=", "ex_tids", ",", "\n", "use_weighted_loss", "=", "use_weighted_loss", ",", "weight_for_mlm", "=", "weight_for_mlm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.WeakBatchLoader.__iter__": [[161, 163], ["bertufexp.WeakBatchLoader.gen_batch"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.WeakBatchLoader.gen_batch"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "gen_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.WeakBatchLoader.gen_batch": [[164, 177], ["range", "bertufexp.WeakBatchLoader.el_batch_loader.next_batch", "bertufexp.WeakBatchLoader.open_batch_loader.next_batch", "bertufexp.WeakBatchLoader.pn_batch_loader.next_batch"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.next_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.next_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.next_batch"], ["", "def", "gen_batch", "(", "self", ")", ":", "\n", "        ", "state", "=", "'wiki'", "\n", "for", "i", "in", "range", "(", "self", ".", "n_steps", ")", ":", "\n", "            ", "if", "state", "==", "'wiki'", ":", "\n", "                ", "batch", "=", "self", ".", "el_batch_loader", ".", "next_batch", "(", ")", "\n", "yield", "'wiki'", ",", "batch", "\n", "", "elif", "state", "==", "'open'", ":", "\n", "                ", "batch", "=", "self", ".", "open_batch_loader", ".", "next_batch", "(", ")", "\n", "yield", "'open'", ",", "batch", "\n", "", "elif", "state", "==", "'pn'", ":", "\n", "                ", "batch", "=", "self", ".", "pn_batch_loader", ".", "next_batch", "(", ")", "\n", "yield", "'pn'", ",", "batch", "\n", "", "state", "=", "self", ".", "next_state", "[", "state", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.train_bert_uf": [[33, 113], ["transformers.BertTokenizer.from_pretrained", "utils.datautils.load_vocab_file", "exp.expdatautils.bert_sm_samples_from_json_data", "exp.expdatautils.bert_sm_samples_from_json_data", "exp.expdatautils.bert_sm_samples_from_json_data", "exp.expdatautils.SampleBatchLoader", "exp.expdatautils.SampleBatchLoader", "exp.expdatautils.SampleBatchLoader", "utils.datautils.read_json_objs", "utils.datautils.read_json_objs", "len", "bertuf.BertUF.to", "logging.info", "torch.nn.BCEWithLogitsLoss", "utils.bertutils.get_bert_adam_optim", "logging.info", "logging.info", "list", "models.bertuf.BertUF.from_trained", "logging.info", "models.bertuf.BertUF", "list", "torch.optim.lr_scheduler.MultiplicativeLR", "models.utils.pad_id_seqs", "bertuf.BertUF.", "exp.exputils.onehot_encode_batch", "torch.tensor", "exp.exputils.define_loss", "list.append", "bertutils.get_bert_adam_optim.zero_grad", "exputils.define_loss.backward", "bertutils.get_bert_adam_optim.step", "bertuf.BertUF.named_parameters", "exputils.define_loss.data.cpu().numpy", "sum", "list", "bertuf.BertUF.eval", "exp.exputils.eval_uf", "exp.exputils.eval_uf", "logging.info", "bertuf.BertUF.train", "torch.save", "logging.info", "torch.optim.lr_scheduler.MultiplicativeLR.step", "print", "vars().items", "exputils.define_loss.data.cpu", "bertuf.BertUF.state_dict", "vars"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.read_json_objs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.read_json_objs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.bertutils.get_bert_adam_optim", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.from_trained", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.onehot_encode_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.define_loss", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.eval_uf", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.eval_uf"], ["", "", "def", "train_bert_uf", "(", "tc", ":", "TrainConfig", ",", "type_vocab_file", ",", "train_data_file", ",", "dev_data_file", ",", "test_data_file", ",", "\n", "load_model_file", ",", "save_model_file", ")", ":", "\n", "# bert_model_name = 'bert-base-cased'", "\n", "    ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "tc", ".", "bert_model", ")", "\n", "pad_id", "=", "tokenizer", ".", "pad_token_id", "\n", "type_vocab", ",", "type_id_dict", "=", "datautils", ".", "load_vocab_file", "(", "type_vocab_file", ")", "\n", "\n", "train_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "tokenizer", ",", "type_id_dict", ",", "train_data_file", ")", "\n", "dev_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "tokenizer", ",", "type_id_dict", ",", "dev_data_file", ")", "\n", "test_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "tokenizer", ",", "type_id_dict", ",", "test_data_file", ")", "\n", "\n", "train_batch_iter", "=", "expdatautils", ".", "SampleBatchLoader", "(", "train_samples", ",", "tc", ".", "batch_size", ",", "tc", ".", "n_iter", ",", "n_steps", "=", "tc", ".", "n_steps", ")", "\n", "dev_batch_iter", "=", "expdatautils", ".", "SampleBatchLoader", "(", "dev_samples", ",", "tc", ".", "eval_bs", ",", "1", ")", "\n", "test_batch_iter", "=", "expdatautils", ".", "SampleBatchLoader", "(", "test_samples", ",", "tc", ".", "eval_bs", ",", "1", ")", "\n", "dev_mentions", "=", "datautils", ".", "read_json_objs", "(", "dev_data_file", ")", "\n", "test_mentions", "=", "datautils", ".", "read_json_objs", "(", "test_data_file", ")", "\n", "# dev_mstrs = [m['mention_span'] for m in dev_mentions]", "\n", "# test_mstrs = [m['mention_span'] for m in test_mentions]", "\n", "\n", "n_types", "=", "len", "(", "type_vocab", ")", "\n", "if", "load_model_file", ":", "\n", "        ", "model", "=", "bertuf", ".", "BertUF", ".", "from_trained", "(", "load_model_file", ")", "\n", "logging", ".", "info", "(", "'load model from {}'", ".", "format", "(", "load_model_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "bertuf", ".", "BertUF", "(", "n_types", ",", "pretrained_bert_model", "=", "tc", ".", "bert_model", ")", "\n", "", "model", ".", "to", "(", "tc", ".", "device", ")", "\n", "logging", ".", "info", "(", "model", ".", "__class__", ".", "__name__", ")", "\n", "\n", "loss_obj", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "optimizer", "=", "bertutils", ".", "get_bert_adam_optim", "(", "list", "(", "model", ".", "named_parameters", "(", ")", ")", ",", "learning_rate", "=", "tc", ".", "lr", ",", "w_decay", "=", "tc", ".", "w_decay", ")", "\n", "\n", "lr_scheduler", "=", "None", "\n", "if", "tc", ".", "lr_schedule", ":", "\n", "        ", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiplicativeLR", "(", "optimizer", ",", "lambda", "epoch", ":", "tc", ".", "lr_decay", ")", "\n", "\n", "", "logging", ".", "info", "(", "' '", ".", "join", "(", "[", "'{}={}'", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "vars", "(", "tc", ")", ".", "items", "(", ")", "]", ")", ")", "\n", "logging", ".", "info", "(", "'{} batches, {} steps'", ".", "format", "(", "train_batch_iter", ".", "n_batches", ",", "train_batch_iter", ".", "n_steps", ")", ")", "\n", "step", "=", "0", "\n", "losses", "=", "list", "(", ")", "\n", "best_dev_f1", "=", "0", "\n", "lr_reduced", "=", "False", "\n", "for", "batch", "in", "train_batch_iter", ":", "\n", "        ", "tok_id_seqs", "=", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", "\n", "token_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "tok_id_seqs", ",", "tc", ".", "device", ",", "pad_id", ")", "\n", "logits", "=", "model", "(", "token_id_seqs_tensor", ",", "attn_mask", ")", "\n", "labels", "=", "exputils", ".", "onehot_encode_batch", "(", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", ",", "n_types", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "loss", "=", "exputils", ".", "define_loss", "(", "tc", ".", "device", ",", "loss_obj", ",", "logits", ",", "labels", ")", "\n", "losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "step", "+=", "1", "\n", "\n", "if", "step", "%", "tc", ".", "eval_interval", "==", "0", ":", "\n", "            ", "loss_val", "=", "sum", "(", "losses", ")", "\n", "losses", "=", "list", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "p", ",", "r", ",", "f1", ",", "results", "=", "exputils", ".", "eval_uf", "(", "tc", ".", "device", ",", "model", ",", "type_vocab", ",", "dev_batch_iter", ")", "\n", "pt", ",", "rt", ",", "f1t", ",", "resultst", "=", "exputils", ".", "eval_uf", "(", "tc", ".", "device", ",", "model", ",", "type_vocab", ",", "test_batch_iter", ")", "\n", "# print(step, loss_val, p, r, f1)", "\n", "best_tag", "=", "'*'", "if", "f1", ">", "best_dev_f1", "else", "''", "\n", "logging", ".", "info", "(", "\n", "'i={} loss={:.4f} p={:.4f} r={:.4f} f1={:.4f} '", "\n", "' pt={:.4f} rt={:.4f} f1t={:.4f}{}'", ".", "format", "(", "\n", "step", ",", "loss_val", ",", "p", ",", "r", ",", "f1", ",", "pt", ",", "rt", ",", "f1t", ",", "best_tag", ")", ")", "\n", "if", "f1", ">", "best_dev_f1", "and", "save_model_file", "is", "not", "None", ":", "\n", "                ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_model_file", ")", "\n", "logging", ".", "info", "(", "'model saved to {}'", ".", "format", "(", "save_model_file", ")", ")", "\n", "", "if", "f1", ">", "best_dev_f1", ":", "\n", "                ", "best_dev_f1", "=", "f1", "\n", "", "model", ".", "train", "(", ")", "\n", "if", "f1", ">", "0.47", "and", "not", "lr_reduced", "and", "lr_scheduler", "is", "not", "None", ":", "\n", "                ", "lr_scheduler", ".", "step", "(", ")", "\n", "lr_reduced", "=", "True", "\n", "print", "(", "'lr reduced'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.bertufexp.train_wuf": [[179, 273], ["logging.info", "transformers.BertTokenizer.from_pretrained", "utils.datautils.load_vocab_file", "bertufexp.WeakBatchLoader", "exp.expdatautils.bert_sm_samples_from_json_data", "exp.expdatautils.SampleBatchLoader", "len", "bertuf.BertUF.to", "utils.bertutils.get_bert_adam_optim", "logging.info", "list", "models.bertuf.BertUF.from_trained", "logging.info", "models.bertuf.BertUF", "exp.exputils.WeightedBCELoss", "torch.nn.BCEWithLogitsLoss", "list", "models.utils.pad_id_seqs", "bertuf.BertUF.", "len", "list.append", "bertutils.get_bert_adam_optim.zero_grad", "exputils.define_loss.backward", "bertutils.get_bert_adam_optim.step", "bertuf.BertUF.named_parameters", "torch.zeros", "torch.ones", "enumerate", "exp.exputils.define_loss_partial", "exp.exputils.onehot_encode_batch", "torch.tensor", "exp.exputils.define_loss", "exputils.define_loss.data.cpu().numpy", "sum", "list", "bertuf.BertUF.eval", "exp.exputils.eval_uf", "logging.info", "bertuf.BertUF.train", "zip", "zip", "torch.save", "logging.info", "vars().items", "exputils.define_loss.data.cpu", "bertuf.BertUF.state_dict", "vars"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.bertutils.get_bert_adam_optim", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.from_trained", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.define_loss_partial", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.onehot_encode_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.define_loss", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.eval_uf"], ["", "", "", "def", "train_wuf", "(", "tc", ":", "TrainConfig", ",", "type_vocab_file", ",", "el_data_file", ",", "el_extra_label_file", ",", "open_data_files", ",", "\n", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "dev_data_file", ",", "\n", "load_model_file", ",", "save_model_file_prefix", ")", ":", "\n", "    ", "pad_id", "=", "0", "\n", "# bert_model_name = 'bert-base-cased'", "\n", "# for filename in open_data_files:", "\n", "#     print(filename)", "\n", "logging", ".", "info", "(", "' '", ".", "join", "(", "[", "'{}={}'", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "vars", "(", "tc", ")", ".", "items", "(", ")", "]", ")", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "tc", ".", "bert_model", ")", "\n", "type_vocab", ",", "type_id_dict", "=", "datautils", ".", "load_vocab_file", "(", "type_vocab_file", ")", "\n", "weak_batch_iter", "=", "WeakBatchLoader", "(", "\n", "tokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "el_data_file", ",", "el_extra_label_file", ",", "open_data_files", ",", "\n", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "tc", ".", "batch_size", ",", "tc", ".", "max_n_ex_types", ",", "tc", ".", "n_steps", ",", "\n", "ex_tids", "=", "tc", ".", "ex_tids", ",", "weight_for_origin_label", "=", "tc", ".", "weight_for_origin_label", ",", "weight_for_mlm", "=", "tc", ".", "weight_for_mlm", ")", "\n", "dev_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "tokenizer", ",", "type_id_dict", ",", "dev_data_file", ")", "\n", "dev_batch_iter", "=", "expdatautils", ".", "SampleBatchLoader", "(", "dev_samples", ",", "tc", ".", "eval_bs", ",", "1", ")", "\n", "\n", "n_types", "=", "len", "(", "type_vocab", ")", "\n", "if", "load_model_file", ":", "\n", "        ", "model", "=", "bertuf", ".", "BertUF", ".", "from_trained", "(", "load_model_file", ")", "\n", "logging", ".", "info", "(", "'load model from {}'", ".", "format", "(", "load_model_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "bertuf", ".", "BertUF", "(", "n_types", ",", "pretrained_bert_model", "=", "tc", ".", "bert_model", ")", "\n", "", "model", ".", "to", "(", "tc", ".", "device", ")", "\n", "\n", "if", "tc", ".", "weight_for_origin_label", ">", "0", ":", "\n", "        ", "loss_obj", "=", "exputils", ".", "WeightedBCELoss", "(", ")", "\n", "", "else", ":", "\n", "        ", "loss_obj", "=", "torch", ".", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "optimizer", "=", "bertutils", ".", "get_bert_adam_optim", "(", "list", "(", "model", ".", "named_parameters", "(", ")", ")", ",", "learning_rate", "=", "tc", ".", "lr", ",", "\n", "w_decay", "=", "tc", ".", "w_decay", ")", "\n", "\n", "logging", ".", "info", "(", "loss_obj", ".", "__class__", ")", "\n", "step", "=", "0", "\n", "losses", "=", "list", "(", ")", "\n", "best_dev_f1", "=", "0", "\n", "for", "data_type", ",", "batch", "in", "weak_batch_iter", ":", "\n", "        ", "tok_id_seqs", "=", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", "\n", "labels_batch", "=", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", "\n", "# print(labels_batch)", "\n", "# if step > 3:", "\n", "#     exit()", "\n", "label_weights_batch", "=", "None", "\n", "if", "tc", ".", "weight_for_origin_label", ">", "0", ":", "\n", "            ", "label_weights_batch", "=", "[", "x", "[", "3", "]", "for", "x", "in", "batch", "]", "\n", "\n", "", "token_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "tok_id_seqs", ",", "tc", ".", "device", ",", "pad_id", ")", "\n", "\n", "logits", "=", "model", "(", "token_id_seqs_tensor", ",", "attn_mask", ")", "\n", "data_type_tmp", "=", "data_type", "\n", "cur_batch_size", "=", "len", "(", "batch", ")", "\n", "if", "el_extra_label_file", "is", "not", "None", "and", "data_type", "==", "'wiki'", ":", "\n", "            ", "data_type_tmp", "=", "'open'", "\n", "", "if", "tc", ".", "weight_for_origin_label", ">", "0", ":", "\n", "            ", "labels_tensor", "=", "torch", ".", "zeros", "(", "(", "cur_batch_size", ",", "n_types", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "weights_tensor", "=", "torch", ".", "ones", "(", "(", "cur_batch_size", ",", "n_types", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "for", "i", ",", "(", "labels", ",", "weights", ")", "in", "enumerate", "(", "zip", "(", "labels_batch", ",", "label_weights_batch", ")", ")", ":", "\n", "                ", "for", "tid", ",", "weight", "in", "zip", "(", "labels", ",", "weights", ")", ":", "\n", "                    ", "labels_tensor", "[", "i", "]", "[", "tid", "]", "=", "1", "\n", "weights_tensor", "[", "i", "]", "[", "tid", "]", "=", "weight", "\n", "", "", "loss", "=", "exputils", ".", "define_loss_partial", "(", "tc", ".", "device", ",", "loss_obj", ",", "logits", ",", "labels_tensor", ",", "weights_tensor", ")", "\n", "", "else", ":", "\n", "            ", "labels", "=", "exputils", ".", "onehot_encode_batch", "(", "labels_batch", ",", "n_types", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "loss", "=", "exputils", ".", "define_loss", "(", "tc", ".", "device", ",", "loss_obj", ",", "logits", ",", "labels", ",", "data_type_tmp", ")", "\n", "", "if", "loss", "is", "None", ":", "\n", "            ", "continue", "\n", "\n", "", "losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "step", "+=", "1", "\n", "# print(step)", "\n", "if", "step", "%", "tc", ".", "eval_interval", "==", "0", ":", "\n", "            ", "loss_val", "=", "sum", "(", "losses", ")", "\n", "losses", "=", "list", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "p", ",", "r", ",", "f1", ",", "results", "=", "exputils", ".", "eval_uf", "(", "tc", ".", "device", ",", "model", ",", "type_vocab", ",", "dev_batch_iter", ")", "\n", "# print(step, loss_val, p, r, f1)", "\n", "best_tag", "=", "'*'", "if", "f1", ">", "best_dev_f1", "else", "''", "\n", "logging", ".", "info", "(", "\n", "'i={} loss={:.6f} p={:.6f} r={:.6f} f1={:.6f}{}'", ".", "format", "(", "step", ",", "loss_val", ",", "p", ",", "r", ",", "f1", ",", "best_tag", ")", ")", "\n", "if", "step", "%", "tc", ".", "save_interval", "==", "0", "and", "save_model_file_prefix", "is", "not", "None", ":", "\n", "                ", "file_name", "=", "f'{save_model_file_prefix}-{step}.pth'", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "file_name", ")", "\n", "logging", ".", "info", "(", "'model saved to {}'", ".", "format", "(", "file_name", ")", ")", "\n", "", "if", "f1", ">", "best_dev_f1", ":", "\n", "                ", "best_dev_f1", "=", "f1", "\n", "", "model", ".", "train", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.UfMentionLabelLoader.__init__": [[8, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mention_file", ",", "extra_label_file", ",", "yield_id", "=", "False", ")", ":", "\n", "        ", "self", ".", "mention_file", "=", "mention_file", "\n", "self", ".", "extra_label_file", "=", "extra_label_file", "\n", "self", ".", "yield_id", "=", "yield_id", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.UfMentionLabelLoader.__iter__": [[13, 15], ["expdatautils.UfMentionLabelLoader.mention_label_gen"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionLabelLoader.mention_label_gen"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mention_label_gen", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.UfMentionLabelLoader.mention_label_gen": [[16, 47], ["open", "enumerate", "open.close", "open", "json.loads", "fl.close", "next", "json.loads", "fl.close"], "methods", ["None"], ["", "def", "mention_label_gen", "(", "self", ")", ":", "\n", "        ", "fm", "=", "open", "(", "self", ".", "mention_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "fl", "=", "open", "(", "self", ".", "extra_label_file", ",", "encoding", "=", "'utf-8'", ")", "if", "self", ".", "extra_label_file", "is", "not", "None", "else", "None", "\n", "cur_label_obj", "=", "None", "\n", "for", "i", ",", "line_m", "in", "enumerate", "(", "fm", ")", ":", "\n", "            ", "mention", "=", "json", ".", "loads", "(", "line_m", ")", "\n", "if", "self", ".", "extra_label_file", "is", "None", ":", "\n", "                ", "if", "self", ".", "yield_id", ":", "\n", "                    ", "yield", "i", ",", "mention", ",", "None", "\n", "", "else", ":", "\n", "                    ", "yield", "mention", ",", "None", "\n", "", "", "else", ":", "\n", "                ", "if", "(", "cur_label_obj", "is", "None", "or", "cur_label_obj", "[", "'id'", "]", "<", "i", ")", "and", "fl", "is", "not", "None", ":", "\n", "                    ", "try", ":", "\n", "                        ", "line_l", "=", "next", "(", "fl", ")", "\n", "cur_label_obj", "=", "json", ".", "loads", "(", "line_l", ")", "\n", "", "except", "StopIteration", ":", "\n", "                        ", "fl", ".", "close", "(", ")", "\n", "fl", "=", "None", "\n", "", "", "r_label_obj", "=", "None", "\n", "if", "cur_label_obj", "[", "'id'", "]", "==", "i", ":", "\n", "                    ", "r_label_obj", "=", "cur_label_obj", "\n", "", "else", ":", "\n", "                    ", "assert", "cur_label_obj", "[", "'id'", "]", ">", "i", "\n", "", "if", "self", ".", "yield_id", ":", "\n", "                    ", "yield", "i", ",", "mention", ",", "r_label_obj", "\n", "", "else", ":", "\n", "                    ", "yield", "mention", ",", "r_label_obj", "\n", "", "", "", "fm", ".", "close", "(", ")", "\n", "if", "fl", "is", "not", "None", ":", "\n", "            ", "fl", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SimpleUFBertBatchLoader.__init__": [[50, 59], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "mention_files", ",", "label_files", ",", "max_seq_len", ",", "batch_size", ",", "yield_id", "=", "False", ",", "loop", "=", "True", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "mention_files", "=", "mention_files", "\n", "self", ".", "label_files", "=", "label_files", "\n", "self", ".", "file_idx", "=", "0", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "yield_id", "=", "yield_id", "\n", "self", ".", "loop", "=", "loop", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SimpleUFBertBatchLoader.__iter__": [[60, 62], ["expdatautils.SimpleUFBertBatchLoader.next_batch"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.next_batch"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "next_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SimpleUFBertBatchLoader.next_batch": [[63, 92], ["iter", "list", "expdatautils.UfMentionLabelLoader", "expdatautils.uf_mention_to_sm_bert_sample", "next", "next", "list.append", "iter", "len", "list", "len", "expdatautils.UfMentionLabelLoader"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.uf_mention_to_sm_bert_sample"], ["", "def", "next_batch", "(", "self", ")", ":", "\n", "        ", "ml_loader", "=", "iter", "(", "UfMentionLabelLoader", "(", "\n", "self", ".", "mention_files", "[", "self", ".", "file_idx", "]", ",", "self", ".", "label_files", "[", "self", ".", "file_idx", "]", ",", "yield_id", "=", "self", ".", "yield_id", ")", ")", "\n", "\n", "batch", "=", "list", "(", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "mid", "=", "None", "\n", "if", "self", ".", "yield_id", ":", "\n", "                    ", "mid", ",", "mention", ",", "lobj", "=", "next", "(", "ml_loader", ")", "\n", "", "else", ":", "\n", "                    ", "mention", ",", "lobj", "=", "next", "(", "ml_loader", ")", "\n", "# print(lobj)", "\n", "# exit()", "\n", "", "tok_id_seq", "=", "uf_mention_to_sm_bert_sample", "(", "self", ".", "tokenizer", ",", "mention", ",", "self", ".", "max_seq_len", ")", "\n", "if", "tok_id_seq", "is", "not", "None", ":", "\n", "                    ", "if", "self", ".", "yield_id", ":", "\n", "                        ", "sample", "=", "mid", ",", "tok_id_seq", ",", "mention", "[", "'y_str'", "]", ",", "mention", ",", "lobj", "\n", "", "else", ":", "\n", "                        ", "sample", "=", "tok_id_seq", ",", "mention", "[", "'y_str'", "]", ",", "lobj", "\n", "", "batch", ".", "append", "(", "sample", ")", "\n", "if", "len", "(", "batch", ")", ">=", "self", ".", "batch_size", ":", "\n", "                        ", "yield", "batch", "\n", "batch", "=", "list", "(", ")", "\n", "", "", "", "except", "StopIteration", ":", "\n", "                ", "self", ".", "file_idx", "=", "(", "self", ".", "file_idx", "+", "1", ")", "%", "len", "(", "self", ".", "mention_files", ")", "\n", "if", "self", ".", "file_idx", "==", "0", "and", "not", "self", ".", "loop", ":", "\n", "                    ", "break", "\n", "", "ml_loader", "=", "iter", "(", "UfMentionLabelLoader", "(", "self", ".", "mention_files", "[", "self", ".", "file_idx", "]", ",", "None", ",", "yield_id", "=", "self", ".", "yield_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SampleBatchLoader.__init__": [[95, 105], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "samples", ",", "batch_size", ",", "n_iter", ",", "shuffle", "=", "False", ",", "n_steps", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "samples", "=", "samples", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "n_samples", "=", "len", "(", "self", ".", "samples", ")", "\n", "self", ".", "n_batches", "=", "(", "self", ".", "n_samples", "+", "batch_size", "-", "1", ")", "//", "batch_size", "\n", "self", ".", "n_steps", "=", "n_iter", "*", "self", ".", "n_batches", "\n", "if", "n_steps", ">", "0", ":", "\n", "            ", "self", ".", "n_steps", "=", "n_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SampleBatchLoader.batch_at": [[106, 110], ["min"], "methods", ["None"], ["", "", "def", "batch_at", "(", "self", ",", "batch_idx", ")", ":", "\n", "        ", "batch_idx", "=", "batch_idx", "%", "self", ".", "n_batches", "\n", "batch_beg", ",", "batch_end", "=", "batch_idx", "*", "self", ".", "batch_size", ",", "min", "(", "(", "batch_idx", "+", "1", ")", "*", "self", ".", "batch_size", ",", "self", ".", "n_samples", ")", "\n", "return", "self", ".", "samples", "[", "batch_beg", ":", "batch_end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SampleBatchLoader.__iter__": [[111, 113], ["expdatautils.SampleBatchLoader.batch_iter"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SampleBatchLoader.batch_iter"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_iter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.SampleBatchLoader.batch_iter": [[114, 122], ["range", "min", "random.shuffle"], "methods", ["None"], ["", "def", "batch_iter", "(", "self", ")", ":", "\n", "        ", "for", "step", "in", "range", "(", "self", ".", "n_steps", ")", ":", "\n", "            ", "batch_idx", "=", "step", "%", "self", ".", "n_batches", "\n", "batch_beg", ",", "batch_end", "=", "batch_idx", "*", "self", ".", "batch_size", ",", "min", "(", "(", "batch_idx", "+", "1", ")", "*", "self", ".", "batch_size", ",", "self", ".", "n_samples", ")", "\n", "batch", "=", "self", ".", "samples", "[", "batch_beg", ":", "batch_end", "]", "\n", "if", "batch_beg", "==", "self", ".", "n_samples", "and", "self", ".", "shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "self", ".", "samples", ")", "\n", "", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.LabelReader.__init__": [[171, 174], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "label_file", ")", ":", "\n", "        ", "self", ".", "f", "=", "open", "(", "label_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "self", ".", "cur_label_obj", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.LabelReader.labels_for": [[175, 193], ["next", "json.loads", "expdatautils.LabelReader.f.close"], "methods", ["None"], ["", "def", "labels_for", "(", "self", ",", "mention_id", ")", ":", "\n", "        ", "if", "self", ".", "f", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "while", "True", ":", "\n", "            ", "if", "self", ".", "cur_label_obj", "is", "not", "None", ":", "\n", "                ", "cur_id", "=", "self", ".", "cur_label_obj", "[", "'id'", "]", "\n", "if", "cur_id", "==", "mention_id", ":", "\n", "                    ", "return", "self", ".", "cur_label_obj", "\n", "", "if", "cur_id", ">", "mention_id", ":", "\n", "                    ", "return", "None", "\n", "", "", "try", ":", "\n", "                ", "line", "=", "next", "(", "self", ".", "f", ")", "\n", "self", ".", "cur_label_obj", "=", "json", ".", "loads", "(", "line", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "self", ".", "f", ".", "close", "(", ")", "\n", "self", ".", "f", "=", "None", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.UfDataBatchLoader.__init__": [[217, 241], ["len", "expdatautils.LabelReader", "logging.info"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "mention_files", ",", "extra_label_files", ",", "\n", "batch_size", ",", "max_seq_len", ",", "max_n_ex_types", ",", "ex_tids", "=", "False", ",", "weight_for_original_labels", "=", "1", ",", "\n", "weight_for_mlm", "=", "1", ")", ":", "\n", "        ", "self", ".", "mention_files", "=", "mention_files", "\n", "self", ".", "extra_label_files", "=", "extra_label_files", "\n", "self", ".", "f", "=", "None", "\n", "self", ".", "file_idx", "=", "0", "\n", "self", ".", "n_files", "=", "len", "(", "self", ".", "mention_files", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "type_vocab", "=", "type_vocab", "\n", "self", ".", "type_id_dict", "=", "type_id_dict", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "ex_label_reader", "=", "None", "\n", "if", "extra_label_files", "is", "not", "None", ":", "\n", "            ", "self", ".", "ex_label_reader", "=", "LabelReader", "(", "extra_label_files", "[", "0", "]", ")", "\n", "# print('use labels {}'.format(self.extra_label_files[0]))", "\n", "logging", ".", "info", "(", "'use labels {}'", ".", "format", "(", "self", ".", "extra_label_files", "[", "0", "]", ")", ")", "\n", "", "self", ".", "mention_id", "=", "0", "\n", "self", ".", "max_n_ex_types", "=", "max_n_ex_types", "\n", "self", ".", "ex_tids", "=", "ex_tids", "\n", "self", ".", "is_first_file", "=", "True", "\n", "self", ".", "weight_for_original_labels", "=", "weight_for_original_labels", "\n", "self", ".", "weight_for_mlm", "=", "weight_for_mlm", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.UfDataBatchLoader.next_batch": [[242, 289], ["list", "open", "logging.info", "len", "next", "json.loads", "expdatautils.UfDataBatchLoader.ex_label_reader.labels_for", "expdatautils.uf_mention_to_sm_bert_sample", "list.append", "expdatautils.UfDataBatchLoader.f.close", "open", "logging.info", "min", "expdatautils.get_labels_with_weights", "expdatautils.LabelReader", "logging.info", "len"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.LabelReader.labels_for", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.uf_mention_to_sm_bert_sample", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.get_labels_with_weights"], ["", "def", "next_batch", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "f", "is", "None", ":", "\n", "            ", "self", ".", "f", "=", "open", "(", "self", ".", "mention_files", "[", "self", ".", "file_idx", "]", ",", "encoding", "=", "'utf-8'", ")", "\n", "# print('use {}'.format(self.mention_files[self.file_idx]))", "\n", "logging", ".", "info", "(", "'use {}'", ".", "format", "(", "self", ".", "mention_files", "[", "self", ".", "file_idx", "]", ")", ")", "\n", "\n", "", "batch", "=", "list", "(", ")", "\n", "while", "len", "(", "batch", ")", "<", "self", ".", "batch_size", ":", "\n", "            ", "try", ":", "\n", "                ", "line", "=", "next", "(", "self", ".", "f", ")", "\n", "x", "=", "json", ".", "loads", "(", "line", ")", "\n", "ex_labels", "=", "None", "\n", "if", "self", ".", "ex_label_reader", "is", "not", "None", ":", "\n", "                    ", "ex_label_obj", "=", "self", ".", "ex_label_reader", ".", "labels_for", "(", "self", ".", "mention_id", ")", "\n", "if", "ex_label_obj", "is", "not", "None", ":", "\n", "# ex_labels = ex_label_obj['types']", "\n", "                        ", "ex_labels", "=", "ex_label_obj", "[", "'tids'", "]", "if", "self", ".", "ex_tids", "else", "ex_label_obj", "[", "'types'", "]", "\n", "n_tmp", "=", "min", "(", "len", "(", "ex_labels", ")", ",", "self", ".", "max_n_ex_types", ")", "\n", "ex_labels", "=", "ex_labels", "[", ":", "n_tmp", "]", "\n", "\n", "# print(x)", "\n", "# print(ex_label_obj)", "\n", "", "", "sample", "=", "None", "\n", "if", "ex_labels", "is", "not", "None", "or", "self", ".", "ex_label_reader", "is", "None", ":", "\n", "                    ", "token_id_seq", "=", "uf_mention_to_sm_bert_sample", "(", "self", ".", "tokenizer", ",", "x", ",", "self", ".", "max_seq_len", ")", "\n", "if", "token_id_seq", "is", "not", "None", ":", "\n", "                        ", "tids", ",", "weights", "=", "get_labels_with_weights", "(", "\n", "self", ".", "type_id_dict", ",", "x", "[", "'y_str'", "]", ",", "ex_labels", ",", "self", ".", "ex_tids", ",", "\n", "weight_for_original", "=", "self", ".", "weight_for_original_labels", ",", "\n", "weight_for_mlm", "=", "self", ".", "weight_for_mlm", ")", "\n", "sample", "=", "(", "-", "1", ",", "token_id_seq", ",", "tids", ",", "weights", ")", "\n", "", "", "if", "sample", "is", "not", "None", ":", "\n", "                    ", "batch", ".", "append", "(", "sample", ")", "\n", "", "self", ".", "mention_id", "+=", "1", "\n", "", "except", "StopIteration", ":", "\n", "                ", "self", ".", "f", ".", "close", "(", ")", "\n", "self", ".", "is_first_file", "=", "False", "\n", "self", ".", "file_idx", "=", "(", "self", ".", "file_idx", "+", "1", ")", "%", "self", ".", "n_files", "\n", "self", ".", "f", "=", "open", "(", "self", ".", "mention_files", "[", "self", ".", "file_idx", "]", ",", "encoding", "=", "'utf-8'", ")", "\n", "# print('use {}'.format(self.mention_files[self.file_idx]))", "\n", "logging", ".", "info", "(", "'use {}'", ".", "format", "(", "self", ".", "mention_files", "[", "self", ".", "file_idx", "]", ")", ")", "\n", "self", ".", "mention_id", "=", "0", "\n", "if", "self", ".", "extra_label_files", "is", "not", "None", ":", "\n", "                    ", "self", ".", "ex_label_reader", "=", "LabelReader", "(", "self", ".", "extra_label_files", "[", "self", ".", "file_idx", "]", ")", "\n", "# print('use labels {}'.format(self.extra_label_files[self.file_idx]))", "\n", "logging", ".", "info", "(", "'use labels {}'", ".", "format", "(", "self", ".", "extra_label_files", "[", "self", ".", "file_idx", "]", ")", ")", "\n", "", "", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionLabelLoader.__init__": [[292, 295], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mention_file", ",", "label_file", ")", ":", "\n", "        ", "self", ".", "mention_file", "=", "mention_file", "\n", "self", ".", "label_file", "=", "label_file", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionLabelLoader.__iter__": [[296, 298], ["expdatautils.MyMentionLabelLoader.mention_label_gen"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionLabelLoader.mention_label_gen"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mention_label_gen", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionLabelLoader.mention_label_gen": [[299, 326], ["open", "open", "enumerate", "open.close", "json.loads", "open.close", "next", "json.loads", "print", "print", "print", "open.close"], "methods", ["None"], ["", "def", "mention_label_gen", "(", "self", ")", ":", "\n", "        ", "fm", "=", "open", "(", "self", ".", "mention_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "fl", "=", "open", "(", "self", ".", "label_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "cur_label_obj", "=", "None", "\n", "for", "i", ",", "line_m", "in", "enumerate", "(", "fm", ")", ":", "\n", "            ", "mention", "=", "json", ".", "loads", "(", "line_m", ")", "\n", "mention_id", "=", "mention", "[", "'id'", "]", "\n", "if", "(", "cur_label_obj", "is", "None", "or", "cur_label_obj", "[", "'id'", "]", "<", "mention_id", ")", "and", "fl", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "line_l", "=", "next", "(", "fl", ")", "\n", "cur_label_obj", "=", "json", ".", "loads", "(", "line_l", ")", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "fl", ".", "close", "(", ")", "\n", "fl", "=", "None", "\n", "break", "\n", "", "", "if", "cur_label_obj", "[", "'id'", "]", "==", "mention_id", ":", "\n", "                ", "yield", "mention", ",", "cur_label_obj", "\n", "", "else", ":", "\n", "                ", "if", "cur_label_obj", "[", "'id'", "]", "<", "mention_id", ":", "\n", "                    ", "print", "(", "i", ",", "mention", ")", "\n", "print", "(", "cur_label_obj", ")", "\n", "print", "(", ")", "\n", "", "assert", "cur_label_obj", "[", "'id'", "]", ">", "mention_id", "\n", "yield", "mention", ",", "None", "\n", "", "", "fm", ".", "close", "(", ")", "\n", "if", "fl", "is", "not", "None", ":", "\n", "            ", "fl", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionTypeDataBatchLoader.__init__": [[340, 358], ["iter", "expdatautils.MyMentionLabelLoader"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "type_vocab", ",", "type_id_dict", ",", "mention_file", ",", "type_file", ",", "batch_size", ",", "\n", "max_n_types", ",", "max_seq_len", ",", "ex_tids", "=", "False", ",", "use_weighted_loss", "=", "False", ",", "weight_for_mlm", "=", "1", ")", ":", "\n", "        ", "self", ".", "mention_file", "=", "mention_file", "\n", "self", ".", "type_file", "=", "type_file", "\n", "self", ".", "type_vocab", "=", "type_vocab", "\n", "self", ".", "mention_file", "=", "mention_file", "\n", "self", ".", "label_file", "=", "type_file", "\n", "self", ".", "ml_loader", "=", "iter", "(", "MyMentionLabelLoader", "(", "mention_file", ",", "type_file", ")", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "type_id_dict", "=", "type_id_dict", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "max_n_types", "=", "max_n_types", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "rr_state", "=", "0", "\n", "self", ".", "ex_tids", "=", "ex_tids", "\n", "self", ".", "person_type_id", "=", "self", ".", "type_id_dict", "[", "'person'", "]", "\n", "self", ".", "use_weighted_loss", "=", "use_weighted_loss", "\n", "self", ".", "weight_for_mlm", "=", "weight_for_mlm", "if", "weight_for_mlm", ">", "0", "else", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.MyMentionTypeDataBatchLoader.next_batch": [[359, 401], ["list", "len", "next", "expdatautils.bert_sm_seq_from_my_mention", "len", "iter", "mstr.lower", "type_labels.append", "type_labels.append", "list.append", "list.append", "expdatautils.MyMentionLabelLoader", "range", "len"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_seq_from_my_mention"], ["", "def", "next_batch", "(", "self", ")", ":", "\n", "        ", "batch", "=", "list", "(", ")", "\n", "# for i, (mention, lobj) in enumerate(self.ml_loader):", "\n", "while", "len", "(", "batch", ")", "<", "self", ".", "batch_size", ":", "\n", "            ", "try", ":", "\n", "                ", "mention", ",", "lobj", "=", "next", "(", "self", ".", "ml_loader", ")", "\n", "if", "lobj", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "type_labels", "=", "lobj", "[", "'tids'", "]", "if", "self", ".", "ex_tids", "else", "lobj", "[", "'types'", "]", "\n", "if", "len", "(", "type_labels", ")", ">", "self", ".", "max_n_types", ":", "\n", "                    ", "type_labels", "=", "type_labels", "[", ":", "self", ".", "max_n_types", "]", "\n", "", "if", "type_labels", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "pbeg", ",", "pend", "=", "mention", "[", "'span'", "]", "\n", "mstr", "=", "mention", "[", "'text'", "]", "[", "pbeg", ":", "pend", "]", "\n", "if", "mstr", ".", "lower", "(", ")", "in", "utils", ".", "person_pronouns", "and", "'person'", "not", "in", "type_labels", ":", "\n", "                    ", "if", "self", ".", "ex_tids", ":", "\n", "                        ", "type_labels", ".", "append", "(", "self", ".", "person_type_id", ")", "\n", "", "else", ":", "\n", "                        ", "type_labels", ".", "append", "(", "'person'", ")", "\n", "\n", "", "", "if", "not", "self", ".", "ex_tids", ":", "\n", "                    ", "type_labels", "=", "[", "self", ".", "type_id_dict", "[", "t", "]", "for", "t", "in", "type_labels", "]", "\n", "\n", "", "token_id_seq", "=", "bert_sm_seq_from_my_mention", "(", "self", ".", "tokenizer", ",", "mention", ",", "self", ".", "max_seq_len", ")", "\n", "if", "token_id_seq", "is", "not", "None", ":", "\n", "                    ", "if", "self", ".", "use_weighted_loss", ":", "\n", "                        ", "weights", "=", "[", "self", ".", "weight_for_mlm", "for", "i", "in", "range", "(", "len", "(", "type_labels", ")", ")", "]", "\n", "# print(self.tokenizer.convert_ids_to_tokens(token_id_seq))", "\n", "# print([self.type_vocab[tid] for tid in type_labels])", "\n", "# print(weights)", "\n", "# exit()", "\n", "batch", ".", "append", "(", "(", "mention", "[", "'id'", "]", ",", "token_id_seq", ",", "type_labels", ",", "weights", ")", ")", "\n", "", "else", ":", "\n", "                        ", "batch", ".", "append", "(", "(", "mention", "[", "'id'", "]", ",", "token_id_seq", ",", "type_labels", ")", ")", "\n", "# if sample is not None:", "\n", "#     batch.append(sample)", "\n", "", "", "", "except", "StopIteration", ":", "\n", "                ", "self", ".", "ml_loader", "=", "iter", "(", "MyMentionLabelLoader", "(", "self", ".", "mention_file", ",", "self", ".", "type_file", ")", ")", "\n", "", "", "return", "batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.get_bert_sep_token_seq": [[124, 141], ["len", "len", "max", "len", "len", "len", "len", "min", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "get_bert_sep_token_seq", "(", "ltokens", ",", "rtokens", ",", "mstr_tokens", ",", "second_seg_tokens", ",", "max_seq_len", ",", "discard_too_long", ")", ":", "\n", "    ", "seq_len", "=", "len", "(", "ltokens", ")", "+", "len", "(", "rtokens", ")", "+", "len", "(", "mstr_tokens", ")", "+", "len", "(", "second_seg_tokens", ")", "+", "3", "\n", "if", "seq_len", ">", "max_seq_len", ":", "\n", "        ", "if", "discard_too_long", ":", "\n", "            ", "return", "None", "\n", "", "l_ex", "=", "seq_len", "-", "max_seq_len", "\n", "rtokens", "=", "rtokens", "[", ":", "max", "(", "0", ",", "len", "(", "rtokens", ")", "-", "l_ex", ")", "]", "\n", "l_ex", "=", "len", "(", "ltokens", ")", "+", "len", "(", "rtokens", ")", "+", "len", "(", "mstr_tokens", ")", "+", "len", "(", "second_seg_tokens", ")", "+", "3", "-", "max_seq_len", "\n", "if", "l_ex", ">", "0", ":", "\n", "            ", "ltokens", "=", "ltokens", "[", "min", "(", "l_ex", ",", "len", "(", "ltokens", ")", "-", "1", ")", ":", "]", "\n", "", "l_ex", "=", "len", "(", "ltokens", ")", "+", "len", "(", "rtokens", ")", "+", "len", "(", "mstr_tokens", ")", "+", "len", "(", "second_seg_tokens", ")", "+", "3", "-", "max_seq_len", "\n", "if", "l_ex", ">", "0", ":", "\n", "            ", "mstr_tokens", "=", "[", "]", "\n", "second_seg_tokens", "=", "second_seg_tokens", "[", ":", "100", "]", "\n", "", "", "assert", "len", "(", "ltokens", ")", "+", "len", "(", "rtokens", ")", "+", "len", "(", "mstr_tokens", ")", "+", "len", "(", "second_seg_tokens", ")", "+", "3", "<=", "max_seq_len", "\n", "token_seq", "=", "[", "'[CLS]'", "]", "+", "ltokens", "+", "mstr_tokens", "+", "rtokens", "+", "[", "'[SEP]'", "]", "+", "second_seg_tokens", "+", "[", "'[SEP]'", "]", "\n", "return", "token_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.uf_mention_to_sm_bert_sample": [[143, 152], ["tokenizer.tokenize", "expdatautils.get_bert_sep_token_seq", "tokenizer.convert_tokens_to_ids", "tokenizer.tokenize", "tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.get_bert_sep_token_seq"], ["", "def", "uf_mention_to_sm_bert_sample", "(", "tokenizer", ",", "mention", ",", "max_seq_len", ",", "discard_too_long", "=", "True", ")", ":", "\n", "    ", "lcxt", ",", "rcxt", "=", "' '", ".", "join", "(", "mention", "[", "'left_context_token'", "]", ")", ",", "' '", ".", "join", "(", "mention", "[", "'right_context_token'", "]", ")", "\n", "mstr", "=", "mention", "[", "'mention_span'", "]", "\n", "\n", "ltokens", ",", "rtokens", "=", "tokenizer", ".", "tokenize", "(", "lcxt", ")", ",", "tokenizer", ".", "tokenize", "(", "rcxt", ")", "\n", "mstr_tokens", "=", "tokenizer", ".", "tokenize", "(", "mstr", ")", "\n", "token_seq", "=", "get_bert_sep_token_seq", "(", "ltokens", ",", "rtokens", ",", "mstr_tokens", ",", "mstr_tokens", ",", "max_seq_len", ",", "discard_too_long", ")", "\n", "token_id_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "token_seq", ")", "\n", "return", "token_id_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data": [[154, 168], ["list", "open", "enumerate", "open.close", "json.loads", "expdatautils.uf_mention_to_sm_bert_sample", "list.append", "len"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.uf_mention_to_sm_bert_sample"], ["", "def", "bert_sm_samples_from_json_data", "(", "\n", "tokenizer", ",", "type_id_dict", ",", "json_data_file", ",", "max_seq_len", "=", "128", ",", "n_sample_limit", "=", "-", "1", ")", ":", "\n", "    ", "samples", "=", "list", "(", ")", "\n", "f", "=", "open", "(", "json_data_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "        ", "x", "=", "json", ".", "loads", "(", "line", ")", "\n", "token_id_seq", "=", "uf_mention_to_sm_bert_sample", "(", "tokenizer", ",", "x", ",", "max_seq_len", ",", "discard_too_long", "=", "False", ")", "\n", "\n", "type_ids", "=", "[", "type_id_dict", "[", "t", "]", "for", "t", "in", "x", "[", "'y_str'", "]", "]", "\n", "samples", ".", "append", "(", "(", "i", ",", "token_id_seq", ",", "type_ids", ")", ")", "\n", "if", "n_sample_limit", ">", "0", "and", "len", "(", "samples", ")", ">", "n_sample_limit", ":", "\n", "            ", "break", "\n", "", "", "f", ".", "close", "(", ")", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.get_labels_with_weights": [[195, 214], ["enumerate", "type_id_dict.get", "tids.append", "type_weights.append"], "function", ["None"], ["", "", "", "", "def", "get_labels_with_weights", "(", "\n", "type_id_dict", ",", "orignal_labels", ",", "ex_labels", ",", "ex_label_is_tids", ",", "weight_for_original", ",", "weight_for_mlm", ")", ":", "\n", "    ", "if", "weight_for_mlm", "<", "0", ":", "\n", "        ", "weight_for_mlm", "=", "1.0", "\n", "\n", "", "tids", "=", "[", "type_id_dict", ".", "get", "(", "t", ",", "-", "1", ")", "for", "t", "in", "orignal_labels", "]", "\n", "tids", "=", "[", "tid", "for", "tid", "in", "tids", "if", "tid", ">", "-", "1", "]", "\n", "type_weights", "=", "[", "weight_for_original", "for", "_", "in", "tids", "]", "\n", "\n", "if", "ex_labels", "is", "None", ":", "\n", "        ", "return", "tids", ",", "type_weights", "\n", "\n", "", "for", "i", ",", "label", "in", "enumerate", "(", "ex_labels", ")", ":", "\n", "        ", "tid", "=", "label", "if", "ex_label_is_tids", "else", "type_id_dict", "[", "label", "]", "\n", "if", "tid", "not", "in", "tids", ":", "\n", "            ", "tids", ".", "append", "(", "tid", ")", "\n", "type_weights", ".", "append", "(", "weight_for_mlm", ")", "\n", "\n", "", "", "return", "tids", ",", "type_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_seq_from_my_mention": [[328, 337], ["tokenizer.convert_tokens_to_ids", "len", "tokenizer.tokenize", "tokenizer.tokenize"], "function", ["None"], ["", "", "", "def", "bert_sm_seq_from_my_mention", "(", "tokenizer", ",", "mention", ",", "max_seq_len", ")", ":", "\n", "    ", "text", "=", "mention", "[", "'text'", "]", "\n", "bp", ",", "ep", "=", "mention", "[", "'span'", "]", "\n", "mstr", "=", "text", "[", "bp", ":", "ep", "]", "\n", "tokens", "=", "[", "'[CLS]'", "]", "+", "tokenizer", ".", "tokenize", "(", "text", ")", "+", "[", "'[SEP]'", "]", "+", "tokenizer", ".", "tokenize", "(", "mstr", ")", "+", "[", "'[SEP]'", "]", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_len", ":", "\n", "        ", "return", "None", "\n", "", "token_id_seq", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "return", "token_id_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.pattern_mention_sample_for_uf_mention": [[11, 30], ["tokenizer.tokenize", "token_id_seq.index", "mstr.split", "tokenizer.tokenize", "len", "len", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "len", "words[].lower", "mstr[].lower", "tokenizer.tokenize"], "function", ["None"], ["def", "pattern_mention_sample_for_uf_mention", "(", "tokenizer", ":", "BertTokenizer", ",", "mention", ",", "pattern_str", ",", "max_seq_len", ",", "stopwords", "=", "None", ")", ":", "\n", "    ", "pattern_token_seq", "=", "tokenizer", ".", "tokenize", "(", "pattern_str", ")", "\n", "lcxt_tokens", "=", "mention", "[", "'left_context_token'", "]", "\n", "left_cxt", ",", "right_cxt", "=", "' '", ".", "join", "(", "lcxt_tokens", ")", ",", "' '", ".", "join", "(", "mention", "[", "'right_context_token'", "]", ")", "\n", "mstr", "=", "mention", "[", "'mention_span'", "]", "\n", "if", "stopwords", "is", "not", "None", "and", "len", "(", "lcxt_tokens", ")", "==", "0", ":", "\n", "        ", "words", "=", "mstr", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "words", ")", ">", "0", "and", "words", "[", "0", "]", ".", "lower", "(", ")", "in", "stopwords", ":", "\n", "# print(mstr)", "\n", "            ", "mstr", "=", "mstr", "[", "0", "]", ".", "lower", "(", ")", "+", "mstr", "[", "1", ":", "]", "\n", "# print(mstr)", "\n", "\n", "", "", "tokens", "=", "tokenizer", ".", "tokenize", "(", "left_cxt", ")", "+", "pattern_token_seq", "+", "tokenizer", ".", "tokenize", "(", "\n", "mstr", ")", "+", "tokenizer", ".", "tokenize", "(", "right_cxt", ")", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_len", ":", "\n", "        ", "return", "None", "\n", "", "token_id_seq", "=", "[", "tokenizer", ".", "cls_token_id", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "mask_idx", "=", "token_id_seq", ".", "index", "(", "tokenizer", ".", "mask_token_id", ")", "\n", "return", "token_id_seq", ",", "mask_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.find_head_end": [[32, 51], ["len", "list", "text.find", "inflect_engine.plural", "text.find", "max", "list.append", "len", "inflect_engine.plural.split", "list.append", "text[].isalnum", "text[].isalnum", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "find_head_end", "(", "inflect_engine", ",", "text", ",", "types", ")", ":", "\n", "    ", "text_len", "=", "len", "(", "text", ")", "\n", "pends", "=", "list", "(", ")", "\n", "for", "t", "in", "types", ":", "\n", "        ", "if", "'_'", "in", "t", ":", "\n", "            ", "t", "=", "t", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "\n", "", "beg_pos", "=", "text", ".", "find", "(", "t", ")", "\n", "if", "beg_pos", ">", "-", "1", ":", "\n", "            ", "if", "beg_pos", "+", "len", "(", "t", ")", ">=", "text_len", "or", "not", "text", "[", "beg_pos", "+", "len", "(", "t", ")", "]", ".", "isalnum", "(", ")", ":", "\n", "                ", "pends", ".", "append", "(", "beg_pos", "+", "len", "(", "t", ")", ")", "\n", "continue", "\n", "\n", "", "", "t", "=", "inflect_engine", ".", "plural", "(", "t", ")", "\n", "# print(t)", "\n", "beg_pos", "=", "text", ".", "find", "(", "t", ")", "\n", "if", "beg_pos", "+", "len", "(", "t", ")", ">=", "text_len", "or", "not", "text", "[", "beg_pos", "+", "len", "(", "t", ")", "]", ".", "isalnum", "(", ")", ":", "\n", "            ", "pends", ".", "append", "(", "beg_pos", "+", "len", "(", "t", ")", ")", "\n", "", "", "pend", "=", "max", "(", "pends", ")", "if", "len", "(", "pends", ")", ">", "0", "else", "-", "1", "\n", "return", "pend", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mention_pattern_sample_for_uf_mention": [[53, 80], ["tokenizer.tokenize", "token_id_seq.index", "tokenizer.tokenize", "len", "utils.utils.get_mention_type", "labelgenexp.find_head_end", "tokenizer.tokenize", "tokenizer.tokenize", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "tokenizer.tokenize"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.get_mention_type", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.find_head_end"], ["", "def", "mention_pattern_sample_for_uf_mention", "(", "\n", "tokenizer", ":", "BertTokenizer", ",", "mention", ",", "pattern_str", ",", "max_seq_len", ",", "inflect_engine", ",", "head_words", ",", "\n", "use_hw_by_mention_type", "=", "False", ")", ":", "\n", "    ", "pattern_token_seq", "=", "tokenizer", ".", "tokenize", "(", "pattern_str", ")", "\n", "left_cxt", ",", "right_cxt", "=", "' '", ".", "join", "(", "mention", "[", "'left_context_token'", "]", ")", ",", "' '", ".", "join", "(", "mention", "[", "'right_context_token'", "]", ")", "\n", "mstr", "=", "mention", "[", "'mention_span'", "]", "\n", "pend", "=", "-", "1", "\n", "if", "head_words", "is", "not", "None", ":", "\n", "        ", "mtype", "=", "2", "\n", "if", "use_hw_by_mention_type", ":", "\n", "            ", "mtype", "=", "utils", ".", "get_mention_type", "(", "mstr", ")", "\n", "", "if", "mtype", "==", "2", ":", "\n", "            ", "pend", "=", "find_head_end", "(", "inflect_engine", ",", "mstr", ",", "head_words", ")", "\n", "\n", "# print(mstr, head_words, pend)", "\n", "", "", "if", "pend", ">", "-", "1", ":", "\n", "        ", "mstr_pattern_tokens", "=", "tokenizer", ".", "tokenize", "(", "\n", "mstr", "[", ":", "pend", "]", ")", "+", "pattern_token_seq", "+", "tokenizer", ".", "tokenize", "(", "mstr", "[", "pend", ":", "]", ")", "\n", "", "else", ":", "\n", "        ", "mstr_pattern_tokens", "=", "tokenizer", ".", "tokenize", "(", "mstr", ")", "+", "pattern_token_seq", "\n", "\n", "", "token_seq", "=", "tokenizer", ".", "tokenize", "(", "left_cxt", ")", "+", "mstr_pattern_tokens", "+", "tokenizer", ".", "tokenize", "(", "right_cxt", ")", "\n", "if", "len", "(", "token_seq", ")", ">", "max_seq_len", ":", "\n", "        ", "return", "None", "\n", "", "token_id_seq", "=", "[", "tokenizer", ".", "cls_token_id", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "token_seq", ")", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "mask_idx", "=", "token_id_seq", ".", "index", "(", "tokenizer", ".", "mask_token_id", ")", "\n", "return", "token_id_seq", ",", "mask_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mlm_type_results_for_batch": [[82, 126], ["list", "len", "torch.softmax().data.cpu().numpy", "enumerate", "torch.no_grad", "models.pad_id_seqs", "model", "numpy.argsort", "list", "enumerate", "torch.softmax().data.cpu", "list", "list", "inflect_engine.singular_noun", "type_id_dict.get", "len", "list.append", "numpy.arange", "pred_types.append", "top_logits.append", "list.append", "float", "len", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs"], ["", "def", "mlm_type_results_for_batch", "(", "device", ",", "tokenizer", ",", "inflect_engine", ",", "type_id_dict", ",", "model", ",", "batch", ",", "n_types", ",", "pad_id", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "token_id_seqs_tenser", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", ",", "device", ",", "pad_id", ")", "\n", "outputs", "=", "model", "(", "token_id_seqs_tenser", ",", "attn_mask", ")", "\n", "\n", "", "results", "=", "list", "(", ")", "\n", "# logits_batch = outputs.logits.data.cpu().numpy()", "\n", "batch_size", "=", "len", "(", "batch", ")", "\n", "mask_idxs", "=", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", "\n", "logits_batch", "=", "outputs", ".", "logits", "[", "np", ".", "arange", "(", "batch_size", ")", ",", "mask_idxs", ",", ":", "]", "\n", "logits_batch", "=", "torch", ".", "softmax", "(", "logits_batch", ",", "dim", "=", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", ",", "logits", "in", "enumerate", "(", "logits_batch", ")", ":", "\n", "        ", "mention_idx", "=", "batch", "[", "j", "]", "[", "0", "]", "\n", "idxs", "=", "np", ".", "argsort", "(", "-", "logits", ")", "\n", "\n", "# print([tokenizer.ids_to_tokens[idx] for idx in idxs])", "\n", "# left_cxt, right_cxt = ' '.join(mention['left_context_token']), ' '.join(mention['right_context_token'])", "\n", "# mstr = mention['mention_span']", "\n", "# print(left_cxt + ' [[' + mstr + ']] ' + right_cxt)", "\n", "pred_types", ",", "top_logits", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# for w in [tokenizer.ids_to_tokens[idx] for idx in idxs]:", "\n", "type_ranks", "=", "list", "(", ")", "\n", "for", "rank", ",", "idx", "in", "enumerate", "(", "idxs", ")", ":", "\n", "# print(w)", "\n", "            ", "w", "=", "tokenizer", ".", "ids_to_tokens", "[", "idx", "]", "\n", "singular_w", "=", "inflect_engine", ".", "singular_noun", "(", "w", ")", "\n", "if", "singular_w", ":", "\n", "                ", "w", "=", "singular_w", "\n", "\n", "", "type_id", "=", "type_id_dict", ".", "get", "(", "w", ",", "-", "1", ")", "\n", "if", "type_id", "<", "0", ":", "\n", "                ", "continue", "\n", "", "if", "type_id", "not", "in", "pred_types", ":", "\n", "                ", "pred_types", ".", "append", "(", "type_id", ")", "\n", "top_logits", ".", "append", "(", "float", "(", "logits", "[", "idx", "]", ")", ")", "\n", "type_ranks", ".", "append", "(", "rank", ")", "\n", "if", "len", "(", "pred_types", ")", ">=", "n_types", ":", "\n", "                    ", "break", "\n", "# if output_results_file is not None:", "\n", "", "", "", "if", "len", "(", "pred_types", ")", ">", "0", ":", "\n", "            ", "result_obj", "=", "{", "'id'", ":", "mention_idx", ",", "'tids'", ":", "pred_types", ",", "'logits'", ":", "top_logits", "}", "\n", "# result_obj = {'id': mention_idx, 'types': pred_types}", "\n", "results", ".", "append", "(", "result_obj", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.gen_mask_hyp_for_uf": [[128, 206], ["print", "print", "transformers.BertTokenizer.from_pretrained", "utils.datautils.load_vocab_file", "transformers.BertForMaskedLM.from_pretrained", "BertForMaskedLM.from_pretrained.to", "BertForMaskedLM.from_pretrained.eval", "inflect.engine", "open", "open", "list", "open.close", "open", "next", "json.loads", "labelgenexp.mlm_type_results_for_batch", "list", "next.strip", "print", "labelgenexp.pattern_mention_sample_for_uf_mention", "list.append", "open.close", "len", "open.write", "labelgenexp.mention_pattern_sample_for_uf_mention", "len", "labelgenexp.mention_pattern_sample_for_uf_mention", "json.dumps"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mlm_type_results_for_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.pattern_mention_sample_for_uf_mention", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mention_pattern_sample_for_uf_mention", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mention_pattern_sample_for_uf_mention"], ["", "def", "gen_mask_hyp_for_uf", "(", "device", ",", "uf_type_vocab_file", ",", "mention_file_name", ",", "output_file", ",", "pattern", ",", "\n", "use_head", "=", "False", ",", "head_words_file", "=", "None", ",", "y_str_as_headwords", "=", "False", ")", ":", "\n", "    ", "bert_model_name", "=", "'bert-base-cased'", "\n", "print", "(", "mention_file_name", ")", "\n", "print", "(", "output_file", ")", "\n", "max_seq_len", "=", "128", "\n", "batch_size", "=", "16", "\n", "pad_id", "=", "0", "\n", "k", "=", "20", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model_name", ")", "\n", "\n", "type_vocab", ",", "type_id_dict", "=", "datautils", ".", "load_vocab_file", "(", "uf_type_vocab_file", ")", "\n", "\n", "model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "bert_model_name", ",", "return_dict", "=", "True", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "head_words", "=", "None", "\n", "if", "head_words_file", "is", "not", "None", "and", "use_head", ":", "\n", "        ", "with", "open", "(", "head_words_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "head_words", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "", "", "inflect_engine", "=", "inflect", ".", "engine", "(", ")", "\n", "f", "=", "open", "(", "mention_file_name", ",", "encoding", "=", "'utf-8'", ")", "\n", "fout", "=", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "batch", "=", "list", "(", ")", "\n", "reach_end", "=", "False", "\n", "line_cnt", "=", "-", "1", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "line", "=", "next", "(", "f", ")", "\n", "line_cnt", "+=", "1", "\n", "if", "line_cnt", "%", "10000", "==", "0", ":", "\n", "                ", "print", "(", "line_cnt", ")", "\n", "", "mention", "=", "json", ".", "loads", "(", "line", ")", "\n", "# print(mention)", "\n", "# exit()", "\n", "m_hws", "=", "[", "head_words", "[", "line_cnt", "]", "]", "if", "head_words", "is", "not", "None", "else", "None", "\n", "if", "y_str_as_headwords", ":", "\n", "                ", "m_hws", "=", "mention", "[", "'y_str'", "]", "\n", "\n", "", "sample", "=", "None", "\n", "if", "pattern", "==", "'suchas'", ":", "\n", "# sample = such_as_samples_for_uf_mention(tokenizer, mention, max_seq_len)", "\n", "                ", "sample", "=", "pattern_mention_sample_for_uf_mention", "(", "tokenizer", ",", "mention", ",", "'[MASK] such as'", ",", "max_seq_len", ")", "\n", "", "elif", "pattern", "==", "'andanyother'", ":", "\n", "                ", "sample", "=", "mention_pattern_sample_for_uf_mention", "(", "\n", "tokenizer", ",", "mention", ",", "'and any other [MASK]'", ",", "max_seq_len", ",", "inflect_engine", ",", "m_hws", ")", "\n", "# sample = mention_pattern_mask_sample_for_uf_mention(tokenizer, mention, 'and any other', max_seq_len)", "\n", "", "elif", "pattern", "==", "'andsomeother'", ":", "\n", "                ", "sample", "=", "mention_pattern_sample_for_uf_mention", "(", "\n", "tokenizer", ",", "mention", ",", "'and some other [MASK]'", ",", "max_seq_len", ",", "inflect_engine", ",", "m_hws", ")", "\n", "", "if", "sample", "is", "not", "None", ":", "\n", "                ", "token_id_seq", ",", "mask_idx", "=", "sample", "\n", "# print(mention['mention_span'], '*', mention['y_str'])", "\n", "# print(tokenizer.convert_ids_to_tokens(token_id_seq))", "\n", "# print()", "\n", "# if line_cnt > 10:", "\n", "#     exit()", "\n", "batch", ".", "append", "(", "(", "line_cnt", ",", "token_id_seq", ",", "mask_idx", ")", ")", "\n", "# else:", "\n", "#     print('NONE')", "\n", "", "", "except", "StopIteration", ":", "\n", "            ", "reach_end", "=", "True", "\n", "f", ".", "close", "(", ")", "\n", "\n", "", "if", "len", "(", "batch", ")", "==", "batch_size", "or", "(", "reach_end", "and", "len", "(", "batch", ")", ">", "0", ")", ":", "\n", "            ", "results", "=", "mlm_type_results_for_batch", "(", "\n", "device", ",", "tokenizer", ",", "inflect_engine", ",", "type_id_dict", ",", "model", ",", "batch", ",", "k", ",", "pad_id", ")", "\n", "for", "r", "in", "results", ":", "\n", "                ", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "r", ")", ")", ")", "\n", "", "batch", "=", "list", "(", ")", "\n", "\n", "# if line_cnt > 1000:", "\n", "#     break", "\n", "", "if", "reach_end", ":", "\n", "            ", "break", "\n", "", "", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.pattern_mention_sample_for_span_mention": [[208, 221], ["tokenizer.tokenize", "token_id_seq.index", "tokenizer.tokenize", "len", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids"], "function", ["None"], ["", "def", "pattern_mention_sample_for_span_mention", "(", "tokenizer", ":", "BertTokenizer", ",", "mention", ",", "pattern_str", ",", "max_seq_len", ")", ":", "\n", "    ", "pattern_token_seq", "=", "tokenizer", ".", "tokenize", "(", "pattern_str", ")", "\n", "text", "=", "mention", "[", "'text'", "]", "\n", "bp", ",", "ep", "=", "mention", "[", "'span'", "]", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", "[", ":", "bp", "]", ")", "+", "pattern_token_seq", "+", "tokenizer", ".", "tokenize", "(", "text", "[", "bp", ":", "]", ")", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_len", ":", "\n", "        ", "return", "None", "\n", "", "token_id_seq", "=", "[", "tokenizer", ".", "cls_token_id", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "# mask_idx = (token_ids_seq == tokenizer.mask_token_id).nonzero()[0][1]", "\n", "mask_idx", "=", "token_id_seq", ".", "index", "(", "tokenizer", ".", "mask_token_id", ")", "\n", "# print(mask_idx)", "\n", "return", "mention", "[", "'id'", "]", ",", "token_id_seq", ",", "mask_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mention_pattern_sample_for_span_mention": [[223, 236], ["tokenizer.tokenize", "token_id_seq.index", "tokenizer.tokenize", "len", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids"], "function", ["None"], ["", "def", "mention_pattern_sample_for_span_mention", "(", "tokenizer", ":", "BertTokenizer", ",", "mention", ",", "pattern_str", ",", "max_seq_len", ")", ":", "\n", "    ", "pattern_token_seq", "=", "tokenizer", ".", "tokenize", "(", "pattern_str", ")", "\n", "text", "=", "mention", "[", "'text'", "]", "\n", "bp", ",", "ep", "=", "mention", "[", "'span'", "]", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", "[", ":", "ep", "]", ")", "+", "pattern_token_seq", "+", "tokenizer", ".", "tokenize", "(", "text", "[", "ep", ":", "]", ")", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_len", ":", "\n", "        ", "return", "None", "\n", "", "token_id_seq", "=", "[", "tokenizer", ".", "cls_token_id", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "# mask_idx = (token_ids_seq == tokenizer.mask_token_id).nonzero()[0][1]", "\n", "mask_idx", "=", "token_id_seq", ".", "index", "(", "tokenizer", ".", "mask_token_id", ")", "\n", "# print(mask_idx)", "\n", "return", "mention", "[", "'id'", "]", ",", "token_id_seq", ",", "mask_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.gen_mask_hyp_for_pronouns": [[238, 327], ["print", "transformers.BertTokenizer.from_pretrained", "utils.datautils.load_vocab_file", "transformers.BertForMaskedLM.from_pretrained", "BertForMaskedLM.from_pretrained.to", "BertForMaskedLM.from_pretrained.eval", "inflect.engine", "open", "open", "list", "open.close", "next", "json.loads", "len", "torch.softmax().data.cpu().numpy", "enumerate", "list", "print", "labelgenexp.pattern_mention_sample_for_span_mention", "list.append", "open.close", "len", "torch.no_grad", "models.pad_id_seqs", "BertForMaskedLM.from_pretrained.", "numpy.argsort", "enumerate", "labelgenexp.mention_pattern_sample_for_span_mention", "len", "torch.softmax().data.cpu", "list", "list", "inflect.engine.singular_noun", "type_id_dict.get", "len", "open.write", "labelgenexp.mention_pattern_sample_for_span_mention", "numpy.arange", "pred_types.append", "top_logits.append", "float", "len", "json.dumps", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.pattern_mention_sample_for_span_mention", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mention_pattern_sample_for_span_mention", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.mention_pattern_sample_for_span_mention"], ["", "def", "gen_mask_hyp_for_pronouns", "(", "device", ",", "uf_type_vocab_file", ",", "mention_file_name", ",", "output_file", ",", "pattern", "=", "'andother'", ")", ":", "\n", "    ", "bert_model_name", "=", "'bert-base-cased'", "\n", "print", "(", "mention_file_name", ")", "\n", "max_seq_len", "=", "128", "\n", "batch_size", "=", "16", "\n", "pad_id", "=", "0", "\n", "k", "=", "20", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model_name", ")", "\n", "\n", "type_vocab", ",", "type_id_dict", "=", "datautils", ".", "load_vocab_file", "(", "uf_type_vocab_file", ")", "\n", "\n", "model", "=", "BertForMaskedLM", ".", "from_pretrained", "(", "bert_model_name", ",", "return_dict", "=", "True", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "inflect_engine", "=", "inflect", ".", "engine", "(", ")", "\n", "f", "=", "open", "(", "mention_file_name", ",", "encoding", "=", "'utf-8'", ")", "\n", "fout", "=", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "batch", "=", "list", "(", ")", "\n", "reach_end", "=", "False", "\n", "line_cnt", "=", "0", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "line", "=", "next", "(", "f", ")", "\n", "line_cnt", "+=", "1", "\n", "if", "line_cnt", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "line_cnt", ")", "\n", "# if line_cnt > 10:", "\n", "#     exit()", "\n", "", "mention", "=", "json", ".", "loads", "(", "line", ")", "\n", "sample", "=", "None", "\n", "if", "pattern", "==", "'suchas'", ":", "\n", "                ", "sample", "=", "pattern_mention_sample_for_span_mention", "(", "\n", "tokenizer", ",", "mention", ",", "'[MASK] such as'", ",", "max_seq_len", ")", "\n", "", "elif", "pattern", "==", "'andanyother'", ":", "\n", "                ", "sample", "=", "mention_pattern_sample_for_span_mention", "(", "\n", "tokenizer", ",", "mention", ",", "'and any other [MASK]'", ",", "max_seq_len", ")", "\n", "", "elif", "pattern", "==", "'andsomeother'", ":", "\n", "                ", "sample", "=", "mention_pattern_sample_for_span_mention", "(", "\n", "tokenizer", ",", "mention", ",", "'and some other [MASK]'", ",", "max_seq_len", ")", "\n", "", "if", "sample", "is", "not", "None", ":", "\n", "# print(tokenizer.convert_ids_to_tokens(sample[1]))", "\n", "                ", "batch", ".", "append", "(", "sample", ")", "\n", "", "", "except", "StopIteration", ":", "\n", "            ", "reach_end", "=", "True", "\n", "f", ".", "close", "(", ")", "\n", "\n", "", "if", "len", "(", "batch", ")", "==", "batch_size", "or", "(", "reach_end", "and", "len", "(", "batch", ")", ">", "0", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "token_id_seqs_tenser", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", ",", "device", ",", "pad_id", ")", "\n", "outputs", "=", "model", "(", "token_id_seqs_tenser", ",", "attn_mask", ")", "\n", "\n", "# logits_batch = outputs.logits.data.cpu().numpy()", "\n", "\n", "", "mask_idxs", "=", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", "\n", "cur_batch_size", "=", "len", "(", "batch", ")", "\n", "logits_batch", "=", "outputs", ".", "logits", "[", "np", ".", "arange", "(", "cur_batch_size", ")", ",", "mask_idxs", ",", ":", "]", "\n", "logits_batch", "=", "torch", ".", "softmax", "(", "logits_batch", ",", "dim", "=", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "j", ",", "logits", "in", "enumerate", "(", "logits_batch", ")", ":", "\n", "                ", "mention_idx", "=", "batch", "[", "j", "]", "[", "0", "]", "\n", "idxs", "=", "np", ".", "argsort", "(", "-", "logits", ")", "\n", "\n", "pred_types", ",", "top_logits", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "rank", ",", "idx", "in", "enumerate", "(", "idxs", ")", ":", "\n", "# print(w)", "\n", "                    ", "w", "=", "tokenizer", ".", "ids_to_tokens", "[", "idx", "]", "\n", "singular_w", "=", "inflect_engine", ".", "singular_noun", "(", "w", ")", "\n", "if", "singular_w", ":", "\n", "                        ", "w", "=", "singular_w", "\n", "\n", "", "type_id", "=", "type_id_dict", ".", "get", "(", "w", ",", "-", "1", ")", "\n", "if", "type_id", "<", "0", ":", "\n", "                        ", "continue", "\n", "", "if", "type_id", "not", "in", "pred_types", ":", "\n", "                        ", "pred_types", ".", "append", "(", "type_id", ")", "\n", "top_logits", ".", "append", "(", "float", "(", "logits", "[", "idx", "]", ")", ")", "\n", "if", "len", "(", "pred_types", ")", ">=", "k", ":", "\n", "                            ", "break", "\n", "", "", "", "if", "len", "(", "pred_types", ")", ">", "0", ":", "\n", "# result_obj = {'id': mention_idx, 'types': pred_types}", "\n", "                    ", "result_obj", "=", "{", "'id'", ":", "mention_idx", ",", "'tids'", ":", "pred_types", ",", "'logits'", ":", "top_logits", "}", "\n", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "result_obj", ")", ")", ")", "\n", "# write_mlm_label_result(fout, mention_idx, pred_types, top_logits)", "\n", "", "", "batch", "=", "list", "(", ")", "\n", "# break", "\n", "\n", "", "if", "reach_end", ":", "\n", "            ", "break", "\n", "", "", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.label_select_batch": [[329, 352], ["model.data.cpu().numpy", "list", "enumerate", "torch.no_grad", "models.pad_id_seqs", "model", "numpy.squeeze", "list", "list.append", "model.data.cpu", "numpy.argwhere", "len", "int", "set", "sum", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs"], ["", "def", "label_select_batch", "(", "device", ",", "type_vocab", ",", "model", ",", "batch", ",", "ex_labels_lists", ",", "pad_id", ",", "discard_no_match", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "token_id_seqs_tenser", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", ",", "device", ",", "pad_id", ")", "\n", "logits_batch", "=", "model", "(", "token_id_seqs_tenser", ",", "attn_mask", ")", "\n", "\n", "", "logits_batch", "=", "logits_batch", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "selected_labels_list", "=", "list", "(", ")", "\n", "for", "i", ",", "logits", "in", "enumerate", "(", "logits_batch", ")", ":", "\n", "        ", "idxs", "=", "np", ".", "squeeze", "(", "np", ".", "argwhere", "(", "logits", ">", "0", ")", ",", "axis", "=", "1", ")", "\n", "if", "len", "(", "idxs", ")", "==", "0", ":", "\n", "            ", "idxs", "=", "[", "np", ".", "argmax", "(", "logits", ")", "]", "\n", "# labels_pred = [type_vocab[idx] for idx in idxs]", "\n", "", "labels_pred", "=", "[", "int", "(", "idx", ")", "for", "idx", "in", "idxs", "]", "\n", "labels_to_match", "=", "list", "(", "set", "(", "labels_pred", "+", "batch", "[", "i", "]", "[", "2", "]", ")", ")", "\n", "max_match_cnt", "=", "0", "if", "discard_no_match", "else", "-", "1", "\n", "ex_labels_select", "=", "None", "\n", "for", "ex_labels", "in", "ex_labels_lists", "[", "i", "]", ":", "\n", "            ", "match_cnt", "=", "sum", "(", "1", "if", "t", "in", "labels_to_match", "else", "0", "for", "t", "in", "ex_labels", ")", "\n", "if", "match_cnt", ">", "max_match_cnt", ":", "\n", "                ", "ex_labels_select", "=", "ex_labels", "\n", "max_match_cnt", "=", "match_cnt", "\n", "", "", "selected_labels_list", ".", "append", "(", "ex_labels_select", ")", "\n", "", "return", "selected_labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.write_selected_labels": [[354, 360], ["enumerate", "fout.write", "json.dumps"], "function", ["None"], ["", "def", "write_selected_labels", "(", "fout", ",", "batch", ",", "selected_labels_list", ")", ":", "\n", "    ", "for", "i", ",", "x", "in", "enumerate", "(", "batch", ")", ":", "\n", "        ", "if", "selected_labels_list", "[", "i", "]", "is", "None", ":", "\n", "            ", "continue", "\n", "", "r", "=", "{", "'id'", ":", "x", "[", "0", "]", ",", "'tids'", ":", "selected_labels_list", "[", "i", "]", "}", "\n", "fout", ".", "write", "(", "'{}\\n'", ".", "format", "(", "json", ".", "dumps", "(", "r", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.select_with_model_uf": [[362, 430], ["utils.datautils.load_vocab_file", "len", "transformers.BertTokenizer.from_pretrained", "bertuf.BertUF.from_trained", "bertuf.BertUF.from_trained.to", "bertuf.BertUF.from_trained.eval", "print", "print", "open", "open", "enumerate", "open.close", "open.close", "exp.expdatautils.LabelReader", "list", "list", "json.loads", "list", "len", "labelgenexp.label_select_batch", "labelgenexp.write_selected_labels", "print", "reader.labels_for", "len", "len", "labelgenexp.label_select_batch", "labelgenexp.write_selected_labels", "list.append", "exp.expdatautils.bert_sm_seq_from_my_mention", "exp.expdatautils.uf_mention_to_sm_bert_sample", "batch.append", "ex_labels_lists.append", "list", "list", "list", "type_id_dict.get"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.from_trained", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.label_select_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.write_selected_labels", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.LabelReader.labels_for", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.label_select_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.labelgenexp.write_selected_labels", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_seq_from_my_mention", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.uf_mention_to_sm_bert_sample"], ["", "", "def", "select_with_model_uf", "(", "\n", "device", ",", "type_vocab_file", ",", "data_file", ",", "is_my_mention", ",", "load_model_file", ",", "ex_labels_files", ",", "\n", "discard_no_match", ",", "output_file", ",", "n_types_use", ")", ":", "\n", "    ", "from", "models", "import", "bertuf", "\n", "\n", "bert_model", "=", "'bert-base-cased'", "\n", "max_seq_len", "=", "128", "\n", "batch_size", "=", "16", "\n", "type_vocab", ",", "type_id_dict", "=", "datautils", ".", "load_vocab_file", "(", "type_vocab_file", ")", "\n", "\n", "n_types", "=", "len", "(", "type_vocab", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "bert_model", ")", "\n", "pad_id", "=", "tokenizer", ".", "pad_token_id", "\n", "\n", "model", "=", "bertuf", ".", "BertUF", ".", "from_trained", "(", "load_model_file", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "print", "(", "data_file", ")", "\n", "print", "(", "output_file", ")", "\n", "ex_label_readers", "=", "[", "expdatautils", ".", "LabelReader", "(", "filename", ")", "for", "filename", "in", "ex_labels_files", "]", "\n", "fout", "=", "open", "(", "output_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "f", "=", "open", "(", "data_file", ",", "encoding", "=", "'utf-8'", ")", "\n", "batch", ",", "ex_labels_lists", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "        ", "if", "i", "%", "10000", "==", "0", ":", "\n", "            ", "print", "(", "i", ")", "\n", "", "m", "=", "json", ".", "loads", "(", "line", ")", "\n", "ex_labels_list", "=", "list", "(", ")", "\n", "mention_id", "=", "m", "[", "'id'", "]", "if", "is_my_mention", "else", "i", "\n", "for", "reader", "in", "ex_label_readers", ":", "\n", "            ", "lobj", "=", "reader", ".", "labels_for", "(", "mention_id", ")", "\n", "if", "lobj", "is", "not", "None", ":", "\n", "                ", "tids", "=", "lobj", "[", "'tids'", "]", "[", ":", "n_types_use", "]", "\n", "# ex_labels_list.append([type_vocab[tid] for tid in tids])", "\n", "ex_labels_list", ".", "append", "(", "tids", ")", "\n", "\n", "", "", "if", "len", "(", "ex_labels_list", ")", ">", "0", ":", "\n", "            ", "if", "is_my_mention", ":", "\n", "                ", "tok_id_seq", "=", "expdatautils", ".", "bert_sm_seq_from_my_mention", "(", "tokenizer", ",", "m", ",", "max_seq_len", ")", "\n", "", "else", ":", "\n", "                ", "tok_id_seq", "=", "expdatautils", ".", "uf_mention_to_sm_bert_sample", "(", "\n", "tokenizer", ",", "m", ",", "max_seq_len", ",", "discard_too_long", "=", "False", ")", "\n", "# print(tokenizer.convert_ids_to_tokens(tok_id_seq))", "\n", "# exit()", "\n", "", "if", "tok_id_seq", "is", "not", "None", ":", "\n", "# print(tokenizer.convert_ids_to_tokens(sample[1]))", "\n", "                ", "if", "is_my_mention", ":", "\n", "                    ", "original_labels", "=", "list", "(", ")", "\n", "", "else", ":", "\n", "                    ", "original_labels", "=", "[", "type_id_dict", ".", "get", "(", "t", ",", "-", "1", ")", "for", "t", "in", "m", "[", "'y_str'", "]", "]", "\n", "original_labels", "=", "[", "tid", "for", "tid", "in", "original_labels", "if", "tid", ">", "-", "1", "]", "\n", "", "batch", ".", "append", "(", "(", "mention_id", ",", "tok_id_seq", ",", "original_labels", ")", ")", "\n", "ex_labels_lists", ".", "append", "(", "ex_labels_list", ")", "\n", "\n", "", "", "if", "len", "(", "batch", ")", ">=", "batch_size", ":", "\n", "            ", "selected_labels_list", "=", "label_select_batch", "(", "\n", "device", ",", "type_vocab", ",", "model", ",", "batch", ",", "ex_labels_lists", ",", "pad_id", ",", "discard_no_match", ")", "\n", "write_selected_labels", "(", "fout", ",", "batch", ",", "selected_labels_list", ")", "\n", "batch", ",", "ex_labels_lists", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "# break", "\n", "", "", "f", ".", "close", "(", ")", "\n", "\n", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "        ", "selected_labels_list", "=", "label_select_batch", "(", "\n", "device", ",", "type_vocab", ",", "model", ",", "batch", ",", "ex_labels_lists", ",", "pad_id", ",", "discard_no_match", ")", "\n", "write_selected_labels", "(", "fout", ",", "batch", ",", "selected_labels_list", ")", "\n", "", "fout", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.TrainConfig.__init__": [[11, 39], ["torch.device", "torch.device", "len", "torch.cuda.device_count"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device_ids", ",", "lr", "=", "1e-5", ",", "batch_size", "=", "32", ",", "w_decay", "=", "0.01", ",", "n_iter", "=", "20", ",", "max_n_ex_types", "=", "10", ",", "\n", "bert_model", "=", "'bert-base-cased'", ",", "eval_interval", "=", "100", ",", "eval_bs", "=", "32", ",", "n_runs", "=", "1", ",", "n_steps", "=", "-", "1", ",", "\n", "mask_pos_prob_thres", "=", "0.9", ",", "mask_neg_prob_thres", "=", "0.1", ",", "save_interval", "=", "20000", ",", "\n", "sample_nums", "=", "(", "16", ",", "3", ",", "7", ",", "6", ")", ",", "gamma", "=", "-", "1", ",", "lr_schedule", "=", "False", ",", "lr_decay", "=", "0.1", ",", "weak_lamb", "=", "0.1", ",", "\n", "weak_to_pos_thres", "=", "0.5", ",", "lr_decay_thres", "=", "0.46", ")", ":", "\n", "        ", "cuda_device_str", "=", "'cuda'", "if", "len", "(", "device_ids", ")", "==", "0", "else", "'cuda:{}'", ".", "format", "(", "device_ids", "[", "0", "]", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "cuda_device_str", ")", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", "else", "torch", ".", "device", "(", "'cpu'", ")", "\n", "self", ".", "device_ids", "=", "device_ids", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "w_decay", "=", "w_decay", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "bert_model", "=", "bert_model", "\n", "self", ".", "eval_interval", "=", "eval_interval", "\n", "self", ".", "max_n_ex_types", "=", "max_n_ex_types", "\n", "self", ".", "eval_bs", "=", "eval_bs", "\n", "self", ".", "n_runs", "=", "n_runs", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "mask_pos_prob_thres", "=", "mask_pos_prob_thres", "\n", "self", ".", "mask_neg_prob_thres", "=", "mask_neg_prob_thres", "\n", "self", ".", "save_interval", "=", "save_interval", "\n", "self", ".", "sample_nums", "=", "sample_nums", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "lr_schedule", "=", "lr_schedule", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "weak_lamb", "=", "weak_lamb", "\n", "self", ".", "weak_to_pos_thres", "=", "weak_to_pos_thres", "\n", "self", ".", "lr_decay_thres", "=", "lr_decay_thres", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.UFAddtSampleLoader.__init__": [[42, 55], ["exp.expdatautils.SimpleUFBertBatchLoader", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "tokenizer", ",", "type_id_dict", ",", "addt_model", ",", "mention_files", ",", "label_files", ",", "\n", "mask_pos_prob_thres", ",", "mask_neg_prob_thres", ",", "max_seq_len", ",", "addt_batch_size", ",", "\n", "n_max_ex", ")", ":", "\n", "        ", "self", ".", "uf_bert_batch_loader", "=", "expdatautils", ".", "SimpleUFBertBatchLoader", "(", "\n", "tokenizer", ",", "mention_files", ",", "label_files", ",", "max_seq_len", ",", "addt_batch_size", ")", "\n", "self", ".", "sample_pool", "=", "list", "(", ")", "\n", "self", ".", "addt_model", "=", "addt_model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "type_id_dict", "=", "type_id_dict", "\n", "self", ".", "pad_id", "=", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "mask_pos_prob_thres", "=", "mask_pos_prob_thres", "\n", "self", ".", "mask_neg_prob_thres", "=", "mask_neg_prob_thres", "\n", "self", ".", "n_max_ex", "=", "n_max_ex", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.UFAddtSampleLoader.__iter__": [[56, 58], ["ufstexp.UFAddtSampleLoader.next_sample"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.PNAddtSampleLoader.next_sample"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "next_sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.UFAddtSampleLoader.next_sample": [[59, 101], ["iter", "next", "numpy.argwhere", "numpy.argwhere", "enumerate", "len", "torch.no_grad", "models.utils.pad_id_seqs", "ufstexp.UFAddtSampleLoader.addt_model", "torch.sigmoid().data.cpu().numpy", "list", "pos_labels_list[].append", "list", "list", "uncertain_labels_list[].append", "uncertain_probs_list[].append", "dict", "set", "ufstexp.UFAddtSampleLoader.sample_pool.pop", "range", "range", "range", "ufstexp.UFAddtSampleLoader.type_id_dict.get", "list", "len", "ufstexp.UFAddtSampleLoader.sample_pool.append", "torch.sigmoid().data.cpu", "len", "len", "len", "len", "len", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs"], ["", "def", "next_sample", "(", "self", ")", ":", "\n", "        ", "uf_bert_batch_iter", "=", "iter", "(", "self", ".", "uf_bert_batch_loader", ")", "\n", "while", "True", ":", "\n", "            ", "if", "len", "(", "self", ".", "sample_pool", ")", ">", "0", ":", "\n", "                ", "yield", "self", ".", "sample_pool", ".", "pop", "(", ")", "\n", "continue", "\n", "\n", "", "batch", "=", "next", "(", "uf_bert_batch_iter", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "tok_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "\n", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", ",", "self", ".", "device", ",", "self", ".", "pad_id", ")", "\n", "logits", "=", "self", ".", "addt_model", "(", "tok_id_seqs_tensor", ",", "attn_mask", ")", "\n", "probs_batch", "=", "torch", ".", "sigmoid", "(", "logits", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# print(probs_batch)", "\n", "", "pos_labels_list", "=", "[", "list", "(", ")", "for", "_", "in", "range", "(", "len", "(", "batch", ")", ")", "]", "\n", "pos_idxs", "=", "np", ".", "argwhere", "(", "probs_batch", ">", "self", ".", "mask_pos_prob_thres", ")", "\n", "for", "pi", ",", "pj", "in", "pos_idxs", ":", "\n", "                ", "pos_labels_list", "[", "pi", "]", ".", "append", "(", "pj", ")", "\n", "", "uncertain_labels_list", "=", "[", "list", "(", ")", "for", "_", "in", "range", "(", "len", "(", "batch", ")", ")", "]", "\n", "uncertain_idxs", "=", "np", ".", "argwhere", "(", "\n", "(", "(", "probs_batch", ">", "self", ".", "mask_neg_prob_thres", ")", "&", "(", "probs_batch", "<", "self", ".", "mask_pos_prob_thres", ")", ")", ")", "\n", "uncertain_probs_list", "=", "[", "list", "(", ")", "for", "_", "in", "range", "(", "len", "(", "batch", ")", ")", "]", "\n", "\n", "origin_labels_list", "=", "[", "[", "self", ".", "type_id_dict", ".", "get", "(", "t", ",", "-", "1", ")", "for", "t", "in", "x", "[", "1", "]", "]", "for", "x", "in", "batch", "]", "\n", "origin_labels_list", "=", "[", "[", "tid", "for", "tid", "in", "labels", "if", "tid", ">", "-", "1", "]", "for", "labels", "in", "origin_labels_list", "]", "\n", "for", "pi", ",", "pj", "in", "uncertain_idxs", ":", "\n", "                ", "uncertain_labels_list", "[", "pi", "]", ".", "append", "(", "pj", ")", "\n", "uncertain_probs_list", "[", "pi", "]", ".", "append", "(", "probs_batch", "[", "pi", "]", "[", "pj", "]", ")", "\n", "\n", "", "for", "i", ",", "x", "in", "enumerate", "(", "batch", ")", ":", "\n", "                ", "pos_labels", ",", "uncertain_labels", "=", "pos_labels_list", "[", "i", "]", ",", "uncertain_labels_list", "[", "i", "]", "\n", "# print(x[2])", "\n", "# exit()", "\n", "ex_labels", "=", "list", "(", ")", "if", "x", "[", "2", "]", "is", "None", "else", "x", "[", "2", "]", "[", "'tids'", "]", "\n", "if", "len", "(", "ex_labels", ")", ">", "self", ".", "n_max_ex", ":", "\n", "                    ", "ex_labels", "=", "ex_labels", "[", ":", "self", ".", "n_max_ex", "]", "\n", "", "label_probs_dict", "=", "dict", "(", ")", "\n", "for", "tid", "in", "set", "(", "origin_labels_list", "[", "i", "]", "+", "ex_labels", "+", "pos_labels", "+", "uncertain_labels", ")", ":", "\n", "                    ", "label_probs_dict", "[", "tid", "]", "=", "probs_batch", "[", "i", "]", "[", "tid", "]", "\n", "", "if", "len", "(", "x", "[", "1", "]", ")", "+", "len", "(", "pos_labels", ")", ">", "0", ":", "\n", "                    ", "self", ".", "sample_pool", ".", "append", "(", "\n", "(", "x", "[", "0", "]", ",", "origin_labels_list", "[", "i", "]", ",", "ex_labels", ",", "pos_labels", ",", "uncertain_labels", ",", "label_probs_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.MyBertBatchLoader.__init__": [[104, 112], ["exp.expdatautils.MyMentionLabelLoader"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "mention_file", ",", "type_file", ",", "max_seq_len", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "mention_file", "=", "mention_file", "\n", "self", ".", "type_file", "=", "type_file", "\n", "self", ".", "ml_loader", "=", "expdatautils", ".", "MyMentionLabelLoader", "(", "mention_file", ",", "type_file", ")", "\n", "self", ".", "file_idx", "=", "0", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.MyBertBatchLoader.__iter__": [[113, 115], ["ufstexp.MyBertBatchLoader.batch_gen"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.MyBertBatchLoader.batch_gen"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_gen", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.MyBertBatchLoader.batch_gen": [[116, 133], ["iter", "list", "next", "exp.expdatautils.bert_sm_seq_from_my_mention", "list.append", "iter", "len", "list"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_seq_from_my_mention"], ["", "def", "batch_gen", "(", "self", ")", ":", "\n", "        ", "ml_iter", "=", "iter", "(", "self", ".", "ml_loader", ")", "\n", "batch", "=", "list", "(", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "mention", ",", "lobj", "=", "next", "(", "ml_iter", ")", "\n", "if", "lobj", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "tok_id_seq", "=", "expdatautils", ".", "bert_sm_seq_from_my_mention", "(", "self", ".", "tokenizer", ",", "mention", ",", "self", ".", "max_seq_len", ")", "\n", "if", "tok_id_seq", "is", "not", "None", ":", "\n", "                    ", "batch", ".", "append", "(", "(", "tok_id_seq", ",", "lobj", "[", "'tids'", "]", ")", ")", "\n", "if", "len", "(", "batch", ")", ">=", "self", ".", "batch_size", ":", "\n", "                        ", "yield", "batch", "\n", "batch", "=", "list", "(", ")", "\n", "", "", "", "except", "StopIteration", ":", "\n", "                ", "ml_iter", "=", "iter", "(", "self", ".", "ml_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.PNAddtSampleLoader.__init__": [[136, 146], ["ufstexp.MyBertBatchLoader", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "tokenizer", ",", "teacher_model", ",", "mention_file", ",", "type_file", ",", "\n", "mask_pos_prob_thres", ",", "mask_neg_prob_thres", ",", "max_seq_len", ",", "addt_batch_size", ",", "n_max_ex", ")", ":", "\n", "        ", "self", ".", "bert_batch_loader", "=", "MyBertBatchLoader", "(", "tokenizer", ",", "mention_file", ",", "type_file", ",", "max_seq_len", ",", "addt_batch_size", ")", "\n", "self", ".", "sample_pool", "=", "list", "(", ")", "\n", "self", ".", "teacher_model", "=", "teacher_model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "pad_id", "=", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "mask_pos_prob_thres", "=", "mask_pos_prob_thres", "\n", "self", ".", "mask_neg_prob_thres", "=", "mask_neg_prob_thres", "\n", "self", ".", "n_max_ex", "=", "n_max_ex", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.PNAddtSampleLoader.__iter__": [[147, 149], ["ufstexp.PNAddtSampleLoader.next_sample"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.PNAddtSampleLoader.next_sample"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "next_sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.PNAddtSampleLoader.next_sample": [[150, 186], ["iter", "next", "numpy.argwhere", "numpy.argwhere", "enumerate", "len", "torch.no_grad", "models.utils.pad_id_seqs", "ufstexp.PNAddtSampleLoader.teacher_model", "torch.sigmoid().data.cpu().numpy", "list", "pos_labels_list[].append", "list", "uncertain_labels_list[].append", "dict", "set", "ufstexp.PNAddtSampleLoader.sample_pool.pop", "range", "range", "len", "len", "ufstexp.PNAddtSampleLoader.sample_pool.append", "torch.sigmoid().data.cpu", "len", "len", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs"], ["", "def", "next_sample", "(", "self", ")", ":", "\n", "        ", "bert_batch_iter", "=", "iter", "(", "self", ".", "bert_batch_loader", ")", "\n", "while", "True", ":", "\n", "            ", "if", "len", "(", "self", ".", "sample_pool", ")", ">", "0", ":", "\n", "                ", "yield", "self", ".", "sample_pool", ".", "pop", "(", ")", "\n", "continue", "\n", "\n", "", "batch", "=", "next", "(", "bert_batch_iter", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "tok_id_seqs", "=", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", "\n", "tok_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "tok_id_seqs", ",", "self", ".", "device", ",", "self", ".", "pad_id", ")", "\n", "logits", "=", "self", ".", "teacher_model", "(", "tok_id_seqs_tensor", ",", "attn_mask", ")", "\n", "probs_batch", "=", "torch", ".", "sigmoid", "(", "logits", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# print(probs_batch)", "\n", "", "pos_labels_list", "=", "[", "list", "(", ")", "for", "_", "in", "range", "(", "len", "(", "batch", ")", ")", "]", "\n", "pos_idxs", "=", "np", ".", "argwhere", "(", "probs_batch", ">", "self", ".", "mask_pos_prob_thres", ")", "\n", "for", "pi", ",", "pj", "in", "pos_idxs", ":", "\n", "                ", "pos_labels_list", "[", "pi", "]", ".", "append", "(", "pj", ")", "\n", "", "uncertain_labels_list", "=", "[", "list", "(", ")", "for", "_", "in", "range", "(", "len", "(", "batch", ")", ")", "]", "\n", "uncertain_idxs", "=", "np", ".", "argwhere", "(", "\n", "(", "(", "probs_batch", ">", "self", ".", "mask_neg_prob_thres", ")", "&", "(", "probs_batch", "<", "self", ".", "mask_pos_prob_thres", ")", ")", ")", "\n", "for", "pi", ",", "pj", "in", "uncertain_idxs", ":", "\n", "                ", "uncertain_labels_list", "[", "pi", "]", ".", "append", "(", "pj", ")", "\n", "\n", "", "for", "i", ",", "x", "in", "enumerate", "(", "batch", ")", ":", "\n", "                ", "mlm_labels", "=", "x", "[", "1", "]", "\n", "if", "len", "(", "mlm_labels", ")", ">", "self", ".", "n_max_ex", ":", "\n", "                    ", "mlm_labels", "=", "mlm_labels", "[", ":", "self", ".", "n_max_ex", "]", "\n", "", "pos_labels", ",", "uncertain_labels", "=", "pos_labels_list", "[", "i", "]", ",", "uncertain_labels_list", "[", "i", "]", "\n", "# print(pos_labels, uncertain_labels, mlm_labels)", "\n", "# exit()", "\n", "label_probs_dict", "=", "dict", "(", ")", "\n", "for", "tid", "in", "set", "(", "mlm_labels", "+", "pos_labels", "+", "uncertain_labels", ")", ":", "\n", "                    ", "label_probs_dict", "[", "tid", "]", "=", "probs_batch", "[", "i", "]", "[", "tid", "]", "\n", "", "if", "len", "(", "pos_labels", ")", ">", "0", ":", "\n", "                    ", "self", ".", "sample_pool", ".", "append", "(", "(", "x", "[", "0", "]", ",", "mlm_labels", ",", "pos_labels", ",", "uncertain_labels", ",", "label_probs_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.__init__": [[217, 244], ["exp.expdatautils.bert_sm_samples_from_json_data", "ufstexp.UFAddtSampleLoader", "ufstexp.UFAddtSampleLoader", "ufstexp.PNAddtSampleLoader"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "type_vocab", ",", "tokenizer", ":", "BertTokenizer", ",", "teacher_model", ",", "type_id_dict", ",", "train_data_file", ",", "\n", "el_data_file", ",", "el_extra_label_file", ",", "open_data_files", ",", "open_extra_label_files", ",", "pronoun_mention_file", ",", "\n", "pronoun_type_file", ",", "mask_pos_prob_thres", ",", "mask_neg_prob_thres", ",", "batch_size", ",", "\n", "sample_nums_per_batch", ",", "max_n_ex_types", ",", "n_steps", ",", "weak_to_pos_thres", ")", ":", "\n", "        ", "max_seq_len", "=", "128", "\n", "self", ".", "type_id_dict", "=", "type_id_dict", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "type_vocab", "=", "type_vocab", "\n", "# self.el_data_file = el_data_file", "\n", "# self.open_data_files = open_data_files", "\n", "self", ".", "pronoun_mention_file", "=", "pronoun_mention_file", "\n", "self", ".", "pronoun_type_file", "=", "pronoun_type_file", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "hl_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "\n", "tokenizer", ",", "type_id_dict", ",", "train_data_file", ",", "max_seq_len", "=", "max_seq_len", ")", "\n", "self", ".", "el_sample_loader", "=", "UFAddtSampleLoader", "(", "\n", "device", ",", "tokenizer", ",", "type_id_dict", ",", "teacher_model", ",", "[", "el_data_file", "]", ",", "[", "el_extra_label_file", "]", ",", "mask_pos_prob_thres", ",", "\n", "mask_neg_prob_thres", ",", "max_seq_len", ",", "batch_size", ",", "max_n_ex_types", ")", "\n", "self", ".", "open_sample_loader", "=", "UFAddtSampleLoader", "(", "\n", "device", ",", "tokenizer", ",", "type_id_dict", ",", "teacher_model", ",", "open_data_files", ",", "open_extra_label_files", ",", "\n", "mask_pos_prob_thres", ",", "mask_neg_prob_thres", ",", "max_seq_len", ",", "batch_size", ",", "max_n_ex_types", ")", "\n", "self", ".", "pn_sample_loader", "=", "PNAddtSampleLoader", "(", "\n", "device", ",", "tokenizer", ",", "teacher_model", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "mask_pos_prob_thres", ",", "\n", "mask_neg_prob_thres", ",", "max_seq_len", ",", "batch_size", ",", "max_n_ex_types", ")", "\n", "self", ".", "sample_nums_per_batch", "=", "sample_nums_per_batch", "\n", "self", ".", "weak_to_pos_thres", "=", "weak_to_pos_thres", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.__iter__": [[245, 247], ["ufstexp.STBatchLoader.next_batch"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.next_batch"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "next_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.STBatchLoader.next_batch": [[248, 289], ["iter", "iter", "iter", "list", "range", "range", "range", "range", "list.append", "next", "ufstexp.get_pos_and_uncertain_labels", "list.append", "next", "ufstexp.get_pos_and_uncertain_labels", "list.append", "next", "ufstexp.get_pos_and_uncertain_labels", "list.append", "len", "list"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.get_pos_and_uncertain_labels", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.get_pos_and_uncertain_labels", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.get_pos_and_uncertain_labels"], ["", "def", "next_batch", "(", "self", ")", ":", "\n", "        ", "el_sample_iter", "=", "iter", "(", "self", ".", "el_sample_loader", ")", "\n", "open_sample_iter", "=", "iter", "(", "self", ".", "open_sample_loader", ")", "\n", "pn_sample_iter", "=", "iter", "(", "self", ".", "pn_sample_loader", ")", "\n", "hl_idx", "=", "0", "\n", "\n", "while", "True", ":", "\n", "            ", "batch", "=", "list", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "sample_nums_per_batch", "[", "0", "]", ")", ":", "\n", "                ", "x", "=", "self", ".", "hl_samples", "[", "hl_idx", "]", "\n", "batch", ".", "append", "(", "(", "x", "[", "1", "]", ",", "x", "[", "2", "]", ",", "list", "(", ")", ")", ")", "\n", "hl_idx", "=", "(", "hl_idx", "+", "1", ")", "%", "len", "(", "self", ".", "hl_samples", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "sample_nums_per_batch", "[", "1", "]", ")", ":", "\n", "                ", "x", "=", "next", "(", "el_sample_iter", ")", "\n", "tok_id_seq", ",", "original_labels", ",", "ex_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "label_probs_dict", "=", "x", "\n", "pos_labels", ",", "uncertain_labels", "=", "get_pos_and_uncertain_labels", "(", "\n", "None", ",", "ex_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "label_probs_dict", ",", "\n", "self", ".", "weak_to_pos_thres", ")", "\n", "\n", "batch", ".", "append", "(", "(", "tok_id_seq", ",", "pos_labels", ",", "uncertain_labels", ")", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "sample_nums_per_batch", "[", "2", "]", ")", ":", "\n", "                ", "x", "=", "next", "(", "open_sample_iter", ")", "\n", "tok_id_seq", ",", "original_labels", ",", "ex_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "label_probs_dict", "=", "x", "\n", "pos_labels", ",", "uncertain_labels", "=", "get_pos_and_uncertain_labels", "(", "\n", "original_labels", ",", "ex_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "label_probs_dict", ",", "\n", "self", ".", "weak_to_pos_thres", ",", "is_from_hw", "=", "True", ")", "\n", "batch", ".", "append", "(", "(", "tok_id_seq", ",", "pos_labels", ",", "uncertain_labels", ")", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "sample_nums_per_batch", "[", "3", "]", ")", ":", "\n", "                ", "x", "=", "next", "(", "pn_sample_iter", ")", "\n", "# batch.append((x[0], x[1], x[2]))", "\n", "tok_id_seq", ",", "mlm_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "label_probs_dict", "=", "x", "\n", "pos_labels", ",", "uncertain_labels", "=", "get_pos_and_uncertain_labels", "(", "\n", "[", "]", ",", "mlm_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "label_probs_dict", ",", "\n", "self", ".", "weak_to_pos_thres", ")", "\n", "batch", ".", "append", "(", "(", "tok_id_seq", ",", "pos_labels", ",", "uncertain_labels", ")", ")", "\n", "\n", "# exit()", "\n", "", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.get_pos_and_uncertain_labels": [[188, 214], ["set", "set", "set.update", "list", "set.update", "set.add", "len", "set.update", "set.update"], "function", ["None"], ["", "", "", "", "", "def", "get_pos_and_uncertain_labels", "(", "\n", "original_labels", ",", "mlm_labels", ",", "model_pos_labels", ",", "model_uncertain_labels", ",", "tid_prob_dict", ",", "weak_to_pos_thres", ",", "\n", "is_from_hw", "=", "False", ")", ":", "\n", "    ", "pos_labels_set", "=", "set", "(", "model_pos_labels", ")", "\n", "\n", "weak_labels", "=", "set", "(", ")", "\n", "if", "original_labels", "is", "not", "None", ":", "\n", "        ", "if", "is_from_hw", ":", "\n", "            ", "if", "len", "(", "original_labels", ")", "==", "1", ":", "\n", "                ", "pos_labels_set", ".", "update", "(", "original_labels", ")", "\n", "", "else", ":", "\n", "                ", "weak_labels", ".", "update", "(", "original_labels", ")", "\n", "", "", "else", ":", "\n", "            ", "weak_labels", ".", "update", "(", "original_labels", ")", "\n", "", "", "if", "mlm_labels", "is", "not", "None", ":", "\n", "        ", "weak_labels", ".", "update", "(", "mlm_labels", ")", "\n", "\n", "# cnt = 0", "\n", "", "for", "tid", "in", "weak_labels", ":", "\n", "        ", "if", "tid_prob_dict", "[", "tid", "]", ">", "weak_to_pos_thres", ":", "\n", "            ", "pos_labels_set", ".", "add", "(", "tid", ")", "\n", "#         cnt += 1", "\n", "# print(cnt)", "\n", "\n", "", "", "uncertain_labels", "=", "[", "tid", "for", "tid", "in", "model_uncertain_labels", "if", "tid", "not", "in", "pos_labels_set", "]", "\n", "return", "list", "(", "pos_labels_set", ")", ",", "uncertain_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.get_loss_sep_batch": [[291, 316], ["models.utils.pad_id_seqs", "numpy.ones", "torch.tensor", "model", "exp.exputils.onehot_encode_batch", "torch.tensor", "exp.exputils.define_loss_partial", "numpy.ones", "enumerate", "torch.tensor", "models.utils.pad_id_seqs", "model", "exp.exputils.onehot_encode_batch", "torch.tensor", "loss_obj_weak", "len", "len"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.onehot_encode_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.define_loss_partial", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.onehot_encode_batch"], ["", "", "", "def", "get_loss_sep_batch", "(", "tc", ":", "TrainConfig", ",", "loss_obj", ",", "loss_obj_weak", ",", "n_types", ",", "n_strong", ",", "model", ",", "batch", ",", "weak_weight", ",", "pad_id", ")", ":", "\n", "    ", "batch_strong", ",", "batch_weak", "=", "batch", "[", ":", "n_strong", "]", ",", "batch", "[", "n_strong", ":", "]", "\n", "token_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "[", "x", "[", "0", "]", "for", "x", "in", "batch_strong", "]", ",", "tc", ".", "device", ",", "pad_id", ")", "\n", "target_mask", "=", "np", ".", "ones", "(", "(", "len", "(", "batch_strong", ")", ",", "n_types", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "target_mask", "=", "torch", ".", "tensor", "(", "target_mask", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "logits", "=", "model", "(", "token_id_seqs_tensor", ",", "attn_mask", ")", "\n", "labels", "=", "exputils", ".", "onehot_encode_batch", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch_strong", "]", ",", "n_types", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "# print('strong')", "\n", "loss_strong", "=", "exputils", ".", "define_loss_partial", "(", "tc", ".", "device", ",", "loss_obj", ",", "logits", ",", "labels", ",", "target_mask", ")", "\n", "\n", "target_mask", "=", "np", ".", "ones", "(", "(", "len", "(", "batch_weak", ")", ",", "n_types", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "batch_weak", ")", ":", "\n", "        ", "target_mask", "[", "i", "]", "[", "x", "[", "2", "]", "]", "=", "0", "\n", "", "target_mask", "=", "torch", ".", "tensor", "(", "target_mask", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "\n", "token_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "[", "x", "[", "0", "]", "for", "x", "in", "batch_weak", "]", ",", "tc", ".", "device", ",", "pad_id", ")", "\n", "logits", "=", "model", "(", "token_id_seqs_tensor", ",", "attn_mask", ")", "\n", "labels", "=", "exputils", ".", "onehot_encode_batch", "(", "[", "x", "[", "1", "]", "for", "x", "in", "batch_weak", "]", ",", "n_types", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "\n", "loss_weak", "=", "loss_obj_weak", "(", "logits", ",", "labels", ",", "target_mask", ")", "\n", "# print('sw', loss_strong, loss_weak)", "\n", "loss", "=", "loss_strong", "+", "weak_weight", "*", "loss_weak", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.train_st": [[318, 422], ["logging.info", "transformers.BertTokenizer.from_pretrained", "utils.datautils.load_vocab_file", "models.bertuf.BertUF.from_trained", "bertuf.BertUF.from_trained.to", "bertuf.BertUF.from_trained.eval", "logging.info", "ufstexp.STBatchLoader", "exp.expdatautils.bert_sm_samples_from_json_data", "exp.expdatautils.SampleBatchLoader", "exp.expdatautils.bert_sm_samples_from_json_data", "exp.expdatautils.SampleBatchLoader", "len", "torch.nn.DataParallel.to", "exp.exputils.PartialBCELoss", "exp.exputils.PartialBCELoss", "utils.bertutils.get_bert_adam_optim", "logging.info", "list", "list", "torch.ones", "sum", "models.bertuf.BertUF.from_trained", "logging.info", "models.bertuf.BertUF", "len", "torch.nn.DataParallel", "list", "torch.optim.lr_scheduler.MultiplicativeLR", "ufstexp.get_loss_sep_batch", "list.append", "bertutils.get_bert_adam_optim.zero_grad", "get_loss_sep_batch.backward", "bertutils.get_bert_adam_optim.step", "torch.nn.DataParallel.named_parameters", "get_loss_sep_batch.data.cpu().numpy", "sum", "list", "torch.nn.DataParallel.eval", "exp.exputils.eval_uf", "exp.exputils.eval_uf", "logging.info", "torch.nn.DataParallel.train", "logging.info", "torch.optim.lr_scheduler.MultiplicativeLR.step", "print", "vars().items", "get_loss_sep_batch.data.cpu", "len", "torch.save", "torch.save", "torch.nn.DataParallel.module.state_dict", "torch.nn.DataParallel.state_dict", "vars"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.datautils.load_vocab_file", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.from_trained", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.expdatautils.bert_sm_samples_from_json_data", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.bertutils.get_bert_adam_optim", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.from_trained", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.ufstexp.get_loss_sep_batch", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.eval_uf", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.eval_uf"], ["", "def", "train_st", "(", "tc", ":", "TrainConfig", ",", "type_vocab_file", ",", "el_data_file", ",", "el_extra_label_file", ",", "open_data_files", ",", "\n", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "train_data_file", ",", "dev_data_file", ",", "\n", "test_data_file", ",", "teacher_model_file", ",", "load_model_file", ",", "save_model_file", ")", ":", "\n", "# bert_model_name = 'bert-base-cased'", "\n", "    ", "logging", ".", "info", "(", "' '", ".", "join", "(", "[", "'{}={}'", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "vars", "(", "tc", ")", ".", "items", "(", ")", "]", ")", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "tc", ".", "bert_model", ")", "\n", "pad_id", "=", "tokenizer", ".", "pad_token_id", "\n", "type_vocab", ",", "type_id_dict", "=", "datautils", ".", "load_vocab_file", "(", "type_vocab_file", ")", "\n", "\n", "teacher_model", "=", "bertuf", ".", "BertUF", ".", "from_trained", "(", "teacher_model_file", ")", "\n", "teacher_model", ".", "to", "(", "tc", ".", "device", ")", "\n", "teacher_model", ".", "eval", "(", ")", "\n", "logging", ".", "info", "(", "'load teacher model from {}'", ".", "format", "(", "teacher_model_file", ")", ")", "\n", "\n", "assert", "sum", "(", "tc", ".", "sample_nums", ")", "==", "tc", ".", "batch_size", "\n", "st_batch_iter", "=", "STBatchLoader", "(", "\n", "tc", ".", "device", ",", "type_vocab", ",", "tokenizer", ",", "teacher_model", ",", "type_id_dict", ",", "train_data_file", ",", "el_data_file", ",", "el_extra_label_file", ",", "\n", "open_data_files", ",", "open_extra_label_files", ",", "pronoun_mention_file", ",", "pronoun_type_file", ",", "tc", ".", "mask_pos_prob_thres", ",", "\n", "tc", ".", "mask_neg_prob_thres", ",", "tc", ".", "batch_size", ",", "tc", ".", "sample_nums", ",", "tc", ".", "max_n_ex_types", ",", "tc", ".", "n_steps", ",", "\n", "tc", ".", "weak_to_pos_thres", ")", "\n", "# for batch in st_batch_iter:", "\n", "#     break", "\n", "# exit()", "\n", "dev_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "\n", "tokenizer", ",", "type_id_dict", ",", "dev_data_file", ")", "\n", "dev_batch_iter", "=", "expdatautils", ".", "SampleBatchLoader", "(", "dev_samples", ",", "tc", ".", "eval_bs", ",", "1", ")", "\n", "test_samples", "=", "expdatautils", ".", "bert_sm_samples_from_json_data", "(", "\n", "tokenizer", ",", "type_id_dict", ",", "test_data_file", ")", "\n", "test_batch_iter", "=", "expdatautils", ".", "SampleBatchLoader", "(", "test_samples", ",", "tc", ".", "eval_bs", ",", "1", ")", "\n", "\n", "n_types", "=", "len", "(", "type_vocab", ")", "\n", "if", "load_model_file", ":", "\n", "        ", "model", "=", "bertuf", ".", "BertUF", ".", "from_trained", "(", "load_model_file", ")", "\n", "logging", ".", "info", "(", "'load model from {}'", ".", "format", "(", "load_model_file", ")", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "bertuf", ".", "BertUF", "(", "n_types", ",", "pretrained_bert_model", "=", "tc", ".", "bert_model", ")", "\n", "", "model", ".", "to", "(", "tc", ".", "device", ")", "\n", "if", "len", "(", "tc", ".", "device_ids", ")", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "tc", ".", "device_ids", ")", "\n", "\n", "", "loss_obj", "=", "exputils", ".", "PartialBCELoss", "(", ")", "\n", "loss_obj_weak", "=", "exputils", ".", "PartialBCELoss", "(", ")", "\n", "optimizer", "=", "bertutils", ".", "get_bert_adam_optim", "(", "\n", "list", "(", "model", ".", "named_parameters", "(", ")", ")", ",", "learning_rate", "=", "tc", ".", "lr", ",", "w_decay", "=", "tc", ".", "w_decay", ")", "\n", "\n", "lr_scheduler", "=", "None", "\n", "if", "tc", ".", "lr_schedule", ":", "\n", "        ", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiplicativeLR", "(", "optimizer", ",", "lambda", "epoch", ":", "tc", ".", "lr_decay", ")", "\n", "\n", "", "logging", ".", "info", "(", "loss_obj", ".", "__class__", ")", "\n", "step", "=", "0", "\n", "losses", "=", "list", "(", ")", "\n", "ltups", "=", "list", "(", ")", "\n", "best_dev_f1", "=", "0", "\n", "lr_reduced", "=", "False", "\n", "weights_tensor", "=", "torch", ".", "ones", "(", "tc", ".", "batch_size", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "tc", ".", "device", ")", "\n", "weights_tensor", "[", "tc", ".", "sample_nums", "[", "0", "]", ":", "]", "=", "tc", ".", "weak_lamb", "\n", "n_strong", "=", "tc", ".", "sample_nums", "[", "0", "]", "\n", "# print(weights_tensor)", "\n", "# exit()", "\n", "for", "batch", "in", "st_batch_iter", ":", "\n", "        ", "loss", "=", "get_loss_sep_batch", "(", "\n", "tc", ",", "loss_obj", ",", "loss_obj_weak", ",", "n_types", ",", "n_strong", ",", "model", ",", "batch", ",", "tc", ".", "weak_lamb", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "# print(loss)", "\n", "# exit()", "\n", "if", "loss", "is", "None", ":", "\n", "            ", "continue", "\n", "\n", "", "losses", ".", "append", "(", "loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "step", "+=", "1", "\n", "# if step > 3:", "\n", "#     exit()", "\n", "if", "step", "%", "tc", ".", "eval_interval", "==", "0", ":", "\n", "            ", "loss_val", "=", "sum", "(", "losses", ")", "\n", "losses", "=", "list", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "p", ",", "r", ",", "f1", ",", "results", "=", "exputils", ".", "eval_uf", "(", "tc", ".", "device", ",", "model", ",", "type_vocab", ",", "dev_batch_iter", ")", "\n", "pt", ",", "rt", ",", "f1t", ",", "results", "=", "exputils", ".", "eval_uf", "(", "tc", ".", "device", ",", "model", ",", "type_vocab", ",", "test_batch_iter", ")", "\n", "# print(step, loss_val, p, r, f1)", "\n", "best_tag", "=", "'*'", "if", "f1", ">", "best_dev_f1", "else", "''", "\n", "logging", ".", "info", "(", "\n", "'i={} loss={:.3f} p={:.5f} r={:.5f} f1={:.5f} p={:.5f} r={:.5f} f1={:.5f}{}'", ".", "format", "(", "\n", "step", ",", "loss_val", ",", "p", ",", "r", ",", "f1", ",", "pt", ",", "rt", ",", "f1t", ",", "best_tag", ")", ")", "\n", "if", "f1", ">", "best_dev_f1", "and", "save_model_file", "is", "not", "None", ":", "\n", "                ", "if", "len", "(", "tc", ".", "device_ids", ")", ">", "1", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "save_model_file", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_model_file", ")", "\n", "", "logging", ".", "info", "(", "'model saved to {}'", ".", "format", "(", "save_model_file", ")", ")", "\n", "", "if", "f1", ">", "best_dev_f1", ":", "\n", "                ", "best_dev_f1", "=", "f1", "\n", "", "model", ".", "train", "(", ")", "\n", "if", "f1", ">", "tc", ".", "lr_decay_thres", "and", "not", "lr_reduced", "and", "lr_scheduler", "is", "not", "None", ":", "\n", "                ", "lr_scheduler", ".", "step", "(", ")", "\n", "lr_reduced", "=", "True", "\n", "print", "(", "'lr reduced'", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.WeightedBCELoss.__init__": [[102, 107], ["super().__init__", "torch.nn.LogSigmoid"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "neg_scale", "=", "-", "1", ",", "bce_sum", "=", "False", ")", ":", "\n", "        ", "super", "(", "WeightedBCELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "log_sigmoid", "=", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "self", ".", "neg_scale", "=", "neg_scale", "\n", "self", ".", "bce_sum", "=", "bce_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.WeightedBCELoss.forward": [[108, 121], ["torch.mean", "exputils.WeightedBCELoss.log_sigmoid", "torch.sum", "exputils.WeightedBCELoss.log_sigmoid", "torch.sum", "logits.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "target_weights", ")", ":", "\n", "        ", "neg_vals", "=", "self", ".", "log_sigmoid", "(", "-", "logits", ")", "*", "(", "1", "-", "targets", ")", "\n", "if", "self", ".", "neg_scale", ">", "0", ":", "\n", "            ", "neg_vals", "*=", "self", ".", "neg_scale", "\n", "", "vals", "=", "-", "targets", "*", "self", ".", "log_sigmoid", "(", "logits", ")", "-", "neg_vals", "\n", "# print(vals)", "\n", "# print(target_weights)", "\n", "if", "self", ".", "bce_sum", ":", "\n", "            ", "losses", "=", "torch", ".", "sum", "(", "vals", "*", "target_weights", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "losses", "=", "torch", ".", "sum", "(", "vals", "*", "target_weights", ",", "dim", "=", "-", "1", ")", "/", "logits", ".", "size", "(", ")", "[", "1", "]", "\n", "# print(torch.mean(torch.mean(vals, dim=-1)))", "\n", "", "return", "torch", ".", "mean", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.PartialBCELoss.__init__": [[212, 215], ["super().__init__", "torch.nn.LogSigmoid"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PartialBCELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "log_sigmoid", "=", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.PartialBCELoss.forward": [[216, 226], ["torch.sum", "torch.mean", "exputils.PartialBCELoss.log_sigmoid", "exputils.PartialBCELoss.log_sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "logits", ",", "targets", ",", "targets_mask", ",", "weights", "=", "None", ")", ":", "\n", "        ", "pos_vals", "=", "-", "targets", "*", "self", ".", "log_sigmoid", "(", "logits", ")", "\n", "neg_vals", "=", "-", "self", ".", "log_sigmoid", "(", "-", "logits", ")", "*", "(", "1", "-", "targets", ")", "\n", "vals", "=", "pos_vals", "+", "neg_vals", "\n", "\n", "losses", "=", "torch", ".", "sum", "(", "vals", "*", "targets_mask", ",", "dim", "=", "-", "1", ")", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "losses", "*=", "weights", "\n", "\n", "", "return", "torch", ".", "mean", "(", "losses", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.onehot_encode_batch": [[6, 13], ["len", "numpy.zeros", "enumerate"], "function", ["None"], ["def", "onehot_encode_batch", "(", "class_ids_list", ",", "n_classes", ")", ":", "\n", "    ", "batch_size", "=", "len", "(", "class_ids_list", ")", "\n", "tmp", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "n_classes", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "class_ids", "in", "enumerate", "(", "class_ids_list", ")", ":", "\n", "        ", "for", "cid", "in", "class_ids", ":", "\n", "            ", "tmp", "[", "i", "]", "[", "cid", "]", "=", "1.0", "\n", "", "", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.define_loss": [[15, 69], ["torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.squeeze", "gen_targets.index_select", "loss_func", "torch.sum", "torch.squeeze", "fine_targets.index_select", "loss_func", "torch.sum", "torch.squeeze", "finer_targets.index_select", "loss_func", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.min", "torch.min", "torch.sum", "torch.min", "torch.sum"], "function", ["None"], ["", "def", "define_loss", "(", "device", ",", "loss_func", ",", "logits", ",", "targets", ",", "data_type", "=", "'open'", ")", ":", "\n", "    ", "gen_cutoff", ",", "fine_cutoff", ",", "final_cutoff", "=", "config", ".", "TYPE_NUM_DICT", "[", "'gen'", "]", ",", "config", ".", "TYPE_NUM_DICT", "[", "'kb'", "]", ",", "None", "\n", "if", "data_type", "==", "'wiki'", ":", "\n", "        ", "final_cutoff", "=", "config", ".", "TYPE_NUM_DICT", "[", "'wiki'", "]", "\n", "", "loss_is_valid", "=", "False", "\n", "loss", "=", "torch", ".", "tensor", "(", "0.0", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "comparison_tensor", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ",", "device", "=", "device", ")", "\n", "gen_targets", "=", "targets", "[", ":", ",", ":", "gen_cutoff", "]", "\n", "fine_targets", "=", "targets", "[", ":", ",", "gen_cutoff", ":", "fine_cutoff", "]", "\n", "gen_target_sum", "=", "torch", ".", "sum", "(", "gen_targets", ",", "1", ")", "\n", "fine_target_sum", "=", "torch", ".", "sum", "(", "fine_targets", ",", "1", ")", "\n", "# print(logits.size())", "\n", "# print(targets)", "\n", "# print(gen_target_sum)", "\n", "# print(gen_target_sum.size())", "\n", "\n", "if", "torch", ".", "sum", "(", "gen_target_sum", ".", "data", ")", ">", "0", ":", "\n", "        ", "gen_mask", "=", "torch", ".", "squeeze", "(", "torch", ".", "nonzero", "(", "\n", "torch", ".", "min", "(", "gen_target_sum", ".", "data", ",", "comparison_tensor", ")", ",", "as_tuple", "=", "False", ")", ",", "dim", "=", "1", ")", "\n", "# print(gen_mask)", "\n", "gen_logit_masked", "=", "logits", "[", ":", ",", ":", "gen_cutoff", "]", "[", "gen_mask", ",", ":", "]", "\n", "# gen_mask = torch.autograd.Variable(gen_mask).cuda()", "\n", "gen_target_masked", "=", "gen_targets", ".", "index_select", "(", "0", ",", "gen_mask", ")", "\n", "# print(gen_target_masked)", "\n", "# exit()", "\n", "gen_loss", "=", "loss_func", "(", "gen_logit_masked", ",", "gen_target_masked", ")", "\n", "loss", "+=", "gen_loss", "\n", "loss_is_valid", "=", "True", "\n", "", "if", "torch", ".", "sum", "(", "fine_target_sum", ".", "data", ")", ">", "0", ":", "\n", "        ", "fine_mask", "=", "torch", ".", "squeeze", "(", "torch", ".", "nonzero", "(", "\n", "torch", ".", "min", "(", "fine_target_sum", ".", "data", ",", "comparison_tensor", ")", ",", "as_tuple", "=", "False", ")", ",", "dim", "=", "1", ")", "\n", "fine_logit_masked", "=", "logits", "[", ":", ",", "gen_cutoff", ":", "fine_cutoff", "]", "[", "fine_mask", ",", ":", "]", "\n", "# fine_mask = torch.autograd.Variable(fine_mask).cuda()", "\n", "fine_target_masked", "=", "fine_targets", ".", "index_select", "(", "0", ",", "fine_mask", ")", "\n", "fine_loss", "=", "loss_func", "(", "fine_logit_masked", ",", "fine_target_masked", ")", "\n", "loss", "+=", "fine_loss", "\n", "loss_is_valid", "=", "True", "\n", "\n", "", "if", "final_cutoff", ":", "\n", "        ", "finer_targets", "=", "targets", "[", ":", ",", "fine_cutoff", ":", "final_cutoff", "]", "\n", "logit_masked", "=", "logits", "[", ":", ",", "fine_cutoff", ":", "final_cutoff", "]", "\n", "", "else", ":", "\n", "        ", "logit_masked", "=", "logits", "[", ":", ",", "fine_cutoff", ":", "]", "\n", "finer_targets", "=", "targets", "[", ":", ",", "fine_cutoff", ":", "]", "\n", "", "if", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "finer_targets", ",", "1", ")", ".", "data", ")", ">", "0", ":", "\n", "        ", "finer_mask", "=", "torch", ".", "squeeze", "(", "torch", ".", "nonzero", "(", "\n", "torch", ".", "min", "(", "torch", ".", "sum", "(", "finer_targets", ",", "1", ")", ".", "data", ",", "comparison_tensor", ")", ",", "as_tuple", "=", "False", ")", ",", "dim", "=", "1", ")", "\n", "# finer_mask = torch.autograd.Variable(finer_mask).cuda()", "\n", "finer_target_masked", "=", "finer_targets", ".", "index_select", "(", "0", ",", "finer_mask", ")", "\n", "logit_masked", "=", "logit_masked", "[", "finer_mask", ",", ":", "]", "\n", "layer_loss", "=", "loss_func", "(", "logit_masked", ",", "finer_target_masked", ")", "\n", "loss", "+=", "layer_loss", "\n", "loss_is_valid", "=", "True", "\n", "", "return", "loss", "if", "loss_is_valid", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.eval_uf": [[71, 99], ["list", "len", "list", "utils.macro_f1_gptups", "list", "list", "model.data.cpu().numpy", "enumerate", "torch.no_grad", "modelutils.pad_id_seqs", "model", "numpy.squeeze", "logits_list.append", "gold_tids_list.append", "list.append", "list.append", "model.data.cpu", "numpy.argwhere", "len", "print", "numpy.argmax", "len", "len"], "function", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.utils.utils.macro_f1_gptups", "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs"], ["", "def", "eval_uf", "(", "device", ",", "model", ",", "type_vocab", ",", "batch_iter", ",", "pad_id", "=", "0", ",", "show_progress", "=", "False", ")", ":", "\n", "    ", "from", "models", "import", "utils", "as", "modelutils", "\n", "from", "utils", "import", "utils", "\n", "\n", "results", "=", "list", "(", ")", "\n", "n_types", "=", "len", "(", "type_vocab", ")", "\n", "gp_tups", "=", "list", "(", ")", "\n", "logits_list", ",", "gold_tids_list", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "batch", "in", "batch_iter", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "tok_id_seqs", "=", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", "\n", "token_id_seqs_tensor", ",", "attn_mask", "=", "modelutils", ".", "pad_id_seqs", "(", "tok_id_seqs", ",", "device", ",", "pad_id", ")", "\n", "logits_batch", "=", "model", "(", "token_id_seqs_tensor", ",", "attn_mask", ")", "\n", "# logits_batch = model(token_id_seqs_tensor, attn_mask)", "\n", "", "logits_batch", "=", "logits_batch", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", ",", "logits", "in", "enumerate", "(", "logits_batch", ")", ":", "\n", "            ", "idxs", "=", "np", ".", "squeeze", "(", "np", ".", "argwhere", "(", "logits", ">", "0", ")", ",", "axis", "=", "1", ")", "\n", "if", "len", "(", "idxs", ")", "==", "0", ":", "\n", "                ", "idxs", "=", "[", "np", ".", "argmax", "(", "logits", ")", "]", "\n", "", "logits_list", ".", "append", "(", "logits", ")", "\n", "gold_tids_list", ".", "append", "(", "batch", "[", "i", "]", "[", "2", "]", ")", "\n", "gp_tups", ".", "append", "(", "(", "batch", "[", "i", "]", "[", "2", "]", ",", "idxs", ")", ")", "\n", "r", "=", "{", "'id'", ":", "batch", "[", "i", "]", "[", "0", "]", ",", "'types'", ":", "[", "type_vocab", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "}", "\n", "results", ".", "append", "(", "r", ")", "\n", "if", "show_progress", "and", "len", "(", "results", ")", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "len", "(", "results", ")", ")", "\n", "", "", "", "p", ",", "r", ",", "f1", "=", "utils", ".", "macro_f1_gptups", "(", "gp_tups", ")", "\n", "return", "p", ",", "r", ",", "f1", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.exp.exputils.define_loss_partial": [[123, 209], ["torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.squeeze", "gen_targets.index_select", "gen_targets_mask.index_select", "torch.sum", "torch.squeeze", "fine_targets.index_select", "fine_targets_mask.index_select", "torch.sum", "torch.sum", "torch.squeeze", "finer_targets.index_select", "finer_targets_mask.index_select", "torch.nonzero", "loss_func", "loss_func", "torch.nonzero", "loss_func", "loss_func", "torch.nonzero", "loss_func", "loss_func", "torch.min", "torch.min", "torch.min"], "function", ["None"], ["", "", "def", "define_loss_partial", "(", "device", ",", "loss_func", ",", "logits", ",", "targets", ",", "targets_mask", ",", "data_type", "=", "'open'", ",", "weights", "=", "None", ")", ":", "\n", "    ", "gen_cutoff", ",", "fine_cutoff", ",", "final_cutoff", "=", "config", ".", "TYPE_NUM_DICT", "[", "'gen'", "]", ",", "config", ".", "TYPE_NUM_DICT", "[", "'kb'", "]", ",", "None", "\n", "if", "data_type", "==", "'wiki'", ":", "\n", "        ", "final_cutoff", "=", "config", ".", "TYPE_NUM_DICT", "[", "'wiki'", "]", "\n", "", "loss_is_valid", "=", "False", "\n", "loss", "=", "torch", ".", "tensor", "(", "0.0", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "comparison_tensor", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ",", "device", "=", "device", ")", "\n", "gen_targets", "=", "targets", "[", ":", ",", ":", "gen_cutoff", "]", "\n", "fine_targets", "=", "targets", "[", ":", ",", "gen_cutoff", ":", "fine_cutoff", "]", "\n", "gen_target_sum", "=", "torch", ".", "sum", "(", "gen_targets", ",", "1", ")", "\n", "fine_target_sum", "=", "torch", ".", "sum", "(", "fine_targets", ",", "1", ")", "\n", "# print(logits.size())", "\n", "# print(gen_targets)", "\n", "# print(gen_target_sum)", "\n", "# print(gen_target_sum.size())", "\n", "\n", "if", "torch", ".", "sum", "(", "gen_target_sum", ".", "data", ")", ">", "0", ":", "\n", "        ", "gen_mask", "=", "torch", ".", "squeeze", "(", "torch", ".", "nonzero", "(", "\n", "torch", ".", "min", "(", "gen_target_sum", ".", "data", ",", "comparison_tensor", ")", ",", "as_tuple", "=", "False", ")", ",", "dim", "=", "1", ")", "\n", "# print(gen_mask)", "\n", "gen_logit_masked", "=", "logits", "[", ":", ",", ":", "gen_cutoff", "]", "[", "gen_mask", ",", ":", "]", "\n", "# gen_mask = torch.autograd.Variable(gen_mask).cuda()", "\n", "gen_target_masked", "=", "gen_targets", ".", "index_select", "(", "0", ",", "gen_mask", ")", "\n", "\n", "gen_targets_mask", "=", "targets_mask", "[", ":", ",", ":", "gen_cutoff", "]", "\n", "gen_target_mask_masked", "=", "gen_targets_mask", ".", "index_select", "(", "0", ",", "gen_mask", ")", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "gen_loss", "=", "loss_func", "(", "\n", "gen_logit_masked", ",", "gen_target_masked", ",", "gen_target_mask_masked", ",", "weights", "=", "weights", "[", "gen_mask", "]", ")", "\n", "", "else", ":", "\n", "            ", "gen_loss", "=", "loss_func", "(", "\n", "gen_logit_masked", ",", "gen_target_masked", ",", "gen_target_mask_masked", ")", "\n", "# print(gen_target_mask_masked)", "\n", "# print(gen_loss)", "\n", "# exit()", "\n", "", "loss", "+=", "gen_loss", "\n", "loss_is_valid", "=", "True", "\n", "", "if", "torch", ".", "sum", "(", "fine_target_sum", ".", "data", ")", ">", "0", ":", "\n", "        ", "fine_mask", "=", "torch", ".", "squeeze", "(", "torch", ".", "nonzero", "(", "\n", "torch", ".", "min", "(", "fine_target_sum", ".", "data", ",", "comparison_tensor", ")", ",", "as_tuple", "=", "False", ")", ",", "dim", "=", "1", ")", "\n", "fine_logit_masked", "=", "logits", "[", ":", ",", "gen_cutoff", ":", "fine_cutoff", "]", "[", "fine_mask", ",", ":", "]", "\n", "# fine_mask = torch.autograd.Variable(fine_mask).cuda()", "\n", "fine_target_masked", "=", "fine_targets", ".", "index_select", "(", "0", ",", "fine_mask", ")", "\n", "\n", "fine_targets_mask", "=", "targets_mask", "[", ":", ",", "gen_cutoff", ":", "fine_cutoff", "]", "\n", "fine_target_mask_masked", "=", "fine_targets_mask", ".", "index_select", "(", "0", ",", "fine_mask", ")", "\n", "# print(fine_target_mask_masked)", "\n", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "fine_loss", "=", "loss_func", "(", "fine_logit_masked", ",", "fine_target_masked", ",", "fine_target_mask_masked", ",", "\n", "weights", "=", "weights", "[", "fine_mask", "]", ")", "\n", "", "else", ":", "\n", "            ", "fine_loss", "=", "loss_func", "(", "fine_logit_masked", ",", "fine_target_masked", ",", "fine_target_mask_masked", ")", "\n", "# print('fine', fine_loss)", "\n", "", "loss", "+=", "fine_loss", "\n", "loss_is_valid", "=", "True", "\n", "\n", "", "if", "final_cutoff", ":", "\n", "        ", "finer_targets", "=", "targets", "[", ":", ",", "fine_cutoff", ":", "final_cutoff", "]", "\n", "logit_masked", "=", "logits", "[", ":", ",", "fine_cutoff", ":", "final_cutoff", "]", "\n", "", "else", ":", "\n", "        ", "logit_masked", "=", "logits", "[", ":", ",", "fine_cutoff", ":", "]", "\n", "finer_targets", "=", "targets", "[", ":", ",", "fine_cutoff", ":", "]", "\n", "\n", "", "finger_targets_sum", "=", "torch", ".", "sum", "(", "finer_targets", ",", "1", ")", ".", "data", "\n", "if", "torch", ".", "sum", "(", "finger_targets_sum", ")", ">", "0", ":", "\n", "        ", "finer_mask", "=", "torch", ".", "squeeze", "(", "torch", ".", "nonzero", "(", "\n", "torch", ".", "min", "(", "finger_targets_sum", ",", "comparison_tensor", ")", ",", "as_tuple", "=", "False", ")", ",", "dim", "=", "1", ")", "\n", "# finer_mask = torch.autograd.Variable(finer_mask).cuda()", "\n", "finer_target_masked", "=", "finer_targets", ".", "index_select", "(", "0", ",", "finer_mask", ")", "\n", "\n", "finer_targets_mask", "=", "(", "\n", "targets_mask", "[", ":", ",", "fine_cutoff", ":", "final_cutoff", "]", "if", "final_cutoff", "else", "targets_mask", "[", ":", ",", "fine_cutoff", ":", "]", ")", "\n", "finer_target_mask_masked", "=", "finer_targets_mask", ".", "index_select", "(", "0", ",", "finer_mask", ")", "\n", "\n", "logit_masked", "=", "logit_masked", "[", "finer_mask", ",", ":", "]", "\n", "# finer_weights_masked = None if weights is None else weights[finer_mask]", "\n", "if", "weights", "is", "not", "None", ":", "\n", "            ", "layer_loss", "=", "loss_func", "(", "logit_masked", ",", "finer_target_masked", ",", "finer_target_mask_masked", ",", "\n", "weights", "=", "weights", "[", "finer_mask", "]", ")", "\n", "", "else", ":", "\n", "            ", "layer_loss", "=", "loss_func", "(", "logit_masked", ",", "finer_target_masked", ",", "finer_target_mask_masked", ")", "\n", "# print('finer', layer_loss)", "\n", "", "loss", "+=", "layer_loss", "\n", "loss_is_valid", "=", "True", "\n", "", "return", "loss", "if", "loss_is_valid", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.__init__": [[7, 18], ["torch.nn.Module.__init__", "pretrained_bert_model.startswith", "torch.nn.Linear", "transformers.BertModel.from_pretrained", "transformers.RobertaModel.from_pretrained", "bertuf.BertUF.bert.embeddings.word_embeddings.weight.size"], "methods", ["home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_classes", ",", "pretrained_bert_model", "=", "'bert-base-cased'", ")", ":", "\n", "        ", "super", "(", "BertUF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "pretrained_bert_model", ".", "startswith", "(", "'bert'", ")", ":", "\n", "            ", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "pretrained_bert_model", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bert", "=", "RobertaModel", ".", "from_pretrained", "(", "pretrained_bert_model", ")", "\n", "", "bert_dim", "=", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "size", "(", ")", "[", "1", "]", "\n", "# for k, v in self.bert.named_parameters():", "\n", "#     print(k, v.size())", "\n", "self", ".", "top_lin", "=", "nn", ".", "Linear", "(", "bert_dim", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.get_reps": [[19, 23], ["bertuf.BertUF.bert"], "methods", ["None"], ["", "def", "get_reps", "(", "self", ",", "tok_id_seqs", ",", "attn_mask", ",", "segment_ids", "=", "None", ")", ":", "\n", "        ", "tok_rep_seqs", ",", "_", "=", "self", ".", "bert", "(", "tok_id_seqs", ",", "attn_mask", ",", "token_type_ids", "=", "segment_ids", ")", "\n", "cls_reps", "=", "tok_rep_seqs", "[", ":", ",", "0", ",", ":", "]", "\n", "return", "cls_reps", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.forward": [[24, 30], ["bertuf.BertUF.bert", "bertuf.BertUF.top_lin"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tok_id_seqs", ",", "attn_mask", ",", "segment_ids", "=", "None", ")", ":", "\n", "        ", "tok_rep_seqs", ",", "_", "=", "self", ".", "bert", "(", "tok_id_seqs", ",", "attn_mask", ",", "token_type_ids", "=", "segment_ids", ")", "\n", "cls_reps", "=", "tok_rep_seqs", "[", ":", ",", "0", ",", ":", "]", "\n", "logits", "=", "self", ".", "top_lin", "(", "cls_reps", ")", "\n", "# print(cls_reps.size())", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.bertuf.BertUF.from_trained": [[31, 48], ["torch.load", "dict", "torch.load.items", "bertuf.BertUF", "BertUF.load_state_dict", "k.startswith", "state_dict[].size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_trained", "(", "model_file", ",", "bert_model", "=", "'bert-base-cased'", ")", ":", "\n", "        ", "state_dict_tmp", "=", "torch", ".", "load", "(", "model_file", ",", "map_location", "=", "'cpu'", ")", "\n", "state_dict", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict_tmp", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'module'", ")", ":", "\n", "                ", "state_dict", "[", "k", "[", "7", ":", "]", "]", "=", "v", "\n", "", "else", ":", "\n", "                ", "state_dict", "[", "k", "]", "=", "v", "\n", "\n", "", "", "n_classes", "=", "state_dict", "[", "'top_lin.weight'", "]", ".", "size", "(", ")", "[", "0", "]", "\n", "# for k, v in state_dict.items():", "\n", "#     print(k, v.size())", "\n", "# exit()", "\n", "model", "=", "BertUF", "(", "n_classes", ",", "pretrained_bert_model", "=", "bert_model", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "model", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HKUST-KnowComp_MLMET.models.utils.pad_id_seqs": [[5, 16], ["len", "max", "numpy.zeros", "enumerate", "torch.tensor", "torch.tensor", "numpy.ones", "len", "len", "len"], "function", ["None"], ["\n", "pronouns", "=", "{", "'i'", ",", "'me'", ",", "'myself'", ",", "'we'", ",", "'us'", ",", "'ourselves'", ",", "'he'", ",", "'him'", ",", "'himself'", ",", "'she'", ",", "'her'", ",", "'herself'", ",", "\n", "'it'", ",", "'they'", ",", "'them'", ",", "'themselves'", ",", "'you'", "}", "\n", "\n", "\n", "def", "calc_f1", "(", "p", ",", "r", ")", ":", "\n", "    ", "if", "r", "==", "0.", ":", "\n", "        ", "return", "0.", "\n", "", "return", "2", "*", "p", "*", "r", "/", "float", "(", "p", "+", "r", ")", "\n", "\n", "\n", "", "def", "macro_f1_gptups", "(", "true_and_prediction", ")", ":", "\n"]]}