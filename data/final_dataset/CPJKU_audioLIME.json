{"home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.Factorization.__init__": [[46, 63], ["isinstance", "factorization_base.compute_segments", "audioLIME.audio_utils.load_audio"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.compute_segments", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.audio_utils.load_audio"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "target_sr", ",", "temporal_segmentation_params", "=", "None", ",", "composition_fn", "=", "None", ")", ":", "\n", "        ", "self", ".", "_audio_path", "=", "None", "\n", "self", ".", "target_sr", "=", "target_sr", "\n", "if", "isinstance", "(", "input", ",", "str", ")", ":", "\n", "            ", "self", ".", "_audio_path", "=", "input", "\n", "input", "=", "load_audio", "(", "input", ",", "target_sr", ")", "\n", "", "self", ".", "_original_mix", "=", "input", "\n", "if", "composition_fn", "is", "None", ":", "\n", "            ", "composition_fn", "=", "default_composition_fn", "\n", "", "self", ".", "_composition_fn", "=", "composition_fn", "\n", "\n", "self", ".", "original_components", "=", "[", "]", "\n", "self", ".", "components", "=", "[", "]", "\n", "self", ".", "_components_names", "=", "[", "]", "\n", "self", ".", "temporal_segments", ",", "self", ".", "explained_length", "=", "compute_segments", "(", "self", ".", "_original_mix", ",", "\n", "self", ".", "target_sr", ",", "\n", "temporal_segmentation_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.Factorization.compose_model_input": [[64, 66], ["factorization_base.Factorization._composition_fn", "factorization_base.Factorization.retrieve_components"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.retrieve_components"], ["", "def", "compose_model_input", "(", "self", ",", "components", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_composition_fn", "(", "self", ".", "retrieve_components", "(", "components", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.Factorization.get_number_components": [[67, 70], ["len"], "methods", ["None"], ["", "def", "get_number_components", "(", "self", ")", ":", "\n", "# TODO: probably no need to overwrite in other classes", "\n", "        ", "return", "len", "(", "self", ".", "_components_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.Factorization.retrieve_components": [[71, 73], ["None"], "methods", ["None"], ["", "def", "retrieve_components", "(", "self", ",", "selection_order", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.Factorization.get_ordered_component_names": [[74, 76], ["None"], "methods", ["None"], ["", "def", "get_ordered_component_names", "(", "self", ")", ":", "# e.g. instrument names", "\n", "        ", "return", "self", ".", "_components_names", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.TimeOnlyFactorization.__init__": [[80, 84], ["factorization_base.Factorization.__init__", "range", "len", "factorization_base.TimeOnlyFactorization._components_names.append", "str"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "target_sr", ",", "temporal_segmentation_params", "=", "None", ",", "composition_fn", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input", ",", "target_sr", ",", "temporal_segmentation_params", ",", "composition_fn", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "temporal_segments", ")", ")", ":", "\n", "            ", "self", ".", "_components_names", ".", "append", "(", "\"T\"", "+", "str", "(", "i", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.TimeOnlyFactorization.retrieve_components": [[85, 94], ["numpy.zeros_like"], "methods", ["None"], ["", "", "def", "retrieve_components", "(", "self", ",", "selection_order", "=", "None", ")", ":", "\n", "# TODO: check if selection_order contains out of bounds segments", "\n", "        ", "if", "selection_order", "is", "None", ":", "\n", "            ", "return", "self", ".", "_original_mix", "\n", "", "retrieved_mix", "=", "np", ".", "zeros_like", "(", "self", ".", "_original_mix", ")", "\n", "for", "so", "in", "selection_order", ":", "\n", "            ", "s", ",", "e", "=", "self", ".", "temporal_segments", "[", "so", "]", "\n", "retrieved_mix", "[", "s", ":", "e", "]", "=", "self", ".", "_original_mix", "[", "s", ":", "e", "]", "\n", "", "return", "retrieved_mix", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.__init__": [[98, 110], ["factorization_base.Factorization.__init__", "factorization_base.SourceSeparationBasedFactorization.initialize_components", "factorization_base.SourceSeparationBasedFactorization.prepare_components", "len"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.SpleeterPrecomputedFactorization.initialize_components", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.prepare_components"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "target_sr", "=", "16000", ",", "temporal_segmentation_params", "=", "None", ",", "composition_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param input: file_name of audio or numpy array containing waveform\n        :param n_temporal_segments: number of temporal segments used in the segmentation\n        :param composition_fn: allows to apply transformations to the summed sources,\n                e.g. return a spectrogram\n                (same factorization class can be used independent of the input the model requires)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "input", ",", "target_sr", ",", "temporal_segmentation_params", ",", "composition_fn", ")", "\n", "# the following part is specific to each source sep. algorithm", "\n", "self", ".", "original_components", ",", "self", ".", "_components_names", "=", "self", ".", "initialize_components", "(", ")", "\n", "self", ".", "prepare_components", "(", "0", ",", "len", "(", "self", ".", "_original_mix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.compose_model_input": [[111, 118], ["factorization_base.SourceSeparationBasedFactorization.retrieve_components", "factorization_base.SourceSeparationBasedFactorization._composition_fn", "len", "sum"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.retrieve_components"], ["", "def", "compose_model_input", "(", "self", ",", "components", "=", "None", ")", ":", "\n", "        ", "sel_sources", "=", "self", ".", "retrieve_components", "(", "selection_order", "=", "components", ")", "\n", "if", "len", "(", "sel_sources", ")", ">", "1", ":", "\n", "            ", "y", "=", "sum", "(", "sel_sources", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "sel_sources", "[", "0", "]", "\n", "", "return", "self", ".", "_composition_fn", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.get_number_components": [[119, 121], ["len"], "methods", ["None"], ["", "def", "get_number_components", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "components", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.retrieve_components": [[122, 128], ["len", "numpy.zeros_like"], "methods", ["None"], ["", "def", "retrieve_components", "(", "self", ",", "selection_order", "=", "None", ")", ":", "\n", "        ", "if", "selection_order", "is", "None", ":", "\n", "            ", "return", "self", ".", "components", "\n", "", "if", "len", "(", "selection_order", ")", "==", "0", ":", "\n", "            ", "return", "[", "np", ".", "zeros_like", "(", "self", ".", "components", "[", "0", "]", ")", "]", "\n", "", "return", "[", "self", ".", "components", "[", "o", "]", "for", "o", "in", "selection_order", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.get_ordered_component_names": [[129, 133], ["len", "Exception"], "methods", ["None"], ["", "def", "get_ordered_component_names", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "_components_names", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Components were not named.\"", ")", "\n", "", "return", "self", ".", "_components_names", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.initialize_components": [[134, 136], ["None"], "methods", ["None"], ["", "def", "initialize_components", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.SourceSeparationBasedFactorization.prepare_components": [[137, 153], ["enumerate", "range", "factorization_base.SourceSeparationBasedFactorization.get_number_components", "numpy.zeros", "temporary_components.append", "component_names.append", "str"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.get_number_components"], ["", "def", "prepare_components", "(", "self", ",", "start_sample", ",", "y_length", ")", ":", "\n", "# this resets in case temporal segmentation was previously applied", "\n", "        ", "self", ".", "components", "=", "[", "\n", "comp", "[", "start_sample", ":", "start_sample", "+", "y_length", "]", "for", "comp", "in", "self", ".", "original_components", "]", "\n", "\n", "component_names", "=", "[", "]", "\n", "temporary_components", "=", "[", "]", "\n", "for", "s", ",", "(", "segment_start", ",", "segment_end", ")", "in", "enumerate", "(", "self", ".", "temporal_segments", ")", ":", "\n", "            ", "for", "co", "in", "range", "(", "self", ".", "get_number_components", "(", ")", ")", ":", "\n", "                ", "current_component", "=", "np", ".", "zeros", "(", "self", ".", "explained_length", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "current_component", "[", "segment_start", ":", "segment_end", "]", "=", "self", ".", "components", "[", "co", "]", "[", "segment_start", ":", "segment_end", "]", "\n", "temporary_components", ".", "append", "(", "current_component", ")", "\n", "component_names", ".", "append", "(", "self", ".", "_components_names", "[", "co", "]", "+", "str", "(", "s", ")", ")", "\n", "\n", "", "", "self", ".", "components", "=", "temporary_components", "\n", "self", ".", "_components_names", "=", "component_names", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.default_composition_fn": [[6, 8], ["None"], "function", ["None"], ["def", "default_composition_fn", "(", "x", ")", ":", "\n", "    ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_base.compute_segments": [[10, 43], ["len", "min", "isinstance", "range", "warnings.warn", "segments.append"], "function", ["None"], ["", "def", "compute_segments", "(", "signal", ",", "sr", ",", "temporal_segmentation_params", "=", "None", ")", ":", "\n", "# TODO: parameter for return type (samples, frames, seconds)?", "\n", "    ", "audio_length", "=", "len", "(", "signal", ")", "\n", "explained_length", "=", "audio_length", "\n", "if", "temporal_segmentation_params", "is", "None", ":", "\n", "        ", "n_temporal_segments_default", "=", "min", "(", "audio_length", "//", "sr", ",", "10", ")", "# 1 segment per second, but maximally 10 segments", "\n", "temporal_segmentation_params", "=", "{", "'type'", ":", "'fixed_length'", ",", "\n", "'n_temporal_segments'", ":", "n_temporal_segments_default", "}", "\n", "", "elif", "isinstance", "(", "temporal_segmentation_params", ",", "int", ")", ":", "\n", "        ", "temporal_segmentation_params", "=", "{", "'type'", ":", "'fixed_length'", ",", "\n", "'n_temporal_segments'", ":", "temporal_segmentation_params", "}", "\n", "\n", "", "segmentation_type", "=", "temporal_segmentation_params", "[", "'type'", "]", "\n", "assert", "segmentation_type", "in", "[", "'fixed_length'", ",", "'manual'", "]", "\n", "\n", "segments", "=", "[", "]", "\n", "if", "segmentation_type", "==", "\"fixed_length\"", ":", "\n", "        ", "n_temporal_segments", "=", "temporal_segmentation_params", "[", "'n_temporal_segments'", "]", "\n", "samples_per_segment", "=", "audio_length", "//", "n_temporal_segments", "\n", "\n", "explained_length", "=", "samples_per_segment", "*", "n_temporal_segments", "\n", "if", "explained_length", "<", "audio_length", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"last {} samples are ignored\"", ".", "format", "(", "audio_length", "-", "explained_length", ")", ")", "\n", "\n", "", "for", "s", "in", "range", "(", "n_temporal_segments", ")", ":", "\n", "            ", "segment_start", "=", "s", "*", "samples_per_segment", "\n", "segment_end", "=", "segment_start", "+", "samples_per_segment", "\n", "segments", ".", "append", "(", "(", "segment_start", ",", "segment_end", ")", ")", "\n", "", "", "elif", "segmentation_type", "==", "\"manual\"", ":", "\n", "        ", "segments", "=", "temporal_segmentation_params", "[", "\"manual_segments\"", "]", "\n", "explained_length", "=", "segments", "[", "-", "1", "]", "[", "1", "]", "# end of last segment", "\n", "\n", "", "return", "segments", ",", "explained_length", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_image.ImageLikeFactorization.__init__": [[10, 37], ["audioLIME.factorization_base.Factorization.__init__", "torchaudio_spec.detach().cpu().numpy", "factorization_image.ImageLikeFactorization.initialize_components", "len", "ValueError", "torchaudio_spec.detach().cpu", "torchaudio_spec.detach"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.SpleeterPrecomputedFactorization.initialize_components"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "target_sr", ",", "torchaudio_spec", ",", "\n", "image_segmentation_algorithm", "=", "\"slic\"", ",", "image_segmentation_params", "=", "None", ",", "\n", "baseline", "=", "\"zero\"", ",", "temporal_segmentation_params", "=", "None", ")", ":", "\n", "# TODO: pass spectrogram", "\n", "        ", "assert", "image_segmentation_algorithm", "in", "image_segmentation_algorithm_options", "\n", "assert", "baseline", "in", "[", "\"zero\"", ",", "\"min\"", "]", "\n", "assert", "len", "(", "torchaudio_spec", ".", "shape", ")", "==", "2", "\n", "if", "temporal_segmentation_params", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"temporal_segmentation_params can not be used with ImageLikeFactorization\"", ")", "\n", "", "temporal_segmentation_params", "=", "{", "'type'", ":", "'fixed_length'", ",", "\n", "'n_temporal_segments'", ":", "1", "}", "\n", "super", "(", ")", ".", "__init__", "(", "input", ",", "target_sr", ",", "temporal_segmentation_params", ",", "composition_fn", "=", "None", ")", "\n", "self", ".", "spectrogram", "=", "torchaudio_spec", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "baseline", "=", "baseline", "\n", "if", "image_segmentation_params", "is", "None", ":", "\n", "            ", "if", "image_segmentation_algorithm", "==", "\"slic\"", ":", "\n", "                ", "image_segmentation_params", "=", "{", "}", "# to disable warning", "\n", "", "elif", "image_segmentation_algorithm", "==", "\"fsz\"", ":", "\n", "                ", "image_segmentation_params", "=", "{", "\n", "\"scale\"", ":", "25", ",", "\n", "\"min_size\"", ":", "40", "\n", "}", "\n", "", "", "if", "image_segmentation_algorithm", "==", "\"slic\"", ":", "\n", "            ", "image_segmentation_params", "[", "\"start_label\"", "]", "=", "1", "# to disable warning", "\n", "", "self", ".", "image_segmentation_algorithm", "=", "image_segmentation_algorithm", "\n", "self", ".", "image_segmentation_params", "=", "image_segmentation_params", "\n", "self", ".", "original_components", ",", "self", ".", "_components_names", "=", "self", ".", "initialize_components", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_image.ImageLikeFactorization.initialize_components": [[38, 53], ["numpy.unique", "skimage.slic", "skimage.felzenszwalb", "str"], "methods", ["None"], ["", "def", "initialize_components", "(", "self", ")", ":", "\n", "        ", "algorithm", "=", "self", ".", "image_segmentation_algorithm", "\n", "params", "=", "self", ".", "image_segmentation_params", "\n", "segments", "=", "[", "]", "\n", "if", "algorithm", "==", "\"slic\"", ":", "\n", "            ", "segments", "=", "segmentation", ".", "slic", "(", "self", ".", "spectrogram", ",", "**", "params", ")", "\n", "", "elif", "algorithm", "==", "\"fsz\"", ":", "\n", "# Finally, regarding possible image segmentation algorithms", "\n", "# (Felzenszwalb, SLIC, Chan Vese, Watershed),", "\n", "# experiments showed that Felzenszwalb (with scale=25 and minsize=40)", "\n", "# provided the most reasonable visual segmentation of the spectrograms.", "\n", "            ", "segments", "=", "segmentation", ".", "felzenszwalb", "(", "self", ".", "spectrogram", ",", "**", "params", ")", "\n", "", "unique_components", "=", "np", ".", "unique", "(", "segments", ")", "\n", "segment_names", "=", "[", "\"S\"", "+", "str", "(", "nr", ")", "for", "nr", "in", "unique_components", "]", "\n", "return", "segments", ",", "segment_names", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_image.ImageLikeFactorization.retrieve_components": [[54, 75], ["max", "numpy.zeros_like", "numpy.ones_like", "numpy.zeros_like", "factorization_image.ImageLikeFactorization.get_number_components", "ValueError", "factorization_image.ImageLikeFactorization.get_number_components", "factorization_image.ImageLikeFactorization.spectrogram.min"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.get_number_components", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.get_number_components"], ["", "def", "retrieve_components", "(", "self", ",", "selection_order", "=", "None", ")", ":", "\n", "        ", "if", "selection_order", "is", "None", ":", "\n", "            ", "return", "self", ".", "spectrogram", "\n", "\n", "", "max_val", "=", "max", "(", "selection_order", ")", "\n", "if", "max_val", ">=", "self", ".", "get_number_components", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"{} out of bounds for {} components\"", ",", "max_val", ",", "self", ".", "get_number_components", "(", ")", ")", "\n", "\n", "", "mask", "=", "np", ".", "zeros_like", "(", "self", ".", "spectrogram", ")", "\n", "unmask", "=", "np", ".", "ones_like", "(", "self", ".", "spectrogram", ")", "\n", "baseline", "=", "np", ".", "zeros_like", "(", "self", ".", "spectrogram", ")", "\n", "\n", "if", "self", ".", "baseline", "==", "\"min\"", ":", "\n", "            ", "baseline", "=", "baseline", "+", "self", ".", "spectrogram", ".", "min", "(", ")", "\n", "\n", "", "for", "so", "in", "selection_order", ":", "\n", "            ", "mask_idx", "=", "self", ".", "original_components", "==", "so", "+", "1", "# skimage starts counting at 1, lime at 0", "\n", "mask", "[", "mask_idx", "]", "=", "1.", "\n", "unmask", "[", "mask_idx", "]", "=", "0.", "\n", "\n", "", "return", "self", ".", "spectrogram", "*", "mask", "+", "baseline", "*", "unmask", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.__init__": [[44, 54], ["audioLIME.factorization_base.Factorization.__init__", "factorization_slime.initialize_baseline", "len"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.initialize_baseline"], ["def", "__init__", "(", "self", ",", "input", ",", "target_sr", ",", "frequency_segments", "=", "4", ",", "temporal_segmentation_params", "=", "6", ",", "hop_length", "=", "256", ",", "baseline", "=", "\"zero\"", ",", "\n", "composition_fn", "=", "None", ")", ":", "\n", "        ", "assert", "len", "(", "input", ".", "shape", ")", "==", "2", "\n", "super", "(", ")", ".", "__init__", "(", "input", ",", "target_sr", ",", "temporal_segmentation_params", ",", "composition_fn", "=", "composition_fn", ")", "\n", "assert", "baseline", "in", "[", "\"zero\"", ",", "\"min\"", ",", "\"mean\"", ",", "\"unif\"", ",", "\"shuffle\"", ",", "\"max\"", "]", "\n", "self", ".", "n_frequency_segments", "=", "frequency_segments", "\n", "self", ".", "spectrogram", "=", "input", "\n", "self", ".", "hop_length", "=", "hop_length", "\n", "self", ".", "baseline_type", "=", "baseline", "\n", "self", ".", "baseline", "=", "initialize_baseline", "(", "baseline_type", "=", "baseline", ",", "x", "=", "self", ".", "spectrogram", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.compose_model_input": [[56, 58], ["factorization_slime.TimeFrequencyTorchFactorization._composition_fn", "factorization_slime.TimeFrequencyTorchFactorization.retrieve_components"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.retrieve_components"], ["", "def", "compose_model_input", "(", "self", ",", "components", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_composition_fn", "(", "self", ".", "retrieve_components", "(", "components", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.get_number_components": [[59, 61], ["len"], "methods", ["None"], ["", "def", "get_number_components", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_frequency_segments", "*", "len", "(", "self", ".", "temporal_segments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.retrieve_components": [[62, 103], ["torch.zeros_like", "torch.ones_like", "len", "max", "len", "warnings.warn", "librosa.samples_to_frames", "factorization_slime.TimeFrequencyTorchFactorization.retrieve_components.compute_f_start"], "methods", ["None"], ["", "def", "retrieve_components", "(", "self", ",", "selection_order", "=", "None", ")", ":", "\n", "        ", "if", "selection_order", "is", "None", ":", "\n", "            ", "return", "self", ".", "spectrogram", "\n", "\n", "", "if", "len", "(", "selection_order", ")", ">", "0", ":", "\n", "            ", "max_val", "=", "max", "(", "selection_order", ")", "\n", "if", "max_val", ">=", "self", ".", "get_number_components", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"{} out of bounds for {} components\"", ",", "max_val", ",", "self", ".", "get_number_components", "(", ")", ")", "\n", "\n", "", "", "mask", "=", "torch", ".", "zeros_like", "(", "self", ".", "spectrogram", ")", "\n", "unmask", "=", "torch", ".", "ones_like", "(", "self", ".", "spectrogram", ")", "\n", "\n", "# following the order of segments in [Mishra 2017] Figure 4", "\n", "temp_length", "=", "mask", ".", "shape", "[", "1", "]", "//", "len", "(", "self", ".", "temporal_segments", ")", "\n", "freq_length", "=", "mask", ".", "shape", "[", "0", "]", "//", "self", ".", "n_frequency_segments", "\n", "\n", "left_over", "=", "mask", ".", "shape", "[", "1", "]", "-", "temp_length", "*", "len", "(", "self", ".", "temporal_segments", ")", "\n", "if", "left_over", ">", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Adding last {} frames to last segment\"", ".", "format", "(", "left_over", ")", ")", "\n", "\n", "", "def", "compute_f_start", "(", "f", ")", ":", "\n", "            ", "return", "f", "*", "freq_length", "\n", "\n", "", "def", "compute_f_end", "(", "f", ")", ":", "\n", "            ", "return", "compute_f_start", "(", "f", ")", "+", "freq_length", "\n", "\n", "", "for", "so", "in", "selection_order", ":", "\n", "            ", "t", "=", "so", "//", "self", ".", "n_frequency_segments", "# index of temporal_segment", "\n", "# print(\"t\", t)", "\n", "f", "=", "so", "%", "self", ".", "n_frequency_segments", "\n", "\n", "[", "t_start", ",", "t_end", "]", "=", "librosa", ".", "samples_to_frames", "(", "self", ".", "temporal_segments", "[", "t", "]", ",", "hop_length", "=", "self", ".", "hop_length", ")", "\n", "if", "t", "==", "len", "(", "self", ".", "temporal_segments", ")", "-", "1", ":", "\n", "                ", "t_end", "=", "mask", ".", "shape", "[", "1", "]", "\n", "# print(\"t_start {}, t_end{}\".format(t_start, t_end))", "\n", "", "f_start", "=", "compute_f_start", "(", "f", ")", "\n", "f_end", "=", "compute_f_end", "(", "f", ")", "\n", "mask", "[", "f_start", ":", "f_end", ",", "t_start", ":", "t_end", "]", "=", "1.", "\n", "unmask", "[", "f_start", ":", "f_end", ",", "t_start", ":", "t_end", "]", "=", "0.", "\n", "\n", "", "return", "self", ".", "spectrogram", "*", "mask", "+", "self", ".", "baseline", "*", "unmask", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.initialize_baseline": [[8, 33], ["torch.zeros_like", "x.min", "x.max", "x.mean", "torch.rand_like", "x.max", "numpy.arange", "numpy.random.shuffle", "enumerate", "factorization_slime.initialize_baseline._1d_to2d"], "function", ["None"], ["def", "initialize_baseline", "(", "baseline_type", ",", "x", ")", ":", "\n", "    ", "baseline", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "if", "baseline_type", "==", "\"min\"", ":", "\n", "        ", "baseline", "=", "baseline", "+", "x", ".", "min", "(", ")", "\n", "", "elif", "baseline_type", "==", "\"max\"", ":", "\n", "        ", "baseline", "=", "baseline", "+", "x", ".", "max", "(", ")", "\n", "", "elif", "baseline_type", "==", "\"mean\"", ":", "\n", "        ", "baseline", "=", "baseline", "+", "x", ".", "mean", "(", ")", "\n", "", "elif", "baseline_type", "==", "\"unif\"", ":", "\n", "        ", "baseline", "=", "torch", ".", "rand_like", "(", "x", ")", "*", "x", ".", "max", "(", ")", "\n", "", "elif", "baseline_type", "==", "\"shuffle\"", ":", "\n", "        ", "def", "_1d_to2d", "(", "n_col", ",", "i", ")", ":", "\n", "# https://softwareengineering.stackexchange.com/a/212813/91332", "\n", "            ", "new_col", "=", "i", "%", "n_col", "\n", "new_row", "=", "i", "//", "n_col", "\n", "return", "new_col", ",", "new_row", "\n", "\n", "", "n_rows", ",", "n_cols", "=", "x", ".", "shape", "\n", "index", "=", "np", ".", "arange", "(", "n_rows", "*", "n_cols", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "index", ")", "\n", "for", "orig_i", ",", "new_i", "in", "enumerate", "(", "index", ")", ":", "\n", "            ", "new_col", ",", "new_row", "=", "_1d_to2d", "(", "n_cols", ",", "new_i", ")", "\n", "orig_col", ",", "orig_row", "=", "_1d_to2d", "(", "x", ".", "shape", "[", "1", "]", ",", "orig_i", ")", "\n", "baseline", "[", "new_row", ",", "new_col", "]", "=", "x", "[", "orig_row", ",", "orig_col", "]", "\n", "", "", "return", "baseline", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.SpleeterFactorization.__init__": [[21, 25], ["audioLIME.factorization_base.SourceSeparationBasedFactorization.__init__"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "temporal_segmentation_params", ",", "composition_fn", ",", "target_sr", "=", "16000", ",", "\n", "model_name", "=", "\"spleeter:5stems\"", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "model_name", "\n", "super", "(", ")", ".", "__init__", "(", "input", ",", "target_sr", ",", "temporal_segmentation_params", ",", "composition_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.SpleeterFactorization.initialize_components": [[26, 41], ["Separator", "librosa.resample", "numpy.expand_dims", "Separator.separate", "list", "librosa.resample", "Separator.separate.keys", "numpy.mean"], "methods", ["None"], ["", "def", "initialize_components", "(", "self", ")", ":", "\n", "        ", "spleeter_sr", "=", "44100", "\n", "\n", "waveform", "=", "self", ".", "_original_mix", "\n", "separator", "=", "Separator", "(", "self", ".", "model_name", ",", "multiprocess", "=", "False", ")", "\n", "waveform", "=", "librosa", ".", "resample", "(", "waveform", ",", "self", ".", "target_sr", ",", "spleeter_sr", ")", "\n", "waveform", "=", "np", ".", "expand_dims", "(", "waveform", ",", "axis", "=", "1", ")", "\n", "prediction", "=", "separator", ".", "separate", "(", "waveform", ")", "\n", "\n", "original_components", "=", "[", "\n", "librosa", ".", "resample", "(", "np", ".", "mean", "(", "prediction", "[", "key", "]", ",", "axis", "=", "1", ")", ",", "spleeter_sr", ",", "self", ".", "target_sr", ")", "for", "\n", "key", "in", "prediction", "]", "\n", "\n", "components_names", "=", "list", "(", "prediction", ".", "keys", "(", ")", ")", "\n", "return", "original_components", ",", "components_names", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.SpleeterPrecomputedFactorization.__init__": [[52, 62], ["isinstance", "os.path.join", "os.path.exists", "factorization_spleeter.SpleeterFactorization.__init__", "TypeError"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "temporal_segmentation_params", ",", "composition_fn", ",", "target_sr", "=", "16000", ",", "\n", "model_name", "=", "\"spleeter:5stems\"", ",", "spleeter_sources_path", "=", "None", ",", "recompute", "=", "False", ")", ":", "\n", "        ", "assert", "isinstance", "(", "input", ",", "str", ")", ",", "\"input must be file path. otherwise use SpleeterFactorization.\"", "\n", "if", "spleeter_sources_path", "is", "None", ":", "\n", "            ", "raise", "TypeError", "(", "\"spleeter_sources_path must not be None. \"", "\n", "\"Provide path or use SpleeterFactorization.\"", ")", "\n", "", "self", ".", "spleeter_sources_path", "=", "os", ".", "path", ".", "join", "(", "spleeter_sources_path", ",", "model_name", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "spleeter_sources_path", ")", "\n", "self", ".", "recompute", "=", "recompute", "\n", "super", "(", ")", ".", "__init__", "(", "input", ",", "temporal_segmentation_params", ",", "composition_fn", ",", "target_sr", ",", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.SpleeterPrecomputedFactorization.initialize_components": [[63, 83], ["os.path.join", "list", "os.path.basename", "Separator", "librosa.resample", "numpy.expand_dims", "Separator.separate", "factorization_spleeter.pickle_dump", "factorization_spleeter.pickle_load", "librosa.resample", "pickle_load.keys", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.pickle_dump", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.pickle_load"], ["", "def", "initialize_components", "(", "self", ")", ":", "\n", "        ", "spleeter_sr", "=", "44100", "\n", "precomputed_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "_audio_path", ")", "+", "\".pt\"", "\n", "precomputed_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "spleeter_sources_path", ",", "precomputed_name", ")", "\n", "if", "self", ".", "recompute", ":", "\n", "            ", "waveform", "=", "self", ".", "_original_mix", "\n", "separator", "=", "Separator", "(", "self", ".", "model_name", ",", "multiprocess", "=", "False", ")", "\n", "waveform", "=", "librosa", ".", "resample", "(", "waveform", ",", "self", ".", "target_sr", ",", "spleeter_sr", ")", "\n", "waveform", "=", "np", ".", "expand_dims", "(", "waveform", ",", "axis", "=", "1", ")", "\n", "prediction", "=", "separator", ".", "separate", "(", "waveform", ")", "\n", "pickle_dump", "(", "prediction", ",", "precomputed_path", ")", "\n", "", "else", ":", "\n", "            ", "prediction", "=", "pickle_load", "(", "precomputed_path", ")", "\n", "\n", "", "original_components", "=", "[", "\n", "librosa", ".", "resample", "(", "np", ".", "mean", "(", "prediction", "[", "key", "]", ",", "axis", "=", "1", ")", ",", "spleeter_sr", ",", "self", ".", "target_sr", ")", "for", "\n", "key", "in", "prediction", "]", "\n", "\n", "components_names", "=", "list", "(", "prediction", ".", "keys", "(", ")", ")", "\n", "return", "original_components", ",", "components_names", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.pickle_dump": [[43, 45], ["pickle.dump", "open"], "function", ["None"], ["", "", "def", "pickle_dump", "(", "x", ",", "path", ")", ":", "\n", "    ", "pickle", ".", "dump", "(", "x", ",", "open", "(", "path", ",", "\"wb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_spleeter.pickle_load": [[47, 49], ["pickle.load", "open"], "function", ["None"], ["", "def", "pickle_load", "(", "path", ")", ":", "\n", "    ", "return", "pickle", ".", "load", "(", "open", "(", "path", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.__init__": [[14, 33], ["sklearn.utils.check_random_state"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "kernel_fn", ",", "\n", "verbose", "=", "False", ",", "\n", "absolute_feature_sort", "=", "False", ",", "\n", "random_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Init function\n\n        Args:\n            kernel_fn: function that transforms an array of distances into an\n                        array of proximity values (floats).\n            verbose: if true, print local prediction values from linear model.\n            random_state: an integer or numpy.RandomState that will be used to\n                generate random numbers. If None, the random state will be\n                initialized using the internal numpy seed.\n        \"\"\"", "\n", "self", ".", "kernel_fn", "=", "kernel_fn", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "absolute_feature_sort", "=", "absolute_feature_sort", "\n", "self", ".", "random_state", "=", "check_random_state", "(", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.generate_lars_path": [[34, 52], ["sklearn.linear_model.lars_path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "generate_lars_path", "(", "weighted_data", ",", "weighted_labels", ")", ":", "\n", "        ", "\"\"\"Generates the lars path for weighted data.\n\n        Args:\n            weighted_data: data that has been weighted by kernel\n            weighted_label: labels, weighted by kernel\n\n        Returns:\n            (alphas, coefs), both are arrays corresponding to the\n            regularization parameter and coefficients, respectively\n        \"\"\"", "\n", "x_vector", "=", "weighted_data", "\n", "alphas", ",", "_", ",", "coefs", "=", "lars_path", "(", "x_vector", ",", "\n", "weighted_labels", ",", "\n", "method", "=", "'lasso'", ",", "\n", "verbose", "=", "False", ")", "\n", "return", "alphas", ",", "coefs", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.forward_selection": [[53, 73], ["sklearn.linear_model.Ridge", "range", "numpy.array", "min", "range", "used_features.append", "sklearn.linear_model.Ridge.fit", "sklearn.linear_model.Ridge.score"], "methods", ["None"], ["", "def", "forward_selection", "(", "self", ",", "data", ",", "labels", ",", "weights", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"Iteratively adds features to the model\"\"\"", "\n", "clf", "=", "Ridge", "(", "alpha", "=", "0", ",", "fit_intercept", "=", "True", ",", "random_state", "=", "self", ".", "random_state", ")", "\n", "used_features", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "min", "(", "num_features", ",", "data", ".", "shape", "[", "1", "]", ")", ")", ":", "\n", "            ", "max_", "=", "-", "100000000", "\n", "best", "=", "0", "\n", "for", "feature", "in", "range", "(", "data", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "if", "feature", "in", "used_features", ":", "\n", "                    ", "continue", "\n", "", "clf", ".", "fit", "(", "data", "[", ":", ",", "used_features", "+", "[", "feature", "]", "]", ",", "labels", ",", "\n", "sample_weight", "=", "weights", ")", "\n", "score", "=", "clf", ".", "score", "(", "data", "[", ":", ",", "used_features", "+", "[", "feature", "]", "]", ",", "\n", "labels", ",", "\n", "sample_weight", "=", "weights", ")", "\n", "if", "score", ">", "max_", ":", "\n", "                    ", "best", "=", "feature", "\n", "max_", "=", "score", "\n", "", "", "used_features", ".", "append", "(", "best", ")", "\n", "", "return", "np", ".", "array", "(", "used_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.feature_selection": [[74, 140], ["numpy.array", "range", "lime_base.LimeBase.forward_selection", "sklearn.linear_model.Ridge", "sklearn.linear_model.Ridge.fit", "scipy.sparse.issparse", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix.multiply", "len", "numpy.abs().argsort", "sorted", "numpy.array", "range", "lime_base.LimeBase.generate_lars_path", "range", "numpy.concatenate", "set", "range", "zip", "numpy.sqrt", "numpy.sqrt", "lime_base.LimeBase.feature_selection", "numpy.abs", "range", "numpy.average", "numpy.average", "len", "coefs.T[].nonzero", "len", "numpy.zeros", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.forward_selection", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.generate_lars_path", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.feature_selection"], ["", "def", "feature_selection", "(", "self", ",", "data", ",", "labels", ",", "weights", ",", "num_features", ",", "method", ")", ":", "\n", "        ", "\"\"\"Selects features for the model. see explain_instance_with_data to\n           understand the parameters.\"\"\"", "\n", "if", "method", "==", "'none'", ":", "\n", "            ", "return", "np", ".", "array", "(", "range", "(", "data", ".", "shape", "[", "1", "]", ")", ")", "\n", "", "elif", "method", "==", "'forward_selection'", ":", "\n", "            ", "return", "self", ".", "forward_selection", "(", "data", ",", "labels", ",", "weights", ",", "num_features", ")", "\n", "", "elif", "method", "==", "'highest_weights'", ":", "\n", "            ", "clf", "=", "Ridge", "(", "alpha", "=", "0", ",", "fit_intercept", "=", "True", ",", "\n", "random_state", "=", "self", ".", "random_state", ")", "\n", "clf", ".", "fit", "(", "data", ",", "labels", ",", "sample_weight", "=", "weights", ")", "\n", "\n", "coef", "=", "clf", ".", "coef_", "\n", "if", "sp", ".", "sparse", ".", "issparse", "(", "data", ")", ":", "\n", "                ", "coef", "=", "sp", ".", "sparse", ".", "csr_matrix", "(", "clf", ".", "coef_", ")", "\n", "weighted_data", "=", "coef", ".", "multiply", "(", "data", "[", "0", "]", ")", "\n", "# Note: most efficient to slice the data before reversing", "\n", "sdata", "=", "len", "(", "weighted_data", ".", "data", ")", "\n", "argsort_data", "=", "np", ".", "abs", "(", "weighted_data", ".", "data", ")", ".", "argsort", "(", ")", "\n", "# Edge case where data is more sparse than requested number of feature importances", "\n", "# In that case, we just pad with zero-valued features", "\n", "if", "sdata", "<", "num_features", ":", "\n", "                    ", "nnz_indexes", "=", "argsort_data", "[", ":", ":", "-", "1", "]", "\n", "indices", "=", "weighted_data", ".", "indices", "[", "nnz_indexes", "]", "\n", "num_to_pad", "=", "num_features", "-", "sdata", "\n", "indices", "=", "np", ".", "concatenate", "(", "(", "indices", ",", "np", ".", "zeros", "(", "num_to_pad", ",", "dtype", "=", "indices", ".", "dtype", ")", ")", ")", "\n", "indices_set", "=", "set", "(", "indices", ")", "\n", "pad_counter", "=", "0", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "1", "]", ")", ":", "\n", "                        ", "if", "i", "not", "in", "indices_set", ":", "\n", "                            ", "indices", "[", "pad_counter", "+", "sdata", "]", "=", "i", "\n", "pad_counter", "+=", "1", "\n", "if", "pad_counter", ">=", "num_to_pad", ":", "\n", "                                ", "break", "\n", "", "", "", "", "else", ":", "\n", "                    ", "nnz_indexes", "=", "argsort_data", "[", "sdata", "-", "num_features", ":", "sdata", "]", "[", ":", ":", "-", "1", "]", "\n", "indices", "=", "weighted_data", ".", "indices", "[", "nnz_indexes", "]", "\n", "", "return", "indices", "\n", "", "else", ":", "\n", "                ", "weighted_data", "=", "coef", "*", "data", "[", "0", "]", "\n", "feature_weights", "=", "sorted", "(", "# TODO: check if abs should be optional", "\n", "zip", "(", "range", "(", "data", ".", "shape", "[", "1", "]", ")", ",", "weighted_data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "np", ".", "abs", "(", "x", "[", "1", "]", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "return", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "feature_weights", "[", ":", "num_features", "]", "]", ")", "\n", "", "", "elif", "method", "==", "'lasso_path'", ":", "\n", "            ", "weighted_data", "=", "(", "(", "data", "-", "np", ".", "average", "(", "data", ",", "axis", "=", "0", ",", "weights", "=", "weights", ")", ")", "\n", "*", "np", ".", "sqrt", "(", "weights", "[", ":", ",", "np", ".", "newaxis", "]", ")", ")", "\n", "weighted_labels", "=", "(", "(", "labels", "-", "np", ".", "average", "(", "labels", ",", "weights", "=", "weights", ")", ")", "\n", "*", "np", ".", "sqrt", "(", "weights", ")", ")", "\n", "nonzero", "=", "range", "(", "weighted_data", ".", "shape", "[", "1", "]", ")", "\n", "_", ",", "coefs", "=", "self", ".", "generate_lars_path", "(", "weighted_data", ",", "\n", "weighted_labels", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "coefs", ".", "T", ")", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "nonzero", "=", "coefs", ".", "T", "[", "i", "]", ".", "nonzero", "(", ")", "[", "0", "]", "\n", "if", "len", "(", "nonzero", ")", "<=", "num_features", ":", "\n", "                    ", "break", "\n", "", "", "used_features", "=", "nonzero", "\n", "return", "used_features", "\n", "", "elif", "method", "==", "'auto'", ":", "\n", "            ", "if", "num_features", "<=", "6", ":", "\n", "                ", "n_method", "=", "'forward_selection'", "\n", "", "else", ":", "\n", "                ", "n_method", "=", "'highest_weights'", "\n", "", "return", "self", ".", "feature_selection", "(", "data", ",", "labels", ",", "weights", ",", "\n", "num_features", ",", "n_method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.explain_instance_with_data": [[141, 220], ["lime_base.LimeBase.kernel_fn", "lime_base.LimeBase.feature_selection", "easy_model.fit", "easy_model.score", "easy_model.predict", "sklearn.linear_model.Ridge", "neighborhood_data[].reshape", "sorted", "sorted", "print", "print", "print", "print", "zip", "zip", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.feature_selection"], ["", "", "def", "explain_instance_with_data", "(", "self", ",", "\n", "neighborhood_data", ",", "\n", "neighborhood_labels", ",", "\n", "distances", ",", "\n", "label", ",", "\n", "num_features", ",", "\n", "feature_selection", "=", "'auto'", ",", "\n", "model_regressor", "=", "None", ",", "\n", "fit_intercept", "=", "True", ")", ":", "\n", "        ", "\"\"\"Takes perturbed data, labels and distances, returns explanation.\n\n        Args:\n            neighborhood_data: perturbed data, 2d array. first element is\n                               assumed to be the original data point.\n            neighborhood_labels: corresponding perturbed labels. should have as\n                                 many columns as the number of possible labels.\n            distances: distances to original data point.\n            label: label for which we want an explanation\n            num_features: maximum number of features in explanation\n            feature_selection: how to select num_features. options are:\n                'forward_selection': iteratively add features to the model.\n                    This is costly when num_features is high\n                'highest_weights': selects the features that have the highest\n                    product of absolute weight * original data point when\n                    learning with all the features\n                'lasso_path': chooses features based on the lasso\n                    regularization path\n                'none': uses all features, ignores num_features\n                'auto': uses forward_selection if num_features <= 6, and\n                    'highest_weights' otherwise.\n            model_regressor: sklearn regressor to use in explanation.\n                Defaults to Ridge regression if None. Must have\n                model_regressor.coef_ and 'sample_weight' as a parameter\n                to model_regressor.fit()\n\n        Returns:\n            (intercept, exp, score, local_pred):\n            intercept is a float.\n            exp is a sorted list of tuples, where each tuple (x,y) corresponds\n            to the feature id (x) and the local weight (y). The list is sorted\n            by decreasing absolute value of y.\n            score is the R^2 value of the returned explanation\n            local_pred is the prediction of the explanation model on the original instance\n        \"\"\"", "\n", "\n", "weights", "=", "self", ".", "kernel_fn", "(", "distances", ")", "\n", "labels_column", "=", "neighborhood_labels", "[", ":", ",", "label", "]", "\n", "used_features", "=", "self", ".", "feature_selection", "(", "neighborhood_data", ",", "\n", "labels_column", ",", "\n", "weights", ",", "\n", "num_features", ",", "\n", "feature_selection", ")", "\n", "if", "model_regressor", "is", "None", ":", "\n", "            ", "model_regressor", "=", "Ridge", "(", "alpha", "=", "1", ",", "fit_intercept", "=", "fit_intercept", ",", "\n", "random_state", "=", "self", ".", "random_state", ")", "\n", "", "easy_model", "=", "model_regressor", "\n", "easy_model", ".", "fit", "(", "neighborhood_data", "[", ":", ",", "used_features", "]", ",", "\n", "labels_column", ",", "sample_weight", "=", "weights", ")", "\n", "prediction_score", "=", "easy_model", ".", "score", "(", "\n", "neighborhood_data", "[", ":", ",", "used_features", "]", ",", "\n", "labels_column", ",", "sample_weight", "=", "weights", ")", "\n", "\n", "local_pred", "=", "easy_model", ".", "predict", "(", "neighborhood_data", "[", "0", ",", "used_features", "]", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "\n", "\n", "if", "self", ".", "absolute_feature_sort", ":", "\n", "            ", "sorted_local_exp", "=", "sorted", "(", "zip", "(", "used_features", ",", "easy_model", ".", "coef_", ")", ",", "\n", "key", "=", "lambda", "x", ":", "np", ".", "abs", "(", "x", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "sorted_local_exp", "=", "sorted", "(", "zip", "(", "used_features", ",", "easy_model", ".", "coef_", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'Intercept:'", ",", "easy_model", ".", "intercept_", ")", "\n", "print", "(", "'Prediction_local:'", ",", "local_pred", ",", ")", "\n", "print", "(", "'Right:'", ",", "neighborhood_labels", "[", "0", ",", "label", "]", ")", "\n", "print", "(", "'Score:'", ",", "prediction_score", ")", "\n", "", "return", "(", "easy_model", ".", "intercept_", ",", "\n", "sorted_local_exp", ",", "\n", "prediction_score", ",", "local_pred", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_audio.AudioExplanation.__init__": [[14, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "factorization", ",", "neighborhood_data", ",", "neighborhood_labels", ")", ":", "\n", "        ", "\"\"\"Init function.\n\n        Args:\n            factorization: a Factorization object\n        \"\"\"", "\n", "self", ".", "factorization", "=", "factorization", "\n", "self", ".", "neighborhood_data", "=", "neighborhood_data", "\n", "self", ".", "neighborhood_labels", "=", "neighborhood_labels", "\n", "self", ".", "intercept", "=", "{", "}", "\n", "self", ".", "local_exp", "=", "{", "}", "\n", "self", ".", "local_pred", "=", "{", "}", "\n", "self", ".", "score", "=", "{", "}", "\n", "self", ".", "distance", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_audio.AudioExplanation.get_sorted_components": [[29, 67], ["lime_audio.AudioExplanation.factorization.retrieve_components", "KeyError", "ValueError", "ValueError", "len", "isinstance", "numpy.array", "numpy.array", "numpy.argwhere", "numpy.argwhere", "numpy.argwhere", "abs"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.retrieve_components"], ["", "def", "get_sorted_components", "(", "self", ",", "label", ",", "positive_components", "=", "True", ",", "negative_components", "=", "True", ",", "num_components", "=", "'all'", ",", "\n", "min_abs_weight", "=", "0.0", ",", "return_indeces", "=", "False", ")", ":", "\n", "        ", "if", "label", "not", "in", "self", ".", "local_exp", ":", "\n", "            ", "raise", "KeyError", "(", "'Label not in explanation'", ")", "\n", "", "if", "positive_components", "is", "False", "and", "negative_components", "is", "False", ":", "\n", "            ", "raise", "ValueError", "(", "'positive_components, negative_components or both must be True'", ")", "\n", "", "if", "num_components", "==", "'auto'", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_components='auto' was removed.\"", ")", "\n", "\n", "", "exp", "=", "self", ".", "local_exp", "[", "label", "]", "\n", "\n", "w", "=", "[", "[", "x", "[", "0", "]", ",", "x", "[", "1", "]", "]", "for", "x", "in", "exp", "]", "\n", "used_features", ",", "weights", "=", "np", ".", "array", "(", "w", ",", "dtype", "=", "int", ")", "[", ":", ",", "0", "]", ",", "np", ".", "array", "(", "w", ")", "[", ":", ",", "1", "]", "\n", "\n", "if", "not", "negative_components", ":", "\n", "            ", "pos_weights", "=", "np", ".", "argwhere", "(", "weights", ">", "0", ")", "[", ":", ",", "0", "]", "\n", "used_features", "=", "used_features", "[", "pos_weights", "]", "\n", "weights", "=", "weights", "[", "pos_weights", "]", "\n", "", "elif", "not", "positive_components", ":", "\n", "            ", "neg_weights", "=", "np", ".", "argwhere", "(", "weights", "<", "0", ")", "[", ":", ",", "0", "]", "\n", "used_features", "=", "used_features", "[", "neg_weights", "]", "\n", "weights", "=", "weights", "[", "neg_weights", "]", "\n", "", "if", "min_abs_weight", "!=", "0.0", ":", "\n", "            ", "abs_weights", "=", "np", ".", "argwhere", "(", "abs", "(", "weights", ")", ">=", "min_abs_weight", ")", "[", ":", ",", "0", "]", "\n", "used_features", "=", "used_features", "[", "abs_weights", "]", "\n", "weights", "=", "weights", "[", "abs_weights", "]", "\n", "\n", "", "if", "num_components", "==", "'all'", ":", "\n", "            ", "num_components", "=", "len", "(", "used_features", ")", "\n", "", "else", ":", "\n", "            ", "assert", "(", "isinstance", "(", "num_components", ",", "int", ")", ")", "\n", "# max_components = used_features[:num_components]", "\n", "\n", "", "used_features", "=", "used_features", "[", ":", "num_components", "]", "\n", "components", "=", "self", ".", "factorization", ".", "retrieve_components", "(", "used_features", ")", "\n", "if", "return_indeces", ":", "\n", "            ", "return", "components", ",", "used_features", "\n", "", "return", "components", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_audio.LimeAudioExplainer.__init__": [[72, 102], ["float", "functools.partial", "sklearn.utils.check_random_state", "sklearn.utils.check_random_state", "audioLIME.lime_base.LimeBase", "numpy.sqrt", "numpy.exp"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "kernel_width", "=", ".25", ",", "kernel", "=", "None", ",", "verbose", "=", "False", ",", "\n", "feature_selection", "=", "'auto'", ",", "absolute_feature_sort", "=", "False", ",", "random_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Init function.\n\n        Args:\n            kernel_width: kernel width for the exponential kernel.\n            If None, defaults to sqrt(number of columns) * 0.75.\n            kernel: similarity kernel that takes euclidean distances and kernel\n                width as input and outputs weights in (0,1). If None, defaults to\n                an exponential kernel.\n            verbose: if true, print local prediction values from linear model\n            feature_selection: feature selection method. can be\n                'forward_selection', 'lasso_path', 'none' or 'auto'.\n                See function 'explain_instance_with_data' in lime_base.py for\n                details on what each of the options does.\n            : an integer or numpy.RandomState that will be used to\n                generate random numbers. If None, the random state will be\n                initialized using the internal numpy seed.\n        \"\"\"", "\n", "kernel_width", "=", "float", "(", "kernel_width", ")", "\n", "\n", "if", "kernel", "is", "None", ":", "\n", "            ", "def", "kernel", "(", "d", ",", "kernel_width", ")", ":", "\n", "                ", "return", "np", ".", "sqrt", "(", "np", ".", "exp", "(", "-", "(", "d", "**", "2", ")", "/", "kernel_width", "**", "2", ")", ")", "\n", "\n", "", "", "kernel_fn", "=", "partial", "(", "kernel", ",", "kernel_width", "=", "kernel_width", ")", "\n", "\n", "self", ".", "random_state", "=", "check_random_state", "(", "random_state", ")", "\n", "self", ".", "feature_selection", "=", "feature_selection", "\n", "self", ".", "base", "=", "lime_base", ".", "LimeBase", "(", "kernel_fn", ",", "verbose", ",", "absolute_feature_sort", ",", "random_state", "=", "self", ".", "random_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_audio.LimeAudioExplainer.explain_instance": [[103, 196], ["lime_audio.LimeAudioExplainer.data_labels", "sklearn.metrics.pairwise_distances().ravel", "sklearn.metrics.pairwise_distances().ravel", "sklearn.metrics.pairwise_distances().ravel", "sklearn.metrics.pairwise_distances().ravel", "lime_audio.AudioExplanation", "ValueError", "lime_audio.LimeAudioExplainer.random_state.randint", "range", "sklearn.metrics.pairwise_distances", "sklearn.metrics.pairwise_distances", "sklearn.metrics.pairwise_distances", "sklearn.metrics.pairwise_distances", "list", "AudioExplanation.top_labels.reverse", "lime_audio.LimeAudioExplainer.base.explain_instance_with_data", "lime_audio.LimeAudioExplainer.base.explain_instance_with_data", "data[].reshape", "numpy.argsort"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_audio.LimeAudioExplainer.data_labels", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.explain_instance_with_data", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_base.LimeBase.explain_instance_with_data"], ["", "def", "explain_instance", "(", "self", ",", "factorization", ",", "predict_fn", ",", "\n", "labels", "=", "None", ",", "\n", "top_labels", "=", "None", ",", "\n", "num_reg_targets", "=", "None", ",", "\n", "num_features", "=", "100000", ",", "\n", "num_samples", "=", "1000", ",", "\n", "batch_size", "=", "10", ",", "\n", "distance_metric", "=", "'cosine'", ",", "\n", "model_regressor", "=", "None", ",", "\n", "random_seed", "=", "None", ",", "\n", "fit_intercept", "=", "True", ")", ":", "\n", "        ", "\"\"\"Generates explanations for a prediction.\n\n        First, we generate neighborhood data by randomly perturbing features\n        from the instance (see __data_inverse). We then learn locally weighted\n        linear models on this neighborhood data to explain each of the classes\n        in an interpretable way (see lime_base.py).\n\n        Args:\n            factorization: function used for factorizing input audio\n            classifier_fn: classifier prediction probability function, which\n                takes a numpy array and outputs prediction probabilities.  For\n                ScikitClassifiers , this is classifier.predict_proba.\n            labels: iterable with labels to be explained.\n            top_labels: if not None, ignore labels and produce explanations for\n                the K labels with highest prediction probabilities, where K is\n                this parameter.\n            num_features: maximum number of features present in explanation\n            num_samples: size of the neighborhood to learn the linear model\n            batch_size: nr. of samples passed to the global model per batch when computing\n            the neighborhood labels\n            distance_metric: the distance metric to use for weights.\n            model_regressor: sklearn regressor to use in explanation. Defaults\n            to Ridge regression in LimeBase. Must have model_regressor.coef_\n            and 'sample_weight' as a parameter to model_regressor.fit()\n            random_seed: integer used as random seed for the segmentation\n                algorithm. If None, a random integer, between 0 and 1000,\n                will be generated using the internal random number generator.\n\n        Returns:\n            An AudioExplanation object (see lime_audio.py) with the corresponding\n            explanations.\n        \"\"\"", "\n", "\n", "# check whether regression or classification task", "\n", "is_classification", "=", "False", "\n", "if", "labels", "or", "top_labels", ":", "\n", "            ", "is_classification", "=", "True", "\n", "", "if", "is_classification", "and", "num_reg_targets", ":", "\n", "            ", "raise", "ValueError", "(", "'Set labels or top_labels for classification. '", "\n", "'Set num_reg_targets for regression.'", ")", "\n", "\n", "", "if", "random_seed", "is", "None", ":", "\n", "            ", "random_seed", "=", "self", ".", "random_state", ".", "randint", "(", "0", ",", "high", "=", "1000", ")", "\n", "\n", "", "self", ".", "factorization", "=", "factorization", "\n", "top", "=", "labels", "\n", "\n", "data", ",", "labels", "=", "self", ".", "data_labels", "(", "predict_fn", ",", "num_samples", ",", "\n", "batch_size", "=", "batch_size", ")", "\n", "\n", "distances", "=", "sklearn", ".", "metrics", ".", "pairwise_distances", "(", "\n", "data", ",", "\n", "data", "[", "0", "]", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "\n", "metric", "=", "distance_metric", "\n", ")", ".", "ravel", "(", ")", "\n", "\n", "ret_exp", "=", "AudioExplanation", "(", "self", ".", "factorization", ",", "data", ",", "labels", ")", "\n", "\n", "if", "is_classification", ":", "\n", "            ", "if", "top_labels", ":", "\n", "                ", "top", "=", "np", ".", "argsort", "(", "labels", "[", "0", "]", ")", "[", "-", "top_labels", ":", "]", "\n", "ret_exp", ".", "top_labels", "=", "list", "(", "top", ")", "\n", "ret_exp", ".", "top_labels", ".", "reverse", "(", ")", "\n", "", "for", "label", "in", "top", ":", "\n", "                ", "(", "ret_exp", ".", "intercept", "[", "label", "]", ",", "\n", "ret_exp", ".", "local_exp", "[", "label", "]", ",", "\n", "ret_exp", ".", "score", "[", "label", "]", ",", "ret_exp", ".", "local_pred", "[", "label", "]", ")", "=", "self", ".", "base", ".", "explain_instance_with_data", "(", "\n", "data", ",", "labels", ",", "distances", ",", "label", ",", "num_features", ",", "\n", "model_regressor", "=", "model_regressor", ",", "\n", "feature_selection", "=", "self", ".", "feature_selection", ",", "\n", "fit_intercept", "=", "fit_intercept", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "target", "in", "range", "(", "num_reg_targets", ")", ":", "\n", "                ", "(", "ret_exp", ".", "intercept", "[", "target", "]", ",", "\n", "ret_exp", ".", "local_exp", "[", "target", "]", ",", "\n", "ret_exp", ".", "score", "[", "target", "]", ",", "\n", "ret_exp", ".", "local_pred", "[", "target", "]", ")", "=", "self", ".", "base", ".", "explain_instance_with_data", "(", "\n", "data", ",", "labels", ",", "distances", ",", "target", ",", "num_features", ",", "\n", "model_regressor", "=", "model_regressor", ",", "\n", "feature_selection", "=", "self", ".", "feature_selection", ",", "\n", "fit_intercept", "=", "fit_intercept", ")", "\n", "", "", "return", "ret_exp", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.lime_audio.LimeAudioExplainer.data_labels": [[197, 238], ["lime_audio.LimeAudioExplainer.factorization.get_number_components", "numpy.array", "lime_audio.LimeAudioExplainer.random_state.randint().reshape", "lime_audio.LimeAudioExplainer.factorization.compose_model_input", "audios.append", "len", "predict_fn", "labels.extend", "numpy.array", "list", "numpy.where", "len", "predict_fn", "labels.extend", "numpy.array", "map", "lime_audio.LimeAudioExplainer.random_state.randint", "numpy.array", "itertools.product"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.get_number_components", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.compose_model_input"], ["", "def", "data_labels", "(", "self", ",", "\n", "predict_fn", ",", "\n", "num_samples", ",", "\n", "batch_size", "=", "10", ")", ":", "\n", "        ", "\"\"\"Generates audio and predictions in the neighborhood of this audio.\n\n        Args:\n            predict_fn: function that takes a list of audio inputs and returns a\n                matrix of predictions\n            num_samples: size of the neighborhood to learn the linear model\n            batch_size: classifier_fn will be called on batches of this size.\n\n        Returns:\n            A tuple (data, labels), where:\n                data: dense num_samples * num_factors\n                labels: prediction probabilities matrix\n        \"\"\"", "\n", "n_features", "=", "self", ".", "factorization", ".", "get_number_components", "(", ")", "\n", "if", "num_samples", "==", "'exhaustive'", ":", "\n", "            ", "import", "itertools", "\n", "num_samples", "=", "2", "**", "n_features", "\n", "data", "=", "np", ".", "array", "(", "list", "(", "map", "(", "list", ",", "itertools", ".", "product", "(", "[", "1", ",", "0", "]", ",", "repeat", "=", "n_features", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "self", ".", "random_state", ".", "randint", "(", "0", ",", "2", ",", "num_samples", "*", "n_features", ")", ".", "reshape", "(", "(", "num_samples", ",", "n_features", ")", ")", "\n", "data", "[", "0", ",", ":", "]", "=", "1", "# first row all is set to 1", "\n", "\n", "", "labels", "=", "[", "]", "\n", "audios", "=", "[", "]", "\n", "for", "row", "in", "data", ":", "\n", "            ", "non_zeros", "=", "np", ".", "where", "(", "row", "!=", "0", ")", "[", "0", "]", "\n", "temp", "=", "self", ".", "factorization", ".", "compose_model_input", "(", "non_zeros", ")", "\n", "audios", ".", "append", "(", "temp", ")", "\n", "if", "len", "(", "audios", ")", "==", "batch_size", ":", "\n", "                ", "preds", "=", "predict_fn", "(", "np", ".", "array", "(", "audios", ")", ")", "\n", "labels", ".", "extend", "(", "preds", ")", "\n", "audios", "=", "[", "]", "\n", "", "", "if", "len", "(", "audios", ")", ">", "0", ":", "\n", "            ", "preds", "=", "predict_fn", "(", "np", ".", "array", "(", "audios", ")", ")", "\n", "labels", ".", "extend", "(", "preds", ")", "\n", "", "return", "data", ",", "np", ".", "array", "(", "labels", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.audio_utils.load_audio": [[8, 11], ["librosa.load"], "function", ["None"], ["def", "load_audio", "(", "audio_path", ",", "target_sr", ")", ":", "\n", "    ", "waveform", ",", "_", "=", "librosa", ".", "load", "(", "audio_path", ",", "mono", "=", "True", ",", "sr", "=", "target_sr", ")", "\n", "return", "waveform", "\n", "", ""]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.evaluation.compute_complexity": [[4, 10], ["numpy.array", "sum", "numpy.array", "scipy.stats.entropy", "numpy.abs", "len"], "function", ["None"], ["def", "compute_complexity", "(", "explanation", ",", "target_idx", ")", ":", "\n", "    ", "local_exp", "=", "explanation", ".", "local_exp", "[", "target_idx", "]", "\n", "absolute_weights", "=", "np", ".", "array", "(", "[", "np", ".", "abs", "(", "x", "[", "1", "]", ")", "for", "x", "in", "local_exp", "]", ")", "\n", "sum_weigths", "=", "sum", "(", "absolute_weights", ")", "\n", "Pg", "=", "np", ".", "array", "(", "[", "gi", "/", "sum_weigths", "for", "gi", "in", "absolute_weights", "]", ")", "\n", "return", "entropy", "(", "Pg", ",", "base", "=", "len", "(", "Pg", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__": [[8, 14], ["unittest.TestCase.__init__", "librosa.util.example_audio_file", "audioLIME.audio_utils.load_audio", "librosa.load"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.__init__", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.audio_utils.load_audio"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "target_sr", "=", "16000", "\n", "self", ".", "audio_path", "=", "librosa", ".", "util", ".", "example_audio_file", "(", ")", "\n", "self", ".", "audio", "=", "load_audio", "(", "self", ".", "audio_path", ",", "target_sr", ")", "\n", "self", ".", "reference", ",", "_", "=", "librosa", ".", "load", "(", "self", ".", "audio_path", ",", "sr", "=", "target_sr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.test_SumAllComponents": [[15, 21], ["audioLIME.factorization_spleeter.SpleeterFactorization", "audioLIME.factorization_spleeter.SpleeterFactorization.compose_model_input", "test_SpleeterFactorization.TestSpleeterFactorization.assertTrue", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.compose_model_input"], ["", "def", "test_SumAllComponents", "(", "self", ")", ":", "\n", "        ", "factorization", "=", "SpleeterFactorization", "(", "self", ".", "audio", ",", "temporal_segmentation_params", "=", "1", ",", "\n", "composition_fn", "=", "None", ",", "\n", "model_name", "=", "'spleeter:5stems'", ")", "\n", "all_components", "=", "factorization", ".", "compose_model_input", "(", ")", "\n", "self", ".", "assertTrue", "(", "np", ".", "allclose", "(", "all_components", ",", "self", ".", "reference", ",", "atol", "=", "10", "**", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CPJKU_audioLIME.tests.test_SpleeterFactorization.TestSpleeterFactorization.test_TemporalSegmentation": [[22, 31], ["audioLIME.factorization_spleeter.SpleeterFactorization", "audioLIME.factorization_spleeter.SpleeterFactorization.compose_model_input", "len", "test_SpleeterFactorization.TestSpleeterFactorization.assertTrue", "test_SpleeterFactorization.TestSpleeterFactorization.assertEqual", "numpy.allclose", "audioLIME.factorization_spleeter.SpleeterFactorization.get_number_components"], "methods", ["home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.compose_model_input", "home.repos.pwc.inspect_result.CPJKU_audioLIME.audioLIME.factorization_slime.TimeFrequencyTorchFactorization.get_number_components"], ["", "def", "test_TemporalSegmentation", "(", "self", ")", ":", "\n", "        ", "n_segments", "=", "7", "\n", "factorization", "=", "SpleeterFactorization", "(", "self", ".", "audio", ",", "temporal_segmentation_params", "=", "n_segments", ",", "\n", "composition_fn", "=", "None", ",", "\n", "model_name", "=", "'spleeter:5stems'", ")", "\n", "all_components", "=", "factorization", ".", "compose_model_input", "(", ")", "\n", "leng", "=", "len", "(", "all_components", ")", "# to deal with ignored samples at the end", "\n", "self", ".", "assertTrue", "(", "np", ".", "allclose", "(", "all_components", ",", "self", ".", "reference", "[", ":", "leng", "]", ",", "atol", "=", "10", "**", "5", ")", ")", "\n", "self", ".", "assertEqual", "(", "n_segments", "*", "5", ",", "factorization", ".", "get_number_components", "(", ")", ")", "# nr. sources = 5", "\n", "\n"]]}